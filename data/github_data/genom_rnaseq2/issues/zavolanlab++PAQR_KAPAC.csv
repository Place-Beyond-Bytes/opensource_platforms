id,title,state,created_at,updated_at,closed_at,body,user,url
MDU6SXNzdWUzNDE5MTc2Njc=,Error when generating paqr_kapac virtual environment,CLOSED,2018-07-17T13:23:49Z,2018-08-30T14:04:38Z,2018-08-30T14:04:38Z,"I tried the command:

`conda create -n paqr_kapac -c bioconda -c ostrokach --file requirements_py3.txt`

And I get the following error message:

> Solving environment: failed
> 
> UnsatisfiableError: The following specifications were found to be in conflict:
>   - r-essentials==1.4.3
>   - r-optparse==1.3.2
> Use ""conda info <package>"" to see the dependencies for each package.",fgypas,https://github.com/zavolanlab/PAQR_KAPAC/issues/1
MDU6SXNzdWUzNDE5MTk2NDY=,README missing R and SRA tools version,CLOSED,2018-07-17T13:28:44Z,2018-11-19T08:35:23Z,2018-11-19T08:35:23Z,In the README it's missing the R and the SRA tools version that one should use.,fgypas,https://github.com/zavolanlab/PAQR_KAPAC/issues/2
MDU6SXNzdWUzNzcyODYyNTk=,annotation files for mm10,CLOSED,2018-11-05T07:56:39Z,2019-01-15T09:29:20Z,2019-01-15T09:29:20Z,"Hello, PAQR_KAPAC is a powerful tool to investigate APA.
You have provided  two annotation file of human.
data/annotation/clusters.hg38.canonical_chr.tandem.noOverlap_strand_specific.bed
data/annotation/full_transcripts.hg38.canonical_chr.tandem.noOverlap_strand_specific.bed

Now, I try to  investigate APA of mouse.
So, could provide the annotation files of mm10?",xflicsu,https://github.com/zavolanlab/PAQR_KAPAC/issues/3
MDU6SXNzdWU0NDg3MTAxMDU=,Input files for KAPAC,OPEN,2019-05-27T07:37:55Z,2019-06-17T13:43:34Z,,"Hello,

I'm interested in using PAQR and KAPAC on my own samples, but I'm unsure about the KAPAC input files. Specifically, I would like to know how to obtain the site count file for KAPAC (corresponding to kmer_counts.tsv of the test data). I don't see a suitable file among the output of PAQR.


Best regards,
Darius",khandarius,https://github.com/zavolanlab/PAQR_KAPAC/issues/4
MDU6SXNzdWU0NjcxOTI3ODM=,use custome annotation,CLOSED,2019-07-12T02:42:23Z,2019-11-27T09:23:15Z,2019-11-27T09:23:15Z,"hello, I wan't to use PAQR find APA in other species, and I have some polyA site information, how can i get annotation file like mm10,hg38 ",yuxinghai,https://github.com/zavolanlab/PAQR_KAPAC/issues/5
MDU6SXNzdWU0ODI0MjI5MjE=,Error in setting up the environment,OPEN,2019-08-19T16:59:24Z,2019-08-25T15:42:26Z,,"Hi,

I used the following command:
conda create -n paqr_kapac -c bioconda -c ostrokach --file requirements_py3.txt

And I received this error message:
Collecting package metadata (current_repodata.json): done
Solving environment: failed with current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: failed

PackagesNotFoundError: The following packages are not available from current channels:

  - python==3.5.1
  - docutils==0.12

Current channels:

  - https://conda.anaconda.org/bioconda/linux-64
  - https://conda.anaconda.org/bioconda/noarch
  - https://conda.anaconda.org/ostrokach/linux-64
  - https://conda.anaconda.org/ostrokach/noarch
  - https://repo.anaconda.com/pkgs/main/linux-64
  - https://repo.anaconda.com/pkgs/main/noarch
  - https://repo.anaconda.com/pkgs/r/linux-64
  - https://repo.anaconda.com/pkgs/r/noarch

To search for alternate channels that may provide the conda package you're
looking for, navigate to

    https://anaconda.org

and use the search bar at the top of the page.

Do you have any advice for solving this? 
Thanks for your help!

",jchariker,https://github.com/zavolanlab/PAQR_KAPAC/issues/6
MDU6SXNzdWU1MDUzNTE3MjE=,Incorrect indentation in one of the scripts.,OPEN,2019-10-10T15:36:12Z,2019-10-16T03:08:56Z,,"My initial problem is that I want to run PAQR with Python3. While I was modifying the syntax in the scripts I noticed a piece of code that did not raise any error while running with Python2, hovewer with Python3 - it does: `IndentationError: expected an indented block`. I nailed the error down: please take a look at the script `deNovo-used-sites-and-usage-inference.single_distal_included.py`, lines 1650:1678 in this repository. Tabs are mixed with spaces and I cannot disentangle how the proper indentation should look like.  
I have been trying and guessing a few options (with an input that I know that runs through on Python2) but all of them resulted in another error downstream.",AngryMaciek,https://github.com/zavolanlab/PAQR_KAPAC/issues/7
MDU6SXNzdWU1MjE0MzEyOTY=,snakemake symlink problem,CLOSED,2019-11-12T09:32:17Z,2019-11-13T04:32:57Z,2019-11-13T04:32:57Z,"```
snakemake -s part_two.Snakefile -n -p
MissingInputException in line 42 of /SAN/vyplab/alb_projects/tools/PAQR_KAPAC/PAQR/part_two.Snakefile:
Missing input files for rule create_coverages:
test_study/valid_samples/wt_1.bam
```
 
Link 235 in the part_one.Snakefile creates a broken a symlink if config['dir.input""] is already a full path
```
bam_file = ""../../"" + config[""dir.input""] + ""/"" + config[curr_uuid]['bam'] + "".bam""
```

The fix here was just removing the unnecessary ""../../"" ",aleighbrown,https://github.com/zavolanlab/PAQR_KAPAC/issues/8
MDU6SXNzdWU1MjE1MDA4NzU=,Error in rule infer_relative_usage UnboundLocalError: local variable 'end_idx' referenced before assignment,CLOSED,2019-11-12T11:44:53Z,2019-11-27T16:38:25Z,2019-11-27T16:38:25Z,"```
############## Started script on 12-11-2019 at 11:39:43 ##############
[INFO] Tue Nov 12 11:40:52 2019 Finished reading input
[INFO] Distal site skipped due to conflicting global break points in all samples in exon ENSMUST00000045887:3:3:71330480:71331126. Skipped exon!
[INFO] No site was inferred for ENSMUST00000115417:15:15:17942670:17943020. Skipped exon!
Traceback (most recent call last):
  File ""scripts/deNovo-used-sites-and-usage-inference.single_distal_included.py"", line 2302, in <module>
    main(options)
  File ""scripts/deNovo-used-sites-and-usage-inference.single_distal_included.py"", line 2118, in main
    result_tuples = pool.map( process_exon_wrapper_function, data_entries)
  File ""/SAN/vyplab/alb_projects/tools/.conda/envs/py2_paqr/lib/python2.7/multiprocessing/pool.py"", line 251, in map
    return self.map_async(func, iterable, chunksize).get()
  File ""/SAN/vyplab/alb_projects/tools/.conda/envs/py2_paqr/lib/python2.7/multiprocessing/pool.py"", line 567, in get
    raise self._value
UnboundLocalError: local variable 'end_idx' referenced before assignment
```",aleighbrown,https://github.com/zavolanlab/PAQR_KAPAC/issues/9
MDU6SXNzdWU1MjI1ODk4Mjg=,annotation files for hg19,OPEN,2019-11-14T02:47:37Z,2019-11-27T10:40:35Z,,"Hello!
We have annotation files of hg38 and mm10.
But I need to run PAQR in our data, which has been mapped to hg19.
Could you provide the annotation files of hg19? or, can I change the coordinate from hg38 to hg19 in the provided files?

Best wishes,
Jiayi Yang",yangjywhu,https://github.com/zavolanlab/PAQR_KAPAC/issues/10
MDU6SXNzdWU1MjUzNjk5NjI=,Error in rule infer_relative_usage: TypeError: not all arguments converted during string formatting,OPEN,2019-11-20T01:50:16Z,2019-11-27T10:52:50Z,,"Hello,

There is no problem in part_one, and all samples are in `no_bias_samples.out`.
But there is a problem in `infer_relative_usage` of part_two:
`TypeError: not all arguments converted during string formatting`
log of snakemake: 
```
RuleException:
CalledProcessError in line 142 of /data1/zhoulab/yangjiayi/project/hl/result/PAQR_gxl/PAQR/part_two.Snakefile:
Command 'set -euo pipefail;  ~/miniconda3/envs/py2_paqr/bin/python scripts/deNovo-used-sites-and-usage-inference.single_distal_included.py         --verbose         --clusters data/annotation/clusters.hg38.canonical_chr.tandem.noOverlap_strand_specific.bed         --coverages DE/coverages/DE-CE.pkl DE/coverages/DE-NM.pkl DE/coverages/DE-CE2.pkl DE/coverages/DE-NM2.pkl         --conditions CNTRL NM CNTRL NM 	--ex_extension_files DE/coverages/DE-CE.extensions.tsv DE/coverages/DE-NM.extensions.tsv DE/coverages/DE-CE2.extensions.tsv DE/coverages/DE-NM2.extensions.tsv         --names DE-CE DE-NM DE-CE2 DE-NM2         --read_length 150         --min_coverage_region 100         --min_mean_coverage 5         --ds_reg_for_no_coverage 200         --min_cluster_distance 200         --mse_ratio_threshold 0.5         --best_break_point_upstream_extension 200         --processors 8         --max_downstream_coverage 10         --expressions_out DE/tandem_pas_expressions.tsv         --distal_sites DE/single_distal_sites.tsv         > DE/relative_usages.tsv         2> DE/logs/infer_relative_usage.log' returned non-zero exit status 1.
  File ""/data1/zhoulab/yangjiayi/project/hl/result/PAQR_gxl/PAQR/part_two.Snakefile"", line 142, in __rule_infer_relative_usage
  File ""/data1/zhoulab/yangjiayi/softwares/miniconda3/envs/paqr_kapac/lib/python3.7/concurrent/futures/thread.py"", line 57, in run
Removing output files of failed job infer_relative_usage since they might be corrupted:
DE/relative_usages.tsv, DE/relative_usages.header.out
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
```
log of `infer_relative_usage.log`:
```
############## Started script on 19-11-2019 at 23:59:12 ##############
[INFO] Wed Nov 20 00:03:13 2019 Finished reading input
[INFO] No site was inferred for ENST00000522918:2:2:55517240:55517786. Skipped exon!
......
[INFO] No site was inferred for ENST00000567540:1:1:10039092:10040663. Skipped exon!
Traceback (most recent call last):
  File ""scripts/deNovo-used-sites-and-usage-inference.single_distal_included.py"", line 2302, in <module>
    main(options)
  File ""scripts/deNovo-used-sites-and-usage-inference.single_distal_included.py"", line 2118, in main
    result_tuples = pool.map( process_exon_wrapper_function, data_entries)
  File ""/home/yangjiayi/miniconda3/envs/py2_paqr/lib/python2.7/multiprocessing/pool.py"", line 253, in map
    return self.map_async(func, iterable, chunksize).get()
  File ""/home/yangjiayi/miniconda3/envs/py2_paqr/lib/python2.7/multiprocessing/pool.py"", line 572, in get
    raise self._value
TypeError: not all arguments converted during string formatting
[INFO] No site was inferred for ENST00000233468:4:4:24067584:24067851. Skipped exon!
[INFO] No site was inferred for ENST00000604724:3:3:13406380:13408433. Skipped exon!
```

Thank you!

Best Wishes,
Jiayi Yang.",yangjywhu,https://github.com/zavolanlab/PAQR_KAPAC/issues/11
MDU6SXNzdWU1MjY2NDI2MjA=,Infer relative usage: IndexError: list index out of range,CLOSED,2019-11-21T14:50:02Z,2019-11-27T09:22:28Z,2019-11-27T09:22:28Z,"Hi, I am running the example data through the snakemake pipeline to test it. Part one proceeds successfully, however I get a 'list index out of range' error while it runs the 'deNovo-used-sites-and-usage-inference.single_distal_included.py' script. I have attached the log.

I am using a conda installation, using the 'UPDATED' requirements text file. 
I have attached the log from the failing step.

Thanks,
Peter
[infer_relative_usage.log](https://github.com/zavolanlab/PAQR_KAPAC/files/3875216/infer_relative_usage.log)
",peterkilfeather,https://github.com/zavolanlab/PAQR_KAPAC/issues/12
MDU6SXNzdWU1MjkyODc1NTQ=,config.yaml has a readlength parameters which is not mentioned in the README,CLOSED,2019-11-27T11:28:27Z,2019-12-05T15:31:39Z,2019-12-05T15:31:39Z,"In the config.yaml there's a parameter for readlength which I did not see mention of in the readme and only just noticed; line 99. 
```
# read length of the study (when different samples have different read length
# it is suggested to take the maximum)
# the read length is used to define regions upstream of valid 3' ends with
# expected decrease in read coverage
relUse.read_length: 100
```

Should this be appropiately set? I'd been trying to run on 75 bp reads and I'm not sure if that flag is going to be causing issues. Anyway, if it's something people should be adjusting per their study it might be helpful to move it up in the config.yaml next to the other parameters which need to be custom set. Or to mention in the read.me, but to be clear I realize this is my fault for not properly reading the config file before :) ",aleighbrown,https://github.com/zavolanlab/PAQR_KAPAC/issues/13
MDU6SXNzdWU1MjkyOTM3Njg=,Further question about how to properly set up the sample relationships,OPEN,2019-11-27T11:41:32Z,2020-05-13T11:37:43Z,,"A bit confused about the appropiate way to set up the samples in the config.yaml

Currently the config.yaml as provided when you download looks likes this:

```
#-------------------------------------------------------------------------------
# sample specific values:
# - name of samples per study
# - name of BAM file and condition per sample
#-------------------------------------------------------------------------------

HNRNPC_KD:
  samples: [ctl_rep1, ctl_rep2, HNRNPC_rep1, HNRNPC_rep2]

ctl_rep1: {bam: CTL_rep1, type: CNTRL}
ctl_rep2: {bam: CTL_rep2, type: CNTRL}
HNRNPC_rep1: {bam: KD_rep1, type: KD, control: ctl_rep1}
HNRNPC_rep2: {bam: KD_rep2, type: KD, control: ctl_rep2}
````

Are the HNRNPC_rep1 being directly compared to ctl_rep1?
What if my samples don't have such a clear cut this control should be compared to this case relationship, eg, I've done 3 biological replicates in each condition but they're not what I would call directly matched. 

If my samples are MUT1,MUT2,MUT3, WT1,WT2,WT3 how would it make a difference in the final analysis if matter if I did set up the relationship as 
```
MUT1: {bam: MUT1, type: MUT, control: WT1}
MUT2: {bam: MUT2, type: MUT, control: WT2}
```

vs 

```
MUT1: {bam: MUT1, type: MUT, control: WT2}
MUT2: {bam: MUT2, type: MUT, control: WT3}
```

What if my sample sizes for conditions weren't matched, if I have 5 in one condition and 8 in another for example? 

Thanks!",aleighbrown,https://github.com/zavolanlab/PAQR_KAPAC/issues/14
MDU6SXNzdWU1NDYyOTkyOTU=,Updating mm10 annotation files with PolyASite 2.0 release,OPEN,2020-01-07T13:59:45Z,2020-06-23T20:46:32Z,,"Thanks for providing the mm10 annotation files for the poly(A) sites and for the clearly written documentation, I've been able to get PAQR running on our data pretty smoothly.

Judging from the commit dates I assume they were created with the initial PolyASite database release from 2016. An update was released in June 2019 and I think it would be useful to run PAQR with the latest reference sites to see if this has any effect on the reliability of the output. Would you be able to update the example mm10 annotation files to account for the new database release?

Alternatively could I also just get a little more information on how to set up the annotation files as I'd like to give this a try myself? The reply to the closed issue  #5  is very useful, but can I just double-check you didn't do any filtering of the mouse_polyAclusters file containing poly(A) site annotations (i.e. the name of the file just reflects the name of the transcript annotation BED file (where same strand overlapping exons etc have been filtered out))? Apologies if that last question is a little unclear. 

Thank you for your time,
Sam
>",SamBryce-Smith,https://github.com/zavolanlab/PAQR_KAPAC/issues/15
MDU6SXNzdWU1ODQyNzY0NTc=,Intronic polyadenylation quantification,OPEN,2020-03-19T09:29:19Z,2020-03-27T13:20:08Z,,"Hello,

First of all: thank you very much for sharing this code with very clear description here! 

After running the PAQR pipeline successfully, I am getting a list of differential usage of polyA sites for different terminal exon (TE) isoforms. 

Actually, I am especially interested in quantifying differential intronic polyA site usage (e.g. switching from a regular TE isoform to intronic polyA isoform). Therefore, I was wondering if we could also get the relative usage for these intronic polyA sites isoforms, as included in the polyAsite atlas, using this pipeline? 

I noticed that the .bed annotation file contains also only the TE polyA sites. Would it be possible to extend this file with the intronic polyadenylation clusters (IN) from the polyAsite atlas and run the script as normal? Or are there then other issues? If this would be possible: could you give me some advice on what would be an easy way to annotate the .bed file from the polyA atlas to transcript/gene IDs so that they can be uploaded in a similar way as the TE's (I am quite new to these genomic bioinformatics tools)? 

Hopefully you can help with this!

Best regards,
Vera
",vvdnoord,https://github.com/zavolanlab/PAQR_KAPAC/issues/17
MDU6SXNzdWU2OTQwNjUwNzk=,Errors when running PAQR step2,OPEN,2020-09-05T11:24:29Z,2020-09-08T21:19:06Z,,"Hi,

Thanks for developing PAQR_KAPAC. I am facing a problem when running step2 of PAQR with the source code (error shown in the attached figure).

Does anyone have idea from which the error comes? Many Thanks!

<img width=""537"" alt=""Screen Shot 2020-09-05 at 7 24 12 PM"" src=""https://user-images.githubusercontent.com/18133362/92304074-628cd980-efad-11ea-9d5f-bb99a637b004.png"">


",Sylarair,https://github.com/zavolanlab/PAQR_KAPAC/issues/19
MDU6SXNzdWU3Mjg1MTc0Mzg=,Missing conda packages break creation of py2_paqr environment.,CLOSED,2020-10-23T20:53:34Z,2020-11-11T07:04:22Z,2020-11-11T07:04:22Z,"Hi there, 

Python 2.7.11 does not seem to be available to install via the 'conda install python=2.7.11' step in the py2-paqr virtual environment creation. Additionally, pymongo 3.4.0 does not seem to be available either. Perhaps this is an issue with my installation in particular; however, checking for these versions with 'conda search --full-name python' and 'conda search --full-name pymongo' seems to show they are missing from the default repos. It may be a similar issue to the one you encountered early on with the python3 environment. If this is the case, it would be best to update the installation readme to reflect the changes in availability of these components.

Much thanks!",ClarinetK622,https://github.com/zavolanlab/PAQR_KAPAC/issues/20
