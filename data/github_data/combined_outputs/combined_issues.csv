id,title,state,created_at,updated_at,closed_at,body,user,url,file_name
MDU6SXNzdWUzNjUxNjg5Nzg=,Confirm that use of BLAST's `-max_target_seqs` is intentional,OPEN,2018-09-29T21:37:16Z,2018-09-29T21:37:16Z,,"Hi there,

This is a semi-automated message from a fellow bioinformatician. Through a GitHub search, I found that the following source files make use of BLAST's `-max_target_seqs` parameter: 

- [scripts/run_swissprot_blast.sh](https://github.com/1KFG/annotate_genomes/blob/0067b8d965ffd75059583a7af8974e84b93b9a25/scripts/run_swissprot_blast.sh)
- [scripts/run_swissprot_blast_array.sh](https://github.com/1KFG/annotate_genomes/blob/0067b8d965ffd75059583a7af8974e84b93b9a25/scripts/run_swissprot_blast_array.sh)
- [scripts/run_swissprot_blast_array.sh](https://github.com/1KFG/annotate_genomes/blob/0067b8d965ffd75059583a7af8974e84b93b9a25/scripts/run_swissprot_blast_array.sh)

Based on the recently published report, [Misunderstood parameter of NCBI BLAST impacts the correctness of bioinformatics workflows](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/bty833/5106166?redirectedFrom=fulltext), there is a strong chance that this parameter is misused in your repository.

If the use of this parameter was intentional, please feel free to ignore and close this issue but I would highly recommend to add a comment to your source code to notify others about this use case. If this is a duplicate issue, please accept my apologies for the redundancy as this simple automation is not smart enough to identify such issues.

Thank you!
-- Arman ([armish/blast-patrol](https://github.com/armish/blast-patrol))",armish,https://github.com/1KFG/annotate_genomes/issues/1,1KFG++annotate_genomes.csv
I_kwDOGdK4u86FRPVn,dependency installation doesn't work,OPEN,2024-04-10T15:31:52Z,2024-04-10T15:31:52Z,,"We have installed poetry (we don't have docker) on the server and I am trying to run the 'poetry install' command from the directory with the files from github and I get the following error:
[tool.poetry] section not found in /u/jhumann/Genome-Assembly-and-Annotation-Nomenclature_WG/pyproject.toml

",jhumann,https://github.com/AgBioData/Genome-Assembly-and-Annotation-Nomenclature_WG/issues/2,AgBioData++Genome-Assembly-and-Annotation-Nomenclature_WG.csv
MDU6SXNzdWUxNTc1MzA5MjA=,How to run RPS-BLAST+ and `cdd2cog`,OPEN,2016-05-30T16:28:32Z,2018-11-27T13:49:24Z,,"A master student from Brazil contacted me via email with questions how to run RPS-BLAST+ and `cdd2cog.pl` correctly. I'm copying the correspondence in here in case it is useful for someone else:

Hi, I am a master student of genetics at the Universidade Federal de Minas Gerais, Brasil. I was reading the cdd2goc description at
https://github.com/aleimba/bac-genomics-scripts/tree/master/cdd2cog#rps-blast

In the line referring to the use of RPS-Blast :

rpsblast -query protein.fasta -db **Cog** -out rps-blast.out -evalue 1e-2 -outfmt 6

I am confuse about the cog, which I highlighted. Is this another database we must download? If so, where could I find it, and to perform a search for protein sequences of a draft bacterial genome I assembled, how database should I get? Thank you in advance.
",aleimba,https://github.com/aleimba/bac-genomics-scripts/issues/1,aleimba++bac-genomics-scripts.csv
MDU6SXNzdWUxODcyMzE2OTc=,update compatibility to COG2014? ,OPEN,2016-11-04T01:28:40Z,2017-07-18T13:43:57Z,,"Hi Andreas,

Love the `cdd2cog.pl` script and description, thanks for making this available. Was wondering if you planned to update this to the newer release of COG [ftp://ftp.ncbi.nlm.nih.gov/pub/COG/COG2014/data/](url) with the fun and whog updated to fun2003-2014.tab and cognames2003-2014.tab. I tried running `cdd2cog.pl` with these newer classification files and it doesn't seem to parse the COG categories and so the func_stats.txt file does not get populated.",sirmicrobe,https://github.com/aleimba/bac-genomics-scripts/issues/2,aleimba++bac-genomics-scripts.csv
MDU6SXNzdWUyNDE2NjQxMTU=,CDS-extractor.pl should return error message (and exit code 1) when no CDS could be extracted,OPEN,2017-07-10T10:14:03Z,2017-07-11T09:44:36Z,,"When genbanks are used as input that still have windows/dos line-endings, cds-extractor.pl just quits without an error message, giving the impression that it successfully extracted all CDS.

Maybe it could either be adjusted to tolerate windows line endings or to always double-check the number of extracted CDS when finished and generally raise a warning if it is zero. ",jvollme,https://github.com/aleimba/bac-genomics-scripts/issues/3,aleimba++bac-genomics-scripts.csv
MDU6SXNzdWUyNDM1MDExMDU=,running rpsblast with gi numbers as queries,OPEN,2017-07-17T19:29:28Z,2017-07-17T19:29:28Z,,"Hi, I'm trying to do an rpsblast using ncbi-blast-2.5.0+. I have a file containing gi numbers as my query and my command line is below.

`rpsblast -query t -db results/Cog/Cog -out rps-blast.out -evalue 1e-2 -outfmt 6`
Oddly the rpbslast keeps giving me this error:

`Warning: [rpsblast] Error initializing remote BLAST database data loader: Protein BLAST database 'Cog/Cog nr' does not exist in the NCBI servers`
My query file (t) looks like this. I've tried to remove search using just the numbers (292833481) but it still doesn't solve the problem. 
gi|292833481 
gi|383341230 
gi|289693981

However, when I try to the same search but using a fasta file as query, it runs fine and gives the results I need.
`rpsblast -query GCF_000005845.2_ASM584v2_protein.faa -db results/Cog/Cog -out rps-blast.out -evalue 1e-2 -outfmt 6`
Is there something that I did wrong here? What is the correct way to format query a list of gi's for blast? Thanks!",arolni,https://github.com/aleimba/bac-genomics-scripts/issues/4,aleimba++bac-genomics-scripts.csv
MDU6SXNzdWUyNDgxNzI0MTM=,Error while executing po2group_stats.pl,OPEN,2017-08-05T08:35:31Z,2017-10-15T22:11:35Z,,"Hi,

I get this error while executing  po2group_stats.pl:

Bareword found where operator expected at ./po2group_stats.pl line 669, near ""s/\.\w+$//r""
syntax error at ./po2group_stats.pl line 669, near ""s/\.\w+$//r""
BEGIN not safe after errors--compilation aborted at ./po2group_stats.pl line 913

Any advice please?

Thanks",bioinfo17,https://github.com/aleimba/bac-genomics-scripts/issues/6,aleimba++bac-genomics-scripts.csv
MDU6SXNzdWUyOTQyNDE4NDY=,cdd2cog and RPSBLAST 2.2.31+ report parse,OPEN,2018-02-04T23:30:31Z,2018-02-04T23:30:31Z,,"Hi,

Thanks for the tool, really useful!. 

There seems to be a change on the output of RPS-Blast, an example line:

`fig|992418.4.peg.8018	gnl|CDD|223110	26.42	159	100	6	20	165	11	165	4e-13	65.6	45`

The `subject id` format changed, and the current regex on cdd2cog doesn't work. Changing the line `302` to `my $pssm_id = $1 if $line[1] =~ /^gnl\|CDD\|(\d+)/; # get PSSM-Id from the subject hit` fix the issue.

Regards",mberacochea,https://github.com/aleimba/bac-genomics-scripts/issues/7,aleimba++bac-genomics-scripts.csv
MDU6SXNzdWUzMDAwNDM2MzA=,Error with rpsblast+,OPEN,2018-02-25T17:21:28Z,2018-02-25T17:21:28Z,,"Dear Aleimba,

I tried running the following command with the respective error message.

> rpsblast+ -query protein.faa -db ../../COG/cog_LE_db/ -evalue 0.00001 -outfmt ""6 qseqid sseqid evalue pident score qstart qend sstart send length slen"" -out cog_blast_output.out

BLAST Database error: No alias or index file found for protein database [../../COG/cog_LE_db/] in search path [/home/rajal/Downloads/prokka/prokka_annotation:/var/lib/blastdb::]

I am using rpsblast+ version [Reverse Position Specific BLAST 2.2.28+]. What am I missing here?

Thank you.",rajaldebnath,https://github.com/aleimba/bac-genomics-scripts/issues/8,aleimba++bac-genomics-scripts.csv
MDU6SXNzdWUzNTgyMDgyNTA=,Cannot retrieve path to RPS database,OPEN,2018-09-07T20:54:05Z,2019-05-08T18:04:49Z,,"Hi, I think this has a simple answer, I get this error when running the rpsblast command:

`rpsblast -query ROD1.txt -db /Users/Laura/Desktop/rspblast/Cog_LE/ -out rps.blast.out -evalue 1e-5 -outfmt 6
`
Cannot retrieve path to RPS database


Thanks!
",Alopias1988,https://github.com/aleimba/bac-genomics-scripts/issues/9,aleimba++bac-genomics-scripts.csv
MDU6SXNzdWUzNjU0ODUxMTY=,Can't convert CDDs IDs to COGs,CLOSED,2018-10-01T14:21:30Z,2018-10-01T16:35:06Z,2018-10-01T16:35:06Z,"Following all the commands in #1 , I get rpsblast claiming that the arguments in the command ""rpsblast -query GCF_000005845.2_ASM584v2_protein.faa -db Cog -out rps-blast.out -evalue 1e-2 -outfmt 6"" are wrong, and it works after I adjust the command to 
```
rpsblast -i GCF_000005845.2_ASM584v2_protein.faa -d Cog -o rps-blast.out -m 8
```
which gets the job done, however the conversion to COGs with
```
perl cdd2cog.pl -r rps-blast.out -c cddid.tbl -f fun.txt -w whog
```
gets the result
```
Overall assignment statistics:
~ Total query proteins categorized into COGs: 4134
~ Total COGs used for the query proteins [of 4873 overall]: 1
~ Total number of assigned functional categories: 0
~ Total functional categories used for the query proteins [of 25 overall]: 0
```
which brings no information, since nothing was identified. It also outputs a lot of ""Use of uninitialized value"" which probably means the CDD's IDs are not being recognized. The rest of the commands were used as suggested, so what is happening here? Also, this is using the 2003 COGs right?",iquasere,https://github.com/aleimba/bac-genomics-scripts/issues/10,aleimba++bac-genomics-scripts.csv
MDU6SXNzdWU1MzQwMjAyMTM=,No output argument?,OPEN,2019-12-06T14:18:10Z,2019-12-06T14:18:10Z,,"Greetings

Does cdd2cog have an output argument for deciding where to export results, or do they have to go the the ./results directory always?",iquasere,https://github.com/aleimba/bac-genomics-scripts/issues/11,aleimba++bac-genomics-scripts.csv
MDU6SXNzdWU1Mzk3MzI0Njc=,Error when running cdd2cog,OPEN,2019-12-18T14:56:10Z,2019-12-18T14:56:10Z,,"Hi, I am trying to run cdd2cog and I am getting the Error: Excessively long <> operator at ./cdd2cog.pl line 21

I am running: $ perl ./cdd2cog.pl -r GRW1_COGs_rpsblast.out -c cddid.tbl -f fun.txt -w whog -a

I got the rpsblast output by running: rpsblast -i ../proteins/GRW1_prots.fas -d Cog_LE/Cog -o GRW1_COGs_rpsblast.out -e 0.01 -m 8

I notice that the outfmt parameter written in the README file for running RPS-BLAST says to use ""-outfmt 6 or 7"", but when I tried running this option it did not want to take it. 

Here are the first few lines of the GRW1_COGs_rpsblast.out:
gene_3|GeneMark.hmm|389_aa|+|1295|2464	>k123_143	gnl|CDD|226020	17.25	313	213	12	105	389	65	359	2e-05	42.9
gene_6|GeneMark.hmm|322_aa|-|993|1961	>k123_238	gnl|CDD|224392	21.43	140	92	3	70	209	16	137	5e-08	49.9
gene_7|GeneMark.hmm|235_aa|-|1975|2682	>k123_238	gnl|CDD|224113	21.79	179	126	2	20	198	76	240	2e-19	81.8

",ngilber3,https://github.com/aleimba/bac-genomics-scripts/issues/13,aleimba++bac-genomics-scripts.csv
MDU6SXNzdWU5MzQ3NzU0NDM=,small code change for use of the cdd2cog.pl script with COG20,OPEN,2021-07-01T12:09:37Z,2021-07-01T12:09:37Z,,"Hi!

not really an issue, but putting this here in case the original author doesn't have time to modify the ```cdd2cog.pl``` script for use with the updated COG20 database. I guess this would be more properly done via pull request, but I figure more people might see an opened issue. I also realise this is a ""band-aid"" style fix, but might be useful to someone nonetheless.

if you're interested in using the ```cdd2cog.pl``` script with the COG20 database (which can be found here https://ftp.ncbi.nih.gov/pub/COG/COG2020/data/) only a small change is required. The body of the script will work perfectly fine, but the information parsed from the ```fun.txt``` and ```whog``` files now needs to be parsed from files with a slightly different name and format. 

```fun.txt``` is now replaced by ```fun-20.tab```
```whog``` can be replaced by ```cog-20.def.tab```
both of these files can be downloaded from the link above

to retrieve the relevant info from these files, the subroutines all the way at the end of ```cdd2cog.pl``` need to be modified. For clarity and ease of copy/pasting, I have pasted the entire subroutine here. The orignal code is still in place, but commented out. The 4 added lines are present under ```# code to parse fun-20.tab file``` and ```# code to parse cog-20.def.tab```. 

after the modifications are made, the script can be run using:
```cdd2cog.pl -r rps-blast.out -c cddid.tbl -f fun-20.tab -w cog-20.def.tab```

Hope this is helpful!



```
###############
# Subroutines #
###############

### Subroutine to parse the 'cddid.tbl', 'fun' and 'whog' file contents and store in hash structures
sub parse_cdd_cog {

    ### 'cddid.tbl'
    open (my $cddid_fh, ""<"", ""$CDDid_File"");
    print ""\nParsing CDDs '$CDDid_File' file ...\n""; # status message
    while (<$cddid_fh>) {
        chomp;
        my @line = split(/\t/, $_); # split line at the tabs
        if ($line[1] =~ /^COG\d{4}$/) { # search for COG CD accessions in cddid
            $CDDid{$line[0]} = $line[1]; # hash to store info; $line[0] = PSSM-Id
        }
    }
    close $cddid_fh;

    ### 'fun.txt'
    open (my $fun_fh, ""<"", ""$Fun_File"");
    print ""Parsing COGs '$Fun_File' file ...\n""; # status message
    while (<$fun_fh>) {
        chomp;
	
	# code to parse fun-20.tab file
	my @line = split(/\t/, $_); # split line at the tabs
	$Fun{$line[0]} = {'desc' => $line[2], 'count' => 0}; # anonymous hash in hash
        # $line[0] = single-letter functional category, $line[2] = description of functional category
        # count used to find functional categories not present in the query proteins for final overall assignment statistics	

	# code and comments to parse original fun.txt file
	#$_ =~ s/^\s*|\s+$//g; # get rid of all leading and trailing whitespaces
        #if (/^\[(\w)\]\s*(.+)$/) {
        #    $Fun{$1} = {'desc' => $2, 'count' => 0}; # anonymous hash in hash
        #    # $1 = single-letter functional category, $2 = description of functional category
        #    # count used to find functional categories not present in the query proteins for final overall assignment statistics

        #}
    }
    close $fun_fh;

    ### 'whog'
    open (my $whog_fh, ""<"", ""$Whog_File"");
    print ""Parsing COGs '$Whog_File' file ...\n""; # status message
    while (<$whog_fh>) {
        chomp;
	# code to parse cog-20.def.tab
	my @line = split(/\t/, $_); # split line at the tabs
	$Whog{$line[0]} = {'function' => $line[1], 'desc' => $line[2]}; # anonymous hash in hash
	# $line[1] = single-letter functional categories, maximal four per COG in COG20 (COG5032 no longer exists)
	# $line[0] = COG#, $line[2] = COG protein description

	#code and comments to parse the original whog file
        #$_ =~ s/^\s*|\s+$//g; # get rid of all leading and trailing whitespaces
        #if (/^\[(\w+)\]\s*(COG\d{4})\s+(.+)$/) {
        #    $Whog{$2} = {'function' => $1, 'desc' => $3}; # anonymous hash in hash
        #    # $1 = single-letter functional categories, maximal five per COG (only COG5032 with five)
	#    # $2 = COG#, $3 = COG protein description
        #}
    }
    close $whog_fh;

    return 1;
}
```",dspeth,https://github.com/aleimba/bac-genomics-scripts/issues/14,aleimba++bac-genomics-scripts.csv
MDU6SXNzdWUzNjUxNjkxMjY=,Confirm that use of BLAST's `-max_target_seqs` is intentional,OPEN,2018-09-29T21:39:05Z,2018-09-29T21:39:05Z,,"Hi there,

This is a semi-automated message from a fellow bioinformatician. Through a GitHub search, I found that the following source files make use of BLAST's `-max_target_seqs` parameter: 

- [bing_RBBH.py](https://github.com/BingW/GenomeAnnotationToolkit/blob/3f9d67bb8f5b57b433db1fe0ff14f9c21df25b1d/bing_RBBH.py)

Based on the recently published report, [Misunderstood parameter of NCBI BLAST impacts the correctness of bioinformatics workflows](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/bty833/5106166?redirectedFrom=fulltext), there is a strong chance that this parameter is misused in your repository.

If the use of this parameter was intentional, please feel free to ignore and close this issue but I would highly recommend to add a comment to your source code to notify others about this use case. If this is a duplicate issue, please accept my apologies for the redundancy as this simple automation is not smart enough to identify such issues.

Thank you!
-- Arman ([armish/blast-patrol](https://github.com/armish/blast-patrol))",armish,https://github.com/BingW/GenomeAnnotationToolkit/issues/1,BingW++GenomeAnnotationToolkit.csv
MDU6SXNzdWUzNjcyMzQyOTk=,Error tagging new release,CLOSED,2018-10-05T14:24:40Z,2018-10-05T14:34:48Z,2018-10-05T14:34:48Z,"The REQUIRE file could not be found.
cc: @kdyrhage",attobot,https://github.com/BioJulia/GenomicAnnotations.jl/issues/1,BioJulia++GenomicAnnotations.jl.csv
MDU6SXNzdWUzNjcyMzYwMjc=,Error tagging new release,CLOSED,2018-10-05T14:28:50Z,2018-10-05T14:34:48Z,2018-10-05T14:34:48Z,"The REQUIRE file could not be found.
cc: @kdyrhage",attobot,https://github.com/BioJulia/GenomicAnnotations.jl/issues/2,BioJulia++GenomicAnnotations.jl.csv
MDU6SXNzdWU3NDk1Nzg1NDg=,TagBot trigger issue,CLOSED,2020-11-24T10:26:36Z,2024-11-22T18:49:37Z,2020-11-24T10:26:36Z,"This issue is used to trigger TagBot; feel free to unsubscribe.

If you haven't already, you should update your `TagBot.yml` to include issue comment triggers.
Please see [this post on Discourse](https://discourse.julialang.org/t/ann-required-updates-to-tagbot-yml/49249) for instructions and more details.

If you'd like for me to do this for you, comment `TagBot fix` on this issue.
I'll open a PR within a few hours, please be patient!
",JuliaTagBot,https://github.com/BioJulia/GenomicAnnotations.jl/issues/5,BioJulia++GenomicAnnotations.jl.csv
MDU6SXNzdWU4NDk2MjIzODA=,Error when loading genebank file from NCBI,CLOSED,2021-04-03T09:46:31Z,2021-04-06T11:19:18Z,2021-04-06T09:44:52Z,"Hello,
I have downloaded a genebank file from NCBI (https://www.ncbi.nlm.nih.gov/nuccore/NC_022898.1?report=genbank then send to -> file -> GeneBank (full))

I then try to open the file using 
```julia
gbff = readgbk(""sequence.gb"")
```
but get an error:
```
ERROR: ArgumentError: invalid index: nothing of type Nothing
Stacktrace:
 [1] to_index(i::Nothing)
   @ Base ~/julia-1.3.1/bin/../share/julia/base/indices.jl:273

 [2] to_index(A::Array{SubString{String},1}, i::Nothing)
   @ Base ~/julia-1.3.1/bin/../share/julia/base/indices.jl:250

 [3] to_indices
   @ Base ~/julia-1.3.1/bin/../share/julia/base/indices.jl:301 [inlined]

 [4] to_indices
   @ Base ~/julia-1.3.1/bin/../share/julia/base/indices.jl:298 [inlined]

 [5] getindex
   @ ~/julia-1.3.1/bin/../share/julia/base/abstractarray.jl:981 [inlined]

 [6] parseheader(header::String)
   @ GenomicAnnotations.GenBank ~/.julia/packages/GenomicAnnotations/gigUo/src/GenBank/reader.jl:58

 [7] parsechromosome!(stream::TranscodingStreams.TranscodingStream{TranscodingStreams.Noop,IOStream}, record::GenomicAnnotations.Record{Gene})
   @ GenomicAnnotations.GenBank ~/.julia/packages/GenomicAnnotations/gigUo/src/GenBank/reader.jl:227

 [8] tryread!
   @ GenomicAnnotations.GenBank ~/.julia/packages/GenomicAnnotations/gigUo/src/GenBank/reader.jl:49 [inlined]

 [9] iterate
   @ GenomicAnnotations.GenBank ~/.julia/packages/GenomicAnnotations/gigUo/src/GenBank/reader.jl:42 [inlined]

[10] _collect(cont::UnitRange{Int64}, itr::GenomicAnnotations.GenBank.Reader{TranscodingStreams.TranscodingStream{TranscodingStreams.Noop,IOStream}}, ::Base.HasEltype, isz::Base.SizeUnknown)
   @ Base ~/julia-1.3.1/bin/../share/julia/base/array.jl:572

[11] collect
   @ Base ~/julia-1.3.1/bin/../share/julia/base/array.jl:560 [inlined]

[12] readgbk(input::String)
   @ GenomicAnnotations ~/.julia/packages/GenomicAnnotations/gigUo/src/utils.jl:65

[13] top-level scope
   @ REPL[15]:1
```

It should get noted that if I download the GeneBank file instead (no ""(full)""), then I can load it (but there's not much actual content in it).",TorkelE,https://github.com/BioJulia/GenomicAnnotations.jl/issues/7,BioJulia++GenomicAnnotations.jl.csv
I_kwDOB7QJcs5Ae-W-,GzipDecompressorStream not defined,CLOSED,2021-12-16T07:31:34Z,2021-12-17T00:23:27Z,2021-12-17T00:23:27Z,"Hi, I'm trying to open a `.gbff.gz` file and I'm getting the following error:
```Julia
julia> readgbk(joinpath(DATA_DIR, ""genome.gbff.gz""))
ERROR: UndefVarError: GzipDecompressorStream not defined
Stacktrace:
 [1] open(#unused#::Type{GenomicAnnotations.GenBank.Reader}, input::String)
   @ GenomicAnnotations.GenBank ~/.julia/packages/GenomicAnnotations/aGEUx/src/GenBank/reader.jl:31
 [2] readgbk(input::String)
   @ GenomicAnnotations ~/.julia/packages/GenomicAnnotations/aGEUx/src/utils.jl:65
 [3] top-level scope
   @ REPL[5]:1
```
Any help would be much appreciated. Thanks!",jowch,https://github.com/BioJulia/GenomicAnnotations.jl/issues/8,BioJulia++GenomicAnnotations.jl.csv
I_kwDOB7QJcs5S0YMJ,Can GenomicAnnotations.jl deal with multi-exon genes?,CLOSED,2022-09-28T14:25:48Z,2024-06-14T13:34:16Z,2024-06-14T13:34:16Z,"Hi, I'm trying converting a genbank file to a gff with the package, however it fails. For example, one gene is as below:
Input: Screenshot 1;  https://www.ncbi.nlm.nih.gov/nuccore/7525012
![Screen Shot 2022-09-28 at 10 30 09 pm](https://user-images.githubusercontent.com/22763795/192807573-fed20b22-3e61-4b28-8008-a5a0356703c1.png)

Code: Screenshot 2
![Screen Shot 2022-09-28 at 10 36 05 pm](https://user-images.githubusercontent.com/22763795/192807808-3a581704-2804-4437-912f-a6306ff96e9e.png)

Output: Screenshot 3
<img width=""1345"" alt=""Screen Shot 2022-09-28 at 10 37 43 pm"" src=""https://user-images.githubusercontent.com/22763795/192808233-2cf2d089-4fc4-45a6-8644-ded221a8bd73.png"">

As shown, the CDS in the gff output doesn't have an intron between the two exons. CDS sequences extracted based on these kinds of coordinates must be wrong. Thank you!",Xiao-Zhong,https://github.com/BioJulia/GenomicAnnotations.jl/issues/9,BioJulia++GenomicAnnotations.jl.csv
I_kwDOB7QJcs5r6nXN,Having location field in genes,CLOSED,2023-07-18T19:00:39Z,2024-01-03T09:29:28Z,2023-09-01T08:03:08Z,"Hi all

This package is so great! I was wondering if there is any way to fetch the `location` out of the `gbk.genes` field. Currently we can get all the fields that start with the `/` in the record:

```
gbk.genes[end]

     CDS             47738..47944
                     /db_xref=""GeneID:2703534""
                     /locus_tag=""lambdap79""
                     /codon_start=1
                     /transl_table=11
                     /product=""hypothetical protein""
                     /protein_id=""NP_597782.1""
                     /translation=""MNKEQSADDPSVDLIRVKNMLNSTISMSYPDVVIACIEHKVSLE
                     AFRAIEAALVKHDNNMKDYSLVVD""
                     /note=""Predicted by GeneMark""
```

I want to be able to get the location qualifier `47738..47944` encoded later as a `UnitRange{Int64}` --> `47738:47944`. Is this a feature we can have in `GenomicAnnotations` (or already have)? 

Best.",camilogarciabotero,https://github.com/BioJulia/GenomicAnnotations.jl/issues/11,BioJulia++GenomicAnnotations.jl.csv
I_kwDOB7QJcs5u05-t,[Feature Request] Support for GTF format!,CLOSED,2023-08-21T13:21:13Z,2024-11-22T07:27:12Z,2024-11-22T07:27:12Z,"Thank you for your hard work on this package! 
However, I have noticed that the current version does not support the basic format of GTF, while it already supports GFF3. Would it be possible to add support for GTF in the future? 
Thank you!",yang-dongxu,https://github.com/BioJulia/GenomicAnnotations.jl/issues/12,BioJulia++GenomicAnnotations.jl.csv
I_kwDOB7QJcs5xYUbY,Trouble loading `.gb` file downloaded via benchling,CLOSED,2023-09-19T04:51:19Z,2023-09-20T19:30:04Z,2023-09-20T08:25:29Z,"I'm trying to parse a `.gb` file that I exported via Benchling (it shouldn't make a difference), but for some reason `readgbk` just keeps running without ever ending. BioPython parses the file, so I assume the file is encoded correctly. I'm attaching the file below. Thanks in advance! Really appreciate the package

```
LOCUS       pAC03_(pQJ6_w/_mOrange 10073 bp ds-DNA     circular     17-SEP-2023
DEFINITION  .
FEATURES             Location/Qualifiers
     primer          596..615
                     /label=""oLAC01""
                     /note=""sequence: GATTCATTAATGCAGCTGGC""
                     /ApEinfo_revcolor=""#d59687""
                     /ApEinfo_fwdcolor=""#d59687""
     primer          621..642
                     /label=""oQJ70""
                     /note=""sequence: CGCGTAGCCTGTCAGAAATTGA""
                     /ApEinfo_revcolor=""#faac61""
                     /ApEinfo_fwdcolor=""#faac61""
     primer          621..642
                     /label=""oQJ70""
                     /note=""sequence: CGCGTAGCCTGTCAGAAATTGA""
                     /ApEinfo_revcolor=""#f7977a""
                     /ApEinfo_fwdcolor=""#f7977a""
     misc_feature    621..1698
                     /label=""lacZ upstream""
                     /ApEinfo_revcolor=""#ffef86""
                     /ApEinfo_fwdcolor=""#ffef86""
     3'UTR           672..690
                     /label=""KS1469""
                     /ApEinfo_revcolor=""#b1ff67""
                     /ApEinfo_fwdcolor=""#b1ff67""
     primer          801..819
                     /label=""oLAC22""
                     /note=""sequence: AAGTAGCAGTGAAAGCCAA""
                     /ApEinfo_revcolor=""#c7b0e3""
                     /ApEinfo_fwdcolor=""#c7b0e3""
     3'UTR           824..849
                     /label=""KS584""
                     /ApEinfo_revcolor=""#b1ff67""
                     /ApEinfo_fwdcolor=""#b1ff67""
     misc_feature    824..849
                     /label=""KS584\""
                     /ApEinfo_revcolor=""#faac61""
                     /ApEinfo_fwdcolor=""#faac61""
     misc_feature    923..942
                     /label=""KS281\""
                     /ApEinfo_revcolor=""#85dae9""
                     /ApEinfo_fwdcolor=""#85dae9""
     primer          951..971
                     /label=""oLAC19""
                     /note=""sequence: AACACATAACCCTGCAGTAAG""
                     /ApEinfo_revcolor=""#faac61""
                     /ApEinfo_fwdcolor=""#faac61""
     primer          1033..1053
                     /label=""oLAC09""
                     /note=""sequence: AGTAGCTTCAAGCCATGAATC""
                     /ApEinfo_revcolor=""#d59687""
                     /ApEinfo_fwdcolor=""#d59687""
     primer          1196..1213
                     /label=""oLAC23""
                     /note=""sequence: CAACTTGGCTAGAACCGG""
                     /ApEinfo_revcolor=""#b4abac""
                     /ApEinfo_fwdcolor=""#b4abac""
     primer          1479..1498
                     /label=""oQY48""
                     /note=""sequence: CACCATTATGATGGCAATCG""
                     /ApEinfo_revcolor=""#85dae9""
                     /ApEinfo_fwdcolor=""#85dae9""
     misc_feature    1573..1595
                     /label=""p1""
                     /ApEinfo_revcolor=""#b1ff67""
                     /ApEinfo_fwdcolor=""#b1ff67""
     misc_feature    complement(1678..1698)
                     /label=""pr""
                     /ApEinfo_revcolor=""#84b0dc""
                     /ApEinfo_fwdcolor=""#84b0dc""
     misc_feature    1699..1733
                     /label=""BBa_J23119""
                     /ApEinfo_revcolor=""#75c6a9""
                     /ApEinfo_fwdcolor=""#75c6a9""
     misc_feature    1734..1767
                     /label=""FRT""
                     /ApEinfo_revcolor=""#c7b0e3""
                     /ApEinfo_fwdcolor=""#c7b0e3""
     misc_feature    1768..1787
                     /label=""pf""
                     /ApEinfo_revcolor=""#f8d3a9""
                     /ApEinfo_fwdcolor=""#f8d3a9""
     misc_feature    1785..1819
                     /label=""kanR promoter""
                     /ApEinfo_revcolor=""#b7e6d7""
                     /ApEinfo_fwdcolor=""#b7e6d7""
     primer          1815..1840
                     /label=""oLAC30""
                     /note=""sequence: TTTAAATACTGTAGAAAAGAGGAAGG""
                     /ApEinfo_revcolor=""#f58a5e""
                     /ApEinfo_fwdcolor=""#f58a5e""
     misc_feature    1834..1839
                     /label=""RBS""
                     /ApEinfo_revcolor=""#c6c9d1""
                     /ApEinfo_fwdcolor=""#c6c9d1""
     CDS             1850..2644
                     /label=""KanR""
                     /ApEinfo_revcolor=""#faac61""
                     /ApEinfo_fwdcolor=""#faac61""
     misc_feature    2626..2648
                     /label=""KS445\""
                     /ApEinfo_revcolor=""#b4abac""
                     /ApEinfo_fwdcolor=""#b4abac""
     misc_feature    complement(2627..2644)
                     /label=""ACM205\""
                     /ApEinfo_revcolor=""#ff9ccd""
                     /ApEinfo_fwdcolor=""#ff9ccd""
     misc_feature    2657..2678
                     /label=""KS518\""
                     /ApEinfo_revcolor=""#b1ff67""
                     /ApEinfo_fwdcolor=""#b1ff67""
     misc_feature    complement(2657..2678)
                     /label=""KS464\""
                     /ApEinfo_revcolor=""#85dae9""
                     /ApEinfo_fwdcolor=""#85dae9""
     3'UTR           2666..2717
                     /label=""terminator""
                     /ApEinfo_revcolor=""#ff9ccd""
                     /ApEinfo_fwdcolor=""#ff9ccd""
     misc_feature    2676..2695
                     /label=""ACM300\""
                     /ApEinfo_revcolor=""#c6c9d1""
                     /ApEinfo_fwdcolor=""#c6c9d1""
     misc_feature    complement(2720..2739)
                     /label=""KS325\""
                     /ApEinfo_revcolor=""#85dae9""
                     /ApEinfo_fwdcolor=""#85dae9""
     misc_feature    2720..2759
                     /label=""KS635\""
                     /ApEinfo_revcolor=""#d6b295""
                     /ApEinfo_fwdcolor=""#d6b295""
     misc_feature    complement(2720..2759)
                     /label=""KS661\""
                     /ApEinfo_revcolor=""#b7e6d7""
                     /ApEinfo_fwdcolor=""#b7e6d7""
     primer          2729..2747
                     /label=""oLAC32""
                     /note=""sequence: CTCTCCTGAGTCCCACAAT""
                     /ApEinfo_revcolor=""#85dae9""
                     /ApEinfo_fwdcolor=""#85dae9""
     primer          complement(2729..2747)
                     /label=""oLAC31""
                     /note=""sequence: ATTGTGGGACTCAGGAGAG""
                     /ApEinfo_revcolor=""#c7b0e3""
                     /ApEinfo_fwdcolor=""#c7b0e3""
     misc_feature    2740..2759
                     /label=""KS644\""
                     /ApEinfo_revcolor=""#75c6a9""
                     /ApEinfo_fwdcolor=""#75c6a9""
     misc_feature    2750..2760
                     /label=""ACM325\""
                     /ApEinfo_revcolor=""#ff9ccd""
                     /ApEinfo_fwdcolor=""#ff9ccd""
     misc_feature    complement(2750..2760)
                     /label=""ACM324\""
                     /ApEinfo_revcolor=""#faac61""
                     /ApEinfo_fwdcolor=""#faac61""
     primer          2929..2948
                     /label=""oLAC04""
                     /note=""sequence: CACTCCCGTTCTGGATAATG""
                     /ApEinfo_revcolor=""#c7b0e3""
                     /ApEinfo_fwdcolor=""#c7b0e3""
     primer          complement(2929..2948)
                     /label=""oLAC33""
                     /note=""sequence: CATTATCCAGAACGGGAGTG""
                     /ApEinfo_revcolor=""#b7e6d7""
                     /ApEinfo_fwdcolor=""#b7e6d7""
     misc_feature    3000..3005
                     /label=""-35 box""
                     /ApEinfo_revcolor=""#75c6a9""
                     /ApEinfo_fwdcolor=""#75c6a9""
     promoter        3000..3028
                     /label=""tac promoter""
                     /ApEinfo_revcolor=""#75c6a9""
                     /ApEinfo_fwdcolor=""#75c6a9""
     misc_feature    3006..3021
                     /label=""Ptac""
                     /ApEinfo_revcolor=""#b4abac""
                     /ApEinfo_fwdcolor=""#b4abac""
     misc_feature    3022..3028
                     /label=""-10 box""
                     /ApEinfo_revcolor=""#c6c9d1""
                     /ApEinfo_fwdcolor=""#c6c9d1""
     misc_binding    3032..3054
                     /label=""LacO""
                     /ApEinfo_revcolor=""#84b0dc""
                     /ApEinfo_fwdcolor=""#84b0dc""
     misc_feature    3094..3127
                     /label=""FRT""
                     /ApEinfo_revcolor=""#c7b0e3""
                     /ApEinfo_fwdcolor=""#c7b0e3""
     misc_feature    3170..3175
                     /label=""RBS?""
                     /ApEinfo_revcolor=""#f8d3a9""
                     /ApEinfo_fwdcolor=""#f8d3a9""
     misc_feature    3181..3891
                     /label=""mTFP""
                     /ApEinfo_revcolor=""#85dae9""
                     /ApEinfo_fwdcolor=""#85dae9""
     primer          3805..3824
                     /label=""oLAC05""
                     /note=""sequence: CACGACAAGGACTACAACAA""
                     /ApEinfo_revcolor=""#c6c9d1""
                     /ApEinfo_fwdcolor=""#c6c9d1""
     misc_feature    3911..3927
                     /label=""Hairpin - terminator""
                     /ApEinfo_revcolor=""#f8d3a9""
                     /ApEinfo_fwdcolor=""#f8d3a9""
     misc_feature    3963..3981
                     /label=""Hairpin (less likely) - terminator""
                     /ApEinfo_revcolor=""#d6b295""
                     /ApEinfo_fwdcolor=""#d6b295""
     misc_feature    4068..4196
                     /label=""BBa_B0015""
                     /ApEinfo_revcolor=""#b7e6d7""
                     /ApEinfo_fwdcolor=""#b7e6d7""
     misc_feature    4224..4257
                     /label=""FRT""
                     /ApEinfo_revcolor=""#c7b0e3""
                     /ApEinfo_fwdcolor=""#c7b0e3""
     misc_feature    complement(4263..4280)
                     /label=""pr""
                     /ApEinfo_revcolor=""#b1ff67""
                     /ApEinfo_fwdcolor=""#b1ff67""
     primer          4277..4298
                     /label=""oLAC18""
                     /note=""sequence: AGGAcaagagacaggatactag""
                     /ApEinfo_revcolor=""#faac61""
                     /ApEinfo_fwdcolor=""#faac61""
     misc_feature    4281..4304
                     /label=""pf""
                     /ApEinfo_revcolor=""#faac61""
                     /ApEinfo_fwdcolor=""#faac61""
     misc_feature    4302..4307
                     /label=""RBS""
                     /ApEinfo_revcolor=""#ff9ccd""
                     /ApEinfo_fwdcolor=""#ff9ccd""
     CDS             4313..5023
                     /label=""mOrange2""
                     /ApEinfo_revcolor=""#c7b0e3""
                     /ApEinfo_fwdcolor=""#c7b0e3""
                     /note=""product: photostable monomeric orange derivative of DsRed fluorescent protein (Shaner et al., 2008) note: mammalian codon-optimized translation: MVSKGEENNMAIIKEFMRFKVRMEGSVNGHEFEIEGEGEGRPYEGFQTAKLKVTKGGPLPFAWDILSPHFTYGSKAYVKHPADIPDYFKLSFPEGFKWERVMNYEDGGVVTVTQDSSLQDGEFIYKVKLRGTNFPSDGPVMQKKTMGWEASSERMYPEDGALKGKIKMRLKLKDGGHYTSEVKTTYKAKKPVQLPGAYIVDIKLDITSHNEDYTIVEQYERAEGRHSTGGMDELYK""
     primer          4505..4523
                     /label=""oLAC13""
                     /note=""sequence: atcctgtcccctcatttca""
                     /ApEinfo_revcolor=""#84b0dc""
                     /ApEinfo_fwdcolor=""#84b0dc""
     primer          4731..4750
                     /label=""oLAC11""
                     /note=""sequence: tgatgcagaagaagaccatg""
                     /ApEinfo_revcolor=""#84b0dc""
                     /ApEinfo_fwdcolor=""#84b0dc""
     misc_feature    complement(5011..5037)
                     /label=""pr""
                     /ApEinfo_revcolor=""#d59687""
                     /ApEinfo_fwdcolor=""#d59687""
     primer          5024..5044
                     /label=""oLAC26""
                     /note=""sequence: taattagctgagctCTTCACG""
                     /ApEinfo_revcolor=""#85dae9""
                     /ApEinfo_fwdcolor=""#85dae9""
     misc_feature    5058..5085
                     /label=""pf""
                     /ApEinfo_revcolor=""#75c6a9""
                     /ApEinfo_fwdcolor=""#75c6a9""
     misc_feature    5065..5070
                     /label=""RBS""
                     /ApEinfo_revcolor=""#c6c9d1""
                     /ApEinfo_fwdcolor=""#c6c9d1""
     misc_feature    5070..5075
                     /label=""RBS""
                     /ApEinfo_revcolor=""#f8d3a9""
                     /ApEinfo_fwdcolor=""#f8d3a9""
     CDS             5081..5875
                     /label=""KanR""
                     /ApEinfo_revcolor=""#faac61""
                     /ApEinfo_fwdcolor=""#faac61""
     misc_feature    5857..5879
                     /label=""KS445\""
                     /ApEinfo_revcolor=""#b4abac""
                     /ApEinfo_fwdcolor=""#b4abac""
     misc_feature    complement(5858..5875)
                     /label=""ACM205\""
                     /ApEinfo_revcolor=""#ff9ccd""
                     /ApEinfo_fwdcolor=""#ff9ccd""
     misc_feature    complement(5860..5882)
                     /label=""pr""
                     /ApEinfo_revcolor=""#b4abac""
                     /ApEinfo_fwdcolor=""#b4abac""
     primer          5883..5901
                     /label=""oLAC24""
                     /note=""sequence: CAAACTGGGGCACAGATAG""
                     /ApEinfo_revcolor=""#b4abac""
                     /ApEinfo_fwdcolor=""#b4abac""
     misc_feature    5883..5903
                     /label=""pf""
                     /ApEinfo_revcolor=""#b7e6d7""
                     /ApEinfo_fwdcolor=""#b7e6d7""
     primer          complement(5895..5913)
                     /label=""oLAC28""
                     /note=""sequence: GGGATGGGTACCCTATCTG""
                     /ApEinfo_revcolor=""#faac61""
                     /ApEinfo_fwdcolor=""#faac61""
     misc_feature    5932..6154
                     /label=""From pJA02""
                     /ApEinfo_revcolor=""#ffef86""
                     /ApEinfo_fwdcolor=""#ffef86""
     misc_feature    5993..5993
                     /label=""C->T""
                     /ApEinfo_revcolor=""#ff9ccd""
                     /ApEinfo_fwdcolor=""#ff9ccd""
     misc_feature    5999..6127
                     /label=""BBa_B0015""
                     /ApEinfo_revcolor=""#b7e6d7""
                     /ApEinfo_fwdcolor=""#b7e6d7""
     misc_feature    6155..7290
                     /label=""lacZ downstream""
                     /ApEinfo_revcolor=""#ff9ccd""
                     /ApEinfo_fwdcolor=""#ff9ccd""
     misc_feature    complement(6165..6185)
                     /label=""p2""
                     /ApEinfo_revcolor=""#85dae9""
                     /ApEinfo_fwdcolor=""#85dae9""
     primer          complement(6265..6282)
                     /label=""oLAC27""
                     /note=""sequence: AGTTGGCTCTTGCTTTGG""
                     /ApEinfo_revcolor=""#d59687""
                     /ApEinfo_fwdcolor=""#d59687""
     primer          6293..6312
                     /label=""oLAC25""
                     /note=""sequence: TTCTGCCATCAGTTGGATTG""
                     /ApEinfo_revcolor=""#faac61""
                     /ApEinfo_fwdcolor=""#faac61""
     primer          6492..6509
                     /label=""oQJ39""
                     /note=""sequence: AGGTTAGTCATCGCCTGT""
                     /ApEinfo_revcolor=""#85dae9""
                     /ApEinfo_fwdcolor=""#85dae9""
     primer          6969..6987
                     /label=""oLAC16""
                     /note=""sequence: GGATCAGAAACATCGCTGA""
                     /ApEinfo_revcolor=""#f58a5e""
                     /ApEinfo_fwdcolor=""#f58a5e""
     primer          complement(7270..7290)
                     /label=""oQJ71""
                     /note=""sequence: TGTTGAACAAGCGTCATGGCT""
                     /ApEinfo_revcolor=""#f7977a""
                     /ApEinfo_fwdcolor=""#f7977a""
     primer          complement(7270..7290)
                     /label=""oQJ71""
                     /note=""sequence: TGTTGAACAAGCGTCATGGCT""
                     /ApEinfo_revcolor=""#c7b0e3""
                     /ApEinfo_fwdcolor=""#c7b0e3""
     misc_feature    7431..8291
                     /label=""AmpR""
                     /ApEinfo_revcolor=""#b7e6d7""
                     /ApEinfo_fwdcolor=""#b7e6d7""
ORIGIN
        1 GTTATTTCTT GATGTCTCTG ACCAGACACC CATCAACAGT ATTATTTTCT CCCATGAAGA
       61 CGGTACGCGA CTGGGCGTGG AGCATCTGGT CGCATTGGGT CACCAGCAAA TCGCGCTGTT
      121 AGCGGGCCCA TTAAGTTCTG TCTCGGCGCG TCTGCGTCTG GCTGGCTGGC ATAAATATCT
      181 CACTCGCAAT CAAATTCAGC CGATAGCGGA ACGGGAAGGC GACTGGAGTG CCATGTCCGG
      241 TTTTCAACAA ACCATGCAAA TGCTGAATGA GGGCATCGTT CCCACTGCGA TGCTGGTTGC
      301 CAACGATCAG ATGGCGCTGG GCGCAATGCG CGCCATTACC GAGTCCGGGC TGCGCGTTGG
      361 TGCGGATATC TCGGTAGTGG GATACGACGA TACCGAAGAC AGCTCATGTT ATATCCCGCC
      421 GTCAACCACC ATCAAACAGG ATTTTCGCCT GCTGGGGCAA ACCAGCGTGG ACCGCTTGCT
      481 GCAACTCTCT CAGGGCCAGG CGGTGAAGGG CAATCAGCTG TTGCCCGTCT CACTGGTGAA
      541 AAGAAAAACC ACCCTGGCGC CCAATACGCA AACCGCCTCT CCCCGCGCGT TGGCCGATTC
      601 ATTAATGCAG CTGGCACGAC CGCGTAGCCT GTCAGAAATT GATCGGTCGA TAGGCTGTCA
      661 CCTAAGGCAT TTTGCAGCAA GGGAAGAACC ACATGACCGC CACCAAACAC TAAGCTTCCT
      721 GCTTGGAAGA AATGGCCAAA CAACTCAACC AGCGGTGAGC TTGCAGCCAA GAGCGGCAGC
      781 CCGAGTAATA AACTTGCAAA AAGTAGCAGT GAAAGCCAAG AGGGGCTGAA CGTGGTTGTC
      841 GAAAATGACT GTTGTGGTGC CAAGCGGGCT TGGCCAACGA AAGCGGCGAT CAGAAGGACC
      901 GCAAACTGAG TGATGAGACC GGGAGCTAAC GTAATCGCAA CCGCAGTCAG AACACATAAC
      961 CCTGCAGTAA GGCGTTGCTG ACAAAAATTG CGATACATGG TTAAACAAGC ATCGGCCACC
     1021 ACTATGATCG CGAGTAGCTT CAAGCCATGA ATCATTTGTT CAAACAGTGG GGTATCAAGG
     1081 AGATGGCTGC TTAGCCCCGC GAGCAGCAGC ATGATGAGCA CGGAGGGAAG GGTAAAACCG
     1141 AGAAACGCTG CCCAAGCGCC AGCCAGACCA CCACGATGAT AACCAATCGC AAAACCAACT
     1201 TGGCTAGAAC CGGGGCCAGG AAGGAACTGG CTCAGTGCCA CAAATTGTGC ATATTCTTGC
     1261 TCGCTAACCC AGCGTAATTT CTCAACAAAG GTGTGGCGAA AGTAACCTAT ATGTGCGGCT
     1321 GGCCCACCAA AACTCACCCA TCCGAGAGCA AAAAAAGTTC TAAAAATCGT TAGCATAATG
     1381 ATCTGAAGTC ATCCGTAATC AATGGAAGGT CAACATCCGT AGGAGCATAG GTTATGGAGA
     1441 GTCAAAGCGC AGAACAACTC CGAATGTGTA AAAAATTACA CCATTATGAT GGCAATCGTA
     1501 TGAATCGATT CAGAAATAGA AAAATTGGGT CAATATCGAC CTCTATTTAA ATTGTGGAAA
     1561 CGTTTACACA ATTGGTGAGT GGTTCACAGA ATCGGTGTTT GAAAGTTTGT TAGACTTTTT
     1621 TGCATCTGCA GCATGTCATC ATTCCTATTC AAAGCTGCGA ATCTTATTGA ATGACTTCTT
     1681 TACTCCTCGG CTTGAGGGtt gacagctagc tcagtcctag gtataatgct agcgaagttc
     1741 ctattctcta gaaagtatag gaacttcCGA AGCTGGGGAT CCGTTTGATT TTTAATGGAT
     1801 AATGTGATAT AATCTTTAAA TACTGTAGAA AAGAGGAAGG AAATAATAAA TGGCTAAAAT
     1861 GAGAATATCA CCGGAATTGA AAAAACTGAT CGAAAAATAC CGCTGCGTAA AAGATACGGA
     1921 AGGAATGTCT CCTGCTAAGG TATATAAGCT GGTGGGAGAA AATGAAAACC TATATTTAAA
     1981 AATGACGGAC AGCCGGTATA AAGGGACCAC CTATGATGTG GAACGGGAAA AGGACATGAT
     2041 GCTATGGCTG GAAGGAAAGC TGCCTGTTCC AAAGGTCCTG CACTTTGAAC GGCATGATGG
     2101 CTGGAGCAAT CTGCTCATGA GTGAGGCCGA TGGCGTCCTT TGCTCGGAAG AGTATGAAGA
     2161 TGAACAAAGC CCTGAAAAGA TTATCGAGCT GTATGCGGAG TGCATCAGGC TCTTTCACTC
     2221 CATCGACATA TCGGATTGTC CCTATACGAA TAGCTTAGAC AGCCGCTTAG CCGAATTGGA
     2281 TTACTTACTG AATAACGATC TGGCCGATGT GGATTGCGAA AACTGGGAAG AAGACACTCC
     2341 ATTTAAAGAT CCGCGCGAGC TGTATGATTT TTTAAAGACG GAAAAGCCCG AAGAGGAACT
     2401 TGTCTTTTCC CACGGCGACC TGGGAGACAG CAACATCTTT GTGAAAGATG GCAAAGTAAG
     2461 TGGCTTTATT GATCTTGGGA GAAGCGGCAG GGCGGACAAG TGGTATGACA TTGCCTTCTG
     2521 CGTCCGGTCG ATCAGGGAGG ATATCGGGGA AGAACAGTAT GTCGAGCTAT TTTTTGACTT
     2581 ACTGGGGATC AAGCCTGATT GGGAGAAAAT AAAATATTAT ATTTTACTGG ATGAATTGTT
     2641 TTAGGACGTC GCCGGCGGCA TCAAATAAAA CGAAAGGCTC AGTCGAAAGA CTGGGCCTTT
     2701 CGTTTTATCT GTTGTTTGTC GGTGAACGCT CTCCTGAGTC CCACAATAAG CCAGAGAGCC
     2761 GGTGTCAACG TAAATGCATG CCGCTTCGCC TTCGCGCGCG AATTGCAAGC TGATCCGGGC
     2821 TTATCGACTG CACGGTGCAC CAATGCTTCT GGCGTCAGGC AGCCATCGGA AGCTGTGGTA
     2881 TGGCTGTGCA GGTCGTAAAT CACTGCATAA TTCGTGTCGC TCAAGGCGCA CTCCCGTTCT
     2941 GGATAATGTT TTTTGCGCCG ACATCATAAC GGTTCTGGCA AATATTCTGA AATGAGCTGT
     3001 TGACAATTAA TCATCGGCTC GTATAATGTG TGGAATTGTG AGCGGATAAC AATTTCACAC
     3061 AGGAAACAGC CTCGACAGGC CTAGGAATTC AGGgaagttc ctattctcta gaaagtatag
     3121 gaacttcAGT GTGGGGTCTG CCTCGACAGG CCTAGGAATT CAGGAGCTAA GGAAGCTAAA
     3181 ATGGTGAGCA AGGGCGAGGA GACCACAATG GGCGTAATCA AGCCCGACAT GAAGATCAAG
     3241 CTGAAGATGG AGGGCAACGT GAATGGCCAC GCCTTCGTGA TCGAGGGCGA GGGCGAGGGC
     3301 AAGCCCTACG ACGGCACCAA CACCATCAAC CTGGAGGTGA AGGAGGGAGC CCCCCTGCCC
     3361 TTCTCCTACG ACATTCTGAC CACCGCGTTC GCCTACGGCA ACAGGGCCTT CACCAAGTAC
     3421 CCCGACGACA TCCCCAACTA CTTCAAGCAG TCCTTCCCCG AGGGCTACTC TTGGGAGCGC
     3481 ACCATGACCT TCGAGGACAA GGGCATCGTG AAGGTGAAGT CCGACATCTC CATGGAGGAG
     3541 GACTCCTTCA TCTACGAGAT ACACCTCAAG GGCGAGAACT TCCCCCCCAA CGGCCCCGTG
     3601 ATGCAGAAGA AGACCACCGG CTGGGACGCC TCCACCGAGA GGATGTACGT GCGCGACGGC
     3661 GTGCTGAAGG GCGACGTCAA GCACAAGCTG CTGCTGGAGG GCGGCGGCCA CCACCGCGTT
     3721 GACTTCAAGA CCATCTACAG GGCCAAGAAG GCGGTGAAGC TGCCCGACTA TCACTTTGTG
     3781 GACCACCGCA TCGAGATCCT GAACCACGAC AAGGACTACA ACAAGGTGAC CGTTTACGAG
     3841 AGCGCCGTGG CCCGCAACTC CACCGACGGC ATGGACGAGC TGTACAAGTA AGGATCCGGT
     3901 GATTGATTGA GCAAGCTTTA TGCTTGTAAA CCGTTTTGTG AAAAAATTTT TAAAATAAAA
     3961 AAGGGGACCT CTAGGGTCCC CAATTACTAG CCAGCGGCCG GCTGTTTTGG CGGATGAGAG
     4021 AAGATTTTCA GCCTGATACA GATTAAATCA GAACGCAGAA GCGGTCTcca ggcatcaaat
     4081 aaaacgaaag gctcagtcga aagactgggc ctttcgtttt atctgttgtt tgtcggtgaa
     4141 cgctctctac tagagtcaca ctggctcacc ttcgggtggg cctttctgcg tttataGATA
     4201 AAACAGAATT TGCCTGGCGG CAGgaagttc ctattctcta gaaagtatag gaacttcAAA
     4261 CAGCCTCGAC AGGCCTAGGA caagagacag gatactagtg gaggaagaaa aaatggtgag
     4321 caagggcgag gagaataaca tggccatcat caaggagttc atgcgcttca aggtgcgcat
     4381 ggagggctcc gtgaacggcc acgagttcga gatcgagggc gagggcgagg gccgccccta
     4441 cgagggcttt cagaccgcta agctgaaggt gaccaagggt ggccccctgc ccttcgcctg
     4501 ggacatcctg tcccctcatt tcacctacgg ctccaaggcc tacgtgaagc accccgccga
     4561 catccccgac tacttcaagc tgtccttccc cgagggcttc aagtgggagc gcgtgatgaa
     4621 ctacgaggac ggcggcgtgg tgaccgtgac ccaggactcc tccctgcagg acggcgagtt
     4681 catctacaag gtgaagctgc gcggcaccaa cttcccctcc gacggccccg tgatgcagaa
     4741 gaagaccatg ggctgggagg cctcctccga gcggatgtac cccgaggacg gtgccctgaa
     4801 gggcaagatc aagatgaggc tgaagctgaa ggacggcggc cactacacct ccgaggtcaa
     4861 gaccacctac aaggccaaga agcccgtgca gctgcccggc gcctacatcg tcgacatcaa
     4921 gttggacatc acctcccaca acgaggacta caccatcgtg gaacagtacg aacgcgccga
     4981 gggccgccac tccaccggcg gcatggacga gctgtacaag taataattag ctgagctCTT
     5041 CACGTGAGAC GTCAACCAGA AAAGAGGAAG GAAATAATAA ATGGCTAAAA TGAGAATATC
     5101 ACCGGAATTG AAAAAACTGA TCGAAAAATA CCGCTGCGTA AAAGATACGG AAGGAATGTC
     5161 TCCTGCTAAG GTATATAAGC TGGTGGGAGA AAATGAAAAC CTATATTTAA AAATGACGGA
     5221 CAGCCGGTAT AAAGGGACCA CCTATGATGT GGAACGGGAA AAGGACATGA TGCTATGGCT
     5281 GGAAGGAAAG CTGCCTGTTC CAAAGGTCCT GCACTTTGAA CGGCATGATG GCTGGAGCAA
     5341 TCTGCTCATG AGTGAGGCCG ATGGCGTCCT TTGCTCGGAA GAGTATGAAG ATGAACAAAG
     5401 CCCTGAAAAG ATTATCGAGC TGTATGCGGA GTGCATCAGG CTCTTTCACT CCATCGACAT
     5461 ATCGGATTGT CCCTATACGA ATAGCTTAGA CAGCCGCTTA GCCGAATTGG ATTACTTACT
     5521 GAATAACGAT CTGGCCGATG TGGATTGCGA AAACTGGGAA GAAGACACTC CATTTAAAGA
     5581 TCCGCGCGAG CTGTATGATT TTTTAAAGAC GGAAAAGCCC GAAGAGGAAC TTGTCTTTTC
     5641 CCACGGCGAC CTGGGAGACA GCAACATCTT TGTGAAAGAT GGCAAAGTAA GTGGCTTTAT
     5701 TGATCTTGGG AGAAGCGGCA GGGCGGACAA GTGGTATGAC ATTGCCTTCT GCGTCCGGTC
     5761 GATCAGGGAG GATATCGGGG AAGAACAGTA TGTCGAGCTA TTTTTTGACT TACTGGGGAT
     5821 CAAGCCTGAT TGGGAGAAAA TAAAATATTA TATTTTACTG GATGAATTGT TTTAGGACGT
     5881 CGCAAACTGG GGCACAGATA GGGTACCCAT CCCTCAAGCC GAGCCCCATG CGCTGTTTTG
     5941 GCGGATGAGA GAAGATTTTC AGCCTGATAC AGATTAAATC AGAACGCAGA AGCGGTCTcc
     6001 aggcatcaaa taaaacgaaa ggctcagtcg aaagactggg cctttcgttt tatctgttgt
     6061 ttgtcggtga acgctctcta ctagagtcac actggctcac cttcgggtgg gcctttctgc
     6121 gtttataGAT AAAACAGAAT TTGCCTGGCG GCAGCCCACA ATAAGCCAGA GAGCCTTAAG
     6181 GCTCTCTTTT TTGTGCCACG CTGTCGCGGC GAACGATGGT GGGCGAAAAG ATCATCGGAT
     6241 CATTTTCACG CGGTGCATCG GTTGCCAAAG CAAGAGCCAA CTGAGTGGCT TTTTCTGCCA
     6301 TCAGTTGGAT TGGGTAACGC ACGGTCGTCA GGCGTGGGCG TAAGTAGCGC GAAATCAGGG
     6361 CATCGTCAAA ACCAATCACT GAGACATGTT CAGGAACCGA ATGCCCATTT TCCTCAAGTA
     6421 CCAACAGGGC TCCAGCGGCC ATATTGTCGT TGTAAGCGAC CACTGCGGTA AAAGGCAGTG
     6481 ATTTCACCAG TAGGTTAGTC ATCGCCTGTT CGCCGCCTTC ACTGTCTGGG CTGGCTTTTT
     6541 CAATATAGCT GCTGCTTAGG GTGATGCCAT GTTCGTTCAA GGCTTGTTGA TAGCCCGCAA
     6601 TACGCTGATC GGCATCCTCA ATTTGATGAG AGGAGCTGAT GCAAGCAATG TTTCTATGTC
     6661 CTTGACGGAT GAGAAAATCG GTTGCTAAAT AAGCACCTTT CTGGTTGTCG AGTGAAATAC
     6721 AGCGATCGGC GAGCTGAGGA ATATGGCGAT TGATCAACAC CAGCGTTTTT ACCTCGTTGG
     6781 CGTACTCAAT CAGCTCTTCA TTGGGAAGCG CTTTGGAGTG GATGACCAGT GCATCACAGC
     6841 GGCTGTTGAT GAGCAGTTCC AGCGCGCGGC GCTCTTCTTC CGCTCGGTGG TAGCCGTTGC
     6901 CGATCAGCAA ATGTTTTCCT TCGCGGTGGG CGACAGTGTC GACGGCTTTG ACTAAAGTTC
     6961 CAAAGAAGGG ATCAGAAACA TCGCTGACCA AGACCCCTAT GGTATTGGTG CTTTGATTGA
     7021 CTAAAGCGCG AGCCGCGGCG TTCGGACGAT AGCCGAGTTT GTGCATCGCA CTGGTCACCG
     7081 TATCAATCGA GGCTTGGCTG GCTTTCGGGG ATTTGTTGAT GACGCGTGAA ACCGTTGCCA
     7141 CAGATACACC GGCTTCACGT GCTACGTCTT TTATGGTTGC CATAAGATTC CTTCTCTATC
     7201 ACAGGCGCAA TAGTAGCGCT CCCTGTGAAA ACAGCGCAAT TGTAACTGAG TACATAAGAG
     7261 TGAATTGTGA GCCATGACGC TTGTTCAACA CAGAAGGCCA TCCTGACGGA TGGCCTTTTT
     7321 GCGTTTCTAC AAACTCTTTT TGTTTATTTT TCTAAATACA TTCAAATATG TATCCGCTCA
     7381 TGAGACAATA ACCCTGATAA ATGCTTCAAT AATATTGAAA AAGGAAGAGT ATGAGTATTC
     7441 AACATTTCCG TGTCGCCCTT ATTCCCTTTT TTGCGGCATT TTGCCTTCCT GTTTTTGCTC
     7501 ACCCAGAAAC GCTGGTGAAA GTAAAAGATG CTGAAGATCA GTTGGGTGCA CGAGTGGGTT
     7561 ACATCGAACT GGATCTCAAC AGCGGTAAGA TCCTTGAGAG TTTTCGCCCC GAAGAACGTT
     7621 TTCCAATGAT GAGCACTTTT AAAGTTCTGC TATGTGGCGC GGTATTATCC CGTGTTGACG
     7681 CCGGGCAAGA GCAACTCGGT CGCCGCATAC ACTATTCTCA GAATGACTTG GTTGAGTACT
     7741 CACCAGTCAC AGAAAAGCAT CTTACGGATG GCATGACAGT AAGAGAATTA TGCAGTGCTG
     7801 CCATAACCAT GAGTGATAAC ACTGCGGCCA ACTTACTTCT GACAACGATC GGAGGACCGA
     7861 AGGAGCTAAC CGCTTTTTTG CACAACATGG GGGATCATGT AACTCGCCTT GATCGTTGGG
     7921 AACCGGAGCT GAATGAAGCC ATACCAAACG ACGAGCGTGA CACCACGATG CCTACAGCAA
     7981 TGGCAACAAC GTTGCGCAAA CTATTAACTG GCGAACTACT TACTCTAGCT TCCCGGCAAC
     8041 AATTAATAGA CTGGATGGAG GCGGATAAAG TTGCAGGACC ACTTCTGCGC TCGGCCCTTC
     8101 CGGCTGGCTG GTTTATTGCT GATAAATCTG GAGCCGGTGA GCGTGGGTCT CGCGGTATCA
     8161 TTGCAGCACT GGGGCCAGAT GGTAAGCCCT CCCGTATCGT AGTTATCTAC ACGACGGGGA
     8221 GTCAGGCAAC TATGGATGAA CGAAATAGAC AGATCGCTGA GATAGGTGCC TCACTGATTA
     8281 AGCATTGGTA ACTGTCAGAC CAAGTTTACT CATATATACT TTAGATTGAT TTAAAACTTC
     8341 ATTTTTAATT TAAAAGGATC TAGGTGAAGA TCCTTTTTGA TAATCTCATG ACCAAAATCC
     8401 CTTAACGTGA GTTTTCGTTC CACTGAGCGT CAGACCCCGT AGAAAAGATC AAAGGATCTT
     8461 CTTGAGATCC TTTTTTTCTG CGCGTAATCT GCTGCTTGCA AACAAAAAAA CCACCGCTAC
     8521 CAGCGGTGGT TTGTTTGCCG GATCAAGAGC TACCAACTCT TTTTCCGAAG GTAACTGGCT
     8581 TCAGCAGAGC GCAGATACCA AATACTGTCC TTCTAGTGTA GCCGTAGTTA GGCCACCACT
     8641 TCAAGAACTC TGTAGCACCG CCTACATACC TCGCTCTGCT AATCCTGTTA CCAGTGGCTG
     8701 CTGCCAGTGG CGATAAGTCG TGTCTTACCG GGTTGGACTC AAGACGATAG TTACCGGATA
     8761 AGGCGCAGCG GTCGGGCTGA ACGGGGGGTT CGTGCACACA GCCCAGCTTG GAGCGAACGA
     8821 CCTACACCGA ACTGAGATAC CTACAGCGTG AGCTATGAGA AAGCGCCACG CTTCCCGAAG
     8881 GGAGAAAGGC GGACAGGTAT CCGGTAAGCG GCAGGGTCGG AACAGGAGAG CGCACGAGGG
     8941 AGCTTCCAGG GGGAAACGCC TGGTATCTTT ATAGTCCTGT CGGGTTTCGC CACCTCTGAC
     9001 TTGAGCGTCG ATTTTTGTGA TGCTCGTCAG GGGGGCGGAG CCTATGGAAA AACGCCAGCA
     9061 ACGCGGCCTT TTTACGGTTC CTGGCCTTTT GCTGGCCTTT TGCTCACATG TTCTTTCCTG
     9121 CGTTATCCCC TGATTCTGTG GATAACCGTA TTACCGCCTT TGAGTGAGCT GATACCGCTC
     9181 GCCGCAGCCG AACGACCGAG CGCAGCGAGT CAGTGAGCGA GGAAGCGGAA GAGCGCCTGA
     9241 TGCGGTATTT TCTCCTTACG CATCTGTGCG GTATTTCACA CCGCATATGG TGCACTCTCA
     9301 GTACAATCTG CTCTGATGCC GCATAGTTAA GCCAGTATAC ACTCCGCTAT CGCTACGTGA
     9361 CTGGGTCATG GCTGCGCCCC GACACCCGCC AACACCCGCT GACGCGCCCT GACGGGCTTG
     9421 TCTGCTCCCG GCATCCGCTT ACAGACAAGC TGTGACCGTC TCCGGGAGCT GCATGTGTCA
     9481 GAGGTTTTCA CCGTCATCAC CGAAACGCGC GAGGCAGCAG ATCAATTCGC GCGCGAAGGC
     9541 GAAGCGGCAT GCATTTACGT TGACACCATC GAATGGTGCA AAACCTTTCG CGGTATGGCA
     9601 TGATAGCGCC CGGAAGAGAG TCAATTCAGG GTGGTGAATG TGAAACCAGT AACGTTATAC
     9661 GATGTCGCAG AGTATGCCGG TGTCTCTTAT CAGACCGTTT CCCGCGTGGT GAACCAGGCC
     9721 AGCCACGTTT CTGCGAAAAC GCGGGAAAAA GTGGAAGCGG CGATGGCGGA GCTGAATTAC
     9781 ATTCCCAACC GCGTGGCACA ACAACTGGCG GGCAAACAGT CGTTGCTGAT TGGCGTTGCC
     9841 ACCTCCAGTC TGGCCCTGCA CGCGCCGTCG CAAATTGTCG CGGCGATTAA ATCTCGCGCC
     9901 GATCAACTGG GTGCCAGCGT GGTGGTGTCG ATGGTAGAAC GAAGCGGCGT CGAAGCCTGT
     9961 AAAGCGGCGG TGCACAATCT TCTCGCGCAA CGCGTCAGTG GGCTGATCAT TAACTATCCG
    10021 CTGGATGACC AGGATGCCAT TGCTGTGGAA GCTGCCTGCA CTAATGTTCC GGC
//
```",adityanprasad,https://github.com/BioJulia/GenomicAnnotations.jl/issues/13,BioJulia++GenomicAnnotations.jl.csv
I_kwDOB7QJcs6arGW3,Type piracy of Base breaks package in 1.11,CLOSED,2024-10-17T14:54:45Z,2024-10-17T16:26:34Z,2024-10-17T16:15:36Z,"This package defines this method:
```
function Base.getproperty(genes::AbstractArray{G, 1}, name::Symbol) where {G <: AbstractGene}
   ....
```
This is piracy, since both `AbstractArray` and `AbstractGene` is implemented in Base, and breaks the package in Julia 1.11.
It may seem like it shouldn't be piracy since you explicitly only overrode `AbstractArray{<:AbstractGene}`, and this package owns `AbstractGene`. And indeed, this piracy should not be able to break code unrelated to this package.
The problem is that this package relies on existing methods for `AbstractArray` working, such as `getproperty`. When this method is overwritten, then any code that used `getproperty` for `AbstractArray{<:AbstractGene}` breaks, which includes basic Base code.

The solution is to stop pirating Base here.",jakobnissen,https://github.com/BioJulia/GenomicAnnotations.jl/issues/14,BioJulia++GenomicAnnotations.jl.csv
I_kwDOB7QJcs6eCHoP,gffstring merges multi-position features,CLOSED,2024-11-12T07:53:33Z,2024-11-12T09:17:57Z,2024-11-12T09:17:56Z,"julia> test_locus = Join([ClosedSpan(1:10), ClosedSpan(20:30)])
join(1..10,20..30)
julia> test_locus.position isa Vector
false
julia> typeof(test_locus.position)
Base.Iterators.Flatten{Base.Generator{Vector{SpanLocus{ClosedSpan}}, GenomicAnnotations.var""#24#25""}}

Thus 'if locus(gene).position isa Vector' in gffstring() fails and the feature is written to the .gff file as a single span from 1:30
This messes up CDS features with introns, for example.
Is this a bug, or am I creating my Joins wrongly?",ian-small,https://github.com/BioJulia/GenomicAnnotations.jl/issues/15,BioJulia++GenomicAnnotations.jl.csv
I_kwDOB7QJcs6eLgvr,gffstring can still merge reverse strand multi-position loci,CLOSED,2024-11-13T01:19:06Z,2024-11-13T16:40:58Z,2024-11-13T16:40:58Z,"Thanks for the very rapid fix, but it's not quite complete. 'if locus(gene) isa Union{Join, Order}' fails for loci constructed as Complement(Join([Locus, Locus])). I can work round this by constructing all such features as Join([Complement(Locus), Complement(Locus)]) (in which case everything works perfectly as far as I can see), but you might not want to rely on features always being constructed that way.",ian-small,https://github.com/BioJulia/GenomicAnnotations.jl/issues/16,BioJulia++GenomicAnnotations.jl.csv
I_kwDOB7QJcs6eMP-J,gffstring mishandles transpliced genes,CLOSED,2024-11-13T03:26:06Z,2024-11-14T11:32:46Z,2024-11-14T11:29:12Z,"'locus(gene).strand' in gffstring assumes all positions in the locus are on the same strand, which is not true for trans-spliced genes, e.g. join(11056..11919,complement(94283..95886)) is a valid GenBank locus that can now be faithfully represented using your much-appreciated rewrite of GenomicAnnotations.Locus, but which is rendered as 
gene	11056	11919	.	+
gene	94283	95886	.	+
by GFF.gffstring() ",ian-small,https://github.com/BioJulia/GenomicAnnotations.jl/issues/17,BioJulia++GenomicAnnotations.jl.csv
I_kwDOB7QJcs6eOLXB,minor issues with headers,CLOSED,2024-11-13T07:30:23Z,2024-11-13T15:26:00Z,2024-11-13T15:25:59Z,"Records can be created with empty headers:
Record{Gene}() = Record{Gene}("""", dna"""", """", Gene[], DataFrame(), false)
but 'if chrs[1].header[1:15] == ""#gff-version 3\n""' in printgff() errors with an empty header (or even on one with less than 15 chars)
What's more, the equality fails even with a valid gff3 header as it should be testing for '##gff-version 3' according to the spec.
I would suggest this be changed to
if isempty(chrs[1].header)) || ~startswith(chrs[1].header, ""##gff-version 3"")

A question, not an issue as such. Is the ultimate intention to have some sort of cross-format Header structure for metadata? At the moment, it is not very clear how to transfer metadata from one format to another, or how to efficiently create headers from scratch.",ian-small,https://github.com/BioJulia/GenomicAnnotations.jl/issues/18,BioJulia++GenomicAnnotations.jl.csv
I_kwDOB7QJcs6f7MtL,Sequence section of .gbk output is non-standard?,CLOSED,2024-11-22T12:48:41Z,2024-11-22T18:14:21Z,2024-11-22T18:14:21Z,"I'm now using GenomicAnnotations.jl in [Chloe](https://github.com/ian-small/Chloe.jl), so thanks for your efforts in making that possible.
I'm just passing on an observation from a user about the .gbk output that it generates:
'[Scanner.py](https://github.com/biopython/biopython/blob/master/Bio/GenBank/Scanner.py) of BioPython raises a malformed sequence error apparently due to improper indentation of the sequence. Adding a single space to each line of the sequence entry at the bottom of the file removes that error.'
It seems that the sequence part of the .gbk files generated by GenomicAnnotations.jl have fewer spaces at the start of the line than files from GenBank. I'm not sure what the official spec is.
",ian-small,https://github.com/BioJulia/GenomicAnnotations.jl/issues/19,BioJulia++GenomicAnnotations.jl.csv
MDU6SXNzdWUzMjk0MTU3OA==,Create example dataset,OPEN,2014-05-06T23:05:04Z,2014-05-06T23:05:04Z,,"- one _Oryza sativa var. japonica_ chromosome
- a set of real reads subsetted to only those aligning to the chromosome
- _Arabidopsis_ one representative protein per locus
",blahah,https://github.com/blahah/TGAC-2014-genome-annotation/issues/1,blahah++TGAC-2014-genome-annotation.csv
I_kwDOD5u-Rs5HvKk5,Temp folder need to specify,OPEN,2022-04-13T16:45:47Z,2022-04-13T16:45:47Z,,"When using parallel to users need to specify a temp folder in there user directories and export the temp file.
Otherwise there will be error whenever the default temp is full and cannot write.

```
mkdir -p ${HOME}/temp
export TMPDIR=""${HOME}/temp""
```

above need to be specify in the 01_fasterq_dump.sh and the following in everyother script with uses parallel
`export TMPDIR=""${HOME}/temp""`",golden75,https://github.com/CBC-UCONN/RNA-seq-with-reference-genome-and-annotation/issues/1,CBC-UCONN++RNA-seq-with-reference-genome-and-annotation.csv
I_kwDOD5u-Rs5ICRV0,SRAtools intialize,OPEN,2022-04-19T15:54:06Z,2022-04-19T15:54:06Z,," before using sratoolkit/2.11.3, need to set up the configuration for the temp folder",golden75,https://github.com/CBC-UCONN/RNA-seq-with-reference-genome-and-annotation/issues/2,CBC-UCONN++RNA-seq-with-reference-genome-and-annotation.csv
I_kwDOD5u-Rs5P7B7C,add cityscape stuff,OPEN,2022-08-16T20:58:13Z,2022-08-16T20:58:13Z,,"per jill, add genemania and stringdb?",nreid,https://github.com/CBC-UCONN/RNA-seq-with-reference-genome-and-annotation/issues/3,CBC-UCONN++RNA-seq-with-reference-genome-and-annotation.csv
I_kwDOD5u-Rs5QSsFa,easy teaching purpose for align.sh ,OPEN,2022-08-22T22:38:17Z,2022-08-22T22:38:17Z,,"Change the SLURM header from
#SBATCH --array=[0-18]%5
to 
#SBATCH --array=[1-19]%5.  Per learning purpose.

So NUM=$(expr ${SLURM_ARRAY_TASK_ID} + 1)

will be just
NUM=${SLURM_ARRAY_TASK_ID} 

",golden75,https://github.com/CBC-UCONN/RNA-seq-with-reference-genome-and-annotation/issues/4,CBC-UCONN++RNA-seq-with-reference-genome-and-annotation.csv
I_kwDOD5u-Rs5YNeRH,Module updates,OPEN,2022-12-06T19:04:53Z,2022-12-15T15:27:38Z,,- update sratoolkit to sratoolkit/3.0.1  - newer version avoids running program for configuration,mianahom,https://github.com/CBC-UCONN/RNA-seq-with-reference-genome-and-annotation/issues/5,CBC-UCONN++RNA-seq-with-reference-genome-and-annotation.csv
MDU6SXNzdWU4MTEzMjcyMzM=,Images,CLOSED,2021-02-18T17:51:23Z,2021-02-18T17:54:11Z,2021-02-18T17:54:11Z,"![Pipeline_Scheme](https://user-images.githubusercontent.com/7016350/108399339-9cf6d580-71df-11eb-97ad-cf0366fddd02.jpg)
",cfarkas,https://github.com/cfarkas/annotate_my_genomes/issues/2,cfarkas++annotate_my_genomes.csv
I_kwDODMnPJc4-1KPR,dyld: Library not loaded: @rpath/libcrypto.1.0.0.dylib,OPEN,2021-11-15T21:37:29Z,2021-11-15T21:40:55Z,,"The following error appear when I used genome-download-macOSX:

dyld: Library not loaded: @rpath/libcrypto.1.0.0.dylib
  Referenced from: /opt/miniconda3/envs/annotate_my_genomes/bin/samtools
  Reason: image not found
./genome-download-macOSX: line 70:  9356 Abort trap: 6           samtools faidx ${genome}.fa

please help
Amella

",andymella,https://github.com/cfarkas/annotate_my_genomes/issues/3,cfarkas++annotate_my_genomes.csv
I_kwDODMnPJc6HqD0C,"Error: Too many positional arguments (1), the offending value: -",OPEN,2024-05-02T16:23:03Z,2024-05-02T16:23:03Z,,"Hello,

I try to annotate my transcripts with annotated genome. I think your workflow is perfect for my purpose. However, I ran into the following error during the `process > feelnc_annotation`.

`
Error: Too many positional arguments (1), the offending value: -
Error:  (CArgException::eSynopsis) Too many positional arguments (1), the offending value: -
`
Can you guide me where to find the `blastx` script to fix `-`

![Screenshot 2024-05-02 at 12 21 11PM](https://github.com/cfarkas/annotate_my_genomes/assets/42744112/52322b1a-5c3d-4728-bc0a-0fca2e2d808f)
![Screenshot 2024-05-02 at 12 20 13PM
](https://github.com/cfarkas/annotate_my_genomes/assets/42744112/2d7eb1dc-73b0-45dd-bcd0-bebe9f332f12)
",chenyanniii,https://github.com/cfarkas/annotate_my_genomes/issues/5,cfarkas++annotate_my_genomes.csv
I_kwDODFC6585d7oec,custom RNAseq data,CLOSED,2023-02-08T11:01:41Z,2023-04-01T15:54:29Z,2023-04-01T15:54:29Z,"Hi, 
Is it possible to run your pipeline with funannotate installed with docker rather than conda ? 
Second question : is it possible to add custom rnaseq data in addition to yours ? 

Thank you very much,",lalalagartija,https://github.com/cmdoret/Acastellanii_genome_annotation/issues/2,cmdoret++Acastellanii_genome_annotation.csv
I_kwDOD94Zvc5S1Ziu,pretextview step not working in GAP_hic_map7,OPEN,2022-09-28T17:42:42Z,2022-09-28T17:42:55Z,,Not working due to the .sam format that is output from `chromap`. Try to use a .pairs format instead.,conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/1,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5WUoSo,remove the fasta file from the output directory containing cool/mcool files. it has things named by JBAT,OPEN,2022-11-14T15:14:16Z,2022-11-14T15:14:16Z,,,conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/2,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5e0AXW,remove seaborn dependencies,OPEN,2023-02-19T13:38:45Z,2023-02-19T13:38:45Z,,"it causes too many problems, with GAP_annotate_miniprot for example",conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/3,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5gqejo,remove pretextmap from hic_map7 or implement pairs,OPEN,2023-03-13T15:38:25Z,2023-03-13T15:38:25Z,,"pretextmap now uses pairs as well, change to use this",conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/4,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5gs-JL,GAP_sort_scaffolds_by_hic_insert drops scaffolds,OPEN,2023-03-13T22:53:31Z,2023-03-13T23:03:29Z,,"Some of the scaffolds disappear, presumably because they lack Hi-C data",conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/5,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5kVBpy,make a chromap install snakemake script,OPEN,2023-04-25T13:59:39Z,2023-04-25T13:59:39Z,,used in GAP_sort_scaffolds_by_hic_insert,conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/6,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5r9veq,remove pysam dependency - add fasta,OPEN,2023-07-19T07:35:31Z,2023-07-19T07:35:46Z,,"There is a dependency on pysam in `bin/assembly-from-fasta.py`, remove the dependency and replace it with a prepackaged fasta parser",conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/7,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5sAOpM,max-threads vs cores,OPEN,2023-07-19T13:50:38Z,2023-07-19T13:50:38Z,,"In principle either should work. The usage of both is just to specify the maximum number of threads that should be used for SMPs, while most other things are limited to one thread.

One improvement could be to make these redundant through a runtime check to set whichever of this is present to a global variable within each snakemake script.",conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/8,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5sSyZG,check if zlib is installed for chromap,OPEN,2023-07-22T19:01:34Z,2023-07-22T19:01:34Z,,currently fails if zlib is not installed.,conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/9,conchoecia++genome_assembly_pipelines.csv
I_kwDOFwAbyc51O5P8,gene annotation with actual gene names,OPEN,2023-10-29T04:22:36Z,2023-10-29T04:22:36Z,,"Downloaded the gene annotation file of AB strain, ABBA.genomic.gff.gz, and want to use it in the sequencing analyses. It would be helpful providing actual gene names instead of names like ""ID=evm.model.Chromosome1.3"" in the file. Thanks!",litd,https://github.com/dana0201/zebrafish-AB-genome-annotation/issues/1,dana0201++zebrafish-AB-genome-annotation.csv
MDU6SXNzdWU3NTcwODQxOTU=,rmOutToGFF3custom sorts gff3 header into gff3 file,CLOSED,2020-12-04T12:59:07Z,2022-02-04T18:05:42Z,2022-02-04T18:05:41Z,"Hi Daren,

Thanks for posting some really detailed work on Maker, especially with examples including custom masked repeats. I found a slight error with your `rmOutToGFF3custom` script. As it is written it sorts the `##gff-version 3` header along with the contents of the gff file. Moving one parenthesis fixes it.

```
#!/usr/bin/env bash
usage()
{
cat << EOF
rmOutToGFF3custom
Version 1 (2019-10-10)
License: GNU GPLv2
To report bugs or errors, please contact Daren Card (dcard@uta.edu).
This script is provided as-is, with no support and no guarantee of proper or
desirable functioning.

This script converts the .out file from RepeatMasker to a GFF3 file. Note that the output
is probably not perfect GFF3, so beware with downstream applications. This script
emulates the rmOutToGFF3.pl script supplied with RepeatMasker but provides a fuller ID
(""target="") for each element in column 9 of the GFF. This ID includes the matching element,
like rmOutToGFF3.pl, but also includes the repeat family: in the format <Family>/<Element>.
This change is because many matching elements produced from RepeatModeler have IDs that
provide no information about repeat family classification. Output is written to standard
output (SDOUT).

This script requires requires awk, which should be available on any standard Unix system.

rmOutToGFF3custom -o <RM.out> [-h] > <name.gff3>

OPTIONS:
        -h              usage information and help (this message)
        -o              RepeatMasker .out file
EOF
}

while getopts ""ho:"" OPTION
do
        case $OPTION in
                help)
                        usage
                        exit 1
                        ;;
                o)
                        RMOUT=$OPTARG
                        ;;
        esac
done

if [[ -z $RMOUT ]]
then
        usage
        exit 1
fi

cat <(echo ""##gff-version 3"") \
<(cat ${RMOUT} | tail -n +4 | \
awk -v OFS=""\t"" '{ if ($12 ~ /)/) print $5, ""RepeatMasker"", ""dispersed_repeat"", $6, $7, $1, $9, ""."", ""Target=""$11""/""$10"" ""$14"" ""$13; \
else print $5, ""RepeatMasker"", ""dispersed_repeat"", $6, $7, $1, $9, ""."", ""Target=""$11""/""$10"" ""$12"" ""$13 }' | \
awk -v OFS=""\t"" '{ if ($7 == ""C"") print $1, $2, $3, $4, $5, $6, ""-"", $8, $9; else print $0 }' | \
sort -k1,1 -k4,4n -k5,5n )

```",AdamStuckert,https://github.com/darencard/GenomeAnnotation/issues/1,darencard++GenomeAnnotation.csv
I_kwDOLctQ6c6Ejk0z,Versioned docs,CLOSED,2024-04-03T21:01:39Z,2024-04-15T14:36:33Z,2024-04-15T14:36:33Z,"https://github.com/deepgenomics/GenomeKit/pull/30 added auto-published docs to Github Pages but it overwrites all the docs every time.

Change the repo config to grab the pages source from a branch, and add docs to that branch from the Github Actions workflow.",ovesh,https://github.com/deepgenomics/GenomeKit/issues/31,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6E13vH,DefaultDataManager checks GCS before the local path,CLOSED,2024-04-05T19:53:34Z,2024-04-08T16:33:49Z,2024-04-08T16:33:49Z,"https://github.com/deepgenomics/GenomeKit/blob/a5e7b44195bb3dee55b39369d7522f7b6038e8ba/genome_kit/data_manager.py#L192
DefaultDataManager.get_file() first checks if a file exists in the GCS bucket. If users build their own data files and put them in GENOMEKIT_DATA_DIR then GK will still claim that it can't find the files.",ovesh,https://github.com/deepgenomics/GenomeKit/issues/37,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6FCuXz,Add starter example for other data file types,OPEN,2024-04-08T21:09:02Z,2024-04-08T21:09:02Z,,"Add examples in starter/build.sh for generating:
* Appris
* gtrack
* vcfbin
* ralign
* jralign
* rdist",ovesh,https://github.com/deepgenomics/GenomeKit/issues/41,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6KIEwV,Trouble with ftp in starter build script,CLOSED,2024-05-26T01:27:31Z,2024-05-27T16:49:50Z,2024-05-27T16:49:50Z,"Hi!

Playing with `starter/build.sh` on a fedora linux system, I get errors like `Failed to parse URI 'ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_29/gencode.v29.annotation.gff3.gz'`. This is because my system uses wget2 which doesn't support ftp.

However, the resources are available over http(s) at the same location,  e.g. `https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_29/gencode.v29.annotation.gff3.gz` works and is probably preferable to using ftp anyway. Changing all ""ftp://"" to ""https://"" in build.sh makes the script work for me.

Thanks for open-sourcing GenomeKit :smile:
",kzuberi,https://github.com/deepgenomics/GenomeKit/issues/58,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6L6fyV,Reverse-lookup refg name from hash,CLOSED,2024-06-11T21:51:04Z,2024-06-13T04:33:45Z,2024-06-13T04:33:45Z,"Refg names are not encoded as part of intervals. Instead, it's a 32-bit hash of the name.
There is no way for GK to know the refg name from the hash. If a user loads a GK binary file (e.g gtrack) and tries to get the refg name from an interval, they get a cryptic error:
```
ValueError: src/refg.cpp:74: Could not retrieve name for 18068147913528327027
```",ovesh,https://github.com/deepgenomics/GenomeKit/issues/60,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6MAV9b,"Error passing 2D np array to GenomeTrackBuilder, but a copy works.",CLOSED,2024-06-12T14:17:47Z,2024-08-20T05:52:08Z,2024-08-20T05:52:07Z,"# Description

When trying to build a gtrack with multiple dimensions, you have to pass a copy of the array to the `GenomeTrackBuilder` for it to work. If you pass the original array, you get the following error:

```
ValueError: src/py_genome_track.cpp:219: Data must have stride=1, consider making a copy with `np.array`
```

# Steps to Reproduce

```
def test():
    genome = gk.Genome(""hg38"")
    itvl = gk.Interval(""chr1"", ""+"", 1000000, 1000010, genome)
    data = np.vstack([np.arange(10, dtype=np.int8)] * 5).T

    track = gk.GenomeTrackBuilder(
        f""test.gtrack"",
        ""i8"",
        ""single_stranded"",
        genome,
        dim=5,
    )
    track.set_default_value(0)

    # this breaks
    # track.set_data(itvl, data)
    # track.finalize()

    # this works
    track.set_data(itvl, data.copy())
    track.finalize()
```",parthgvora,https://github.com/deepgenomics/GenomeKit/issues/61,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6Mkmp8,Detect use-after-free bugs in debug mode,OPEN,2024-06-17T22:44:39Z,2024-06-17T22:44:39Z,,"#62 and #63 showed that it's too easy to introduce use-after-free bugs.
These can be caught by adding the fsanitize=address flag, which will exit non-zero if such a bug is found. Due to the performance penalty, enable this only in debug mode.",ovesh,https://github.com/deepgenomics/GenomeKit/issues/64,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6NF4Sx,No type check on genome.dna(Interval),CLOSED,2024-06-21T19:26:30Z,2024-06-22T00:55:56Z,2024-06-22T00:55:56Z,"Getting this cryptic error instead:
```
>>> import genome_kit as gk
>>> genome = gk.Genome(""hg38"")
>>> genome.dna(0)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: src/py_init.cpp:72: Traceback (most recent call last):
  File ""redacted.../python3.10/site-packages/genome_kit/gk_data.py"",
 line 87, in resolve_datafile_path
   path = get_file(rel_path)
  File ""redacted.../python3.10/site-packages/genome_kit/gk_data.py"",
 line 53, in get_file
   return data_manager.get_file(filename)
  File ""redacted.../python3.10/site-packages/gk_dg_plugins/data_mana
ger.py"", line 124, in get_file
   raise ValueError(f""No such file: {filename}"")
ValueError: No such file: 2551.hash
```",ovesh,https://github.com/deepgenomics/GenomeKit/issues/67,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6PxCBg,Broken docs link on anaconda.org,CLOSED,2024-07-16T20:32:25Z,2024-08-19T07:17:25Z,2024-08-19T07:17:25Z,The docs link on https://anaconda.org/conda-forge/genomekit points to https://genomekit.readthedocs.io/ instead of https://deepgenomics.github.io/GenomeKit/,ovesh,https://github.com/deepgenomics/GenomeKit/issues/69,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6TueAp,Interval compatibility across patches,OPEN,2024-08-21T16:09:16Z,2024-08-22T05:30:44Z,,"Hi GenomeKit team! Regarding hg38 patch compatibility. Imagine we are using an annotation on hg38.p12, and define the following three intervals:
```
import genome_kit as gk

genome = gk.Genome('ncbi_refseq.v109') # uses hg38.p12

itv = gk.Interval('chr7', '-', 65967466, 65968201, 'hg38')
itv_p12 = gk.Interval('chr7', '-', 65967466, 65968201, 'hg38.p12')
itv_p13 = gk.Interval('chr7', '-', 65967466, 65968201, 'hg38.p13')
```
Only the interval `itv_p12` will work with the object `genome`. For example, if we try to retrieve the sequence:
```
genome.dna(itv) # error
genome.dna(itv_p12) # works
genome.dna(itv_p13) # error
```
Similar errors occur when trying to find overlapping genes and transcripts, or creating new intervals based on a combination of these three intervals.

However, the sequence information on the main chromosome does not change between patches, and the intervals are actually compatible with each other. It would be useful to have either:
- Support for combining main chromosome intervals across patches 
   - In practice, this would mean that the above operations do not error out, but take advantage of the fact that the coordinates are the same across patches and return the same result as if `itv_p12` were used.
- A way of explicitly lifting/translating intervals across patches
    - Imagine we had something like a `genome.make_compatible(itv)` function that returns an interval on the same patch if the interval is on the main chromosome of the same major assembly. 
        - In this case, `genome.make_compatible(itv)`  and  `genome.make_compatible(itv_p13)` should return `itv_p12`
   - It would be easiest if `genome.make_compatible(itv_p12)` still returned `itv_p12` so we can call the function without checking the reference patch first. 
   - If the intervals are not compatible (e.g. different major assemblies, or non-main chromosome), the function should throw an error
   
This would be especially useful when dealing with intervals saved in a database. Currently, we are restricted to always working with the same patch that the interval was saved on, which limits our choice of annotations. This problem will get worse over time. 

Let me know if any clarificiations are needed. Thank you!
",eholgersen,https://github.com/deepgenomics/GenomeKit/issues/85,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6XmUFu,Quickstart VCFTable example doesn't work,OPEN,2024-09-23T18:52:42Z,2024-09-23T20:09:06Z,,"Trying to open the file in the example results in this error:
```
>>> vcf = VCFTable.from_vcf(""test.vcf.gz"", Genome(""hg19""), info_ids=[""AF""], fmt_ids=[""GT"", ""AD""])
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/foo/GenomeKit/genome_kit/vcf_table.py"", line 247, in from_vcf
    VCFTable.build_vcfbin(
ValueError: src/variant_table.cpp:983: In VCF file: test.vcf.gz:9
  src/variant_table.cpp:751: Invalid REF ""-"".
```

The correct contents of the file are in demos/query_vcf.py",ovesh,https://github.com/deepgenomics/GenomeKit/issues/95,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6ZoLaO,allow_outside_chromosome is default=True in python but actually defaults as False in the C layer,CLOSED,2024-10-10T03:37:07Z,2024-10-16T19:24:52Z,2024-10-16T19:24:52Z,"https://github.com/deepgenomics/GenomeKit/blob/8e8fca0237d647561637ef44fd7dc89b4370ee4a/genome_kit/genome_dna.py#L30

vs

https://github.com/deepgenomics/GenomeKit/blob/8e8fca0237d647561637ef44fd7dc89b4370ee4a/src/py_genome_dna.cpp#L63

Also VariantGenome.dna doesn't support it",s22chan,https://github.com/deepgenomics/GenomeKit/issues/97,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6agS20,support python 311 312 313,OPEN,2024-10-16T14:57:22Z,2024-11-06T17:44:47Z,,"Requires updating meta.yaml (on conda-forge, but only after local testing)",ovesh,https://github.com/deepgenomics/GenomeKit/issues/102,deepgenomics++GenomeKit.csv
I_kwDOLctQ6c6fYsYb,Starter build missing from main,OPEN,2024-11-20T01:37:02Z,2024-11-20T15:51:33Z,,"Hello dear genomekit team. Thanks for releasing the project it's been tremendously useful - I've been using it to help folks start using a model we made https://github.com/bowang-lab/Orthrus?tab=readme-ov-file#create-and-set-up-the-environment

It looks like the starter build link which is specified in [the docs ](https://deepgenomics.github.io/GenomeKit/quickstart.html#initial-data-access) now points to an empty page:

https://raw.githubusercontent.com/deepgenomics/GenomeKit/main/starter/build.sh

However, https://raw.githubusercontent.com/deepgenomics/GenomeKit/v6.0.3/starter/build.sh is still available. 

Is it possible to bring that page back online?

Thanks
",phil-fradkin,https://github.com/deepgenomics/GenomeKit/issues/115,deepgenomics++GenomeKit.csv
MDU6SXNzdWU2ODgxMjg5Mjg=,Use the read config class to handle configuration in the data preparation step,CLOSED,2020-08-28T14:48:46Z,2020-10-22T02:43:21Z,2020-10-22T02:43:21Z,"In `./functions/readConfig.py`

New methods are required:
- [x] Add test for checking if the provided config file exist
- [x] Functions to set `data_dir`, `chunksize` and `tolerance`
- [x] Functions to retrieve sources for GWAS, Gencode, Cytobands etc.
- [x] Functions to update data source versions and filenames.
- [x] A function is needed to save the updated config file.

In `./Prepare_data.py`

Update:
- [x] Use readConfigy to extract hardcoded parameters.
- [x] Use methods to update parameters in configuration
- [x] Use methods to save updated config file.
",DSuveges,https://github.com/DSuveges/GenomePlotter/issues/5,DSuveges++GenomePlotter.csv
MDU6SXNzdWU5MTk0ODE4MzE=,Adding github repo description,CLOSED,2021-06-12T07:43:58Z,2021-06-13T01:00:11Z,2021-06-13T01:00:11Z,,DSuveges,https://github.com/DSuveges/GenomePlotter/issues/6,DSuveges++GenomePlotter.csv
MDU6SXNzdWU5MTk0ODIwNTY=,Review scripts ,CLOSED,2021-06-12T07:44:45Z,2021-06-13T00:58:40Z,2021-06-13T00:58:40Z,"- [x] Refactor + comments
- [x] PEP8 compliance
- [x] Set up code quality checks eg. codacy
- [x] Add tests",DSuveges,https://github.com/DSuveges/GenomePlotter/issues/7,DSuveges++GenomePlotter.csv
MDU6SXNzdWU5MTk0ODI0MjE=,Review environment,CLOSED,2021-06-12T07:45:50Z,2021-06-13T01:00:03Z,2021-06-13T01:00:03Z,"- [x] Scrutinise imported libraries.
- [x] Properly define environment requirements.
- [x] Update requirements file.",DSuveges,https://github.com/DSuveges/GenomePlotter/issues/8,DSuveges++GenomePlotter.csv
MDU6SXNzdWU5MTk0ODMwOTA=,Align centromere,OPEN,2021-06-12T07:48:25Z,2021-06-12T07:48:25Z,,The centromeric region is not properly aligned. There's still a few pixel width overhang. This needs to resolved.,DSuveges,https://github.com/DSuveges/GenomePlotter/issues/9,DSuveges++GenomePlotter.csv
MDU6SXNzdWU5MTk0ODQyMjc=,New annotation based OpenTargets data,OPEN,2021-06-12T07:53:14Z,2021-06-12T07:56:25Z,,"Create a visualization where genes with known drugs are shown + Disease.

- [ ] Establish sourcing data.
- [ ] Create a visual with genes only to see how busy the plot would be.
- [ ] Adding drugs.
- [ ] Adding disease indications.",DSuveges,https://github.com/DSuveges/GenomePlotter/issues/10,DSuveges++GenomePlotter.csv
MDU6SXNzdWU5MjY1MjAxMzg=,Custom gene plot,OPEN,2021-06-21T19:20:37Z,2021-07-05T14:29:58Z,,"As part of the legend there should be a custom gene plot showing exactly the same features and chunks as in the full chromosome plot.

1. Feed in a gene symbol or Ensembl gene Id.
2. Retrieve genomic coordinates for the gene.
2. Extract genome chunks for the coordinates +/- 10kb (~20chunks each side)
3. Call data integrator.
4. Plot.",DSuveges,https://github.com/DSuveges/GenomePlotter/issues/15,DSuveges++GenomePlotter.csv
MDU6SXNzdWU5MzA4MjYxMzA=,Updating GENCODE parser,CLOSED,2021-06-27T01:23:03Z,2021-07-05T14:28:22Z,2021-07-05T14:28:22Z,"More information is required in the final gencode file:

- [x] Adding direction of gene `+` or `-`
- [x] Adding CDS",DSuveges,https://github.com/DSuveges/GenomePlotter/issues/17,DSuveges++GenomePlotter.csv
MDU6SXNzdWU2NDA4MzYwMw==,document mounting of interproscan databases/extra tools (SignalP/etc),OPEN,2015-03-24T19:43:26Z,2015-03-24T19:43:26Z,,,hexylena,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/1,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWU2NDA4MzYzOQ==,Integrate Apollo,CLOSED,2015-03-24T19:43:44Z,2017-06-29T05:30:52Z,2017-06-29T05:30:52Z,,hexylena,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/2,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUxNjI3NTgzMDY=,Tool:  barrnap,OPEN,2016-06-28T18:48:26Z,2016-06-28T19:18:31Z,,"- [x] conda
- [x] wrapped  (by @slugger70 in toolshed)
- [ ] installed
- [x] outputs GFF
",tseemann,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/3,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUxNjI3NjQzMDQ=,Tool: prodigal,OPEN,2016-06-28T19:17:53Z,2016-06-28T19:18:10Z,,"- [x] conda
- [ ] wrapped 
- [ ] installed
- [ ] Outputs GFF
",tseemann,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/4,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUxNjMwNjk0NjE=,Workflow for trinotate,OPEN,2016-06-30T02:42:13Z,2017-04-09T14:31:12Z,,"https://trinotate.github.io
- [ ] upgrade signalp wrapper to 4.0 hg clone https://toolshed.g2.bx.psu.edu/repos/peterjc/tmhmm_and_signalp
- [ ] Upgrade transdecoder wrapper to 3.0
  https://github.com/galaxyproject/tools-iuc/tree/master/tools/transdecoder
",Eduardo-Alves,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/5,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUxNjY4ODY0MzE=,Toolkit: RAST,CLOSED,2016-07-21T18:27:37Z,2019-03-14T12:43:15Z,2019-03-14T12:43:15Z,"I **may** (or may not) wrap parts/all as part of our viral annotation comparison. (I'm not thrilled at the prospect)

Update: No. Heck no.
",hexylena,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/6,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUyMzQzNDgzODI=,Merge with erasche/docker-galaxy-annotation?,CLOSED,2017-06-07T21:27:46Z,2017-06-12T20:41:03Z,2017-06-12T20:41:03Z,"Is there plan to merge this image with https://github.com/erasche/docker-galaxy-annotation?
It looks like the main difference is the apollo tools which are only in @erasche's repo
I'd like to add the tripal tools as well (if you're ok of course!)",abretaud,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/7,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUyMzk0Mjc4NDI=,Tool: prokka,CLOSED,2017-06-29T10:04:33Z,2017-06-29T14:35:39Z,2017-06-29T14:35:39Z,"There is a galaxy tool (in the toolshed) and conda recipe for prokka.. (Fast prokaryotic automatic annotation)

[x] conda
[x] wrapped
[ ]  installed
[x] Outputs GFF",Slugger70,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/11,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUyMzk3MzI4Mjc=,tool: maker,CLOSED,2017-06-30T09:57:55Z,2017-06-30T12:22:38Z,2017-06-30T12:22:38Z,"http://www.yandell-lab.org/software/maker.html

http://gmod.org/wiki/MAKER

> MAKER is not available for commercial use without a license. Those wishing to license MAKER for commercial use should contact Aaron Duffy at the University of Utah TVC to discuss your needs.

I think we just display this for the tool somewhere so it is up to the user to handle any licensing issues.  

Also, we could have a ""license"" tool piece that will generate a license directly:

http://yandell.topaz.genetics.utah.edu/cgi-bin/maker_license.cgi

Maker-P might be another option:  http://www.yandell-lab.org/software/maker-p.html

The Yandell  Lab may have additional licensing suggestions as well.  

",nathandunn,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/15,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUyMzk3MzQ3NjM=,Tool: AMIGO API for enrichment of gene for an organism,OPEN,2017-06-30T10:05:49Z,2017-07-10T17:48:28Z,,"Want to emulate the behavior of this tool:

<img width=""423"" alt=""screen shot 2017-06-30 at 11 58 28 am"" src=""https://user-images.githubusercontent.com/751274/27730957-7c84681a-5d8b-11e7-91e1-fd3b4c3ab01f.png"">

I think it actually calls this tool (which would also be fine), but I don't see a webservice for this (though maybe just a post is fine).    

You can look at Amigo as well, but I think that is just wrapping panther: 
 http://wiki.geneontology.org/index.php/AmiGO_2_Web_Services#API_Documentation

@kltm is that true (the amigo enrichment is just calling Panther) or are you calling the GOLR backend?   Are you doing a post to pantherdb for this or is there a hidden web-service that you are calling? ",nathandunn,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/16,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUyMzk3MzQ4NDA=,tool:  Add EuGene,OPEN,2017-06-30T10:06:08Z,2017-06-30T10:06:08Z,,http://eugene.toulouse.inra.fr/,nathandunn,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/17,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUyNDAxMzU4NzY=,tool: jq wrapper,OPEN,2017-07-03T10:47:58Z,2017-07-03T10:47:58Z,,"Similar to to the sed wrapper:

https://toolshed.g2.bx.psu.edu/repository?repository_id=9652a50c5a932f3e&changeset_revision=12ac67b5c81d",nathandunn,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/18,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUyNDAxNzUzODQ=,Wrap NCBI tool kit (includes gnomon gene prediction),OPEN,2017-07-03T13:37:29Z,2020-11-05T06:38:45Z,,"NCBI pipeline for eukaryotic annotation uses gnomon:
""Protein, transcript and RNA-Seq read alignments are passed to Gnomon for gene prediction. Gnomon first chains together non-conflicting alignments into putative models. In a second step, Gnomon extends predictions missing a start or a stop codon or internal exon(s) using an HMM-based algorithm. Gnomon additionally creates pure ab initio predictions where open reading frames of sufficient length but with no supporting alignment are detected.""
https://www.ncbi.nlm.nih.gov/genome/annotation_euk/process/

There are no license restrictions and the code is part of ncbi toolkit:
""NCBI C++ Toolkit provides free, portable, public domain libraries with no restrictions use""
https://www.ncbi.nlm.nih.gov/IEB/ToolBox/CPP_DOC/
https://www.ncbi.nlm.nih.gov/viewvc/v1/trunk/c%2B%2B/src/algo/gnomon/",Eduardo-Alves,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/19,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUyNDA1MzgzNzc=,Tool: Gemini Genome Annotation,CLOSED,2017-07-05T05:02:06Z,2018-06-22T14:52:36Z,2018-06-22T14:52:36Z,"Someone had brought this up for doing genome annotation:

https://gemini.readthedocs.io/en/latest/",nathandunn,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/20,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUyNDIyOTQ3MTU=,Tool: add Maker annotation pipeline,CLOSED,2017-07-12T08:10:51Z,2017-12-16T08:38:05Z,2017-12-15T16:03:49Z,"Maker homepage: http://www.yandell-lab.org/software/maker.html
There is something strange about the license: 

>  MAKER is available for academic use under either the Artistic License 2.0 developed by the Perl Foundation or the GNU General Public License developed by the Free Software Foundation.
> 
> MAKER is not available for commercial use without a license. Those wishing to license MAKER for commercial use should contact Aaron Duffy at the University of Utah TVC to discuss your needs. 

But, discussed with Carson Holt who is ok for packaging it.

There is already a brew recipe there: https://github.com/Homebrew/homebrew-science/blob/master/maker.rb

And the GPL-licensed code can be downloaded directly there: http://yandell.topaz.genetics.utah.edu/maker_downloads/static/maker-2.31.9.tgz

I intend to work on a conda recipe in the coming weeks",abretaud,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/21,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUzMzQ2MTExMTc=,Tool: braker,OPEN,2018-06-21T18:40:52Z,2018-06-21T18:40:52Z,,"While I think about it, it would be nice to have a galaxy tool for braker.
There's already a conda package in https://bioconda.github.io/recipes/braker/README.html but it's not the latest version (http://exon.gatech.edu/braker1.html).
There might be some licensing issue with the GeneMark-ET dependency",abretaud,https://github.com/galaxy-genome-annotation/docker-galaxy-genome-annotation/issues/29,galaxy-genome-annotation++docker-galaxy-genome-annotation.csv
MDU6SXNzdWUxODk4MzEwOTA=,Add cancer hotspot annotation to annotator for MAF annotation,OPEN,2016-11-16T20:17:50Z,2017-01-12T20:39:17Z,,Add a new column call `is-cancer-hotspot` with value of `yes` or `no`,jjgao,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/5,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWUyODE4MDY2MTM=,Add annotation for variants without hgvsc/hgvsp,OPEN,2017-12-13T16:13:11Z,2017-12-13T19:09:55Z,,"Reported by @jjgao 

Ignoring record with HGVSp null classification 5Flank: (sampleId,chr,start,end,ref,alt,url)= (DS-uttcc-073-P,5,1295250,1295250,G,,http://annotation.genomenexus.org/hgvs/5:g.1295250G>A?isoformOverrideSource=mskcc&fields=hotspots).

https://github.com/genome-nexus/genome-nexus-annotation-pipeline/blob/master/annotationPipeline/src/main/java/org/cbioportal/annotation/pipeline/MutationRecordReader.java#L158-L163. If u look at the response of genome nexus, there are no hgvsc and hgvsp changes. We should still annotate it as a 5'Flank variant, just leave those fields empty.",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/51,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWUyODIyMTk3ODU=,Move annotation logic to the web server,OPEN,2017-12-14T19:53:52Z,2017-12-14T19:53:52Z,,"- The logic of amino acid changes for splice sites (the `X_splice`) should be in `genome-nexus/genome-nexus`
- The logic of Hgvsp_Short should be in `genome-nexus/genome-nexus`
- logic of converting ref/alt/pos/chrom to hgvs should be a different endpoint in `genome-nexus/genome-nexus` (potentially call annotation endpoint)
- .. see if there is more logic that can be moved
",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/53,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWUyODM1ODM4Mzg=,Make maf test cover more chromosomes/mutation types,OPEN,2017-12-20T14:39:49Z,2017-12-20T19:22:51Z,,"Instead of just taking first 100 of impact maf, span more different types",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/54,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWUzMzI1ODIzNTM=,application.properties.EXAMPLE base url,CLOSED,2018-06-14T22:12:09Z,2020-06-26T14:54:22Z,2020-06-26T14:54:22Z,"Currently, in [application.properties.EXAMPLE](https://github.com/genome-nexus/genome-nexus-annotation-pipeline/blob/master/annotationPipeline/src/main/resources/application.properties.EXAMPLE#L2), genomenexus.base=<HOST> is not specified. Maybe we can just add the public genome nexus address here?",jjgao,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/66,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWUzMzI1ODI2ODk=,no error messages in command line,OPEN,2018-06-14T22:13:35Z,2018-06-14T22:13:35Z,,there is currently no error message throwing out when annotation failed (e.g. BASE url is wrong),jjgao,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/67,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWUzMzI2MDE3MDc=,annotate complete MAF,OPEN,2018-06-14T23:48:50Z,2018-06-14T23:48:50Z,,"I think we should annotate a more complete MAF, maybe based on [this spec](https://docs.gdc.cancer.gov/Data/File_Formats/MAF_Format/)?

Hugo_Symbol and Entrez_Gene_ID should also be populated.",jjgao,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/68,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWUzMzI2Mjc2NzI=,turn on replace-symbol-entrez by default,CLOSED,2018-06-15T02:37:06Z,2023-09-19T15:44:26Z,2023-09-19T15:44:26Z,"Should we consider turning on `replace-symbol-entrez` by default? The symbols should be synchronized with the annotated results.

https://github.com/genome-nexus/genome-nexus-annotation-pipeline/blob/master/annotationPipeline/src/main/java/org/cbioportal/annotation/AnnotationPipeline.java#L59

@n1zea144 @inodb @onursumer ",jjgao,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/69,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU0MDY5OTY0NTY=,unskip MT mutations,CLOSED,2019-02-05T22:08:55Z,2019-02-08T19:46:09Z,2019-02-08T19:46:09Z,"Based on discussion on Slack, we are skipping MT mutations in annotator. Let's unskip that. ",jjgao,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/80,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU0MTUzMzM3NDM=,Make the jar file accept proper command line parameters,OPEN,2019-02-27T21:24:50Z,2019-02-27T21:24:50Z,,"Instead of having to use `-D` system parameters it would be nice to use command line parameters. We can follow webapp-runners logic:

https://github.com/jsimone/webapp-runner/blob/master/main/src/main/java/webapp/runner/launch/CommandLineParams.java",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/83,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU0Mjg5MDM0MDc=,turn on line number error by default,CLOSED,2019-04-03T18:07:55Z,2019-04-05T20:45:56Z,2019-04-05T20:45:56Z,now need to use `--verbose`,inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/89,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU0MzI2NzYzMjQ=,build releases and make them available on github,OPEN,2019-04-12T17:49:24Z,2020-05-15T22:40:40Z,,,jjgao,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/91,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU0NDQ1Nzg3Nzk=,check protein length of all canonical transcript (make sure they have it),OPEN,2019-05-15T18:20:08Z,2019-05-15T18:20:08Z,,,inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/92,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU0NDgzNjE2NTI=,Better representing of Tumor_Seq_Allele,OPEN,2019-05-24T21:36:23Z,2019-05-30T18:57:20Z,,"For example,

| | Chromosome | Start_Position | End_Position | Reference_Allele | Tumor_Seq_Allele1 | Tumor_Seq_Allele2 | NCBI_Build |
---|---|---|---|---|---|---|---
**input**| 11 | 108151707 | 108151707 | T | TA | | 37 |
**output**| 11 | 108151707 | 108151708 | - | TA | A | 37 |

The `Tumor_Seq_Allele2`  can also represent the zygosity, so maybe we could consider a better way to show those fields? 
",leexgh,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/93,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU0NjE3NDExNTU=,Automatic Fill for `introgenic_variants` and `IGR`,OPEN,2019-06-27T20:46:01Z,2019-06-28T19:30:38Z,,"Right now the GN leaves `consequence` and `variants classification`columns empty, for rows annotated as `introgenic_variants`. 

As a result:
1. the circle CI validation wouldn't pass. 
2. Sometimes when the MAF is really large and there are thousands of rows with this case (for example prostate_dkfz_2018), it is becoming really time consuming to manually check each unannotated rows and fill them in. 

So here just requesting the GN to fill in rows with consequence as `introgenic_variants` (and variants classficiation as `IGR`) automatically.  ",yichaoS,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/95,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU1MzcxNzMyNzM=,VCF - Genome Nexus annotation script,CLOSED,2019-12-12T19:36:16Z,2020-01-29T17:47:50Z,2020-01-29T17:47:50Z,"Background -

AACR Project GENIE collects VCFs of various flavors from consortium members.  Currently they use vcf2maf to annotate these files.  We desire to move them to the Genome Nexus platform. There we would like to create a script for annotating a set of VCF files using our GN annotation pipeline.  Rough outline:

1. Point tool to folder which contains VCFs of various shapes/size.
2. Run [vcf2vcf](https://github.com/mskcc/vcf2maf/) over files to normalize them. 
3. Run normalized vcfs through @ao508 vcf2maf converter.
3. Annoate mafs using genome nexus annotation client.
4. Combine mafs into single file for import.

Note, for 2:
vcf2vcf is required because there is a need to normalize allele depths which is handled by [FixAllelDepths](https://github.com/mskcc/vcf2maf/blob/v1.6.17/vcf2maf.pl#L986).  Ensure the following option is set (should be set by default)

--retain-format GT,AD,DP

These three fields contain the values needed to extract t_depth, t_ref_count, t_alt_count, n_depth, n_ref_count, n_alt_count.
",n1zea144,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/111,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU1MzkyNzgzMTU=,In_Frame mutation converted to frameshift,CLOSED,2019-12-17T19:55:58Z,2019-12-17T20:11:40Z,2019-12-17T20:11:40Z,"e.g. this:

```
7 55242466 55242485 AATTAAGAGAAGCAACATCT AGCAA
```
becomes
```
7 55242468 55242482 ATTAAGAGAAGCAAC GCAA
```",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/112,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU1Mzk4MjYzMDE=,Add SORT Functionality before Sending POSTS to Server,CLOSED,2019-12-18T17:45:27Z,2020-02-26T20:34:30Z,2020-02-26T20:34:30Z,"Having sorted variants speeds up VEP performance. Since the pipeline batches out requests, performance would be better if all variants are sorted before batching. This way each batch will be localized to shred regions. 

Unit tests included.",averyniceday,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/114,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU1NDQ2NjIyNzQ=,annotation pipeline (and CVR fetcher) notices failed records in response,CLOSED,2020-01-02T17:02:52Z,2020-02-27T03:01:17Z,2020-02-27T03:01:17Z,"After the response comes back from genome nexus, some records will have a failure status. These should be detected and logged / stripped out or otherwise treated properly.",sheridancbio,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/115,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU1NzE1MjA5ODc=,Migrate GN Annotation Pipeline to Work with Genome Nexus Server Master,CLOSED,2020-02-26T16:49:58Z,2020-03-11T21:10:28Z,2020-03-11T21:10:28Z,"- [x] Document and resolve differences in the model (verify that changes are okay, what data is lost or gained)
- [x] Get GN Annotation Pipeline to build (including unit tests) when using a genome nexus java api hash that is based on master (including newest changes with successfully_annotated flag)
- [x] document migration steps for future reference (as a readme checked in to docs)
- [x] regression tests show that the revised code with a master branch deployment of genome nexus produces comparable results to the current production pipeline.",averyniceday,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/120,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU1ODYzMjk1Mjc=,GENIE Genome Nexus Documentation,CLOSED,2020-03-23T16:13:35Z,2021-06-09T16:30:40Z,2021-06-09T16:30:40Z,"documentation for Genome Nexus

- [x] including VEP setup (S3 bucket, file renaming inside the kubectl description)
- [x] including helm deployment for NFS/mongo
- [x] setting up PV, PVCs
- [x] mongo backups - loading, etc.
- [x] migrating java api? ",averyniceday,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/122,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU2NTQ5MzE3ODM=,Msk-mind cohort upload,CLOSED,2020-07-10T17:36:15Z,2020-07-10T17:37:45Z,2020-07-10T17:37:45Z,,ritikakundra,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/139,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU2OTg1NTk4Nzk=,add Ref_Tri and Var_Tri columns,CLOSED,2020-09-10T22:21:54Z,2021-02-11T14:51:15Z,2021-02-11T14:51:15Z,"Can we add Ref_Tri and Var_Tri columns into the MAF?

e.g. for [this variant](https://www.genomenexus.org/annotation/17:g.37880220T%3EC?fields=hotspots%2Cmutation_assessor%2Cmy_variant_info%2Cptms%2Cannotation_summary,nucleotide_context), Ref_Tri is 'TTG' and Var_Tri is 'TCG'.

![image](https://user-images.githubusercontent.com/840895/92815590-62685180-f392-11ea-9e7c-69e2ebe34b93.png)
",jjgao,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/146,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU3MDIyOTI4MzE=,options to add functional impact columns into MAF,CLOSED,2020-09-15T21:40:24Z,2020-10-07T18:37:53Z,2020-10-07T18:37:52Z,"
- MutationAssessor
- SIFT
- PolyPhen-2",jjgao,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/147,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU3NTk1NDUzMDM=,"Store immutable version of (chrom,pos,ref,alt1,alt2) in separate columns with prefix",OPEN,2020-12-08T15:34:23Z,2021-06-14T18:12:54Z,,"We have had a lot of issues trying to reproduce the original chrom/pos/ref/alt1/alt2 after normalizing it in the genome nexus annotation pipeline. Basically imagine the use case of running genome-nexus-annotation-pipeline twice in a row on the same MAF file. When there is an error in the normalization of chrom/pos/ref/alt1/alt2, we are not able to reproduce the original chrom/pos/ref/alt1/alt2. Let's store a copy as a separate column that's immutable to get around this issue

We could have the following logic:

If the columns prefixed with  `genome_nexus_ignore_original` are missing (`genome_nexus_ignore_original_Chromosome	genome_nexus_ignore_original_Start_Position	genome_nexus_ignore_original_End_Position	genome_nexus_ignore_original_Reference_Allele	genome_nexus_ignore_original_Tumor_Seq_Allele1	genome_nexus_ignore_original_Tumor_Seq_Allele2`) then create these columns and copy over the values from the inputted MAF `Chromosome	Start_Position	End_Position	Reference_Allele	Tumor_Seq_Allele1`

If they are not missing then use the columns prefixed with `genome_nexus_ignore_original` to annotate them instead of the inputted  `Chromosome	Start_Position	End_Position	Reference_Allele	Tumor_Seq_Allele1	Tumor_Seq_Allele2`. We do this because we might have normalized the non-prefixed ones incorrectly before.

Bonus points: note that if we really want to manually change some `genome_nexus_ignore_original` ones, we can add another column prefix like `genome_nexus_ignore_original_manual_override`. That one would be preferred over `genome_nexus_ignore_original`. That way we can continue to keep the immutable column truly immutable and also see which records we manually override.",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/157,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU4MTExMDU2MTE=,Figure out a way to handle default properties,OPEN,2021-02-18T13:36:00Z,2021-02-18T13:41:20Z,,"Currently we are putting all configuration in `application.properties.EXAMPLE`. There are some issues with this:

1. It is unclear which of the configuration in EXAMPLE is for a user to change and which isn't (e.g. spring configuration that shouldn't be changed is in the EXAMPLE file)
2. When a new default is introduced that requires a value, it will currently break the pipeline for anybody that's upgrading which already has a properties file
3. Using `application.properties` for a command line client is in general questionable imo, everything should be a command line parameter. If we really want to use a configuration file it might be better to pass it as a command line argument and handle missing values etc elegantly with clear user output of what values are missing. Using spring properties files directly can result in very hard to understand errors for users unfamiliar with Java (there might be a way to override the way spring throws missing config errors, that could be another approach)",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/168,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU4MTIyNDgyNzk=,Migrate Spring version to 2.3.3.RELEASE ,CLOSED,2021-02-19T18:38:28Z,2021-02-22T16:15:08Z,2021-02-22T16:15:08Z,"This is part of an effort to synchronize the spring boot version we have across multiple projects. 

Current pull request: https://github.com/genome-nexus/genome-nexus-annotation-pipeline/pull/169

The integration test still needs fixing. ",ao508,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/170,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU4MTM2NDE1NjM=,Fix broken integration test environment due to Spring boot migration to 2.3.3.RELEASE (updated from 1.2.7.RELEASE) (PR #169),CLOSED,2021-02-22T16:10:47Z,2021-08-06T14:12:35Z,2021-08-06T14:12:35Z,"https://github.com/genome-nexus/genome-nexus-annotation-pipeline/pull/169


this might be helpful https://www.baeldung.com/spring-boot-h2-database",ao508,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/171,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU4MjEyMDAzOTM=,Still annotating when mutation fails annotation,OPEN,2021-03-03T15:11:37Z,2021-03-16T22:08:43Z,,"It seems like we still try to annotate mutations even when the annotation failed, see: 

https://github.com/genome-nexus/annotation-tools/issues/31

For instance for this case:

```
17      7578212 CG      CA
```

The annotation pipeline might use this endpoint:

https://genie.genomenexus.org/annotation/17:g.7578213G%3EA?fields=annotation_summary&isoformOverrideSource=uniprot

and throws a warning:

```
07:14:36 [main] WARN  org.cbioportal.annotator.internal.GenomeNexusImpl - Annotated record is invalid for variant 17:7578213-7578213:1/A
```

Yet the `ANNOTATION_STATUS == SUCCESS`. This is slightly peculiar, it should probably indicate a fail if the annotated record is invalid.

However the real issue is the following: 7578213 is not G at that position. But using region format we don't supply the inputted reference allele, so technically we would still annotate it and VEP would not fail. One would have to compare the resulting referenceAllele against the inputted reference allele and throw a failure if they don't match.",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/172,genome-nexus++genome-nexus-annotation-pipeline.csv
MDU6SXNzdWU4Mzc5MzcxNTc=,Handle incorrect MAF format for deletions,CLOSED,2021-03-22T17:12:21Z,2021-03-26T18:22:37Z,2021-03-26T18:22:37Z,"This MAF format is incorrect:

```
ADGRA2  8       37699139        37699138        GENIE-SAGE-1-1  DEL     CCGCCCCGGGCCCTGCCCGCCGCC        -
```

Since it should be:

```
GPR124  8       37699138        37699161        GENIE-SAGE-1-1  DEL     CCGCCCCGGGCCCTGCCCGCCGCC        -
```

We could fix the MAF format on our end (since we know the length of the deletion and could for instance assume the start_position is correct). This might be better done at the server layer than in the command line annotator",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/174,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85LgZYP,Many output errors and warnings when running the minimal example,OPEN,2022-06-09T23:58:23Z,2022-06-14T17:31:42Z,,"Seems like things get annotated correctly but tons of errors about reading fields:

```
Something went wrong reading field Entrez_Gene_Id
Something went wrong reading field dbSNP_RS
Something went wrong reading field Match_Norm_Seq_Allele1
Something went wrong reading field Validation_Method
Something went wrong reading field Match_Norm_Seq_Allele2
Something went wrong reading field n_ref_count
Something went wrong reading field t_alt_count
Something went wrong reading field BAM_File
Something went wrong reading field Variant_Classification
Something went wrong reading field dbSNP_Val_Status
Something went wrong reading field Mutation_Status
Something went wrong reading field Matched_Norm_Sample_Barcode
Something went wrong reading field Validation_Status
Something went wrong reading field Variant_Type
Something went wrong reading field Strand
Something went wrong reading field Hugo_Symbol
Something went wrong reading field Sequencer
Something went wrong reading field n_alt_count
Something went wrong reading field Center
Something went wrong reading field Match_Norm_Validation_Allele2
Something went wrong reading field Tumor_Sample_Barcode
Something went wrong reading field Verification_Status
Something went wrong reading field t_ref_count
Something went wrong reading field Tumor_Seq_Allele2
Something went wrong reading field Match_Norm_Validation_Allele1
Something went wrong reading field Score
Something went wrong reading field Sequencing_Phase
Something went wrong reading field Tumor_Validation_Allele2
Something went wrong reading field Tumor_Validation_Allele1
Something went wrong reading field NCBI_Build
Something went wrong reading field Sequence_Source
Something went wrong reading field Entrez_Gene_Id
Something went wrong reading field dbSNP_RS
Something went wrong reading field Match_Norm_Seq_Allele1
Something went wrong reading field Validation_Method
Something went wrong reading field Match_Norm_Seq_Allele2
Something went wrong reading field n_ref_count
Something went wrong reading field t_alt_count
Something went wrong reading field BAM_File
Something went wrong reading field Variant_Classification
Something went wrong reading field dbSNP_Val_Status
Something went wrong reading field Mutation_Status
Something went wrong reading field Matched_Norm_Sample_Barcode
Something went wrong reading field Validation_Status
Something went wrong reading field Variant_Type
Something went wrong reading field Strand
Something went wrong reading field Hugo_Symbol
Something went wrong reading field Sequencer
Something went wrong reading field n_alt_count
Something went wrong reading field Center
Something went wrong reading field Match_Norm_Validation_Allele2
Something went wrong reading field Tumor_Sample_Barcode
Something went wrong reading field Verification_Status
Something went wrong reading field t_ref_count
Something went wrong reading field Tumor_Seq_Allele2
Something went wrong reading field Match_Norm_Validation_Allele1
Something went wrong reading field Score
Something went wrong reading field Sequencing_Phase
Something went wrong reading field Tumor_Validation_Allele2
Something went wrong reading field Tumor_Validation_Allele1
Something went wrong reading field NCBI_Build
Something went wrong reading field Sequence_Source
Something went wrong reading field Entrez_Gene_Id
Something went wrong reading field dbSNP_RS
Something went wrong reading field Match_Norm_Seq_Allele1
Something went wrong reading field Validation_Method
Something went wrong reading field Match_Norm_Seq_Allele2
Something went wrong reading field n_ref_count
Something went wrong reading field t_alt_count
Something went wrong reading field BAM_File
Something went wrong reading field Variant_Classification
Something went wrong reading field dbSNP_Val_Status
Something went wrong reading field Mutation_Status
Something went wrong reading field Matched_Norm_Sample_Barcode
Something went wrong reading field Validation_Status
Something went wrong reading field Variant_Type
Something went wrong reading field Strand
Something went wrong reading field Hugo_Symbol
Something went wrong reading field Sequencer
Something went wrong reading field n_alt_count
Something went wrong reading field Center
Something went wrong reading field Match_Norm_Validation_Allele2
Something went wrong reading field Tumor_Sample_Barcode
Something went wrong reading field Verification_Status
Something went wrong reading field t_ref_count
Something went wrong reading field Tumor_Seq_Allele2
Something went wrong reading field Match_Norm_Validation_Allele1
Something went wrong reading field Score
Something went wrong reading field Sequencing_Phase
Something went wrong reading field Tumor_Validation_Allele2
Something went wrong reading field Tumor_Validation_Allele1
Something went wrong reading field NCBI_Build
Something went wrong reading field Sequence_Source

Annotation Summary:
	Records with ambiguous SNP and INDEL allele changes:  0
	All variants annotated successfully without failures!
```",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/193,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85Lw-Sh,Custom output format files,OPEN,2022-06-14T17:31:10Z,2022-07-30T15:38:34Z,,"Allow changing the column names etc using a supplied output format file

Some of the output formats could be:

- [ ] `tcga`: https://docs.cbioportal.org/file-formats/#extended-maf-format. List all 37 first and anything extra goes in the back alphabetically
- [ ] `minimal`: whatever was inputted and newly annotated columns by genome nexus
- [ ] `gdc`: ??? Not sure what this should be yet. (They might have a few additional columns beyond `tcga`, 126 columns)
- [ ] any custom ordering of columns (already implemented)",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/194,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85OEgwi,Use subcommands for command line interface,OPEN,2022-07-19T16:57:31Z,2022-07-19T17:21:51Z,,"It would be nice if we could use a more subcommand style interface as done here: https://github.com/genome-nexus/genome-nexus-cli

So e.g. to convert:

```
genome-nexus-annotation-pipeline convert variants.vcf > variants.maf
```
merge multiple MAFs:
```
genome-nexus-annotation-pipeline merge folder_with_mafs > output.maf
```

annotate a MAF:
```
genome-nexus-annotation-pipeline annotate maf test/data/minimal_example.in.txt [...more arguments] > test/data/minimal_example.out.txt
```

annotate a variant:
```
genome-nexus-annotation-pipeline annotate variant 17:g.41242962_41242963insGA > variant.json
```

show full help of all commands:

```
$ genome-nexus-annotation-pipeline --help
    convert
    merge
    annotate
```

The current pipeline arguments are idiosyncratic to our internal annotation processes and not super user friendly for external users",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/201,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85OEjWX,vcf2maf test implementation incomplete,CLOSED,2022-07-19T17:08:21Z,2022-08-08T21:33:28Z,2022-08-08T21:33:28Z,vcf2maf test implementation incomplete - needs to be completed,jagnathan,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/202,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85OEj-S,MAF file validation,CLOSED,2022-07-19T17:10:53Z,2022-07-19T17:36:10Z,2022-07-19T17:36:10Z,"MAF file validation -

Details

- [x] Checks hard requirements of the MAF file. Search for these column names: Chromosome, Start_Position, End_Position, Reference_Allele. 
- [x] Check if either Tumor_Seq_Allele1 or Tumor_Seq_Allele2 are present",jagnathan,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/203,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85Ol1x9,genome nexus tests to support both hg19 and hg38 ,OPEN,2022-07-26T17:18:38Z,2024-01-28T14:12:24Z,,genome nexus tests to support both hg19 and hg38 versions,jagnathan,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/205,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85OmMck,Account for Genome Nexus Timeout issue - check if all the variants in the MAF are annotated,OPEN,2022-07-26T18:55:24Z,2022-07-26T18:55:24Z,,"**Issue:**
Sometimes when annotating a huge MAF, some variants do not get a protein change or the annotation times out. Re-running those failed records produces the amino acid change.

**Solution:**
Would be nice to add a flag to the `annotate` subcommand or let the default behaviour be such that if all the records are not successfully annotated on the first attempt, then the script will continue running the annotator on the remaining unannotated records until no new annotated records are produced in further attempts.

**Logic:**
- Let the annotation run normally the in the first attempt.
- Subset the variants which failed annotation i.e, the `Variant_Classification` is not in `[""Silent"", ""Intron"", ""3'UTR"", ""5'UTR"", ""3'Flank"", ""5'Flank"", ""IGR""]` and the `HGVSp_Short` is `empty` or `Annotation_Status` is `FAILED`. Basically, split the MAF to annotated and unannotated parts.
- Re-run the annotation of the unannotated MAF and merge the annotated records to the annotated MAF.
- Repeat until all the variants are annotated or no new annotated records are produced in the further attempts.

Refer to the python implementation here for more details - https://github.com/cBioPortal/datahub-study-curation-tools/tree/master/GN-annotation-wrapper",rmadupuri,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/206,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85PfPD-,Minimal Output format is similar to TCGA,OPEN,2022-08-09T17:46:34Z,2022-08-09T17:46:40Z,,"As reported by @rmadupuri - the minimal and tcga formats are very similar 

Let's find out:

1. What columns are actually annotated by Genome Nexus
2. What would be the real minimal set of output columns",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/210,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85P6OtZ,documentation for MAF formats,OPEN,2022-08-16T17:26:35Z,2022-08-16T17:39:52Z,,"documentation for MAF formats - TCGA Extended and Minimal.

Simple documentation describing the columns for the MAF formats that are used.

Add link to cbioportal docs page to ensure the uptodate format is maintained.

Update the main docs page and add additional pages based on length.",jagnathan,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/215,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85P6XWS,Annotate big mutation file w/o failure,OPEN,2022-08-16T18:03:00Z,2022-09-09T13:37:02Z,,"We can use this file to test:

https://github.com/cBioPortal/datahub/blob/master/public/difg_glass_2019/data_mutations.txt",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/216,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85QJE2p,Add more versions in MAF header,OPEN,2022-08-19T14:58:36Z,2022-11-01T18:44:31Z,,"Now that we have a new endpoint with version of VEP etc, it would be nice to add this information in the MAF header. That is include versions for:

- Genome Nexus Server
- Genome Nexus Seed Database
- Genome Nexus Annotation Pipeline
- VEP (Ensembl version + reference version)",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/218,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85QwMq-,Annotation pipeline issues,CLOSED,2022-08-29T20:06:06Z,2022-09-06T15:56:44Z,2022-09-06T15:56:18Z,"1. The annotation build fails
![image](https://user-images.githubusercontent.com/34350829/187287465-cfcd593c-868f-4244-b0ce-0b5228b509e3.png)


2. The **logging** seems to be not writing to the file - https://github.com/genome-nexus/genome-nexus-annotation-pipeline/blob/7c93747468098bdeaa0518f42b3c8ca6c831f96c/annotationPipeline/src/main/resources/log4j.properties.EXAMPLE#L19
Something to do with - https://github.com/genome-nexus/genome-nexus-annotation-pipeline/pull/199?

3. If the annotation fails - the script just outputs the banner to stdout. Would be nice to throw a message of why it failed.
![Screen Shot 2022-08-29 at 2 42 54 PM](https://user-images.githubusercontent.com/34350829/187287853-be86ff83-8969-4d4d-a117-90f09d6989b4.png)
Ex: If a required column is missing per - https://github.com/genome-nexus/genome-nexus-annotation-pipeline/pull/196, the script doesn't show why the annotation failed in stdout (missing field here)

4. Custom output format **extended** didnt produce any annotation (the annotation process didnt begin)
![Screen Shot 2022-08-29 at 2 46 10 PM](https://user-images.githubusercontent.com/34350829/187287965-c78389ab-ab1c-4313-be90-02f2a946334b.png)
If I try to use **tcga** as the argument which was renamed to **extended**, should it throw a warning that tcga is not a recognized format? Currently shows the below,
![Screen Shot 2022-08-29 at 2 47 43 PM](https://user-images.githubusercontent.com/34350829/187288047-6fa91883-95b9-4080-ae3b-b7cce44337cf.png)
**minimal** output format works.

5. The **custom** output format produced an error,
![Screen Shot 2022-08-29 at 3 18 43 PM](https://user-images.githubusercontent.com/34350829/187288160-3adabd4c-c1ec-4d9e-be7d-91ff2f3abc7b.png)

6. **Merge** subcommand - when merging two files with same variants but one file having more columns than the other, the file with more information should be outputted? Currently the variants from the first file are shown in the output in the case of duplicate variants in two files.
",rmadupuri,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/223,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85RA865,Fix version in MAF header,CLOSED,2022-09-01T17:50:05Z,2022-11-01T18:44:42Z,2022-11-01T18:44:42Z,"We are outputting the version in the output. Currently however it just shows unknown version:

`#genome_nexus_version: 0-unknown-version-SNAPSHOT`

Ideally we can give (1) version of the genome-nexus-annotation-pipeline and (2) version of the genome-nexus server.

For (2) we can use https://www.genomenexus.org/actuator/info instead of https://www.genomenexus.org/version",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/225,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85UIYDh,Allow not normalizing of bases in the MAF with command line option,CLOSED,2022-10-17T12:23:07Z,2022-12-12T20:41:25Z,2022-12-12T20:41:25Z,"This is related to this issue:

https://github.com/mskcc/vcf2maf/issues/279

Basically occasionally you might want to keep the ref/alt allele bases because it gives you more information about the surrounding bases. There are three options for the base normalization:

1. Strip off only the very first matching base from ref+alt (first)
2. Strip off all matching starting bases from ref+alt (all) -- this is the current behavior
3. Don't do any harmonization (do store all the appropriate fields as if it were normalized) (none)

This could be something that is relevant for both annotation-tools as well as genome-nexus-annotation-pipleine. The former does the vcf2maf conversion, but the latter also does harmonization of bases as well (the API returns harmonized version of chrom/pos/ref/alt). We should prolly add options to both those tools around this, so the annotation pipeline can have some option like this:

```
--strip-matching-bases {first,all,none}
```
And the annotation-tools could have something like:
```
--strip-matching-bases {first,all}
```
For annotation-tools it prolly doesn't make sense to have the ""none"" option since you are starting from the VCF file which by definition lists the additional base in ref and alt for indels

Note that the issue with using ""first' is that if you run the MAF thru multiple times it will change every time until all bases are stripped off. This is not a big deal if you start from the source VCF, which is how it works for most internal pipelines at MSK, but it can be an issue when you use MAF as the source of truth file. Some way to capture immutable genomic locations was [implemented previously](https://github.com/genome-nexus/genome-nexus-annotation-pipeline/pull/173) but never merged so might be good to revisit that. Another option is to add some feature like that in the conversion script from VCF to MAF i.e. add the original VCF fields in the resulting MAF to make sure you don't lose the source of truth. Then whenever you re-annotate you use the source of truth fields rather than the potentially harmonized fields

Note: need to figure out what to do with matching ending bases",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/232,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85Z9tWJ,Improve dockerhub documentation,OPEN,2022-12-23T13:26:38Z,2022-12-23T13:26:38Z,,"The current dockerhub page (https://hub.docker.com/r/genomenexus/gn-annotation-pipeline) has no information about this project. It would be nice to link back to the github location.



![image](https://user-images.githubusercontent.com/2900303/209343581-cfb1df45-986f-47f8-85e5-52df5e065962.png)
",pieterlukasse,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/237,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85dFrcn,"Latest build of genomenexus/gn-annotation-pipeline:master is non-functional, even when using the toy example on https://docs.genomenexus.org/annotate-file",CLOSED,2023-01-30T05:20:15Z,2023-04-17T04:39:43Z,2023-04-17T04:39:43Z,"This tool used to work great, but the most recent build appears to be broken, no matter the input.  

Whenever I try to use it, I get a SLF4J error. Because I kept getting these errors with my own MAFs, I decided to try using the toy example from https://docs.genomenexus.org/annotate-file, however, I get an error with that as well:

`$ (echo -e ""Chromosome\tStart_Position\tEnd_Position\tReference_Allele\tTumor_Seq_Allele1""; echo -e ""7\t55220240\t55220240\tG\tT"") > input.txt`
`$ docker run -v ${PWD}:/wd genomenexus/gn-annotation-pipeline:master --filename /wd/input.txt  --output-filename /wd/output.txt --isoform-override uniprot`
```SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/genome-nexus-annotation-pipeline/annotationPipeline/target/annotationPipeline.jar!/BOOT-INF/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/genome-nexus-annotation-pipeline/annotationPipeline/target/annotationPipeline.jar!/BOOT-INF/lib/logback-classic-1.2.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
log4j:WARN No appenders could be found for logger (org.cbioportal.annotation.AnnotationPipeline).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
 RUNTIME: 0 secs.
```",pwaltman,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/238,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85hnU-P,test failures building the project annotationPipeline,OPEN,2023-03-23T14:51:31Z,2024-06-14T15:02:45Z,,"Hi, 
I'm trying to build the project annotationPipeline but got an error:

Test set: org.cbioportal.annotation.SpringBatchIntegrationTest
-------------------------------------------------------------------------------
Tests run: 18, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 22.057 s <<< FAILURE! - in org.cbioportal.annotation.SpringBatchIntegrationTest
check_if_maf_file_still_the_same_when_annotating_with_mskcc_transcripts  Time elapsed: 0.546 s  <<< FAILURE!
org.junit.ComparisonFailure: Line number 15 does not match. expected:<...       202     244                     ENST00000[407796.2:c.49G>A      p.Glu17Lys      p.E17K  ENST00000407796 NM_001014431.1  17      Gag/Aag 3/14]   SUCCESS> but was:<...   202     244                     ENST00000[349310.3:c.49G>A      p.Glu17Lys      p.E17K  ENST00000349310 NM_001014432.1  17      Gag/Aag 4/15]   SUCCESS>
        at org.cbioportal.annotation.SpringBatchIntegrationTest.testWith(SpringBatchIntegrationTest.java:405)
        at org.cbioportal.annotation.SpringBatchIntegrationTest.check_if_maf_file_still_the_same_when_annotating_with_mskcc_transcripts(SpringBatchIntegrationTest.java:92)


I'll appreciate any help. 
Thanks, 

Luisa. 

",ldelgado-serrano,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/243,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85k4nE1,Turn on logging for genome-nexus runs,CLOSED,2023-05-02T14:43:28Z,2023-06-09T06:18:57Z,2023-06-09T06:18:57Z,"Hello,

I would like to change the logging threshold to debug so I can figure out why my annotations are failing. I see the following console output using a minimal example test run:

```sh
docker run -v ${PWD}:/wd genomenexus/gn-annotation-pipeline:master --filename /wd/scratch/minimal_example.in.txt --output-filename /wd/scratch/minimal_example.out.txt
```

```sh
WARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested
log4j:WARN No appenders could be found for logger (org.springframework.core.env.StandardEnvironment).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
  _____                                               _   _                             
 / ____|                                             | \ | |                            
| |  __    ___   _ __     ___    _ __ ___     ___    |  \| |   ___  __  __  _   _   ___ 
| | |_ |  / _ \ | '_ \   / _ \  | '_ ` _ \   / _ \   | . ` |  / _ \ \ \/ / | | | | / __|
| |__| | |  __/ | | | | | (_) | | | | | | | |  __/   | |\  | |  __/  >  <  | |_| | \__ \
 \_____|  \___| |_| |_|  \___/  |_| |_| |_|  \___|   |_| \_|  \___| /_/\_\  \__,_| |___/


Annotation Summary:
        Records with ambiguous SNP and INDEL allele changes:  0

        Failed annotations summary:  3 total failed annotations
                Records with HGVSp null variant classification:  0
                Records that failed due to other unknown reason: 3

        Average Response Time:  1.000 sec.
          Total Response Time:  1 sec.

 RUNTIME: 46 secs.
 ```

The line `log4j:WARN No appenders could be found for logger ` seems to indicate the log4j.properties file can not be found and the application instead performs no explicit configuration (https://logging.apache.org/log4j/1.2/faq.html#noconfig).

I tried making own image, disabling the entrypoint and running the jar in an interactive shell with:

```sh
cd /genome-nexus-annotation-pipeline
$JAVA_HOME/bin/java -cp ""/genome-nexus-annotation-pipeline/annotationPipeline/src/main/resources"" -Dlog4j.configuration=log4j.properties -jar annotationPipeline/target/annotationPipeline.jar -f /mnt/docker-sandbox-data/scratch/minimal_example.in.txt -o /mnt/docker-sandbox-data/annotate_output/scratch/minimal_example.out.txt
```

or

```sh
$JAVA_HOME/bin/java -Dlog4j.configuration=/genome-nexus-annotation-pipeline/annotationPipeline/src/main/resources/log4j.properties -jar annotationPipeline/target/annotationPipeline.jar -f /mnt/docker-sandbox-data/scratch/minimal_example.in.txt -o /mnt/docker-sandbox-data/annotate_output/scratch/minimal_example.out.txt
```

to no avail. 

Any help on this front? 


",japerez-cls,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/244,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85o4T9-,Add new flag for logging verbosity and log output location,OPEN,2023-06-15T21:48:41Z,2024-04-29T18:49:30Z,,"The current logging is a bit complicated to see if running through docker. Add new flags for logging:
1. set verbosity to print out logging info to command line: e.g. `--verbosity=verbose`
2. set log file path: e.g. `--output-log=output.log`",leexgh,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/247,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85pb8ZW,CTNNB1 annotation fails but direct genome nexus API call succeed   ,OPEN,2023-06-22T05:04:25Z,2023-06-22T05:08:42Z,,"```
CTNNB1		MSKCC	GRCh37	3	41265562	41266260	+	In_Frame_Del	DEL	GCTACTCAAGGTTTGTGTCATTAAATCTTTAGTTACTGAATTGGGGCTCTGCTTCGTTGCCATTAAGCCAGTCTGGCTGAGATCCCCCTGCTTTCCTCTCTCCCTGCTTACTTGTCAGGCTACCTTTTGCTCCATTTTCTGCTCACTCCTCCTAATGGCTTGGTGAAATAGCAAACAAGCCACCAGCAGGAATCTAGTCTGGATGACTGCTTCTGGAGCCTGGATGCAGTACCATTCTTCCACTGATTCAGTGAGTAACTGTTAGGTGGTTCCCTAAGGGATTAGGTATTTCATCACTGAGCTAACCCTGGCTATCATTCTGCTTTTCTTGGCTGTCTTTCAGATTTGACTTTATTTCTAAAAATATTTCAATGGGTCATATCACAGATTCTTTTTTTTTAAATTAAAGTAACATTTCCAATCTACTAATGCTAATACTGTTTCGTATTTATAGCTGATTTGATGGAGTTGGACATGGCCATGGAACCAGACAGAAAAGCGGCTGTTAGTCACTGGCAGCAACAGTCTTACCTGGACTCTGGAATCCATTCTGGTGCCACTACCACAGCTCCTTCTCTGAGTGGTAAAGGCAATCCTGAGGAAGAGGATGTGGATACCTCCCAAGTCCTGTATGAGTGGGAACAGGGATTTTCTCAGTCCTTCACTCAAGAACAAGTAGCTGGTAAGAGTATTATTTTT	GCTACTCAAGGTTTGTGTCATTAAATCTTTAGTTACTGAATTGGGGCTCTGCTTCGTTGCCATTAAGCCAGTCTGGCTGAGATCCCCCTGCTTTCCTCTCTCCCTGCTTACTTGTCAGGCTACCTTTTGCTCCATTTTCTGCTCACTCCTCCTAATGGCTTGGTGAAATAGCAAACAAGCCACCAGCAGGAATCTAGTCTGGATGACTGCTTCTGGAGCCTGGATGCAGTACCATTCTTCCACTGATTCAGTGAGTAACTGTTAGGTGGTTCCCTAAGGGATTAGGTATTTCATCACTGAGCTAACCCTGGCTATCATTCTGCTTTTCTTGGCTGTCTTTCAGATTTGACTTTATTTCTAAAAATATTTCAATGGGTCATATCACAGATTCTTTTTTTTTAAATTAAAGTAACATTTCCAATCTACTAATGCTAATACTGTTTCGTATTTATAGCTGATTTGATGGAGTTGGACATGGCCATGGAACCAGACAGAAAAGCGGCTGTTAGTCACTGGCAGCAACAGTCTTACCTGGACTCTGGAATCCATTCTGGTGCCACTACCACAGCTCCTTCTCTGAGTGGTAAAGGCAATCCTGAGGAAGAGGATGTGGATACCTCCCAAGTCCTGTATGAGTGGGAACAGGGATTTTCTCAGTCCTTCACTCAAGAACAAGTAGCTGGTAAGAGTATTATTTTT	-		NA	P-0013404-T01-IM5																	NA	NA	NA	NA	p.2_D81del
CTNNB1		MSKCC	GRCh37	3	41265568	41266266	+	In_Frame_Del	DEL	CAAGGTTTGTGTCATTAAATCTTTAGTTACTGAATTGGGGCTCTGCTTCGTTGCCATTAAGCCAGTCTGGCTGAGATCCCCCTGCTTTCCTCTCTCCCTGCTTACTTGTCAGGCTACCTTTTGCTCCATTTTCTGCTCACTCCTCCTAATGGCTTGGTGAAATAGCAAACAAGCCACCAGCAGGAATCTAGTCTGGATGACTGCTTCTGGAGCCTGGATGCAGTACCATTCTTCCACTGATTCAGTGAGTAACTGTTAGGTGGTTCCCTAAGGGATTAGGTATTTCATCACTGAGCTAACCCTGGCTATCATTCTGCTTTTCTTGGCTGTCTTTCAGATTTGACTTTATTTCTAAAAATATTTCAATGGGTCATATCACAGATTCTTTTTTTTTAAATTAAAGTAACATTTCCAATCTACTAATGCTAATACTGTTTCGTATTTATAGCTGATTTGATGGAGTTGGACATGGCCATGGAACCAGACAGAAAAGCGGCTGTTAGTCACTGGCAGCAACAGTCTTACCTGGACTCTGGAATCCATTCTGGTGCCACTACCACAGCTCCTTCTCTGAGTGGTAAAGGCAATCCTGAGGAAGAGGATGTGGATACCTCCCAAGTCCTGTATGAGTGGGAACAGGGATTTTCTCAGTCCTTCACTCAAGAACAAGTAGCTGGTAAGAGTATTATTTTTCATTGC	CAAGGTTTGTGTCATTAAATCTTTAGTTACTGAATTGGGGCTCTGCTTCGTTGCCATTAAGCCAGTCTGGCTGAGATCCCCCTGCTTTCCTCTCTCCCTGCTTACTTGTCAGGCTACCTTTTGCTCCATTTTCTGCTCACTCCTCCTAATGGCTTGGTGAAATAGCAAACAAGCCACCAGCAGGAATCTAGTCTGGATGACTGCTTCTGGAGCCTGGATGCAGTACCATTCTTCCACTGATTCAGTGAGTAACTGTTAGGTGGTTCCCTAAGGGATTAGGTATTTCATCACTGAGCTAACCCTGGCTATCATTCTGCTTTTCTTGGCTGTCTTTCAGATTTGACTTTATTTCTAAAAATATTTCAATGGGTCATATCACAGATTCTTTTTTTTTAAATTAAAGTAACATTTCCAATCTACTAATGCTAATACTGTTTCGTATTTATAGCTGATTTGATGGAGTTGGACATGGCCATGGAACCAGACAGAAAAGCGGCTGTTAGTCACTGGCAGCAACAGTCTTACCTGGACTCTGGAATCCATTCTGGTGCCACTACCACAGCTCCTTCTCTGAGTGGTAAAGGCAATCCTGAGGAAGAGGATGTGGATACCTCCCAAGTCCTGTATGAGTGGGAACAGGGATTTTCTCAGTCCTTCACTCAAGAACAAGTAGCTGGTAAGAGTATTATTTTTCATTGC	-		NA	P-0007600-T01-IM5																	NA	NA	NA	NA	p.4_D81del
CTNNB1		MSKCC	GRCh37	3	41265571	41266206	+	In_Frame_Del	DEL	GGTTTGTGTCATTAAATCTTTAGTTACTGAATTGGGGCTCTGCTTCGTTGCCATTAAGCCAGTCTGGCTGAGATCCCCCTGCTTTCCTCTCTCCCTGCTTACTTGTCAGGCTACCTTTTGCTCCATTTTCTGCTCACTCCTCCTAATGGCTTGGTGAAATAGCAAACAAGCCACCAGCAGGAATCTAGTCTGGATGACTGCTTCTGGAGCCTGGATGCAGTACCATTCTTCCACTGATTCAGTGAGTAACTGTTAGGTGGTTCCCTAAGGGATTAGGTATTTCATCACTGAGCTAACCCTGGCTATCATTCTGCTTTTCTTGGCTGTCTTTCAGATTTGACTTTATTTCTAAAAATATTTCAATGGGTCATATCACAGATTCTTTTTTTTTAAATTAAAGTAACATTTCCAATCTACTAATGCTAATACTGTTTCGTATTTATAGCTGATTTGATGGAGTTGGACATGGCCATGGAACCAGACAGAAAAGCGGCTGTTAGTCACTGGCAGCAACAGTCTTACCTGGACTCTGGAATCCATTCTGGTGCCACTACCACAGCTCCTTCTCTGAGTGGTAAAGGCAATCCTGAGGAAGAGGATGTGGATACCTCCCAAGTCCTGTATGAGTGGGAACAG	GGTTTGTGTCATTAAATCTTTAGTTACTGAATTGGGGCTCTGCTTCGTTGCCATTAAGCCAGTCTGGCTGAGATCCCCCTGCTTTCCTCTCTCCCTGCTTACTTGTCAGGCTACCTTTTGCTCCATTTTCTGCTCACTCCTCCTAATGGCTTGGTGAAATAGCAAACAAGCCACCAGCAGGAATCTAGTCTGGATGACTGCTTCTGGAGCCTGGATGCAGTACCATTCTTCCACTGATTCAGTGAGTAACTGTTAGGTGGTTCCCTAAGGGATTAGGTATTTCATCACTGAGCTAACCCTGGCTATCATTCTGCTTTTCTTGGCTGTCTTTCAGATTTGACTTTATTTCTAAAAATATTTCAATGGGTCATATCACAGATTCTTTTTTTTTAAATTAAAGTAACATTTCCAATCTACTAATGCTAATACTGTTTCGTATTTATAGCTGATTTGATGGAGTTGGACATGGCCATGGAACCAGACAGAAAAGCGGCTGTTAGTCACTGGCAGCAACAGTCTTACCTGGACTCTGGAATCCATTCTGGTGCCACTACCACAGCTCCTTCTCTGAGTGGTAAAGGCAATCCTGAGGAAGAGGATGTGGATACCTCCCAAGTCCTGTATGAGTGGGAACAG	-		NA	P-0007066-T01-IM5																	NA	NA	NA	NA	p.A5_Q68del
CTNNB1		MSKCC	GRCh37	3	41265990	41266204	+	In_Frame_Del	DEL	ATGCTAATACTGTTTCGTATTTATAGCTGATTTGATGGAGTTGGACATGGCCATGGAACCAGACAGAAAAGCGGCTGTTAGTCACTGGCAGCAACAGTCTTACCTGGACTCTGGAATCCATTCTGGTGCCACTACCACAGCTCCTTCTCTGAGTGGTAAAGGCAATCCTGAGAAGAGGATGTGGATACCTCCCAAGTCCTGTATGAGTGGGAAC	ATGCTAATACTGTTTCGTATTTATAGCTGATTTGATGGAGTTGGACATGGCCATGGAACCAGACAGAAAAGCGGCTGTTAGTCACTGGCAGCAACAGTCTTACCTGGACTCTGGAATCCATTCTGGTGCCACTACCACAGCTCCTTCTCTGAGTGGTAAAGGCAATCCTGAGAAGAGGATGTGGATACCTCCCAAGTCCTGTATGAGTGGGAAC	-		NA	P-0003501-T01-IM5																	NA	NA	NA	NA	p.A5_Q68del
CTNNB1		MSKCC	GRCh37	3	41266017	41266244	+	In_Frame_Del	DEL	CTGATTTGATGGAGTTGGACATGGCCATGGAACCAGACAGAAAAGCGGCTGTTAGTCACTGGCAGCAACAGTCTTACCTGGACCTGGAATCCATTCTGGTGCCACTACCACAGCTCCTTCTCTGAGTGGTAAAGGCAATCCTGAGGAAGAGGATGTGGATACCTCCCAGTCCTGTATGAGTGGGAACAGGGATTTTCTCAGTCCTTCACTCAAGAACAAGTAGCTG	CTGATTTGATGGAGTTGGACATGGCCATGGAACCAGACAGAAAAGCGGCTGTTAGTCACTGGCAGCAACAGTCTTACCTGGACCTGGAATCCATTCTGGTGCCACTACCACAGCTCCTTCTCTGAGTGGTAAAGGCAATCCTGAGGAAGAGGATGTGGATACCTCCCAGTCCTGTATGAGTGGGAACAGGGATTTTCTCAGTCCTTCACTCAAGAACAAGTAGCTG	-		NA	P-0000874-T01-IM3																	NA	NA	NA	NA	p.A5_D81del
```
Annotation is failing but Genome Nexus api response is fine:
https://www.genomenexus.org/annotation/3%3Ag.41265562_41266260del?isoformOverrideSource=mskcc&fields=annotation_summary
",leexgh,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/248,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85tyW2P,Add a new command parameter to set oncokb token ,OPEN,2023-08-08T19:24:40Z,2023-08-08T19:57:21Z,,"Add support to set oncokb token in command line.
E.g. ""--oncokbToken abc123""",leexgh,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/254,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85uZLPb,Add note column to include some important comments,CLOSED,2023-08-15T20:36:43Z,2023-09-25T14:28:38Z,2023-09-25T14:28:38Z,"**Background**:
- If there are common prefix being removed, or end position is altered (when end position is missing or is not correct), start position and / or end position might be updated. We have a new field in genome nexus response, e.g. `""genomicLocationExplanation"":""End position changes from 123 to 122, because end position should be the position of last deleted nucleotide.`
- Add comments for failing variants, we have a new field called `errorMessage`, e.g. `  ""errorMessage"": ""Unable to parse HGVS notation '12:g.58142319A>C': Reference allele extracted from 12:58142319-58142319 (T) does not match reference allele given by HGVS notation 12:g.58142319A>C (A)"",
`
    - wrong coordinates, alleles
    - no matches in VEP
 - server issues

**Proposal**:
- Add new parameter for instance `-n` `--note`.
- If have `-n`, add a new column:`GenomicLocation Explanation`.
- (if user defines `-e`) In error report, add `Error Message` column using the ""errorMessage"" value.
",leexgh,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/255,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85ugDAF,Adding sift and polyphen causes all annotations fail,CLOSED,2023-08-16T20:56:11Z,2023-08-17T16:16:40Z,2023-08-17T16:16:40Z,"Adding `sift` and `polyphen` in ""enrichment_fields"" causes all annotations fail, this is because `sift` and `polyphen` are not valid fields name for genome nexus server, so giving `sift` and `polyphen` in genome nexus query causes failing annotation.
The `sift` and `polyphen` annotations are actually resolved from canonical transcript.",leexgh,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/257,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85upBoR,Error runnnig docker on v1.0.0,CLOSED,2023-08-18T07:54:56Z,2023-09-07T17:59:10Z,2023-09-07T17:59:10Z,"Hi, 
I am having troubles to run the new docker version. 

docker: Error response from daemon: failed to create task for container: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: exec: ""--filename"": executable file not found in $PATH: unknown.

This error was not present in the previous version of the docker image. Also I was comparing both docker image version and the size is different.

Could you please check the new docker image?

Thanks",aclosa,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/258,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85u33yD,Some complex variants with common prefix - suffix fail the annotation,OPEN,2023-08-21T20:58:53Z,2023-08-21T21:00:27Z,,"These variants needs some pre-processing like removing both common prefix and suffixes, adjusting the coordinates etc., before passing to GN. It's a bit tricky in some cases. 



Chr | Start Pos | End Pos | Ref Allele | Tumor Allele
-- | -- | -- | -- | --
5 | 112175377 | 112175378 | CAAAAG | CAAAAAT
17 | 7578231 | 7578232 | CAAAT | CAAAAAT
17 | 7578439 | 7578440 | TTGT | TGCTTGG
5 | 112175650 | 112175651 | TAAAAAT | TAAAAAAT
20 | 31022441 | 31022442 | AGGGGGGGGT | AGGGGGGGGGT
22 | 41574678 | 41574679 | GCCCCCCCA | GCCCCCCCCA
2 | 48033651 | 48033652 | AAATT | AAATAATT
17 | 11924243 | 11924244 | GGCGGCAGCGGCAGCGGCAC | GGCGGCAGCGGCAGCGGCAGCGGCAC
6 | 157100116 | 157100117 | AGGCGGCGGCGGCGGCGGCT | AGGCGGCGGCGGCGGCGGCGGCT
6 | 157099165 | 157099166 | GTCCTCCTCCTCCTCCTCCTCCG | GTCCTCCTCCTCCTCCTCCTCCTCCG
1 | 27023007 | 27023008 | AGGCGGCGGCGGCGGCA | AGGCGGCGGCGGCGGCGGCGGCA
7 | 55248999 | 55249000 | TGGCCAGCGTGGAC | TGGCCAGCGTGGCCAGCGTGGAT
7 | 55242460 | 55242461 | ATCAAGGAATTAAGAGAAGCA | ATCAAAGGAATTAAGAGAAGCA
7 | 55249015 | 55249016 | CCCC | CCCAACCCCT
7 | 151874147 | 151874148 | CTTTTTTTTTG | CTTTTTTTTTTG
17 | 7577091 | 7577092 | GCCG | GCCCCG
16 | 67660601 | 67660602 | GATT | GATATT
7 | 55248999 | 55249000 | TGGCCAGCGTGGAC | TGGCCAGCCGTGGAC
19 | 1221313 | 1221314 | GCCCCCCG | GCCCCCCTG
17 | 7578467 | 7578475 | GACGCGGGT | GACGCGGG
7 | 55242465 | 55242482 | CAAGGAATTAAGAGAAGC | CAA
9 | 1393967398 | 1393967410 | GTCCTCGCCGAGG | GCCCTC
X | 66766357 | 66766356 | GGCGGCGGCGGCGGCGGCGGC | -
17 | 7577541 | 7577540 | TTCATGCCGCCCATGCAGGAA | -

",rmadupuri,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/259,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85u39HK,Handling variants with common prefixes between GENIE and public GN,OPEN,2023-08-21T21:13:34Z,2023-08-29T17:39:10Z,,"A few variants successfully annotate when pointed to the public GN (https://www.genomenexus.org/) but are failing when pointing to the Genie GN (https://genie.genomenexus.org/). The variants are passed in region format for genie and hgvsg format for public and the variants with common prefixes are handled differently in each case. 

Below are a few examples that pass annotation when pointed to public but fail when pointed to genie site.
[test_failed_variants.txt](https://github.com/genome-nexus/genome-nexus-annotation-pipeline/files/12410849/test_failed_variants.txt)

",rmadupuri,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/260,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85wU_-8,entrypoint to cmd switch breaks old usage of cli,OPEN,2023-09-06T18:38:29Z,2023-09-06T18:39:13Z,,"See related PR: https://github.com/genome-nexus/genome-nexus-annotation-pipeline/pull/250 and example of how it breaks the old documented interface: https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/258

- [ ] Restore old CLI usage
- [ ] Add test that follows steps of the docs for annotating a MAF: https://docs.genomenexus.org/annotate-maf-file

",inodb,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/262,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85xeOHj,Add command parameter groups,OPEN,2023-09-19T21:23:09Z,2023-09-19T21:23:09Z,,"We have more and more parameters now that are a bit hard to track, the idea is to create a few groups for command parameters:
for example:
```
--minimal activate minimal set of annotation columns
--full add all available annotation columns
--debug add all available annotation columns, and need to specify the log file and error report file, can also extend to different levels of logging (https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/247)
```",leexgh,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/266,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85zYAMe,Tumor_Seq_Allele1 and Tumor_Seq_Allele2 should be the same,OPEN,2023-10-10T15:42:09Z,2023-10-10T15:43:29Z,,"If the variant has common postfix, e.g.

23 | 8993426 | 8993426 | A | CA
-- | -- | -- | -- | --

**Problem**: The current output only updates Tumor_Seq_Allele2 but fill Tumor_Seq_Allele1 with the original input

|Chromosome | Start_Position | End_Position |  Reference_Allele |Tumor_Seq_Allele1  | Tumor_Seq_Allele2 |
|-- | -- | -- | -- | -- | --|
|23 | 8993425 | 8993426 | -  | CA | C|

**Expected result**: Tumor_Seq_Allele1 and Tumor_Seq_Allele2 should be the same so the expected output should be:

|Chromosome | Start_Position | End_Position |  Reference_Allele |Tumor_Seq_Allele1  | Tumor_Seq_Allele2 |
|-- | -- | -- | -- | -- | --|
|23 | 8993425 | 8993426 | -  | C | C|

",leexgh,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/268,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_858YkVZ,Error when having duplicated variants and no end positions,OPEN,2024-01-17T19:13:34Z,2024-01-17T19:13:34Z,,"If the input file contains duplicated variants and doesn't have end positions,  the GN annotation pipeline fails with error: `java.lang.NullPointerException: Cannot invoke ""java.lang.Integer.compareTo(java.lang.Integer)"" because the return value of ""org.genome_nexus.client.GenomicLocation.getEnd()"" is null` .

GN annotation pipeline can handle duplications with full genomic location, or missing end position with no duplication, but throws errors for duplication AND missing end position.
",leexgh,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/271,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_85_QePb,Handling Intergenic Variants in the MAF: Annotation Pipeline doesn't fill out any columns when VEP returns no transcript,OPEN,2024-02-14T19:15:47Z,2024-02-14T19:22:48Z,,"When VEP doesnt return any transcript info (for intergenic variants), the annotation pipeline doesnt fill out any columns. 
For example, https://www.genomenexus.org/annotation/2%3Ag.159740254C%3EA?fields=annotation_summary is an intergenic variant and this would get imported as MUTATED into the database although this is an intergenic event and should be filtered out. Importer uses Variant_Classification column to filter out the variants. 

Solution:
Would be ideal to use the ""most_severe_consequence"" to update the Consequence (intergenic_variant) and Variant_Classification (IGR) coulumns so these would be filtered out during import. 

More examples: 
[error.txt](https://github.com/genome-nexus/genome-nexus-annotation-pipeline/files/14285125/error.txt)
",rmadupuri,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/274,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_86Del5W,Documentation for application.properties overrides via ENV variables,OPEN,2024-03-25T14:00:00Z,2024-03-25T14:00:01Z,,"User to override application.properties via environment variables. ENV variables are currently supported in a limited or full-supported way, however it may not be clear to the end user.

### Use case:
It would be helpful for users to be able to
1) Point to specific VEP version of genome-nexus. e.g. `<vep_version>.genomenexus.org`
2) Modify the enrichment fields via environment variable

Alternative (instead of ENV variables)
1) User supplied application.properties file. Not friendly for usage in NextFlow

### Deliverables:
1) Provide examples of ENV usage, especially with `docker` usage.
2) Provide example of user supplying custom `application.properties` file and location to file.
3) Document the ENV variables currently being used",hweej,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/275,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_86ELdiY,Singularity 3.3 cannot pull master docker ,OPEN,2024-04-01T06:05:12Z,2024-04-01T06:05:12Z,,"When running on Singularity 3.3, it can run docker GN:latest but not GN:master. The ""latest"" tag is the same as the latest official tag (v1.0.3), while ""master"" has some commits that are not release yet (PR 267, 270, 272, 273)
Error message:
```
error initializing image from source docker://genomenexus/gn-annotation-pipeline:master: unsupported schema version 2
```",leexgh,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/276,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_86ELeZW,Singularity 3.7 got LinkageError when running master,OPEN,2024-04-01T06:07:28Z,2024-04-01T06:07:53Z,,"Error message:
```
Error: LinkageError occurred while loading main class org.springframework.boot.loader.JarLauncher
java.lang.UnsupportedClassVersionError: org/springframework/boot/loader/JarLauncher has been 
compiled by a more recent version of the Java Runtime (class file version 61.0), this version of the 
Java Runtime only recognizes class file versions up to 55.0
```",leexgh,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/277,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_86EYxlQ,Error report misses '/' in URL column,OPEN,2024-04-02T17:45:39Z,2024-04-02T17:46:57Z,,"E.g. https://www.genomenexus.organnotation/genomic/8,37539334,37539334,G,A?isofromOverrideSource=null&fields=annotation_summary,my_variant_info,mutation_assessor,nucleotide_context,oncokb
Should have / after `.org`
https://www.genomenexus.org/annotation/genomic/8,37539334,37539334,G,A?isofromOverrideSource=null&fields=annotation_summary,my_variant_info,mutation_assessor,nucleotide_context,oncokb",leexgh,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/278,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOA8bm_86PbCyI,Java Null Pointer Exception while running annotator with Docker,OPEN,2024-07-12T19:46:37Z,2024-07-16T02:50:55Z,,"When running the annotator with Docker, I get a java.lang.NullPointerException. It reads data from my file just fine, but I would like to eliminate these errors and warnings. I have the most recent Docker image pulled down. Has anyone encountered this?


### My command
```
$ docker run -v ${PWD}:/wd genomenexus/gn-annotation-pipeline:master java -jar annotationPipeline.jar --filename /wd/mutations.txt --output-filename /wd/output.txt
```

### TL;DR Output
```
2024-07-12 19:34:28 [main] ERROR org.springframework.batch.core.step.AbstractStep - Encountered an error executing step step in job annotationJob
org.springframework.batch.item.ItemStreamException: java.lang.NullPointerException
```

### Full Output
```
  _____                                               _   _                             
 / ____|                                             | \ | |                            
| |  __    ___   _ __     ___    _ __ ___     ___    |  \| |   ___  __  __  _   _   ___ 
| | |_ |  / _ \ | '_ \   / _ \  | '_ ` _ \   / _ \   | . ` |  / _ \ \ \/ / | | | | / __|
| |__| | |  __/ | | | | | (_) | | | | | | | |  __/   | |\  | |  __/  >  <  | |_| | \__ \
 \_____|  \___| |_| |_|  \___/  |_| |_| |_|  \___|   |_| \_|  \___| /_/\_\  \__,_| |___/
                                                                                        

2024-07-12 19:34:27 [main] INFO  org.cbioportal.annotation.AnnotationPipeline - Starting AnnotationPipeline v7a064a4-SNAPSHOT using Java 21.0.3 with PID 1 (/genome-nexus-annotation-pipeline/annotationPipeline/target/annotationPipeline.jar started by root in /genome-nexus-annotation-pipeline/annotationPipeline/target)
2024-07-12 19:34:27 [main] INFO  org.cbioportal.annotation.AnnotationPipeline - No active profile set, falling back to 1 default profile: ""default""
2024-07-12 19:34:27 [main] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Starting...
2024-07-12 19:34:27 [main] INFO  com.zaxxer.hikari.pool.PoolBase - HikariPool-1 - Driver does not support get/set network timeout for connections. (Receiver class org.h2.jdbc.JdbcConnection does not define or inherit an implementation of the resolved method 'abstract int getNetworkTimeout()' of interface java.sql.Connection.)
2024-07-12 19:34:27 [main] INFO  com.zaxxer.hikari.pool.HikariPool - HikariPool-1 - Added connection conn0: url=jdbc:h2:mem:7c100da6-32c8-43e7-9efa-fe77e318345b user=SA
2024-07-12 19:34:27 [main] INFO  com.zaxxer.hikari.HikariDataSource - HikariPool-1 - Start completed.
2024-07-12 19:34:28 [main] WARN  org.springframework.batch.core.listener.AbstractListenerFactoryBean - org.springframework.batch.item.ItemStreamReader is an interface. The implementing class will not be queried for annotation based listener configurations. If using @StepScope on a @Bean method, be sure to return the implementing class so listener annotations can be used.
2024-07-12 19:34:28 [main] WARN  org.springframework.batch.core.listener.AbstractListenerFactoryBean - org.springframework.batch.item.ItemStreamWriter is an interface. The implementing class will not be queried for annotation based listener configurations. If using @StepScope on a @Bean method, be sure to return the implementing class so listener annotations can be used.
2024-07-12 19:34:28 [main] INFO  org.cbioportal.annotation.AnnotationPipeline - Started AnnotationPipeline in 1.087 seconds (process running for 1.457)
2024-07-12 19:34:28 [main] INFO  org.springframework.boot.autoconfigure.batch.JobLauncherApplicationRunner - Running default command line with: [/wd/mutations.txt, /wd/output.txt]
2024-07-12 19:34:28 [main] INFO  org.springframework.batch.core.launch.support.SimpleJobLauncher - Job: [SimpleJob: [name=annotationJob]] launched with the following parameters: [{}]
2024-07-12 19:34:28 [main] INFO  org.springframework.batch.core.job.SimpleStepHandler - Executing step: [step]
2024-07-12 19:34:28 [main] ERROR org.springframework.batch.core.step.AbstractStep - Encountered an error executing step step in job annotationJob
org.springframework.batch.item.ItemStreamException: java.lang.NullPointerException
	at org.cbioportal.annotation.pipeline.MutationRecordReader.processComments(MutationRecordReader.java:233)
	at org.cbioportal.annotation.pipeline.MutationRecordReader.open(MutationRecordReader.java:109)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.support.DelegatingIntroductionInterceptor.doProceed(DelegatingIntroductionInterceptor.java:137)
	at org.springframework.aop.support.DelegatingIntroductionInterceptor.invoke(DelegatingIntroductionInterceptor.java:124)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:244)
	at jdk.proxy2/jdk.proxy2.$Proxy32.open(Unknown Source)
	at org.springframework.batch.item.support.CompositeItemStream.open(CompositeItemStream.java:124)
	at org.springframework.batch.core.step.tasklet.TaskletStep.open(TaskletStep.java:293)
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:226)
	at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:153)
	at org.springframework.batch.core.job.AbstractJob.handleStep(AbstractJob.java:418)
	at org.springframework.batch.core.job.SimpleJob.doExecute(SimpleJob.java:132)
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:317)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:157)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:148)
	at org.springframework.batch.core.launch.support.TaskExecutorJobLauncher.run(TaskExecutorJobLauncher.java:59)
	at org.springframework.boot.autoconfigure.batch.JobLauncherApplicationRunner.execute(JobLauncherApplicationRunner.java:211)
	at org.springframework.boot.autoconfigure.batch.JobLauncherApplicationRunner.executeLocalJobs(JobLauncherApplicationRunner.java:195)
	at org.springframework.boot.autoconfigure.batch.JobLauncherApplicationRunner.launchJobFromProperties(JobLauncherApplicationRunner.java:175)
	at org.springframework.boot.autoconfigure.batch.JobLauncherApplicationRunner.run(JobLauncherApplicationRunner.java:170)
	at org.springframework.boot.autoconfigure.batch.JobLauncherApplicationRunner.run(JobLauncherApplicationRunner.java:165)
	at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:765)
	at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:755)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:322)
	at org.cbioportal.annotation.AnnotationPipeline.annotateJob(AnnotationPipeline.java:75)
	at org.cbioportal.annotation.AnnotationPipeline.annotate(AnnotationPipeline.java:267)
	at org.cbioportal.annotation.AnnotationPipeline.subMain(AnnotationPipeline.java:127)
	at org.cbioportal.annotation.AnnotationPipeline.main(AnnotationPipeline.java:138)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49)
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:95)
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:58)
	at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:65)
Caused by: java.lang.NullPointerException
	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:144)
	at java.base/java.io.FileInputStream.<init>(FileInputStream.java:106)
	at java.base/java.io.FileReader.<init>(FileReader.java:60)
	at org.cbioportal.annotation.pipeline.MutationRecordReader.processComments(MutationRecordReader.java:216)
	... 40 more
2024-07-12 19:34:28 [main] INFO  org.springframework.batch.core.step.AbstractStep - Step: [step] executed in 751ms
2024-07-12 19:34:28 [main] ERROR org.springframework.batch.core.step.AbstractStep - Exception while closing step execution resources in step step in job annotationJob
java.lang.NullPointerException: Cannot invoke ""java.lang.Integer.intValue()"" because ""this.recordsToWriteCount"" is null
	at org.cbioportal.annotation.pipeline.MutationRecordWriter.close(MutationRecordWriter.java:95)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:343)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:196)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.aop.support.DelegatingIntroductionInterceptor.doProceed(DelegatingIntroductionInterceptor.java:137)
	at org.springframework.aop.support.DelegatingIntroductionInterceptor.invoke(DelegatingIntroductionInterceptor.java:124)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:184)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:244)
	at jdk.proxy2/jdk.proxy2.$Proxy33.close(Unknown Source)
	at org.springframework.batch.item.support.CompositeItemStream.close(CompositeItemStream.java:111)
	at org.springframework.batch.core.step.tasklet.TaskletStep.close(TaskletStep.java:288)
	at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:312)
	at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:153)
	at org.springframework.batch.core.job.AbstractJob.handleStep(AbstractJob.java:418)
	at org.springframework.batch.core.job.SimpleJob.doExecute(SimpleJob.java:132)
	at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:317)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:157)
	at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)
	at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:148)
	at org.springframework.batch.core.launch.support.TaskExecutorJobLauncher.run(TaskExecutorJobLauncher.java:59)
	at org.springframework.boot.autoconfigure.batch.JobLauncherApplicationRunner.execute(JobLauncherApplicationRunner.java:211)
	at org.springframework.boot.autoconfigure.batch.JobLauncherApplicationRunner.executeLocalJobs(JobLauncherApplicationRunner.java:195)
	at org.springframework.boot.autoconfigure.batch.JobLauncherApplicationRunner.launchJobFromProperties(JobLauncherApplicationRunner.java:175)
	at org.springframework.boot.autoconfigure.batch.JobLauncherApplicationRunner.run(JobLauncherApplicationRunner.java:170)
	at org.springframework.boot.autoconfigure.batch.JobLauncherApplicationRunner.run(JobLauncherApplicationRunner.java:165)
	at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:765)
	at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:755)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:322)
	at org.cbioportal.annotation.AnnotationPipeline.annotateJob(AnnotationPipeline.java:75)
	at org.cbioportal.annotation.AnnotationPipeline.annotate(AnnotationPipeline.java:267)
	at org.cbioportal.annotation.AnnotationPipeline.subMain(AnnotationPipeline.java:127)
	at org.cbioportal.annotation.AnnotationPipeline.main(AnnotationPipeline.java:138)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49)
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:95)
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:58)
	at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:65)
2024-07-12 19:34:28 [main] WARN  org.springframework.beans.factory.support.DisposableBeanAdapter - Custom destroy method 'close' on bean with name 'scopedTarget.writer' threw an exception: java.lang.NullPointerException: Cannot invoke ""java.lang.Integer.intValue()"" because ""this.recordsToWriteCount"" is null
2024-07-12 19:34:28 [main] INFO  org.springframework.batch.core.launch.support.SimpleJobLauncher - Job: [SimpleJob: [name=annotationJob]] completed with the following parameters: [{}] and the following status: [FAILED] in 766ms
2024-07-12 19:34:28 [main] INFO  org.springframework.batch.core.launch.support.SimpleJobLauncher - Job: [SimpleJob: [name=annotationJob]] launched with the following parameters: [{'ignoreOriginalGenomicLocation':'{value=false, type=class java.lang.String, identifying=true}','filename':'{value=/wd/mutations.txt, type=class java.lang.String, identifying=true}','outputFilename':'{value=/wd/output.txt, type=class java.lang.String, identifying=true}','noteColumn':'{value=true, type=class java.lang.String, identifying=true}','replace':'{value=true, type=class java.lang.String, identifying=true}','postIntervalSize':'{value=100, type=class java.lang.String, identifying=true}','stripMatchingBases':'{value=all, type=class java.lang.String, identifying=true}'}]
```",grabnervan,https://github.com/genome-nexus/genome-nexus-annotation-pipeline/issues/283,genome-nexus++genome-nexus-annotation-pipeline.csv
I_kwDOKPsgBs5yGcpR,Retain the last image for each user.,CLOSED,2023-09-26T20:55:34Z,2023-09-27T19:24:33Z,2023-09-27T19:24:33Z,"Now, when an annotator saves a partially complete transcription (one that is not marked as complete), the page reloads and this means that the image is lost. This is very bad UX: it discourages saving often, and thus increases the likelihood of losing work (hence marking this as a bug).

A solution would be to retain the image data in local storage in the browser and reload it when the melody ID stays the same.
More generally, we can cache the images for *each* melody ID that the user looks at, so that at some point when a dashboard gets implemented, giving them a choice of melodies to continue annotating, all the images are available. ",hajicj,https://github.com/Genome-of-Melody/genomel_editor/issues/1,Genome-of-Melody++genomel_editor.csv
I_kwDOKPsgBs5yGgRv,Auto-render after the next Volpiano word is finished?,OPEN,2023-09-26T21:08:15Z,2023-09-26T21:08:15Z,,"To make sure that the user basically cannot submit without rendering, and that errors are caught early, we could render every time the user writes three hyphens in the Volpiano (or possibly 2). 

This can possibly be also an options checkbox (likely a bit hidden, because we don't want the users to switch it off without being sure).",hajicj,https://github.com/Genome-of-Melody/genomel_editor/issues/2,Genome-of-Melody++genomel_editor.csv
I_kwDOKPsgBs5yNZOK,Syllabization can be taken from a transcribed melody with the same Cantus ID,OPEN,2023-09-27T18:32:47Z,2023-09-27T18:32:48Z,,"Many texts will have the same syllabization (if the manuscript spelling is the same).

For instance, the Melody with the chant of the same Cantus ID that has the most syllables in its text. Can be further filtered by 
status -- prioritize syllabification from finalized melodies, then those in checks, then those in transcription.

If the manuscript spelling is not the same, then syllabization guessing will be a more involved process -- likely some kind of Needleman-Wunsch alignment and inferring gaps from that.",hajicj,https://github.com/Genome-of-Melody/genomel_editor/issues/3,Genome-of-Melody++genomel_editor.csv
I_kwDOKPsgBs50F2P_,Add basic annotator leaderboard.,CLOSED,2023-10-17T15:22:44Z,2023-10-17T15:28:37Z,2023-10-17T15:28:37Z,,hajicj,https://github.com/Genome-of-Melody/genomel_editor/issues/4,Genome-of-Melody++genomel_editor.csv
I_kwDOKPsgBs50F3-z,Image pasting fails when a chant goes into transcription for the first time.,CLOSED,2023-10-17T15:26:08Z,2023-10-17T15:28:38Z,2023-10-17T15:28:37Z,"
The annotate() view creates a Melody object, but it does not yet have an ID. The script that tries to retrieve an image from local storage is run with ""None"" (but not as a string), which results in an error, and the rest of the script that adds the onpaste() event never gets read. Thus, not only does it not retrieve an image from storage (which is the expected behavior when the melody is new), pasting a new image has no response.",hajicj,https://github.com/Genome-of-Melody/genomel_editor/issues/5,Genome-of-Melody++genomel_editor.csv
I_kwDOKPsgBs50GM2B,Add annotator reporting system to the (admin) dashboard.,OPEN,2023-10-17T16:11:29Z,2023-10-17T16:11:30Z,,In order to figure out the payments and other metrics.,hajicj,https://github.com/Genome-of-Melody/genomel_editor/issues/6,Genome-of-Melody++genomel_editor.csv
I_kwDOKPsgBs50eZHb,Race condition on selecting the next chant: two annotators can be given the same chant.,CLOSED,2023-10-20T11:49:29Z,2023-10-20T12:47:06Z,2023-10-20T12:47:06Z,,hajicj,https://github.com/Genome-of-Melody/genomel_editor/issues/7,Genome-of-Melody++genomel_editor.csv
I_kwDOKPsgBs50evho,Saving a melody with empty Volpiano fails.,CLOSED,2023-10-20T12:44:54Z,2023-10-20T12:52:39Z,2023-10-20T12:52:39Z,,hajicj,https://github.com/Genome-of-Melody/genomel_editor/issues/8,Genome-of-Melody++genomel_editor.csv
I_kwDOKPsgBs507UU5,REST API for annotation,OPEN,2023-10-25T15:31:12Z,2023-10-25T15:31:12Z,,"It would be useful to have annotations available over a REST API - both for the annotators, and for exporting data on the fly.

The specification would be:

```
/annotate/{melody_id}
/annotator/{annotator_name}  -- clickable list of melodies that the annotator has done
/export/json/{chant_id} -- JSON of a single chant
/export/csv/{chant_id} -- CSV row of a single chant
/export/csv/all -- CSV of all the chants
/export/csv/annotated -- CSV of all the chants that have a melody

```",hajicj,https://github.com/Genome-of-Melody/genomel_editor/issues/9,Genome-of-Melody++genomel_editor.csv
I_kwDOKPsgBs530T9P,Switch between writing the melody directly rendered as Volpiano vs. plain text,OPEN,2023-11-24T20:36:09Z,2023-11-24T20:36:09Z,,,hajicj,https://github.com/Genome-of-Melody/genomel_editor/issues/10,Genome-of-Melody++genomel_editor.csv
MDU6SXNzdWUxNjQ2NzY3OQ==,gt_xfread vs gt_xfwrite,CLOSED,2013-07-08T12:06:10Z,2013-07-11T13:23:30Z,2013-07-11T13:23:30Z,"There is a discrepancy between gt_xfread and gt_xfwrite, read returns the number of bytes read, but write does not. Both already check for the right number of bytes and exit with an error if there is a difference. So there is no need for gt_xfread to return the number of bytes read.

Would it be ok to change this?
",Garonenur,https://github.com/genometools/genometools/issues/8,genometools++genometools.csv
MDU6SXNzdWUxNjUwNjU4OQ==,Honor sequence-region pragmas when specified,CLOSED,2013-07-09T03:48:10Z,2013-07-11T13:46:26Z,2013-07-11T13:46:26Z,"[The GFF3 spec](http://sequenceontology.org/resources/gff3.html) discusses the utility of `##sequence-region` directives for bounds checking. Many GFF3 files do not provide these directives, but the `GtGFF3InStream` class conveniently infers theses boundaries from the annotations corresponding to each sequence.

However, it seems that when `##sequence-region` pragmas are provided, they are ignored or overridden by the `GtGFF3InStream` class. For example, I have a GFF3 file with the entry `##sequence-region   chr8 1 1000000` to indicate that the corresponding sequence is 100kb long. However, the right-most annotation in the file spans 88551-92176. When I parse these data with a `GtGFF3InStream` object, I get [1-92176] as the range, rather than [1-100000].

Being able to infer ranges from the annotations is no doubt a very useful feature, but when `##sequence-region` directives are explicitly provided, shouldn't these be honored and used?
",standage,https://github.com/genometools/genometools/issues/13,genometools++genometools.csv
MDU6SXNzdWUxNjUxNTAwMg==,hmm class unit tests,CLOSED,2013-07-09T09:18:53Z,2013-07-10T11:52:39Z,2013-07-10T11:52:39Z,"using

``` bash
make opt=no curses=no cairo=no test -j6 testthreads=6 
```

hmm class...error
first error: gt_ensure(gt_double_equals_double(gt_hmm_rmsd(fair_hmm, fair_hmm), 0.0)) failed: function gt_hmm_unit_test, file src/extended/hmm.c, line 644.
This is probably a bug, please report.

this fails in the current master.
",Garonenur,https://github.com/genometools/genometools/issues/14,genometools++genometools.csv
MDU6SXNzdWUxNjUzMDU0MA==,Allow removal/deletion of feature nodes from the annotation graph,CLOSED,2013-07-09T15:20:39Z,2013-07-12T10:09:31Z,2013-07-12T10:09:31Z,"The functionality of removing a node from an annotation graph is still missing. This is important to gain full graph manipulation support, as it is the only operation missing IIRC. 

We need to agree on an API, with the following questions in mind:
- Do we only support to remove leaves or also internal nodes (and their children, if not otherwise connected to the CC)?
- How do we modify refcounts?
- How do we update the tree/non-tree property?
",satta,https://github.com/genometools/genometools/issues/19,genometools++genometools.csv
MDU6SXNzdWUxNjUzMTkxNQ==,travis build time,CLOSED,2013-07-09T15:44:07Z,2013-07-10T15:13:09Z,2013-07-10T11:54:10Z,"the travis build time depends mainly on our ruby testsuite.
I will split the tests up, so every build will be done multiple times with different tests.
",Garonenur,https://github.com/genometools/genometools/issues/20,genometools++genometools.csv
MDU6SXNzdWUxNzM4NTY3MA==,make compact ulong store dynamic,OPEN,2013-07-30T09:27:46Z,2014-06-11T12:13:26Z,,"right now, compact ulong store is as class to store fixed width values of arbitrary widths in an array like fashion.
Its only drawback in my opinion is its rigidity, the number of elements to be stored has to be known in advance.

I think it would be fairly easy to change this to be dynamic, resizing the array when setting values outside of the bounds.

What do you think?
",Garonenur,https://github.com/genometools/genometools/issues/35,genometools++genometools.csv
MDU6SXNzdWUxNzUwMzQ3Ng==,store encseq to disk from EncseqBuilder,OPEN,2013-08-01T12:03:03Z,2014-06-11T12:13:26Z,,"there is no possibility to generate an encseq within memory and then store it directly to hard disk. 
it would be nice to create an encseq with EncseqBuilder and then store it. right now, I have to write the sequences into a FASTA file and then convert the FASTA file to an encseq
",oeigenbrod,https://github.com/genometools/genometools/issues/36,genometools++genometools.csv
MDU6SXNzdWUxNzUxNTM0Nw==,Include API - extern variables in documentation,CLOSED,2013-08-01T16:00:10Z,2013-08-01T23:16:04Z,2013-08-01T23:16:04Z,"I am currently working on an extension to the automatic documentation for the API to include extern variables.
If these are part of a module it works fine, but if defined within a class file there need to be changes for them to be recognized.
I will add 2 modules that will benefit from this later.

Right now there is only the `gt_jobs` variable in `core/thread_api.h` and to include this into the API (which in itself makes sense) there are 3 possible changes:
- rename gt_jobs so it will be recognized as part of one of the classes in threads_api.h. It has to be moved on a line after the class is defined for that to work.
- move `gt_jobs` to `multithread_api` which is a module. This could be complicated, because the definition has to be moved to.
- by far the easiest way: add a comment line before the extern variable, with an Name and codeword module in it. This will add a module with only that variable to the documentation. I propose to name the module Thread like the file it resides in.
",Garonenur,https://github.com/genometools/genometools/issues/37,genometools++genometools.csv
MDU6SXNzdWUxNzU0MzAwNg==,Node stream for resetting GtFeatureNode source,CLOSED,2013-08-02T03:28:54Z,2013-08-05T14:00:13Z,2013-08-02T08:22:09Z,"Features created in memory by default have no source. When working with these, perhaps in combination with feature nodes from other sources, a node stream that enables resetting `GtFeatureNode` source values would be very helpful.
",standage,https://github.com/genometools/genometools/issues/41,genometools++genometools.csv
MDU6SXNzdWUxNzU1NzE3MA==,bit pack string module unit test fails with seed 509083971,CLOSED,2013-08-02T12:14:36Z,2013-08-05T14:53:42Z,2013-08-05T14:53:42Z,"this was recognized when travis failed only on one build but not the others.
This also fails with older versions of gt.

```
Assertion failed: (numBitsList[0] <= sizeof (val[0])*CHAR_BIT), function gt_bsStoreNonUniformUInt8Array, file src/core/bitpackstringop8.c, line 513.
```
",Garonenur,https://github.com/genometools/genometools/issues/44,genometools++genometools.csv
MDU6SXNzdWUxNzY4MTYxOA==,gt_ensure uses err,CLOSED,2013-08-06T09:55:11Z,2013-08-07T14:47:50Z,2013-08-07T14:47:50Z,"gt_ensure is an makro in the form of a funciton, it uses GtError err without err being one of the parameters of that makro.
this should be changed to:

``` C
#define gt_ensure(had_err, err, exp)
```
",Garonenur,https://github.com/genometools/genometools/issues/47,genometools++genometools.csv
MDU6SXNzdWUxNzc1MTE4MA==,Seed for Testsuite,CLOSED,2013-08-07T14:32:10Z,2013-08-26T10:03:09Z,2013-08-26T10:03:09Z,"Right now there is no way to find the seed with which a testsuite run was started.
So if travis fails just on one test and this is not reproducible, this might be due to some random value, which is very hard to debug without the seed.

Here are some ideas to fix this:

testsuite.rb produces random number, outputs this number and uses this number as a seed for all tests in that run.

To pass the seed value to all the thousands of tests each calling gt multiple times one either has to change all the calls to gt in the testsuite and add -seed=X or we change the gt binary to check for an environmental variable GT_SEED. If defined it will use this. So the testsuite simple has to set that variable and no test-code has to be changed.
The gt-option -seed takes precedence over GT_SEED for those cases where a specific test has to use exactly one seedvalue and the testsuite only generates a random value if GT_SEED is not defined so it is possible to reproduce errors within the testsuite depending on random values.
[edit: typos]
",Garonenur,https://github.com/genometools/genometools/issues/49,genometools++genometools.csv
MDU6SXNzdWUxODE3ODQzNA==,Add *_try_cast functions to API,CLOSED,2013-08-16T20:55:36Z,2013-08-23T11:55:22Z,2013-08-23T11:55:22Z,"The `GtNodeVisitor` interface provides a flexible solution for processing genome nodes. The various `*_try_cast` functions are not nearly as elegant, but can be quite useful. Unfortunately, they are not yet part of the public API. I suggest exposing these functions to 3rd party users.
",standage,https://github.com/genometools/genometools/issues/52,genometools++genometools.csv
MDU6SXNzdWUxODE3ODY3Mg==,Make class alloc lock module API public,CLOSED,2013-08-16T21:00:42Z,2013-08-17T14:13:47Z,2013-08-17T13:33:51Z,"The `GtAllocLock` module is used in node stream and node visitor implementations for thread safety while casting (if I understand correctly). Both the node stream interface and the node visitor interface are described in the public API, but the `GtAllocLock` module is not accessible in the public API, which makes it unavailable for use by third party implementations leveraging these interfaces. I suggest we make this module available via the public API.
",standage,https://github.com/genometools/genometools/issues/53,genometools++genometools.csv
MDU6SXNzdWUxODQzMjk0Nw==,Outstream using feature index,CLOSED,2013-08-22T19:05:57Z,2013-08-27T11:42:34Z,2013-08-27T11:42:34Z,"The `GtFeatureStream` class is convenient when the data to be processed will ultimately reside in a `GtFeatureIndex` object--analogous to the `GtArrayInStream` class for `GtArray` objects.

However, no analog of the `GtArrayOutStream` class exists for feature index. This would also be convenient to facilitate use of a feature index as the starting point for a node stream.
",standage,https://github.com/genometools/genometools/issues/56,genometools++genometools.csv
MDU6SXNzdWUxODUxMjY4Nw==,GenomeTools Windows Port,OPEN,2013-08-24T21:30:20Z,2017-06-12T21:52:43Z,,"I'm currently porting GenomeTools to Windows (MinGW).
Some notes can be found here:
https://github.com/genometools/genometools/wiki/GenomeTools-Windows-Port
I'm pushing in this branch:
https://github.com/gordon/genometools/tree/windows
It's not ready for a pull request, though. Comments welcome.
",gordon,https://github.com/genometools/genometools/issues/61,genometools++genometools.csv
MDU6SXNzdWUxODUyNzE1MQ==,make manuals fails,CLOSED,2013-08-25T21:33:43Z,2013-08-26T09:35:29Z,2013-08-26T09:33:23Z,"On my Ubuntu Linux 32-bit machine `make manuals` fails with:

```
! LaTeX Error: File `bbm.sty' not found.
```

and the file bbm.sty is not part of GenomeTools.
Is this a bug or do I have to install another Latex package?
",gordon,https://github.com/genometools/genometools/issues/62,genometools++genometools.csv
MDU6SXNzdWUxODUyNzM4NA==,unsigned long on Windows,CLOSED,2013-08-25T21:53:49Z,2013-09-06T15:31:14Z,2013-09-06T15:31:14Z,"The implicit assumption we make in GenomeTools so far is that `unsigned long` has the word size of the machine (4 byte on 32-bit systems and 8 byte on 64-bit systems).
Unfortunately, on Windows `unsigned long` is always 4 bytes wide which leads to problems in the code.

How to we want to deal with this problem? We could reuse `GtUlong` (or introduce `GtUword`) in such a way that the `unsigned long` behaviour on Linux is mirrored on Windows for `GtUlong` and use `GtUlong` where appropriate.

Or we switch to types which always have a defined size, regardless of the machine.
No matter what, we have to make sure that we don't break existing APIs.

Any comments?
",gordon,https://github.com/genometools/genometools/issues/63,genometools++genometools.csv
MDU6SXNzdWUxODU0NjYxOA==,"gt_malloc _realloc etc and the ""possible NULL pointer"" problem",CLOSED,2013-08-26T12:38:45Z,2013-08-29T14:26:59Z,2013-08-29T14:26:59Z,"Hi,

as I see it our memory allocation functions will never return NULL, right?

Is there a way to make compilers and static checkers aware of that? There are many gt_asserts checking this after calling a function that uses gt_malloc. As I see it makes sense to assert for not NULL in a function that gets a pointer as parameter, but not after calling gt_malloc.

And: compiling with assert=no results in static checkers complaining about possible NULL-pointer dereference.
",Garonenur,https://github.com/genometools/genometools/issues/67,genometools++genometools.csv
MDU6SXNzdWUxODU5NjQ1MQ==,Documentation for deprecated functions and renaming API-functions,OPEN,2013-08-27T09:29:26Z,2014-06-11T12:13:26Z,,"as I mentioned here: #68 it would be nice if there was something to mark functions as deprecated in the docu. One could mention it in the comment, but changing the text colour or something?

And the second Idea: If the API-change is a simple renaming, it is possible to use a typedef to introduce the new function name, but it will not appear in the docu, how about adding functionality to recognize such things and document them as if they were functions?
I think its complicated but might be interesting if more API-changes are proposed in the future.
",Garonenur,https://github.com/genometools/genometools/issues/72,genometools++genometools.csv
MDU6SXNzdWUxODY3MDk1OA==,current master does not do much with make test,CLOSED,2013-08-28T14:09:42Z,2013-08-28T14:17:06Z,2013-08-28T14:17:06Z,"bin/gt -test gets executed but no test starts with the testsuite.
",Garonenur,https://github.com/genometools/genometools/issues/75,genometools++genometools.csv
MDU6SXNzdWUxODcyOTk4Mw==,~0 is a bad choice to represent an undefined INT.,CLOSED,2013-08-29T13:15:47Z,2013-09-03T17:51:41Z,2013-08-29T17:49:14Z,"GT_UNDEF_INT is defined as ~0, which on systems using 2s complement (is there any current system where it is not?) means -1.

I think a better choice would be to define it as INT_MIN or INT_MAX: -1 is a value which _does_ often mean something. Indeed I noticed this for example because I created in my development branch an integer option which has -1 as default value and the parser shows in this case ""default: undefined"" (which per se can be fixed by showing the default manually, but this is not the point).
",ggonnella,https://github.com/genometools/genometools/issues/76,genometools++genometools.csv
MDU6SXNzdWUxODc0Mjc0MA==,Signature for 'gt_feature_index_has_seqid',CLOSED,2013-08-29T16:51:37Z,2013-08-29T17:27:02Z,2013-08-29T17:27:02Z,"It seems a bit strange that the function always returns a 0 and accepts a pointer to a boolean. Is there a particular reason for this function signature instead of just returning the boolean?
",standage,https://github.com/genometools/genometools/issues/78,genometools++genometools.csv
MDU6SXNzdWUxODc0ODM1Ng==,AnnotationSketch weirdness,OPEN,2013-08-29T18:25:21Z,2018-04-14T12:47:14Z,,"I encountered some strange behavior with the sketch API recently, and I've isolated a small use case to reproduce it. See http://gremlin2.soic.indiana.edu/tmp/sketch-issue/.

When I run with the default files (first command in README), a separate track is created for the 5' UTR but also seems to duplicate the 3' UTR.
![default](https://f.cloud.github.com/assets/566823/1052146/23774962-10d8-11e3-883b-d562e0ac5545.png)

When I remove the ID from the 5' UTR (second command in README), everthing renders correctly.
![sansids](https://f.cloud.github.com/assets/566823/1052145/237a63a4-10d8-11e3-868c-e9b823917fc5.png)

Bug with the AnnotationSketch logic?
",standage,https://github.com/genometools/genometools/issues/79,genometools++genometools.csv
MDU6SXNzdWUxOTEwNzIzNw==,Travis runtime enhancement,CLOSED,2013-09-06T14:08:43Z,2013-09-10T22:45:05Z,2013-09-10T22:45:05Z,"I have to take a closer look at travis for this, but looking at the run times of our many travis tests, clang compiled code performs better.
It should be possible to compile with gcc and run gt -test, but do all the other tests only with clang, this would reduce the total runtime and I doubt that we find bugs that are compiler dependant.
",Garonenur,https://github.com/genometools/genometools/issues/89,genometools++genometools.csv
MDU6SXNzdWUxOTExMjg2Mg==,Documentation of the allowed types,OPEN,2013-09-06T15:49:03Z,2014-12-10T14:01:52Z,,"Currently it is not written in the developer manual (at least I did not find it).
",ggonnella,https://github.com/genometools/genometools/issues/90,genometools++genometools.csv
MDU6SXNzdWUxOTExNDEzMQ==,Renaming UNDEF macros,CLOSED,2013-09-06T16:11:11Z,2013-09-13T14:48:42Z,2013-09-13T14:48:42Z,"I think the GT_UNDEF_ULONG and GT_UNDEF_LONG macro should be renamed to GT_UNDEF_UWORD and GT_UNDEF_WORD. 
",ggonnella,https://github.com/genometools/genometools/issues/91,genometools++genometools.csv
MDU6SXNzdWUxOTExNDIxOA==,Range macros for new types.,CLOSED,2013-09-06T16:13:18Z,2013-09-08T06:00:25Z,2013-09-08T06:00:25Z,"type_api.h should also define the macros GT_WORD_MIN, GT_WORD_MAX, GT_UWORD_MAX to support the GtUword and GtWord types.
",ggonnella,https://github.com/genometools/genometools/issues/92,genometools++genometools.csv
MDU6SXNzdWUxOTExNTEyMQ==,make spgt fails,CLOSED,2013-09-06T16:30:38Z,2013-09-09T19:06:10Z,2013-09-09T19:06:10Z,"After the change to Gt(Uw|W)ord, make spgt outputs hundreds of warnings.
",ggonnella,https://github.com/genometools/genometools/issues/93,genometools++genometools.csv
MDU6SXNzdWUxOTE0NTc1MA==,Rename option_new for (u)long,CLOSED,2013-09-07T14:45:04Z,2013-09-09T10:33:12Z,2013-09-09T10:33:12Z,"The methods:

```
gt_option_new_long
gt_option_new_ulong
gt_option_new_ulong_min
gt_option_new_ulong_min_max
```

should be renamed to

```
gt_option_new_word
gt_option_new_uword
gt_option_new_uword_min
gt_option_new_uword_min_max
```

in order to reflect the type of variable where the value is stored after the change to GtUword/GtWord.
",ggonnella,https://github.com/genometools/genometools/issues/104,genometools++genometools.csv
MDU6SXNzdWUxOTE1MTU3OQ==,Name of the printf macros GT_LU etc,CLOSED,2013-09-07T21:00:24Z,2013-09-13T14:48:42Z,2013-09-13T14:48:42Z,"I think a good name for the macros such as `GT_LU` should reflect the fact that they are for `GtUword` and `GtWord`. Instead LU only refers to the ""lu"", which is not always true, and this is the reason why the macro exists.

Therefore, I propose renaming the macros to `GT_WU`, `GT_WUS`, `GT_WD`, `GT_WDS`.
",ggonnella,https://github.com/genometools/genometools/issues/106,genometools++genometools.csv
MDU6SXNzdWUxOTI5NjY3OA==,Setting ID attribute for feature nodes,CLOSED,2013-09-11T02:48:40Z,2013-09-11T23:39:59Z,2013-09-11T23:39:59Z,"The API documentation states that `gt_feature_node_set_attribute` and `gt_feature_node_add_attribute` should not be used for ID and Parent attributes. This makes sense to some extent, but what about for features created in memory using the API? For example, I have code that creates several coding sequences in memory and then outputs them. I try to set IDs via the API--I get no error/warning messages, but the ID attribute remains unchanged and I still get warning messages like

```
warning: feature ID """" not unique: changing to .1
warning: feature ID """" not unique: changing to .2
```

Comments or suggestions?
",standage,https://github.com/genometools/genometools/issues/115,genometools++genometools.csv
MDU6SXNzdWUxOTM5MDgwNA==,src_check is to aggressive,CLOSED,2013-09-12T14:39:24Z,2013-09-13T13:32:35Z,2013-09-13T09:59:50Z,"the word ""long"" is not that uncommon in strings for some printout but triggers the warning in src_check.

is there a way around that that does not need a c-parser?
",Garonenur,https://github.com/genometools/genometools/issues/118,genometools++genometools.csv
MDU6SXNzdWUxOTQxNzc4Mw==,"SVG suggestion, if possible.",OPEN,2013-09-12T21:56:31Z,2014-06-11T12:13:27Z,,"I don't know how complicated this would be, but it would be great if there was away to add SVG mouseover or click actions to AnnotationSketch. I've been using it very successfully now for a while to generate hard-coded images that I can send to coworkers without requiring them to access a database or paying an expensive commercial license for VectorNTI when all we need is very simple a Genbank/gff viewer (ie not Artemis). It would be even more useful to be able to layer additional information (ie nucleotide positions, or even whole sequences) into the image without cluttering up labels. 

It looks like you use Cairo to render, and the resulting SVGs are not a bit human readable, so I have no idea of the complexity here, but I also have no familiarity with Cairo. But mouseover and click events are built into the SVG spec, so maybe it's not impossible? Just a thought. 

And thanks for the great set of tools!
",danudwary,https://github.com/genometools/genometools/issues/122,genometools++genometools.csv
MDU6SXNzdWUxOTU1NzE0OQ==,test 'gt repfind small' fails for some seeds,CLOSED,2013-09-16T15:24:47Z,2013-09-25T11:37:19Z,2013-09-25T11:37:19Z,"seeds where it fails to run:

```
471897537
71207745
```

errormessage in both cases but at different stages of program progress:

```
Assertion failed: (queryrep != NULL && pos < queryrep->length), function gt_mmsearch_accessquery, file src/match/esa-mmsearch.c, line 55.
```
",Garonenur,https://github.com/genometools/genometools/issues/128,genometools++genometools.csv
MDU6SXNzdWUyMzMwOTYyNw==,expand gt encseq info,CLOSED,2013-11-26T11:57:34Z,2014-01-28T17:25:51Z,2014-01-28T17:25:51Z,"this all assumes that files usually represent some logical subset of a sequence set in an encseq
- [x] number of sequences per file
- [x] smallest / largest sequence per file
- [x] N50 total
- [x] N50 per file
- [x] human readable output option (kilo, mega etc)

alternatively this could be in a different subtool seqstats or similar
",Garonenur,https://github.com/genometools/genometools/issues/150,genometools++genometools.csv
MDU6SXNzdWUyMzM3OTE2OA==,GtSeqabstract len issues,CLOSED,2013-11-27T10:44:41Z,2014-02-09T12:12:54Z,2014-02-09T12:12:54Z,"The Class GtSeqabstract needs a parameter len, this is not used in any way.

The class does therefore not work as intuitively guessed.

There is some serious refactoring needed, and unit test should be added, to show how the class is intended to be used.
",Garonenur,https://github.com/genometools/genometools/issues/151,genometools++genometools.csv
MDU6SXNzdWUyNDE4NDM5MQ==,Multi-features with different attributes,CLOSED,2013-12-12T15:10:49Z,2013-12-13T14:56:07Z,2013-12-13T14:24:00Z,"Hi everyone (e.g. @gordon ),

is there a specific reason why we are disallowing multi-features with different attributes? I have a few CDS's here containing an additional 'rank' attribute which takes different values. I had a look at the spec, and I could not find any mention of this restriction.

Sascha
",satta,https://github.com/genometools/genometools/issues/153,genometools++genometools.csv
MDU6SXNzdWUyNDE4NjY5NQ==,clang 3.4 does not compile tre library,CLOSED,2013-12-12T15:44:28Z,2013-12-20T10:34:29Z,2013-12-20T10:34:29Z,"src/external/tre/lib/tre-compile.c does not compile with clang 3.4, because it complains about

errcode = errcode

they use goto there in that part of the code. I felt bad for just reading that.

hadn't we some problems with warnings in external code befor? Is it possible to turn them off for some of the external stuff? (Preverably all of it, because we are not the maintainers of the external files.)
",Garonenur,https://github.com/genometools/genometools/issues/154,genometools++genometools.csv
MDU6SXNzdWUyNDQ5NTYxNg==,get random sequences with encseq decode,CLOSED,2013-12-18T15:14:14Z,2014-01-28T17:24:27Z,2014-01-28T17:24:27Z,"add an option to encseq decode that takes a number as a parameter and extracts this number of random sequences from the encseq.

no duplicates

maybe extend this, so that parameter can be total length of extracted sequences.
",Garonenur,https://github.com/genometools/genometools/issues/160,genometools++genometools.csv
MDU6SXNzdWUyNDUwMDMyNg==,join more tools in toolboxes,OPEN,2013-12-18T16:22:07Z,2014-09-13T19:32:56Z,,"the list of tools is quite long,

some tools, like csa and cds do similar things, in this case for gff3. These could be put into one toolbox, to shorten the list of tools.
",Garonenur,https://github.com/genometools/genometools/issues/162,genometools++genometools.csv
MDU6SXNzdWUyNDU1NjYyMw==,type checker part_of reflexivity,CLOSED,2013-12-19T13:40:57Z,2013-12-19T15:28:17Z,2013-12-19T15:28:17Z,"The type checker currently reports for any feature type that it is _part_of_ itself, which is obviously not always correct but rather depends on the contents of the underlying ontology. The reason for that behaviour is that in `gt_type_node_has_parent` in that case the check for parent and child ID equality (which I guess was intended for recursion termination) is always triggered right away, without looking at the ontology.

To fix this one would have to base every decision solely on what is in the adjacency matrices for the ontology DAG, using recursive search in the nodes only to extend the matrices. @gordon do you agree?
",satta,https://github.com/genometools/genometools/issues/164,genometools++genometools.csv
MDU6SXNzdWUyNDU2MjQ3NQ==,Add parser for Dbxref abbreviations and validate their format in GFF3 ,CLOSED,2013-12-19T15:21:43Z,2013-12-22T18:58:33Z,2013-12-22T18:58:33Z,"The GFF3 spec states that Dbxref and Ontology_term attributes should have the form DBTAG:ID where the list of valid DBTAGs comes from a separate abbreviation file defined here: ftp://ftp.geneontology.org/pub/go/doc/GO.xrf_abbs_spec

We should be able to parse such a file and use its content to validate the values of Dbxref and Ontology_term reserved attributes in GFF3 files. 
",satta,https://github.com/genometools/genometools/issues/165,genometools++genometools.csv
MDU6SXNzdWUyNDY4NTI1Ng==,Usage of -usedesc/-matchdesc/MD5 ,CLOSED,2013-12-22T18:18:07Z,2014-01-28T16:57:23Z,2014-01-28T10:47:18Z,"AFAICS, when someone uses `-seqfile`, `-seqfiles`, and `-encseq` to specify a sequence to be used in a tool (using the GtRegionMapping interface), they must decide how to map sequence IDs (e.g. headers) to region IDs in an annotation. This is currently done by specifying `-usedesc` or `-matchdesc` options, or by tagging region IDs with MD5 hashes identifying the respective sequences, in which case the connection is made automagically. However, it is currently possible not to specify `-usedesc` or `-matchdesc` options as they are not mandatory. So in principle, it is possible to give a sequence file (or a GtEncseq, or a set of sequence files) with no hint about region mapping and no MD5 tagging. In this case, the first sequence in the set is (silently) taken as the source for all regions in the annotation. This can be very confusing and misleading if someone simply expects things to work (e.g. when using legacy LTRharvest output with 'seq0', 'seq1'... tags as input for the new LTRdigest which supports `-seqfile`, `-seqfiles`, and `-encseq`). All you eventually get is an error message if you try to access regions outside the sequence length. 
Is there any reason why this behaviour was there in the first place? I am fairly certain I did not implement it on purpose like this, but there were tests that expected it IIRC. I'd propose the following as a suggestion to make things more straightforward:
- Usually expect  `-usedesc` or `-matchdesc` as options if someone uses `-seqfile`, `-seqfiles`, and `-encseq` 
- If `-regionmapping` is used, use the entries in the mapping file to refer to the first sequence in the respective sequence files
- If none of these is given, try to use MD5 mapping or _fail_ when no MD5 is present!

In this case, users would not get unexpected results. Any comments or ideas?
",satta,https://github.com/genometools/genometools/issues/168,genometools++genometools.csv
MDU6SXNzdWUyNDY5NjE1MA==,check format of GFF3 Gap attribute,CLOSED,2013-12-23T06:52:54Z,2013-12-23T15:23:12Z,2013-12-23T15:23:12Z,"The GFF3 format specifies a _Gap_ attribute used for describing alignments in detail using a CIGAR-like string. It would be nice if the GenomeTools were able to check this string for validity, both syntactically as well as length-wise (i.e. comparing the number of matches and indels vs. the length of the feature).
",satta,https://github.com/genometools/genometools/issues/170,genometools++genometools.csv
MDU6SXNzdWUyNDcwNjU4MA==,Implement complete relationship resolution.,CLOSED,2013-12-23T13:43:27Z,2014-09-06T09:50:31Z,2014-09-06T09:50:31Z,"In the current implementation, part_of relationships are not inherited by child terms in an is_a relationship from their parent term. Example: _match_part_ is currently not recognized by the _GtTypeChecker_ as being part_of _cDNA_match_, but _match_part_ is generally part_of a _match_, and _cDNA_match_ is_a _match_. This breaks relationship checking in such cases. As other SO-aware projects must have solved this problem somehow, I will read http://www.gmod.org/wiki/Chado_CV_Module#Transitive_Closure in detail and try to find out how to do this accurately.
",satta,https://github.com/genometools/genometools/issues/172,genometools++genometools.csv
MDU6SXNzdWUyNDc0MDk5NA==,GFF3 validator should not stop on first error,OPEN,2013-12-24T09:40:01Z,2014-09-09T06:57:26Z,,"Currently, the GFF3 parser stops on and outputs only the first error encountered in the input. For automated use, e.g. in a GFF/Git-based annotation tracking system, it might be convenient to have it output _all_ errors instead of only the first one. This functionality could, for example, be optional in the parser or input stream, so it may be activated in the validator tool but not in the other GtGFF3InStream-using tools. 
I see that is difficult to do because we try to ensure that everything that comes out of an input stream is guaranteed to be valid, and some errors simply cannot lead to valid annotation graphs. However, one might restrict this more relaxed error output to typically non-fatal errors in GFF3 input.
",satta,https://github.com/genometools/genometools/issues/173,genometools++genometools.csv
MDU6SXNzdWUyNDk1ODMxNA==,"Assertion messages (""This is a bug, report it"") should include link to GitHub issue tracker.",CLOSED,2014-01-02T10:42:59Z,2014-01-07T12:39:43Z,2014-01-02T14:06:51Z,"These messages should also include a link to the issue tracker to make sure that bugs receive more attention and can be handled in a centralized way. Moreover, issues and their solutions become searchable in the web interface.
",satta,https://github.com/genometools/genometools/issues/175,genometools++genometools.csv
MDU6SXNzdWUyNTE1ODMyNg==,wrong line number in encseq encode error message,CLOSED,2014-01-07T10:24:13Z,2014-01-11T18:26:51Z,2014-01-11T18:26:51Z,"When using encseq encode with -protein argument and the input below, an error is reported in line 3 although the lower case character causing the error is located in line 4.
Why does a lower case character cause an error at all? If the -protein argument is not given, there is no error.

Edit: there are other examples where the error occurs although the -protein argument is not given.

Input fasta file:

```
>YAL001C
M
>YAL002W
Ms
```
",kowsky,https://github.com/genometools/genometools/issues/179,genometools++genometools.csv
MDU6SXNzdWUyNTI3MDgwMg==,Issues with GtFeatureOutStream class,CLOSED,2014-01-08T20:52:53Z,2014-01-09T13:10:45Z,2014-01-09T13:10:45Z,"I just noted two concerns with the `GtFeatureOutStream` class.
- The **seqstr** object (`GtStr *`) is not being freed properly.
- The **regioncache** object (`GtArray`) is being used as a queue, whereas the `GtQueue` is of course better suited for this. (The **featurecache** object is also being used as a queue, but since it is being created by another function, it doesn't make sense to copy all of the data to a new queue--reversing the array and popping entries is an acceptable alternative in this case).
",standage,https://github.com/genometools/genometools/issues/182,genometools++genometools.csv
MDU6SXNzdWUyNTQ4OTg0Mw==,Suffixerator -tis option,CLOSED,2014-01-13T11:00:53Z,2020-01-03T15:23:52Z,2014-01-13T15:32:59Z,"I'm using the gt suffixerator tool following the advice of the LTR Harvest user manual. So after database and indexname options, I'm specifying for options for: -tis -suf -lcp -des -ssp -sds -dna
This runs fine and gives file extensions: .des .esq .lcp .llv .md5 .prj .sds .ssp .suf
There is no .tis file - the user manual says this is necessary for LTR harvest to run. Sure enough, when I try it creates and out file and gff3 file that are empty. 
Any suggestions? I'm using gt 1.5.1
Thanks
",andrewstephenmason,https://github.com/genometools/genometools/issues/185,genometools++genometools.csv
MDU6SXNzdWUyNTUwMzkzNA==,Add support for End_range and Start_range attributes,CLOSED,2014-01-13T15:24:07Z,2014-01-14T01:03:45Z,2014-01-14T01:03:45Z,"GFF3 1.22 defines two new reserved attributes, _Start_range_ and _End_range_ (see http://www.sequenceontology.org/resources/gff3_1.22.html). The GFF3 parser should be aware of these and not treat them like illegal uppercase attributes. 
Ideally, in the long run, any plausibility checks on coordinates should use the  _Start_range_ and _End_range_ information  to allow ambiguity in the feature coordinates.
",satta,https://github.com/genometools/genometools/issues/186,genometools++genometools.csv
MDU6SXNzdWUyNTUwNDM5Ng==,Check for containment in parent-child coordinates  ,CLOSED,2014-01-13T15:30:09Z,2014-01-17T11:14:46Z,2014-01-17T11:14:46Z,"The GFF3 parser should check whether child features are contained within the coordinates of their parent features and output a warning if this is not the case. In tidy mode, it should also truncate the child to the boundaries of its parent.
",satta,https://github.com/genometools/genometools/issues/187,genometools++genometools.csv
MDU6SXNzdWUyNTU4MDU4Nw==,GFF3 file creation,CLOSED,2014-01-14T15:21:55Z,2014-01-14T15:45:25Z,2014-01-14T15:41:02Z,"When LTR Harvest generates gff3 files, how does it assign the sequence numbers? This is in reference to the when sequences need to be declared as ""seqX"" where X is a number. 
I'm trying to create a gff3 file from data output from another program and can't seem to correctly assign numbers so that the correct reference sequence is used. 
Any help would be great.
Cheers.
",andrewstephenmason,https://github.com/genometools/genometools/issues/193,genometools++genometools.csv
MDU6SXNzdWUyNTYzOTU4Mg==,add formating options to encseq decode,CLOSED,2014-01-15T10:59:47Z,2014-05-27T18:12:32Z,2014-05-27T18:12:32Z,"it should be possible to have formatted fasta output from encseq decode. Right now there is no -width parameter.

one can just pipe the output through one of the other tools, but that is a little overkill.
",Garonenur,https://github.com/genometools/genometools/issues/195,genometools++genometools.csv
MDU6SXNzdWUyNTY0MjgzOQ==,Weird booleans in Ruby bindings on Mac OS X,OPEN,2014-01-15T12:05:09Z,2014-08-12T12:49:49Z,,"Boolean values returned from C function calls are unpredictable on Mac OS X if they are checked for being equal/different from 0/1, probably due to 64/32-bit issues. Try using the BOOL type in the DL function prototypes to avoid this.
",satta,https://github.com/genometools/genometools/issues/196,genometools++genometools.csv
MDU6SXNzdWUyNTc0MDM2Mw==,GFF3 escaping,OPEN,2014-01-16T17:09:07Z,2016-05-02T11:32:14Z,,"I was just wondering whether GFF3 escaping is used in the GFF3 input/output streams at all?

```
[ss34@mib106184i:~/develop/genometools] git grep gt_gff3_escape
src/extended/gff3_escaping.c:static int gt_gff3_escape_hex2prnchar(const char* str, char *out)
src/extended/gff3_escaping.c:static void gt_gff3_escape_controlchar2hex(GtStr *escaped_seq, char ctrlchar)
src/extended/gff3_escaping.c:void gt_gff3_escape(GtStr *escaped_seq, const char *unescaped_seq,
src/extended/gff3_escaping.c:          gt_gff3_escape_controlchar2hex(escaped_seq, *cc);
src/extended/gff3_escaping.c:        int ret = gt_gff3_escape_hex2prnchar(cc, &x);
src/extended/gff3_escaping.c:    gt_gff3_escape(escaped_seq, unescaped_testseq, strlen(unescaped_testseq));
src/extended/gff3_escaping.h:void gt_gff3_escape(GtStr *escaped_seq, const char *unescaped_seq,
src/gth/sa.c:  gt_gff3_escape(sa->gff3_target_attribute, gt_str_get(sa->ref_id),
[ss34@mib106184i:~/develop/genometools] git grep gt_gff3_unescape 
src/extended/gff3_escaping.c:int gt_gff3_unescape(GtStr *unescaped_seq, const char *escaped_seq,
src/extended/gff3_escaping.c:    had_err = gt_gff3_unescape(unescaped_seq, gt_str_get(escaped_seq),
src/extended/gff3_escaping.c:    had_err = gt_gff3_unescape(unescaped, code, 10, err);
src/extended/gff3_escaping.c:  gt_ensure(gt_gff3_unescape(seq, ""foo%2"", 5, NULL));
src/extended/gff3_escaping.h:int  gt_gff3_unescape(GtStr *unescaped_seq, const char *escaped_seq,
src/extended/gff3_parser.c:    had_err = gt_gff3_unescape(unescaped_target,
src/tools/gt_extracttarget.c:    had_err = gt_gff3_unescape(unescaped_target,
```

I implemented that quite some time ago, but I always figured it would actually be used somewhere in a common place in the GFF output visitor or GFF parser. The parser only uses it for the target attribute, AFAICS. Am I missing something (like this was not done on purpose) or is this functionality actually missing?
",satta,https://github.com/genometools/genometools/issues/198,genometools++genometools.csv
MDU6SXNzdWUyNTc3Nzk2OA==,Feature streams not analogous to array streams,CLOSED,2014-01-17T00:14:21Z,2014-01-17T12:05:36Z,2014-01-17T12:05:36Z,"@gordon's implementation of `GtFeatureStream` provides the functionality to capture feature nodes from a stream into a feature index. This is analogous to the `GtArrayOutStream`, that allows similar capture of nodes into an array.

A while ago I implemented a new class to provide complementary functionality--feeding nodes _into_ a stream from a feature index. This is analogous to the `GtArrayInStream` class.

However, when I implemented the new class and updated the API, I got the **in** and **out** labels reversed. The `GtArrayOutStream` captures nodes and the `GtArrayInStream` delivers nodes, while `GtFeatureInStream` captures nodes and  `GtFeatureOutStream` delivers nodes.

This should be resolved so naming conventions are consistent.
",standage,https://github.com/genometools/genometools/issues/199,genometools++genometools.csv
MDU6SXNzdWUyNTk1MDMyMg==,GtFeatureInStream featorig bug,CLOSED,2014-01-20T22:12:08Z,2014-01-21T08:18:15Z,2014-01-21T08:18:15Z,"With #201 I added some functionality to the `GtFeatureInStream` class, allowing the programmer to choose whether `GtRegionNode`s delivered to the node stream should use ranges inferred from the feature nodes (default behavior) or from the feature index's region nodes.

Unfortunately, by the time the user can call the function, all ranges have already been processed. Because I have not implemented any automated testing for this class, I didn't catch the bug right away.

So there are two issues that need to be addressed with the `GtFeatureInStream` class.
- Fix the `gt_feature_in_stream_use_orig_ranges` function.
- Add a simple unit test for the class.
",standage,https://github.com/genometools/genometools/issues/202,genometools++genometools.csv
MDU6SXNzdWUyNjExNzkzMw==,GtLTRdigestPdomVisitor memleaks,CLOSED,2014-01-22T19:57:20Z,2014-01-23T13:05:51Z,2014-01-23T13:05:51Z,"This class leaks memory as some GtStr and GtArray objects are not freed.

```
==32731== HEAP SUMMARY:
==32731==     in use at exit: 126,776 bytes in 855 blocks
==32731==   total heap usage: 302,021 allocs, 301,166 frees, 63,086,614 bytes allocated
==32731== 
==32731== 6,840 bytes in 171 blocks are definitely lost in loss record 1 of 5
==32731==    at 0x4C2C494: calloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==32731==    by 0x486859: gt_calloc_mem (ma.c:58)
==32731==    by 0x443512: gt_array_new (array.c:43)
==32731==    by 0x5DB67D: gt_ltrdigest_pdom_visitor_feature_node (ltrdigest_pdom_visitor.c:435)
==32731==    by 0x5264AE: visitor_stream_next (visitor_stream.c:40)
==32731==    by 0x4F7BFE: gt_node_stream_next (node_stream.c:94)
==32731==    by 0x526495: visitor_stream_next (visitor_stream.c:38)
==32731==    by 0x4F7BFE: gt_node_stream_next (node_stream.c:94)
==32731==    by 0x526495: visitor_stream_next (visitor_stream.c:38)
==32731==    by 0x4F7BFE: gt_node_stream_next (node_stream.c:94)
==32731==    by 0x4D7E93: gff3_out_stream_next (gff3_out_stream.c:41)
==32731==    by 0x4F7BFE: gt_node_stream_next (node_stream.c:94)
==32731==    by 0x4F7D5C: gt_node_stream_pull (node_stream.c:116)
==32731==    by 0x5D29EF: gt_ltrdigest_runner (gt_ltrdigest.c:630)
==32731==    by 0x4AB6CB: gt_tool_run (tool.c:107)
==32731==    by 0x408EA7: gtr_run (gtr.c:485)
==32731==    by 0x407B30: main (gt.c:40)
==32731== 
==32731== 25,376 (5,472 direct, 19,904 indirect) bytes in 171 blocks are definitely lost in loss record 3 of 5
==32731==    at 0x4C2A2DB: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==32731==    by 0x4866D5: gt_malloc_mem (ma.c:73)
==32731==    by 0x4A70E6: gt_str_new (str.c:38)
==32731==    by 0x5DA462: gt_ltrdigest_pdom_visitor_parse_alignments (ltrdigest_pdom_visitor.c:339)
==32731==    by 0x5DB875: gt_ltrdigest_pdom_visitor_feature_node (ltrdigest_pdom_visitor.c:442)
==32731==    by 0x5264AE: visitor_stream_next (visitor_stream.c:40)
==32731==    by 0x4F7BFE: gt_node_stream_next (node_stream.c:94)
==32731==    by 0x526495: visitor_stream_next (visitor_stream.c:38)
==32731==    by 0x4F7BFE: gt_node_stream_next (node_stream.c:94)
==32731==    by 0x526495: visitor_stream_next (visitor_stream.c:38)
==32731==    by 0x4F7BFE: gt_node_stream_next (node_stream.c:94)
==32731==    by 0x4D7E93: gff3_out_stream_next (gff3_out_stream.c:41)
==32731==    by 0x4F7BFE: gt_node_stream_next (node_stream.c:94)
==32731==    by 0x4F7D5C: gt_node_stream_pull (node_stream.c:116)
==32731==    by 0x5D29EF: gt_ltrdigest_runner (gt_ltrdigest.c:630)
==32731==    by 0x4AB6CB: gt_tool_run (tool.c:107)
==32731==    by 0x408EA7: gtr_run (gtr.c:485)
==32731==    by 0x407B30: main (gt.c:40)
==32731== 
==32731== 94,560 (5,472 direct, 89,088 indirect) bytes in 171 blocks are definitely lost in loss record 5 of 5
==32731==    at 0x4C2A2DB: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==32731==    by 0x4866D5: gt_malloc_mem (ma.c:73)
==32731==    by 0x4A70E6: gt_str_new (str.c:38)
==32731==    by 0x5DA452: gt_ltrdigest_pdom_visitor_parse_alignments (ltrdigest_pdom_visitor.c:338)
==32731==    by 0x5DB875: gt_ltrdigest_pdom_visitor_feature_node (ltrdigest_pdom_visitor.c:442)
==32731==    by 0x5264AE: visitor_stream_next (visitor_stream.c:40)
==32731==    by 0x4F7BFE: gt_node_stream_next (node_stream.c:94)
==32731==    by 0x526495: visitor_stream_next (visitor_stream.c:38)
==32731==    by 0x4F7BFE: gt_node_stream_next (node_stream.c:94)
==32731==    by 0x526495: visitor_stream_next (visitor_stream.c:38)
==32731==    by 0x4F7BFE: gt_node_stream_next (node_stream.c:94)
==32731==    by 0x4D7E93: gff3_out_stream_next (gff3_out_stream.c:41)
==32731==    by 0x4F7BFE: gt_node_stream_next (node_stream.c:94)
==32731==    by 0x4F7D5C: gt_node_stream_pull (node_stream.c:116)
==32731==    by 0x5D29EF: gt_ltrdigest_runner (gt_ltrdigest.c:630)
==32731==    by 0x4AB6CB: gt_tool_run (tool.c:107)
==32731==    by 0x408EA7: gtr_run (gtr.c:485)
==32731==    by 0x407B30: main (gt.c:40)

```
",satta,https://github.com/genometools/genometools/issues/204,genometools++genometools.csv
MDU6SXNzdWUyNjE1NzA2OQ==,GtLTRdigestPdomVisitor leaks file descriptors,CLOSED,2014-01-23T10:33:06Z,2014-01-23T13:05:51Z,2014-01-23T13:05:51Z,"During the `pipe`/`dup`/`fork` action not all file descriptors are closed properly. This leads on some platforms (Mac OS X) to runs terminating with 'Too many open files' when processing even moderately large data sets.
",satta,https://github.com/genometools/genometools/issues/205,genometools++genometools.csv
MDU6SXNzdWUyNjM3OTYxNA==,ORF finder sets wrong strand,CLOSED,2014-01-27T18:29:34Z,2014-01-28T12:01:58Z,2014-01-28T12:01:58Z,"Strands are inverted in GtORFfinderVisitor outputs.
",satta,https://github.com/genometools/genometools/issues/208,genometools++genometools.csv
MDU6SXNzdWUyNjM3OTcyNQ==,Consistent use of sequence-annotation mapping across LTR tools,OPEN,2014-01-27T18:31:07Z,2018-04-14T12:55:06Z,,"Some tools still rely on the `seq0`, `seq1`... naming scheme for sequence regions. For example, the LTR clustering and classification tools. They need to be adapted to use _GtRegionMapping_ input for sequence access. Right now the formats are incompatible.
",satta,https://github.com/genometools/genometools/issues/209,genometools++genometools.csv
MDU6SXNzdWUyNjQyNjg4MQ==,Python bindings segfault on Mac OS X,CLOSED,2014-01-28T09:47:17Z,2014-12-02T09:54:40Z,2014-12-02T09:54:40Z,"Some function calls in the Python bindings segfault on Mac OS X. Some quick investigation showed that implicit restype/argtype conversion in ctypes seems to work differently from Linux, and that all restype/argtypes must be explicitly defined in the FFI initialization (`register()` class method). Check for all classes whether this solves the issue.
",satta,https://github.com/genometools/genometools/issues/211,genometools++genometools.csv
MDU6SXNzdWUyNjQ1Mjg5NQ==,testsuite error 32bit,CLOSED,2014-01-28T16:04:22Z,2014-02-01T10:43:52Z,2014-02-01T10:43:52Z,"this is something funny, I compiled gt on my 64bit Ubuntu as a 32bit binary, compiling was fine.

then I ran the tests and get this in test 504 (gt ltrharvest missing tables (suf)):

```
Test 504 'gt ltrharvest missing tables (suf)': failed:
missing /cannot open file descriptor 'Random159.fna.suf'/ in stderr_2:
```

the content of stderr_2 is as follows:

```
gt32/bin/gt ltrharvest: error: fopen(): cannot open file 'Random159.fna.suf': No such file or directory
```

so, the error messages differ, depending on the bitness?

the problem lies is esa-map.c, lines 363 to 382. the 64bit-binary calls gt_file_size_with_suffix, the 32bit-binary does not.

Do I adjust the test to grep for both error messages, or do I adjust the code to fix this?
",Garonenur,https://github.com/genometools/genometools/issues/214,genometools++genometools.csv
MDU6SXNzdWUyNjYyNjA3MQ==,Feature stream memory management issues,CLOSED,2014-01-30T19:44:38Z,2014-02-07T00:04:24Z,2014-02-07T00:04:24Z,"I'm implementing a couple of node streams that utilize the following workflow.
- Use a `GtFeatureOutStream` to capture the incoming stream of nodes into a `GtFeatureIndex` object.
- Process the nodes in the feature object and store the processed nodes in another `GtFeatureIndex` object.
- Use a `GtFeatureInStream` to deliver the processed nodes from this `GtFeatureIndex` to the next step in the node stream.

I'm having some issues with memory management. When I delete everything properly, I'm running into segfaults and core dumps. I can selectively omit deleting some node stream or feature index objects, but of course this introduces memory leaks that could be a big problem for large data sets.

I've tried to reduce all this to a simple example to wrap my mind around it. See [this gist](https://gist.github.com/standage/8717134). Note that running with valgrind, it will report no memory leaks (except the 5 libpixman cases), but lots of invalid reads. Comment out either line 87 or 89 and the invalid read messages go away, but memory leaks are introduced.

I don't know why I'm struggling to grasp the problem here, but I really can't tell what the issue is. Any insight?
",standage,https://github.com/genometools/genometools/issues/217,genometools++genometools.csv
MDU6SXNzdWUyNjcwMTE1Mg==,python binding tests fail 32bit on 64bit machine,CLOSED,2014-01-31T17:24:03Z,2014-02-02T11:44:15Z,2014-02-02T11:44:15Z,"make curses=no cairo=no CFLAGS+=-fstrict-aliasing opt=no CC='clang' -j2 testthreads=2 amalagamation=yes test:
test616:
https://gist.github.com/Garonenur/8737247
test617:
https://gist.github.com/Garonenur/8737088
618:
https://gist.github.com/Garonenur/8737290
619:
https://gist.github.com/Garonenur/8737312

maybe this only works with a 32bit python present?
",Garonenur,https://github.com/genometools/genometools/issues/219,genometools++genometools.csv
MDU6SXNzdWUyNjkzOTcxNQ==,Gap attributes for multifeatures,CLOSED,2014-02-05T06:06:49Z,2014-02-07T21:47:49Z,2014-02-07T21:47:49Z,"The GFF3 spec describes two ways of encoding alignments: a single line with the alignment structure described entirely in the `Gap` attribute, or a multifeature with the alignment structure described by the different lines of the multifeature. The spec also makes it clear that these methods can be combined.

> The two types of representations can be mixed, allowing large aligned segments to have their own GFF line and score, while small gaps within them are represented using a Gap attribute.

GFF3 produced by NCBI's annotwriter (part of the NCBI C++ toolkit) declares `match` and `cDNA_match` features as multifeatures, but utilizes line-specific `Gap` attributes to list small gaps in the alignment structure. GenomeTools complains about this, with an error message suggesting that multifeatures should have the same Gap attribute for each line. Unless I'm reading something incorrectly, this seems to violate cases explicitly allowed by the GFF3 spec.

As an example, try downloading ftp://ftp.ncbi.nih.gov/genomes/Apis_mellifera/GFF/ref_Amel_4.5_top_level.gff3.gz and running it through `gt gff3`.
",standage,https://github.com/genometools/genometools/issues/224,genometools++genometools.csv
MDU6SXNzdWUyNjkzOTkwNA==,Handling of trans splicing,CLOSED,2014-02-05T06:14:08Z,2016-08-18T22:25:32Z,2015-01-25T18:53:13Z,"The _D. melanogaster_ genome has 2 genes with trans splicing annotated. As a result, the exons and CDS segments do not all share the same strand. This does not seem to be a problem for the exon features, since they are distinct from each other, but since the CDS is a multifeature, GenomeTools complains that not all CDS segments have the same strand.

This is a biologically valid, although admittedly rare, case. Perhaps this should generate only a warning and not an error? Will this have unintended consequences elsewhere?

To see the error, try downloading ftp://ftp.ncbi.nih.gov/genomes/Drosophila_melanogaster/RELEASE_5_48/CHR_3/NT_033777.gff and running it through `gt gff3`.
",standage,https://github.com/genometools/genometools/issues/225,genometools++genometools.csv
MDU6SXNzdWUyNjk4ODIzMA==,Handling fasta files,CLOSED,2014-02-05T19:09:28Z,2014-02-06T17:30:47Z,2014-02-06T17:30:47Z,"I can see the GFF3 parser's function for creating `GtSequenceNode` objects from FASTA entries in a GFF3 file, but I'm almost embarrassed to ask the typical method for handling sequences in Fasta files. It seems so basic, and yet I don't see any data structures or modules to facilitate this.

Is fasta parsing hard coded everywhere it's needed in GenomeTools, or are there any reusable functions/data structures? Ideally, and following the design pattern used throughout the library, we would have something like a `GtSequenceInStream` class for reading `GtSequenceNode` objects from a Fasta, and a `GtSequenceOutStream` outstream class for writing `GtSequenceNode` objects to a fasta file.

I feel like I'm missing something really big and obvious, and if so please point me to where I can read up. Thanks!
",standage,https://github.com/genometools/genometools/issues/226,genometools++genometools.csv
MDU6SXNzdWUyNzA2MDQ2MA==,gitter - open it and integrate travis?,CLOSED,2014-02-06T16:06:47Z,2014-04-03T11:07:22Z,2014-04-03T11:07:22Z,"currently the gitter-chatroom for genometool is only open to its maintainers. We could open this up, so that people with small questions could check there if anyone of the maintainers is online and ask directly.
Also it is possible to connect travis with the chatroom, so a message is send, if a travis run fails or finishes.

What do you all think about that?

we could add this button to the README : [![Gitter chat](https://badges.gitter.im/genometools.png)](https://gitter.im/genometools)
",Garonenur,https://github.com/genometools/genometools/issues/230,genometools++genometools.csv
MDU6SXNzdWUyNzIyNTgxMA==,Seqabstract changes break LTRharvest test cases,CLOSED,2014-02-09T16:45:34Z,2014-02-12T17:08:32Z,2014-02-12T17:08:32Z,"#229 seems to break LTRharvest tests (only run with gttestdata). Results are missing.
",satta,https://github.com/genometools/genometools/issues/237,genometools++genometools.csv
MDU6SXNzdWUyNzI1MDcyOQ==,test fails: 'gt cds bug',CLOSED,2014-02-10T09:24:35Z,2014-02-13T08:31:19Z,2014-02-12T21:40:26Z,"this test fails only with gttestdata included in the tests.

the error (stderr_1) message is:

```
[..]/genometools/testsuite/../bin/gt cds: error: no mapping rule given and no MD5 tags present in the query seqid ""region.fas|1"" -- no mapping can be defined
```
",Garonenur,https://github.com/genometools/genometools/issues/239,genometools++genometools.csv
MDU6SXNzdWUyNzM1ODk0OQ==,Warn when nonprintable characters are used in options,CLOSED,2014-02-11T16:00:09Z,2014-04-03T10:11:15Z,2014-04-03T10:11:15Z,"We have had some bug reports where a user seemingly copied the command line string for a `gt` call from somewhere and the options in the copied string contained some special multibyte characters (a long dash instead of a normal '-') leading to errors in option parsing that seemed somewhat non-obvious. I propose to emit a warning on the option parser level when any string in argv contains such a 'strange' character (as defined by `isprint(3)`) like the following:

```
warning: parameter 'XXXX' contains non-printable character 
```

In such cases, this would at least give the caller some idea about why the call does not work while it looks reasonable.
",satta,https://github.com/genometools/genometools/issues/241,genometools++genometools.csv
MDU6SXNzdWUyNzM2NjcyOQ==,gt merge will not merge GFF3s with inline sequences,CLOSED,2014-02-11T17:07:41Z,2014-02-12T00:21:56Z,2014-02-12T00:21:56Z,"Currently, when I try to merge GFF3s with sequences, I will get the error message that they are not sorted: 

```
$ bin/gt merge testdata/minimal_fasta.gff3 testdata/standard_fasta_example.gff3
bin/gt merge: error: the file testdata/minimal_fasta.gff3 is not sorted (example: line 5 and 6)
```

I would expect the merging to work with any kind of annotation content. I'm filing this as a bug unless it is a known and intended limitation.
",satta,https://github.com/genometools/genometools/issues/242,genometools++genometools.csv
MDU6SXNzdWUyNzQzNzgwOQ==,upcoming 1.5.2 release,CLOSED,2014-02-12T14:40:33Z,2014-02-18T10:09:03Z,2014-02-18T10:09:03Z,"It has been nearly a year since we released 1.5.1. What about we fix the failing tests and release a new version?
",gordon,https://github.com/genometools/genometools/issues/245,genometools++genometools.csv
MDU6SXNzdWUyNzQzOTcyOA==,'gt seqlensort'  test fails on Mac OS X,OPEN,2014-02-12T15:06:36Z,2014-08-06T07:11:04Z,,"Apparently on Mac OS X the encoded sequence output from 'gt seqlensort' causes a different 'gt encseq info' output than the one from 'gt encseq encode', causing a test to fail.
",satta,https://github.com/genometools/genometools/issues/246,genometools++genometools.csv
MDU6SXNzdWUyNzQ3MzE5NA==,GtFeatureInStream incorrectly handles unannotated sequences,CLOSED,2014-02-12T21:45:54Z,2014-02-14T14:16:09Z,2014-02-13T10:41:21Z,"In various parts of the `GtFeatureInStream` class, I wrote the code under the assumption that features will be attached to any sequence or region node which the node stream encounters. This leads to issues when the input includes `GtRegionNodes` with no corresponding `GtFeatureNodes`.
",standage,https://github.com/genometools/genometools/issues/249,genometools++genometools.csv
MDU6SXNzdWUyNzU5Nzg0OA==,Memory leak.,CLOSED,2014-02-14T14:16:09Z,2014-02-14T18:42:41Z,2014-02-14T18:42:41Z,"I fixed #249 with commit f6207beefb16089e685f3a262fe0f8df0c235eec, but unfortunately I introduced a small memory leak: the feature array is not freed properly when it is empty.
",standage,https://github.com/genometools/genometools/issues/253,genometools++genometools.csv
MDU6SXNzdWUyNzYxNjc5OQ==,'tidy' stop codon handling in GTF parser ,CLOSED,2014-02-14T18:56:10Z,2014-03-08T13:28:25Z,2014-03-08T13:25:15Z,"I am using the `gtf_to_gff3` tool to import some results from GeneMark-ES in GTF format. However, I was wondering why
- ...the `start codon` GTF feature type is not recognized at all, and
- ...the `stop_codon` GTF feature type is handled like a separate CDS, leading to duplicated CDS entries if the CDS includes the stop codon. In my GTF input it does, so I get overlapping CDS lines in my output GFF for the CDS and the stop codon.

I propose to make this behaviour configurable in the parser, as http://www.sequenceontology.org/resources/converter_readme.html does. So depending on this setting either the codon is ignored (as it is already included in the CDS) or the last CDS feature is actually extended to include the stop codon instead of adding a separate new CDS feature.
",satta,https://github.com/genometools/genometools/issues/255,genometools++genometools.csv
MDU6SXNzdWUyNzc4MjI1Nw==,Debian packages for 1.5.2,CLOSED,2014-02-18T10:11:55Z,2014-05-20T08:35:14Z,2014-05-20T08:35:14Z,"The GenomeTools packages should be updated to include the new upstream version.
",satta,https://github.com/genometools/genometools/issues/263,genometools++genometools.csv
MDU6SXNzdWUyNzc4MjMxMg==,Windows/Mac OS X binary packages for 1.5.2,CLOSED,2014-02-18T10:12:52Z,2014-02-20T07:58:05Z,2014-02-20T07:58:05Z,"These need to be rebuilt to include the new release.
",satta,https://github.com/genometools/genometools/issues/264,genometools++genometools.csv
MDU6SXNzdWUyODg3NzAxMA==,extractfeat tool should output feature IDs on request,CLOSED,2014-03-06T13:04:38Z,2014-03-06T16:21:30Z,2014-03-06T16:21:30Z,"Currently there is no way of telling the extractfeat tool to put feature IDs into the extracted FASTA headers if they are present. I am trying to pull out the proteins for an annotation using

```
gt extractfeat -type CDS -translate -seqfile foo.fas -matchdesc in.gff3
```

do something with the protein sequences, and match the results back to the original features, which right now is rather complicated. I propose to add a `-retainids` option to the extractfeat tool similar to the one in the GFF3 handling tools, and make it also honor the `GT_RETAINIDS` environment variable. This functionality would fall back to the old numbering scheme if a feature does not have an ID. 
",satta,https://github.com/genometools/genometools/issues/270,genometools++genometools.csv
MDU6SXNzdWUyOTAyMTMzMg==,seqabstract changes break LTRharvest,CLOSED,2014-03-08T13:18:53Z,2014-03-26T11:44:39Z,2014-03-11T16:33:36Z,"Commit 9071889e6f471cdc34bcc297ecd86bc25d8071b9 seems to break LTRharvest when run on some indices with multiple sequences. I was able to trigger this problem using the _Leishmania major_ genome (ftp://ftp.sanger.ac.uk/pub/pathogens/Leishmania/major/Current/LmjF_v6.1_20131105/fasta/LmjF_v6.1_all_20131105.fa), index created with `-suf` and `-lcp`:

```
[satta@siyah:~gt]  git checkout 9071889e6f471cdc34bcc297ecd86bc25d8071b9
HEAD is now at 9071889... change in GtSeqabstract and xdrop using these
[satta@siyah:~gt]  make 64bit=yes -j5 errorcheck=no
...
[satta@siyah:~gt]  bin/gt ltrharvest -seqids yes -index LjmF -tabout no -md5 yes
Assertion failed: (forward || (ulen - 1 > (GtWord) i && vlen - 1 > (GtWord) j)), function gt_evalxdroparbitscoresextend, file src/match/xdrop.c, line 343.
```

Before that the run worked fine.
Note that the error message changed in later versions (e.g. current master):

```
Assertion failed: (ulen != 0 && vlen != 0), function gt_evalxdroparbitscoresextend, file src/match/xdrop.c, line 250.
This is a bug, please report it at https://github.com/genometools/genometools/issues.

```
",satta,https://github.com/genometools/genometools/issues/274,genometools++genometools.csv
MDU6SXNzdWUyOTg5NDM2NA==,Compilation issue on Mac OS X,CLOSED,2014-03-21T11:42:23Z,2014-03-21T17:41:08Z,2014-03-21T17:41:08Z,"I guess I haven't done a full `make clean` and recompile in a while. Today I did and I got this error while recompiling (on Mac OS X).

```
[compile disc_distri.o]
src/core/disc_distri.c:44:1: error: unused function 'ul_ull_gt_hashmap_new_with_start_size' [-Werror,-Wunused-function]
DECLARE_HASHMAP(GtUword, ul, GtUint64, ull, static, inline)
^
/Users/standage/Software/AEGeAn/src/genometools/src/core/hashmap-generic.h:94:17: note: expanded from macro 'DECLARE_HASHMAP'
  GtHashtable * keytag##_##valuetag##_gt_hashmap_new_with_start_size(\
                ^
<scratch space>:170:1: note: expanded from here
ul_ull_gt_hashmap_new_with_start_size
^
src/core/disc_distri.c:44:1: error: unused function 'ul_ull_gt_hashmap_delete' [-Werror,-Wunused-function]
/Users/standage/Software/AEGeAn/src/genometools/src/core/hashmap-generic.h:102:3: note: expanded from macro 'DECLARE_HASHMAP'
  keytag##_##valuetag##_gt_hashmap_delete(GtHashtable *ht)    \
  ^
<scratch space>:176:1: note: expanded from here
ul_ull_gt_hashmap_delete
^
src/core/disc_distri.c:44:1: error: unused function 'ul_ull_gt_hashmap_remove' [-Werror,-Wunused-function]
/Users/standage/Software/AEGeAn/src/genometools/src/core/hashmap-generic.h:120:3: note: expanded from macro 'DECLARE_HASHMAP'
  keytag##_##valuetag##_gt_hashmap_remove(GtHashtable *ht,    \
  ^
<scratch space>:185:1: note: expanded from here
ul_ull_gt_hashmap_remove
^
src/core/disc_distri.c:44:1: error: unused function 'ul_ull_gt_hashmap_add_and_return_storage' [-Werror,-Wunused-function]
/Users/standage/Software/AEGeAn/src/genometools/src/core/hashmap-generic.h:143:3: note: expanded from macro 'DECLARE_HASHMAP'
  keytag##_##valuetag##_gt_hashmap_add_and_return_storage(GtHashtable *ht,  \
  ^
<scratch space>:197:1: note: expanded from here
ul_ull_gt_hashmap_add_and_return_storage
^
src/core/disc_distri.c:45:1: error: unused function 'ul_ull_gt_hashmap_foreach' [-Werror,-Wunused-function]
DEFINE_HASHMAP(GtUword, ul, GtUint64, ull, gt_ht_ul_elem_hash,
^
/Users/standage/Software/AEGeAn/src/genometools/src/core/hashmap-generic.h:230:3: note: expanded from macro 'DEFINE_HASHMAP'
  keytag##_##valuetag##_gt_hashmap_foreach(                   \
  ^
<scratch space>:266:1: note: expanded from here
ul_ull_gt_hashmap_foreach
^
5 errors generated.
make[1]: *** [obj/src/core/disc_distri.o] Error 1
make: *** [gt] Error 2
```

It looks like it was a problem even with the stable 1.5.2 release. I don't observe the problem on Linux, which is another reason I probably didn't see the behavior before.
",standage,https://github.com/genometools/genometools/issues/277,genometools++genometools.csv
MDU6SXNzdWUyOTg5NjYxMA==,Issue with gt_strand_join and GTF data,CLOSED,2014-03-21T12:24:00Z,2014-03-23T13:06:38Z,2014-03-23T13:06:38Z,"[This small excerpt of a Cufflinks-produced GTF file](https://gist.github.com/standage/9685009) throws an error when processed with `gtf_to_gff3`.

```
$ gt gtf_to_gff3 scratch/demo.gtf 
skipping line 1 in file ""scratch/demo.gtf"": unknown feature: ""transcript""
skipping line 3 in file ""scratch/demo.gtf"": unknown feature: ""transcript""
skipping line 5 in file ""scratch/demo.gtf"": unknown feature: ""transcript""
Assertion failed: (0), function gt_strand_join, file src/core/strand.c, line 63.
This is a bug, please report it at https://github.com/genometools/genometools/issues.
```

The offending code is the case statement in the `gt_strand_join` function. It appears that two cases complete and then proceed to the default (since they lack `break` statements), rather than exit the case statement, which seems to be the intended behavior.
",standage,https://github.com/genometools/genometools/issues/278,genometools++genometools.csv
MDU6SXNzdWUzMDUxNDQyMw==,Fix handling of sequence regions with trailing whitespace,CLOSED,2014-03-31T14:06:36Z,2014-05-25T17:16:40Z,2014-05-25T17:16:40Z,"If a sequence region ID has trailing whitespace (e.g. an extra blank at the end), piping GFF3 data describing that region through multiple calls of `gt gff3`  will invalidate the GFF3 file:
- During the first parsing the content of the `##sequence-region` tags will be stripped of the trailing blank. It will stay in the first column of the features though.
- After parsing, the `GtAddIdsVisitor` will find that there is no sequence region with a trailing blank and add it. Now there are two sequence regions, one with and one without trailing blank.
- When trying to parse this concoction the next time, the GFF3 parser will complain about a duplicate sequence region and stop.

Example:

```
$ bin/gt gff3 testdata/gt_gff3_whitespace_problem.gff3 | bin/gt gff3
warning: seqid ""ctg123 "" on line 3 in file ""testdata/gt_gff3_whitespace_problem.gff3"" has not been previously introduced with a ""##sequence-region"" line, create such a line automatically
bin/gt gff3: error: the sequence region ""ctg123"" on line 3 in file ""stdin"" has already been defined
```

(this file is not in the repo yet, it's just the standard eden gene with a blank added to the end of the region ID)

The cause is that the `##sequence-region` line supports any kind of whitespace as a separator, while the feature lines only recognize tabs as separators.
",satta,https://github.com/genometools/genometools/issues/281,genometools++genometools.csv
MDU6SXNzdWUzMDU4ODQ3NQ==,GTF parser outputs invalid feature names/IDs,CLOSED,2014-04-01T10:49:36Z,2014-04-03T10:11:15Z,2014-04-03T10:11:15Z,"When parsing a GTF file containing features with transcript or gene names intermixed with features without transcript or gene names, the GTF parser will produce erroneous gene and transcript IDS, e.g. with ftp://ftp.ensembl.org/pub/release-75/gtf/ciona_intestinalis/Ciona_intestinalis.KH.75.gtf.gz.
Apparently, the parser is missing initialisation of the strings for each new parsed feature.
",satta,https://github.com/genometools/genometools/issues/282,genometools++genometools.csv
MDU6SXNzdWUzMDg1NzQ0OQ==,"Assertion failed: (ulen != 0 && vlen != 0), function gt_evalxdroparbitscoresextend, file src/match/xdrop.c, line 250.",CLOSED,2014-04-04T12:51:49Z,2014-04-06T14:15:46Z,2014-04-06T14:15:46Z,"Hello, I am trying to use LTRharvest with my genome and had a bug.

Here are the command lines : 

/Data/Programs/genometools-1.5.2/bin/gt suffixerator -db Pdac_ref2013s.fasta -indexname Pdac_ref2013sindex -tis -suf -lcp -des -ssp

This creates different files. Also, I wanted to run with the -dna option but it says :+1: error: superfluous argument ""dna""
So I removed it.
Is it ok ?

Next, I did :

Data/Programs/genometools-1.5.2/bin/gt ltrharvest -index Pdac_ref2013sindex -out Pdac_ref2013sindex.out99 -outinner Pdac_ref2013sindex.outinner99 -gff3 Pdac_ref2013sindex.gff99 -minlenltr 100 -maxlenltr 6000 -mindistltr 1500 -maxdistltr 25000 -mintsd 5 -maxtsd 5 -motif tgca -similar 99 -vic 10  > Pdac_ref2013sindex.result99

Here is the bug 
Assertion failed: (ulen != 0 && vlen != 0), function gt_evalxdroparbitscoresextend, file src/match/xdrop.c, line 250.

What can I do ?

Thanks a lot for your help,

Muriel
",murielgb,https://github.com/genometools/genometools/issues/286,genometools++genometools.csv
MDU6SXNzdWUzMTMzNTkwMg==,Complete Lua bindings for node types,CLOSED,2014-04-11T15:17:27Z,2014-05-08T13:25:34Z,2014-05-08T13:25:34Z,"Currently not all node subclasses and their methods are supported in the Lua bindings, only feature nodes and the region node constructor. Add support for the others. 
",satta,https://github.com/genometools/genometools/issues/289,genometools++genometools.csv
MDU6SXNzdWUzMTcxNjg5MA==,Double-check LTR boundaries after seed extension,CLOSED,2014-04-17T10:38:06Z,2014-06-03T07:28:27Z,2014-06-03T07:28:27Z,"Hello,

Here is my command :
/Data/Programs/genometools-unstable/bin/gt ltrharvest -index Pdac_ref2013sindex -out Pdac_ref2013sindex.outT99 -outinner Pdac_ref2013sindex.outinnerT99 -gff3 Pdac_ref2013sindex.gffT99 -minlenltr 70 -maxlenltr 500 -mindistltr 280 -maxdistltr 1500 -mintsd 5 -maxtsd 5 -motif tgca -similar 99 -vic 10  > Pdac_ref2013sindex.resultT99

And I have this bug : 
Assertion failed: (ulen != 0 && vlen != 0), function gt_evalxdroparbitscoresextend, file src/match/xdrop.c, line 250.

I tried with the version 1.5.2, with an unstable version that I downloaded the 4th of April and with an unstable version that I downloaded today. None of them work.

Any suggestion ?!

Thanks you !

Muriel GB
",murielgb,https://github.com/genometools/genometools/issues/291,genometools++genometools.csv
MDU6SXNzdWUzMjg5MjkwNg==,Specify location of cairo headers (and/or other -I directories),CLOSED,2014-05-06T13:39:07Z,2014-05-06T23:57:21Z,2014-05-06T23:57:21Z,"If I install cairo manually into a non-standard location, is there a way I can indicate the location of that header when I run `make`?
",standage,https://github.com/genometools/genometools/issues/293,genometools++genometools.csv
MDU6SXNzdWUzMzExMzYxNg==,"online validator fails file on CDS phase, 1.5.1 passes it",CLOSED,2014-05-08T19:08:32Z,2014-05-09T09:04:21Z,2014-05-09T09:04:21Z,"I tested a file that was failing with a CDS phase error on the online validator, chopped it down to a minimal file, tested all combinations of phases (0,1,2) on the two CDS in the file, and no combination passes the online validator. However, the command line gt gff3validator says it is a valid gff3 file.

The command line version is from genometools/1.5.1, was run as:
rotillar@genepool11 ~/projects/gff3/bin Thu May 08 12:05:22 ( 634 )
$ gt gff3validator 295.gff3
warning: seqid ""bd_20x24"" on line 2 in file ""295.gff3"" has not been previously introduced with a ""##sequence-region"" line, create such a line automatically
input is valid GFF3

The web version reports:
Validation unsuccessful!
GenomeTools error: CDS feature on line 5 in file ""/tmp/295.gff3"" has multiple parents which require different phases
Copyright  2012 Sascha Steinbiss. Last update: 2012-04-11 

The contents of the file are:
rotillar@genepool11 ~/projects/gff3/bin Thu May 08 12:07:49 ( 635 )
$ cat 295.gff3
## gff-version 3

bd_20x24        prediction      gene    4454    5401    0       -       .       ID=gene_295;Name=jgi.p|Phatr2_bd|417;portal_id=Phatr2_bd;proteinId=417;transcriptId=417
bd_20x24        prediction      mRNA    4454    5401    .       -       .       ID=mRNA_295;Name=jgi.p|Phatr2_bd|417;Parent=gene_295;proteinId=417;track=FilteredModels1;transcriptId=417
bd_20x24        prediction      exon    4638    5401    .       -       .       ID=exon_295_1;Parent=mRNA_295
bd_20x24        prediction      CDS     4638    5401    .       -       0       ID=CDS_295;Parent=mRNA_295
bd_20x24        prediction      exon    4454    4556    .       -       .       ID=exon_295_2;Parent=mRNA_295
bd_20x24        prediction      CDS     4454    4556    .       -       1       ID=CDS_295;Parent=mRNA_295
",bobbyo,https://github.com/genometools/genometools/issues/297,genometools++genometools.csv
MDU6SXNzdWUzMzY1ODE0Mg==,Failing intset test on 32bit,CLOSED,2014-05-16T09:02:43Z,2014-05-16T16:13:47Z,2014-05-16T16:13:47Z,"With current master.

```
ss34@pcs5b:~/genometools$ make 64bit=no -j5 opt=no cairo=no
[create obj/gt_config.h]
[compile sqlite3.o]
[compile alphabet.o]
[compile array2dim.o]
[compile array2dim_sparse.o]
[compile array3dim.o]
...
```

```
ss34@pcs5b:~/genometools$ bin/gt -test
seed=3643430742
...
intset classes...error
first error: gt_ensure(gt_intset_32_get_test(is, idx) == arr[idx]) failed: function gt_intset_32_unit_test, file src/extended/intset_32.c, line 336.
This is probably a bug, please report at https://github.com/genometools/genometools/issues.
```
",satta,https://github.com/genometools/genometools/issues/307,genometools++genometools.csv
MDU6SXNzdWUzMzc5ODI3MA==,Failing tests on Linux/PPC,OPEN,2014-05-19T13:22:29Z,2016-02-01T14:22:43Z,,"While debugging some code to get the GenomeTools Debian packages to build successfully on exotic platforms, I noticed that other tests fail as well (~150). A complete list is here: https://gist.github.com/satta/b4effb09a7729eacc6ab

I suspect the main reason for most tests failing is the fact that char is unsigned there, leading to issues with file parsing etc.
",satta,https://github.com/genometools/genometools/issues/311,genometools++genometools.csv
MDU6SXNzdWUzNDA2NjcxMA==,Implement Tabix support for FeatureIndex,OPEN,2014-05-22T09:54:45Z,2014-06-11T12:13:27Z,,"Tabix (http://bioinformatics.oxfordjournals.org/content/27/5/718) is a generic indexing library for genomic regions. We should investigate its use as a persistence back-end for the GtFeatureIndex as it is expected to be way faster than the SQLite based one currently implemented. 
",satta,https://github.com/genometools/genometools/issues/312,genometools++genometools.csv
MDU6SXNzdWUzNDA2Njk5OQ==,Fix unsafe parameter passing in Lua Encseq bindings,CLOSED,2014-05-22T09:58:55Z,2014-05-26T08:52:12Z,2014-05-26T08:52:12Z,"Rebuilding the 1.5.1 source with a compiler implementing extended type checking has shown that there is some unsafe double-int conversion without error checking being done in the Lua bindings. 

```
[compile encseq_lua.o]

file src/gtlua/encseq_lua.c line 83 function encseq_reader_lua_reinit_with_readmode: in expression `luaL_checknumber(L, 3)':
conversion from `double' to `int': implicit conversion not permitted
CONVERSION ERROR
make[2]: *** [obj/src/gtlua/encseq_lua.o] Error 64
make[2]: Leaving directory `/srv/jenkins-slave/workspace/sid-goto-cc-genometools/genometools-1.5.1'
```

See http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=748305.
",satta,https://github.com/genometools/genometools/issues/313,genometools++genometools.csv
MDU6SXNzdWUzNDE4ODc2Mg==,-matchdesc and multiple occurrences of IDs in headers,CLOSED,2014-05-23T16:04:40Z,2014-05-29T12:32:38Z,2014-05-29T12:32:38Z,"The `-matchdesc` option causes confusion when a query seqid could match more than sequence in a set. For example, in _D. melanogaster_, there are heterochromatin sequences intermingled with the euchromatin sequences:

```
$ zgrep '>' dmel-all-chromosome-r5.57.fasta.gz | cut -f 1 -d' '
>YHet
>2RHet
>2LHet
>3LHet
>3RHet
>U
>XHet
>dmel_mitochondrion_genome
>2L
>X
>3L
>4
>2R
>3R
>Uextra
```

So using, for example, `-matchdesc` with a sequence ID of `2L` will return `2LHet` as the corresponding sequence as `2LHet` is the first sequence in the set whose description contains `2L`. But it is not the correct one ('2L' coming later in the set). That makes the `-matchdesc` quite unintuitive to use. Moreover, there is AFAICS no other way to find sequences by header matching in a multi-sequence input.
I propose to add another matching option, for instance called `-matchdescstart`, which will behave like many other sequence processing tools do: it will try to match the given sequence ID  _exactly_ against the prefix of each sequence description up to the first whitespace. This way, a one-to-one mapping is obtained and ambiguous results like above should not occur.
I also propose to emit a warning (or even error?) if a `-matchdesc` seqid query matches multiple sequence descriptions so the caller gets notified of this.

Any other suggestions about how to approach this issue?
",satta,https://github.com/genometools/genometools/issues/314,genometools++genometools.csv
MDU6SXNzdWUzNDM3MzMyOQ==,"function gt_encseq_get_encoded_char, file src/core/encseq.c, line 255",CLOSED,2014-05-27T13:43:53Z,2014-06-04T01:39:57Z,2014-06-03T07:37:05Z,"My code is :
gt ltrharvest -seed 20 -minlenltr 100 -maxlenltr 3500 -mindistltr 1000 -maxdistltr 20000 -similar 70 -motif tgca -motifmis 0 -longoutput -index H.repeat.detail.seq -out H.repeat.detail.seq.h1 > H.repeat.detail.seq.h2

And the bug is: 
Assertion failed: (encseq != NULL && pos < encseq->logicaltotallength), function gt_encseq_get_encoded_char, file src/core/encseq.c, line 255.

Please help,Thanks!
",buyejue,https://github.com/genometools/genometools/issues/320,genometools++genometools.csv
MDU6SXNzdWUzNDM5ODc2MQ==,gt -help more verbose,OPEN,2014-05-27T18:19:35Z,2015-04-02T08:28:26Z,,"print out one liners on gt -help output
",Garonenur,https://github.com/genometools/genometools/issues/321,genometools++genometools.csv
MDU6SXNzdWUzNDM5ODk3MA==,zsh/bash tab completion files for gt,OPEN,2014-05-27T18:21:45Z,2014-09-13T19:34:47Z,,"z-shell and bash allow for customized completion files either write a script or a direct (possibly hidden) option for gt to print out such a file.
",Garonenur,https://github.com/genometools/genometools/issues/322,genometools++genometools.csv
MDU6SXNzdWUzNDUyOTg3NA==,Assertion failed: (ulen != 0 && vlen != 0),CLOSED,2014-05-29T05:32:38Z,2014-06-03T09:34:24Z,2014-06-03T07:49:25Z,"```
$ /home/wish/Programs/gt-1.5.2-Linux_x86_64-64bit/bin/gt ltrharvest -index  my.fasta -gff3 my.gff3 -out my.fa -seqids yes -v
# args=-index my.fasta -gff3 my.gff3 -out my_ltrharvest.fa -seqids yes -v
# user defined options and values:
#   verbosemode: On
#   indexname: my.fasta
#   outputfile: my.fa
#   outputfile gff3 format: my.gff3
#   xdropbelowscore: 5
#   similaritythreshold: 85.00
#   minseedlength: 30
#   matchscore: 2
#   mismatchscore: -2
#   insertionscore: -3
#   deletionscore: -3
#   minLTRlength: 100
#   maxLTRlength: 1000
#   minLTRdistance: 1000
#   maxLTRdistance: 15000
#   overlaps: best
#   minTSDlength: 4
#   maxTSDlength: 20
#   palindromic motif: 
#   motifmismatchesallowed: 4
#   vicinity: 60 nt
# predictions are reported in the following way
# s(ret) e(ret) l(ret) s(lLTR) e(lLTR) l(lLTR) s(rLTR) e(rLTR) l(rLTR) sim(LTRs) seq-nr 
# where:
# s = starting position
# e = ending position
# l = length
# ret = LTR-retrotransposon
# lLTR = left LTR
# rLTR = right LTR
# sim = similarity
# seq-nr = sequence number
Assertion failed: (ulen != 0 && vlen != 0), function gt_evalxdroparbitscoresextend, file src/match/xdrop.c, line 250.
This is a bug, please report it at https://github.com/genometools/genometools/issues
```
",Rushirajm,https://github.com/genometools/genometools/issues/323,genometools++genometools.csv
MDU6SXNzdWUzNDg0NjMxNw==,make disc_distri class handle errors,OPEN,2014-06-03T09:27:11Z,2014-06-11T12:13:27Z,,"the disc_distri class can not handle functions that fail with GtError. I will have to change that, but as this is a public API I think the most compatible way of doing it, is to provide additional functions and don't change the existing ones.
I will add the new functions to the right now non-existent disc_distri.h until they are approved and can be merged into the _api.h

Ok?
",Garonenur,https://github.com/genometools/genometools/issues/326,genometools++genometools.csv
MDU6SXNzdWUzNTEyNzMxMw==,Implement full custom stream/visitor functionality for Lua,CLOSED,2014-06-06T08:23:31Z,2014-07-09T09:39:19Z,2014-07-09T09:39:19Z,"I currently use the Ruby custom visitor/stream interface a lot to tie together several external tools in an annotation pipeline. It would be very convenient for both performance and ease of use if I could rewrite these components in Lua for the following reasons:
- scripts can be executed using only the gt binary without needing to install the Gt shared library
- independence of Ruby versions (currently only the ancient 1.8 is supported)
- the Ruby/Python bindings are not stable on some platforms, e.g. on Mac OS X
- the Ruby bindings are the slowest of all supported scripting languages
",satta,https://github.com/genometools/genometools/issues/328,genometools++genometools.csv
MDU6SXNzdWUzNTQ3Mjg1NQ==,Fix behaviour in -matchdesc when sequence IDs contain regex special characters,CLOSED,2014-06-11T11:10:21Z,2014-06-11T16:20:06Z,2014-06-11T16:20:06Z,"The `-matchdesc` and `-matchdescstart` options behave wrongly when given seqids with characters in them which have special meaning in regular expressions, e.g. `|`, which are interpreted in the context of the regex. Hence something like `gi|528751396|gb|ATBK01001229.1` would match any other string with `gi` in it, reporting ambiguity where none exists. 

To fix this, strings passed to `gt_grep` should be escaped properly if they are meant to be searched literally.

Also, `-matchdescstart` should also match a sequence header from the beginning up to the end of the line, if there is no white space in it.
",satta,https://github.com/genometools/genometools/issues/330,genometools++genometools.csv
MDU6SXNzdWUzNTU2MDUwNw==,1.5.3 release,CLOSED,2014-06-12T08:47:38Z,2014-06-13T09:09:35Z,2014-06-13T09:09:35Z,"How about a new release? A number of important bugs has been fixed and new features introduced. I will prepare the changelog. If there are any objections, please discuss them here.
",satta,https://github.com/genometools/genometools/issues/333,genometools++genometools.csv
MDU6SXNzdWUzNTY1NzUwNg==,Debian packages for 1.5.3,CLOSED,2014-06-13T09:38:41Z,2014-08-09T16:56:17Z,2014-08-09T16:56:17Z,"I should update the Debian packages for 1.5.3 -- without the symbols file hassle this time.
",satta,https://github.com/genometools/genometools/issues/338,genometools++genometools.csv
MDU6SXNzdWUzNjEyMTE0Mg==,gt select failures,CLOSED,2014-06-19T21:37:59Z,2014-09-23T09:08:47Z,2014-09-23T05:58:52Z,"`gt select -seqid 'species.scaffold00011' species.all.gff > subset.gff`

fails with the error

```
gt(53499,0x7fff727de310) malloc: *** error for object 0x7fb584175110: pointer being freed was not allocated
*** set a breakpoint in malloc_error_break to debug
Abort trap: 6
```

This is genometools version 1.5.2 (tried git HEAD too) on OS X Mavericks 10.9.3.
",yeban,https://github.com/genometools/genometools/issues/340,genometools++genometools.csv
MDU6SXNzdWUzNjI4Njg2OA==,Add tool to process inline sequences from GFF3s,CLOSED,2014-06-23T12:40:28Z,2014-06-27T15:57:47Z,2014-06-27T15:57:47Z,"I am going to write tools for splitting inline sequences from GFF3 input into a separate FASTA file, outputting GFF3 without inline sequences, and vice versa (taking a GFF3 file and adding sequences from an external sequence source, making sure that seqids match). Any comments or further requests? I assume there is no tool with that functionality yet?
",satta,https://github.com/genometools/genometools/issues/342,genometools++genometools.csv
MDU6SXNzdWUzNjM2NDc3NA==,make clean,CLOSED,2014-06-24T08:51:29Z,2014-06-24T11:55:31Z,2014-06-24T11:55:31Z,"I would like to change make clean, so that it does not delete splint and scan-build targets, these would only be deleted with `make cleanup`.
`make clean` would delete all `.o` files within `opt` and `amalgamation.c` if that exists.
Any comments?
",Garonenur,https://github.com/genometools/genometools/issues/343,genometools++genometools.csv
MDU6SXNzdWUzNjM2OTY4OA==,Make the GTF parser handle alternative CDS per transcript,OPEN,2014-06-24T10:03:12Z,2014-11-13T10:10:45Z,,"This tool seems to create duplicate features when given a DAG as input:

```
$ bin/gt gff3_to_gtf testdata/standard_gene_as_dag.gff3                                                 warning: skipping GFF3 feature of type ""TF_binding_site"" (from line 4 in file ""testdata/standard_gene_as_dag.gff3"")
ctg123  .   exon    1050    1500    .   +   .   gene_id ""1""; transcript_id ""1.1"";
ctg123  .   exon    3000    3902    .   +   .   gene_id ""1""; transcript_id ""1.1"";
ctg123  .   exon    5000    5500    .   +   .   gene_id ""1""; transcript_id ""1.1"";
ctg123  .   exon    7000    9000    .   +   .   gene_id ""1""; transcript_id ""1.1"";
ctg123  .   CDS 1201    1500    .   +   0   gene_id ""1""; transcript_id ""1.1"";
ctg123  .   CDS 3000    3902    .   +   0   gene_id ""1""; transcript_id ""1.1"";
ctg123  .   CDS 5000    5500    .   +   0   gene_id ""1""; transcript_id ""1.1"";
ctg123  .   CDS 7000    7600    .   +   0   gene_id ""1""; transcript_id ""1.1"";
ctg123  .   exon    1050    1500    .   +   .   gene_id ""1""; transcript_id ""1.2"";
ctg123  .   exon    5000    5500    .   +   .   gene_id ""1""; transcript_id ""1.2"";
ctg123  .   exon    7000    9000    .   +   .   gene_id ""1""; transcript_id ""1.2"";
ctg123  .   CDS 1201    1500    .   +   0   gene_id ""1""; transcript_id ""1.2"";
ctg123  .   CDS 5000    5500    .   +   0   gene_id ""1""; transcript_id ""1.2"";
ctg123  .   CDS 7000    7600    .   +   0   gene_id ""1""; transcript_id ""1.2"";
ctg123  .   exon    1300    1500    .   +   .   gene_id ""1""; transcript_id ""1.3"";
ctg123  .   exon    3000    3902    .   +   .   gene_id ""1""; transcript_id ""1.3"";
ctg123  .   exon    5000    5500    .   +   .   gene_id ""1""; transcript_id ""1.3"";
ctg123  .   exon    7000    9000    .   +   .   gene_id ""1""; transcript_id ""1.3"";
ctg123  .   CDS 3301    3902    .   +   0   gene_id ""1""; transcript_id ""1.3"";
ctg123  .   CDS 3391    3902    .   +   0   gene_id ""1""; transcript_id ""1.3"";
ctg123  .   CDS 5000    5500    .   +   1   gene_id ""1""; transcript_id ""1.3"";
ctg123  .   CDS 5000    5500    .   +   1   gene_id ""1""; transcript_id ""1.3"";
ctg123  .   CDS 7000    7600    .   +   1   gene_id ""1""; transcript_id ""1.3"";
ctg123  .   CDS 7000    7600    .   +   1   gene_id ""1""; transcript_id ""1.3"";
```

Note that things seem to look correct if a tree is given as input:

```
$ bin/gt gff3_to_gtf testdata/standard_gene_as_tree.gff3                                                
warning: skipping GFF3 feature of type ""TF_binding_site"" (from line 4 in file ""testdata/standard_gene_as_tree.gff3"")
ctg123  .   exon    1050    1500    .   +   .   gene_id ""1""; transcript_id ""1.1"";
ctg123  .   exon    3000    3902    .   +   .   gene_id ""1""; transcript_id ""1.1"";
ctg123  .   exon    5000    5500    .   +   .   gene_id ""1""; transcript_id ""1.1"";
ctg123  .   exon    7000    9000    .   +   .   gene_id ""1""; transcript_id ""1.1"";
ctg123  .   exon    1050    1500    .   +   .   gene_id ""1""; transcript_id ""1.2"";
ctg123  .   exon    5000    5500    .   +   .   gene_id ""1""; transcript_id ""1.2"";
ctg123  .   exon    7000    9000    .   +   .   gene_id ""1""; transcript_id ""1.2"";
ctg123  .   exon    1300    1500    .   +   .   gene_id ""1""; transcript_id ""1.3"";
ctg123  .   exon    3000    3902    .   +   .   gene_id ""1""; transcript_id ""1.3"";
ctg123  .   exon    5000    5500    .   +   .   gene_id ""1""; transcript_id ""1.3"";
ctg123  .   exon    7000    9000    .   +   .   gene_id ""1""; transcript_id ""1.3"";
```
",satta,https://github.com/genometools/genometools/issues/345,genometools++genometools.csv
MDU6SXNzdWUzNjM3MzE3OA==,GtNodeVisitor requires handler for feature nodes?,CLOSED,2014-06-24T10:55:51Z,2014-06-24T16:13:23Z,2014-06-24T16:13:23Z,"Apparently a GtNodeVisitor currently always needs a handler for feature nodes:

https://github.com/genometools/genometools/blob/master/src/extended/node_visitor.c#L97

Can anyone think of a reason for this? I am writing a visitor which only needs to handle sequence nodes, so I would prefer not having to write an empty callback just to satisfy this... 
",satta,https://github.com/genometools/genometools/issues/346,genometools++genometools.csv
MDU6SXNzdWUzNjU4MTAwNw==,Accelerating merging of many GFF3 files,CLOSED,2014-06-26T14:30:40Z,2014-07-01T17:36:13Z,2014-07-01T17:36:13Z,"The `gt merge` tool is quite slow when processing large numbers (thousands) of input files (e.g. per-scaffold annotations). That is because for each feature output by the merge stream, the 'smallest' feature has to be found among all input streams to ensure sortedness (taking _O(nm)_ time for _n_ streams with _m_ features!). In this situation, I would rather prefer to merge all inputs in an unsorted fashion and sort them later (at the expense of memory, but _O(m_ log _m)_ time), when all inputs have been read. Any comments on this?
",satta,https://github.com/genometools/genometools/issues/348,genometools++genometools.csv
MDU6SXNzdWUzNjU4ODI2Mg==,CDS sequence translation/extraction ignores phase information,CLOSED,2014-06-26T15:43:59Z,2014-07-02T08:31:45Z,2014-07-02T08:31:45Z,"In GenomeTools, phase information is currently not used during the translation of a protein-coding sequence. This is OK for internal CDSs as the DNA parts are concatenated and translated as a whole. However, if the first CDS (in reading direction) in a protein coding transcript has a phase different from zero, the resulting protein products are broken in the current implementation as the necessary amount of bases is not skipped from the beginning of the concatenated sequence while translating.

I am aware of the fact that this can be 'fixed' by forcing a phase of 0 for the first CDS and adjusting the start position of the CDS in this case, but I am currently facing a set of partial gene annotations, a substantial number of which are annotated in this way and I do not want to mess with the gene models. AFAICS nothing in the GFF3 spec disallows having a non-zero phase at the beginning of a coding region. 
Any opinions (e.g. @gordon)?
",satta,https://github.com/genometools/genometools/issues/349,genometools++genometools.csv
MDU6SXNzdWUzNjYyMTk2Ng==,Overhang internal boundary of LTR candidates (LTRharvest),OPEN,2014-06-26T22:41:25Z,2015-01-08T10:19:04Z,,"[version] gt.1.5.3 LTRharvest
[parameters]
              gt ltrharvest -index Bond -minlenltr 100 -maxlenltr 7000 -mintsd 5 -maxtsd 5 -motif TGCA -motifmis 0 -similar 90 -vic 40 -seed 40 -seqids yes -out Bond.ltrTE.fa -gff3 Bond.gff3 > Bond.scn

[description]
              when use strict motif and tsd length in search LTR candidates in the LTRharvest, the ~1/3 of the candidates have at least one overhang internal boundaries (the 3' lLTR or 5' rLTR boundary that extend more than enough)
I tried to use the -xdrop 3, but not improved.

[Examples and sequence] see this dropbox link:
https://www.dropbox.com/sh/7idk4qbltwhywyt/AAD7BoegkIEoaogz7EfjwwIUa

The sequence has been extended 100 bp on both sides. Also the LTRharvest tabulate output and LTRdigest output are attached.
Txt files are case studies by blastn, the second lines of each file describe the problem. Within the alignments, [TG] or [CA] denotes the motif location reported by LTRharvest, /TG/ or /CA/ indicate the correct motif location that they should be. {} indicates the TSD.

Thanks,
Shujun
",oushujun,https://github.com/genometools/genometools/issues/350,genometools++genometools.csv
MDU6SXNzdWUzNjg3NTc2NQ==,Lua GenomeNode bindings should implement __eq and __tostring metamethods,CLOSED,2014-07-01T09:27:05Z,2014-07-02T08:31:45Z,2014-07-02T08:31:45Z,"This would allow one to compare two Lua node objects such that they are equal if they wrap the same C pointer. Also, having a string output to show when `print()`ing a node helps with debugging.
",satta,https://github.com/genometools/genometools/issues/352,genometools++genometools.csv
MDU6SXNzdWUzNjk4MjQxOA==,Line-based sorting of annotations,CLOSED,2014-07-02T13:39:06Z,2014-07-18T18:24:55Z,2014-07-18T18:24:55Z,"Currently `gt gff3 -sort` outputs GFF3 input sorted by node type, sequence, and start position. That is, CCs are sorted but always kept together, finishing the output for one CC before starting to output another. That is, sorted overlapping features would be output like this:

```
seq1     chado   gene    1644    11288   .       +       .       ID=feature1;
seq1     chado   mRNA    1644    11288   .       +       .       ID=feature1.1;Parent=feature1;
seq1     chado   CDS     1644    2547    .       +       0       ID=feature1.1:exon:1;Parent=feature1.1;
seq1     chado   CDS     3448    4477    .       +       2       ID=feature1.1:exon:2;Parent=feature1.1;
seq1     chado   CDS     4513    4701    .       +       1       ID=feature1.1:exon:3;Parent=feature1.1;
seq1     chado   CDS     4837    5221    .       +       1       ID=feature1.1:exon:4;Parent=feature1.1;
seq1     chado   CDS     5409    5733    .       +       0       ID=feature1.1:exon:5;Parent=feature1.1;
seq1     chado   CDS     5823    6200    .       +       2       ID=feature1.1:exon:6;Parent=feature1.1;
seq1     chado   CDS     6383    7365    .       +       2       ID=feature1.1:exon:7;Parent=feature1.1;
seq1     chado   CDS     7416    7788    .       +       0       ID=feature1.1:exon:8;Parent=feature1.1;
seq1     chado   CDS     7837    8312    .       +       2       ID=feature1.1:exon:9;Parent=feature1.1;
seq1     chado   CDS     8354    9695    .       +       0       ID=feature1.1:exon:10;Parent=feature1.1;
seq1     chado   CDS     9919    11288   .       +       2       ID=feature1.1:exon:11;Parent=feature1.1;
###
seq1     chado   polypeptide     1644    11288   .       +       .       ID=feature1.1:pep;Derives_from=feature1.1;
###
```

Unfortunately, there are some tools (Tabix, I'm looking at you!) which expect GFF3 output sorted on a individual line basis.  From this point of view, the example above would not be sorted (the polypeptide starts after the last CDS)!

I propose to implement an alternative output stream for annotation graphs, which would output `###` separated blocks not only on the basis of graph connectivity, but also consider overlapping features and place them within the same block, resulting in an output format like the following:

```
seq1     chado   gene    1644    11288   .       +       .       ID=feature1;
seq1     chado   mRNA    1644    11288   .       +       .       ID=feature1.1;Parent=feature1;
seq1     chado   polypeptide     1644    11288   .       +       .       ID=feature1.1:pep;Derives_from=feature1.1;
seq1     chado   CDS     1644    2547    .       +       0       ID=feature1.1:exon:1;Parent=feature1.1;
seq1     chado   CDS     3448    4477    .       +       2       ID=feature1.1:exon:2;Parent=feature1.1;
seq1     chado   CDS     4513    4701    .       +       1       ID=feature1.1:exon:3;Parent=feature1.1;
seq1     chado   CDS     4837    5221    .       +       1       ID=feature1.1:exon:4;Parent=feature1.1;
seq1     chado   CDS     5409    5733    .       +       0       ID=feature1.1:exon:5;Parent=feature1.1;
seq1     chado   CDS     5823    6200    .       +       2       ID=feature1.1:exon:6;Parent=feature1.1;
seq1     chado   CDS     6383    7365    .       +       2       ID=feature1.1:exon:7;Parent=feature1.1;
seq1     chado   CDS     7416    7788    .       +       0       ID=feature1.1:exon:8;Parent=feature1.1;
seq1     chado   CDS     7837    8312    .       +       2       ID=feature1.1:exon:9;Parent=feature1.1;
seq1     chado   CDS     8354    9695    .       +       0       ID=feature1.1:exon:10;Parent=feature1.1;
seq1     chado   CDS     9919    11288   .       +       2       ID=feature1.1:exon:11;Parent=feature1.1;
###
```

Any comments/suggestions?
",satta,https://github.com/genometools/genometools/issues/355,genometools++genometools.csv
MDU6SXNzdWUzNzA1NzcyMg==,`gt readjoiner assembly` fails on  Linux_x86_64,CLOSED,2014-07-03T08:50:59Z,2014-11-13T13:02:43Z,2014-11-13T13:02:43Z,"gt-1.5.3-Linux_x86_64-64bit-complete/bin/gt readjoiner assembly -readset datafile -l 50

fails with the error message

Assertion failed: (encseq != NULL && seqnum < encseq->logicalnumofdbsequences), function gt_encseq_seqlength, file /home/gordon/genometools/src/core/encseq.c, line 3889.
",sebafaye,https://github.com/genometools/genometools/issues/356,genometools++genometools.csv
MDU6SXNzdWUzNzU1MjcxNg==,Add support for 'Derives_from' edges to the annotation graph interface,OPEN,2014-07-10T11:12:24Z,2014-07-10T11:13:53Z,,"Currently, `Derives_from` is handled just like any other attribute. But in reality it, much like the `Parent` attribute, is part of the graph structure definition and references the ID of an existing node in the annotation. These 'edges' break if IDs are changed during processing, i.e. when merging, filtering, etc. They are not updated to reflect their target's new ID and left dangling. 
To consider this fact in the interface, we need to model a second edge type to be recorded in the feature nodes.
",satta,https://github.com/genometools/genometools/issues/359,genometools++genometools.csv
MDU6SXNzdWUzNzg3MTAwOA==,Optimize seqid->sequence mapping for -matchdescstart,CLOSED,2014-07-15T10:49:59Z,2014-09-08T12:54:03Z,2014-09-06T16:53:45Z,"When accessing sequences in sequence sets containing lots of sequences, the iterative regex scanning done in the  `-matchdesc` and `-matchdescstart` cases dominates the total run time. Here's the top part of a gprof output (I was using `gt speck` to check gene annotations from the _Sorghum bicolor_ genome, 44k gene features with ~10k sequences):

```
  %   cumulative   self              self     total
 time   seconds   seconds    calls   s/call   s/call  name
 20.28     33.28    33.28 20759710     0.00     0.00  tre_parse
  9.68     49.17    15.89 1019518464     0.00     0.00  tre_isspace_func
  8.62     63.32    14.15 20759710     0.00     0.00  tre_compile
  8.04     76.51    13.19 20759710     0.00     0.00  tre_tnfa_run_parallel
  6.55     87.25    10.74 3615273600     0.00     0.00  tre_stack_push_int
  6.05     97.17     9.92 2293722420     0.00     0.00  tre_mem_alloc_impl
  3.66    103.18     6.01 2127644740     0.00     0.00  tre_stack_push_voidptr
  3.35    108.67     5.49 598496460     0.00     0.00  tre_make_trans
  2.70    113.10     4.43 3615273600     0.00     0.00  tre_stack_pop_int
  2.37    116.99     3.89 41519420     0.00     0.00  tre_copy_ast
  2.07    120.38     3.39 3988948380     0.00     0.00  tre_stack_num_objects
  1.77    123.28     2.90 464221933     0.00     0.00  gzread
  1.60    125.91     2.63 702295010     0.00     0.00  tre_ast_new_node
```

Generally, when there's many sequences with few annotations each the sequence access takes very long. I propose to implement `-matchdescstart` separately by preprocessing the relevant part of the sequence headers into a hash table when the sequence set is loaded for the first time, allowing to do the mapping in constant time afterwards. 
For `-matchdesc` there is not much one can do as the match positions are unconstrained.
",satta,https://github.com/genometools/genometools/issues/363,genometools++genometools.csv
MDU6SXNzdWUzODA3NDgyOA==,ltrdigest domaine identification probleme,CLOSED,2014-07-17T12:09:02Z,2014-08-14T15:19:18Z,2014-08-14T15:19:18Z,"I am working on a Red Hat 4.4.7-4 cluster (http://www.vital-it.ch/) with genometools.
I got the following issue:

Assertion failed: (strspn(b, ""012+-"") == (size_t) 2), function gt_ltrdigest_pdom_visitor_parse_alignments, file src/ltr/ltrdigest_pdom_visitor.c, line 381.

with the following command:

gt ltrdigest -pptlen 10 30 -pbsoffset 0 3 -trnas at_trna.fa -hmms Pfam-A.hmm -outfileprefix b_napus_ltrs pred_no_tds_brassica_napus_ltr_sorted.gff3 brassica_napus_genome.fa > b_napus_ltrs_after_ltrdigest.gff3

where b_napus_ltrs pred_no_tds_brassica_napus_ltr_sorted.gff3 is a 11M file size set of lts obtained from ltrharvest

the genometools version I'm using is the genometools-mater downloaded on the 19 Jun 2014 built with ""make 64bit=yes cairo=yes errorcheck=yes with-hmmer=yes""

This build worked on a smaller set

Thanks for your time
",twolfe,https://github.com/genometools/genometools/issues/365,genometools++genometools.csv
MDU6SXNzdWUzODYxMDU4OQ==,gff3validator bug,CLOSED,2014-07-24T09:13:34Z,2014-08-09T14:55:09Z,2014-08-09T14:55:09Z,"Hello,

I am trying to use gff3validator to process gff-file generated by maker annotation. Validator reports a problem like this:

Assertion failed: (gt_feature_node_get_multi_representative(fn->representative) == fn->representative), function gt_feature_node_get_multi_representative, file src/extended/feature_node.c, line 485.
This is a bug, please report it at https://github.com/genometools/genometools/issues.

I feel this is a result of misformatted <a href=https://drive.google.com/file/d/0B-sFp7IbYnWtWkxyM1gzZnNGSUE/edit?usp=sharing>gff-file</a>. Howerer, there are no tips how to fix the problem.
",yuragal,https://github.com/genometools/genometools/issues/367,genometools++genometools.csv
MDU6SXNzdWUzOTQ5ODA0Mw==,gt seqfilter using stdinput produces files with problematic name,CLOSED,2014-08-05T08:56:05Z,2014-08-06T19:20:23Z,2014-08-06T07:09:09Z,"it seems to me, that if gt seqfilter is used with stdinput, my uscase was:

```
gt shredder infile.fas | gt seqfilter -minlength 500 > outfile.fas
```

it will create an encseq with the basename `-`. As the `-` is usualy used for  options on the unix command line I think this is not very clever. Could this be changed to, for example `input` or `infile`?
",Garonenur,https://github.com/genometools/genometools/issues/368,genometools++genometools.csv
MDU6SXNzdWUzOTUxMzkxMg==,gt shredder fasta header improvement,CLOSED,2014-08-05T12:31:21Z,2014-08-07T08:50:06Z,2014-08-07T08:50:06Z,"it would be nice if gt shredder would provide additional information in the fasta-header, like start position and length of a fragment.

I have to check the current behaviour, but to reduce header lengths maybe a truncation of the input header to the identifier would be in order.
",Garonenur,https://github.com/genometools/genometools/issues/369,genometools++genometools.csv
MDU6SXNzdWUzOTk1NjE5NA==,Missing methods in GtEOFNode not handled,CLOSED,2014-08-11T13:08:38Z,2014-08-11T15:01:38Z,2014-08-11T15:01:38Z,"The _GtEOFNode_ class does not implement methods like `gt_genome_node_get_range()` etc. leading to failing assertions when these are called on such objects. I propose to handle these cases analogously to _GtSequenceNode_, which simply delivers (0,0) as the range. As `idstr`, I would propose to return the filename. Any objections?
",satta,https://github.com/genometools/genometools/issues/374,genometools++genometools.csv
MDU6SXNzdWUzOTk2NjU1MQ==,Error converting gtf to gff,CLOSED,2014-08-11T14:59:00Z,2014-08-28T23:58:47Z,2014-08-28T23:58:47Z,"Hi,

When I try running GenomeTools converter from gtf to gff, I get this error:

/site/ne/home/e0215817/local/src/genometools/bin/gt gtf_to_gff3 hg19.gtf
Assertion failed: (strand_a != GT_STRAND_FORWARD), function gt_strand_join, file src/core/strand.c, line 54.
This is a bug, please report it at https://github.com/genometools/genometools/issues.

Could you please let me know if you have a fix for this?

Thanks
Sharvari
",sharvari14,https://github.com/genometools/genometools/issues/376,genometools++genometools.csv
MDU6SXNzdWUzOTk2Njc1OA==,assertion failed with gt stat (version 1.5.4),CLOSED,2014-08-11T15:00:48Z,2014-08-12T17:01:55Z,2014-08-11T18:11:25Z,"gt gff3validator Tcas3.22.gff3
input is valid GFF3

gt stat -genelengthdistri -genescoredistri -exonlengthdistri -exonnumberdistri -intronlengthdistri -cdslengthdistri -source -addintrons Tcas3.22.gff3 > tcastat
Assertion failed: (gt_feature_node_score_is_defined(fn)), function gt_feature_node_get_score, file src/extended/feature_node.c, line 492.
This is a bug, please report it at https://github.com/genometools/genometools/issues.
",n-long,https://github.com/genometools/genometools/issues/377,genometools++genometools.csv
MDU6SXNzdWU0MDAzNDI4Nw==,Investigate stability problems with malformed LTRdigest input,CLOSED,2014-08-12T08:28:58Z,2014-12-04T10:09:12Z,2014-12-04T10:09:12Z,"When processing candidate annotations in GFF3 not conforming to the requirements (one `LTR_retrotransposon` feature with two `long_terminal_repeat` child nodes), LTRdigest runs into assertions or in some cases even segfaults. The same happens when some of the required features are there but only have length 1. This was discovered when crafting input GFF3 from the output of other transposon prediction tools. 
Input needs to be checked for sanity before trying to process it with any of the LTRdigest visitors and rejected if it does not meet the requirements.
",satta,https://github.com/genometools/genometools/issues/379,genometools++genometools.csv
MDU6SXNzdWU0MDE1NTI0OQ==,GtFeatureNode Lua bindings should include iterators for attributes,CLOSED,2014-08-13T13:42:38Z,2014-08-15T12:19:18Z,2014-08-15T12:19:18Z,"Right now there is no way to find out what attributes a feature has using the Lua bindings. I propose to add an iterator which could be used in the following way:

``` Lua
for k,v in featurenode:attribute_pairs() do
  print(""Attribute: "" .. k ..  "" has value "" .. v)
end
```
",satta,https://github.com/genometools/genometools/issues/382,genometools++genometools.csv
MDU6SXNzdWU0MDE2MzE5Mg==,GtTagValueMap fails to correctly remove the only tag in a map,CLOSED,2014-08-13T15:00:23Z,2014-08-15T12:19:18Z,2014-08-15T12:19:18Z,"If there is only one tag-value pair left in a map, trying to remove that entry via `gt_tag_value_map_remove()` will corrupt the map in a way that subsequent add/set operations will not recover from this problem.
",satta,https://github.com/genometools/genometools/issues/384,genometools++genometools.csv
MDU6SXNzdWU0MDMxMTQyMg==,gt fingerprint is case insensitive,CLOSED,2014-08-14T23:47:50Z,2014-08-19T21:23:07Z,2014-08-19T21:23:07Z,"MD5 of 'a' is different from 'A' and lower case in fasta means soft-masked. So I was looking for an option to make `gt fingerprint` case insensitive, which turned out to be the default behaviour.

I dunno if this should be documented. And the question remains in my head: is it correct to call AAG the same as 'AaG'?
",yeban,https://github.com/genometools/genometools/issues/386,genometools++genometools.csv
MDU6SXNzdWU0MDMzNjAxNw==,match_iterator_blast fails on small E-values,CLOSED,2014-08-15T09:50:36Z,2014-08-15T11:01:53Z,2014-08-15T11:01:53Z,"in `match_iterator_blast.c` blast gets called and a provided E-value gets passed to the blast process. The problem there is the restriction of the possible E-values by using

``` c
sprintf(callstring, ""-evalue %.6f"", callstring);
```

If very small evalues like x^e-7 are to be used.

as blast understands scientific formating of numbers, I propose to change it to `""%.6e""`, if the `%e` conversion specifier is not a problem for other platforms.
",Garonenur,https://github.com/genometools/genometools/issues/387,genometools++genometools.csv
MDU6SXNzdWU0MDgzMjIyOQ==,Graceful handling of strand for interfeat inference,CLOSED,2014-08-21T18:13:29Z,2014-08-21T20:02:11Z,2014-08-21T20:02:11Z,"Currently the `GtInterFeatureVisitor` uses an assert statement to ensure that related features of interest (i.e. exons) are on the same strand when inferring internal features (i.e. introns). I had an erroneous GFF3 file (produced by Maker) where the exons of a tRNA gene were on opposite strands. The assert message gave me (a frequent GenomeTools user/contributor) an idea of what the problem was, but it still took me a while to track down the precise details. The message would be much more cryptic to a novice user.

I propose setting an error and returning -1 instead of failing by assertion for errors of this type.
",standage,https://github.com/genometools/genometools/issues/394,genometools++genometools.csv
MDU6SXNzdWU0MDk5MzA5Mw==,gt_readjoiner_assembly_runner bug,CLOSED,2014-08-24T02:37:27Z,2015-07-17T08:19:07Z,2014-12-09T10:09:44Z,"Hello, I met this problem with gtgt_readjoiner_assembly_runner, which might be a bug.
My command is:

```
$ gt readjoiner assembly  -readset test.fasta -l 60
# gt readjoiner assembly (version 1.2)
Assertion failed: (reads != NULL), function gt_readjoiner_assembly_runner, file src/tools/gt_readjoiner_assembly.c, line 510.
This is a bug, please report it at https://github.com/genometools/genometools/issues.
```

I appreciate if you could let me know there is anything that I may have missed. 
",yifangt,https://github.com/genometools/genometools/issues/396,genometools++genometools.csv
MDU6SXNzdWU0MTY5MTYyNA==,Make Lua script location available in scripts ,CLOSED,2014-09-02T09:41:36Z,2014-09-02T10:54:21Z,2014-09-02T10:54:21Z,"Lua's `require` does not have a concept of directories, so including source from relative paths is not trivial. One has to adapt the `package.path` global variable with the exact directory to search for the file to load. Unfortunately, there is no easy way to obtain the location of the script which is currently executed (you would need some magic involving the `debug` library), which can become a problem when the script currently executed  is not in the current working directory.

I propose to add a new field to the global `gt` table, say `gt.script_dir`, containing the directory the current script is located in (based on the path used for calling it). If there was no path, i.e. the script is in the current working directory, `gt.script_path` should be `.`.

This would allow one to write the following:

```
package.path = gt.script_dir .. ""/../?.lua;"" .. package.path
require(""lib"")
```

(in this example the file (`../lib.lua`) to include is in the parent directory relative to the script directory)
",satta,https://github.com/genometools/genometools/issues/398,genometools++genometools.csv
MDU6SXNzdWU0MjUxNDE5Mg==,addition to coding convention,OPEN,2014-09-11T11:30:53Z,2014-10-29T07:38:34Z,,"The pull request #410 added spaces to a usage of `GT_LLU`. I would like this to be added to all of these, first as we see it is needed for C++11, and it helps readability in my opinion.
Also removing the redundand `""""` at the end of format strings with one of our makros at the end or beginning i.e. `""Some Value: ""GT_WU"""", gtuwordvar` should be written as: `""Some Value: "" GT_WU, gtuwordvar`
I have no Idea if this is easy to add to the src-check script, but it should be added to the devguide if all are ok with this.
",Garonenur,https://github.com/genometools/genometools/issues/411,genometools++genometools.csv
MDU6SXNzdWU0MjUyMTA4OQ==,-createman ignores ```gt_option_hide_default()```,CLOSED,2014-09-11T13:03:09Z,2015-04-02T08:28:26Z,2014-12-10T12:28:18Z,"The documentation of gt is created by calling `gt -createman` this ignores if any option for a tool was set to not show its default value.
This is a little missleading in case of the -seed option for gt, because showing a default seed which is different everytime we call `gt -createman` makes no sense. Also many options hide their default values for a reason, and these defaults should not show up in the documentation.
",Garonenur,https://github.com/genometools/genometools/issues/412,genometools++genometools.csv
MDU6SXNzdWU0MjU1MTg1NQ==,Can we have an option to suppress warnings?,CLOSED,2014-09-11T17:50:55Z,2014-09-13T20:36:23Z,2014-09-13T20:36:23Z,"I think,
- `-q / --quiet` would be the name.
- It would be a global option, i.e. it would be invoked such: `gt -q gff3 <filename>`.
- Setting this option would somehow cause stderr to be redirected to `/dev/null`, or make the method that prints warning a null-op (a function that does nothing). 
",yeban,https://github.com/genometools/genometools/issues/414,genometools++genometools.csv
MDU6SXNzdWU0Mjc4MTYwMQ==,-createman should break long lines,OPEN,2014-09-15T15:01:15Z,2015-04-02T08:28:26Z,,"This came up in #417.
",yeban,https://github.com/genometools/genometools/issues/418,genometools++genometools.csv
MDU6SXNzdWU0MzE2MzgwMg==,Cairo surface init fails with very large widths,CLOSED,2014-09-18T18:27:44Z,2014-09-19T15:27:53Z,2014-09-19T15:27:53Z,"ParsEval automatically calculates the width of a graphic to produce based on the width of the genomic region it's displaying. I had previously set a lower bound of 650px, but had not set an upper bound. Therefore when it tried to create a graphic 42k pixels in width, naturally Cairo failed. However, the failure was silent, and even though it was followed directly by a assertion error (`src/annotationsketch/graphics_cairo.c:129`) it still took me some time to isolate the issue.

With a bit of experimentation I found that `cairo_image_surface_create` gives up somewhere between 30000 and 40000 pixels. The exact value may be documented somewhere, but I didn't find it with a quick search. Regardless, this is way above what is expected for typical usage. I ended up using 10000px as the upper bound for ParsEval.

Perhaps we should drop a warning message to stderr whenever the width is above some threshold (e.g., 10000) indicating that if something fails it's probably due to a width issue?
",standage,https://github.com/genometools/genometools/issues/422,genometools++genometools.csv
MDU6SXNzdWU0NTM3MTAzOQ==,Problem running ParsEval: error in gt_node_stream_pull(),CLOSED,2014-10-09T14:14:33Z,2014-10-11T00:07:47Z,2014-10-11T00:07:47Z,"I run ParsEval using the command:
    parseval -f html -o parseval_ncbi_prokka --png bartonella_hens_houston_ncbi.gff ncbi_prokka_def.gff &> parse_ncbi_prokka_4.txt

But I got an error terminating the execution, outputing:

```
[AgnLocusStream::agn_locus_stream_new_pairwise] error processing reference input: the multi-feature with ID ""gltX"" on line 2512 in file ""bartonella_hens_houston_ncbi.gff"" has a different strand than its counterpart on line 2484

Assertion failed: (!err || !gt_error_is_set(err)), function gt_node_stream_pull, file src/extended/node_stream.c, line 115.
This is a bug, please report it at https://github.com/genometools/genometools/issues.
```

In the corresponding file, the mentioned feature is in two different positions once in the negative and once in the positive strand, leading to this error.
I am running Parseval through AEGeAn v. 0.11 with genometools v. 1.5.3.

Thank you.
",damianosmel,https://github.com/genometools/genometools/issues/428,genometools++genometools.csv
MDU6SXNzdWU0NTQ3NDc4OQ==,Installation of userscripts,CLOSED,2014-10-10T12:21:41Z,2014-10-28T12:51:17Z,2014-10-28T12:51:17Z,"some scripts in `$GTDIR/scripts` are intended to be used by non-developers. These scripts should therefore be available after a `make install`.

I think it would be easiest if there were two folders, one for user-scripts that are intended to be used with the gt binary or in preparation of data etc. and one for dev-scripts that contains make wrapers from Stefan and Me, pre-commit hooks code-gen-scripts and the like.

`make install` would then ""just"" copy the contents of the user-scripts to `$PREFIX/bin`.

Any ideas/objections?
",Garonenur,https://github.com/genometools/genometools/issues/429,genometools++genometools.csv
MDU6SXNzdWU0NTQ4MTA1Mg==,pre-selection of tabs in Speck HTML output ,CLOSED,2014-10-10T13:37:02Z,2014-10-17T12:27:59Z,2014-10-17T12:27:59Z,"When a page from the Speck HTML output is opened for the first time, it is always the last tab which is opened by default. The first tab should be opened by default, as it contains the feature results, which are probably what most users are primarily interested in.
",satta,https://github.com/genometools/genometools/issues/430,genometools++genometools.csv
MDU6SXNzdWU0NjAzMzA2NA==,Parsing attributes from GTF input,CLOSED,2014-10-16T20:41:28Z,2014-12-07T11:00:04Z,2014-12-07T11:00:04Z,"It looks like the GenomeTools GTF parser does not load all attribute key-value pairs into memory like the GFF3 parser does: see https://gist.github.com/standage/6ce111784628155c09b0. Was this a conscious decision and is there a good motivation for this? As much as I prefer GFF3, GTF is in wide use because of a few popular tools, and it's quite inconvenient that I cannot access all of the annotated attributes.
",standage,https://github.com/genometools/genometools/issues/431,genometools++genometools.csv
MDU6SXNzdWU0NjI4MjU3NA==,libpangocairo error while building,CLOSED,2014-10-20T14:54:34Z,2014-11-30T19:16:55Z,2014-11-30T19:16:55Z,"How to solve

```
/usr/lib/gcc/i686-linux-gnu/4.8/../../../i386-linux-gnu/libpangocairo-1.0.so: undefined reference to `cairo_ft_scaled_font_unlock_face'
/usr/lib/gcc/i686-linux-gnu/4.8/../../../i386-linux-gnu/libpangocairo-1.0.so: undefined reference to `cairo_ft_font_options_substitute'
/usr/lib/gcc/i686-linux-gnu/4.8/../../../i386-linux-gnu/libpangocairo-1.0.so: undefined reference to `cairo_ft_scaled_font_lock_face'
/usr/lib/gcc/i686-linux-gnu/4.8/../../../i386-linux-gnu/libpangocairo-1.0.so: undefined reference to `cairo_ft_font_face_create_for_pattern'
collect2: error: ld returned 1 exit status
```
",rimjhimroy,https://github.com/genometools/genometools/issues/436,genometools++genometools.csv
MDU6SXNzdWU0NjY3NjQwNQ==,sequniq did not do what is said,CLOSED,2014-10-23T21:00:16Z,2014-10-28T20:02:19Z,2014-10-28T20:02:19Z,"Hello:
When I tried to remove redundant sequences (any substring of both the forward strand and the reverse complement) with genometools, but it did not give me what is expected. Here is my test:
INFILE.fasta: 

```
>seq1
ATCGATCGATATATATATAT
>seq2 part of seq1
CGATCGATATATATATA
>seq3 part of seq2
ATCGATATATAT
>seq4 reverse complementary of seq 2
TATATATATATCGATCG
>seq5 new seq
ATCGATCGACGATCGAGCGCG
>seq6 another new
ATCGATCGCGCGCGCGCGCGCGC
>seq7 psubstring of seq6
CGCGCGCGCGCGCGCG
```

I was expecting to get output like:

```
>seq1
ATCGATCGATATATATATAT
>seq5 new seq
ATCGATCGACGATCGAGCGCG
>seq6 another new
ATCGATCGCGCGCGCGCGCGCGC
```

but the output is the same as input:

```
>seq1
ATCGATCGATATATATATAT
>seq2 part of seq1
CGATCGATATATATATA
>seq3 part of seq2
ATCGATATATAT
>seq4 reverse complementary of seq 2
TATATATATATCGATCG
>seq5 new seq
ATCGATCGACGATCGAGCGCG
>seq6 another new
ATCGATCGCGCGCGCGCGCGCGC
>seq7 psubstring of seq6
CGCGCGCGCGCGCGCG 
#0 out of 7 sequences have been removed (0.000%)
```

Or only one sequence was removed if I turned on ""-rev yes"" option.

```
>seq1
ATCGATCGATATATATATAT
>seq2 part of seq1
CGATCGATATATATATA
>seq3 part of seq2
ATCGATATATAT
>seq4 reverse complementary of seq 2
TATATATATATCGATCG
>seq5 new seq
ATCGATCGACGATCGAGCGCG
>seq6 another new
ATCGATCGCGCGCGCGCGCGCGC

#1 out of 7 sequences have been removed (14.286%)
```

Here is the command I used:

```
$ gt sequniq INPUT.fasta 
$ gt sequniq -rev yes INPUT.fasta 
```

Did I miss anything to accomplish this type of work with genometools?
I appreciate if you could give me some help on this.
Thanks you!

Yifang
",yifangt,https://github.com/genometools/genometools/issues/438,genometools++genometools.csv
MDU6SXNzdWU0NzAzMzMxMA==,default 64bit compilation,CLOSED,2014-10-28T14:37:12Z,2014-11-03T15:38:46Z,2014-11-03T15:38:46Z,"It is confusing that genometools still compiles with 32bit. I recommend 64bit to become default value and then change the make option to 64bit=no for people who need 32bit. 
",joergi-w,https://github.com/genometools/genometools/issues/442,genometools++genometools.csv
MDU6SXNzdWU0NzQ1OTI2OQ==,Number of input HMM files,CLOSED,2014-11-01T00:22:03Z,2014-12-02T10:13:38Z,2014-12-02T10:12:54Z,"```
Assertion failed: (strspn(b, ""012+-"") == (size_t) 2), function gt_ltrdigest_pdom_visitor_parse_alignments, file src/ltr/ltrdigest_pdom_visitor.c, line 381.
```
",ksi2204,https://github.com/genometools/genometools/issues/445,genometools++genometools.csv
MDU6SXNzdWU0NzczODkyMg==,gt extractfeat does not use phase when translating,CLOSED,2014-11-04T17:14:49Z,2014-11-05T12:41:39Z,2014-11-05T12:09:33Z,"It is possible that a CDS feature starts with a phase offset (when missing an initial exon, for example). 
The gff phase column has [special meaning](http://sequenceontology.org/resources/gff3.html) to CDS features, and I suggest that it should be considered when the user uses the `-translate` parameter.

Example:

``` sh
git clone https://gist.github.com/c1f70869f32ce127498d.git
cd c1f70869f32ce127498d
gt extractfeat \
    -type CDS \
    -join \
    -translate \
    -seqfile Scaffold_102.fa \
    -matchdesc \
    Scaffold_102.gff3
```

Giving:

```
>CDS_1 (joined) (translated)
TFRPR*ITRWLSG*GLVRYRN*ADKSLHQLRTAMHHHLKNQERALNLSILISSGP
```

When I would expect:

```
>CDS_1 (joined) (translated)
LPAKVNNSLALRLRSRSLSQLSRQITPPTKNGHAPPPEKSRKSSQSVNPYFIWT
```
",robsyme,https://github.com/genometools/genometools/issues/447,genometools++genometools.csv
MDU6SXNzdWU0NzgyNDU3NQ==,Mixing HMMs of different formats triggers parsing problem in ltrdigest,CLOSED,2014-11-05T11:12:39Z,2014-11-30T19:03:33Z,2014-11-30T19:03:33Z,"To reproduce this error, one needs access to 
the research repo of the Genome Informatics group.

The following call in research/brandt/ltr-SK
leads to an error. It involves HMMs of two different formats:

```
env -i PATH=/work/gi/software/bin \
          ${GTBIN}  -j 4 ltrdigest -hmms \
                    ../HMMs/Pfam/ATHILA.hmm \
                    ../HMMs/GYDB/ENV_athila.hmm \
                 -pdomevalcutoff 1e-4 -trnas hg18-tRNAs.fa.uniq -pbsmaxedist 2 -seqfile 
               /work/steinbiss/hsap_brandt_new/Homo_sapiens.NCBI36.50.dna.chromosome.7.fa              chr7.ltrharvest.gff
```

where `GTBIN` is the gt binary compiled from the gt-master branch ac2724f5047c4bb415fd7cb52eb2acfab0988b7d  with make option
`${MAKE} -j 4 with-sqlite=no 64bit=yes threads=yes CC='ccache gcc'`

The error message is:

```
Error: bad file format in HMM file /tmp/0385e34ad167d68b9af1d2850c4ea1ea
/local/kurtz/genometools/bin/gt ltrdigest: error: an error occurred during HMM preprocessing
```
",stefan-kurtz,https://github.com/genometools/genometools/issues/449,genometools++genometools.csv
MDU6SXNzdWU0NzgzMzk3MA==,GtUlong to GtUword,CLOSED,2014-11-05T13:10:33Z,2014-11-07T09:35:10Z,2014-11-07T09:35:10Z,"I don't see any reason why GtUlong, which is typedefed as GtUword is in use. could this be simply changed by search and replace?
",Garonenur,https://github.com/genometools/genometools/issues/451,genometools++genometools.csv
MDU6SXNzdWU0NzgzNTQzOQ==,option -rule_files parses all following arguments including input file,CLOSED,2014-11-05T13:27:20Z,2014-11-05T17:14:05Z,2014-11-05T17:14:05Z,"This report refers to the gt build from the current master ac2724f5047c4bb415fd7cb52eb2acfab0988b7d

```
bin/gt select -rule_files ./testdata/gtscripts/filter_test_orflength.lua ../gttestdata/gff3testruns/EST.gff
bin/gt select: error: cannot run file: ../gttestdata/gff3testruns/EST.gff:2: malformed number near '2L'
```

should apply the lua-filter to the the file EST.gff It seems to consider this as an additional
rules files and suggests an error in the parser for the select-tool.
",stefan-kurtz,https://github.com/genometools/genometools/issues/452,genometools++genometools.csv
MDU6SXNzdWU0ODA2NDU0NA==,condenser tests fail without BLAST installed,CLOSED,2014-11-07T09:44:30Z,2014-11-11T09:40:19Z,2014-11-11T09:40:19Z,"When trying to run the condenser 'compress + search' tests, I get the following error:

```
[ss34@mib106184i:~] cat /Users/ss34/develop/genometools/testsuite/stest_testsuite/test69/stderr_3                              [0]
debug: seed=1532348643
debug: loading encseq varlen_50.fas_nr with des: 0, sds: 0, ssp: 1, ois: 0, md5: 0, mirr: 0
# IDs const len: 8
debug: 27 queries, avg query size: 300
# Raw E-value set to 2.7940e-07
debug: executed call: makeblastdb -dbtype nucl -in varlen_50.fas_nr.fas
sh: makeblastdb: command not found
sh: blastn: command not found
Assertion failed: (coarse_db_len != 0), function gt_condenser_search_runner, file src/tools/gt_condenser_search.c, line 415.
This is a bug, please report it at https://github.com/genometools/genometools/issues.
```

I do not have BLAST installed -- this case should be detected by the test suite and these test should not be run (and more importantly, this should be handled gracefully by the condenser tool with an error message).
",satta,https://github.com/genometools/genometools/issues/461,genometools++genometools.csv
MDU6SXNzdWU0ODYyODkzMA==,travis compile with threaded,CLOSED,2014-11-13T12:07:42Z,2014-11-19T11:52:23Z,2014-11-19T11:52:23Z,"Should we add travis tests with threads enabled? Just compilation, or also run the tests? (If tests, how many threads are available on travis?)
",Garonenur,https://github.com/genometools/genometools/issues/465,genometools++genometools.csv
MDU6SXNzdWU0ODY0Njk4Mw==,translation code and ambiguity handling,OPEN,2014-11-13T15:16:17Z,2015-08-04T17:43:46Z,,"Currently, the protein translation engine sometimes makes unexpected calls when ambiguity is involved. For example,

```
$ gt -i
gt (GenomeTools) 1.5.3 (2014-06-19 11:44:22)
> print(gt.translate_dna(""nag""))
*
```

So NAG is translated to a stop codon, while it could be CAG (Q) or AAG(K). The only stop codon possible in this context is TAG, but I would expect the translator to give me X here instead of a stop codon. This currently makes some of my validator scripts give incorrect results, stating that gene models have internal stop codons while they may not.
",satta,https://github.com/genometools/genometools/issues/468,genometools++genometools.csv
MDU6SXNzdWU0ODY4ODMzMQ==,Readjoiner same error!,CLOSED,2014-11-13T20:34:39Z,2014-11-14T09:44:54Z,2014-11-14T09:44:54Z,"Hello, I downloaded the new version and compiled without any problem. But the error is exactly the same. Anything that I should pay attention to?
Thanks a lot!
",yifangt,https://github.com/genometools/genometools/issues/470,genometools++genometools.csv
MDU6SXNzdWU0ODc3NDkwOQ==,speck template engine should provide a GtGFF3Visitor printing to the output destination,CLOSED,2014-11-14T11:21:45Z,2014-11-24T12:00:48Z,2014-11-24T12:00:48Z,"This would allow a developer to write output drivers which also print GFF3 lines for offending features, so a user does not have to grep the file for the feature IDs. 
",satta,https://github.com/genometools/genometools/issues/471,genometools++genometools.csv
MDU6SXNzdWU0OTI5NzI0NQ==,Support for Cairo installed with Homebrew,CLOSED,2014-11-18T21:41:59Z,2014-11-18T21:54:59Z,2014-11-18T21:54:59Z,"For Mac users that install Cairo with Homebrew, the current Makefile does not correctly locate the Cairo headers.
",standage,https://github.com/genometools/genometools/issues/473,genometools++genometools.csv
MDU6SXNzdWU0OTg4NDc1Mg==,LTRdigest Assertion failed,CLOSED,2014-11-24T12:33:06Z,2014-11-28T18:42:19Z,2014-11-28T18:41:40Z,"Hi all, 

I am using genometools for the first time to run LTRharvest and LTRdigest. When I specify a hmm for LTRdigest I get the following error: 

```
$ /opt/gt-1.5.3-Linux_x86_64-64bit-barebone/bin/gt -j 4 ltrdigest -hmms ~/Documents/pfam/Pfam-AB.hmm -outfileprefix ltrdigest ltrharvest_sorted.gff3 AP11.scf.fasta >ltrdigest.gff3
Assertion failed: (strspn(b, ""012+-"") == (size_t) 2), function gt_ltrdigest_pdom_visitor_parse_alignments, file /home/gordon/genometools/src/ltr/ltrdigest_pdom_visitor.c, line 381.
This is a bug, please report it at https://github.com/genometools/genometools/issues.
```

Any help would be greatly appreciated. 

Thanks
",RvV1979,https://github.com/genometools/genometools/issues/477,genometools++genometools.csv
MDU6SXNzdWU0OTkwNDA5NA==,Sketch output issues on OS X ,CLOSED,2014-11-24T15:46:47Z,2014-11-24T16:44:37Z,2014-11-24T16:44:37Z,"I installed GenomeTools on my Macbook Pro with Homebrew, which also handled installation of the Cairo and Pango prerequisites. When I use the `gt sketch` tool or link against that library, there are no problems. However, when I clone from GitHub and install myself using make, all PNG files created by `gt sketch` (or by calls to the C API) are blank. The PNG files have the correct dimensions, but no content. No compile-time or run-time warnings/errors are issued.

By the way, I just recently upgraded to Max OS X Yosemite.
",standage,https://github.com/genometools/genometools/issues/478,genometools++genometools.csv
MDU6SXNzdWU1MTE4MDI0Ng==,Prepare for 1.5.4 release,CLOSED,2014-12-06T11:56:05Z,2014-12-12T19:03:49Z,2014-12-12T19:03:49Z,"I think it's time for a new release, with all these changes in the last 6 months. I think most of the critical bugs have been addressed (#396 pending confirmation). I have just added some history items to the CHANGELOG -- if anyone has something to add, please go ahead and do so.
",satta,https://github.com/genometools/genometools/issues/493,genometools++genometools.csv
MDU6SXNzdWU1MTIwNzkxOQ==,GTF parser doesn't handle duplicated tags,CLOSED,2014-12-07T05:21:29Z,2014-12-07T09:53:16Z,2014-12-07T09:53:16Z,"The Gencode GTF file in the `gttestdata` repo includes features with multiple `ont` attributes with different values. While the general case is handled correctly by the GFF3 parser, it is not by the GTF parser.
",standage,https://github.com/genometools/genometools/issues/496,genometools++genometools.csv
MDU6SXNzdWU1MjEzMDAyOQ==,Use ctypes idiomatically for Python bindings,OPEN,2014-12-16T15:57:06Z,2015-01-08T10:18:24Z,,"We recently updated the Python bindings so that they would work ""correctly"" on OS X as well as Linux--that is, it does not segfault and produces correct output. However, the updates abandoned some of the nice features of `ctypes` that did not seem to work correctly on OS X. See #211.

I opened up [a bug report](http://bugs.python.org/issue22945) with the Python folks, and their reply pointed out something that we had missed. See eryksun's message: essentially, we need to do an additional conversion/dereference for pointers to C objects.

``` c
// Old way: problems on OS X
self._as_parameter_ = self.g

// New way: no problems
self._as_parameter_ = c_void_p(self.g)
```

I confirmed that this fix worked for my dummy C library example, so I don't see any reason it shouldn't work for the GenomeTools python bindings. I would much rather use `ctypes` idiomatically than go through and do the type/error checking that seemed inevitable from working with pointers directly.
",standage,https://github.com/genometools/genometools/issues/510,genometools++genometools.csv
MDU6SXNzdWU1Mjk0MTU3Ng==,Is it possible to generate a string graph without doing reverse complements of the reads?,OPEN,2014-12-26T22:40:34Z,2015-01-13T17:33:01Z,,"In my application, I have a set of reads, and I already know that all the reads are from the forward strand. So I do not want to do the reverse complement when generating the string graph using `gt readjoiner overlap`.  Is there an option available for this? Thanks.
",hangelwen,https://github.com/genometools/genometools/issues/513,genometools++genometools.csv
MDU6SXNzdWU1Mjk1MDQ4NA==,Trying to understand gff3 validator error message.,CLOSED,2014-12-27T06:57:47Z,2015-01-21T11:29:34Z,2015-01-21T09:45:37Z,"I'm working on exporting GFF3 from a database for a project of mine. After export I use gt to validate the GFF3 file (will subsequently use gt to obtain mRNA, CDS, and protein sequences from the GFF3).

This snippet - https://gist.github.com/hargup/38aeeec264b2e50d405a - passes locally, but fails the online validator at http://genometools.org/cgi-bin/gff3validator.cgi with the error message:

```
GenomeTools error: the child feature with type 'exon' on line 4 in file ""/tmp/issue.gff"" is not part-of parent feature with type 'mRNA' given on line 3 (according to type checker 'OBO file /home/satta/genometools_for_web/gtdata/obo_files/so.obo')
```

Why would that be?
",yeban,https://github.com/genometools/genometools/issues/514,genometools++genometools.csv
MDU6SXNzdWU1MzYzOTg4NA==,valgrind bin/gt -help gives strange error messages,CLOSED,2015-01-07T14:54:14Z,2015-01-08T11:34:12Z,2015-01-08T11:34:12Z,"`valgrind bin/gt -help` reports many errors of the following kind:

```
16 bytes in 1 blocks are possibly lost in loss record 69 of 244
==20771==    at 0x4C29E44: calloc (vg_replace_malloc.c:623)
==20771==    by 0x5828D58: g_malloc0 (in /usr/lib64/libglib-2.0.so.0.3800.2)
==20771==    by 0x55B458A: ??? (in /usr/lib64/libgobject-2.0.so.0.3800.2)
==20771==    by 0x55B7E01: g_type_register_fundamental (in /usr/lib64/libgobject-2.0.so.0.3800.2)
...
```

and exits with error code 1

I used the current gt master compiled with make and valgrind-3.10.0 on 
Linux roma 3.11.10-25-desktop #1 SMP PREEMPT Wed Dec 17 17:57:03 UTC 2014 (8210f77) x86_64 x86_64 x86_64 GNU/Linux

Bye, Stefan
",stefan-kurtz,https://github.com/genometools/genometools/issues/521,genometools++genometools.csv
MDU6SXNzdWU1Mzc4Mzc4Nw==,Default style,CLOSED,2015-01-08T18:30:35Z,2015-01-09T03:43:33Z,2015-01-09T00:50:46Z,"I want to make my own style file, but starting from the default style. 

Where can I obtain the default file?

(When I specify my own file, the text dissapeard)
",juancresc,https://github.com/genometools/genometools/issues/523,genometools++genometools.csv
MDU6SXNzdWU1Mzg2OTkxMQ==,add padding to sketch,CLOSED,2015-01-09T13:57:18Z,2015-01-09T18:09:05Z,2015-01-09T18:09:05Z,"Some of the titles of the image are splitted. I want to add some padding in order to show them entirely.

This is a screenshot of the issue
![image](https://cloud.githubusercontent.com/assets/2141907/5680598/32a76d2e-97ee-11e4-873f-fbf949f9d442.png)

thank you
",juancresc,https://github.com/genometools/genometools/issues/524,genometools++genometools.csv
MDU6SXNzdWU1Mzg3MTc2Mg==,add API methods to extract flanking sequence for a feature node,OPEN,2015-01-09T14:17:30Z,2015-06-12T17:38:08Z,,"While it is easy to get the sequence for a feature given a GtRegionMapping, it is sometimes desired to extract a flanking sequence, either downstream or upstream of the feature. We should add some API functions implementing these queries, automatically taking strandedness etc. into account.

These methods should also be available in the scripting language bindings (I will need Lua, but it is best done in all of them).
",satta,https://github.com/genometools/genometools/issues/525,genometools++genometools.csv
MDU6SXNzdWU1NDc0MDg0OQ==,gt sketch Assertion failed while generating gene model image,CLOSED,2015-01-19T09:15:06Z,2015-01-25T20:51:42Z,2015-01-25T20:51:42Z,"Hi, I received the following error when running gt sketch:

```
ccgstaff@brlscratch:~/bchapman/Grape/Chapter4_figures/chr18$ gt sketch -start 4109200 -end 4112700 -style default.style -force gene.png 4.AUGUSTUS_PREDICTION3
warning: seqid ""chr18"" on line 2 in file ""4.AUGUSTUS_PREDICTION3"" has not been previously introduced with a ""##sequence-region"" line, create such a line automatically
Assertion failed: (gt_hashmap_get(d->nodeinfo, rep)), function process_node, file src/annotationsketch/diagram.c, line 621.
This is a bug, please report it.
```

I was generating an illustration of the gene models reported by Augustus, and received the error.

Heres an example of a particular gene model I'm interested in. However, I received the error with the whole GFF file for this chromosome, as well as just this GFF of the gene model.

```
chr18   AUGUSTUS        gene    4098351 4112761 .       -       .       ID=g68938
chr18   AUGUSTUS        mRNA    4098351 4112761 0.69    -       .       ID=g68938.t1;Parent=g68938
chr18   AUGUSTUS        CDS     4098351 4098407 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4098408 4098489 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4098490 4100643 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4100644 4100780 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4100781 4100957 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4100958 4101153 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4101154 4101367 1       -       1       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4101368 4101455 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4101456 4101805 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4101806 4101946 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4101947 4102184 1       -       1       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4102185 4102577 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4102578 4102918 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4102919 4103005 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4103006 4103275 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4103276 4103525 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4103526 4103648 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4103649 4103766 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4103767 4103844 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4103845 4104429 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4104430 4104606 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4104607 4104688 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4104689 4104775 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4104776 4104879 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4104880 4104990 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4104991 4105178 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4105179 4105367 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4105368 4105440 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4105441 4105632 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4105633 4105759 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4105760 4105846 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4105847 4106562 0.98    -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4106563 4106667 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4106668 4106800 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4106801 4106857 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4106858 4106959 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4106960 4107034 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4107035 4107150 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4107151 4107267 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4107268 4107370 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4107371 4107495 1       -       2       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4107496 4108928 0.89    -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4108929 4108968 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4108969 4109062 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4109063 4109113 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4109114 4109204 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4109205 4109392 1       -       2       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4109393 4109497 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4109498 4109591 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4109592 4110516 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4110517 4110690 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4110691 4110881 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4110882 4110977 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
chr18   AUGUSTUS        intron  4110978 4111082 1       -       .       Parent=g68938.t1
chr18   AUGUSTUS        CDS     4111083 4111175 1       -       0       ID=g68938.t1.cds;Parent=g68938.t1
```

Thanks for any help you can provide.

Brett
",brettChapman,https://github.com/genometools/genometools/issues/527,genometools++genometools.csv
MDU6SXNzdWU1NTQ5MDQ5Nw==,`gt compreads decompress` output formatting,CLOSED,2015-01-26T14:50:46Z,2015-01-27T14:10:53Z,2015-01-27T14:10:53Z,"If if I compress the following file ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data/HG00096/sequence_read/SRR062634.filt.fastq.gz with

`gt compreads compress -files SRR062634.filt.fastq.gz`

and then decompress with

`gt compreads decompress -file SRR062634.filt.fastq`

the result file `SRR062634.filt.fastq.fastq` is formatted to a width of 80 characters:

```
@0
TGATCATTTGATTAATACTGACATGTAGACAAGAAGAAAAGTATGTTTCATGCTATTTTGAGTAACTTCCATTTAGAAGC
CTACTCCTGAGCACAACATT
+
B5=BD5DAD?:CBDD-DDDDDCDDB+-B:;?A?CCE?;D3A?B?DB??;DDDEEABD+>DAC?A-CD-=D?C5A@::AC-
?AB?=:>CA@##########
@1
AATGTTATTAAAAATGGACACCTTTTTCTCACACATTCAGTTTCATTGTCTCGCACCCCATCGTTTTACTTTTCTTCCTT
CAGAAAATGATAAATGTGGG
+
AAAA?5D?BD==ADBD:DBDDDDD5D=;@>AD-CD?D=C5=@4<7CCAA5?=?>5@BC?*<:=>>:D:B5?B?5?'3::5
?5<:;*97:<A#########
@2
CAGATCAGAATAATTTTTGTGTTATGTACGTGTAAGAAAACATAGCTATTATGATATGGAAACTAGGAGTGAAATATGAG
GAATTTGTGACTTTTCTGAA
+
```

http://en.wikipedia.org/wiki/FASTQ_format says:

""The original Sanger FASTQ files also allowed the sequence and quality strings to be wrapped (split over multiple lines), but this is generally discouraged as it can make parsing complicated due to the unfortunate choice of ""@"" and ""+"" as markers (these characters can also occur in the quality string).""

That's what the original file looks like:

```
@SRR062634.321 HWI-EAS110_103327062:6:1:1446:951/2
TGATCATTTGATTAATACTGACATGTAGACAAGAAGAAAAGTATGTTTCATGCTATTTTGAGTAACTTCCATTTAGAAGCCTACTCCTGAGCACAACATT
+
B5=BD5DAD?:CBDD-DDDDDCDDB+-B:;?A?CCE?;D3A?B?DB??;DDDEEABD+>DAC?A-CD-=D?C5A@::AC-?AB?=:>CA@##########
@SRR062634.488 HWI-EAS110_103327062:6:1:1503:935/2
AATGTTATTAAAAATGGACACCTTTTTCTCACACATTCAGTTTCATTGTCTCGCACCCCATCGTTTTACTTTTCTTCCTTCAGAAAATGATAAATGTGGG
+
AAAA?5D?BD==ADBD:DBDDDDD5D=;@>AD-CD?D=C5=@4<7CCAA5?=?>5@BC?*<:=>>:D:B5?B?5?'3::5?5<:;*97:<A#########
@SRR062634.849 HWI-EAS110_103327062:6:1:1587:921/2
CAGATCAGAATAATTTTTGTGTTATGTACGTGTAAGAAAACATAGCTATTATGATATGGAAACTAGGAGTGAAATATGAGGAATTTGTGACTTTTCTGAA
+
DFFEBEF?FEGGGBEFDFB3>EE=EEEEEEEECEBDCCD<CEEEDAA=EEB=DEDFEEDF?=EBBEEAEAD@:?-?A5<AC(=?>4>?############
```

What about adding an option -width to `gt compreads decompress` with a default of 0 (no formatting), similar to the one in `gt splitfasta`?
",gordon,https://github.com/genometools/genometools/issues/537,genometools++genometools.csv
MDU6SXNzdWU1NTQ5MTEyNw==,`gt compreads decompress -descs` assertion fails,CLOSED,2015-01-26T14:55:46Z,2015-07-08T15:39:08Z,2015-07-07T17:54:28Z,"If if I compress the file ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data/HG00096/sequence_read/SRR062634.filt.fastq.gz with

`gt compreads compress -descs -files SRR062634.filt.fastq.gz`

and then decompress with

`gt compreads decompress -descs -file SRR062634.filt.fastq`

I get a failed assertion:

```
Assertion failed: (s && length <= s->length), function gt_str_set_length, file src/core/str.c, line 198.
```

I used the current master (2371aa7c4aefc3128bd21d6cbe737725321f5b95).
",gordon,https://github.com/genometools/genometools/issues/538,genometools++genometools.csv
MDU6SXNzdWU1NTUwODYxMg==,gt compreads decompress failure,CLOSED,2015-01-26T17:06:46Z,2015-01-27T13:40:26Z,2015-01-27T13:32:48Z,"if gt compreads decompress is used with `-descs` option and compression was done without it the program seqvaults.
",Garonenur,https://github.com/genometools/genometools/issues/539,genometools++genometools.csv
MDU6SXNzdWU1NTg5OTI4MA==,gt_xtmpfp_generic ignores flags?,CLOSED,2015-01-29T13:35:44Z,2016-06-16T12:47:38Z,2016-06-16T12:47:38Z,"https://github.com/genometools/genometools/blob/master/src/core/fa.h#L91

the flags are apparently ignored and TMPFP_DEFAULT_FLAGS is used instead. Is this intended? Why have the argument `flags` then? 
",Garonenur,https://github.com/genometools/genometools/issues/541,genometools++genometools.csv
MDU6SXNzdWU1NTkyNjE0OA==,gt gff3 fails for (what appears to be) a valid tRNA multifeature,CLOSED,2015-01-29T16:59:31Z,2015-01-30T16:10:58Z,2015-01-30T16:10:58Z,"See [this gist](https://gist.github.com/standage/fc0dd17151e97a9dd378): it is taken from _Drosophila_ GFF3 data posted on NCBI. The only change I made to it was to add ID/Parent relationship between the gene and tRNA features.

If you try to process this file with `gt gff3`, it complains about not being able to find the parent ID for the second tRNA entry. As far as I can tell, encoding this tRNA as a multifeature is perfectly valid, even if it's less common (especially when the exons provide the same structure).
",standage,https://github.com/genometools/genometools/issues/542,genometools++genometools.csv
MDU6SXNzdWU1Njk4NTE5Ng==,Assertion failed:,CLOSED,2015-02-09T03:33:57Z,2015-07-22T17:56:40Z,2015-07-22T17:56:40Z,"Here is what the issue reported is:

Assertion failed: (gt_feature_node_get_multi_representative(fn->representative) == fn->representative), function gt_feature_node_get_multi_representative, file src/extended/feature_node.c, line 485.
This is a bug, please report it at https://github.com/genometools/genometools/issues.

Please let me know what other information I may provide. 

CH
",butterflyology,https://github.com/genometools/genometools/issues/548,genometools++genometools.csv
MDU6SXNzdWU1Nzc4Njk2Nw==,Make GenomeTools builds reproducible,CLOSED,2015-02-16T10:23:59Z,2015-07-16T12:40:42Z,2015-07-16T08:26:16Z,"Currently the GenomeTools build process is not fully reproducible, i.e. two builds with the same make parameters will most likely result in distribution tarballs with different md5sums. This is because there are some parts of the process which write (overly detailed?) timestamps, i.e. in PDF files and C headers (leading to different binaries!). There are also random seeds in the `gt -help` output, which end up in a packaged manpage. Here's a list of the resulting differences, as seen by Debian: https://reproducible.debian.net/rb-pkg/genometools.html
",satta,https://github.com/genometools/genometools/issues/549,genometools++genometools.csv
MDU6SXNzdWU1ODA0ODI1MQ==,error in parse_options.c and gt_hop.c,CLOSED,2015-02-18T10:06:05Z,2017-06-02T22:08:43Z,2017-06-02T22:08:43Z,"Compiling genometools 1.5.4 using Intel's icc and iclc, I found two errors.

Regards,
Stefan

```
--- src/gth/parse_options.c.org 2014-12-12 19:59:19.000000000 +0100
+++ src/gth/parse_options.c 2015-02-18 10:55:55.625418731 +0100
@@ -1504,7 +1504,7 @@
   if (oprval == GT_OPTION_PARSER_OK && optproteinsmap &&
       !gt_option_is_set(optproteinsmap)) {
     if (gt_str_length(gth_input_proteinsmap(input)) > MAXSUFFIXLEN) {
-      gt_error_set(err, ""\%s argument \""%s\"" is too long (>MAXSUFFIXLEN=%u)"",
+      gt_error_set(err, ""%s argument \""%s\"" is too long (>MAXSUFFIXLEN=%u)"",
                 PROTEINSMAP_OPT_CSTR,
                 gt_str_get(gth_input_proteinsmap(input)), MAXSUFFIXLEN);
       oprval = GT_OPTION_PARSER_ERROR;
```

```
--- src/tools/gt_hop.c.org  2014-12-12 19:59:19.000000000 +0100
+++ src/tools/gt_hop.c  2015-02-18 10:57:42.914941262 +0100
@@ -197,7 +197,7 @@
   option = gt_option_new_double_min_max(""altmax"",
       ""max support of alternate homopol. length;\n""
       ""e.g. 0.8 means: do not correct any read if homop. length in more than ""
-      ""80\% of the reads has the same value, different from the cognate\n""
+      ""80% of the reads has the same value, different from the cognate\n""
       ""if altmax is set to 1.0 reads are always corrected"",
       &arguments->altmax, (double) 0.8, 0.0, (double) 1.0);
   gt_option_is_extended_option(option);
@@ -208,7 +208,7 @@
   option = gt_option_new_double_min_max(""cogmin"",
       ""min support of cognate sequence homopol. length;\n""
       ""e.g. 0.1 means: do not correct any read if cognate homop. length ""
-      ""is not present in at least 10\% of the reads\n""
+      ""is not present in at least 10% of the reads\n""
       ""if cogmin is set to 0.0 reads are always corrected"",
       &arguments->cogmin, (double) 0.1, 0.0, (double) 1.0);
   gt_option_hide_default(option);
```
",sbecuwe,https://github.com/genometools/genometools/issues/551,genometools++genometools.csv
MDU6SXNzdWU1OTcxMTY5Mg==,Interfeat support for multifeatures,CLOSED,2015-03-03T21:50:20Z,2015-03-04T00:37:24Z,2015-03-04T00:36:52Z,"Consider the following use case. I have a data file with entries like this.

```
chr1     .    EST_match       2500    3050    .       +       .       ID=EST_match4
chr1     .    EST_match       4000    5700    .       +       .       ID=EST_match4
```

I would like to use the interfeat tool and/or visitor to infer `match_gap` features between `EST_match` features. The following does not work.

```
gt interfeat -outside EST_match \
             -inter match_gap \
             annot.gff3
```

I'm guessing this is because the `EST_match` is multifeature, and it's looking at the outer edges of the entire feature instead of the inner edges of individual components.
",standage,https://github.com/genometools/genometools/issues/554,genometools++genometools.csv
MDU6SXNzdWU2Mjc0MDA3OQ==,GC-content on windows,CLOSED,2015-03-18T16:51:29Z,2015-03-21T21:32:05Z,2015-03-21T21:32:05Z,"Hi, I using GenomeTools on windows

```
/cygdrive/c/usr/local/bin/gt (GenomeTools) 1.5.5

Used compiler: cc (GCC) 4.9.2
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -O3
```

and trying to get GC-content for this test set of sequences:

```
>seq1
GGCTTAGAAAAATAGACATTCCAAGATGCCTGAAGTGTTTAAGTGGCTATTGCTAATTGGATGGTGTTGACTGTGGAGGTAAATGGATC
>seq2
TTGAGTCCAGGAGTTTGAGACCAGCCTGGACAACAGGGCAAGACCCCATCTCTAAAAATATAAAATTAGCTGGGCATGGTGTCGTGTGCCTGTGATC
>seq3
TGCACCTGCCGCCGGAGCTCTCTCTGCAAACGTTCTGTGCTGACTTAGGGGAGGCAAAGACACAGAGTTGGAGATC
```

using: `/cygdrive/c/usr/local/bin/gt.exe seq -gc-content test_gc1.fas`

```
showing GC-content for sequence file ""test_gc1.fas""
GC-content: 47.06% (AT-content: 51.84%, N-content: 0.00%)
```

then I check this result with simple awk script

`awk '!/[^ACGTN]/{split($0,a,"""");for(i in a)b[a[i]]++}END{printf(""%.2f%%"",(b[""G""]+b[""C""])/(b[""A""]+b[""T""]+b[""G""]+b[""C""])*100)}' test_gc1.fas`

answer is: 48.09%

but on linux

```
/usr/local/bin/gt (GenomeTools) 1.5.5

Used compiler: cc (Ubuntu 4.9.1-16ubuntu6) 4.9.1
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -O3 -Werror
```

using `/usr/local/bin/gt seq -gc-content test_gc1.fas`

```
showing GC-content for sequence file ""test_gc1.fas""
GC-content: 48.09% (AT-content: 51.91%, N-content: 0.00%)
```

it's OK
",enigene,https://github.com/genometools/genometools/issues/560,genometools++genometools.csv
MDU6SXNzdWU2MjkzMzY1Mg==,Improve stdin/stdout support for Lua bindings,CLOSED,2015-03-19T09:51:31Z,2015-03-20T20:05:31Z,2015-03-20T20:05:31Z,"Currently the Lua bindings (in particular the GFF3InStream/OutStream ones) do not support all the features of the C versions. For example, the instream only reads from a file (not from stdin), while the outstream only writes to stdout (not to a file). This leads to the need for workarounds in Lua scripts, such as the use of temporary files in cases where pipes should suffice.
I propose to make the input/output streams more flexible to support all the options available in the C counterparts.
",satta,https://github.com/genometools/genometools/issues/561,genometools++genometools.csv
MDU6SXNzdWU2Mzk5MjAwMg==,1.5.5 release?,CLOSED,2015-03-24T13:17:57Z,2015-03-25T11:28:26Z,2015-03-24T22:36:27Z,"With the recent bug fixes in mind, what do you think about a bugfix release?
What about #538  and #548? Delay until the next version?
",satta,https://github.com/genometools/genometools/issues/566,genometools++genometools.csv
MDU6SXNzdWU2NDUxMzE5OQ==,Assertion failed during tests,OPEN,2015-03-26T12:26:12Z,2015-03-26T12:26:12Z,,"this assertion failed on one of the tests with keyword gt_splicesiteinfo
https://github.com/genometools/genometools/blob/master/src/extended/splice_site_info_visitor.c#L162
the seed was 792592375 but I didn't gather more info as it was nearly two in the morning and I had own bugs to hunt.
I tried to reproduce it, but couldn't - maybe someone who knows the code should have a look and can close this issue if nothing pops up.
",Garonenur,https://github.com/genometools/genometools/issues/567,genometools++genometools.csv
MDU6SXNzdWU2OTA5OTc2Mw==,extractfeat: option to add attributes from 9th column to defline of resulting FASTA,OPEN,2015-04-17T09:09:04Z,2018-04-14T18:34:26Z,,"Much like `-seqid` option, it would be great if other attributes like 'Name', 'Dbxref', etc. can be added to the defline of the extracted sequence.
",yeban,https://github.com/genometools/genometools/issues/571,genometools++genometools.csv
MDU6SXNzdWU2OTQzNzUxMQ==,gt_assert() implementation,CLOSED,2015-04-19T15:50:59Z,2015-04-19T18:54:40Z,2015-04-19T18:54:40Z,"I think `gt_assert()` should call `abort(3)` instead of `exit(3)` in case of failure. Reasons:
- That's what `assert(3)` does (consistency).
- `abort(3)` signals an abnormal termination of the process and `exit(3)` a normal termination. `gt_assert()` is about abnormal terminations (programming errors).
- If libgenometools is used in programs which detect abnormal program exits (i.e., crashes), `gt_assert()` notifies the supervisor correctly.
",gordon,https://github.com/genometools/genometools/issues/573,genometools++genometools.csv
MDU6SXNzdWU3Mzc2ODIxMA==,gt gff3 -sort: Specify sequence-region sort order,CLOSED,2015-05-06T23:24:56Z,2015-05-21T08:45:01Z,2015-05-21T08:45:01Z,"My sequence regions have numerical identifiers. Is it possible to sort these numerically so that they don't sort like so:
`1 10 11 12 16 17 18 2 21 3 4 5 6 7 8 9`

They're in the correct order in the FASTA file. Perhaps the order could be specified based on that?
",sjackman,https://github.com/genometools/genometools/issues/581,genometools++genometools.csv
MDU6SXNzdWU4MDk0ODE0Mw==,gt interfeat and top-level features,OPEN,2015-05-26T12:49:59Z,2023-04-12T17:14:04Z,,"I am trying to extract intron and intergenic sequences with `gt interfeat` and `gt extractfeat`. For introns, this works nicely:

```
gt interfeat -outside CDS -inter intron annotation.gff3.gz | gt extractfeat -seqfile sequence.fasta -type intron -matchdescstart > introns.fasta
```

For intergenic regions, the outside type is a top-level feature (`gene`). I don't get any inter-features when trying this:

```
gt interfeat -outside gene -inter intergenic_region annotation.gff3.gz
```

Is there a specific reason for this behaviour? I can imagine this could have to do with no parent element to attach the inter-features to, but I would expect them to be emitted as top-level features of their own.

Also, the `gt interfeat` tool should probably be able to also emit the region between the first/last item of the outside type and the start/end of the sequence region containing the feature. 

Cheers
S.
",satta,https://github.com/genometools/genometools/issues/589,genometools++genometools.csv
MDU6SXNzdWU4MTUyMzQwMQ==,GtSplitter,CLOSED,2015-05-27T16:41:43Z,2016-06-16T12:35:33Z,2016-06-16T12:35:33Z,"I was checking out our two tokenizer/splitter classes and would like to ask if it would be possible to enhance the GtSplitter class.
As the GtTokenizer works on files, not strings, which is inconvenient if you have very long lines in a file and just want to extract one of the first tokens from each line.
What I would like to change on GtSplitter is the handling of ""empty"" tokens, if the delimiter is ' ' and the input contains long stretches of those it would be nice if it skipped those empty results and returns the next non empty string.
",Garonenur,https://github.com/genometools/genometools/issues/591,genometools++genometools.csv
MDU6SXNzdWU4MTY0NjMxOQ==,extractfeat: no mapping rule given,OPEN,2015-05-27T22:09:44Z,2015-06-01T14:40:54Z,,"The sequences in the my GFF file and in my FASTA file have the same names, yet `extractfeat` complains that it needs a mapping function. How do I tell it that the mapping function is the identity function?

```
 gt extractfeat -type gene -seqfile foo.fa foo.gff
gt extractfeat: error: no mapping rule given and no MD5 tags present in the query seqid ""1"" -- no mapping can be defined
 head -n1 foo.fa
>1
```
",sjackman,https://github.com/genometools/genometools/issues/592,genometools++genometools.csv
MDU6SXNzdWU4MjA1ODY5NA==,extractfeat: Assertion failed: (gt_str_length(seqid)),CLOSED,2015-05-28T18:06:32Z,2015-05-29T17:41:24Z,2015-05-29T11:38:18Z,"```
 gt extractfeat -translate -type gene -matchdescstart -seqid -seqfile foo.fa foo.gff >aa.fa
Assertion failed: (gt_str_length(seqid)), function construct_description, file src/extended/extract_feature_visitor.c, line 68.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
```
## Test case
### foo.fa

```
>1
TTACAAGCTTGAAAGAATGAATGACATCCTTTTTCTTCCCTCAATGCTATAGAAATAAGG
```
### foo.gff

```
##gff-version   3
##sequence-region   1 1 60
1   prokka  gene    1   60  .   +   1   ID=gene1;locus_tag=OU3MT_00001
1   Prodigal:2.6    mRNA    1   60  .   +   0   Parent=gene1;Name=orf00001;inference=ab initio prediction:Prodigal:2.6;locus_tag=OU3MT_00001;product=hypothetical protein
```
",sjackman,https://github.com/genometools/genometools/issues/593,genometools++genometools.csv
MDU6SXNzdWU4MjA3NDY2Ng==,seqtranslate: Specify frame,CLOSED,2015-05-28T18:38:24Z,2015-06-23T17:47:13Z,2015-06-20T11:47:22Z,"`seqtranslate` does six-frame translation. It would be useful to specify only the first frame `(1+)`. I'm using  this sed script:

``` sh
gt seqtranslate -reverse no -fastawidth 0 \
|sed -n '/ (1+)$/{s/ (1+)$//;p;n;p;n;n;n;n;}'
```

Outputting the longest ORF of the six-frame translation would also be a very useful feature.
",sjackman,https://github.com/genometools/genometools/issues/595,genometools++genometools.csv
MDU6SXNzdWU4MjM4NDk3Mw==,extractfeat: option to add coordinates to defline,CLOSED,2015-05-29T11:11:37Z,2015-06-23T17:48:13Z,2015-06-20T11:45:43Z,"Came up in #592. 
",yeban,https://github.com/genometools/genometools/issues/597,genometools++genometools.csv
MDU6SXNzdWU4MjM4ODA1Mw==,extractfeat: -matchdescstart should probably be set by default,OPEN,2015-05-29T11:23:24Z,2015-08-03T13:05:47Z,,"From #592 

extractfeat tries to pick reference sequences using MD5 tag by default. To look up by id, `-matchdescstart` option must be used.

I am not sure if it's common to refer to ref seqs by their MD5 in GFF files. I think mapping by seqid is more common. And `-matchdescstart` option is not intuitive - even after reading the docs it's not clear that this is the option one is looking for. I resorted to trial and error to pick b/w `-matchdesc`, `-usedesc`, and `-matchdescstart`.

I suggest setting `-matchdescstart` the default, or removing the option altogether if gt can intelligently decide whether to use MD5 or seqid (so as to not break the current behavior).
",yeban,https://github.com/genometools/genometools/issues/598,genometools++genometools.csv
MDU6SXNzdWU4MjQwMDQ2NQ==,gt_xtmpfp_generic_func ignores template,CLOSED,2015-05-29T12:05:08Z,2015-11-15T09:51:26Z,2015-11-14T19:07:37Z,"the problem sits in https://github.com/genometools/genometools/blob/master/src/core/fa.c#L355 where the template is overwritten by the path to the tmp-directory.

I am not sure if this is as intended and the template GtStr is only meant to be used as a way to find the files later, but I expected the template, if a string was given there, to be used.
",Garonenur,https://github.com/genometools/genometools/issues/599,genometools++genometools.csv
MDU6SXNzdWU4MzYzNjk2OQ==,dupfeat: has no effect,CLOSED,2015-06-01T18:37:52Z,2015-06-02T07:04:37Z,2015-06-02T07:04:37Z,"`gt dupfeat` has no effect or I misunderstand its purpose. In the following example I expect the mRNA feature to be duplicated to create a new feature identical to the mRNA feature, but with type exon. The output however is identical to the input.

```
 gt dupfeat -source mRNA -dest exon test.gff >out.gff
 diff -s test.gff out.gff
Files test.gff and out.gff are identical
```
### test.gff

```
##gff-version   3
##sequence-region   6 61475 61912
6   maker   gene    61475   61912   .   +   .   ID=gene1
6   maker   mRNA    61475   61912   18.2    +   .   Parent=gene1
###
```
",sjackman,https://github.com/genometools/genometools/issues/600,genometools++genometools.csv
MDU6SXNzdWU4NDAxNDc3Mg==,"ltrdigest: Assertion failed: (rval == 0), function gt_ltrdigest_pdom_visitor_feature_node",CLOSED,2015-06-02T13:09:32Z,2015-06-21T18:32:11Z,2015-06-21T18:32:11Z,"Full error message:

```
Assertion failed: (rval == 0), function gt_ltrdigest_pdom_visitor_feature_node, file src/ltr/ltrdigest_pdom_visitor.c, line 865.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
trim.sh: line 35: 23274 Aborted                 (core dumped) $gt ltrdigest -trnas $trnas -hmms $hmm -aliout yes -aaout yes -seqfile $db -matchdescstart -seqnamelen 50 -o $gff_h -outfileprefix ltrdigest_trim $gff_sort
```

I am using the latest unstable release (downloaded on June 1st). If I run LTRharvest with the `-similar 99` option I do not see these errors. If I lower the similarity threshold, to the default for example, then I get this error with LTRdigest. I can give more information about the input or try to create a test with a public data set if that would be helpful.
",sestaton,https://github.com/genometools/genometools/issues/604,genometools++genometools.csv
MDU6SXNzdWU4NDgwMjA3NQ==,gt extractfeat -retainids: Optionally use Name rather than ID,OPEN,2015-06-03T22:42:41Z,2015-07-20T20:50:40Z,,"I would like to use the `Name` feature rather than the `ID` feature to name the FASTA record.
",sjackman,https://github.com/genometools/genometools/issues/605,genometools++genometools.csv
MDU6SXNzdWU4NzQxOTY4MQ==,gt seqfilter multiple instanzes with stdin,CLOSED,2015-06-11T17:19:59Z,2015-06-20T12:34:50Z,2015-06-20T12:34:50Z,"I have multiple `GtEncseqs` in one folder and I wanted to use `gt seqorder` to shuffle them, pipe this to `gt seqfilter` to only get the first X entries.
But, as `gt seqfilter` creates a new `GtEncseq` object from `stdin` and names it ""stdin"" this does not work if I want to do this in parallel with multiple inputs.

there should be a way to name implicitly created `GtEncseq` files.
",Garonenur,https://github.com/genometools/genometools/issues/606,genometools++genometools.csv
MDU6SXNzdWU4OTQyMzU5MQ==,gt extractfeat merge multiline CDS features,CLOSED,2015-06-18T23:31:22Z,2015-06-19T19:06:50Z,2015-06-19T17:05:08Z,"CDS features are often multiline. That is, one GFF record is represented with multiple lines, which is shown by the multiple lines having the same ID. It would be very helpful for `gt extractfeat` to output one FASTA record per GFF record, rather than one FASTA record per GFF line. This would be particularly useful with `-translate`.

For example the following four-line GFF record should output a single FASTA record.

```
12  ctg123 . CDS             1201  1500  .  +  0  ID=cds00001;Parent=mRNA00001;Name=edenprotein.1
13  ctg123 . CDS             3000  3902  .  +  0  ID=cds00001;Parent=mRNA00001;Name=edenprotein.1
14  ctg123 . CDS             5000  5500  .  +  0  ID=cds00001;Parent=mRNA00001;Name=edenprotein.1
15  ctg123 . CDS             7000  7600  .  +  0  ID=cds00001;Parent=mRNA00001;Name=edenprotein.1
```

See http://www.sequenceontology.org/gff3.shtml
",sjackman,https://github.com/genometools/genometools/issues/608,genometools++genometools.csv
MDU6SXNzdWU4OTYxOTc5OQ==,1.5.6 release?,CLOSED,2015-06-19T17:37:52Z,2015-06-23T17:42:07Z,2015-06-22T06:22:55Z,"I'd appreciate a stable release that includes the fixes to #581 and #593.
",sjackman,https://github.com/genometools/genometools/issues/609,genometools++genometools.csv
MDU6SXNzdWU4OTYzODA3Ng==,gt seqstat produces no output by default,CLOSED,2015-06-19T19:12:09Z,2015-06-23T17:45:55Z,2015-06-20T12:46:39Z,"Perhaps `-contigs` should be the default behaviour?

```
~/w/pgmtdna git:master  printf "">1\nACGT\n"" >foo.fa
~/w/pgmtdna git:master  gt seqstat foo.fa
~/w/pgmtdna git:master 
```
",sjackman,https://github.com/genometools/genometools/issues/610,genometools++genometools.csv
MDU6SXNzdWU5MDQ2MDc0MQ==,gff3 -addintrons: Inherit Name,CLOSED,2015-06-23T18:40:40Z,2015-06-26T18:43:01Z,2015-06-26T18:43:01Z,"It would be helpful for the newly-created intron features to inherit the `Name` from their parent.
",sjackman,https://github.com/genometools/genometools/issues/616,genometools++genometools.csv
MDU6SXNzdWU5MDc4NjEzMg==,gtdata should be installed in $prefix/share/$package,OPEN,2015-06-24T21:40:21Z,2017-07-10T23:46:17Z,,"The data directory `gtdata` is currently installed in `$bin/gtdata`. Only executables should be installed in `bin`. Data should be installed in `$prefix/share/genometools`. To find the data at run-time, `gt` can look in `$bindir/../share/genometools`. Where `$bindir` is

``` sh
dirname `which $0`
```

and `$0` is the name of the executable, usually `gt`.
",sjackman,https://github.com/genometools/genometools/issues/618,genometools++genometools.csv
MDU6SXNzdWU5NDEzMDUzNg==,gt_str_length assertion failed,CLOSED,2015-07-09T19:18:55Z,2015-07-11T13:34:56Z,2015-07-11T13:34:56Z,"Received this error in 1.5.6:

esrice@edser2 final $ gt
Assertion failed: (gt_str_length(path)), function gt_get_gtdata_path, file src/core/gtdatapath.c, line 48.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Aborted (core dumped)

I compiled with `make 64bit=yes`
",esrice,https://github.com/genometools/genometools/issues/623,genometools++genometools.csv
MDU6SXNzdWU5NDM3MDE0OQ==,"gt stat does not report rRNA, tRNA or intron features",CLOSED,2015-07-10T18:59:08Z,2015-07-15T21:13:00Z,2015-07-15T14:17:22Z,"```
 gt stat -addintrons pg29mt-scaffolds.aragorn.gff
parsed genome node DAGs: 57
sequence regions: 11 (total length: 2521018)
genes: 46
exons: 62
```

```
 grep -v '^#' pg29mt-scaffolds.aragorn.gff |datamash --sort -g 3 count 3
exon    62
gene    46
intron  16
tRNA    46
```

Additionally, `-addintrons` seems to have no effect.

```
 gt stat -addintrons pg29mt-scaffolds.aragorn.gff
parsed genome node DAGs: 57
sequence regions: 11 (total length: 2521018)
genes: 46
exons: 62
```
",sjackman,https://github.com/genometools/genometools/issues/624,genometools++genometools.csv
MDU6SXNzdWU5NDk5NjY0MA==,gt_error_is_set assertion failed,CLOSED,2015-07-14T17:29:27Z,2015-07-16T12:39:28Z,2015-07-16T12:39:28Z,"Received this error:

esrice@edser2 final $ ~/software/genometools-1.5.6/bin/gt merge -retainids yes -tidy yes predictions.sorted.gff3 ../../repeats/repeats.gff3 > predictions.merged.gff3
Assertion failed: (!err || !gt_error_is_set(err)), function gt_node_stream_next, file src/extended/node_stream.c, line 89.
",esrice,https://github.com/genometools/genometools/issues/626,genometools++genometools.csv
MDU6SXNzdWU5NTc0NzIxNQ==,Problem with ReadJoiner outputting incorrect data,CLOSED,2015-07-17T21:16:36Z,2015-09-01T09:30:08Z,2015-09-01T09:30:08Z,"In a previous issue thread sample test data was given, and the output from ReadJoiner was shown.  However the output data was incorrect.  It appears ReadJoiner can/will assign a single read to multiple contigs.  This should not happen. 

The test input file was:

```
>1
acgtacgtacgtagc
>2 test
acgatcgatc
>test2
cgtagcatagcgatatgactta
```

And the output (which is incorrect) from ReadJoiner is:

```
>contig_0 length=31 depth=2 0E-->2E
acgtacgtacgtagcatagcgatatgactta
>contig_1 length=29 depth=2 1B-->2E
gatcgatcgtagcatagcgatatgactta
```

---

What happens is the read ""test2"" is used to build both contigs.  Below is the alignment. 

```
contig_0     acgtacgtacgtagcatagcgatatgactta
1            acgtacgtacgtagc
test2                 cgtagcatagcgatatgactta


contig_1     gatcgatcgtagcatagcgatatgactta
2 (rev)      gatcgatcgt
test2               cgtagcatagcgatatgactta
```

---

The correct output should be ""Contig_0"" and the singlet sequence "">2"".
",deprekate,https://github.com/genometools/genometools/issues/631,genometools++genometools.csv
MDU6SXNzdWU5NjEzMDMxNQ==,seqorder: Sort sequences lexicographically by FASTA ID (feature request),CLOSED,2015-07-20T18:40:45Z,2016-02-15T01:21:26Z,2016-02-13T19:52:48Z,"I'd like to sort the sequences lexicographically be FASTA ID rather than by sequence. I actually found the latter behaviour a bit surprising, although I see that it could be useful. The `-sort` documentation could be improved by changing `sort sequences lexicographically` to `sort sequences lexicographically by sequence`.

http://genometools.org/tools/gt_seqorder.html
",sjackman,https://github.com/genometools/genometools/issues/632,genometools++genometools.csv
MDU6SXNzdWU5NzQxNjMxMg==,Suffixerator says my sequences are empty ?,CLOSED,2015-07-27T08:54:27Z,2015-07-27T11:42:47Z,2015-07-27T11:42:24Z,"Hello,

I am trying to get LTRHarvest and LTRDigest to work on my computer and I figured I'd try an easy small scale test first just to see what the outputs actually look like and if I can manage it since I have pretty much no bio informatics background.

I chose a small file with 3 25kb locuses from the dog genome that I know to contain an almost complete provirus each. However every time I try to start suffixerator as described in the LTRHarvest manual, it tells me my sequence is empty.

My fasta sequences are in a text file ending in .fas as your exemple file does (even though I'm not sure the file extension is important) and follow the format : 

.>sequence_name
_sequence in caps A,T,G,C_
.>sequence2_name
_sequence2 in caps A,T,G,C_
etc...

(Without the . in front of the >, just put it there to avoid GitHub's formatting)

Why does suffixerator think my sequences are empty ?

Thanks in advance.
",FathisMunk,https://github.com/genometools/genometools/issues/634,genometools++genometools.csv
MDU6SXNzdWU5ODQwNzQwMQ==,potential bug -tidy or -fixregionboundaries,CLOSED,2015-07-31T14:52:49Z,2015-07-31T17:48:07Z,2015-07-31T17:48:07Z,"Hi, I am running a command with the option -fixregionboundaries to try to fix wrong phase CDS and I get an error that says ""potential but, please report"".

command:
gt gff3 -sort -fixregionboundaries scaffold399607.gff3 > sorted.gff

error:
Assertion failed: (!err || !gt_error_is_set(err)), function gt_node_stream_next, file src/extended/node_stream.c, line 89.
This is a bug, please report it.

Thank you.
",gonzalezibeas,https://github.com/genometools/genometools/issues/636,genometools++genometools.csv
MDU6SXNzdWU5OTAyMTc1Mg==,gt extractfeat -translate: Support non-standard genetic codes,CLOSED,2015-08-04T17:45:28Z,2015-09-05T13:23:06Z,2015-09-05T13:23:06Z,"See http://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi
",sjackman,https://github.com/genometools/genometools/issues/638,genometools++genometools.csv
MDU6SXNzdWUxMDA3MjU3ODE=,Lua bindings trigger assertion in feature_node:add_child(),CLOSED,2015-08-13T09:45:16Z,2015-08-13T19:23:39Z,2015-08-13T19:23:39Z,"Example:

``` Lua
fn1 = gt.feature_node_new(""foo"", ""gene"", 1, 100, ""+"")
fn1:add_child(gt.feature_node_new(""bar"", ""gene"", 1, 100, ""+""))
```

```
$ gt ~/bug.lua
Assertion failed: (!gt_str_cmp(gt_genome_node_get_seqid((GtGenomeNode*) parent), gt_genome_node_get_seqid((GtGenomeNode*) child))), function gt_feature_node_add_child, file src/extended/feature_node.c, line 1099.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
```

An error should be thrown instead when trying to connect two nodes with different seqids.
",satta,https://github.com/genometools/genometools/issues/640,genometools++genometools.csv
MDU6SXNzdWUxMDI4MDc3MDU=,current master is not scan-build clean,CLOSED,2015-08-24T14:31:18Z,2015-08-24T18:04:31Z,2015-08-24T18:03:49Z,"I dropped splint, because that software got old, but scan-build is pretty current and it finds this error within our master:

```
src/match/seed-extend.c:534:25: warning: Dereference of null pointer (loaded from variable 'perc_mat_history')
      *perc_mat_history = 0; /* case to be implemented */
       ~~~~~~~~~~~~~~~~ ^
```
",Garonenur,https://github.com/genometools/genometools/issues/643,genometools++genometools.csv
MDU6SXNzdWUxMDYxMDcxNjU=,1.5.7 release,CLOSED,2015-09-11T22:38:06Z,2015-09-13T21:53:47Z,2015-09-13T21:53:47Z,"I propose to release 1.5.7 soon to get the bug fixes and improvements out. 
",satta,https://github.com/genometools/genometools/issues/656,genometools++genometools.csv
MDU6SXNzdWUxMDY4MTUyNDY=,Issues with 'ID' description,CLOSED,2015-09-16T16:54:58Z,2015-09-18T12:05:36Z,2015-09-18T12:05:36Z,"Hi,

We have a GFF3 file containing repeats. They do not have 'ID' fields, as we do not have unique ids, but they have 'description' fields.
For some of those, the description is a string 'ID'.
As far as I am aware, none of this is against GFF3 specifications.
When running gt gff3 with the -retainids option however, the 'ID' description is picked up as an 'ID' with no value and added to the start of the attributes fields.
Is this meant to be or could it be updated to only use 'ID' if it is before the '='?

Thanks,
Magali
",magaliruffier,https://github.com/genometools/genometools/issues/659,genometools++genometools.csv
MDU6SXNzdWUxMDcyMjM3OTQ=,issue running 'gt ltrdigest' on compute farm,CLOSED,2015-09-18T15:26:49Z,2016-03-10T11:08:49Z,2016-03-10T11:08:49Z,"Hello,
I've been trying to run 'gt ltrdigest' on a compute farm. I found that if I run one LTRdigest job on the farm, it runs fine, but if I submit lots of LTRdigest jobs at once (all using the same -hmms directory of HMM files), then I get errors and the jobs die, with errors relating to the HMM files. 
I then tried setting the TMPDIR environment variable to be a different local directory for each LTRdigest job, and was able to run lots of jobs at once on our compute farm. All the jobs seemed to finish fine, and at first I thought this had solved the problem.
However, I noticed that the output gff from LTRdigest didn't have any 'protein_match' features when I ran lots of jobs at once on the compute farm (while if I just ran one job on the farm at a time, the output gff did have 'protein_match' features). I'm not sure why this is, because the *fas files for the protein domains are produced fine. However, I think it must be that somehow the hmmer search didn't run ok?
Please let me know if you'd like me to send more info or files.
Kind Regards,
Avril
Avril Coghlan
Sanger Institute
",avrilcoghlan,https://github.com/genometools/genometools/issues/662,genometools++genometools.csv
MDU6SXNzdWUxMDkwOTIzMTc=,Valgrind reports,CLOSED,2015-09-30T13:48:41Z,2015-10-10T16:47:22Z,2015-10-10T16:47:22Z,"It has become increasingly difficult to do memory debugging for my software that links to libgenometools on any system newer than Ubuntu 12.04. On Ubuntu 14.xx, Debian Jessie, and the latest Fedoras, running valgrind will generate a ton of error messages. For the most part these look like they are related to very core system functions like malloc and stuff like that.

Are there really widespread issues with memory management that are pervasive across different Linux distributions? Or are these false positives?

Either way, I've tried creating suppressions files (they're massive and I don't have time to manually inspect them) but it never seems to be a comprehensive solution.

I know GenomeTools has its own init and clean functions, which IIRC do some memory auditing. Is all the GT memory debugging included in the library or do you ever use external tools like Valgrind?
",standage,https://github.com/genometools/genometools/issues/666,genometools++genometools.csv
MDU6SXNzdWUxMTI2MjE4Mzk=,boolean operator precedence issue in compilation,CLOSED,2015-10-21T15:57:47Z,2015-10-22T08:15:05Z,2015-10-22T08:15:05Z,"Here's a compilation issue I found in one of my automated Docker builds (https://hub.docker.com/r/satta/annot-nf/builds/bk7rj366vmtyz7dzxasnwmm/) which compiles GenomeTools as one of its components:

```
src/tools/gt_linspace_align.c: In function 'alignment_with_affine_gap_costs':
src/tools/gt_linspace_align.c:667:61: error: logical not is only applied to the left hand side of comparison [-Werror=logical-not-parentheses] 
  if (!gt_str_array_size(arguments->diagonalbonds) > 0)
```
",satta,https://github.com/genometools/genometools/issues/673,genometools++genometools.csv
MDU6SXNzdWUxMTI2NDM4Mzg=,condenseq_creator.c fails,CLOSED,2015-10-21T17:50:55Z,2015-10-22T09:58:26Z,2015-10-22T09:58:26Z,"when running make test - i get this:

```
[user genometools]$ make test
[compile condenseq_creator.o]
cc1: warnings being treated as errors
src/extended/condenseq_creator.c: In function ces_c_extend_seeds_window:
src/extended/condenseq_creator.c:561: error: match_bounds.start may be used uninitialized in this function
src/extended/condenseq_creator.c: In function ces_c_extend_seeds_brute_force:
src/extended/condenseq_creator.c:701: error: match_bounds.start may be used uninitialized in this function
make: *** [obj/src/extended/condenseq_creator.o] Error 1
```

any ideas? 

I'm running on Centos 6.5
",jonathanjacobs,https://github.com/genometools/genometools/issues/675,genometools++genometools.csv
MDU6SXNzdWUxMTQ2MTQ2Mzk=,LTRGigest Assertion failed,CLOSED,2015-11-02T15:15:14Z,2015-11-28T20:51:14Z,2015-11-28T20:51:14Z,"Hello, 

I am a new user of ltrHarvest and ltrDigest. I used ltrDigest on the chromosome 1 of the Arabidopsis genome as a test, and I got the following error message.

```
Assertion failed: (rval == 0), function gt_ltrdigest_pdom_visitor_feature_node, file src/ltr/ltrdigest_pdom_visitor.c, line 863.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Abort trap: 6
```

The command line I used are the following: 

```
gt suffixerator -db Chr_1.fas -indexname Chr_1.fas.fsa -tis -suf -lcp -des -ssp -sds -dna
gt ltrharvest -index Chr_1.fas.fsa -mintsd 4 -maxtsd 5 -motif TGCA -motifmis 2 -gff3 chr1LtrH
gt -j 2 ltrdigest -pptlen 10 30 -pbsoffset 0 3 -trnas tRNA.fna -hmms Pfam-A.hmm -outfileprefix mygenome-ltrs chr1LtrH.sorted.gff3 Chr_1.fas.fsa > ltrs_after_ltrdigest.gff3
```

The version of gt is: 

```
gt (GenomeTools) 1.5.7
Copyright (c) 2003-2015 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2015 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: Apple LLVM version 7.0.0 (clang-700.1.76)
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -O3 -m64 -Werror
```

Thanks for helping me to solve the problem.
Josquin
",jdaron,https://github.com/genometools/genometools/issues/681,genometools++genometools.csv
MDU6SXNzdWUxMTY3Nzc4MjI=,1.5.7 does not compile on OSX,CLOSED,2015-11-13T14:25:52Z,2015-11-15T13:21:39Z,2015-11-15T13:21:39Z,"Get the error:

```
mac850:genometools-1.5.7 2 John$ make
ls: 2/src/match/*.c: No such file or directory
ls: 2/src/match/*.c: No such file or directory
find: 2: No such file or directory
[compile sqlite3.o]
clang: error: no such file or directory: '2/src'
clang: error: no such file or directory: '2/obj'
clang: error: no such file or directory: '2/src/external/zlib-1.2.8'
clang: error: no such file or directory: '2/src/external/md5-1.1.2/src'
clang: error: no such file or directory: '2/src/external/lua-5.1.5/src'
clang: error: no such file or directory: '2/src/external/luafilesystem-1.5.0/src'
clang: error: no such file or directory: '2/src/external/lpeg-0.10.2'
clang: error: no such file or directory: '2/src/external/expat-2.0.1/lib'
clang: error: no such file or directory: '2/src/external/bzip2-1.0.6'
clang: error: no such file or directory: '2/src/external/samtools-0.1.18'
clang: error: no such file or directory: '2/src/external/sqlite-3.8.7.1'
clang: error: no such file or directory: '2/src/external/tre/include/tre'
clang: error: no such file or directory: '2/src/external/sqlite-3.8.7.1'
make: *** [obj/src/external/sqlite-3.8.7.1/sqlite3.o] Error 1
```

This happens whether i install the extra dependancies via brew or not. 1.5.6 however compiles without issue. I'm running Yosemite 10.10.5. Also, separate point, the INSTALL file for 1.5.7 has a little typo:

```
- 64bit=no         to compile a 32-bit version
- 32bit=yes        to compile a 32-bit version
```
",JohnLonginotto,https://github.com/genometools/genometools/issues/683,genometools++genometools.csv
MDU6SXNzdWUxMTc0MTM2MDE=,spaces in GFF version string,CLOSED,2015-11-17T18:02:15Z,2016-07-05T09:14:10Z,2015-11-19T12:19:06Z,"GenomeTools outputs three spaces between the `##gff-version` directive and the version number, see:
https://github.com/genometools/genometools/blob/master/src/extended/gff3_visitor.c#L76

While the spec does not define the spaces between the directive and the value, some tools are restrictive about this, e.g. Bioconductors makeTxDbFromGFF produces as a warning message:

```
Warning message:
In .local(con, format, text, ...) :
  gff-version directive indicates version is   3, not 3
```

Is there a specific reason why three spaces were chosen?
",satta,https://github.com/genometools/genometools/issues/685,genometools++genometools.csv
MDU6SXNzdWUxMTc5MzM5MDI=,MinGW builds on Travis,CLOSED,2015-11-19T23:38:00Z,2015-11-27T00:19:44Z,2015-11-24T17:29:33Z,"I'm trying to setup automatic MinGW build on Traivs: https://github.com/gordon/genometools/commit/582e363c9e2d67fb981a351341a50e9e1057f47a, but the test fail: https://travis-ci.org/gordon/genometools/builds/92092376

The problem seems to be that the SYSTEM=Windows environment variable is not passed through to   `scripts/travis_test.rb`. I'm wondering if `env = {}` in the scripts resets the complete environment. But if it does, that it is weird that the tests with `cairo=no` build correctly.

@Garonenur: Do you have any idea how to fix this problem? It would be really cool to have the MinGW builds run automatically.
",gordon,https://github.com/genometools/genometools/issues/692,genometools++genometools.csv
MDU6SXNzdWUxMTgwNDc5NDA=,'tidy'ing nodes with invalid parents,OPEN,2015-11-20T14:03:07Z,2015-11-28T21:04:31Z,,"I am thinking about the best way to deal with nodes that have invalid (i.e. dangling) `Parent` IDs. As mentioned earlier, I sometimes encounter these and they usually break any downstream processing by just throwing a parse error. It would be useful to have the stream continue in tidy mode, try to recover a sensible resulting graph and just emit a warning.
My first idea was to just drop these from the stream, e.g. as in https://github.com/satta/genometools/commit/534146c719d2bd71e93b6ae323bf998c529ea839 -- any ideas or other suggestions? One might also just disconnect them from their parents and promote them to top level features... question is which strategy would be less surprising?
",satta,https://github.com/genometools/genometools/issues/693,genometools++genometools.csv
MDU6SXNzdWUxMTg1MzEzMjg=,gt gff3 -checkids,CLOSED,2015-11-24T04:54:37Z,2015-11-29T20:17:55Z,2015-11-29T20:17:55Z,"Hello,

I have a bit of a problem with gt gff3, I wanted to check if I have duplicate gene ids in my file, but the flag seems not to be working.

After gt gff3 -sort yes -retainids yes -checkids yes test.gff3 > gt.out.gff3

[gt.out.gff3.txt](https://github.com/genometools/genometools/files/42371/gt.out.gff3.txt)
[test.gff3.txt](https://github.com/genometools/genometools/files/42372/test.gff3.txt)

There is no warning about duplicate gene ids although they are present. The duplicate gene gets grouped with the first gene.  I tested v1.5.7 and v.1.5.4
Is that expected behavior? It seems counter-intuitive.

I also have a historical question. I was trying to re-run some analysis from 2012. Back then I used v.1.3.5 and I used to get warnings:
warning: feature ID ""BOLE_PAN00005191.1:cds"" not unique: changing to BOLE_PAN00005191.1:cds.1

But what I did not notice is that for some genes the ids got changed and for the others not.

So I ended up with a mosaic file which looked like this: 
[historical.mosaic.gff3.txt](https://github.com/genometools/genometools/files/42373/historical.mosaic.gff3.txt)

Any idea what could have caused that back then? It seems bizarre. It is important 
for my re-analysis as I am trying to understand if it was a strange gff3 file or unexpected 
program behavior. Again no errors.

Best wishes,
Agnieszka
",agolicz,https://github.com/genometools/genometools/issues/696,genometools++genometools.csv
MDU6SXNzdWUxMTkxNzM0MTc=,gff3validator ,CLOSED,2015-11-27T10:37:46Z,2015-11-27T14:48:06Z,2015-11-27T14:48:06Z,"**when I run gt sketch use the following cmd**

```
 gt sketch -addintrons -flattenfiles -width 2000 /GTPlot/png/g005440.2.png   /GTPlot/gtf/g005440.2.gff3 
```

**the folowing error occours:**

```
/genometools/1.5.7/bin/gt sketch: error: CDS feature on line 5 in file ""/GTPlot/gtf/g005440.2.gff3"" has the wrong phase . (should be 0)
```

**Here is the ""/GTPlot/gtf/g005440.2.gff3"" file:**

```
##gff-version 3.2.1
##sequence-region   1  308637  312423
1   Cufflinks   gene    308637  312423  .   +   .   ID=t01g005440.2
1   Cufflinks   mRNA    308637  312423  .   +   .   ID=t01g005440.2.new1;Parent=t01g005440.2
1   Cufflinks   CDS 308637  309207  .   +   .   Parent=t01g005440.2.new1
1   Cufflinks   CDS 310220  310362  .   +   .   Parent=t01g005440.2.new1
1   Cufflinks   CDS 310724  310908  .   +   .   Parent=t01g005440.2.new1
1   Cufflinks   CDS 311118  311208  .   +   .   Parent=t01g005440.2.new1
1   Cufflinks   CDS 311352  311685  .   +   .   Parent=t01g005440.2.new1
1   Cufflinks   CDS 311834  311891  .   +   .   Parent=t01g005440.2.new1
1   Cufflinks   CDS 312006  312423  .   +   .   Parent=t01g005440.2.new1
1   Cufflinks   mRNA    308844  312423  .   +   .   ID=t01g005440.2.new3;Parent=t01g005440.2
1   Cufflinks   CDS 308844  309207  .   +   .   Parent=t01g005440.2.new3
1   Cufflinks   CDS 310220  310362  .   +   .   Parent=t01g005440.2.new3
1   Cufflinks   CDS 310820  310908  .   +   .   Parent=t01g005440.2.new3
1   Cufflinks   CDS 311118  311208  .   +   .   Parent=t01g005440.2.new3
1   Cufflinks   CDS 311352  311685  .   +   .   Parent=t01g005440.2.new3
1   Cufflinks   CDS 311834  311891  .   +   .   Parent=t01g005440.2.new3
1   Cufflinks   CDS 312006  312423  .   +   .   Parent=t01g005440.2.new3
...
```

**What can I do with this problem?**
**Thanks for any adviceO(_)O~**
",52teth,https://github.com/genometools/genometools/issues/700,genometools++genometools.csv
MDU6SXNzdWUxMTkyODE0MDY=,How to set style file for genome mode comparision from two samples?,CLOSED,2015-11-28T09:05:06Z,2015-11-30T03:42:18Z,2015-11-30T03:42:18Z,"I have got two set of genome annotiation stored in two gff3 files. Now I want to see the difference between the gff3 files by gt sketch tool. But the current gt sketch  can only set the same style for each feature. So I wonder if there is a simple way to plot by by changing the  style file (eg. setting different colors for exon from two files)?

Thanks for any replyO(_)O
",52teth,https://github.com/genometools/genometools/issues/701,genometools++genometools.csv
MDU6SXNzdWUxMTk0MTkyNzE=,How to plot a fusion gene located in two chromosome by genometools?,CLOSED,2015-11-30T05:04:52Z,2015-12-03T10:01:45Z,2015-12-03T10:01:45Z,"I have tried to use genometools to plot two genes from a chromosome, I turned out pretty good. Now I wonder if I can use genometools to plot a gene located in two different chromosomes, just like fusion genes?
And how to plot?
Thanks for your time and Look forward to any adviceO(_)O
",52teth,https://github.com/genometools/genometools/issues/705,genometools++genometools.csv
MDU6SXNzdWUxMjAwMjMyNjY=,LTRdigest does not appear to be chaining domain matches,CLOSED,2015-12-02T19:58:27Z,2015-12-04T17:47:17Z,2015-12-04T17:47:17Z,"My understanding is that LTRdigest should be chaining split overlapping domain matches together. From the LTRdigest paper under the section ""Protein domain detection"" it says, ""In the case of
frame shifts, it is possible to obtain multiple partial hits per protein domain occurring in different reading frames. If more than one hit per domain model is found in a candidate, individual hits are combined using a chaining algorithm.."" Though, I am not clear why I am seeing predictions such as the one below: 

```
Contig57_HLAC-254L24    LTRharvest      repeat_region   60096   68658   .       +       .       ID=repeat_region4
Contig57_HLAC-254L24    LTRharvest      target_site_duplication 60096   60100   .       +       .       Parent=repeat_region4
Contig57_HLAC-254L24    LTRharvest      inverted_repeat 60101   60102   .       +       .       Parent=repeat_region4
Contig57_HLAC-254L24    LTRharvest      LTR_retrotransposon     60101   68653   .       +       .       ID=LTR_retrotransposon4;Parent=repeat_region4;ltr_similarity=99.35;seq_number=0
Contig57_HLAC-254L24    LTRharvest      long_terminal_repeat    60101   61950   .       +       .       Parent=LTR_retrotransposon4
Contig57_HLAC-254L24    LTRdigest       protein_match   62716   62977   5.7e-11 +       .       Parent=LTR_retrotransposon4;name=Retrotrans_gag;reading_frame=2
Contig57_HLAC-254L24    LTRdigest       protein_match   64173   64419   3.9e-11 +       .       Parent=LTR_retrotransposon4;name=RVT_1;reading_frame=1
Contig57_HLAC-254L24    LTRdigest       protein_match   64384   64654   2.7e-17 +       .       Parent=LTR_retrotransposon4;name=RVT_1;reading_frame=2
Contig57_HLAC-254L24    LTRdigest       protein_match   65706   66042   2.6e-13 +       .       Parent=LTR_retrotransposon4;name=rve;reading_frame=1
Contig57_HLAC-254L24    LTRdigest       RR_tract        66789   66796   .       +       .       Parent=LTR_retrotransposon4
Contig57_HLAC-254L24    LTRharvest      long_terminal_repeat    66803   68653   .       +       .       Parent=LTR_retrotransposon4
Contig57_HLAC-254L24    LTRharvest      inverted_repeat 61949   61950   .       +       .       Parent=repeat_region4
Contig57_HLAC-254L24    LTRharvest      inverted_repeat 66803   66804   .       +       .       Parent=repeat_region4
Contig57_HLAC-254L24    LTRharvest      inverted_repeat 68652   68653   .       +       .       Parent=repeat_region4
Contig57_HLAC-254L24    LTRharvest      target_site_duplication 68654   68658   .       +       .       Parent=repeat_region4
```

I would expect the two RVT_1 matches in this element to be chained together. Some of these cases can be filtered with the domain match cutoff method and e-value threshold, but in this example, these appear to be very strong matches that would not be filtered by a sensible threshold. Is there a reason why they are split?
",sestaton,https://github.com/genometools/genometools/issues/706,genometools++genometools.csv
MDU6SXNzdWUxMjAxMjE1MDQ=,Error in make ,CLOSED,2015-12-03T08:58:40Z,2016-07-01T11:27:16Z,2015-12-03T10:25:26Z,"HI,

I am getting an error when I am trying to run the ""make""  ( ver 1.5.7) command in linux

[compile extract_feature_stream.o]
src/extended/extract_feature_stream.c:58:2: error: no newline at end of file
make: **\* [obj/src/extended/extract_feature_stream.o] Error 1

How can I solve this? any help would be appreciable.

Thanks
",sajanraju,https://github.com/genometools/genometools/issues/707,genometools++genometools.csv
MDU6SXNzdWUxMjA0NDU5MDE=,Building without Cairo?,CLOSED,2015-12-04T17:15:26Z,2015-12-04T17:32:40Z,2015-12-04T17:28:50Z,"I would like to just use the Python API for https://github.com/sanger-pathogens/gff3toembl but do not need any of the graphical functionality in genometools.

I read the README and skimmed the make file, but it was not obvious is you can build gt without Cairo (which I'm guessing is only used in AnnotationSketch?).
",peterjc,https://github.com/genometools/genometools/issues/708,genometools++genometools.csv
MDU6SXNzdWUxMjEyNzE4Nzg=,Python wrapper does not expose __version__,CLOSED,2015-12-09T15:34:14Z,2015-12-11T10:57:04Z,2015-12-10T23:53:57Z,"Following Python convention, I would expect this to print the genometools Python wrapper version number:

```
$ python2.7 -c ""import gt; print(gt.__version__)""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: 'module' object has no attribute '__version__'
```

Ideally the version string contents should follow PEP693 http://legacy.python.org/dev/peps/pep-0396/ so I would have expected:

```
$ python2.7 -c ""import gt; print(gt.__version__)""
1.5.7
```
",peterjc,https://github.com/genometools/genometools/issues/712,genometools++genometools.csv
MDU6SXNzdWUxMjIyODIwMDQ=,Linesort option fails if second column has a space in it,CLOSED,2015-12-15T14:18:20Z,2015-12-17T08:53:57Z,2015-12-17T08:53:57Z,"I was testing out the ""gt gff3 -linesort"" option and it was failing with this error

```
Assertion failed: (p1s != 0), function gt_linesorted_gff3_cmp, file src/extended/gff3_linesorted_out_stream.c, line 96.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Abort trap: 6
```

When I checked out the GFF3 it looked like it was caused when the second column had a spaces in it(at least, when I replaced instances of ""Curated Genomic"" in second column with ""Curated_Genomic"", the error went away). Maybe either -tidy could fix that up, or the linesort option could handle it?

Tested with 1.5.6 and 1.5.7 and latest unstable.

Thanks for the great tool :)!
",cmdcolin,https://github.com/genometools/genometools/issues/716,genometools++genometools.csv
MDU6SXNzdWUxMjQ4NDIzNzU=,ltrharvest function gt_evalxdroparbitscoresextend bug,CLOSED,2016-01-04T21:23:53Z,2016-01-05T18:36:52Z,2016-01-05T18:36:52Z,"Hello,

I'm doing some testing with ltrharvest from genometools 1.5.7 using the rice chr1 sequence found below.

ftp://ftp.plantbiology.msu.edu/pub/data/Eukaryotic_Projects/o_sativa/annotation_dbs/pseudomolecules/version_7.0/chr01.dir/Chr1.seq

For testing, I'm following example 3.1 from the ltrharvest user manual.

http://www.zbh.uni-hamburg.de/fileadmin/gi/LTRharvest/ltrharvestman.pdf

Here is my suffixerator command, which completed without error.

<pre><code>$ gt suffixerator -db Chr1.seq -indexname Chr1.fsa -tis -suf -lcp -des -ssp -sds -dna</code></pre>


...and my ltrharvest command that is generating an error. The error message indicates that this is a bug, but I'm new to the tool so I may be missing something simple.

<pre><code>$ gt ltrharvest -index Chr1.fsa
# args=-index Chr1.fsa
# predictions are reported in the following way
# s(ret) e(ret) l(ret) s(lLTR) e(lLTR) l(lLTR) s(rLTR) e(rLTR) l(rLTR) sim(LTRs) seq-nr 
# where:
# s = starting position
# e = ending position
# l = length
# ret = LTR-retrotransposon
# lLTR = left LTR
# rLTR = right LTR
# sim = similarity
# seq-nr = sequence number
Assertion failed: (ulen != 0 && vlen != 0), function gt_evalxdroparbitscoresextend, file src/match/xdrop.c, line 250.
This is a bug, please report it at https://github.com/genometools/genometools/issues.</code></pre>
",blauga,https://github.com/genometools/genometools/issues/720,genometools++genometools.csv
MDU6SXNzdWUxMjUwMjQ4NjA=,1.5.8 release?,CLOSED,2016-01-05T18:36:10Z,2016-01-07T21:09:22Z,2016-01-07T21:05:08Z,"Several features have been modified/fixed since 1.5.7. In particular, the spacing of the version number in the `gff-version` pragma is something I'm eager to resolve with a stable release. Some of AEGeAn's functional tests rely on diffs that fail with the new behavior. I don't want to handle this until 1.5.8 is stable.

If the 1.5.8 release isn't already scheduled, consider this a request! :-)
",standage,https://github.com/genometools/genometools/issues/721,genometools++genometools.csv
MDU6SXNzdWUxMjY2OTI0NDk=,ltrdigest assertion failed,CLOSED,2016-01-14T16:35:21Z,2016-01-18T09:37:55Z,2016-01-18T09:37:55Z,"Hello,
I'm trying to run ltrdigest in an effort to create an extensive de novo repeat library for a termite genome. I've encountered following bug:

```
Assertion failed: (esc && filenum < gt_encseq_num_of_files(esc->encseq)), function gt_encseq_col_get_description, file src/core/encseq_col.c, line 410.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
```

I'm running gt 5.8.1 on a cluster with the command:

```
gt suffixerator -db ref.fa -indexname ref.fa -tis -suf -lcp -des -ssp -sds -dna
gt ltrharvest -index ref.fa -seqids yes -tabout no > ltrharvest.out
gt gff3 -sort ltrharvest.out > sorted_input_gff
gt encseq encode -lossless yes ref.fa
gt ltrdigest -hmms /global/scratch/n_arni01/te_analysis/LTR_hmms/*.hmm -outfileprefix csec_ltrdigest -encseq ref.fa -matchdescstart< sorted_input_gff > csec_ltrdigest_output_gff
```

I'm following the instruction on the very helpful blog of Avril Coghlan (http://avrilomics.blogspot.de/2015/09/ltrharvest.html). I'd be thankful for any kind of help
",narni1992,https://github.com/genometools/genometools/issues/729,genometools++genometools.csv
MDU6SXNzdWUxMjcxNjE1MzM=,genometools 1.5.8 make install error,CLOSED,2016-01-18T06:21:47Z,2016-02-01T01:11:33Z,2016-02-01T01:11:33Z,"Hi I am trying to install the tool and get the following error.
I tried no error check option but still get the same error.
Thank you.

```
[r-master-1 genometools-1.5.8]$ make install
[create obj/gt_config.h]
[compile sqlite3.o]
[compile alphabet.o]
[compile array.o]
{standard input}: Assembler messages:
{standard input}:346: Error: expecting string instruction after `rep'
make: *** [obj/src/core/array.o] Error 1
```
",HIM72,https://github.com/genometools/genometools/issues/732,genometools++genometools.csv
MDU6SXNzdWUxMjc1NTM4Mzg=,Issue with sketch tool,OPEN,2016-01-19T22:28:18Z,2016-01-21T12:58:44Z,,"gt version 1.5.8

$ ./gt sketch output.png MR1_a8_5th.all.gff

warnings:
warning: seqid ""scf2"" on line 2 in file ""MR1_a8_5th.all.gff"" has not been previously introduced with a ""##sequence-region"" line, create such a line automatically

Assertion failed: (g->surf && cairo_surface_status(g->surf) == CAIRO_STATUS_SUCCESS), function gt_graphics_cairo_initialize, file /vagrant/src/annotationsketch/graphics_cairo.c, line 136.
This is a bug, please report it at

Just trying to draw the gff file. First attempt at using gt so any help appreciated,.
",Mdha006,https://github.com/genometools/genometools/issues/733,genometools++genometools.csv
MDU6SXNzdWUxMzM1MzE0MTE=,Typo on http://genometools.org/license.html,CLOSED,2016-02-14T11:25:34Z,2016-02-14T16:19:20Z,2016-02-14T16:19:20Z,"The page reads ""We chose one of the most simple and free licenses, the ICS license."", which imho should be ""ISC license""
",teythoon,https://github.com/genometools/genometools/issues/741,genometools++genometools.csv
MDU6SXNzdWUxMzM1MzE3Njk=,Please avoid bundling libraries,OPEN,2016-02-14T11:32:04Z,2018-04-23T21:21:45Z,,"genometools bundles quite a number of libraries:

teythoon@europa /tmp/genometools-1.5.8 % ls -1 src/external
bzip2-1.0.6/
cgilua-5.1.3/
expat-2.0.1/
lpeg-0.10.2/
lua-5.1.5/
luafilesystem-1.5.0/
md5-1.1.2/
samtools-0.1.18/
sqlite-3.8.7.1/
tre/
zlib-1.2.8/

This is generally frowned upon.  See the Debian policy [0] or the Fedora equivalent [1].  The latter gives quite a number of reasons why this is considered bad practice.  In short, it creates more work for both the genometools maintainers and all packagers.

0: https://www.debian.org/doc/debian-policy/ch-source.html#s-embeddedfiles
1: https://fedoraproject.org/wiki/Archive:Bundled_Library_Packaging_Draft#Why_no_Bundled_Libraries
",teythoon,https://github.com/genometools/genometools/issues/742,genometools++genometools.csv
MDU6SXNzdWUxMzQ0MjIyODI=,Add contribution templates,CLOSED,2016-02-17T22:39:30Z,2016-07-01T11:25:18Z,2016-07-01T10:22:16Z,"GitHub have added customizable templates for issues and pull requests (https://github.com/blog/2111-issue-and-pull-request-templates). We should prepare and use these to make it easier for bug reporters and contributors to provide information.
",satta,https://github.com/genometools/genometools/issues/746,genometools++genometools.csv
MDU6SXNzdWUxMzQ5MTkxMDY=,use of ENV['PATH'] in python_tests_runnable?,CLOSED,2016-02-19T17:09:44Z,2016-02-22T11:44:34Z,2016-02-19T20:42:07Z,"I run tests with a minimum environment setting only one env variable (see below). So in particular,
PATH is not defined, but this is now  required to test whether python is available. 
This causes an erro, see belowr. I think we need to check ENV.has_key?(""PATH"") before accessing
ENV[""PATH""]. What's the option?

```
roma [1162] cd testsuite/
roma [1163] env -i GT_MEM_BOOKKEEPING=on ./testsuite.rb -threads 2 -keywords gt_encseq
which: no makeblastdb in ((null))
which: no blastn in ((null))
which: no blastp in ((null))
./testsuite.rb:131:in `python_tests_runnable?': undefined method `split' for nil:NilClass (NoMethodError)
        from ./testsuite.rb:198:in `<main>'
```
",stefan-kurtz,https://github.com/genometools/genometools/issues/750,genometools++genometools.csv
MDU6SXNzdWUxMzUzOTAzMDk=,better build system,OPEN,2016-02-22T11:28:14Z,2016-04-04T09:45:24Z,,"Let's continue the discussion from #748 here.
",gordon,https://github.com/genometools/genometools/issues/752,genometools++genometools.csv
MDU6SXNzdWUxMzU0Nzg4MDc=,broken 32-bit build,CLOSED,2016-02-22T17:08:26Z,2016-02-22T17:43:56Z,2016-02-22T17:43:56Z,"@teythoon: PR #749 breaks building the 32-bit version with `make 32bit=yes`:

```
[link libgenometools.so]
/usr/bin/ld: cannot find -lpango-1.0
/usr/bin/ld: cannot find -lgobject-2.0
/usr/bin/ld: cannot find -lglib-2.0
/usr/bin/ld: cannot find -lcairo
/usr/bin/ld: cannot find -lpangocairo-1.0
/usr/bin/ld: cannot find -lpango-1.0
/usr/bin/ld: cannot find -lcairo
/usr/bin/ld: cannot find -lgobject-2.0
/usr/bin/ld: cannot find -lglib-2.0
collect2: error: ld returned 1 exit status
make: *** [lib/libgenometools.so] Error 1
```
",gordon,https://github.com/genometools/genometools/issues/754,genometools++genometools.csv
MDU6SXNzdWUxMzU5NDk1MDE=,"question about LTRsift, LTRhavest and LTRdigest",CLOSED,2016-02-24T04:15:13Z,2021-10-22T03:36:43Z,2021-10-22T03:36:43Z,"I have a question here  when I use LTRsift, LTRhavest and LTRdigest together, that is:
I analysis the LTR  chromosome by chromosome using LTRharvest and LTRdigest. If there are 5 chromosomes,  I would get 5 gff3 files finally. Then I want use LTRsift to help me filter  candidate sequence. but I also need to analysis chromosome by chromosome because LTRsift only allow select one associated indexname but there are 5 indexnames in fact. If  I do this one chromosome by chromosome, it will influence the classification. For example, A candidate in Chr1 would be the same family with B candidate in Chr2. so, how could I make those 5 index files into 1 index files?

I  combined the 5 chromsomes sequence files to 1 file and tried to only produce one gff3 file and index file through LTRhavest. Howerver, the analysis was out of memory of computer. I cannot image what happen if I merge 20 chromsomes sequence files into 1 file.

I have read the papaer you published about LTRsift, there were two analysis about the fly and mouse and there are also more than one chromosome in every part, how did you solve the problem? Thanks
",Mrwow,https://github.com/genometools/genometools/issues/756,genometools++genometools.csv
MDU6SXNzdWUxMzY5MTg2Mzc=,gt gff3 -sort doesn't work on some gff files in one go,OPEN,2016-02-27T13:26:56Z,2021-07-28T17:32:01Z,,"Sometimes you have to run the GFF3 through `gt gff3 -sort` a few times before it's really sorted and will be accepted by `gt extractfeat`, like with NCBI's fire ant annotations: http://www.ncbi.nlm.nih.gov/genome/annotation_euk/Solenopsis_invicta/100/

The attached scripts download the genome and annotations, and extract exonic, coding and protein sequences corresponding to the annotations, as an example. `process_with_gt` in `extractfeat.rb` captures a workaround for sorting the GFF3 multiple times.

[gt_bug.zip](https://github.com/genometools/genometools/files/149338/gt_bug.zip)
",yeban,https://github.com/genometools/genometools/issues/758,genometools++genometools.csv
MDU6SXNzdWUxMzgwNzk5Nzk=,Behaviour of gt extractfeat -translate if CDS not a multiple of three?,CLOSED,2016-03-03T05:26:15Z,2016-07-05T09:06:54Z,2016-03-03T07:02:40Z,"Just want to be 100% sure: I would imagine it stops at the last codon, ignoring the last 1-2 bp.
",yeban,https://github.com/genometools/genometools/issues/759,genometools++genometools.csv
MDU6SXNzdWUxMzgxOTE4ODk=,gt readjoiner overlap bug,OPEN,2016-03-03T14:25:45Z,2016-04-04T09:44:41Z,,"readjoiner overlap fail and offered to report the bug

version

```
gt-1.5.8-Linux_x86_64-64bit-barebone/bin/gt -version
gt-1.5.8-Linux_x86_64-64bit-barebone/bin/gt (GenomeTools) 1.5.8
Used compiler: cc (Ubuntu 4.9.1-16ubuntu6) 4.9.1
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -O3 -m32 -m64 -Werror
```

Command line

```
gt-1.5.8-Linux_x86_64-64bit-barebone/bin/gt -j 8 readjoiner overlap -readset chr3_reads -l 50 -v
```

Output

```
# gt readjoiner overlap (version 1.2)
# verbose output activated
# readset name = chr3_reads
# number of reads in filtered readset = 53985887
# total length of filtered readset = 4642786282
# read length = 86
# minimal match length = 55
# wset size limit = 32
# eliminate transitive SPM = true
# have stored 107971774 prefix codes
# maximum difference of neighbored codes 45573646849096 (46 bits)
# number of different first codes=88164122 (81.65%) in 107971774 sequences
# maximum space for accumulating counts 2343.16 MB
# codebuffer_total=993095305 (10.572% of all suffixes)
# firstcodehits=520944915 (5.546% of all suffixes), 20 rounds (avg length 49654765)
# maximum space after computing partial sums: 1953.88 MB
# maxbucketsize=68915
# widthofpart[0]=157231178
# widthofpart[1]=157235553
# widthofpart[2]=157226308
# widthofpart[3]=157223650
# use 157235553 bitpackarray-entries for all seqnum/relpos-pairs (32 bits each,628942288 bytes total)
# compute part 0 (25.00% of all candidates)
# maximum space for part 0: 2345.56 MB
# compute part 1 (25.00% of all candidates)
# maximum space for part 1: 2320.01 MB
# compute part 2 (25.00% of all candidates)
# maximum space for part 2: 2302.04 MB
Assertion failed: (fatherdepth != state->read_length), function processleafedge_spmeq, file /vagrant/src/match/rdj-spmfind.c, line 406.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Aborted (core dumped)
```
",timnat,https://github.com/genometools/genometools/issues/760,genometools++genometools.csv
MDU6SXNzdWUxNDAyMzE5NTg=,Superfluous index files in testdata,CLOSED,2016-03-11T16:43:45Z,2016-03-16T13:48:23Z,2016-03-16T13:48:23Z,"I think that the following files do not belong into the testdata directory, as they are platform dependent. I do not see where they are used and It seems that they have accidentially
be added after creating some index files in the testdata dir. Any opions?

foo.32.des
foo.32.esq
foo.32.sds
foo.32.ver0.al1
foo.32.ver0.esq
foo.64.des
foo.64.esq
foo.64.sds
foo.64.ver0.al1
foo.64.ver0.esq
",stefan-kurtz,https://github.com/genometools/genometools/issues/765,genometools++genometools.csv
MDU6SXNzdWUxNDI0ODgzMzY=,Path to Pango and Cairo headers,CLOSED,2016-03-21T22:23:25Z,2020-02-25T15:46:48Z,2016-05-25T09:56:19Z,"I have been trying to link the genometools build to my installs of Pango and Cairo. I have tried using the gcc environment variables, and the -I option on the make command line and none seem to work, I always wind up with the following:

src/annotationsketch/graphics_cairo.c:29:30: error: pango/pangocairo.h: No such file or directory

I have verified that the header exists in the directory I am trying to link. Please, if someone could assist, what is the best method to achieve this?

Thank you!
Aragorn.
",AragornSteiger,https://github.com/genometools/genometools/issues/773,genometools++genometools.csv
MDU6SXNzdWUxNDI3NTUzMTE=,Failed assertion in `gt ltrclustering` tool,OPEN,2016-03-22T19:34:07Z,2016-05-25T09:55:26Z,,"I ran LTRharvest on three files. The resulting LTRs were clustered which worked for two sets and failed for one. Beelow is my command and resulting error

```
gt ltrclustering -psmall 90 -plarge 90 -force -o test.out sunup.asm.fasta pred-sunup.asm.gff3
Assertion failed: ((unsigned int) currentchar < alphabet->mapsize-1), function converttoprettysymbol, file src/core/alphabet.c, line 759.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Aborted (core dumped)
```
",Anupmas,https://github.com/genometools/genometools/issues/775,genometools++genometools.csv
MDU6SXNzdWUxNDU1MTU3OTc=,Current git version fails to build on Mac OS X ,CLOSED,2016-04-03T16:21:10Z,2016-04-10T23:20:43Z,2016-04-10T23:20:43Z,"There's been an addition to the static checks in their clang, resulting in a warning here and in other places. @Garonenur could you check whether the behaviour is correct?

```
src/extended/encdesc.c:1344:13: error: logical not is only applied to the left hand side of this comparison [-Werror,-Wlogical-not-parentheses]
        if (!encdesc->cur_desc == 0 && !sampled) {
            ^                  ~~
src/extended/encdesc.c:1344:13: note: add parentheses after the '!' to evaluate the comparison first
        if (!encdesc->cur_desc == 0 && !sampled) {
            ^
             (                     )
src/extended/encdesc.c:1344:13: note: add parentheses around left hand side expression to silence this warning
        if (!encdesc->cur_desc == 0 && !sampled) {
            ^
            (                 )
1 error generated.
make: *** [obj/src/extended/encdesc.o] Error 1
```
",satta,https://github.com/genometools/genometools/issues/776,genometools++genometools.csv
MDU6SXNzdWUxNDU2MzM1MjA=,Consider supporting newer Lua versions,CLOSED,2016-04-04T09:43:39Z,2016-07-05T09:06:15Z,2016-04-06T16:05:07Z,"Lua 5.1 is not really supported by upstream with 5.1.5 being the latest version (from 2012). We should find out what still keeps us from supporting a newer version, and make the necessary adjustments.
IIRC there were some incompatible API changes?
",satta,https://github.com/genometools/genometools/issues/778,genometools++genometools.csv
MDU6SXNzdWUxNDc3NTMxODE=,gtdoc.lua question,CLOSED,2016-04-12T13:35:44Z,2016-04-13T08:29:55Z,2016-04-13T08:29:55Z,"while working on the gtdoc-code to use it to get the api of some of my code into my thesis I encountered this:
[gtdata/modules/docvisitorlatex.lua#125](https://github.com/genometools/genometools/blob/ac478f2af062c65a1e04d31b8be70871375cdf9f/gtdata/modules/gtdoclib/docvisitorlatex.lua#L125)
and I am wondering if this line is correct? because it sets name to `nil` or `false` which would not work well if given to the markdown latex template. Shouldn't it say: `name = desc.name`? If I am wrong, maybe someone tell me what this is about.
",Garonenur,https://github.com/genometools/genometools/issues/784,genometools++genometools.csv
MDU6SXNzdWUxNDgwMjY0ODc=,gff3_to_gtf doesn't work,CLOSED,2016-04-13T11:15:41Z,2016-07-01T11:24:22Z,2016-04-13T12:04:22Z," I want to transfer parse GFF3 file and show them as GTF file, but it doesn't work. The GFF3 file comes from LTRharvest and LTRdigest.

`gt gff3_to_gtf harvest_pig_sorted.gff3 -o test`
",Mrwow,https://github.com/genometools/genometools/issues/786,genometools++genometools.csv
MDU6SXNzdWUxNDk5MDk3MDQ=,The GFF3 Validator fails phase determination for the CDS for a trans-spliced gene ,OPEN,2016-04-20T23:01:00Z,2016-08-18T23:09:25Z,,"If you take Arabidopsis thaliana GFF from RefSeq.

```
ftp://ftp.ncbi.nlm.nih.gov/genomes/refseq/plant/Arabidopsis_thaliana/reference/GCF_000001735.3_TAIR10/GCF_000001735.3_TAIR10_genomic.gff.gz
```

When you run the tool you get the following error:

```
GenomeTools error: CDS feature on line 483064 in file ""/var/www/servers/genometools.org/htdocs/cgi-bin/gff3/GCF_000001735.3_TAIR10_genomic.gff.gz"" has the wrong phase 0 (should be 2)
```

So here are the offending lines (first line being the line reported):

```
NC_001284.2 RefSeq  CDS 142769  142998  .   -   0   ID=cds35181;Parent=gene33329;Dbxref=GOA:P29388,UniProtKB/Swiss-Prot:P29388,Genbank:NP_085478.1,GeneID:3371313;Name=NP_085478.1;exception=trans-splicing;gbkey=CDS;gene=nad5;product=NADH dehydrogenase subunit 5;protein_id=NP_085478.1
NC_001284.2 RefSeq  CDS 140724  141939  .   -   1   ID=cds35181;Parent=gene33329;Dbxref=GOA:P29388,UniProtKB/Swiss-Prot:P29388,Genbank:NP_085478.1,GeneID:3371313;Name=NP_085478.1;exception=trans-splicing;gbkey=CDS;gene=nad5;product=NADH dehydrogenase subunit 5;protein_id=NP_085478.1
NC_001284.2 RefSeq  CDS 190740  190761  .   -   0   ID=cds35181;Parent=gene33329;Dbxref=GOA:P29388,UniProtKB/Swiss-Prot:P29388,Genbank:NP_085478.1,GeneID:3371313;Name=NP_085478.1;exception=trans-splicing;gbkey=CDS;gene=nad5;product=NADH dehydrogenase subunit 5;protein_id=NP_085478.1
NC_001284.2 RefSeq  CDS 21692   22086   .   -   2   ID=cds35181;Parent=gene33329;Dbxref=GOA:P29388,UniProtKB/Swiss-Prot:P29388,Genbank:NP_085478.1,GeneID:3371313;Name=NP_085478.1;exception=trans-splicing;gbkey=CDS;gene=nad5;product=NADH dehydrogenase subunit 5;protein_id=NP_085478.1
NC_001284.2 RefSeq  CDS 20571   20717   .   -   0   ID=cds35181;Parent=gene33329;Dbxref=GOA:P29388,UniProtKB/Swiss-Prot:P29388,Genbank:NP_085478.1,GeneID:3371313;Name=NP_085478.1;exception=trans-splicing;gbkey=CDS;gene=nad5;product=NADH dehydrogenase subunit 5;protein_id=NP_085478.1
```

So what I am pretty sure is going on here is that since the CDS pieces are not in linear order along the Mitochondria plasmid, your tool is reordering them to be that way.
Here is that order:

```
NC_001284.2 RefSeq  CDS 190740  190761  .   -   0   ID=cds35181;Parent=gene33329;Dbxref=GOA:P29388,UniProtKB/Swiss-Prot:P29388,Genbank:NP_085478.1,GeneID:3371313;Name=NP_085478.1;exception=trans-splicing;gbkey=CDS;gene=nad5;product=NADH dehydrogenase subunit 5;protein_id=NP_085478.1
NC_001284.2 RefSeq  CDS 142769  142998  .   -   0   ID=cds35181;Parent=gene33329;Dbxref=GOA:P29388,UniProtKB/Swiss-Prot:P29388,Genbank:NP_085478.1,GeneID:3371313;Name=NP_085478.1;exception=trans-splicing;gbkey=CDS;gene=nad5;product=NADH dehydrogenase subunit 5;protein_id=NP_085478.1
NC_001284.2 RefSeq  CDS 140724  141939  .   -   1   ID=cds35181;Parent=gene33329;Dbxref=GOA:P29388,UniProtKB/Swiss-Prot:P29388,Genbank:NP_085478.1,GeneID:3371313;Name=NP_085478.1;exception=trans-splicing;gbkey=CDS;gene=nad5;product=NADH dehydrogenase subunit 5;protein_id=NP_085478.1
NC_001284.2 RefSeq  CDS 21692   22086   .   -   2   ID=cds35181;Parent=gene33329;Dbxref=GOA:P29388,UniProtKB/Swiss-Prot:P29388,Genbank:NP_085478.1,GeneID:3371313;Name=NP_085478.1;exception=trans-splicing;gbkey=CDS;gene=nad5;product=NADH dehydrogenase subunit 5;protein_id=NP_085478.1
NC_001284.2 RefSeq  CDS 20571   20717   .   -   0   ID=cds35181;Parent=gene33329;Dbxref=GOA:P29388,UniProtKB/Swiss-Prot:P29388,Genbank:NP_085478.1,GeneID:3371313;Name=NP_085478.1;exception=trans-splicing;gbkey=CDS;gene=nad5;product=NADH dehydrogenase subunit 5;protein_id=NP_085478.1
```

However, for transplicing this is the wrong behavior.
If the rows are taken as seen in the file, the phase is correct.
If the rows are reordered then it would expect the segment from 190740 to 190761 to have a phase of 2.

See attached excel sheet.

Here is the Genbank version of the CDS.  The order in the GFF matches the GenBank coordinates given.

```
     CDS             complement(join(20571..20717,21692..22086,190740..190761,
                     140724..141939,142769..142998))
                     /gene=""nad5"" 
                     /locus_tag=""ArthMp006"" 
                     /EC_number=""1.6.99.3""
                     /trans_splicing
                     /codon_start=1 
                     /product=""NADH dehydrogenase subunit 5""
                     /protein_id=""NP_085478.1""
                     /db_xref=""GI:13449295""
                     /db_xref=""GOA:P29388""
                     /db_xref=""UniProtKB/Swiss-Prot:P29388""
                     /db_xref=""GeneID:3371313""
                     /translation=""MYLLIVFLPLLGSSVAGFFGRFLGSEGSAIMTTTCVSFSSILSL
                     IAFYEVAPGASACYLRIAPWISSEMFDASWGFLFDSPTVVMLIVVTSISSLVHLYSIS
                     YMSEDPHSPRFMCYLSILTFFMPMLVTGDNSLQLFLGWEGVGLASYLLIHFWFTRLQA
                     DKAATKAMLVNRVGDFGLALGISGRFTLFQTVDFSTIFARASAPRNSWISCNMRLNAI
                     SLICILLLIGAVGKSAQIGSHTWSPDAMEGPTPVSASIHAATMVTAGVFMIARCSPLF
                     EYPPTALIVITSAGATTSFLAATTGILQNDLKRVIAYSTCSQLGYMIFACGISNYSVS
                     VFHLMNHAFFKALLFLSAGSVIHAMSDEQDMRKMGGLASSFPLTYAMMLIGSLSLIGF
                     PFLTGFYSKDVILELAYTKYTISGNFAFWLGSVSVLFTSYYSFRLLFLTFLVPTNSFG
                     RDISRCHDAPIPMAIPLILLALGSLFVGYLAKDMMIGLGTNFWANSPLVLPKNEILAE
                     SEFAAPTITKLIPILFSTSGAFVAYNVNPVADQFQRAFQTSTFCNRLYSFFNKRWFFD
                     QVLNDFLVRSFLRFGYEVSFEALDKGAIEILGPYGISYTFRRLAERISQLQSGFVYHY
                     AFAMLLGSTLFVTFSRMWDSLSSWVDNRSSFILIVSSFYTKSSQE""
```

Couple of potential suggestions on how to handle.
1) If ""trans-splicing"" or ""trans-spliced"" and do not reorder
2) Check the phase, but allow it to be warning or a stricter checking option.
[GFF3_Validator_bug.xlsx](https://github.com/genometools/genometools/files/228999/GFF3_Validator_bug.xlsx)
",jkbaumohl,https://github.com/genometools/genometools/issues/787,genometools++genometools.csv
MDU6SXNzdWUxNTA0NTg5NTE=,Duplicate mRNA line is accepted (should be an error),OPEN,2016-04-22T20:02:05Z,2016-04-26T23:07:14Z,,"This seems very problematic that an exact duplicate mRNA line is not seen as a en error.

See attached.

[Duplicate_mRNA.txt](https://github.com/genometools/genometools/files/232485/Duplicate_mRNA.txt)
",jkbaumohl,https://github.com/genometools/genometools/issues/788,genometools++genometools.csv
MDU6SXNzdWUxNTEyNDQ1NTM=,bioseq regression,OPEN,2016-04-26T21:34:20Z,2016-04-28T21:17:14Z,,"Commit c4b5870965270ac3ffb12379c19c2b8bdce54935 breaks `gthbssmtrain` (in the GenomeThreader test suite) and changes the behaviour of a few tools (for example, `gt fingerprint`).

@stefan-kurtz Can I revert the commit? The `GtBioseq` was always about automatically creating the corresponding indices and I think in that case it make more sense to have them in the same directory as the original sequence files (and it's the behaviour we had so far). Or did I miss anything? I see the reason for consistency with the other tools, but it breaks some tools and would require some work in them and might cause problems for existing users.
",gordon,https://github.com/genometools/genometools/issues/791,genometools++genometools.csv
MDU6SXNzdWUxNTMwOTU4Mjc=,Possible error in phase calculation when a CDS segment is 1bp long,CLOSED,2016-05-04T19:32:08Z,2016-07-02T13:02:16Z,2016-07-02T13:02:16Z,"# It seems that GenomeTools is treating 1bp CDS exons in the wrong way when calculating the phase, by considering them as length 2 instead of 1.

Prologue: to calculate phases in a tool I am working on, I am using the following function:

```
def __calculate_phases(coding, previous):

    # Previous indicates whether the record began with a phase different from 0
    # for incomplete gene models
    total_cds_length = -previous

    __calculated_phases = []
    for cds_segment in coding:
        length = cds_segment[1][1] - cds_segment[1][0] + 1
        phase = (3 - (total_cds_length % 3)) % 3
        total_cds_length += length
        __calculated_phases.append(phase)

    return total_cds_length, __calculated_phases
```

I am not sure it is correct as I have not been able to find the relevant corresponding section in the GenomeTools codebase. 

In my case, I have the following GFF entry:

```
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  gene    40282   46004   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960;Name=TRIAE_CS42_5DL_TGACv1_434051_AA1427960;biotype=protein_coding;confidence=High
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  mRNA    40282   46004   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960;Name=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2;aed=0.0;note=TRIAE_CS42_5DL_TGACv1_434051_AA1427960;confidence=High;has_start=True;has_stop=True;original_stop=True;protein_rank=P1;transcript_rank=T2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  exon    40282   40933   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.exon1;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  three_prime_UTR 40282   40720   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.three_prime_UTR1;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  CDS 40721   40933   .   -   0   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.CDS1;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  CDS 41018   41111   .   -   1   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.CDS2;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  exon    41018   41111   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.exon2;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  CDS 41227   41468   .   -   0   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.CDS3;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  exon    41227   41468   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.exon3;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  CDS 41673   41831   .   -   0   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.CDS4;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  exon    41673   41831   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.exon4;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  CDS 41946   42820   .   -   2   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.CDS5;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  exon    41946   42820   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.exon5;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  CDS 42905   42913   .   -   2   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.CDS6;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  exon    42905   42913   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.exon6;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  CDS 45373   45496   .   -   0   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.CDS7;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  exon    45373   45496   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.exon7;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  CDS 45600   45651   .   -   1   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.CDS8;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  exon    45600   45651   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.exon8;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  CDS 45726   45726   .   -   2   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.CDS9;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  exon    45726   45726   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.exon9;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  CDS 45875   45893   .   -   0   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.CDS10;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  exon    45875   46004   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.exon10;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
Triticum_aestivum_CS42_TGACv1_scaffold_434051_5DL   TGACv1  five_prime_UTR  45894   46004   .   -   .   ID=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2.five_prime_UTR1;Parent=TRIAE_CS42_5DL_TGACv1_434051_AA1427960.2
```

The gt gff3 tool (latest release, version 1.5.8, linux x86_64 binaries) complains that the phase is incorrect for this entry, with the following error:

```
warning: CDS feature on line 19 in file ""stdin"" has the wrong phase 1 -> correcting it to 0
warning: CDS feature on line 17 in file ""stdin"" has the wrong phase 0 -> correcting it to 2
warning: CDS feature on line 15 in file ""stdin"" has the wrong phase 2 -> correcting it to 1
warning: CDS feature on line 13 in file ""stdin"" has the wrong phase 2 -> correcting it to 1
warning: CDS feature on line 11 in file ""stdin"" has the wrong phase 0 -> correcting it to 2
warning: CDS feature on line 9 in file ""stdin"" has the wrong phase 0 -> correcting it to 2
warning: CDS feature on line 7 in file ""stdin"" has the wrong phase 1 -> correcting it to 0
warning: CDS feature on line 6 in file ""stdin"" has the wrong phase 0 -> correcting it to 2
```

The complaints begin after line 21, ie an exon/CDS line with length 1 (45276 .. 45276). 
This seems wrong to me, for the following reasons:

1- If I have understood the method of calculation right, the phase should be calculated by taking the modulo 3 of the amount of sequence already met before encountering the current CDS segment; see the code at the beginning of the issue report.

   My function agrees with the phases present in the input GFF record I pasted in the comment, but not with GenomeTools; it reports the total CDS length as being 1788 ie a number divisible by 3.

2 - I can obtain the same results as GenomeTools in terms of phases by adding 2 instead of 1 to the total_cds_length variable when encountering the 1-bp exon:

```
def __calculate_phases(coding, previous):
    # Previous indicates whether the record began with a phase different from 0
    # for incomplete gene models

    total_cds_length = -previous

    __calculated_phases = []
    for cds_segment in coding:
        length = cds_segment[1][1] - cds_segment[1][0] + 1
        # This agrees with GenomeTools
        if length == 1:
             length += 1
        phase = (3 - (total_cds_length % 3)) % 3
        total_cds_length += length
        __calculated_phases.append(phase)

    return total_cds_length, __calculated_phases
```

The result in this case will agree with GenomeTools regarding the phases, _but the total CDS length will be incorrect (1789, and 1789 % 3 == 1)_. This seems quite wrong.
",lucventurini,https://github.com/genometools/genometools/issues/793,genometools++genometools.csv
MDU6SXNzdWUxNTUxNzI3MTc=,gtpython test failed,CLOSED,2016-05-17T04:04:21Z,2016-05-18T02:54:04Z,2016-05-17T14:52:53Z,"Hi there, 

I was installing genometools and got a single test fail:

```
740: gtpython: unittests                                         : failed
     [ problem: unexpected return code: 1 != 0
       in: /home/champi/Software/genometools/testsuite/stest_testsuite/test740 ]
```

I'm using python 2.6.6 and have added the PYTHONPATH and LD_LIBRARY_PATH variables as indicated in the README file within the gtpython folder to my environment.

Any help would be really appreciated.

Thank you,
Juan
",JPascualAnaya,https://github.com/genometools/genometools/issues/795,genometools++genometools.csv
MDU6SXNzdWUxNTUzMDg4MDg=,failing test (occasionally) ,CLOSED,2016-05-17T16:51:43Z,2016-06-17T19:14:12Z,2016-06-17T19:13:53Z,"I am not sure if it is always in gt repfind, but this test just failed on travis for me with the following (not helpful) error:

```
1620: gt repfind extend self vs query                             : failed

FAILING test, output of testsuite/stest_testsuite/test1620/stderr_7

FAILING test, output of stest_error

Test 1620 'gt repfind extend self vs query': failed:

unexpected return code: 1 != 0:

/home/travis/build/genometools/genometools/testsuite/stest.rb:286:in `run'

/home/travis/build/genometools/genometools/testsuite/stest.rb:449:in `run'

/home/travis/build/genometools/genometools/testsuite/gt_repfind_include.rb:79:in `crosstest'

/home/travis/build/genometools/genometools/testsuite/gt_repfind_include.rb:200:in `block (3 levels) in <top (required)>'

/home/travis/build/genometools/genometools/testsuite/gt_repfind_include.rb:197:in `each'

/home/travis/build/genometools/genometools/testsuite/gt_repfind_include.rb:197:in `block (2 levels) in <top (required)>'

/home/travis/build/genometools/genometools/testsuite/gt_repfind_include.rb:192:in `times'

/home/travis/build/genometools/genometools/testsuite/gt_repfind_include.rb:192:in `block in <top (required)>'

/home/travis/build/genometools/genometools/testsuite/stest.rb:176:in `block in test'

/home/travis/build/genometools/genometools/testsuite/stest.rb:165:in `fork'

/home/travis/build/genometools/genometools/testsuite/stest.rb:165:in `test'

/home/travis/build/genometools/genometools/testsuite/stest.rb:120:in `process'

/home/travis/build/genometools/genometools/testsuite/stest.rb:34:in `block (2 levels) in run'

     [ problem: unexpected return code: 1 != 0

       in: /home/travis/build/genometools/genometools/testsuite/stest_testsuite/test1620 ]
```

I think I saw repfind errors fail a few times and looking at the code of the test I am not sure why they would fail only sometimes. Probably race conditions, but it was the grep that failed and the file it was supposed to process was touched before, so it existed.
Also, the tests in gt_repfind_include around lines 200ff are repeated 3 times without a visible reason?
Could someone who has worked on that code have a look? Maybe they understand where there could be a problem with parallel test execution.
",Garonenur,https://github.com/genometools/genometools/issues/797,genometools++genometools.csv
MDU6SXNzdWUxNTYyNDAxOTk=,error during compilation,CLOSED,2016-05-23T09:44:36Z,2016-05-23T10:20:45Z,2016-05-23T10:20:45Z,"Hello,
I am trying to install genometools v.1.5.8 on a server running ""Red Hat Enterprise Linux Server release 7.2 (Maipo)"" with gcc version 4.8.5.
I've tried compiling from source using the following command:
`make -j4  cairo=no`
but get the following error message:

>  lib/libgenometools.a(gt_lua.o): In function `gt_lua_open_lib':
>  /home/jov14/src/genometools-1.5.8/src/gtlua/gt_lua.c:39: undefined reference to 
>  gt_lua_open_annotationsketch'
>  collect2: error: ld returned 1 exit status
> make: **\* [bin/gt] Error 1
> make: **\* Waiting for unfinished jobs....

I've seen that for other compilation issues on this site, it was possible to just ignore error messages using the `error=no` flag, but I am not sure if this is advisable for every case.
What can I do to fix this, or is it safe to just ignore this error message?
",jvollme,https://github.com/genometools/genometools/issues/799,genometools++genometools.csv
MDU6SXNzdWUxNjI3NzkzMTU=,Extend lua API: count children of the specified type,CLOSED,2016-06-28T20:27:49Z,2016-06-28T21:12:06Z,2016-06-28T21:12:06Z,"I'm writing some spec files for gt speck, and a common task I encounter is counting a node's children of a given type. There already exist functions to count all children, and to test whether a child of a certain type exists. But if I simply need the count (for example, to compare the number of exons the the number of introns) I find myself using iterators and counters, and/or building lists. The spec files would be much clearer and more concise if there were a simple function to compute and report the counts directly.
",standage,https://github.com/genometools/genometools/issues/802,genometools++genometools.csv
MDU6SXNzdWUxNjI5Nzk3MzI=,speck: Access sequence from region nodes,CLOSED,2016-06-29T17:15:44Z,2016-07-01T11:24:15Z,2016-07-01T01:45:24Z,"The gt speck docs describe how to process sequence nodes, as well as how to extract sequence data from an external file using the global `region_mapping` variable. I'm struggling to figure out how to access sequence data while processing region nodes. Is this possible?
",standage,https://github.com/genometools/genometools/issues/804,genometools++genometools.csv
MDU6SXNzdWUxNjMzMDEwNjE=,Assertion failed in readjoiner assembly step,OPEN,2016-07-01T01:25:12Z,2016-07-14T09:13:57Z,,"Hi, While running the gt readjoiner assembly, I received the following error.

```
Assertion failed: (nofreads == nofreads_i), function gt_readjoiner_assembly_build_contained_reads_list, file src/tools/gt_readjoiner_assembly.c, line 472.`
```

gt version info:

```
gt (GenomeTools) 1.5.8
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.
Used compiler: cc (Ubuntu 4.9.1-16ubuntu6) 4.9.1
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -O3 -m32 -m64 -Werror
```

I am running the command on CentOS release 6.6
Pre filter, overlap and assembly commands were as follows:

```
gt readjoiner prefilter -v -readset readset1 -memdes -maxlow 10 -lowqual 10 -db Readset1.fastq Readset2.fastq Readset3_1.fastq:Readset3_2.fastq:200
gt -j 12 readjoiner overlap -readset readset -l 35
gt readjoiner assembly -readset algae4639 -l 35 -errors -spmfiles 12 -v
```

Could you please help me solve this problem?
Looking forward to hearing from you.
Kind regards
hardip
",hp2048,https://github.com/genometools/genometools/issues/806,genometools++genometools.csv
MDU6SXNzdWUxNjM0MjExODE=,1.5.9 release?,CLOSED,2016-07-01T15:36:48Z,2016-07-21T17:27:19Z,2016-07-21T17:27:07Z,"We should plan for a new release, there's been a bunch of bugfixes and feature additions. Certainly we want #793 in, do we also want to wait for #806 to be looked at?
",satta,https://github.com/genometools/genometools/issues/810,genometools++genometools.csv
MDU6SXNzdWUxNjM0MjQ3MzQ=,Have 'gt speck' return non-zero status in case of failures or runtime errors,CLOSED,2016-07-01T15:55:09Z,2016-07-02T05:55:24Z,2016-07-02T05:55:24Z,"I don't know whether this would be better as default behavior or as an option, but having `gt speck` return a non-zero status on failure/error would be helpful for integrating into shell-based and Makefile-based workflows.
",standage,https://github.com/genometools/genometools/issues/811,genometools++genometools.csv
MDU6SXNzdWUxNjM4MTQyMjY=,Failing MD5 test,CLOSED,2016-07-05T10:01:45Z,2016-07-14T12:06:57Z,2016-07-14T12:06:57Z,"## Problem description

Travis fails test 1068 with seed 1209700457

```
FAILING test, output of testsuite/stest_testsuite/test1068/stderr_1
/home/travis/build/genometools/genometools/bin/gt: error: could not execute script ...ls/genometools/src/external/md5-1.1.2/tests/test.lua:78: assertion failed!
FAILING test, output of stest_error
Test 1068 'MD5 library': failed:
unexpected return code: 1 != 0:
/home/travis/build/genometools/genometools/testsuite/stest.rb:286:in `run'
/home/travis/build/genometools/genometools/testsuite/stest.rb:449:in `run'
testsuite.rb:98:in `run_test'
/home/travis/build/genometools/genometools/testsuite/gt_scripts_include.rb:137:in `block in <top (required)>'
/home/travis/build/genometools/genometools/testsuite/stest.rb:176:in `block in test'
/home/travis/build/genometools/genometools/testsuite/stest.rb:165:in `fork'
/home/travis/build/genometools/genometools/testsuite/stest.rb:165:in `test'
/home/travis/build/genometools/genometools/testsuite/stest.rb:120:in `process'
/home/travis/build/genometools/genometools/testsuite/stest.rb:34:in `block (2 levels) in run'
     [ problem: unexpected return code: 1 != 0
       in: /home/travis/build/genometools/genometools/testsuite/stest_testsuite/test1068 ]
```
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

1.5.9, latest git (bbd497d)
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

`amalgamation=yes`
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Travis Linux test VM
",satta,https://github.com/genometools/genometools/issues/815,genometools++genometools.csv
MDU6SXNzdWUxNjQzMTU0MTA=,mkindex on both strands?,CLOSED,2016-07-07T13:58:31Z,2016-07-08T09:54:37Z,2016-07-08T09:54:37Z,"Hi,

I am trying to use the mkindex program to find all 20-mers with a minimal occurrence (10 in my example) but I need the program to check both strands of my sequences. I don't know if this is possible but I found the -mirrored option in the suffixerator program. When I use this option to construct the esa, I get an error message when I run mkindex. Is this a bug or is it simply not possible to search on both strands?

These commands work:

```
gt suffixerator -dna -pl -tis -suf -lcp -v -db seqs.fas -indexname seqs
gt tallymer mkindex -minocc 10 -mersize 20 -esa seqs
```

These commands give me an error:

```
gt suffixerator -dna -pl -tis -suf -lcp -mirrored -v -db seqs.fas -indexname mirrored
gt tallymer mkindex -minocc 10 -mersize 20 -esa mirrored
```

error message:

```
gt tallymer mkindex -minocc 10 -mersize 20 -esa mirrored
Assertion failed: (len >= 1UL && encseq != NULL && startpos + len <= encseq->totallength), function gt_encseq_contains_special, file src/core/encseq.c, line 696.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Aborted (core dumped)
```

I am using GenomeTools version: 1.5.8 in Windows (gt-1.5.8-CYGWIN_NT-10.0_i686-32bit). 

Thanks
",FrVan,https://github.com/genometools/genometools/issues/816,genometools++genometools.csv
MDU6SXNzdWUxNjYxNTIxNDM=,'make docs' fails with Lua error,CLOSED,2016-07-18T17:50:57Z,2016-07-21T12:32:48Z,2016-07-21T12:32:48Z,"## Problem description

`make docs` fails when generating the API documentation, terminating with an error. Probably introduced in https://github.com/genometools/genometools/commit/770c4e082a83398d256cfe622d5a8e6896ed7fc3 which touches the problematic line.

This currently blocks #810.
## Exact command line call triggering the problem

```
$ make -j6 threads=yes docs
bin/gt gtscripts/gtdoc.lua -html /Users/satta/uni/gt \
        > www/genometools.org/htdocs/libgenometools.html
bin/gt gtscripts/gtdoc.lua -lua -html /Users/satta/uni/gt \
        > www/genometools.org/htdocs/docs.html
bin/examples/sketch_parsed gtdata/sketch/default.style \
          www/genometools.org/htdocs/images/parsed.png \
          testdata/eden.gff3
bin/examples/sketch_parsed \
          www/genometools.org/htdocs/annotationsketch/callbacks.style \
          www/genometools.org/htdocs/images/callbacks.png \
          www/genometools.org/htdocs/annotationsketch/callback_examples_with_score.gff3
bin/examples/sketch_constructed gtdata/sketch/default.style \
          www/genometools.org/htdocs/images/constructed.png
sed -nf scripts/incl.sed \
          www/genometools.org/htdocs/examples_tmpl.html | \
          sed 'N;N;s/\n//' > /tmp/tmp.sed.$$ && \
        sed -f /tmp/tmp.sed.$$ \
          www/genometools.org/htdocs/examples_tmpl.html > \
          www/genometools.org/htdocs/examples.html; rm -f /tmp/tmp.sed.$$
bin/gt gtscripts/gtdoc.lua -tex /Users/satta/uni/gt \
        > doc/manuals/api_reference.tex
bin/gt: error: could not execute script bin/../gtdata/modules/gtdoclib/docvisitorlatex.lua:134: attempt to perform arithmetic on a nil value
make: *** [docs] Error 1
```
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

1.5.9 (current git master)
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

`make -j6 threads=yes`
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

OS X 10.11.5
",satta,https://github.com/genometools/genometools/issues/821,genometools++genometools.csv
MDU6SXNzdWUxNzAxNzYwMDc=,gff3validator segmentation fault,CLOSED,2016-08-09T14:09:37Z,2016-08-15T09:16:08Z,2016-08-14T12:51:47Z,"## Problem description

I am trying to validate a GFF fiormatted file but I get a segmentation fault error. First I thought it was a memory issue but after trimming down the file the error remains... 
## Exact command line call triggering the problem

```
$ gt gff3validator scf00001.txt 
Segmentation fault (core dumped)
```

See attached file for a minimal input triggering the problem
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

```
$ gt -version
gt (GenomeTools) 1.5.6
```
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

compiled from source without additional parameters
[scf00001.txt](https://github.com/genometools/genometools/files/409124/scf00001.txt)
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

This happens on Ubuntu as well as on OSX 10.11.6.
",RvV1979,https://github.com/genometools/genometools/issues/825,genometools++genometools.csv
MDU6SXNzdWUxNzA0NDIyNzA=,latex documentation math recognition,CLOSED,2016-08-10T15:12:19Z,2016-08-11T12:58:20Z,2016-08-11T10:25:04Z,"## Problem description

the lua docvisitor for latex recognizes some documentation as latex math and surrounds it by `$`.
- [x] `$` is tex, latex should use `\(`
- [x] sometimes numbers are next to symbols like `>`, these should be included into the math environment
- [x] if two math environments are next to each other, could those be combined?
",Garonenur,https://github.com/genometools/genometools/issues/826,genometools++genometools.csv
MDU6SXNzdWUxNzE1MjgxNTI=,Sorting of trans-spliced genes,OPEN,2016-08-16T21:58:33Z,2016-08-25T10:21:10Z,,"## Problem description

Trans-spliced mRNA features sort oddly. In the example below, I would expect the two components of the trans-spliced element mRNA2 to be on consecutive lines. Instead it's split up. See below for an example. Is this behaviour intentional?
## Exact command line call triggering the problem

```
gt gff3 -sort transspliced.gff
```
## Example minimal input triggering the problem

```
##gff-version 3
##sequence-region   KU215903 1 124049
KU215903    manual  gene    9802    9915    .   +   .   ID=gene3;Name=rps12|lcl|NC_021456.1_prot_YP_008082803.1_8-gene;exception=trans-splicing
KU215903    manual  gene    113225  114024  .   +   .   ID=gene4;Name=rps12|lcl|NC_021456.1_prot_YP_008082803.1_8-gene;exception=trans-splicing
KU215903    manual  mRNA    9802    9915    .   +   .   ID=mRNA2;Parent=gene3,gene4;Name=rps12|lcl|NC_021456.1_prot_YP_008082803.1_8;exception=trans-splicing
KU215903    manual  mRNA    113225  114024  .   +   .   ID=mRNA2;Parent= gene3, gene4;Name=rps12|lcl|NC_021456.1_prot_YP_008082803.1_8;exception=trans-splicing
KU215903    manual  exon    9802    9915    .   +   .   Parent=mRNA2
KU215903    manual  CDS 9802    9915    .   +   0   ID=CDS1;Parent=mRNA2
KU215903    manual  exon    113225  113456  .   +   .   Parent=mRNA2
KU215903    manual  CDS 113225  113456  .   +   0   ID=CDS1;Parent=mRNA2
KU215903    manual  intron  113457  113998  .   +   .   Parent=mRNA2
KU215903    manual  exon    113999  114024  .   +   .   Parent=mRNA2
KU215903    manual  CDS 113999  114024  .   +   2   ID=CDS1;Parent=mRNA2
```
## Observed output

```
##gff-version 3
##sequence-region   KU215903 1 124049
KU215903    manual  gene    9802    9915    .   +   .   ID=gene3;Name=rps12|lcl|NC_021456.1_prot_YP_008082803.1_8-gene;exception=trans-splicing
KU215903    manual  gene    113225  114024  .   +   .   ID=gene4;Name=rps12|lcl|NC_021456.1_prot_YP_008082803.1_8-gene;exception=trans-splicing
KU215903    manual  mRNA    9802    9915    .   +   .   ID=mRNA2;Parent=gene3,gene4;Name=rps12|lcl|NC_021456.1_prot_YP_008082803.1_8;exception=trans-splicing
KU215903    manual  exon    9802    9915    .   +   .   Parent=mRNA2
KU215903    manual  CDS 9802    9915    .   +   0   ID=CDS1;Parent=mRNA2
KU215903    manual  exon    113225  113456  .   +   .   Parent=mRNA2
KU215903    manual  CDS 113225  113456  .   +   0   ID=CDS1;Parent=mRNA2
KU215903    manual  intron  113457  113998  .   +   .   Parent=mRNA2
KU215903    manual  exon    113999  114024  .   +   .   Parent=mRNA2
KU215903    manual  CDS 113999  114024  .   +   2   ID=CDS1;Parent=mRNA2
KU215903    manual  mRNA    113225  114024  .   +   .   ID=mRNA2;Parent=gene3,gene4;Name=rps12|lcl|NC_021456.1_prot_YP_008082803.1_8;exception=trans-splicing
```
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

gt (GenomeTools) 1.5.8
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

`brew install genometools`
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Mac OS X 10.11.6
",sjackman,https://github.com/genometools/genometools/issues/829,genometools++genometools.csv
MDU6SXNzdWUxNzQyMTM0OTA=,Travis Mac OS X tests?,CLOSED,2016-08-31T08:26:22Z,2016-09-09T06:13:27Z,2016-09-09T06:13:27Z,"This is more of a public discussion about the test suite -- do we want to have Travis also run builds and tests on Mac OS X machines? I enabled OSX tests recently and after some adjustments to the test driver (https://github.com/genometools/genometools/compare/master...satta:osx_test) it seems to work well: https://travis-ci.org/satta/genometools/builds/156211407

However, this considerably increases the total test run time as the OSX runs tend to be slower than the Linux counterparts. Any opinions?
",satta,https://github.com/genometools/genometools/issues/830,genometools++genometools.csv
MDU6SXNzdWUxNzUwMzQxMzM=,intset test produces a leak,CLOSED,2016-09-05T09:44:05Z,2016-09-17T21:39:40Z,2016-09-16T08:54:03Z,"## Problem description

space leak when running `bin/gt -test`
## Exact command line call triggering the problem

```
valgrind bin/gt -test
```
## Example minimal input triggering the problem

```
valgrind bin/gt -test
intset classes...==10592== Invalid read of size 8
==10592==    at 0x6D6C63: gt_intset_8_unit_test (intset_8.c:507)
==10592==    by 0x526DD9: gt_intset_unit_test (intset_combined.c:129)
==10592==    by 0x4D276B: gt_unit_test_run (unit_testing.c:31)
==10592==    by 0x4A13A6: gt_hashmap_visit (hashmap.c:154)
==10592==    by 0x4A321E: gt_hashtable_foreach_ordered (hashtable.c:589)
==10592==    by 0x4A17D4: gt_hashmap_foreach_in_key_order (hashmap.c:178)
==10592==    by 0x4142E7: run_tests (gtr.c:404)
==10592==    by 0x4142E7: gtr_run (gtr.c:450)
==10592==    by 0x4130B7: main (gt.c:40)
```
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

`bin/gt (GenomeTools) 1.5.10`
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

```
-j 4 wrapmemcpy=yes with-sqlite=no 64bit=yes threads=yes cairo=yes CPPFLAGS='-fno-stack-protector -U_FORTIFY_SOURCE -D_GNU_SOURCE' CC='ccache gcc' test
```
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

```
Linux roma 3.12.57-44-desktop #1 SMP PREEMPT Wed Apr 6 09:18:15 UTC 2016 (9b4534f) x86_64 x86_64 x86_64 GNU/Linux
```
",stefan-kurtz,https://github.com/genometools/genometools/issues/831,genometools++genometools.csv
MDU6SXNzdWUxNzY5NTQ5Mjk=,Tests failing within testsuite with -memcheck,OPEN,2016-09-14T16:26:46Z,2016-09-15T18:25:07Z,,"## Problem description

following tests did fail, most of them with errors originating from valgrind, some just not finishing on time (dots indicate groups of tests):
- gt genomediff ...
- gt linspace_align global lin gap protein filelist
- AnnotationSketch ...
- gt seed_extend: greedy sensitivity, l, minidentity
- gt simreads grep test
- gt sketch ...
- gt greedyfwdmat ...
- gt idxlocali ...
- gt packedindex ...
- gt matstat/uniquesub at1MB U8
- gt repfind extend at1MB
- gt suffixerator ...
## Exact command line call triggering the problem

```
make -j 4 wrapmemcpy=yes with-sqlite=no 64bit=yes threads=yes cairo=yes CPPFLAGS='-fno-stack-protector -U_FORTIFY_SOURCE -D_GNU_SOURCE' CC='ccache gcc' test testthreads=3 memcheck=yes
```
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

bin/gt (GenomeTools) 1.5.10
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.2) 5.4.0 20160609
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror

(current master, head at: ba61a9536c5e1b1f2f2141f3a0816fe8d5c3fb74)
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

see above
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Ubuntu 16.04.1 LTS
",Garonenur,https://github.com/genometools/genometools/issues/834,genometools++genometools.csv
MDU6SXNzdWUxNzY5NjA4NDU=,unit test 'bit pack string module' is not valgrind clean,CLOSED,2016-09-14T16:50:33Z,2016-09-16T11:59:49Z,2016-09-16T11:59:49Z,"## Problem description

Valgrind finds errors for unit test mentioned above
## Exact command line call triggering the problem

```
valgrind gt -test
```
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

bin/gt (GenomeTools) 1.5.10
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.2) 5.4.0 20160609
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

`-j 4 wrapmemcpy=yes with-sqlite=no 64bit=yes threads=yes cairo=yes CPPFLAGS='-fno-stack-protector -U_FORTIFY_SOURCE -D_GNU_SOURCE' CC='ccache gcc'`
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

ubuntu 16.10.1 LTS
",Garonenur,https://github.com/genometools/genometools/issues/836,genometools++genometools.csv
MDU6SXNzdWUxNzcyMjA5ODE=,gt sketch test fails,CLOSED,2016-09-15T16:14:40Z,2016-09-18T08:32:49Z,2016-09-18T08:32:49Z,"## Problem description

one gt sketch test fails with incorrect output, diff fails.
## Exact command line call triggering the problem

```
./testsuite.rb -testdata /home/dirk/Repositories/genometools/testdata -bin /home/dirk/Repositories/genometools/bin -cur /home/dirk/Repositories/genometools \
          -gtruby /home/dirk/Repositories/genometools/gtruby -nordb \
          -select 1381
```
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

```
bin/gt (GenomeTools) 1.5.10
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: clang version 3.8.0-2ubuntu4 (tags/RELEASE_380/final)
Compile flags: -fstrict-aliasing -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Qunused-arguments -Wno-parentheses -Werror
```
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

```
CFLAGS+=-fstrict-aliasing assert=no amalgamation=yes 64bit=yes CC='ccache clang' -j4 cairo=yes
```
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

ubuntu 16.04.1 LTS
",Garonenur,https://github.com/genometools/genometools/issues/837,genometools++genometools.csv
MDU6SXNzdWUxODA2NzkyMDc=,gt readjoiner prefilter does not filter a sequence with N,OPEN,2016-10-03T16:03:27Z,2016-10-04T14:24:05Z,,"## Problem description

`gt readjoiner prefilter` skips a sequence with a N.
## Exact command line call triggering the problem

```
gt readjoiner prefilter -des -readset input_file.set -db input_file.fasta
```
## Example minimal input triggering the problem

``` bash
>HWI-D00483:145:C9HJBANXX:3:2201:7705:21685.1 810 921 14 125
TAACTTTGTNTTTGACCCCCGCCAATTCATTTGAGTTTTAACCTTGCGGCCGTACTCCCCAGGCGGTCGACTTAATGCGTTAGCTGCGCCACTAAGATCTCAAGGATCCCAACGGCTAGTCGACAT
```
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

gt (GenomeTools) 1.5.8
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

I'm using a version on the computing cluster I'm working on, so I am reporting the compile flags as output by `gt -version`.  

``` bash
Used compiler: gcc (GCC) 4.9.2
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -O3 -Werror
```
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Milou Cluster at UPPMAX, with Scientific Linux release 6.8 (Carbon), x86_64.  

Thank you,
Domenico
",domenico-simone,https://github.com/genometools/genometools/issues/841,genometools++genometools.csv
MDU6SXNzdWUxOTk1MjQ0NjU=,gt extractfeat is not working for me,CLOSED,2017-01-09T10:55:42Z,2020-04-23T21:36:05Z,2020-04-23T21:36:05Z,"I want to extract the chromosome location from gff file using the 'gt extract' tool. However, the tool returns with the following error message: gff file is not sorted; although i sorted the gff using ""gt gff3 sort"" . Th gff file to be sorted is [ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/331/145/GCF_000331145.1_ASM33114v1/GCF_000331145.1_ASM33114v1_genomic.gff.gz](url)
",rajultayal,https://github.com/genometools/genometools/issues/843,genometools++genometools.csv
MDU6SXNzdWUyMDgyODc5Nzc=,readjoiner overlap: error: cannot compute enhanced suffix array,CLOSED,2017-02-16T23:56:38Z,2017-02-17T09:41:51Z,2017-02-17T09:41:51Z,"## Problem description
gt -j 1 readjoiner overlap fails with **small values** of minlen (this problem doesn't happen when minlen>10)

## Exact command line call triggering the problem

```
env GT_MEM_BOOKKEEPING=on GT_ENV_OPTIONS='-spacepeak -showtime' /home/readjoiner/bin/gt -j 1 readjoiner overlap -readset /mnt/data/readset.reads.100000.fasta -l 5
```
**output:**

\# gt readjoiner overlap (version 1.2)
\# number of reads in filtered readset = 99745
\# TIME to collect initial prefixes 0.02
\# TIME to sort initial prefixes 0.03
\# TIME to remove duplicates 0.00
\# TIME to accumulate counts 1.55
\# TIME to compute partial sums 0.00
\# TIME cleaning up 0.00
\# TIME overall 1.61
\# space peak in megabytes: 1.68 (in 1769 events)
\# mmap space peak in megabytes: 2.34
\# combined space peak in megabytes: 4.02

**problem:**

```
/home/readjoiner/bin/gt readjoiner overlap: error: cannot compute enhanced suffix array in at mos
t 8103808 bytes
```

I used the following command to prefiltering:

```
/home/readjoiner/bin/gt readjoiner prefilter -readset /mnt/data/readset.reads.100000.fasta --db /mnt/data/reads.100000.fasta -maxlow 1280 -lowqual 0
```
\# gt readjoiner prefilter (version 1.2)
\# number of reads in complete readset = 100000
\# low-quality reads = 0
\# contained reads = 255
\# number of reads in filtered readset = 99745
\# space peak in megabytes: 3.93 (in 827 events)
\# mmap space peak in megabytes: 0.00
\# combined space peak in megabytes: 3.93

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

/home/readjoiner/bin/gt (GenomeTools) 1.5.10
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (Debian 4.9.2-10) 4.9.2
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

make prefix=/home/readjoiner 64bit=yes threads=yes cairo=no install

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Linux 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt11-1+deb8u6 (2015-11-09) x86_64 GNU/Linux

The machine has ~380 GiB of RAM.

Thank you!
",felipelouza,https://github.com/genometools/genometools/issues/845,genometools++genometools.csv
MDU6SXNzdWUyMDgzOTAyOTA=,readjoiner overlap: assertion failed when the number of threads -j is larger than the number of processors,OPEN,2017-02-17T09:53:55Z,2017-03-02T21:33:41Z,,"## Problem description

Sometimes, when the number of threads (set by -j) is larger than the number of processors in the machine, readjoiner breaks with the following message:

```
Assertion failed: (lb < threadinfo[t].sumofwidth), function gt_firstcodes_thread_sortremaining, file 
src/match/firstcodes.c, line 571.
This is a bug, please report it at
```

## Exact command line call triggering the problem

```
env GT_MEM_BOOKKEEPING=on GT_ENV_OPTIONS='-spacepeak -showtime' /home/readjoiner/bin/gt -j 128 readjoiner overlap -readset /mnt/data/readset.reads.400000.fasta -l 10
```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

/home/readjoiner/bin/gt (GenomeTools) 1.5.10
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (Debian 4.9.2-10) 4.9.2
Compile flags: -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

```
make prefix=/home/readjoiner 64bit=yes threads=yes cairo=no install
```

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Linux 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt11-1+deb8u6 (2015-11-09) x86_64 GNU/Linux
The machine has ~380 GiB of RAM.

Thank you!",felipelouza,https://github.com/genometools/genometools/issues/846,genometools++genometools.csv
MDU6SXNzdWUyMDk2NjQwODE=,Installation method is not clear. No targets specified and no makefile found.,OPEN,2017-02-23T04:55:23Z,2017-02-23T15:34:29Z,,"## Problem description

I followed the brew install commands listed in the read me. Everything seems to run fine but when I try to run make it throws this error. 

I have never installed packages using GNU. I have installed many bioinformatic packages but this one has me completely stumped. Can someone please help me? What am I doing wrong?


## Exact command line call triggering the problem
Macbooks-MBP:Reago Jay$ make --version
GNU Make 3.81
Copyright (C) 2006  Free Software Foundation, Inc.
This is free software; see the source for copying conditions.
There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE.

This program built for i386-apple-darwin11.3.0
Macbooks-MBP:Reago Jay$ make cairo=no
make: *** No targets specified and no makefile found.  Stop.
Macbooks-MBP:Reago Jay$ cd

```
gt ...
```

## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
",slvrshot,https://github.com/genometools/genometools/issues/847,genometools++genometools.csv
MDU6SXNzdWUyMDk3ODE4NDA=,installation problem in OSX,CLOSED,2017-02-23T14:48:03Z,2017-02-23T16:03:23Z,2017-02-23T16:03:23Z,"Hi,

I run to installation problem in OSX when compiling  Genometools.  It complained about  `Undefined symbols for architecture x86_64:`

### Exact command line call triggering the problem
```
make cairo=no
```

### output with error message

```
.....
[compile gt_wtree.o]
[compile gt_wtree_bench.o]
[link gt]
Undefined symbols for architecture x86_64:
  ""_gt_lua_open_annotationsketch"", referenced from:
      _gt_lua_open_lib in libgenometools.a(gt_lua.o)
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *** [bin/gt] Error 1
```

###  GenomeTools version 
last stable    __genometools-1.5.9.tar.gz__

### OS and environment
Mac OS X  v10.11.6
Xcodec v 8.1    
command line tools are up to date

some more
```
make cairo=no -v
GNU Make 3.81
Copyright (C) 2006  Free Software Foundation, Inc.
This is free software; see the source for copying conditions.
There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE.
```
and

```
cc -v
Apple LLVM version 8.0.0 (clang-800.0.42.1)
Target: x86_64-apple-darwin15.6.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
```

Any ideas what to do.

Cheers,
Tonu
",tmargus,https://github.com/genometools/genometools/issues/848,genometools++genometools.csv
MDU6SXNzdWUyMTAxMzg5Njc=,question: is there a simple way to transmute gff3 annotation when reverse complement a sequence?,CLOSED,2017-02-24T19:38:18Z,2022-08-30T08:47:56Z,2017-10-12T19:40:40Z,"Hi,
It could be simple question here. I googled but didn't find a good working solution.
Is there a simple way to reverse complement annotation?  I mean annotation - CDS, exons, etc ... what is marked in ""+"" stand will be swapped to ""-"" strand with positions corrected according to reverse complemented sequence. 
Tonu
 
   ",tmargus,https://github.com/genometools/genometools/issues/849,genometools++genometools.csv
MDU6SXNzdWUyMTYwNzY1MTI=,[feature request] gt seqstat using custom value for N statistic,OPEN,2017-03-22T14:11:19Z,2017-03-22T14:20:22Z,,"Would it be possible to add a feature where user could provide custom value for N, instead of default N50 and N80? I can see a situation where I would like to compare various (older) assemblies, with pre-calculated range of N values say from N50-100.",piatekmj,https://github.com/genometools/genometools/issues/850,genometools++genometools.csv
MDU6SXNzdWUyMTg1NjgyOTI=,gff3validator crashed with error message (see below),CLOSED,2017-03-31T17:35:09Z,2022-05-08T18:48:19Z,2022-05-08T18:48:19Z,"## Problem description
```
Assertion failed: (!gt_str_cmp(gt_genome_node_get_seqid((GtGenomeNode*) parent), gt_genome_node_get_seqid((GtGenomeNode*) child))), function gt_feature_node_add_child, file src/extended/feature_node.c, line 1099.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Abgebrochen (Speicherabzug geschrieben)
```
Before the crash it ran without errors and reported gff errors which I've fixed. 

## Exact command line call triggering the problem
`gt gff3validator gff_27032017_small.gff3`

## Example minimal input triggering the problem
A gff3 file to check - repaired some errors of the gff before. Don't know the exact line. 

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
```gt -version
gt (GenomeTools) 1.5.10
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror
```
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
`make` without parameters

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Ubuntu 16.04.4",Rhinogradentia,https://github.com/genometools/genometools/issues/851,genometools++genometools.csv
MDU6SXNzdWUyMTkzMzYyNTA=,error: cairo.h: No such file or directory,CLOSED,2017-04-04T18:09:53Z,2022-04-03T06:48:45Z,2022-04-03T06:48:45Z,"## Problem description

```
error: cairo.h: No such file or directory
```

## Exact command line call triggering the problem

```
make prefix=/home/linuxbrew/.linuxbrew/Cellar/genometools/1.5.9 64bit=yes
```

## Example minimal input triggering the problem

NA

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

1.5.9

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

Yes
```
make prefix=/home/linuxbrew/.linuxbrew/Cellar/genometools/1.5.9 64bit=yes
```

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Ubuntu 14 on x86_64

------

Any ideas on `make` not finding `cairo.h` though both `pkg-config` and `cairo` are installed?
Here's the issue on Homebrew/science: https://github.com/Homebrew/homebrew-science/pull/5389
And the build log from CircleCI:
https://circleci.com/gh/Homebrew/homebrew-science/4067
https://circleci.com/api/v1.1/project/github/Homebrew/homebrew-science/4067/output/29/0?file=true",sjackman,https://github.com/genometools/genometools/issues/852,genometools++genometools.csv
MDU6SXNzdWUyMjcwMjE0MDA=,Error compiling with GCC 7,CLOSED,2017-05-08T11:48:39Z,2020-09-27T09:23:10Z,2020-09-27T09:23:10Z,"## Problem description

The current master fails to build with GCC version 7:
```
src/match/xdrop.c: In function gt_evalxdroparbitscoresextend:
cc1: error: assuming signed overflow does not occur when assuming that (X - c) <= X is always true [-Werror=strict-overflow]
```
Unfortunately there is no more detailed information from the compiler.

## Exact command line call triggering the problem

```
CC=gcc-7 make -j7 assert=no
```

## Example minimal input triggering the problem

n/a

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

current master

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
```
CC=gcc-7 make -j7 assert=no
```

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Debian stretch",satta,https://github.com/genometools/genometools/issues/856,genometools++genometools.csv
MDU6SXNzdWUyMjgyMDQxNjE=,[function converttoprettysymbol] : Assertion failed: ((unsigned int) currentchar < alphabet->mapsize-1),CLOSED,2017-05-12T06:58:22Z,2018-10-08T08:56:26Z,2018-10-08T08:56:26Z,"## Problem description

Assertion failed: ((unsigned int) currentchar < alphabet->mapsize-1), function converttoprettysymbol, file src/core/alphabet.c, line 754

## Exact command line call triggering the problem
I do not know which  step could trigger this problem, as the commands were applied by the LTRSIFT software. This might caused by the Genome file, just a suggestion.

```
#Using [ltrsift]
wget http://www.zbh.uni-hamburg.de/fileadmin/gi/LTRsift/ltrsift-1.0.2-Linux_x86_64-64bit.tar.gz

./run_ltrsift

#Genome used:
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF_000142985.2_Acyr_2.0/GCF_000142985.2_Acyr_2.0_genomic.fna.gz

#The LTR annotation

##LTR_finder and LTR_digest (results)

```

## Example minimal input triggering the problem
The Genome file download link is [Acyr_2.0](ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF_000142985.2_Acyr_2.0/GCF_000142985.2_Acyr_2.0_genomic.fna.gz
).
[test.gff3.txt](https://github.com/genometools/genometools/files/995265/test.gff3.txt)


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt (GenomeTools) 1.5.9
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

```
make  64bit=yes cairo=no 
```
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

CentOS 7 x86_64",BioWu,https://github.com/genometools/genometools/issues/858,genometools++genometools.csv
MDU6SXNzdWUyMjg0NjA2NDA=,Install issue,CLOSED,2017-05-13T09:13:35Z,2017-07-11T22:54:31Z,2017-07-11T22:54:31Z,"Hello,

When I run the `make test`, I get following:

```
cd testsuite && env -i GT_MEM_BOOKKEEPING=on MAKE=make PATH=""/data/apps/sge/bin:/data/apps/sge/bin/lx-amd64:/data/apps/openmpi/bin:/data/apps/sge/bin:/data/apps/sge/bin/lx-amd64:/gpfsdata/apps/R:/data/apps/openmpi/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/gpfsdata/apps/abyss-par/bin:/gpfsdata/apps/abyss2.2/bin:/data/apps/allpathslg-52488/bin:/data/apps/amos/bin:/data/apps/qiime_software/ampliconnoise-1.27-release/bin:/data/apps/qiime_software/ampliconnoise-1.27-release/Scripts:/data/apps/qiime_software/ampliconnoise-1.27-release/Data/LookUp_E123.dat:/data/apps/qiime_software/ampliconnoise-1.27-release/Data/Tran.dat:/data/apps/arb/bin:/data/apps/ascp/:/data/apps/augustus.2.5.5/bin:/data/apps/bambus/bin:/data/apps/bcl2fastq/bin:/data/apps/bedtools2/bin:/data/apps/biopython-1.61::/usr/bin/python:/usr/bin/python2.6:/data/apps/bitbucket/bin:/data/apps/blast-2.2.26/bin:/data/apps/blast2go/bin:/data/apps/ncbi-blast-2.2.28+//bin:/data/apps/blatSrc/bin/x86_64:/data/apps/bowtie-1.1.2/:/data/apps/bowtie2-2.2.5/:/data/apps/bwa-0.7.15:/data/apps/CAP3/bin:/data/apps/qiime_software/cdbtools-10.11.2010-release:/data/apps/qiime_software/cdhit-3.1-release:/data/apps/qiime_software/chimeraslayer-4.29.2010-release/ChimeraSlayer:/data/apps/qiime_software/chimeraslayer-4.29.2010-release/NAST-iEr:/data/apps/clcservercmdline/bin:/data/apps/qiime_software/clearcut-1.0.9-release:/data/apps/clipper:/data/apps/cssc/bin:/data/apps/cufflinks-2.2.1/bin:/gpfsdata/apps/cutadapt-master/bin:/data/apps/discovar/bin:/data/apps/discovardenovo//bin:/data/apps/exonerate/bin:/data/apps/FastQC:/data/apps/fastx_toolkit-0.0.14/bin:/data/apps/fqtrim-0.9.5:/data/apps/galaxy-dist/galaxy-python:/data/apps/sge/lib/lx-amd64/libdrmaa.so.1.0:/data/apps/galaxy-central/database/tmp:/data/apps/GapCloser-1.12-r6/bin:/data/apps/GATK-3.7/:/data/apps/goss-1.2.2-r/bin:/usr/lpp/mmfs/bin:/data/apps/qiime_software/h5py-2.4.0/bin:/data/apps/qiime_software/hdf5-1.8.16-linux-centos6-x86_64-gcc447-shared/bin:/data/apps/qiime_software/hdf5-1.8.16-linux-centos6-x86_64-gcc447-shared/include:/gpfsdata/apps/hisat2-master/:/data/apps/hmmer/bin:/gpfsdata/apps/htseq-0.7:/data/apps/idba/bin:/data/apps/IGV_2.3.8/:/data/apps/qiime_software/infernal-1.0.2-release//bin:/usr/java/latest/bin:/usr/java/jre1.7.0_25/bin:/var/www/html/jbrowse/JBrowse-1.9.3/bin:/data/apps/jemalloc-4.1.1//bin:/data/apps/macs/bin:/data/apps/maker/src/bin:/gpfsdata/apps/MaSuRCA-3.2.2_RC1/bin:/data/apps/mega7/:/data/apps/metAMOS:/phylosift/bin:/AMOS/Linux-x88_64:/data/apps/metAMOS/phymm:/data/apps/metAMOS/Utilities/perl:/data/apps/metAMOS/Utilities/perl/metaphyler:/data/apps/mira/bin:/data/apps/qiime_software/mothur:/data/apps/MUMmer3.23/aux_bin:/data/apps/MUMmer3.23:/data/apps/qiime_software/muscle-3.8.31-release:/data/apps/NGSQCToolkit_v2.3:/data/apps/NGSQCToolkit_v2.3/Format-converter:/data/apps/NGSQCToolkit_v2.3/QC:/data/apps/NGSQCToolkit_v2.3/Statistics:/data/apps/NGSQCToolkit_v2.3/Trimming:/data/apps/nseg/bin:/data/apps/oases_0.2.08/bin:/data/apps/oases_0.2.08/scripts:/data/apps/picard-2.8.3//:/data/apps/pplacer//:/data/apps/qiime/1.9.1/bin:/usr/lib64/qt4/bin:/data/apps/R/bin:/data/apps/qiime_software/raxml-7.3.0-release/:/data/apps/RECON-1.07/bin:/data/apps/remoteViz/bin:/data/apps/RepeatMasker:/data/apps/RepeatModeler:/data/apps/RepeatScout-1/bin:/data/apps/rmblast/bin:/data/apps/qiime_software/rtax-0.984-release:/data/apps/samtools-1.2:/data/apps/samtools-1.2/misc:/data/apps/samtools-1.2/bcftools/bin:/data/apps/SHRiMP_2_2_3/bin:/data/apps/snap:/data/apps/soap2.21/bin:/data/apps/soapdenovo-r223/bin:/data/apps/SOPRA_v1.4.6:/data/apps/qiime_software/sourcetracker-1.0.0-release:/data/apps/sratoolkit.2.8.1-centos_linux64/bin:/data/apps/SSPACE-BASIC-2.0_linux-x86_64:/data/apps/SSPACE-BASIC-2.0_linux-x86_64/bin:/data/apps/SSPACE-BASIC-2.0_linux-x86_64/tools:/data/apps/SSPACE-BASIC-2.0_linux-x86_64/bowtie:/gpfsdata/apps/stacks-1.44/bin:/gpfsdata/apps/stacks-1.44/scripts:/gpfsdata/apps/stacks-1.44/src:/gpfsdata/apps/stacks-1.44/htslib:/data/apps/staden/bin:/data/apps/io_lib-1.13.1/bin:/gpfsdata/apps/STAR-master/bin/Linux_x86_64/:/gpfsdata/apps/stringtie-1.3.3:/data/apps/apache-tomcat-7.0.41/bin:/data/apps/tophat-2.1.0:/data/apps/TRF:/gpfsdata/apps/trim_galore_0.4.3/:/data/apps/trinityrnaseq-2.2.0/Inchworm/bin:/data/apps/trinityrnaseq-2.2.0/Chrysalis:/data/apps/trinityrnaseq-2.2.0/util:/data/apps/trinityrnaseq-2.2.0:/data/apps/qiime_software/usearch-5.2.236:/data/apps/velvet/bin:/data/apps/ViennaRNA/bin:/data/apps/ViennaRNA/share/ViennaRNA/bin:/home/ns_phd06/bin:/gpfsdata/apps/abyss-par/bin:/gpfsdata/apps/abyss2.2/bin:/data/apps/allpathslg-52488/bin:/data/apps/amos/bin:/data/apps/qiime_software/ampliconnoise-1.27-release/bin:/data/apps/qiime_software/ampliconnoise-1.27-release/Scripts:/data/apps/qiime_software/ampliconnoise-1.27-release/Data/LookUp_E123.dat:/data/apps/qiime_software/ampliconnoise-1.27-release/Data/Tran.dat:/data/apps/arb/bin:/data/apps/ascp/:/data/apps/augustus.2.5.5/bin:/data/apps/bambus/bin:/data/apps/bcl2fastq/bin:/data/apps/bedtools2/bin:/data/apps/biopython-1.61::/usr/bin/python:/usr/bin/python2.6:/gpfsdata/apps/cutadapt-master/lib/python/:/usr/bin/python:/usr/bin/python2.6:/data/apps/bitbucket/bin:/data/apps/blast2go/bin:/data/apps/ncbi-blast-2.2.28+//bin:/data/apps/blast-2.2.26/bin:/data/apps/blatSrc/bin/x86_64:/data/apps/bowtie2-2.2.5/:/data/apps/bowtie-1.1.2/:/data/apps/bwa-0.7.15:/data/apps/CAP3/bin:/data/apps/qiime_software/cdbtools-10.11.2010-release:/data/apps/qiime_software/cdhit-3.1-release:/data/apps/qiime_software/chimeraslayer-4.29.2010-release/ChimeraSlayer:/data/apps/qiime_software/chimeraslayer-4.29.2010-release/NAST-iEr:/data/apps/clcservercmdline/bin:/data/apps/qiime_software/clearcut-1.0.9-release:/data/apps/clipper:/data/apps/cssc/bin:/data/apps/cufflinks-2.2.1/bin:/gpfsdata/apps/cutadapt-master/bin:/data/apps/discovardenovo//bin:/data/apps/discovar/bin:/data/apps/exonerate/bin:/data/apps/FastQC:/data/apps/fastx_toolkit-0.0.14/bin:/data/apps/fqtrim-0.9.5:/data/apps/galaxy-dist/galaxy-python:/data/apps/sge/lib/lx-amd64/libdrmaa.so.1.0:/data/apps/galaxy-central/database/tmp:/data/apps/GapCloser-1.12-r6/bin:/data/apps/GATK-3.7/:/data/apps/goss-1.2.2-r/bin:/usr/lpp/mmfs/bin:/data/apps/qiime_software/h5py-2.4.0/bin:/data/apps/qiime_software/hdf5-1.8.16-linux-centos6-x86_64-gcc447-shared/bin:/data/apps/qiime_software/hdf5-1.8.16-linux-centos6-x86_64-gcc447-shared/include:/gpfsdata/apps/hisat2-master/:/data/apps/hmmer/bin:/gpfsdata/apps/htseq-0.7:/data/apps/idba/bin:/data/apps/IGV_2.3.8/:/data/apps/qiime_software/infernal-1.0.2-release//bin:/usr/java/latest/bin:/usr/java/jre1.7.0_25/bin:/var/www/html/jbrowse/JBrowse-1.9.3/bin:/data/apps/jemalloc-4.1.1//bin:/data/apps/macs/bin:/data/apps/maker/src/bin:/gpfsdata/apps/MaSuRCA-3.2.2_RC1/bin:/data/apps/mega7/:/data/apps/metAMOS:/phylosift/bin:/AMOS/Linux-x88_64:/data/apps/metAMOS/phymm:/data/apps/metAMOS/Utilities/perl:/data/apps/metAMOS/Utilities/perl/metaphyler:/data/apps/mira/bin:/data/apps/qiime_software/mothur:/data/apps/MUMmer3.23/aux_bin:/data/apps/MUMmer3.23:/data/apps/qiime_software/muscle-3.8.31-release:/data/apps/NGSQCToolkit_v2.3:/data/apps/NGSQCToolkit_v2.3/Format-converter:/data/apps/NGSQCToolkit_v2.3/QC:/data/apps/NGSQCToolkit_v2.3/Statistics:/data/apps/NGSQCToolkit_v2.3/Trimming:/data/apps/nseg/bin:/data/apps/oases_0.2.08/bin:/data/apps/oases_0.2.08/scripts:/data/apps/picard-2.8.3//:/data/apps/pplacer//:/data/apps/qiime/1.9.1/bin:/usr/lib64/qt4/bin:/data/apps/qiime_software/raxml-7.3.0-release/:/data/apps/RECON-1.07/bin:/data/apps/remoteViz/bin:/data/apps/RepeatMasker:/data/apps/RepeatModeler:/data/apps/RepeatScout-1/bin:/data/apps/rmblast/bin:/data/apps/R/bin:/data/apps/qiime_software/rtax-0.984-release:/data/apps/samtools-1.2:/data/apps/samtools-1.2/misc:/data/apps/samtools-1.2/bcftools/bin:/data/apps/SHRiMP_2_2_3/bin:/data/apps/snap:/data/apps/soap2.21/bin:/data/apps/soapdenovo-r223/bin:/data/apps/SOPRA_v1.4.6:/data/apps/qiime_software/sourcetracker-1.0.0-release:/data/apps/sratoolkit.2.8.1-centos_linux64/bin:/data/apps/SSPACE-BASIC-2.0_linux-x86_64:/data/apps/SSPACE-BASIC-2.0_linux-x86_64/bin:/data/apps/SSPACE-BASIC-2.0_linux-x86_64/tools:/data/apps/SSPACE-BASIC-2.0_linux-x86_64/bowtie:/gpfsdata/apps/stacks-1.44/bin:/gpfsdata/apps/stacks-1.44/scripts:/gpfsdata/apps/stacks-1.44/src:/gpfsdata/apps/stacks-1.44/htslib:/data/apps/staden/bin:/data/apps/io_lib-1.13.1/bin:/gpfsdata/apps/STAR-master/bin/Linux_x86_64/:/gpfsdata/apps/stringtie-1.3.3:/data/apps/apache-tomcat-7.0.41/bin:/data/apps/tophat-2.1.0:/data/apps/TRF:/gpfsdata/apps/trim_galore_0.4.3/:/data/apps/trinityrnaseq-2.2.0/Inchworm/bin:/data/apps/trinityrnaseq-2.2.0/Chrysalis:/data/apps/trinityrnaseq-2.2.0/util:/data/apps/trinityrnaseq-2.2.0:/data/apps/qiime_software/usearch-5.2.236:/data/apps/velvet/bin:/data/apps/ViennaRNA/bin:/data/apps/ViennaRNA/share/ViennaRNA/bin"" \
          CCACHE_DISABLE=yes HOME=/home/ns_phd06 \
          ruby -I. testsuite.rb \
          -testdata /gpfsdata/GenhuaLab/zituo/genometools-master/testdata -bin /gpfsdata/GenhuaLab/zituo/genometools-master/bin -cur /gpfsdata/GenhuaLab/zituo/genometools-master \
          -gtruby /gpfsdata/GenhuaLab/zituo/genometools-master/gtruby  -hmmer \
          -select 0..5000 \
          
env: ruby: No such file or directory
make: *** [test] Error 127
```
What's wrong with it??
Anyone can help me?",YangZituo,https://github.com/genometools/genometools/issues/859,genometools++genometools.csv
MDU6SXNzdWUyMzQwMTE3NjU=,Tirvish giving error,CLOSED,2017-06-06T20:18:38Z,2017-10-12T19:41:21Z,2017-10-12T19:41:21Z,"Hello,

I am trying to run gt tirvish with my sequences. I have 3203 scaffolds in a fasta file named as Ch1 - Ch3203.

It gives me the error:

warning: terminal_inverted_repeat_element (generated, line 0) is too short to be translated (0 nt), skipped domain search
gt tirvish: error: query seqid 'Ch1' could match more than one sequence description


Exact command line call triggering the problem:

```
gt suffixerator -db allo.fasta -indexname Tirlist -tis -suf -lcp -des -ssp -dna -mirrored
gt tirvish -index Tirlist -hmms TEs.hmm -mintirlen 20 -mintirdist 100  1> out.txt
```
It is giving a gff output [out.txt](https://github.com/genometools/genometools/files/1056278/out.txt) but it is empty.

GenomeTools version: 1.5.10


GenomeTools compiled with make cairo=no




Operating system: Mac OS X, OS version 10.12.4 and platform x86_64
",rimjhimroy,https://github.com/genometools/genometools/issues/862,genometools++genometools.csv
MDU6SXNzdWUyMzU1MzMyMTU=,matchtool with non-existing file leaks,CLOSED,2017-06-13T12:13:44Z,2017-06-15T14:28:36Z,2017-06-15T14:28:36Z,"## Problem description
gt matchtool leaks for non-existend input file

## Exact command line call triggering the problem
(xx is a non-existing file)

bin/gt matchtool -type BLASTOUT -matchfile xx
bin/gt matchtool: error: no such file or directory xx
# space peak in megabytes: 0.05 (in 523 events)
# mmap space peak in megabytes: 0.00
# combined space peak in megabytes: 0.05
bug: 16 bytes memory leaked (allocated on line 40 in file ""src/extended/match_iterator.c"")

## Example minimal input triggering the problem

N/A
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
current master of gt

commit e6fe89e516ce7d0fcca147188a678a9df82ecdd1

compiled with

${MAKE} with-sqlite=no 64bit=yes threads=yes cairo=no  popcnt=yes CC='ccache /usr/local/zbhtools/gcc/gcc-7.1.0/bin/gcc'

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

${MAKE} with-sqlite=no 64bit=yes threads=yes cairo=no  popcnt=yes CC='ccache /usr/local/zbhtools/gcc/gcc-7.1.0/bin/gcc'

## What operating system

Linux  3.12.67-64-desktop #1 SMP PREEMPT Fri Dec 9 15:56:17 UTC 2016 (35c7b99) x86_64 x86_64 x86_64 GNU/Linux
",stefan-kurtz,https://github.com/genometools/genometools/issues/864,genometools++genometools.csv
MDU6SXNzdWUyMzY2ODQyMTQ=,Installation problem,CLOSED,2017-06-17T21:06:32Z,2017-06-21T09:30:14Z,2017-06-18T08:40:05Z,"## Problem description
I do this:
```
PATH=$PATH:/home/data/rking/gt-1.5.5-Linux_x86_64-64bit-complete/bin
export LD_LIBRARY_PATH=/home/data/rking/gt-1.5.5-Linux_x86_64-64bit-complete/gtpython
```
Then test it
```
python setup.py test
```
but get this error
```
ERROR:root:Error parsing
Traceback (most recent call last):
  File ""/tmp/easy_install-OwJhcK/mock-2.0.0/pbr-3.0.1-py2.6.egg/pbr/core.py"", line 111, in pbr
    attrs = util.cfg_to_args(path, dist.script_args)
  File ""/tmp/easy_install-OwJhcK/mock-2.0.0/pbr-3.0.1-py2.6.egg/pbr/util.py"", line 251, in cfg_to_args
    kwargs = setup_cfg_to_setup_kwargs(config, script_args)
  File ""/tmp/easy_install-OwJhcK/mock-2.0.0/pbr-3.0.1-py2.6.egg/pbr/util.py"", line 434, in setup_cfg_to_setup_kwargs
    if pkg_resources.evaluate_marker('(%s)' % env_marker):
AttributeError: 'module' object has no attribute 'evaluate_marker'
error: Setup script exited with error in setup command: Error parsing /tmp/easy_install-OwJhcK/mock-2.0.0/setup.cfg: AttributeError: 'module' object has no attribute 'evaluate_marker'
```
Any ideas?
Python 2.6.6 used

## Exact command line call triggering the problem

```
gt ...
```

## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
",rob123king,https://github.com/genometools/genometools/issues/868,genometools++genometools.csv
MDU6SXNzdWUyNDg0MzU4MTE=,automatically apply gffvalidator suggetions,OPEN,2017-08-07T14:50:27Z,2017-08-07T16:04:20Z,,"## Problem description

When trying to reorder some manipulated gff files where the features got mixed up, i bump repeatetly into warning messages and gt stops:  

message:
```
gt gff3: error: CDS feature on line 167553 in file ""peex113.combo.sorted.gff"" has the wrong phase 1 (should be 2)
```
This is nice to know but is there a way to apply the suggested changes automatically rather than having to change each reading frame by hand?

## Exact command line call triggering the problem

```

gt gff3 -sort peex113.combo.sorted.gff > peex113.combo.S.gff 
```



## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt (GenomeTools) 1.5.8


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
No

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu 16.04",MichelMoser,https://github.com/genometools/genometools/issues/875,genometools++genometools.csv
MDU6SXNzdWUyNTU4OTYzODk=,gff3validator assertion failed,OPEN,2017-09-07T10:52:56Z,2018-01-23T13:49:53Z,,"## Problem description
Assertion failed: (elemidx >= q->front), function gt_queue_remove, file /tmp/.RPM23975.d/BUILD/genometools-1.5.9/src/core/queue.c, line 135.

## Exact command line call triggering the problem

```
gt gff3validator gff3validator_error.txt
```

## Example minimal input triggering the problem

[gff3validator_error.txt](https://github.com/genometools/genometools/files/1284408/gff3validator_error.txt)


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
/usr/libexec/genometools/gt (GenomeTools) 1.5.9
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (GCC) 5.3.1 20160406 (Red Hat 5.3.1-6)
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make amalgamation=yes cairo=no

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Fedora 23 x86_64
",zivara,https://github.com/genometools/genometools/issues/877,genometools++genometools.csv
MDU6SXNzdWUyNjQyODU1NzU=,bed to gff3,CLOSED,2017-10-10T16:03:28Z,2017-10-11T06:12:15Z,2017-10-11T06:12:15Z,"## Problem description
Program seems to only print the gff3 file in terminal instead of creating an output file. 

## Exact command line call triggering the problem

```
gt ...Usage: /Users/immuno569/Downloads/gt-1.5.10-Darwin_i386-64bit/bin/gt bed_to_gff3 [BED_file]
Macintosh-4:~ Immuno569$ /Users/Immuno569/Downloads/gt-1.5.10-Darwin_i386-64bit/bin/gt bed_to_gff3 /Users/Immuno569/Downloads/hglft_genome_mm9_VJkl.bed -o Lambda-force yes 
```

## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

gt-1.5.10-Darwin_i386-64bit
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Mac OSX",immuno549,https://github.com/genometools/genometools/issues/879,genometools++genometools.csv
MDU6SXNzdWUyODEwMDUxNDA=,removing false positives,CLOSED,2017-12-11T12:50:54Z,2020-04-23T21:28:07Z,2020-04-23T21:28:07Z,"Hey there,

Is there a common way to remove false positives which are introduced by LTR-Harvest? I was following this protocol (http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/Repeat_Library_Construction-Advanced) but it does not work for me as I get stuck at some point. 

kind regards",timometz,https://github.com/genometools/genometools/issues/881,genometools++genometools.csv
MDU6SXNzdWUyODc1Njc4NjM=,gt ltrdigest: error: no description matched sequence ID 'seq0',CLOSED,2018-01-10T20:32:20Z,2018-01-22T08:23:46Z,2018-01-22T08:23:46Z,"## Problem description
I'm trying to run LTR digest but it gives me error. I already checked my phmm version 

## Exact command line call triggering the problem
gt ltrharvest -index Muschr4.fsa -gff3 ltrs.gff3
gt suffixerator -tis -des -dna -ssp -db Muschr4.fsa -indexname Muschr4.fsa
gt gff3 -sort ltrs.gff3 > ltrs_sorted.gff3

- gt ltrdigest -hmms *hmm -aaout -outfileprefix ltrs_sorted -seqfile Muschr4.fsa -matchdescstart < ltrs_sorted.gff3 > lologre_ltrdigest.gff3
warning: LTR_retrotransposon (stdin, line 5) is too short to be translated (0 nt), skipped domain search
gt ltrdigest: error: no description matched sequence ID 'seq0'


## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt (GenomeTools) 1.5.10

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
 make cairo=no 64bit=yes with-hmmr=no threads=yes install
then i installed hmmer 


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu 16.04 LTS
",intirules,https://github.com/genometools/genometools/issues/882,genometools++genometools.csv
MDU6SXNzdWUyODgxNzI4ODc=,Gt cds question: NOT AN ISSUE,OPEN,2018-01-12T16:25:02Z,2018-01-12T16:25:02Z,,"Hello All,

This is NOT an Issue. I tried to get my question answered via gitter, but I have no response there. Therefore, I have to reluctantly post here.

I had a question on the ""GT CDS"" command. I would like to add the CDS feature to my Gff3 file, that has exons in it. I saw that genometools can do this for you.

gt cds -startcodon -finalstopcodon -seqfile foo.fasta -o foo.gff3 [GFF3-FILE]

1) I am looking for the CDS to be the longest ORF with an ATG start codon per mRNA. Do the gff3 coordinates in the output reflect that? 

2) It is possible that a single mRNA will give rise to two CDS of equal size but with different start and stops. In case of such conflicts, what does gt cds do?

3) I did not see a flag for specifying the genetic code. Is this by default ""standard vertebrate""?

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
I am working on a 64-bit CentOS 6.2 linux system",sanyalab,https://github.com/genometools/genometools/issues/883,genometools++genometools.csv
MDU6SXNzdWUyOTg0NzEwNTI=,cannot malloc(14728584432) memory attempted ,CLOSED,2018-02-20T04:50:23Z,2018-02-20T19:15:55Z,2018-02-20T19:15:55Z,"## Problem description
Im trying to analize some mammals genomes, im not sure what is the max limit of the archive size i can work with  

## Exact command line call triggering the problem

```
gt suffixerator -db Genoma1.fna -indexname Genoma1.fna -tis -suf -lcp -des -ssp -sds -dna 
```
then i solve it aparently with  
 gt suffixerator -db Genoma1.fna -indexname Genoma1.fna -tis -suf -lcp -des -ssp -sds -dna -memlimit 2GB
but im not sure whats the limit i can work, cause i wanna analize some bigger archives 
## Example minimal input triggering the problem
gt suffixerator -db Genoma1.fna -indexname Genoma1.fna -tis -suf -lcp -des -ssp -sds -dna
cannot malloc(14728584432) memory
attempted on line 145 in file ""src/match/sfx-suffixgetset.c""


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

unstable
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using? 

ubuntu 16.04 lts
",intirules,https://github.com/genometools/genometools/issues/884,genometools++genometools.csv
MDU6SXNzdWUzMTcyODI2NzQ=,readjoiner assertion failure,OPEN,2018-04-24T15:36:23Z,2018-04-24T16:32:56Z,,"## Problem description
readjoiner fails with an assertion:

 $ gt readjoiner overlap -readset samp -l 90
# gt readjoiner overlap (version 1.2)
# number of reads in filtered readset = 7960
Assertion failed: (fatherdepth != state->read_length), function processleafedge_spmeq, file src/match/rdj-spmf\
ind.c, line 407.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Aborted
(pehaplo_env2) (viral-ngs)bash:ip-172-31-91-198:/ramdisk/assembly_MuV-081 658 $ gt -version
gt (GenomeTools) 1.5.11
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (GCC) 7.2.1 20170915 (Red Hat 7.2.1-2)
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror


-

## Exact command line call triggering the problem

```
gt readjoiner overlap -readset samp -l 90
[readjoiner_bug.tar.gz](https://github.com/genometools/genometools/files/1943502/readjoiner_bug.tar.gz)

```

## Example minimal input triggering the problem
attached

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt readjoiner overlap -readset samp -l 90


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make -j94 cairo=no

but same bug happens with readjoiner from bioconda, with gt 1.5.9 and 1.5.10

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Amazon Linux (not Amazon Linux 2): 4.14.33-51.34.amzn1.x86_64 #1 SMP Fri Apr 13 18:18:26 UTC 2018 x86_64 x86_64 x86_64 GNU\
/Linux


",notestaff,https://github.com/genometools/genometools/issues/885,genometools++genometools.csv
MDU6SXNzdWUzMzYwNzQzMDc=,genometools-1.5.9 installation problem in Ubuntu 16.04.,CLOSED,2018-06-27T04:36:33Z,2020-04-23T21:27:07Z,2020-04-23T21:26:56Z,"## Problem description
graphics_cairo_api.h:21:19: fatal error: cairo.h: No such file or directory
compilation terminated

## Exact command line call triggering the problem

```
make
```

## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
genometools-1.5.9

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu 16.04",BiodeB,https://github.com/genometools/genometools/issues/886,genometools++genometools.csv
MDU6SXNzdWUzNDAxNzI5Mjg=,Annotate fasta LTR elements with pHMM search option of LTR-digest,CLOSED,2018-07-11T09:57:27Z,2018-07-17T08:33:09Z,2018-07-17T08:33:08Z,"Hi All,

I have a multifasta file with examplars LTR elements obtained using LTR-harvest and LTR-digest follwing the ""Repeat Library Construction-Advanced"" pipeline.

http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/Repeat_Library_Construction-Advanced

I'd like to annotate these fasta LTR elements using the pHMM search option of LTR-digest.
I have installed genometools-1.5.10 including the pHMM search option.

$ make with-hmmer=yes threads=yes cairo=no
$ make install cairo=no prefix=/home/data/genometools-1.5.10/bin

I downloaded all the HMMs from GyDB and converted them in HMMER3.
I created the suffix for my multifasta file:

$ gt suffixerator -tis -des -dna -ssp -db MyLTR.fasta -indexname MyLTR

Finally, I have launched the following command line:

$ gt -j 10 ltrdigest -hmms GyDB/*.hmm -- MyLTR > ltrdigest

The process is running with less than 1 CPU and the output never updates.

Did I miss something in the command line that stuck the process? Or is there something in general that I am missing?

Thank you for any advice",uceleste,https://github.com/genometools/genometools/issues/887,genometools++genometools.csv
MDU6SXNzdWUzNDY2NTc4NjU=,Collapse intron coords into just 1 instance?,CLOSED,2018-08-01T15:44:28Z,2018-09-06T18:19:30Z,2018-09-06T18:19:30Z,"## Problem description
Redundancy in  -addintrons step results
Lines reported by 

## Exact command line call triggering the problem
INPUT FILE is at https://ufile.io/f691x (link expires in 30 days)
Permanent link at https://genome.jgi.doe.gov/portal/pages/dynamicOrganismDownload.jsf?organism=Acoerulea#

**Step 1**
-sort -tidy -retainids Acoerulea: Acoerulea_322_v3.1.gene_exons.gff3.gz > Acoerulea_322_v3.1.gene_exons_Sort_Tidy_RetainIDs_gt.gff3
**Step 2**
gt gff3validator Acoerulea_322_v3.1.gene_exons_Sort_Tidy_RetainIDs_gt.gff3 > Acoerulea_322_v3.1.gene_exons_Sort_Tidy_RetainIDs_gt_gff3validator.txt
This step was OK, returned the message ""input is valid GFF3""
Note that original GFF3 file from the links above do NOT return this message, hence the sort tody step
**Step 3**
gt gff3 -retainids -addintrons Acoerulea_322_v3.1.gene_exons_Sort_Tidy_RetainIDs_gt.gff3 > Acoerulea_322_v3.1.gene_exons_Sort_Tidy_RetainIDs_gt_INTRONSadded.gff3

## Need to eliminate isoform redundancy
grep -e ""32237132"" Acoerulea_322_v3.1.gene_exons_Sort_Tidy_RetainIDs_gt_INTRONSadded.gff3
Chr_03	.	intron	32237031	32237132	.	+	.	Parent=Aqcoe3G276000.1.v3.1
Chr_03	.	intron	32237031	32237132	.	+	.	Parent=Aqcoe3G276000.3.v3.1
Chr_03	.	intron	32237031	32237132	.	+	.	Parent=Aqcoe3G276000.2.v3.1

## Problem Definition
I need to extract intron sequences. So when I use these coords, I get the same intron DNA sequence thrice. This happens for several intron regions. How do I extract sequences without redundancy? i.e. the combination of fasta header and sequence should appear just once? Currently I am using gt generated GFF3 file in combination with bedtools getfasta to extract DNA sequences with GFF3+Genome fasta files as inputs

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt (GenomeTools) 1.5.8

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
I don't think this is a problem.
make --version
GNU Make 4.1
Built for x86_64-pc-linux-gnu
Copyright (C) 1988-2014 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
uname -a
Linux c11-96 4.4.0-124-generic #148-Ubuntu SMP Wed May 2 13:00:18 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux",anandksrao,https://github.com/genometools/genometools/issues/888,genometools++genometools.csv
MDU6SXNzdWUzNDkzMzE2NjQ=,tests failing,OPEN,2018-08-10T00:02:22Z,2018-08-14T01:09:48Z,,"## Problem description
We had several of the tests fail,
```
554: gt inlineseq_split (unwritable GFF)                         : failed
     [ problem: unexpected return code: 0 != 1
       in: /usr/local/src/genometools-1.5.10/testsuite/stest_testsuite/test554 ]
555: gt inlineseq_split (unwritable FASTA)                       : failed
     [ problem: unexpected return code: 0 != 1
       in: /usr/local/src/genometools-1.5.10/testsuite/stest_testsuite/test555 ]
1089: genome_stream bindings (output stream)                      : failed
     [ problem: unexpected return code: 0 != 1
       in: /usr/local/src/genometools-1.5.10/testsuite/stest_testsuite/test1089 ]
1111: gt seed_extend: maxmat                                      : failed
     [ problem: unexpected return code: 1 != 0
       in: /usr/local/src/genometools-1.5.10/testsuite/stest_testsuite/test1111 ]
1112: gt seed_extend: symmetry of maxmat/use-apos                 : failed
     [ problem: unexpected return code: 1 != 0
       in: /usr/local/src/genometools-1.5.10/testsuite/stest_testsuite/test1112 ]
1113: gt seed_extend: fstperquery                                 : failed
     [ problem: unexpected return code: 1 != 0
       in: /usr/local/src/genometools-1.5.10/testsuite/stest_testsuite/test1113 ]
1114: gt seed_extend: display arguments                           : failed
     [ problem: unexpected return code: 1 != 0
       in: /usr/local/src/genometools-1.5.10/testsuite/stest_testsuite/test1114 ]
1116: gt dev show_seedext without alignment                       : failed
     [ problem: unexpected return code: 1 != 0
       in: /usr/local/src/genometools-1.5.10/testsuite/stest_testsuite/test1116 ]
1417: gt sketch short test (unwriteable PNG file)                 : failed
     [ problem: unexpected return code: 0 != 1
       in: /usr/local/src/genometools-1.5.10/testsuite/stest_testsuite/test1417 ]
1418: gt sketch short test (unwriteable PDF file)                 : failed
     [ problem: unexpected return code: 0 != 1
       in: /usr/local/src/genometools-1.5.10/testsuite/stest_testsuite/test1418 ]
```

## Exact command line call triggering the problem

```
make test
```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
1.5.10

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
yes, no parameters

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
CentOS 6.9 x86_64",AGI-chandler,https://github.com/genometools/genometools/issues/889,genometools++genometools.csv
MDU6SXNzdWUzNTUyODA2MjQ=,'prj': No such file or directory,OPEN,2018-08-29T18:28:56Z,2020-04-23T21:26:45Z,,"## Problem description
After running `gt suffixerator`, I don't have **prj** file, and **lcp**, **llv**, **suf** file are empty. 
Any idea?

```
-rw-r--r-- 1 evrpa RstudioUsersGenomeAnalytics 908M Aug 29 17:57 CR51.fa
-rw-r--r-- 1 root  root                         24K Aug 29 18:07 CR51.fa.des
-rw-r--r-- 1 root  root                        224M Aug 29 18:07 CR51.fa.esq
-rw-r--r-- 1 root  root                           0 Aug 29 18:07 CR51.fa.lcp
-rw-r--r-- 1 root  root                           0 Aug 29 18:07 CR51.fa.llv
-rw-r--r-- 1 root  root                         65K Aug 29 18:07 CR51.fa.md5
-rw-r--r-- 1 root  root                         16K Aug 29 18:07 CR51.fa.sds
-rw-r--r-- 1 root  root                        7.9K Aug 29 18:07 CR51.fa.ssp
-rw-r--r-- 1 root  root                           0 Aug 29 18:07 CR51.fa.suf

```

```
gt ltrharvest: error: fopen(): cannot open file 'CR51.fa.prj': No such file or directory
```

## Exact command line call triggering the problem

```
gt suffixerator -db CR51.fa -indexname CR51.fa -tis -suf -lcp -des -ssp -sds -dna
```

## Example minimal input triggering the problem
 

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
```
gt (GenomeTools) 1.5.8
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (Ubuntu 5.3.1-8ubuntu2) 5.3.1 20160205
Compile flags: -g -O2 -fstack-protector-strong -Wformat -Werror=format-security -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -O3

```

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
apt-get install genometools -y

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu
",xinshuaiqi,https://github.com/genometools/genometools/issues/890,genometools++genometools.csv
MDU6SXNzdWUzNTU1NzAwOTc=,.,CLOSED,2018-08-30T12:49:01Z,2018-08-30T12:51:06Z,2018-08-30T12:49:19Z,,Rory-McLeod,https://github.com/genometools/genometools/issues/891,genometools++genometools.csv
MDU6SXNzdWUzNTU5NDg3ODI=,Version Number Question,OPEN,2018-08-31T11:46:12Z,2018-09-06T18:27:54Z,,"## Version number proposal

using `gt --version` prints besides other information `gt (GenomeTools) 1.5.11` (with the current master).
The last Release was 1.5.10 so there is not really a 1.5.11 and, if one has to handle different compiles of gt, all are the same version unless one is older than a recent release.

If one now uses `git describe --tags` on the current master one gets: `v1.5.10-19-g161fb4c21` - which is much more helpful in my eyes. It contains the version, the number of commits following the release-tag and even the hash of HEAD.

The only Problem I see with this: if one compiles the source from a download other than git, this information would not be present. But it could be included in the VERSION file as a fallback for our releases on GitHub?

nevertheless I question the policy of printing a version number that is not released yet.
",Garonenur,https://github.com/genometools/genometools/issues/892,genometools++genometools.csv
MDU6SXNzdWUzNTY0ODgyNDI=,Error when using gt gff3 and NCBI downloaed gff3 files,CLOSED,2018-09-03T12:34:08Z,2018-09-03T12:53:27Z,2018-09-03T12:53:27Z,"## Problem description
When I try to sort and tidy gff files downloaded from NCBI I get the following problem:

""gt gff3: error: the multi-feature with ID ""cds19"" on line 290 in file ""Acyrthosiphon_pisum.gff"" does not have a 'start_range' attribute which is present in its counterpart on line 293""

## Exact command line call triggering the problem
gt gff3 -tidy -sort  Acyrthosiphon_pisum.gff> Test.gff3 
```
gt ...
```

## Example minimal input triggering the problem
The input is the gff3 file of Acyrthosiphon pisum downloaded from the refseq assembly of this species.: https://www.ncbi.nlm.nih.gov/assembly/GCF_000142985.2

The problem appears with other gff files downloaded from NCBI as well.
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
1.5.1

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
Was already installed in the computer I am using
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Linux Mint 17.3 Rosa
",PanosProv,https://github.com/genometools/genometools/issues/897,genometools++genometools.csv
MDU6SXNzdWUzNTg5NDc0NzI=,src/core/md5_fingerprint.c:20:10: fatal error: md5.h: No such file or directory,CLOSED,2018-09-11T08:49:09Z,2018-09-21T23:05:54Z,2018-09-21T23:05:54Z,"Hi,
  I am trying to compile genometools-1.5.10 on Gentoo Linux but it somehow fails to find md5.h. Is it the one from openssl/md5.h actually or some lua stuff?

```
src/core/md5_fingerprint.c:20:10: fatal error: md5.h: No such file or directory
 #include ""md5.h""
          ^~~~~~~
compilation terminated.
make: *** [Makefile:823: obj/src/core/md5_fingerprint.o] Error 1
```

  Further, I lack section Requirements in the INSTALL file stating what is needed. The listing below is maybe redundant?

```
DEPEND=""
    dev-libs/glib
    x11-libs/pango
    cairo? ( x11-libs/cairo )
    sci-biology/samtools:0.1-legacy
    dev-db/sqlite:3
    >=dev-lang/lua-5.1:=
    dev-lua/lpeg
    dev-lua/luafilesystem
    dev-lang/luajit
    dev-libs/tre""
# http://keplerproject.github.io/md5/ ?
# http://keplerproject.org/cgilua ?
RDEPEND=""${DEPEND}""
```

  Where do lua-des56 and lua-md5 come from?
",mmokrejs,https://github.com/genometools/genometools/issues/898,genometools++genometools.csv
MDU6SXNzdWUzNjEwMzQxNzY=,"LTR Harvest ""Longest not defined error""",OPEN,2018-09-17T20:38:01Z,2020-04-23T21:25:49Z,,"## Problem description
When I submit an LTR Harvest job it crashes with the error ""Longest not defined"". This is the error that comes up in the Genome Tools gt script:
^@^@^@^@^@^@longest is already defined as %lu^@^@^@^@^@^@^@program error: not enough space for specpos^@^@^@^@^@program error: too much space for specpos: allocated = %lu != %lu = used^@^@^@^@^@^@^@^@longest is not defined after merging^@^@^@^@gt_sufbwt2fmindex^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@copytheindexfile^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@nextesamergedsufbwttabvalues^@%lu: sum_score=%ld
```

## Exact command line call triggering the problem
gt ltrharvest

## Example minimal input triggering the problem
gt ltrharvest -index pe.cor.suffix_index.fsa -range 0 0 -seed 30 -xdrop 5 -mat 2 -mis -2 -ins -3 -del -3 -minlenltr 100 -maxlenltr 1000 -mindistltr 1000 -maxdistltr 15000 -similar 90 -out predicted.pe.cor.fsa

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
GenomeTools 1.5.9

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make with no parameters

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Mac OS 8 GB but the program is being run in a server with more memory.",joan103777,https://github.com/genometools/genometools/issues/901,genometools++genometools.csv
MDU6SXNzdWUzNjM0OTY0MDk=,pip installation,CLOSED,2018-09-25T09:52:18Z,2020-04-23T21:26:12Z,2020-04-23T21:26:12Z,"## Problem description
I am installing genometools with pip on Ubuntu 18.04 and Debian 9.5 (other computer) and at the end, the gt command is not available. After installation with apt-get install genometools it works, so I think is a problem of pip configuration

## Exact command line call triggering the problem
sudo pip install genometools
```
gt ...
```

## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
",gonzalezibeas,https://github.com/genometools/genometools/issues/903,genometools++genometools.csv
MDU6SXNzdWUzNzMxNzkyMTY=,gt tirvish run,CLOSED,2018-10-23T20:09:32Z,2020-06-02T19:46:21Z,2020-04-23T21:25:32Z,"## Problem description
I  want to discover TIR (Terminal Inverted Repeat) elements with gt tirvish. I ran the command as I show you next (without problems). Then I want to filter the output by protein motif as it can be done with the ltrharvest/ltrdigest, but the output was 0 TIRs. I did it wiht the gt select using the .lua files. Is there a way to filtered complete TIRs with domain identification?

## Exact command line call triggering the problem
# gt tirvish run
gt tirvish -index potato_dm_v404_all_pm_un.fasta -maxtirlen 80000 -similar 90 -seqids -md5 -hmms /GyDB_collection/profiles/*hmm > potato_tir.gff3
#  quick check results
gt stat potato_tir.gff3
# sort output
gt gff3 -sort potato_tir.gff3 > potato_tir.sorted.gff3
# Filter out elements with no protein domain hits
gt select -rule_files -home/dzavallo/software/filter_match.lua < potato_tir.sorted.gff3 > potato_tir_filtered_PM.gf33


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt (GenomeTools) 1.5.9

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Ubuntu 16.04",DiegoZavallo,https://github.com/genometools/genometools/issues/905,genometools++genometools.csv
MDU6SXNzdWUzNzU4MzA0NjM=,gt ltrclustering,OPEN,2018-10-31T07:22:41Z,2018-11-15T10:28:20Z,,"## Problem description

after the identification of LTR through Ltrharvest and annotation using Ltrdigest , I'm facing an error while trying to use (ltrsift) ltrclustering to group the output into families 

## Exact command line call triggering the problem

```
gt ltrclustering -psmall 80 -plarge 30 -o Out_clustring_ltrdigest index.fna Ltrdigst.gff
```

##Error output 

```
gt ltrclustering -psmall 80 -plarge 30 -o Out_Clustrer index.fna Ltrdigst_Result.gff 
Assertion failed: (eb->plainseq), function gt_encseq_builder_build, file src/core/encseq.c, line 9098.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Abort trap: 6


```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
```
gt (GenomeTools) 1.5.10
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: Apple LLVM version 10.0.0 (clang-1000.11.45.2)
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -m64 -Qunused-arguments -Wno-parentheses -Werror
```


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
yes

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Mac OS Mojave version 10.14",ohan-Bioinfo,https://github.com/genometools/genometools/issues/906,genometools++genometools.csv
MDU6SXNzdWUzODg0NDg5MDA=,Trans-spliced gene on different sequences,OPEN,2018-12-06T23:58:08Z,2018-12-07T19:17:38Z,,"## Problem description

Trans-spliced genes on the same sequence work as expected. Trans-spliced genes on different sequences give this error:

```
gt gff3: error: child on line 19 in file ""trans.gff"" has different sequence id than its parent on line 14 ('02' vs. '01')
```

A related but different error occurs when multi-features are on separate sequences.

```
gt gff3: error: the multi-feature with ID ""CDS1"" on line 10 in file ""trans.gff"" has a different sequence id than its counterpart on line 9
```

## Exact command line call triggering the problem

```
gt gff3 trans.gff
```

## Example minimal input triggering the problem

```gff
##gff-version 3
##sequence-region   01 1 1645232
##sequence-region   02 1 769924
01	.	gene	389963	390016	.	+	.	ID=gene1
01	.	mRNA	389963	390016	.	+	.	ID=mRNA1;Parent=gene1,gene2
01	.	gene	222566	222865	.	-	.	ID=gene2
01	.	mRNA	222566	222865	.	-	.	ID=mRNA2;Parent=gene1,gene2
###
01	.	gene	389963	390016	.	+	.	ID=gene3
01	.	mRNA	389963	390016	.	+	.	ID=mRNA3;Parent=gene3,gene4
02	.	gene	222566	222865	.	-	.	ID=gene4
02	.	mRNA	222566	222865	.	-	.	ID=mRNA4;Parent=gene3,gene4
##
01	.	CDS	389963	390016	.	+	.	ID=CDS1
02	.	CDS	222566	222865	.	-	.	ID=CDS1
```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

`gt (GenomeTools) 1.5.10`

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

I installed GenomeTools using brew. `brew install genometools`

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

macOS 10.11.6 on x86_64",sjackman,https://github.com/genometools/genometools/issues/907,genometools++genometools.csv
MDU6SXNzdWUzODkxMDAzNTg=,Assertion failed: (idx < gt_encseq_num_of_sequences(bs->encseq) && end >= start),OPEN,2018-12-10T01:53:30Z,2019-08-11T07:44:46Z,,"## Problem description
I am using genome threader to train a non-model plant species download from Phytozome for Bssm file. After I got the gff3 file with gth as described in the manual (threader manual, section 9, page 32), I used gthbssemtrain to train the file, but get the following error related to genome tools. Please help me out, thanks.

## Exact command line call triggering the problem

```
$ /Applications/gth-1.7.1-Linux_x86_64-64bit/bin/gthbssmtrain -seqfile Esalsugineum_173_v1.fa -outdir esa.bssm.train -force Esa.gth.gff3
gt-ag:  87.94% (n=166593)
gc-ag:   1.75% (n=3315)
Assertion failed: (idx < gt_encseq_num_of_sequences(bs->encseq) && end >= start), function gt_bioseq_get_sequence_range, file src/core/bioseq.c, line 388.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Aborted (core dumped)
$ /Applications/gth-1.7.1-Linux_x86_64-64bit/bin/gth -version
gth (GenomeThreader) 1.7.1
```

## Example minimal input triggering the problem
don't know

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
genometools-1.5.9

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
yes, make used

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Red Hat Linux,  x86_64",HengyouZhang,https://github.com/genometools/genometools/issues/908,genometools++genometools.csv
MDU6SXNzdWU0MTMxOTUwNjU=,Derived_from not checked,OPEN,2019-02-22T01:05:30Z,2019-02-27T16:55:56Z,,"TAIR10 GFF file (ftp://ftp.arabidopsis.org/home/tair/Genes/TAIR10_genome_release/TAIR10_gff3/TAIR10_GFF3_genes.gff) contains the attribute `Derived_from` which references ransposable element features not defined in the GFF file.

I think that `gt gff3` should throw an error (perhaps only when `-checkids` is specified) in such situations. In addition, perhaps `gt gff3validator` should throw an error?

```bash
curl ftp://ftp.arabidopsis.org/home/tair/Genes/TAIR10_genome_release/TAIR10_gff3/TAIR10_GFF3_genes.gff \
| sed '1i ##gff-version 3' \
| sed -r 's/Index/index/g' \
| gt gff3 -retainids \
| git_repos/gff3sort/gff3sort.pl /dev/stdin \
| bgzip \
> TAIR10_GFF3_genes.gff3.gz
gt gff3validator TAIR10_GFF3_genes.gff3.gz
```",nathanhaigh,https://github.com/genometools/genometools/issues/909,genometools++genometools.csv
MDU6SXNzdWU0MTM3NDE1NTY=,Document typecheck option in gff3validator,CLOSED,2019-02-23T21:18:20Z,2020-04-23T21:33:13Z,2020-04-23T21:33:13Z,"Context: https://github.com/The-Sequence-Ontology/SO-Ontologies/issues/465

The gff3 validator uses the sofa.obo file to check gff3. Is there documentation on what the expectations are in the file, both regarding the term names and the ontology graph.

I'm trying to document a kind of service level agreement on the SO side, and want to ensure that future changes to SO don't violate your expectations.

Also, is this the right repo for the canonical gff3 validator? Last I recall it was in perl, not C",cmungall,https://github.com/genometools/genometools/issues/910,genometools++genometools.csv
MDU6SXNzdWU0MTc3NTgyMzc=,gt ltrclusteringAssertion failed: (eb->plainseq),CLOSED,2019-03-06T11:33:30Z,2019-12-01T18:39:17Z,2019-12-01T18:39:17Z,"Dear Sir
When  I used the gt clustering(the command :gt ltrclustering -psmall 80 -plarge 30 genome.fa rename_hic.fa.pass.list.gff3) ,I encountered a question:
##
Assertion failed: (eb->plainseq), function gt_encseq_builder_build, file src/core/encseq.c, line 9098.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
zsh: abort (core dumped)  gt ltrclustering -psmall 80 -plarge 30 genome.fa rename_hic.fa.pass.list.gff3
##
I have got the LTR gff by ltr-retriever and the index is made by ""gt suffixerator -db rename_hic.fa -indexname genome.fa -tis -suf -lcp -des -ssp -sds -dna"".
Can you give me some tips about?
Thank for your work and time!
Chenyang
",SCQUchenyang,https://github.com/genometools/genometools/issues/912,genometools++genometools.csv
MDU6SXNzdWU0Mzk4NzczNzg=,tirvish feature addition,OPEN,2019-05-03T04:03:48Z,2019-05-20T02:56:56Z,,"For gt tirvish, would it be possible to add these 2 additional user-specified features?

`-numberTIRmismatches `
##### so not just perfect TIR matches, but even those with < 100% TIR identity are discovered and reported



`-numberTSDmismatches `
##### so not just perfect TSD matches, but even those with < 100% TSD identity are discovered and reported

Thanks!",anandksrao,https://github.com/genometools/genometools/issues/913,genometools++genometools.csv
MDU6SXNzdWU0NDgzMzU5Nzk=,New User of Genometools,CLOSED,2019-05-24T20:11:23Z,2019-08-19T17:58:41Z,2019-08-19T17:58:41Z,"## Problem description
I am seeking to utilize genometools LTR Harvest and LTR Digest for ERV annotation purposes. Installing and utilizing genometools requires knowledge outside my current skillset for I have zero experience in coding. Is there a guide available anywhere for beginners? I have downloaded Cygwin following instructions on the genometools.org website for it to be run on Windows. I am unsure of what to do next. I read in other places that some use ubuntu, is this the better way? ",APigg0070,https://github.com/genometools/genometools/issues/914,genometools++genometools.csv
MDU6SXNzdWU0NTk5NTYyNzY=,several compile issues on Fedora 30,CLOSED,2019-06-24T15:25:47Z,2019-06-26T09:07:13Z,2019-06-26T09:07:13Z,"## Problem description

Compilation errors as follows:

1)
rc/match/eis-bwtseq-context.c: In function \u2018gt_BWTSCRFGet\u2019:
src/match/eis-bwtseq-context.c:291:39: error: \u2018cxm\u2019 directive output may be truncated writing 3 bytes into a region of size between 2 and 6 [-Werror=format-truncation=]
  291 |       snprintf(buf, sizeof (buf), "".%ucxm"", (unsigned)mapIntervalLog2);
      |                                       ^~~
src/match/eis-bwtseq-context.c:291:7: note: \u2018snprintf\u2019 output between 6 and 10 bytes into a destination of size 8
  291 |       snprintf(buf, sizeof (buf), "".%ucxm"", (unsigned)mapIntervalLog2);
      |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
src/match/eis-bwtseq-context.c: In function \u2018gt_BWTSeqCRLoad\u2019:
src/match/eis-bwtseq-context.c:291:39: error: \u2018cxm\u2019 directive output may be truncated writing 3 bytes into a region of size between 2 and 6 [-Werror=format-truncation=]
  291 |       snprintf(buf, sizeof (buf), "".%ucxm"", (unsigned)mapIntervalLog2);
      |                                       ^~~
src/match/eis-bwtseq-context.c:291:7: note: \u2018snprintf\u2019 output between 6 and 10 bytes into a destination of size 8
  291 |       snprintf(buf, sizeof (buf), "".%ucxm"", (unsigned)mapIntervalLog2);
      |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
src/match/eis-bwtseq-context.c:291:39: error: \u2018cxm\u2019 directive output may be truncated writing 3 bytes into a region of size between 2 and 6 [-Werror=format-truncation=]
  291 |       snprintf(buf, sizeof (buf), "".%ucxm"", (unsigned)mapIntervalLog2);
      |                                       ^~~
src/match/eis-bwtseq-context.c:291:7: note: \u2018snprintf\u2019 output between 6 and 10 bytes into a destination of size 8
  291 |       snprintf(buf, sizeof (buf), "".%ucxm"", (unsigned)mapIntervalLog2);
      |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cc1: all warnings being treated as errors
make: *** [Makefile:811: obj/src/match/eis-bwtseq-context.o] Error 1


2)
src/ltr/ltr_cluster_prepare_seq_visitor.c: In function \u2018gt_ltr_cluster_prepare_seq_visitor_feature_node\u2019:
src/ltr/ltr_cluster_prepare_seq_visitor.c:146:39: error: \u2018%lu\u2019 directive output may be truncated writing between 1 and 20 bytes into a region of size between 0 and 8191 [-Werror=format-truncation=]
  146 |       (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer, range.start,
      |                                       ^~~~~
In file included from /usr/local/src/GENOMETOOLS/OLD/genometools-1.5.9/src/core/array_api.h:23,
                 from /usr/local/src/GENOMETOOLS/OLD/genometools-1.5.9/src/core/array.h:21,
                 from src/ltr/ltr_cluster_prepare_seq_visitor.c:19:
/usr/local/src/GENOMETOOLS/OLD/genometools-1.5.9/src/core/types_api.h:55:16: note: format string is defined here
   55 | #define GT_WU ""%lu""
      |                ^~~
src/ltr/ltr_cluster_prepare_seq_visitor.c:146:14: note: \u2018snprintf\u2019 output between 5 and 8234 bytes into a destination of size 8192
  146 |       (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer, range.start,
      |              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  147 |                       range.end);
      |                       ~~~~~~~~~~
src/ltr/ltr_cluster_prepare_seq_visitor.c:109:39: error: \u2018%lu\u2019 directive output may be truncated writing between 1 and 20 bytes into a region of size between 0 and 8191 [-Werror=format-truncation=]
  109 |       (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer, range.start,
      |                                       ^~~~~
In file included from /usr/local/src/GENOMETOOLS/OLD/genometools-1.5.9/src/core/array_api.h:23,
                 from /usr/local/src/GENOMETOOLS/OLD/genometools-1.5.9/src/core/array.h:21,
                 from src/ltr/ltr_cluster_prepare_seq_visitor.c:19:
/usr/local/src/GENOMETOOLS/OLD/genometools-1.5.9/src/core/types_api.h:55:16: note: format string is defined here
   55 | #define GT_WU ""%lu""
      |                ^~~
src/ltr/ltr_cluster_prepare_seq_visitor.c:109:14: note: \u2018snprintf\u2019 output between 5 and 8234 bytes into a destination of size 8192
  109 |       (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer, range.start,
      |              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  110 |                       range.end);
      |                       ~~~~~~~~~~
cc1: all warnings being treated as errors
make: *** [Makefile:811: obj/src/ltr/ltr_cluster_prepare_seq_visitor.o] Error 1


3)
src/ltr/ltr_cluster_stream.c: In function \u2018process_feature\u2019:
src/ltr/ltr_cluster_stream.c:352:41: error: \u2018%lu\u2019 directive output may be truncated writing between 1 and 20 bytes into a region of size between 0 and 8191 [-Werror=format-truncation=]
  352 |         (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer,
      |                                         ^~~~~
In file included from /usr/local/src/GENOMETOOLS/OLD/genometools-1.5.9/src/core/array_api.h:23,
                 from /usr/local/src/GENOMETOOLS/OLD/genometools-1.5.9/src/core/array.h:21,
                 from src/ltr/ltr_cluster_stream.c:19:
/usr/local/src/GENOMETOOLS/OLD/genometools-1.5.9/src/core/types_api.h:55:16: note: format string is defined here
   55 | #define GT_WU ""%lu""
      |                ^~~
src/ltr/ltr_cluster_stream.c:352:16: note: \u2018snprintf\u2019 output between 5 and 8234 bytes into a destination of size 8192
  352 |         (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer,
      |                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  353 |                         range.start, range.end);
      |                         ~~~~~~~~~~~~~~~~~~~~~~~
src/ltr/ltr_cluster_stream.c:344:41: error: \u2018%lu\u2019 directive output may be truncated writing between 1 and 20 bytes into a region of size between 0 and 8191 [-Werror=format-truncation=]
  344 |         (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer,
      |                                         ^~~~~
In file included from /usr/local/src/GENOMETOOLS/OLD/genometools-1.5.9/src/core/array_api.h:23,
                 from /usr/local/src/GENOMETOOLS/OLD/genometools-1.5.9/src/core/array.h:21,
                 from src/ltr/ltr_cluster_stream.c:19:
/usr/local/src/GENOMETOOLS/OLD/genometools-1.5.9/src/core/types_api.h:55:16: note: format string is defined here
   55 | #define GT_WU ""%lu""
      |                ^~~
src/ltr/ltr_cluster_stream.c:344:16: note: \u2018snprintf\u2019 output between 5 and 8234 bytes into a destination of size 8192
  344 |         (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer,
      |                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  345 |                         range.start, range.end);
      |                         ~~~~~~~~~~~~~~~~~~~~~~~
cc1: all warnings being treated as errors
make: *** [Makefile:811: obj/src/ltr/ltr_cluster_stream.o] Error 1


NOTE: all issues are easily fixed by increasing the buffers, but I have not looked into what the correct minimum size should be.
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make using the following compiler
   gcc (GCC) 9.1.1 20190503 (Red Hat 9.1.1-1)


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Fedora 30, x86_64
",vpbrendel,https://github.com/genometools/genometools/issues/915,genometools++genometools.csv
MDU6SXNzdWU0NjA1MTc5NTQ=,Compile errors on Arch,CLOSED,2019-06-25T16:15:37Z,2019-06-26T09:07:55Z,2019-06-26T09:07:54Z,"## Problem description
Doesn't compile.

```
[compile ltr_cluster_prepare_seq_visitor.o]
src/ltr/ltr_cluster_prepare_seq_visitor.c: In function gt_ltr_cluster_prepare_seq_visitor_feature_node:
src/ltr/ltr_cluster_prepare_seq_visitor.c:146:39: error: %lu directive output may be truncated writing between 1 and 20 bytes into a region of size between 0 and 8191 [-Werror=format-truncation=]
  146 |       (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer, range.start,
      |                                       ^~~~~
In file included from /home/zeth/genometools/src/core/array_api.h:23,
                 from /home/zeth/genometools/src/core/array.h:21,
                 from src/ltr/ltr_cluster_prepare_seq_visitor.c:19:
/home/zeth/genometools/src/core/types_api.h:55:16: note: format string is defined here
   55 | #define GT_WU ""%lu""
      |                ^~~
src/ltr/ltr_cluster_prepare_seq_visitor.c:146:14: note: snprintf output between 5 and 8234 bytes into a destination of size 8192
  146 |       (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer, range.start,
      |              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  147 |                       range.end);
      |                       ~~~~~~~~~~
src/ltr/ltr_cluster_prepare_seq_visitor.c:109:39: error: %lu directive output may be truncated writing between 1 and 20 bytes into a region of size between 0 and 8191 [-Werror=format-truncation=]
  109 |       (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer, range.start,
      |                                       ^~~~~
In file included from /home/zeth/genometools/src/core/array_api.h:23,
                 from /home/zeth/genometools/src/core/array.h:21,
                 from src/ltr/ltr_cluster_prepare_seq_visitor.c:19:
/home/zeth/genometools/src/core/types_api.h:55:16: note: format string is defined here
   55 | #define GT_WU ""%lu""
      |                ^~~
src/ltr/ltr_cluster_prepare_seq_visitor.c:109:14: note: snprintf output between 5 and 8234 bytes into a destination of size 8192
  109 |       (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer, range.start,
      |              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  110 |                       range.end);
      |                       ~~~~~~~~~~
[compile ltr_cluster_stream.o]
cc1: all warnings being treated as errors
make: *** [Makefile:825: obj/src/ltr/ltr_cluster_prepare_seq_visitor.o] Error 1
make: *** Waiting for unfinished jobs....
src/ltr/ltr_cluster_stream.c: In function process_feature:
src/ltr/ltr_cluster_stream.c:352:41: error: %lu directive output may be truncated writing between 1 and 20 bytes into a region of size between 0 and 8191 [-Werror=format-truncation=]
  352 |         (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer,
      |                                         ^~~~~
In file included from /home/zeth/genometools/src/core/array_api.h:23,
                 from /home/zeth/genometools/src/core/array.h:21,
                 from src/ltr/ltr_cluster_stream.c:19:
/home/zeth/genometools/src/core/types_api.h:55:16: note: format string is defined here
   55 | #define GT_WU ""%lu""
      |                ^~~
src/ltr/ltr_cluster_stream.c:352:16: note: snprintf output between 5 and 8234 bytes into a destination of size 8192
  352 |         (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer,
      |                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  353 |                         range.start, range.end);
      |                         ~~~~~~~~~~~~~~~~~~~~~~~
src/ltr/ltr_cluster_stream.c:344:41: error: %lu directive output may be truncated writing between 1 and 20 bytes into a region of size between 0 and 8191 [-Werror=format-truncation=]
  344 |         (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer,
      |                                         ^~~~~
In file included from /home/zeth/genometools/src/core/array_api.h:23,
                 from /home/zeth/genometools/src/core/array.h:21,
                 from src/ltr/ltr_cluster_stream.c:19:
/home/zeth/genometools/src/core/types_api.h:55:16: note: format string is defined here
   55 | #define GT_WU ""%lu""
      |                ^~~
src/ltr/ltr_cluster_stream.c:344:16: note: snprintf output between 5 and 8234 bytes into a destination of size 8192
  344 |         (void) snprintf(header, BUFSIZ, ""%s_""GT_WU""_""GT_WU"""", buffer,
      |                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  345 |                         range.start, range.end);
      |                         ~~~~~~~~~~~~~~~~~~~~~~~
cc1: all warnings being treated as errors
make: *** [Makefile:822: obj/src/ltr/ltr_cluster_stream.o] Error 1

```

## Exact command line call triggering the problem

```
make -j4
```

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Arch Linux most recent",Zethson,https://github.com/genometools/genometools/issues/916,genometools++genometools.csv
MDU6SXNzdWU0NzE3NDUxMjk=,LTR_harvest: 'cannot flock: Function not implemented',CLOSED,2019-07-23T14:52:22Z,2019-07-24T14:30:03Z,2019-07-24T14:30:03Z,"Hi,
Recently, when I was running LTR_harvest, an issue comes up and I have no idea what it means and how to solve this problem.

The genometools was installed by conda 
`conda install -c bioconda genometools-genometools`

The index was generated by following the manual:
`gt suffixerator -db etuer.test.fasta -indexname etuer -tis -suf -lcp -des -ssp -sds -dna`

Then I tried to run LTR_harvest by using the command:
`gt ltrharvest -index etuer -minlenltr 100 -maxlenltr 7000 -mintsd 4 -maxtsd 6 -motif TGCA -motifmis 1 -similar 85 -vic 10 -seed 20 -seqids yes`

However, the software gave a message and ended:
`cannot flock: Function not implemented`

What does this mean? Is there something wrong with the installation or the software setup?
Thanks in advance!
",WTarabidopsis,https://github.com/genometools/genometools/issues/918,genometools++genometools.csv
MDU6SXNzdWU0ODA3MTczNzc=,bed_to_gff3 error ,OPEN,2019-08-14T14:37:40Z,2021-12-29T20:34:57Z,,"## Problem description
Hey there! I'm trying to convert ChIP peaks (in a bed file format) to gff3. Below is the command and the resulting error:

```
$ time gt bed_to_gff3 -force yes -o 0hr-CTCF_ChAsE-Ref_peak.gff3 bed-peaks/0hr-CTCF-ChIP-peaks.bed.txt
gt bed_to_gff3: error: strand '0.82' not one character long on line 1 in file 'bed-peaks/0hr-CTCF-ChIP-peaks.bed.txt'
```
I reformated the bed file to see if that was the issue and got the following error:
```
$ time gt bed_to_gff3 -force yes -o 0hr-CTCF_ChAsE-Ref_peak.gff3 bed-peaks/0hr-CTCF-ChIP-peaks_v2.bed.txt
gt bed_to_gff3: error: file ""bed-peaks/0hr-CTCF-ChIP-peaks_v2.bed.txt"": line 147357: expected character '
', got ''
Command exited with non-zero status 1
```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
$ gt -version
gt (GenomeTools) 1.5.10

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
Yes. I didn't add any make parameters

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubunutu 18.04.3
",aperreault,https://github.com/genometools/genometools/issues/919,genometools++genometools.csv
MDU6SXNzdWU0ODM3MzQ2NDE=,"Assertion failed: (fn), function gt_feature_node_iterator_new, file src/extended/feature_node_iterator.c, line 46.",OPEN,2019-08-22T02:23:01Z,2021-06-27T08:27:59Z,,"## Problem description
When I try running LTR-digest I get this error.

## Exact command line call triggering the problem

```
$gt -j $NCPUS ltrdigest -pptlen 10 30 -trnas $prefix/GtRNAdb-all-tRNAs.fas -hmms /home/m.matsumoto/PfamA/Pfam-A.hmm -outfileprefix cgor_copia_LTR $prefix/copia_LTR.sorted.gff3 $prefix/copia_LTR_index > $prefix/copia_LTR_after_ltrdigest.gff3

```

## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt 1.5.10
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

make with-hmmer=yes
make install prefix=/home/user/gt

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
",MaikaM,https://github.com/genometools/genometools/issues/920,genometools++genometools.csv
MDU6SXNzdWU1MDIzMTEyMDg=,Multithreaded suffixerator fails to build a working set of files,CLOSED,2019-10-03T21:36:02Z,2019-10-09T14:29:57Z,2019-10-09T14:29:57Z,"## Problem description
Using the multithreaded version of suffixerator does not generate a working set of data files.

## Exact command line call triggering the problem

```
make cleanup
make threads=yes cairo=no


gt -j 10 suffixerator -db seq2.fa -indexname seq2 -tis -suf -lcp -des -ssp -sds -dna
         22 Oct  3 14:23 seq2.des
    2000320 Oct  3 14:23 seq2.esq
    8099926 Oct  3 14:13 seq2.fa
    7999921 Oct  3 14:23 seq2.lcp
          0 Oct  3 14:23 seq2.llv  <---- difference
         33 Oct  3 14:23 seq2.md5
        467 Oct  3 14:23 seq2.prj
          0 Oct  3 14:23 seq2.sds
 63999368 Oct  3 14:23 seq2.suf

gt ltrharvest -index seq2
**no results**


gt 10 suffixerator -db seq2.fa -indexname seq2 -tis -suf -lcp -des -ssp -sds -dna
        22 Oct  3 14:26 seq2.des
   2000320 Oct  3 14:26 seq2.esq 
   8099926 Oct  3 14:13 seq2.fa
   7999921 Oct  3 14:26 seq2.lcp
   2475488 Oct  3 14:26 seq2.llv
        33 Oct  3 14:26 seq2.md5
       476 Oct  3 14:26 seq2.prj
         0 Oct  3 14:26 seq2.sds
63999368 Oct  3 14:26 seq2.suf

gt ltrharvest -index seq2
** 136 results **
```

## Example minimal input triggering the problem
[seq2.fa.gz](https://github.com/genometools/genometools/files/3688167/seq2.fa.gz)

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt (GenomeTools) 1.5.10
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36.0.1)
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror

But also 1.5.9 exhibits the same behavior

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make cleanup
make threads=yes cairo=no

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

RedHat 7.6 ( 4.1.12-124.24.3.el7uek.x86_64 )



",rmhubley,https://github.com/genometools/genometools/issues/922,genometools++genometools.csv
MDU6SXNzdWU1MDI3Mjk5MTg=,ltrharvest will hang when run on files stored in NFS,OPEN,2019-10-04T16:25:44Z,2019-10-04T19:59:31Z,,"## Problem description
gt ltrharvest can hang in a rpc_wait_bit_killable state indefinitely under certain circumstances without any obvious timeout-to-failure.  

## Exact command line call triggering the problem

```
% cd /my-nfsv3-mounted-filesystem
% genometools-1.5.10/gt suffixerator -db seq2.fa -indexname seq2 -tis -suf -lcp -des -ssp -sds -dna
% genometools-1.5.10/bin/gt ltrharvest -index seq2

*** Notice that it's taking way too long ***

% ps -elf | grep ltrharvest
0 D rhubley    4912 414105  0  80   0 -  5094 rpc_wa 08:48 pts/31   00:00:00 gt ltrharvest -index seq2

% cat /proc/4912/wchan
rpc_wait_bit_killable

% cat /proc/4912/wchan | grep ""State:""
State:	D (disk sleep)

% cat /proc/4912/syscall 
72 0x3 0x7 0x7fff83708d80 0x7fff83708160 0x0 0x0 0x7fff83708d00 0x7fd455bbb874

% grep 72 /usr/include/asm/unistd_64.h 
#define __NR_fcntl 72

% cat /proc/4912/stack
[<ffffffffa05b7bd4>] rpc_wait_bit_killable+0x24/0xb0 [sunrpc]
[<ffffffffa05b881a>] __rpc_execute+0x18a/0x4a0 [sunrpc]
[<ffffffffa05bc97b>] rpc_execute+0x6b/0xd0 [sunrpc]
[<ffffffffa05af4f0>] rpc_run_task+0x70/0x90 [sunrpc]
[<ffffffffa05af560>] rpc_call_sync+0x50/0xc0 [sunrpc]
[<ffffffffa052adf5>] nlmclnt_call+0xb5/0x330 [lockd]
[<ffffffffa052b5cf>] nlmclnt_proc+0x21f/0x830 [lockd]
[<ffffffffa05492c1>] nfs3_proc_lock+0x21/0x30 [nfsv3]
[<ffffffffa064fb00>] do_setlk+0x100/0x120 [nfs]
[<ffffffffa064fbd1>] nfs_lock+0xb1/0x1b0 [nfs]
[<ffffffff812734c1>] vfs_lock_file+0x21/0x40
[<ffffffff812737aa>] do_lock_file_wait.part.25+0x4a/0xf0
[<ffffffff81274def>] fcntl_setlk+0x14f/0x2f0
[<ffffffff812310c0>] SyS_fcntl+0x340/0x670
[<ffffffff8175579e>] system_call_fastpath+0x18/0xd8
[<ffffffffffffffff>] 0xffffffffffffffff

```
If file locking isn't available the process shouldn't hang.  It should die early ( should locking be absolutely necessary ) or timeout after a reasonable amount of time.  This holds up pipelines when a user inadvertently runs on an unsupported filesystem.

## Example minimal input triggering the problem
Any input

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
genometools-1.5.10/bin/gt -version
/home/rhubley/src/genometools-1.5.10/bin/gt (GenomeTools) 1.5.10
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36.0.1)
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make threads=yes cairo=no

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
RedHat 7.6  - 4.1.12-124.24.3.el7uek.x86_64
NFS V3 with advisory locking through NLM

NOTE: Although I haven't tested it...I suspect NFS V4 fixes this problem.",rmhubley,https://github.com/genometools/genometools/issues/923,genometools++genometools.csv
MDU6SXNzdWU1MjIxOTY0Nzc=,gt ltrclustering error,CLOSED,2019-11-13T12:42:41Z,2019-12-01T18:39:11Z,2019-12-01T18:39:11Z,"## Problem description
I tried to cluster my ltrdigest output, and encountered a bug. I am hoping you would be willing to help me out.
EDIT: now with actual error code:
Assertion failed: (eb->plainseq), function gt_encseq_builder_build, file src/core/encseq.c, line 9060.

## Exact command line call triggering the problem
gt ltrclustering -psmall 80 -plarge 30 bSylAtr1.pri.cur.20190916.fasta Sylvatri_ltrdigest_output.gff2.txt


## Example minimal input triggering the problem
## file 1 - link to genome assembly:
https://s3.amazonaws.com/genomeark/species/Sylvia_atricapilla/bSylAtr1/assembly_curated/bSylAtr1.pri.cur.20190916.fasta.gz
## file2: attached output of ltrharvest and ltrdigest pipeline



## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt (GenomeTools) 1.5.9

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
-

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
-bash-4.2$ uname -r
3.10.0-514.2.2.el7.x86_64
-bash-4.2$ lsb_release -a
LSB Version:    :core-4.1-amd64:core-4.1-noarch
Distributor ID: CentOS
Description:    CentOS Linux release 7.3.1611 (Core)
Release:        7.3.1611
[Sylvatri_ltrdigest_output.gff2.txt](https://github.com/genometools/genometools/files/3841124/Sylvatri_ltrdigest_output.gff2.txt)

Codename:       Core",peterpru,https://github.com/genometools/genometools/issues/925,genometools++genometools.csv
MDU6SXNzdWU1MzE5MjE4MzE=,Inconsistent strand error,CLOSED,2019-12-03T11:35:43Z,2020-04-04T20:22:15Z,2020-04-04T20:22:15Z,"## Problem description
I am getting the error below when i run ltr digest
gt ltrdigest: error: inconsistent strands encountered in `LTR_retrotransposon' feature in file sorted_genome.final.fa.pass.list.gff3, line 23753: found +, expected -

## Exact command line call triggering the problem

```
gt suffixerator -dna -db genome.final.fa -tis -suf -lcp -des -ssp -sds -lossless
gt gff3 -sort genome.final.fa.pass.list.gff3 > sorted_genome.final.fa.pass.list.gff3
gt -j 10 ltrdigest -hmms Pfam-A.hmm -aaout yes -outfileprefix genome.final.fa.pass.list -seqfile genome.final.fa -matchdescstart sorted_genome.final.fa.pass.list.gff3 >
 genome.final.fa.pass.list.digest.gff3
```

## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
genometools/1.5.10

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using? Ubuntu
",OluchiAroh,https://github.com/genometools/genometools/issues/927,genometools++genometools.csv
MDU6SXNzdWU1NDEyMzc4MTE=,gt gff3 -sort incorrectly reports Parent not defined,CLOSED,2019-12-20T23:06:12Z,2020-01-06T18:54:50Z,2020-01-06T18:54:50Z,"## Problem description
The command below reports the following, which can be demonstrated false by examining the test.gff file posted below:
```
gt gff3: error: Parent ""LTR_retrotransposon1"" on line 14 in file ""test.gff"" was not defined (via ""ID="")
```

## Exact command line call triggering the problem

```
gt gff3 -sort test.gff
```

## Example minimal input triggering the problem
test.gff:
```
##gff-version 3
##sequence-region   lcl|NC_hic_scaffold_01 17352 47215727
lcl|NC_hic_scaffold_01	LTRharvest	repeat_region	17352	22870	.	+	.	ID=repeat_region1
lcl|NC_hic_scaffold_01	LTRharvest	target_site_duplication	17352	17356	.	+	.	Parent=repeat_region1
lcl|NC_hic_scaffold_01	LTRharvest	LTR_retrotransposon	17357	22865	.	+	.	ID=LTR_retrotransposon1;Parent=repeat_region1;ltr_similarity=96.02;seq_number=0;dfamClassification=Copia1-I_DM;repbaseClassification=Copia-45_RC-I
lcl|NC_hic_scaffold_01	LTRharvest	long_terminal_repeat	17357	17833	.	+	.	Parent=LTR_retrotransposon1
lcl|NC_hic_scaffold_01	LTRdigest	protein_match	19935	20142	8.7e-06	+	.	Parent=LTR_retrotransposon1;reading_frame=1;name=Retrotran_gag_2
lcl|NC_hic_scaffold_01	LTRdigest	protein_match	20135	20345	5.1e-13	+	.	Parent=LTR_retrotransposon1;reading_frame=0;name=Retrotran_gag_2
lcl|NC_hic_scaffold_01	LTRdigest	protein_match	21026	21074	7.7e-06	+	.	Parent=LTR_retrotransposon1;reading_frame=0;name=gag_pre-integrs
lcl|NC_hic_scaffold_01	LTRdigest	protein_match	21215	21338	2e-05	+	.	Parent=LTR_retrotransposon1;reading_frame=0;name=RVT_2
lcl|NC_hic_scaffold_01	LTRharvest	long_terminal_repeat	22391	22865	.	+	.	Parent=LTR_retrotransposon1
lcl|NC_hic_scaffold_01	LTRharvest	target_site_duplication	22866	22870	.	+	.	Parent=repeat_region1
###
lcl|NC_hic_scaffold_01	getorf	ORF	17966	18386	.	+	.	ID=LTR_retrotransposon1.ORF.01;Parent=LTR_retrotransposon1
```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
1.5.10

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
yes, `make prefix=.`

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Scientific Linux release 6.8 (Carbon) x86_64",mcsimenc,https://github.com/genometools/genometools/issues/928,genometools++genometools.csv
MDU6SXNzdWU1NDY1MDY1OTU=,What does chain2dim do? ,CLOSED,2020-01-07T21:04:34Z,2020-01-08T22:42:09Z,2020-01-08T22:42:09Z,"The documentation for vmatch refers to a manual for chain2dim. However, although http://genometools.org/tools/gt_chain2dim.html describes the options for chain2dim, it does not describe what match chaining is in the first place. ",alexlenail,https://github.com/genometools/genometools/issues/932,genometools++genometools.csv
MDU6SXNzdWU1NTAzMjU3NDc=,"gt gff3 -addintrons: ssertion failed: (elemidx >= q->front), function gt_queue_remove, file src/core/queue.c, line 165.",OPEN,2020-01-15T17:24:36Z,2020-01-15T22:11:41Z,,"## Problem description


## Exact command line call triggering the problem

```
$ gt gff3 -addintrons -o dmel-all-r6.31.updated.gff dmel-all-r6.31.gff
first: -1       999
second: 3409    999
first: -1       999
second: 3409    999
first: -1       999
second: 998     999
Assertion failed: (elemidx >= q->front), function gt_queue_remove, file src/core/queue.c, line 165.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Aborted (core dumped)

```

``` diff
$ git diff
diff --git a/src/core/queue.c b/src/core/queue.c
index daf7709f8..6af4eecee 100644
--- a/src/core/queue.c
+++ b/src/core/queue.c
@@ -154,11 +154,14 @@ void gt_queue_remove(GtQueue *q, void *elem)
       if (q->back == 0) q->back = q->size;
       return;
     }
+    printf(""first: %ld\t%ld\n"", elemidx, q->front);
     for (i = q->size-1; i >= q->front; i--) {
+    //printf(""for: %ld\t%ld\n"", i, q->front);
       if (q->contents[i] == elem)
         break;
     }
     elemidx = i;
+    printf(""second: %ld\t%ld\n"", elemidx, q->front);
     gt_assert(elemidx >= q->front); /* valid element found */
     for (i = elemidx+1; i < q->size; i++)
       q->contents[i-1] = q->contents[i];
```

## Example minimal input triggering the problem

`dmel-all-r6.31.gff` = ftp://ftp.flybase.net/releases/FB2019_06/dmel_r6.31/gff/dmel-all-r6.31.gff.gz

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

(latest git version)
```
$ gt --version
gt (GenomeTools) 1.6.1
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror
```

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

`make install`

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

CentOS 7 x86_64",dweemx,https://github.com/genometools/genometools/issues/935,genometools++genometools.csv
MDU6SXNzdWU1NTUyNDMxNjc=,gt gff3 intron request,OPEN,2020-01-26T15:19:54Z,2021-05-25T20:55:22Z,,"Hello,

It would be helpful if when adding introns to a gff3 it would also add ID's instead of just Parent's. Similar to how exons and cds's have ID's associated with their parent.

I am using the `-retainids -addintrons` flags.

Currently, the results look like:

```
###
1	funannotate	gene	12845	16741	.	+	.	ID=CPUR_00006
1	funannotate	mRNA	12845	16741	.	+	.	ID=CPUR_00006-T1;Parent=CPUR_00006;product=hypothetical protein
1	funannotate	exon	12845	13792	.	+	.	ID=CPUR_00006-T1.exon1;Parent=CPUR_00006-T1
1	funannotate	CDS	12845	13792	.	+	0	ID=CPUR_00006-T1.cds;Parent=CPUR_00006-T1
1	funannotate	intron	13793	13890	.	+	.	Parent=CPUR_00006-T1
1	funannotate	exon	13891	14691	.	+	.	ID=CPUR_00006-T1.exon2;Parent=CPUR_00006-T1
1	funannotate	CDS	13891	14691	.	+	0	ID=CPUR_00006-T1.cds;Parent=CPUR_00006-T1
1	funannotate	intron	14692	15817	.	+	.	Parent=CPUR_00006-T1
1	funannotate	exon	15818	16741	.	+	.	ID=CPUR_00006-T1.exon3;Parent=CPUR_00006-T1
1	funannotate	CDS	15818	16741	.	+	0	ID=CPUR_00006-T1.cds;Parent=CPUR_00006-T1
```

It would be very helpful if the introns could be returned as such.
```

1	funannotate	intron	13793	13890	.	+	.	ID=CPUR_00006-T1.in1;Parent=CPUR_00006-T1
1	funannotate	intron	14692	15817	.	+	.	ID=CPUR_00006-T1.in2;Parent=CPUR_00006-T1
```",PlantDr430,https://github.com/genometools/genometools/issues/936,genometools++genometools.csv
MDU6SXNzdWU1ODMxMDk5MzE=,gt splitfasta Assertion failed,OPEN,2020-03-17T15:45:32Z,2020-04-23T21:21:23Z,,"## Problem description
Assertion failed: (filename && max_filesize), function split_fasta_file, file src/tools/gt_splitfastne 155.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at http://genometools.org/pub/
Aborted (core dumped)


## Exact command line call triggering the problem

```
gt splitfasta -numfiles 4 nt_curated_primate_subtracted.FASTA
```

## Example minimal input triggering the problem
The nt.fa database from NCBI

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
1.5.9

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make curses=no cairo=no
make curses=no cairo=no install


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
ubuntu-16-04 image for singularity",vimlu,https://github.com/genometools/genometools/issues/938,genometools++genometools.csv
MDU6SXNzdWU1ODgzNDE1NTk=,Assertion failed: (genomicdnaptr < aftergenomicdnaline) #bug,OPEN,2020-03-26T11:15:05Z,2020-04-23T21:30:47Z,,"## Problem description
Running genomethreader with genome and protein I had the following error :
```
Assertion failed: (genomicdnaptr < aftergenomicdnaline), function construct_genomic_dna_line, file src/gth/gthalignment.c, line 396.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`...
```

## Exact command line call triggering the problem
```
gth -genomic 55e20_minion.fasta -protein 55e20_Vs_GCF_002114115.1_blastx_sbjct.fasta -species arabidopsis -v -paralogs -mincutoffs -o 55e20_Vs_GCF_002114115.1_gth_mincutoffs
```
## Example minimal input triggering the problem
55e20_minion.fasta 
```
>tig00000057 len=188192 reads=462 covStat=29103.25 gappedBases=no class=contig suggestRepeat=no suggestCircular=yes
CACTAATTCTAATTTTGCAAGTTGACCTCAAGTGAGAAACAATTAATCACAATGTCCCTG
CCCTCCATCTAAGATAATAAAGCATTATATGAATAACAGTAAATAATCTACCGAGAACAT
GTAGTATCATCTAACAGTAATGAGTTCTCTATTCTGACATCTACCAAGTCTAGACTAGAG
GCGAACTTTGACATCTAAGCGCAGCACAAAAACCACTTGAGAGTAGCATTTGAAAAAATG
```
55e20_Vs_GCF_002114115.1_blastx_sbjct.fasta
```
>NP_001315727.1 disease resistance protein TAO1-like [Malus domestica]
MDNWSSLGKLLIMVLVLLSYHYAHRNSGLVFDVLIFLLCSLGLVFRQMNISVPDKTSSSS
SSSPSSSSSSSASSSSSSTSSTSSPSISSSSSTSASPSLSSFSKGLLYEVFISFRGEDTR
```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
```
gth (GenomeThreader) 1.7.3
libgenometools-1.6.1:
Copyright (c) 2003-2018 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2018 Center for Bioinformatics, University of Hamburg
libgenomethreader:
Copyright (c) 2009-2018 Wikena GmbH
libvmatch:
Copyright (c) 2000-2017 LScSA-Software GmbH
Email: gordon@gremme.org
Used compiler: gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -fno-stack-protector -Wno-unknown-pragmas -Wno-error=misleading-indentation -Werror -O3
```
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
No. Executables were downloaded from : http://genomethreader.org/

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Linux version 5.5.10-200.fc31.x86_64 (mockbuild@bkernel03.phx2.fedoraproject.org) (gcc version 9.2.1 20190827 (Red Hat 9.2.1-1) (GCC)) #1 SMP Wed Mar 18 14:21:38 UTC 2020
Fedora release 31 (Thirty One)
",cestaroa,https://github.com/genometools/genometools/issues/939,genometools++genometools.csv
MDU6SXNzdWU1OTI4NTg4NDQ=,Segmentation fault in LTRharvest,CLOSED,2020-04-02T19:01:33Z,2022-11-07T07:09:22Z,2022-11-07T07:09:22Z,"## Problem description

I am running LTR harvest on a 2.7 Gb genome. It gives a segmentation fault and fails repeatedly on multiple machines. RAM is not the issue as I have tried reserving up to 300 GB for this job. Even though the result is only a segmentation fault, it takes 72 hours to run. This is the exact error:
 line 1: 61950 Segmentation fault (core dumped)

The output file as well as the log file are completely empty. There is no information in the core dump file either. 
Note: I have used LTRharvest extensively with this version of GenomeTools and this is the first genome where I've had a problem.

## Exact command line call triggering the problem

gt suffixerator -db inputfile.fa -indexname esa_index -tis -suf -lcp -des -ssp -sds -dna

gt ltrharvest -index esa_index -out ltrharvest.out >ltrharvest.log 2>&1
```
gt ...
```

## Example minimal input triggering the problem
fasta file of the genome

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
genometools-1.5.9

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Linux CentOS 7.6.1810
",jmf422,https://github.com/genometools/genometools/issues/940,genometools++genometools.csv
MDU6SXNzdWU2MDI4MDUxOTk=,Build failure with GCC 10: multiple definition of `gt_cstr_nofree_ulp_hashtype',CLOSED,2020-04-19T19:53:11Z,2020-04-22T23:01:05Z,2020-04-22T23:01:05Z,"Hi, I'm getting this build error with GCC 10:

```
/usr/bin/ld: obj/src/mgth/mg_combinedscore.o:./src/mgth/metagenomethreader.h:224: multiple definition of `gt_cstr_nofree_ulp_hashtype'; obj/src/mgth/metagenomethreader.o:./src/mgth/metagenomethreader.h:224: first defined here
/usr/bin/ld: obj/src/mgth/mg_compute_gene_prediction.o:./src/mgth/metagenomethreader.h:224: multiple definition of `gt_cstr_nofree_ulp_hashtype'; obj/src/mgth/metagenomethreader.o:./src/mgth/metagenomethreader.h:224: first defined here
/usr/bin/ld: obj/src/mgth/mg_computepath.o:./src/mgth/metagenomethreader.h:224: multiple definition of `gt_cstr_nofree_ulp_hashtype'; obj/src/mgth/metagenomethreader.o:./src/mgth/metagenomethreader.h:224: first defined here
/usr/bin/ld: obj/src/mgth/mg_outputwriter.o:./src/mgth/metagenomethreader.h:224: multiple definition of `gt_cstr_nofree_ulp_hashtype'; obj/src/mgth/metagenomethreader.o:./src/mgth/metagenomethreader.h:224: first defined here
/usr/bin/ld: obj/src/mgth/mg_reverse.o:./src/mgth/metagenomethreader.h:224: multiple definition of `gt_cstr_nofree_ulp_hashtype'; obj/src/mgth/metagenomethreader.o:./src/mgth/metagenomethreader.h:224: first defined here
/usr/bin/ld: obj/src/mgth/mg_xmlparser.o:./src/mgth/metagenomethreader.h:224: multiple definition of `gt_cstr_nofree_ulp_hashtype'; obj/src/mgth/metagenomethreader.o:./src/mgth/metagenomethreader.h:224: first defined here
```

Is the declaration of `gt_cstr_nofree` in `src/mgth/metagenomethreader.h` maybe missing an `extern` ?
",bertogg,https://github.com/genometools/genometools/issues/941,genometools++genometools.csv
MDU6SXNzdWU2MDMwNzQ1NDE=,Compile error on ubuntu-19.04,OPEN,2020-04-20T09:12:08Z,2020-04-23T21:34:14Z,,"## Problem description
Doesn't compile.

src/extended/gff3_escaping.c: In function gt_gff3_escaping_unit_test:
src/extended/gff3_escaping.c:196:35: error: __builtin___snprintf_chk output may be truncated before the last format character [-Werror=format-truncation=]
     snprintf(code, 10, ""foo%%%Xbar"", i);
                                   ^
In file included from /usr/include/stdio.h:867,
                 from /home/hanmj/Bioinfo/TEs_identification/genometools-1.5.9/src/core/assert_api.h:21,
                 from /home/genometools-1.5.9/src/core/error_api.h:23,
                 from /home/genometools-1.5.9/src/core/error.h:21,
                 from /home/genometools-1.5.9/src/core/ensure.h:23,
                 from src/extended/gff3_escaping.c:21:
/usr/include/x86_64-linux-gnu/bits/stdio2.h:67:10: note: __builtin___snprintf_chk output between 10 and 11 bytes into a destination of size 10
   return __builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,
          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
        __bos (__s), __fmt, __va_arg_pack ());
        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
cc1: all warnings being treated as errors
make: *** [Makefile:811: obj/src/extended/gff3_escaping.o] Error 1

## Exact command line call triggering the problem
make
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
genometools-1.5.9

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
yes

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu-19.04
gcc (Ubuntu 8.3.0-6ubuntu1) 8.3.0
GNU Make 4.2.1
Built for x86_64-pc-linux-gnu",minjinhan,https://github.com/genometools/genometools/issues/942,genometools++genometools.csv
MDU6SXNzdWU2MDUwMDU4Nzg=,Update the download links on genometools.org,CLOSED,2020-04-22T19:28:06Z,2020-04-23T04:19:24Z,2020-04-23T00:23:38Z,"## Problem description
The genometools.org page still lists old versions (pre-1.6.0) for both source and binary downloads:

http://genometools.org/pub

We should make sure to upload the latest versions there.",satta,https://github.com/genometools/genometools/issues/943,genometools++genometools.csv
MDU6SXNzdWU2MDU0MTk2MTE=,1.6.1: src/core/md5_fingerprint.c:20:10: fatal error: md5.h: No such file or directory,CLOSED,2020-04-23T10:26:48Z,2023-04-05T06:13:34Z,2023-04-05T06:13:34Z,"Hi,
  I wanted to update the package for Gentoo Linux from 1.5.10 to 1.6.1 but now it fails with:

```
[compile md5_encoder.o]
[compile md5_fingerprint.o]
src/core/md5_fingerprint.c:20:10: fatal error: md5.h: No such file or directory
   20 | #include ""md5.h""
      |          ^~~~~~~
[compile md5_seqid.o]
compilation terminated.
make: *** [Makefile:822: obj/src/core/md5_fingerprint.o] Error 1
```

I assume I have the right package but in an unexpected location. Please tell me from where is the md5.h supposed to come from and how you detect for its presence automatically.

[build.log](https://github.com/genometools/genometools/files/4521809/build.log)
",mmokrejs,https://github.com/genometools/genometools/issues/945,genometools++genometools.csv
MDU6SXNzdWU2MjE2MTgyMjg=,src/match/tagerator.c:237:33: error: gt_fromitv2so undeclared (first use in this function),CLOSED,2020-05-20T09:42:21Z,2020-05-22T10:09:27Z,2020-05-22T10:09:17Z,"## Problem description
compile error when I  installed genometools

## Exact command line call triggering the problem

```
make
```

## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

genometools-1.6.1
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Linux version 3.10.0-327.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.3 20140911 (Red Hat 4.8.3-9) (GCC) ) #1 SMP Thu Nov 19 22:10:57 UTC 2015",onmyojiyys,https://github.com/genometools/genometools/issues/946,genometools++genometools.csv
MDU6SXNzdWU2MzYxMDIxNzQ=,"Asseriton Failed: (gn && nv && gn->c_class && gn->c_class->accept), function gt_genome_node_accept, file src/extended/genome_node.c, line 326.",OPEN,2020-06-10T09:43:40Z,2020-06-10T09:43:40Z,,"## Problem description
When running classification in LTRsift, it crashes with segmentation fault and this genometools error:

```
Assertion failed: (gn && nv && gn->c_class && gn->c_class->accept), function gt_genome_node_accept, file src/extended/genome_node.c, line 326.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
```

## Exact command line call triggering the problem

```
LtrSift classification using HMM profiles (GUI)
```

## Example minimal input triggering the problem
N/A

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

```
gt (GenomeTools) 1.6.1
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (Ubuntu 9.3.0-10ubuntu2) 9.3.0
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror

```

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make with-hmmer=yes threads=yes

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu 20.04 
x86_64",TobyBaril,https://github.com/genometools/genometools/issues/947,genometools++genometools.csv
MDU6SXNzdWU2NDQwODMyNjQ=,homopolymer problem in LTRharvest,CLOSED,2020-06-23T19:16:54Z,2020-08-07T05:45:10Z,2020-08-06T19:42:44Z,"## Problem description
One of chromosome includes a homopolymer such as A X 18000bp or G X 18000bp. LTRharvest is hanging for 3days without any output.

## Exact command-line call triggering the problem

```bash
gt suffixerator -db test -indexname test -suf -lcp -des -ssp -sds -dna -mirrored -withradixsort -iterscan -showprogress

gt ltrharvest -index test -minlenltr 100 -maxlenltr 7000 -mintsd 4 -maxtsd 6 -motif TGCA -motifmis 1 -similar 85 -vic 10 -seed 20 -seqids yes
```

## Example minimal input triggering the problem

https://www.dropbox.com/t/yTVS4ooKyIXQXoZq

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
Tested two versions
```
   ~/scratch/bin/genometools-1.6.1/bin/gt -version
/data/gpfs/home/wyim/scratch/bin/genometools-1.6.1/bin/gt (GenomeTools) 1.6.1
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: x86_64-conda_cos6-linux-gnu-cc (crosstool-NG 1.24.0.123_1667d2b) 7.5.0
Compile flags: -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /data/gpfs/home/wyim/scratch/bin/miniconda3/envs/edta/include -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -W
```
```
/data/gpfs/home/wyim/scratch/bin/gt-1.5.10-Linux_x86_64-64bit-complete/bin/gt (GenomeTools) 1.5.10
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (Ubuntu 4.9.1-16ubuntu6) 4.9.1
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -m32 -m64 -Werror
```
## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
I used below. 1.5.10 is binary 
```bash
 make -j 8 cairo=no   threads=yes
```
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
```
CentOS Linux release 7.6.1810 (Core)
Derived from Red Hat Enterprise Linux 7.6 (Source)
Cluster Manager v8.2
```",wyim-pgl,https://github.com/genometools/genometools/issues/948,genometools++genometools.csv
MDU6SXNzdWU2NjgwNzEwMTA=,gff3 sort warnings,OPEN,2020-07-29T19:01:06Z,2021-07-28T17:18:19Z,,"## Problem description
I am trying to sort a large (10.9 GB) gff file for input into a genome browser for viewing. The command has been running for 6 days with warnings, no errors, and no output being written to the output file. Should I expect the sorting to take this long with such a large file? I am specifically concerned about about the 'more than one' warning with the result 'join them'. What does this mean?

```
warning: seqid ""contig_1960_pilon"" on line 3783 in file ""/share2/rmaher/dungeness-rad/MAKER/Dungeness.all.rnd3.gff"" has not been previously introduced with a ""##sequence-region"" line, create such a line automatically
warning: more than one aligned_coverage attribute on line 16065 in file ""/share2/rmaher/dungeness-rad/MAKER/Dungeness.all.rnd3.gff""; join them
warning: more than one aligned_identity attribute on line 16065 in file ""/share2/rmaher/dungeness-rad/MAKER/Dungeness.all.rnd3.gff""; join them
```

## Exact command line call triggering the problem

```
gt gff3 -sortlines -tidy /MAKER/Dungeness.all.rnd2.gff > MAKER/Dungeness.all.rnd2.sorted.gff
```

## Example minimal input triggering the problem

[Dungeness.all.rnd3.sub.txt](https://github.com/genometools/genometools/files/4996879/Dungeness.all.rnd3.sub.txt)

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt (GenomeTools) 1.6.1

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
Unsure. 

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
MacOS Mojave Version 10.14.6",maherrl,https://github.com/genometools/genometools/issues/949,genometools++genometools.csv
MDU6SXNzdWU2Njg0NjA1ODQ=,make error,CLOSED,2020-07-30T07:53:33Z,2020-07-30T08:55:45Z,2020-07-30T08:55:45Z,"## Problem description
[create obj/gt_config.h]
[compile sqlite3.o]
[compile alphabet.o]
[compile array.o]
[compile array2dim.o]
[compile array2dim_sparse.o]
[compile array3dim.o]
[compile basename.o]
[compile bioseq.o]
src/core/bioseq.c: In function 'construct_bioseq_files':
src/core/bioseq.c:121:18: error: ignoring return value of 'fwrite', declared with attribute warn_unused_result [-Werror=unused-result]
       if (i > 0) fwrite(buf, 1, i, tmpfile);
                  ^~~~~~~~~~~~~~~~~~~~~~~~~~
cc1: all warnings being treated as errors
make: *** [Makefile:823: obj/src/core/bioseq.o] Error 1

## Exact command line call triggering the problem

make 64bit=yes universal=yes useshared=no  cairo=no prefix=/ds3200_1/users_root/hezhengshan/bin/08Repeat/genometools1.6.1

## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
genometools-1.6.1

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make 64bit=yes universal=yes useshared=no  cairo=no prefix=/ds3200_1/users_root/hezhengshan/bin/08Repeat/genometools1.6.1

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
x86_64",sanvva,https://github.com/genometools/genometools/issues/950,genometools++genometools.csv
MDU6SXNzdWU3MjQ5NDk0MDU=,Repeated use of inline queue breaks amalgamated build,CLOSED,2020-10-19T20:24:49Z,2020-10-19T23:56:51Z,2020-10-19T23:56:51Z,"## Problem description

When building the current master code with `amalgamation=yes`, redefinition of the `GtInl_Queueelem` type before including `match/queue-inline.h` triggers a compile error:

```
[compile amalgamation.o]
In file included from obj/amalgamation.c:542:0:
/home/travis/build/genometools/genometools/src/match/sfx-diffcov.c:105:27: error: conflicting types for GtInl_Queueelem
 typedef GtDcPairsuffixptr GtInl_Queueelem;
                           ^
In file included from obj/amalgamation.c:116:0:
/home/travis/build/genometools/genometools/src/core/sequence_buffer_dust.c:26:23: note: previous declaration of GtInl_Queueelem was here
 typedef unsigned char GtInl_Queueelem;
                       ^
In file included from obj/amalgamation.c:542:0:
/home/travis/build/genometools/genometools/src/match/sfx-diffcov.c: In function dc_processunsortedrange:
/home/travis/build/genometools/genometools/src/match/sfx-diffcov.c:815:43: error: incompatible type for argument 2 of gt_inl_queue_add
   gt_inl_queue_add(dcov->rangestobesorted,pairelem,false);
                                           ^
In file included from /home/travis/build/genometools/genometools/src/core/sequence_buffer_dust.c:27:0,
                 from obj/amalgamation.c:116:
/home/travis/build/genometools/genometools/src/match/queue-inline.h:123:20: note: expected GtInl_Queueelem {aka unsigned char} but argument is of type GtDcPairsuffixptr {aka struct <anonymous>}
 static inline void gt_inl_queue_add(GtInl_Queue *q, GtInl_Queueelem elem,
                    ^
In file included from obj/amalgamation.c:542:0:
/home/travis/build/genometools/genometools/src/match/sfx-diffcov.c: In function dc_sortremainingsamples:
/home/travis/build/genometools/genometools/src/match/sfx-diffcov.c:1026:14: error: incompatible types when assigning to type GtDcPairsuffixptr {aka struct <anonymous>} from type GtInl_Queueelem {aka unsigned char}
     thispair = gt_inl_queue_get(dcov->rangestobesorted);
              ^
Makefile:840: recipe for target 'obj/obj/amalgamation.o' failed
``` 

## Exact command line call triggering the problem

In principle:
```
make amalgamation=yes
```

See

## Example minimal input triggering the problem

Git master e5c5d6ef9b4305e6238924914e16a6a55a77a6d6

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

git master

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

See above

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Ubuntu 16.04.6 LTS x86_64
gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609",satta,https://github.com/genometools/genometools/issues/959,genometools++genometools.csv
MDU6SXNzdWU3MzM0MzIwNzI=,"Assertion failed: (!gt_array_size(ss->positionmapping) || start > *(GtUword*) gt_array_get_last(ss->positionmapping)), function gt_splicedseq_add, file src/extended/splicedseq.c, line 50.",OPEN,2020-10-30T18:46:15Z,2022-05-08T22:03:48Z,,"## Problem description
Some of my exons did not have a matching CDS. So I run the gt cds command to make sure that every exon had a CDS.  

I got this message after it run for a few lines:
Assertion failed: (!gt_array_size(ss->positionmapping) || start > *(GtUword*) gt_array_get_last(ss->positionmapping)), function gt_splicedseq_add, file src/extended/splicedseq.c, line 50.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Aborted

## Exact command line call triggering the problem

```
gt cds -matchdescstart -seqfile hg38.fasta new.clean.gff3 > new.clean_cds.gff3
```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt (GenomeTools) 1.6.1
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36)
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
Yes. I run make, make test and make install

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
My OS is CentOS 7.6.1810
",DafniG,https://github.com/genometools/genometools/issues/961,genometools++genometools.csv
MDU6SXNzdWU3NTAxMDY2MTQ=,ltrharvest is not finishing in 5 days,CLOSED,2020-11-24T22:15:07Z,2021-07-28T19:29:43Z,2021-07-28T19:29:18Z,"## Problem description

I am running ltrharvest on a ~600 Mbp tree genome. It is not finishing in 5 days therefore I wonder whether ltrharvest hangs without any error or output. It is running on 64 Gb RAM with 4 TB diskspace. I would be happy to provide the files via emailing a link.

## Exact command line call triggering the problem

```
gt suffixerator -db Dacoc.fa -indexname esa_index -tis -suf -lcp -des -ssp -sds -dna
gt ltrharvest -index esa_index -out ltrharvest.out > ltrharvest.log 2>&1
```

## Example minimal input triggering the problem

The esa_index* files are generated from the input genome.

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

1.6.1

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

`make threads=yes`

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Debian 10

Thank you very much for your help.",hung-th,https://github.com/genometools/genometools/issues/962,genometools++genometools.csv
MDU6SXNzdWU3NjA1MTc4ODY=,macOS Travis tests consistently fail,CLOSED,2020-12-09T17:19:55Z,2021-06-09T06:10:24Z,2021-06-09T06:10:24Z,"## Problem description

The macOS travis tests consistently fail due to the dependency installations via Homebrew nor finishing within Travis' specified time limit.  Even some measures to extend the time limit didn't succeed.

Example: https://travis-ci.org/github/satta/genometools/jobs/748440437

## Exact command line call triggering the problem

```
./scripts/travis_installdeps.sh
```

## Example minimal input triggering the problem

n/a

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

any

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

no, problem happens before compilation

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

macOS  x86_64-apple-darwin17.7.0",satta,https://github.com/genometools/genometools/issues/964,genometools++genometools.csv
MDU6SXNzdWU3NzM3NDc4NTM=,segmentation fault,OPEN,2020-12-23T13:12:08Z,2021-06-17T09:09:57Z,,"Hi 
I am getting the error below. I made small reproducible example and attached it ""split.txt"". 64bit version of the program

----
```
$ gt readjoiner prefilter -db split.txt
# gt readjoiner prefilter (version 1.2)
# number of reads in complete readset = 14
# low-quality reads = 0
# contained reads = 1
# number of reads in filtered readset = 13
Assertion failed: ((code & ~mask) >> shift == (GtTwobitencoding)r2t->current_sepcode), function gt_reads2twobit_set_separators_to_less_frequent_char, file src/match/reads2twobit.c, line 1976.
This is a bug, please report it at
```
```
gt -version
gt (GenomeTools) 1.6.1
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-4)
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror
```

[split.txt](https://github.com/genometools/genometools/files/5735323/split.txt)
",RamilNurtdinov,https://github.com/genometools/genometools/issues/965,genometools++genometools.csv
MDU6SXNzdWU3Nzc0ODQ3NDk=,Thanks,OPEN,2021-01-02T16:17:28Z,2021-05-31T19:09:10Z,,"Thank you for doing your great work.
Is there any blockers that community should think on?",ohhmm,https://github.com/genometools/genometools/issues/966,genometools++genometools.csv
MDU6SXNzdWU4NTg5NDgxNzk=,rc/ltr/ltrdigest_file_out_stream.c:121:32 ... [-Werror=format-truncation=],CLOSED,2021-04-15T14:36:12Z,2021-04-16T20:48:18Z,2021-04-16T20:48:18Z,"## Problem description
While compiling genometools 1.6.1 on an up-to-date (April 15 2021) Arch Linux system (X86-64) with gcc version 10.2.0, I run into the following: 
...
[compile ltr_refseq_match_stream.o]
[compile ltrdigest_file_out_stream.o]
src/ltr/ltrdigest_file_out_stream.c: In function gt_ltrelement_format_description.constprop.isra:
src/ltr/ltrdigest_file_out_stream.c:121:32: error: %s directive output may be truncated writing up to 8191 bytes into a region of size 255 [-Werror=format-truncation=]
  121 |   ret = snprintf(buf, buflen, ""%s_""GT_WU""_""GT_WU"""", tmpstr, e->leftLTR_5+1,
      |                                ^~                   ~~~~~~
src/ltr/ltrdigest_file_out_stream.c:121:9: note: snprintf output between 5 and 8234 bytes into a destination of size 255
  121 |   ret = snprintf(buf, buflen, ""%s_""GT_WU""_""GT_WU"""", tmpstr, e->leftLTR_5+1,
      |         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  122 |                  e->rightLTR_3+1);
      |                  ~~~~~~~~~~~~~~~~
cc1: all warnings being treated as errors
make: *** [Makefile:823: obj/src/ltr/ltrdigest_file_out_stream.o] Error 1

## Exact command line call triggering the problem
make

Adding ""errorcheck=no"" circumvents the compilation issue but the code likely needs a permanent fix.",kinestetika,https://github.com/genometools/genometools/issues/967,genometools++genometools.csv
MDU6SXNzdWU4NTg5NTY4MDY=,#include problems while compiling genometools 1.6.1  ,CLOSED,2021-04-15T14:45:11Z,2021-04-16T20:47:57Z,2021-04-16T20:47:57Z,"## Problem description
while compiling genometools 1.61 on an up to date arch linux installation (April 15 2021), compilation fails as follows:
...
[link libsqlite.a]
ar: `u' modifier ignored since `D' is the default (see `U')
ar: creating lib/libsqlite.a
[link libgenometools.a]
ar: creating lib/libgenometools.a
[link libbz2.a]
ar: `u' modifier ignored since `D' is the default (see `U')
ar: creating lib/libbz2.a
[link libz.a]
ar: `u' modifier ignored since `D' is the default (see `U')
ar: creating lib/libz.a
[link libexpat.a]
ar: `u' modifier ignored since `D' is the default (see `U')
ar: creating lib/libexpat.a
[gathering public API symbols to obj/public_symbols.lst]
[link libgenometools.so]
/usr/bin/ld: obj/src/mgth/mg_combinedscore.o:/home/kinestetika/bin/repeats/genometools-1.6.1/src/mgth/metagenomethreader.h:224: multiple definition of `gt_cstr_nofree_ulp_hashtype'; obj/src/mgth/metagenomethreader.o:/home/kinestetika/bin/repeats/genometools-1.6.1/src/mgth/metagenomethreader.h:224: first defined here
/usr/bin/ld: obj/src/mgth/mg_compute_gene_prediction.o:/home/kinestetika/bin/repeats/genometools-1.6.1/src/mgth/metagenomethreader.h:224: multiple definition of `gt_cstr_nofree_ulp_hashtype'; obj/src/mgth/metagenomethreader.o:/home/kinestetika/bin/repeats/genometools-1.6.1/src/mgth/metagenomethreader.h:224: first defined here
/usr/bin/ld: obj/src/mgth/mg_computepath.o:/home/kinestetika/bin/repeats/genometools-1.6.1/src/mgth/metagenomethreader.h:224: multiple definition of `gt_cstr_nofree_ulp_hashtype'; obj/src/mgth/metagenomethreader.o:/home/kinestetika/bin/repeats/genometools-1.6.1/src/mgth/metagenomethreader.h:224: first defined here
/usr/bin/ld: obj/src/mgth/mg_outputwriter.o:/home/kinestetika/bin/repeats/genometools-1.6.1/src/mgth/metagenomethreader.h:224: multiple definition of `gt_cstr_nofree_ulp_hashtype'; obj/src/mgth/metagenomethreader.o:/home/kinestetika/bin/repeats/genometools-1.6.1/src/mgth/metagenomethreader.h:224: first defined here
/usr/bin/ld: obj/src/mgth/mg_reverse.o:/home/kinestetika/bin/repeats/genometools-1.6.1/src/mgth/metagenomethreader.h:224: multiple definition of `gt_cstr_nofree_ulp_hashtype'; obj/src/mgth/metagenomethreader.o:/home/kinestetika/bin/repeats/genometools-1.6.1/src/mgth/metagenomethreader.h:224: first defined here
/usr/bin/ld: obj/src/mgth/mg_xmlparser.o:/home/kinestetika/bin/repeats/genometools-1.6.1/src/mgth/metagenomethreader.h:224: multiple definition of `gt_cstr_nofree_ulp_hashtype'; obj/src/mgth/metagenomethreader.o:/home/kinestetika/bin/repeats/genometools-1.6.1/src/mgth/metagenomethreader.h:224: first defined here

## Exact command line call triggering the problem
make errorcheck=no

gcc version 10.2.0",kinestetika,https://github.com/genometools/genometools/issues/968,genometools++genometools.csv
MDU6SXNzdWU5MDAxNTA5NzE=,"Proper way to ""delete"" children nodes or whole feature trees in gt-python?",CLOSED,2021-05-25T01:09:01Z,2021-06-23T18:06:06Z,2021-06-23T08:22:49Z,"## Problem description

This is both a question and a crash report:

I have been given a series GFF files that have issues with children coordinates (I don't control the annotation source).  Specifically in some genes, some of the exon children happen to overlap (no intron and children have a slight overlap).   From what I see in the code I am not allowed to alter a previously parsed child node's coordinates, but rather to make a new one with the correct coordinates and hopefully delete the problematic child node (the one originally parsed from the file)

There is a gt-python function that implements the C functionality in ""gtlib.gt_feature_node_add_child"" for adding newly created child nodes to a parent feature tree.   However I haven't found a corresponding python method for deleting a node (C code has gt_genome_node_delete or gt_feature_node_remove_leaf)

Have I missed it in the gt-python code? What is the proper way to do this? or maybe is not implemented yet?  

So instead I attempted to make calls to the C methods directly like this in my python script:

```
    from gt.dlload import gtlib
    ...
    gtlib.gt_feature_node_remove_leaf(feature, tfn)  # where tfn is the current child node iterated with FeatureNodeIteratorDirect()

```
Having the last line in my python code that is iterating over feature trees in a FeatureIndexMemory index causes the script to crash with a segmentation fault but no further message. 

Is this a bug or simply the wrong way to go about this?


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
Multiple versions from 1.5 up to current one (version 1.6.1)

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
No.  I downloaded precompiled binaries and libraries from two separate places (Bioconda, Ubuntu packages) and both had same behaviour on multiple versions.  I tryed the Bioconda solution on two distributions (Ubuntu and CentOS)

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu 20.04  and CentOS 7 on x86_64,  both using python3.6 or above

Thanks,
Mauricio La Rota
",maol-corteva,https://github.com/genometools/genometools/issues/969,genometools++genometools.csv
MDU6SXNzdWU5MDAzMDg5MDU=,LTRdigest stuck for ten days,CLOSED,2021-05-25T05:55:44Z,2021-06-08T08:14:34Z,2021-06-03T02:38:28Z,"## Problem description

Hi, 

I was running LTRdigest on the result of LTRharvest. The process is still running (in S status). But the output stopped about ten days ago. I used strace -p to see what's going on for gt and hmmscan. The output is not not updating. 


gt
```
strace: Process 91896 attached
write(13, ""\n"", 1
```

hmmscan
```
$strace -p 333397 
strace: Process 333397 attached
write(1, ""\n  == domain 2  score: 73.5 bits""..., 523
```

$lt output
```
  0 May 14 17:53 Sp.genome.ltrdigest_3ltr.fas
  0 May 14 17:53 Sp.genome.ltrdigest_5ltr.fas
  0 May 14 17:53 Sp.genome.ltrdigest_complete.fas
23K May 14 17:53 Sp.genome.ltrdigest_conditions.csv
  0 May 14 17:53 Sp.genome.ltrdigest_pbs.fas
  0 May 14 17:53 Sp.genome.ltrdigest_ppt.fas
  0 May 14 17:53 Sp.genome.ltrdigest_tabout.csv
```

## Exact command line call triggering the problem

```
gt -j 10 ltrdigest -pptlen 10 30 -pbsoffset 0 3 -trnas /lustre/local/database/tRNA/eukaryotic-tRNAs.fa -hmms /lustre/local/database/gydb/GyDB_collection/profiles/AP_1731.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_17_6.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_412_mdg1.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_a_clade.hmm/lustre/local/database/gydb/GyDB_collection/profiles/AP_alpharetroviridae.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_athila.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_badnavirus.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_b_clade.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_bel.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_betaretroviridae.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_caulimoviridae_dom2.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_caulimovirus.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_cavemovirus.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_cer2_3.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_codi_c.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_codi_d.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_codi_I.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_codi_II.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_cog3577.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_cog5550.hmm /lustre/local/database/gydb/GyDB_collection/profiles/AP_copia.hmm /lustre/local/database/gydb/GyDB_collection/ ...
-outfileprefix ltrdigest/Sp.genome.ltrdigest Sp.genome.ltrharvest.sorted.gff3 Sp.genome

```

## Example minimal input triggering the problem
```
head Sp.genome.ltrharvest.sorted.gff3 
==> Sp.genome.ltrharvest.sorted.gff3 <==
##gff-version 3
##sequence-region   seq0 1 33263194
##sequence-region   seq10 1 44760251
##sequence-region   seq2 1 81372794
##sequence-region   seq3 1 56792611
##sequence-region   seq4 1 56999476
##sequence-region   seq5 1 53814584
##sequence-region   seq6 1 61110319
##sequence-region   seq7 1 39818848
##sequence-region   seq8 1 41393046
##sequence-region   seq9 1 37631608
#10
#1
#3
#2
#5
#4
#7
#6
#9
#8
seq0    LTRharvest      repeat_region   8456236 8553983 .       ?       .       ID=repeat_region1
seq0    LTRharvest      target_site_duplication 8456236 8456240 .       ?       .       Parent=repeat_region1
seq0    LTRharvest      inverted_repeat 8456241 8456242 .       ?       .       Parent=repeat_region1
seq0    LTRharvest      LTR_retrotransposon     8456241 8553978 .       ?       .       ID=LTR_retrotransposon1;Parent=repeat_region1;ltr_similarity=88.
seq0    LTRharvest      long_terminal_repeat    8456241 8458126 .       ?       .       Parent=LTR_retrotransposon1
seq0    LTRharvest      long_terminal_repeat    8552067 8553978 .       ?       .       Parent=LTR_retrotransposon1
seq0    LTRharvest      inverted_repeat 8458125 8458126 .       ?       .       Parent=repeat_region1

```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
1.5.10

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
I used conda to install gt.

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
CentOS7, x86_64",lhui2010,https://github.com/genometools/genometools/issues/970,genometools++genometools.csv
MDU6SXNzdWU5MTAyMjI1Njc=,Update the CI platform,CLOSED,2021-06-03T07:54:02Z,2021-06-08T12:44:22Z,2021-06-08T12:44:22Z,"## Problem description

Travis-CI.org is shutting down and we would need to migrate our CI to Travis-CI.com (https://blog.travis-ci.com/2021-05-07-orgshutdown).
Regarding Travis, we have seen that macOS builds take too long because there are no binary packages for the dependencies for the OS version they are running, so they need to be built from source, which exceeds their time limit for runs.

I am wondering whether we might want to migrate the CI to GitHub Actions completely, which appears to be as a well-integrated, feature-rich solution, which will hopefully be supported for a long time. This would also remove dependencies to external services even more.

Any comments? Alternatively we could just move the CI to Travis-CI.com as described and just remove the macOS tests.",satta,https://github.com/genometools/genometools/issues/973,genometools++genometools.csv
MDU6SXNzdWU5MTU0NDM3ODM=,"Issue with ""source"" in freshly created FeatureNodes in gtpython",OPEN,2021-06-08T20:14:01Z,2021-06-23T08:49:48Z,,"## Problem description

Dear @satta : 

Using Python3, when creating a GFF FeatureNode from scratch,  setting its ""source"" field with fn.set_source() method results in the storage of a string that is possibly twice encoded.

If the user requests the source data back with fn.get_source() method, what the user gets back is a proper string that falsely resembles a ""bytes"" object.   Attempting to decode the object results in an attribute error because the object does not have a ""decode"" attribute.   

The object is already a string,  but it retains (as a string) the format  b'text'  which looks like a bytes object. (See code below)

I assume the source logic is attempting to be transparent to both python2 and python3.  I did not test with python2.

## example python3.8 code ""test_newfeat_source.py"" follows
```python
#!/bin/env python
# -*- coding: utf-8 -*-

from gt.extended.feature_node import FeatureNodeIteratorDirect
from gt.dlload import gtlib
from gt.extended import *
import sys
import re
print(sys.path)

if __name__ == ""__main__"":
    seqid = ""foo""
    seqsource = ""BAR""
    gene = FeatureNode.create_new(seqid, ""gene"", 100, 900, ""+"")
    gene.set_source(  seqsource   )
    exon1 = FeatureNode.create_new(seqid, ""exon"", 100, 200, ""+"")
    exon1.set_source(  seqsource   )
    gene.add_child(exon1)
    exon2 = FeatureNode.create_new(seqid, ""exon"", 800, 900, ""+"")
    exon2.set_source(  seqsource   )
    gene.add_child(exon2)

    fin = FeatureNodeIteratorDepthFirst(gene)
    while True:
        fn = fin.next()
        if not fn:
            break
        tfn_source = fn.get_source().decode('UTF-8')
        print(fn, tfn_source, fn.get_type())

    print(""\n..After reformating source gff3 field..."")
    locregex=re.compile(""b'(.+)'$"")
    fin = FeatureNodeIteratorDepthFirst(gene)
    while True:
        fn = fin.next()
        if not fn:
            break
        tfn_source = fn.get_source().decode('UTF-8')
        #tfn_source = str(fn.get_source())
        if (tfn_source.startswith(""b'"")):
            locpatternsearch = locregex.search(tfn_source)
            tfn_source = locpatternsearch.group(1)               #         <=== FIXed here
        print(f'The type of obj ""source"" is {type(tfn_source)}')
        print(fn, tfn_source, fn.get_type())
```

##Output from above code under Ubuntu's system installed python 3.8

```
 $  python3 test_newfeat_source.py
['/home/testy/Documents/work', '/home/testy/Documents/source/gt/gtpython', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '/usr/local/lib/python3.8/dist-packages', '/usr/lib/python3/dist-packages']
FeatureNode(start=100, end=900, seqid=""foo"") b'BAR' gene
FeatureNode(start=100, end=200, seqid=""foo"") b'BAR' exon
FeatureNode(start=800, end=900, seqid=""foo"") b'BAR' exon

..After reformating source gff3 field...
The type of obj ""source"" is <class 'str'>
FeatureNode(start=100, end=900, seqid=""foo"") BAR gene
The type of obj ""source"" is <class 'str'>
FeatureNode(start=100, end=200, seqid=""foo"") BAR exon
The type of obj ""source"" is <class 'str'>
FeatureNode(start=800, end=900, seqid=""foo"") BAR exon
```
## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
I am using GenomeTools 1.6.1 installed by downloading precompiled binary and python libs from GenomeTools.org (single tar.gz package)
```
$ python3  -V
Python 3.8.5

$ which python3
/usr/bin/python3

$ echo $PYTHONPATH
/home/testy/Documents/source/gt/gtpython

$  /home/testy/Documents/source/gt/bin/gt --version
/home/testy/Documents/source/gt/bin/gt (GenomeTools) 1.6.1
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.
```

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
Same downloaded distro reports: 

```
Used compiler: cc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -m32 -Werror
```

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu 20.04 LTS",maol-corteva,https://github.com/genometools/genometools/issues/977,genometools++genometools.csv
MDU6SXNzdWU5MTU1MzAyMTE=,FeatureRequest:    Can we add gtpython FeatureNode support for  gtlib.gt_genome_node_set_range() and gt_feature_node_set_attribute(),CLOSED,2021-06-08T21:25:11Z,2021-10-14T23:31:07Z,2021-06-24T14:43:03Z,"## Problem description
Dear @satta : 

I use GenomeTools python library to fix or modify GFF files provided by external collaborators when these don't match the spec or don't fit our internal systems.   Many times this involves issues with coordinate systems (coordinate translation for just a region of a chromosome or some major re-arrangement) or fixing other items in the object (attributes, intron/exon boundaries, etc).

Sometimes, it would be simpler to modify an existing FeatureNode object in place rather than to make a a new one to copy most of the old node's attributes and fix the one attribute or coordinates that need fixing from ""failed"" object.

It would be nice to do something like this to the existing FeatureNode class (or one that inherits from it):  

```python
#... as part of class definition ...
def update_range(self, this_start, this_end):
    newrange = Range( this_start, this_end )
    try:
        print(f""Setting range of to : {newrange}"")
        gtlib.gt_genome_node_set_range(self.gn, newrange)
    except:
        raise Exception(""Unable to update the range"")
```

But the code above fails because ""newrange"" is not the C GtRange object expected..  I am not sure what I should be passing from the Python side.   And actually it would be lovely if the python FeatureNode class would support this.

Another nice to have method  would be if the python existing FN.add_attribute()  method (or  a new one)  used the C library  [gtlib.gt_feature_node_set_attribute()](https://github.com/genometools/genometools/blob/694fe366e92d56d2b70ec7ef5742a75560e9a992/src/extended/feature_node.c#L683)   (which allows override of existing attribute) instead of [gtlib.gt_feature_node_add_attribute](https://github.com/genometools/genometools/blob/694fe366e92d56d2b70ec7ef5742a75560e9a992/gtpython/gt/extended/feature_node.py#L157) (expects attribute to be brand new)

I will be happy to submit pull requests, but need to get familiar with the process first.

Cheers,

Mauricio L.
",maol-corteva,https://github.com/genometools/genometools/issues/978,genometools++genometools.csv
MDU6SXNzdWU5MzA4NzkzNjg=,"Assertion failed: (fn), function gt_feature_node_iterator_new, file src/extended/feature_node_iterator.c, line 46.",CLOSED,2021-06-27T08:35:03Z,2022-05-08T22:11:48Z,2022-05-08T18:47:30Z,"## Problem description

Running ltrdigest I get this error:

COMMAND:

gt -j 4 ltrdigest -outfileprefix Prunus_avium -trnas ./INPUT/tRNA_databas/plant_tRNA_cat.fa -hmms ./INPUT/Protein_database/*.hmm -seqfile ./INPUT/genomes/Prunus_avium.fa -matchdescstart < ./EDTA-1.8..2/Prunus_avium_sorted.gff3 > ./Prunus_avium_ltrdigest.gff3

OUTPUT:

Assertion failed: (fn), function gt_feature_node_iterator_new, file src/extended/feature_node_iterator.c, line 46.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with gt -version.
Aborted (core dumped)

## Exact command line call triggering the problem


```
gt -j 4 ltrdigest -outfileprefix Prunus_avium -trnas ./INPUT/tRNA_databas/plant_tRNA_cat.fa -hmms ./INPUT/Protein_database/*.hmm -seqfile ./INPUT/genomes/Prunus_avium.fa -matchdescstart < ./EDTA-1.8..2/Prunus_avium_sorted.gff3 > ./Prunus_avium_ltrdigest.gff3

```

## A preview of my sorted file

##gff-version 3
##sequence-region   CM024352.1 1 62324707
##sequence-region   CM024353.1 1 46928806
##sequence-region   CM024354.1 1 42862123
##sequence-region   CM024355.1 1 37373756
##sequence-region   CM024356.1 1 41299679
##sequence-region   CM024357.1 1 42624765
##sequence-region   CM024358.1 1 30632009
##sequence-region   CM024359.1 1 38835769
#CM024352.1
#CM024353.1
#CM024354.1
#CM024355.1
#CM024356.1
#CM024357.1
#CM024358.1
#CM024359.1
CM024352.1	EDTA	repeat_region	191737	201094	.	?	.	ID=repeat_region1
CM024352.1	EDTA	target_site_duplication	191737	191741	.	?	.	Parent=repeat_region1
CM024352.1	EDTA	LTR/unknown	191742	201089	.	?	.	ID=LTR/unknown1;Parent=repeat_region1;motif=TGCA;tsd=TCCAT;ltr_identity=0.9959;seq_number=0
CM024352.1	EDTA	long_terminal_repeat	191742	193449	.	?	.	Parent=LTR/unknown1
CM024352.1	EDTA	long_terminal_repeat	199383	201089	.	?	.	Parent=LTR/unknown1
CM024352.1	EDTA	target_site_duplication	201090	201094	.	?	.	Parent=repeat_region1
###
CM024352.1	EDTA	repeat_region	1617430	1629426	.	?	.	ID=repeat_region2
CM024352.1	EDTA	target_site_duplication	1617430	1617434	.	?	.	Parent=repeat_region2
CM024352.1	EDTA	LTR/Gypsy	1617435	1629421	.	?	.	ID=LTR/Gypsy1;Parent=repeat_region2;motif=TGCA;tsd=CCAAT;ltr_identity=1.0000;seq_number=0
CM024352.1	EDTA	long_terminal_repeat	1617435	1619599	.	?	.	Parent=LTR/Gypsy1
CM024352.1	EDTA	long_terminal_repeat	1627258	1629421	.	?	.	Parent=LTR/Gypsy1
CM024352.1	EDTA	target_site_duplication	1629422	1629426	.	?	.	Parent=repeat_region2
###
CM024352.1	EDTA	repeat_region	1946186	1956558	.	?	.	ID=repeat_region3
CM024352.1	EDTA	target_site_duplication	1946186	1946190	.	?	.	Parent=repeat_region3
CM024352.1	EDTA	LTR/unknown	1946191	1956553	.	?	.	ID=LTR/unknown2;Parent=repeat_region3;motif=TGCA;tsd=GTAAT;ltr_identity=0.9991;seq_number=0
CM024352.1	EDTA	long_terminal_repeat	1946191	1948386	.	?	.	Parent=LTR/unknown2
CM024352.1	EDTA	long_terminal_repeat	1954358	1956553	.	?	.	Parent=LTR/unknown2
CM024352.1	EDTA	target_site_duplication	1956554	1956558	.	?	.	Parent=repeat_region3
###
CM024352.1	EDTA	repeat_region	2203935	2208697	.	?	.	ID=repeat_region4
CM024352.1	EDTA	target_site_duplication	2203935	2203938	.	?	.	Parent=repeat_region4
CM024352.1	EDTA	LTR/Gypsy	2203939	2208693	.	?	.	ID=LTR/Gypsy2;Parent=repeat_region4;motif=TGCA;tsd=AATT;ltr_identity=0.9921;seq_number=0
CM024352.1	EDTA	long_terminal_repeat	2203939	2204568	.	?	.	Parent=LTR/Gypsy2
CM024352.1	EDTA	long_terminal_repeat	2208064	2208693	.	?	.	Parent=LTR/Gypsy2
CM024352.1	EDTA	target_site_duplication	2208694	2208697	.	?	.	Parent=repeat_region4
###
CM024352.1	EDTA	repeat_region	2418427	2436960	.	?	.	ID=repeat_region5
CM024352.1	EDTA	target_site_duplication	2418427	2418431	.	?	.	Parent=repeat_region5
CM024352.1	EDTA	LTR/unknown	2418432	2436955	.	?	.	ID=LTR/unknown3;Parent=repeat_region5;motif=TGCA;tsd=GAATA;ltr_identity=0.9945;seq_number=0
CM024352.1	EDTA	long_terminal_repeat	2418432	2420445	.	?	.	Parent=LTR/unknown3
CM024352.1	EDTA	long_terminal_repeat	2434948	2436955	.	?	.	Parent=LTR/unknown3
CM024352.1	EDTA	target_site_duplication	2436956	2436960	.	?	.	Parent=repeat_region5
###



## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
1.6.1


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make with-hmmer=yes threads=yes
make install prefix=/home/user/gt


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
PopOS 20.04 (Ubuntu 9.3.0-17ubuntu1~20.04)
",omar25-20,https://github.com/genometools/genometools/issues/982,genometools++genometools.csv
MDU6SXNzdWU5NDQ0Njk5MDA=,make: *** [obj/src/core/encseq.o] Error 1,CLOSED,2021-07-14T14:10:05Z,2024-03-04T10:00:00Z,2024-03-04T10:00:00Z,"[compile encseq.o]
In file included from /home/cjwen/software/genometools-1.6.2/src/core/sequence_buffer_fasta.h:21,
                 from src/core/encseq.c:57:
/home/cjwen/software/genometools-1.6.2/src/core/sequence_buffer.h:36: error: redefinition of typedef 'GtSequenceBuffer'
/home/cjwen/software/genometools-1.6.2/src/core/sequence_buffer_dust.h:26: note: previous declaration of 'GtSequenceBuffer' was here
make: *** [obj/src/core/encseq.o] Error 1",123123456abc,https://github.com/genometools/genometools/issues/983,genometools++genometools.csv
MDU6SXNzdWU5NDkwMTQ2MDY=,ERROR WHILE Make,OPEN,2021-07-20T19:44:00Z,2021-09-28T07:41:56Z,,"## Problem description

% apt-get install genometools
## Exact command line call triggering the problem
make
```
gt ...
```

## Example minimal input triggering the problem
In file included from src/annotationsketch/canvas_cairo.c:34:0:
/media/mittal/FMBL2/genometools-1.6.2/src/annotationsketch/graphics_cairo_api.h:21:19: fatal error: cairo.h: No such file or directory
compilation terminated.
Makefile:842: recipe for target 'obj/src/annotationsketch/canvas_cairo.o' failed
make: *** [obj/src/annotationsketch/canvas_cairo.o] Error 1


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
1.6.2

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

make with-hmmer=yes threads=yes

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu 64",ankush290307,https://github.com/genometools/genometools/issues/984,genometools++genometools.csv
MDU6SXNzdWU5NTQ5MjQxNTc=,gff file is not sorted after using -sortlines,CLOSED,2021-07-28T14:28:27Z,2021-07-29T12:44:05Z,2021-07-29T12:37:33Z,"## Problem description

I am using `tabix` to index a gff file after calling `gt gff3 --sortlines` but `tabix` complains that the file is not sorted

```
[ti_index_core] the file out of order at line 7
```

## Exact command line call triggering the problem

```
gt gff3 -sortlines -tidy -retainids tmp.gff > tmp.sorted.gff
bgzip tmp.sorted.gff
tabix tmp.sorted.gff.gz
```

## Example minimal input triggering the problem

```
NC_007417.3	iBtemplates_Tcas5	HSP	139165	139365	0	-	.	ID=23971391;Name=iB_05965;Target=iB_05965 16 216
NC_007417.3	iBtemplates_Tcas5	HSP	139411	139425	0	-	.	ID=23971391;Name=iB_05965;Target=iB_05965 1 15
NC_007417.3	iBtemplates_Tcas5	HSP	170645	170738	0	-	.	ID=23980693;Name=iB_09325(2/2);Alias=iB_09325;Target=iB_09325 144 237
NC_007417.3	iBtemplates_Tcas5	HSP	175849	175991	0	-	.	ID=23980693;Name=iB_09325(2/2);Alias=iB_09325;Target=iB_09325 1 143
NC_007417.3	iBtemplates_Tcas5	HSP	172917	173410	0	-	.	ID=23974642;Name=iB_04521(2/4);Alias=iB_04521;Target=iB_04521 1 494
NC_007417.3	iBtemplates_Tcas5	HSP	174782	175306	0	-	.	ID=23972312;Name=iB_05964(1/4);Alias=iB_05964;Target=iB_05964 1 525
NC_007417.3	iBtemplates_Tcas5	HSP	185524	185760	0	-	.	ID=23980547;Name=iB_09325(1/2);Alias=iB_09325;Target=iB_09325 1 237
NC_007417.3	iBtemplates_Tcas5	HSP	203540	204069	0	-	.	ID=23972047;Name=iB_07807;Target=iB_07807 1 530
NC_007417.3	iBtemplates_Tcas5	HSP	206671	207150	0	+	.	ID=23976289;Name=iB_05938(3/3);Alias=iB_05938;Target=iB_05938 1 480
NC_007417.3	iBtemplates_Tcas5	HSP	207450	207552	0	-	.	ID=23977814;Name=iB_07781(1/5);Alias=iB_07781;Target=iB_07781 348 450
NC_007417.3	iBtemplates_Tcas5	HSP	207683	207818	0	-	.	ID=23977814;Name=iB_07781(1/5);Alias=iB_07781;Target=iB_07781 212 347
```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

1.6.2

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

Yes. `-j4 cairo=no`

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Ubuntu 18.04.5 LTS x86_64
",canhnd58,https://github.com/genometools/genometools/issues/985,genometools++genometools.csv
I_kwDOAKqP_M47c9Cg,Improve portability of test usage,CLOSED,2021-09-15T19:41:46Z,2021-09-15T20:10:17Z,2021-09-15T20:09:03Z,"## Problem description
Two files (scripts/calltestcase.sh and scripts/spmcheck.sh) use test to check equality with the == operator.  This is not portable and should be replaced with =.

## Exact command line call triggering the problem


## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
1.6.2

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

[patch-scripts_calltestcase.sh.txt](https://github.com/genometools/genometools/files/7172794/patch-scripts_calltestcase.sh.txt)
[patch-scripts_spmcheck.sh.txt](https://github.com/genometools/genometools/files/7172795/patch-scripts_spmcheck.sh.txt)
",brook-milligan,https://github.com/genometools/genometools/issues/989,genometools++genometools.csv
I_kwDOAKqP_M47xZ1l,Assertion failed when reading GFF,CLOSED,2021-09-21T16:19:51Z,2021-09-28T16:29:11Z,2021-09-27T21:31:59Z,"## Problem description

When my input file contains the lines given in the minimal example, `gt` fails with this error:

Assertion failed: (elemidx >= q->front), function gt_queue_remove, file src/core/queue.c, line 135.

This may be similar to [that issue](https://github.com/genometools/genometools/issues/877) although the same solution doesn't seem to apply (here no feature appearing twice).

## Exact command line call triggering the problem

```
gt gff3 -tidy fail.gff3
```

## Example minimal input triggering the problem

[fail.gff3.txt](https://github.com/genometools/genometools/files/7204687/fail.gff3.txt)

(txt extension added for Github to accept upload)

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

Tested both with the Debian packaged version and the latest 1.6 binary.
```
gt (GenomeTools) 1.5.10
[...]

Used compiler: cc (Debian 8.2.0-8) 8.2.0
Compile flags: -g -O2 -fdebug-prefix-map=.=. -fstack-protector-strong -Wformat -Werror=format-security -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3
```

Same error with
```
/opt/gt-1.6.2-Linux_x86_64-64bit-barebone/bin/gt (GenomeTools) 1.6.2
[...]

Used compiler: cc (Ubuntu/Linaro 4.6.3-1ubuntu5) 4.6.3
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -m32 -m64 -Wno-strict-overflow -Werror
```



## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Debian 4.19.194-3 (2021-07-18) x86_64 GNU/Linux
",AlexWeinreb,https://github.com/genometools/genometools/issues/990,genometools++genometools.csv
I_kwDOAKqP_M48zEW7,illegal uppercase attribute,CLOSED,2021-10-07T13:03:18Z,2021-10-15T07:05:01Z,2021-10-15T07:05:01Z,"## Problem description
The gff3 file was produced by ltr_retriever with annotating codes. It seems that they make the sort command confused.

## Exact command line call triggering the problem
gt gff3 genome.fa.mod.pass.list.gff3 >sorted.gff3
```
## Example minimal input triggering the problem
[example.txt](https://github.com/genometools/genometools/files/7303420/example.txt)

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
1.6.2

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make with-hammer=yes threads=yes cario=no

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
GNU/Linux x86_64",BRNiu,https://github.com/genometools/genometools/issues/992,genometools++genometools.csv
I_kwDOAKqP_M49evb2,gt ltrdigest: error: invalid HMM file,OPEN,2021-10-20T14:17:47Z,2023-04-05T06:07:38Z,,"## Problem description

When I use ltrdigest in gt, an error message called ""invalid HMM file"" appeared. I checked my HMM file (HMMER2.0 [2.3.2]). Does ltrdigest only support HMMER3.0?
If I want to deal with HMMER2 files, which version of gt should I use
Thanks!

## Exact command line call triggering the problem

```

```

## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
The version of gt (GenomeTools) is 1.5.11.

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
System: Ubuntu16.0464 bit.",ZhijianZhou01,https://github.com/genometools/genometools/issues/993,genometools++genometools.csv
I_kwDOAKqP_M4-LkL_,Conda installation requires python2.7,CLOSED,2021-11-03T08:46:55Z,2022-04-02T14:02:07Z,2022-04-02T14:02:07Z,"The current bioconda package requires python2.7.*, which is increasingly incompatible with many other tools.

Example: JBrowse2 uses samtools and genometools, but the last samtools version compatible with python 2.7.* is 1.7, whereas the latest samtools version is 1.14.

What would it take to make the switch to python 3.*? I can submit a PR if wanted.",holmrenser,https://github.com/genometools/genometools/issues/994,genometools++genometools.csv
I_kwDOAKqP_M4-YYhr,Aborted (core dumped) with LTR digest,OPEN,2021-11-06T19:23:28Z,2021-12-20T21:50:33Z,,"## Problem description

While using LTRdigest this error always pops up (which also appears in R studio using ltr digest via the LTRpred package)

**This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Aborted (core dumped)**


## Exact command line call triggering the problem

```
#PATH:
proteins=""/home/omar-almulla/Downloads/""
genome=""/home/omar-almulla/Desktop/Prunus_TE_project/INPUT/genomes/""
gff3=""/home/omar-almulla/Desktop/Prunus_TE_project/OUTPUT/EDTA_outputs/20-WGS-PCE.2.0/20-WGS-PCE.2.0_shortIDs.fasta.mod.EDTA.raw/LTR/""

gt ltrdigest -hmms $proteins/Pfam-A.hmm -aaout -outfileprefix ltrs_sorted -seqfile $genome/20-WGS-PCE.2.0_shortIDs.fasta -matchdescstart < $gff3/LTR/ltrs_sorted.gff3 > ltrdigest.gff3

```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt (GenomeTools) 1.6.2
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu 20.04",omar-almolla209,https://github.com/genometools/genometools/issues/995,genometools++genometools.csv
I_kwDOAKqP_M4_2KSu,undefined reference to `fcntl64',CLOSED,2021-12-04T08:58:04Z,2021-12-04T09:14:12Z,2021-12-04T09:14:12Z,"## Problem description
Encountered problems compiling source code, `undefined reference to 'fcntl64'`

## Exact command line call triggering the problem

```
wget http://genometools.org/pub/genometools-1.6.2.tar.gztar -zxvf genometools-1.6.2.tar.gzcd genometools-1.6.2
$make threads=yes
```

## Example minimal input triggering the problem
[link gt]
/xxx/bin/../lib/gcc/x86_64-conda-linux-gnu/9.3.0/../../../../x86_64-conda-linux-gnu/bin/ld: lib/libgenometools.a(option.o): in function `gt_option_parser_manpage':
/xxx/software/genometools-1.6.2/src/core/option.c:691: undefined reference to 'fcntl64'

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
genometools-1.6.2

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
yes

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntux86_64",jingydz,https://github.com/genometools/genometools/issues/996,genometools++genometools.csv
I_kwDOAKqP_M5AyGPC,gt gff3 -sort error,CLOSED,2021-12-22T14:28:01Z,2021-12-23T14:50:21Z,2021-12-23T14:50:21Z,"## Problem description
An error occurs when issuing the sort command on my gff3 file. It seems like the gt program is classifying a single feature as a multi-feature, which leads to an error. The error is copied below: 

**gt gff3: error: the multi-feature with ID ""None"" on line 1911 in file ""input.gff3"" has a different attribute 'Parent' than its counterpart on line 1904 ('mRNA37983' vs. 'mRNA37984')**

I am fairly certain that the ID=""None"" for the CDS is causing this problem. Please let me know if there is a way within gt to circumvent this issue or if you have a suggestion for manually fixing this naming problem (if you agree that this is the cause of the error).

## Exact command line call triggering the problem

```
gt gff3 -sort input.gff3 > output.gff3
```

## Example minimal input triggering the problem
 sed -n '1898,1920p' input.gff3

arahy.BaileyII.gnm1.Scaffold_001        AUGUSTUS        CDS     891087  891632  0       -       0       ID=IDmodified-cds-105196;Parent=IDmodified-mrna-18254
arahy.BaileyII.gnm1.chr01       .       gene    2       1774    .       +       .       ID=gene35815
arahy.BaileyII.gnm1.chr01       .       mRNA    2       1774    .       +       .       ID=mRNA37984;Parent=gene35815
arahy.BaileyII.gnm1.chr01       AUGUSTUS        exon    2       421     .       +       .       ID=nbis-exon-160631;Parent=mRNA37984
arahy.BaileyII.gnm1.chr01       AUGUSTUS        exon    585     1657    .       +       .       ID=nbis-exon-160632;Parent=mRNA37984
arahy.BaileyII.gnm1.chr01       AUGUSTUS        exon    1747    1774    .       +       .       ID=nbis-exon-160633;Parent=mRNA37984
arahy.BaileyII.gnm1.chr01       AUGUSTUS        CDS     2       421     0       +       0       ID=None;Parent=mRNA37984
arahy.BaileyII.gnm1.chr01       AUGUSTUS        CDS     585     1657    1       +       0       ID=None;Parent=mRNA37984
arahy.BaileyII.gnm1.chr01       AUGUSTUS        CDS     1747    1774    1       +       1       ID=None;Parent=mRNA37984
arahy.BaileyII.gnm1.chr01       .       gene    3559    3924    .       +       .       ID=gene35814
arahy.BaileyII.gnm1.chr01       .       mRNA    3559    3924    .       +       .       ID=mRNA37983;Parent=gene35814
arahy.BaileyII.gnm1.chr01       AUGUSTUS        exon    3559    3714    .       +       .       ID=nbis-exon-160629;Parent=mRNA37983
arahy.BaileyII.gnm1.chr01       AUGUSTUS        exon    3877    3924    .       +       .       ID=nbis-exon-160630;Parent=mRNA37983
arahy.BaileyII.gnm1.chr01       AUGUSTUS        CDS     3559    3714    0       +       0       ID=None;Parent=mRNA37983
arahy.BaileyII.gnm1.chr01       AUGUSTUS        CDS     3877    3924    0       +       0       ID=None;Parent=mRNA37983
arahy.BaileyII.gnm1.chr01       .       gene    19013   20264   .       -       .       ID=gene35817
arahy.BaileyII.gnm1.chr01       .       mRNA    19013   20264   .       -       .       ID=mRNA37986;Parent=gene35817
arahy.BaileyII.gnm1.chr01       AUGUSTUS        exon    19013   19614   .       -       .       ID=nbis-exon-160636;Parent=mRNA37986
arahy.BaileyII.gnm1.chr01       AUGUSTUS        exon    19992   20043   .       -       .       ID=nbis-exon-160637;Parent=mRNA37986
arahy.BaileyII.gnm1.chr01       AUGUSTUS        exon    20127   20264   .       -       .       ID=nbis-exon-160638;Parent=mRNA37986
arahy.BaileyII.gnm1.chr01       AUGUSTUS        CDS     19013   19614   0       -       2       ID=None;Parent=mRNA37986
arahy.BaileyII.gnm1.chr01       AUGUSTUS        CDS     19992   20043   0       -       0       ID=None;Parent=mRNA37986
arahy.BaileyII.gnm1.chr01       AUGUSTUS        CDS     20127   20264   0       -       0       ID=None;Parent=mRNA37986


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
genometools/1.5.9 

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
No- provided as a module in HPC Cluster

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
CentOS",cassondranewman,https://github.com/genometools/genometools/issues/998,genometools++genometools.csv
I_kwDOAKqP_M5BJQFy,Aborted (core dumped) with LTR harvest,OPEN,2022-01-04T01:54:29Z,2022-01-05T08:27:59Z,,"## Problem description

While using LTRharvest this error pops up
```
Assertion failed: (refrng.start <= boundaries->leftLTR_5), function gt_removeoverlapswithlowersimilarity, file src/ltr/ltrharvest_stream.c, line
1222.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with `gt -version`.
Aborted (core dumped)
```
## Exact command line call triggering the problem
```
gt suffixerator -db Ps_genome.part-05.fasta  -indexname Ps_genome.part-05 -tis -suf -lcp -des -ssp -sds -dna
```
After creating the index, submit the following command
```
gt ltrharvest -index Ps_genome.part-05 -minlenltr 100 -maxlenltr 3000 -similar 80 -gff3 Ps_genome.part-05_inner.fa > Ps_genome.part-05_harvest.scn
```


## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

gt (GenomeTools) 1.6.2
Copyright (c) 2003-2016 G. Gremme, S. Steinbiss, S. Kurtz, and CONTRIBUTORS
Copyright (c) 2003-2016 Center for Bioinformatics, University of Hamburg
See LICENSE file or http://genometools.org/license.html for license details.

Used compiler: cc (GCC) 8.3.1 20191121 (Red Hat 8.3.1-5)
Compile flags:  -g -Wall -Wunused-parameter -pipe -fPIC -Wpointer-arith -Wno-unknown-pragmas -O3 -Werror


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
CentOS Linux 8 (Core)",xiaoxiaonao,https://github.com/genometools/genometools/issues/999,genometools++genometools.csv
I_kwDOAKqP_M5FO60m,Running LTRharvest/digest with parallel,CLOSED,2022-03-07T15:05:08Z,2022-09-21T09:32:51Z,2022-09-21T09:32:51Z,"Hello, here is my issue. I hope someone will be able to help me! Thanks in advance

## Problem description
Im running LTR harvest/digest and I faced some issues. 
I have over 200 species so I wanted to run several species at once. To do so I wrote a bash function to use with gnu parallel that allows to run several jobs at the same time. When I checked this morning I realised I had a lot of errors like these:

```
Error: File format problem, trying to open HMM file /tmp/198a084286222afb27419fcb9d8e6170.
Opened /tmp/198a084286222afb27419fcb9d8e6170.h3m, a pressed HMM file; but format of its .h3i file unrecognized

gt ltrdigest: error: HMMER child process terminated with error

Error: Unexpected error 7 in opening hmm file /tmp/198a084286222afb27419fcb9d8e6170.

```

I tried to run one species individually and it runs smoothly and found more data than my first parallel run. I tried again with 2 species running at the same time and got the Unexpected error 7 in opening hmm file again for one of the chromosomes. My thought is I cant run LTRharvest/digest on several species at the same time. Is there a way around that?


## Exact command line call triggering the problem

I think it's this one?
```
gt -j 2 ltrdigest -hmms ../Domains/*.hmm  -outfileprefix LTRh/${file}_LTRdigest -seqfile ${file} -matchdescstart < LTRh/${file}_LTRdigest_sorted.gff3 > LTRh/${file}_LTRdigest.gff3

```

## Example minimal input triggering the problem
Running 2 species at once

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
gt (GenomeTools) 1.6.1

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
I'm using gt on a server so I haven't installed it. But the installation is ok I think as there are no issue with doing one individual run.

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu 20.04.3 LTS (GNU/Linux 5.13.0-27-generic x86_64)",JulieDaz,https://github.com/genometools/genometools/issues/1000,genometools++genometools.csv
I_kwDOAKqP_M5F-svk,gt gff3 -sortlines fails on particular gff,CLOSED,2022-03-18T21:57:22Z,2022-05-08T18:46:53Z,2022-05-08T18:46:53Z,"Hi there
I have had great experience with gt gff3 -sortlines on many files and recommend it for jbrowse users before bgzip and tabix

However, we found a file that had an issue
[wormbase_genes.gff3.gz](https://github.com/genometools/genometools/files/8307818/wormbase_genes.gff3.gz)

This produces a file  with unsorted lines

```
$ gt gff3 -sortlines -tidy wormbase_genes.gff3 > wormbase_genes.sort.gff
/* bunch of output about non-tidy stuff */
$ bgzip wormbase_genes.sort.gff
$ tabix wormbase_genes.sort.gff.gz
[E::hts_idx_push] Unsorted positions on sequence #1: 11638470 followed by 11634613
tbx_index_build failed: wormbase_genes.sort.gff.gz

```

Looks like this when looking at file

```
I	WormBase	intron	11633660	11633701	.	-	.	Parent=mRNA3812
I	WormBase	exon	11633702	11633732	.	-	.	Parent=mRNA3812
I	WormBase	CDS	11633702	11633732	.	-	0	ID=CDS3214;Parent=mRNA3812;Name=W04G5.2a;prediction_status=Confirmed;wormpep=CE40145;protein_id=CAJ85753.1;locus=rab-11.2;uniprot_id=Q1ZXR4
I	WormBase	exon	11638470	11638491	.	-	.	Parent=nc_primary_transcript105
###
I	WormBase	CDS	11634613	11634668	.	+	0	ID=CDS3215;Parent=mRNA3813;Name=W04G5.5;prediction_status=Partially_confirmed;wormpep=CE47779;protein_id=CAB07682.4;uniprot_id=O18170
```
",cmdcolin,https://github.com/genometools/genometools/issues/1001,genometools++genometools.csv
I_kwDOAKqP_M5GsD3Z,Difficulty extracting intronic regions,CLOSED,2022-03-30T06:31:42Z,2022-05-08T22:02:44Z,2022-05-08T22:02:43Z,"## Problem description
I pulled the latest gff3 file for Zea mays from refseq (https://ftp.ncbi.nlm.nih.gov/genomes/refseq/plant/Zea_mays/annotation_releases/current/)

I tidied the file with: gt gff3 -tidy yes

I tried pulling intronic sequences with: gt interfeat -outside CDS

The error I got was: gt interfeat: error: feature on line 1048669 of 'temp2.gff3' has a different strand than the feature on line 1048667

I don't understand what I am doing wrong here.

## Exact command line call triggering the problem

```
# tidy with
gt gff3 -tidy yes -o temp2.gff3 GCF_902167145.1_Zm-B73-REFERENCE-NAM-5.0_genomic.gff
# line with error
gt interfeat -outside CDS -o output_cds_intron.gff3 temp.gff3
```

```
gt interfeat: error: feature on line 1048669 of 'temp2.gff3' has a different strand than the feature on line 1048667
```

## Example minimal input triggering the problem

```
# not tidied first
gt interfeat -outside CDS -o output_cds_intron.gff3 GCF_902167145.1_Zm-B73-REFERENCE-NAM-5.0_genomic.gff
```

```
gt interfeat: error: attribute ""replace="" on line 998141 in file ""GCF_902167145.1_Zm-B73-REFERENCE-NAM-5.0_genomic.gff"" has no value
```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

1.6.1


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

no


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Ubuntu
",kd-lab,https://github.com/genometools/genometools/issues/1002,genometools++genometools.csv
I_kwDOAKqP_M5Oahg4,"There is no -retainids when using ltrdigest, Why don't add one?",OPEN,2022-07-23T06:16:35Z,2022-07-23T10:13:02Z,,"Hi,

I found that all IDs were changed after running ltrdigest, why don't add -retainids option to retain original IDs like sort and select?

Best,
Kun
",xiekunwhy,https://github.com/genometools/genometools/issues/1007,genometools++genometools.csv
I_kwDOAKqP_M5OkgKD,We need to run tirvish two times for a single genome?,CLOSED,2022-07-26T12:45:15Z,2022-08-24T07:52:05Z,2022-08-24T07:52:05Z,"Hi,

We need to run tirvish two times for a single genome (one run for original sequence and an other run for reverse complement sequence)?
I found some describtions here (https://github.com/DerKevinRiehl/transposon_annotation_reasonaTE/blob/cc04a2db30c98f21981eb2d90710887be726bfcc/README.md), ""Please note, as some tools (HelitronScanner, MiteFinderII, MITE-Tracker, SINE-Finder, TIRvish) do not annotate on both strands, we recommend to run these on the reverse complementary as well"".

Best,
Kun",xiekunwhy,https://github.com/genometools/genometools/issues/1008,genometools++genometools.csv
I_kwDOAKqP_M5PSa9a,Install error: cairo.h: No such file or directory on RedHat 7,CLOSED,2022-08-05T18:14:52Z,2022-09-21T09:32:14Z,2022-09-21T09:32:13Z,"I downloaded `genometools-1.6.2.tar.gz` from http://genometools.org/pub/ to
my computer, a Red Hat Enterprise Linux Server 7.3 (Maipo)  Linux 3.10.0-327.4.5.el7.x86_64
Upon expand and `make`, it proceed to a point when says:
> /path/to/genometools-1.6.2/src/annotationsketch/graphics_cairo_api.h:21:19: fatal error: cairo.h: No such file or directory
> #include <cairo.h>
>                  ^
> compilation terminated.

I googled for helps and found it's mostly on other platforms; didn't find similar posted issues for RH/CentOS.

With some hits from those on Ubuntu systems, I did
> sudo yum install libXt-devel

on my system and it didn't help to resolve the issue.

Any help will be appreciated.
z.",zhilianghu,https://github.com/genometools/genometools/issues/1009,genometools++genometools.csv
I_kwDOAKqP_M5QtbV2,How to test whether the GenomeTools  library is installed properly,CLOSED,2022-08-29T10:47:23Z,2023-04-10T07:20:08Z,2023-04-10T07:20:08Z,"## Problem description
I have compiled the package on the environment, but I don't know how to test whether the library is installed properly.
![image](https://user-images.githubusercontent.com/77086644/187184511-65632565-f4e7-45f2-bc56-27299de6366d.png)

I found two directories (testdata and TestSuite), which seem to be used for testing. How do I use them?
![image](https://user-images.githubusercontent.com/77086644/187184451-e3eaae63-b561-43da-bd2f-3e58a90aac70.png)


## Exact command line call triggering the problem

```
gt ...
```

## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.


## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
",Wenmj201582,https://github.com/genometools/genometools/issues/1010,genometools++genometools.csv
I_kwDOAKqP_M5SSHJp,"After installation, how to use and test whether the function is normal?",CLOSED,2022-09-21T07:46:06Z,2023-04-05T06:04:34Z,2023-04-05T06:04:34Z,"## Problem description

Can you provide the use method or test case of the software?

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
genometools-1.5.8

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

make 64bit=no errorcheck=no cairo=no CC=clang CXX=clang++ FC=flang
## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
openEuler release 20.03 (LTS-SP3)",DaShaCHun123,https://github.com/genometools/genometools/issues/1011,genometools++genometools.csv
I_kwDOAKqP_M5U6b1k,bed_to_gff3 bug,CLOSED,2022-10-26T19:42:30Z,2022-12-13T00:11:52Z,2022-11-04T10:50:04Z,"## Problem description
a bug reminder appeared when using bed_to_gff3

## Exact command line call triggering the problem

```
gt bed_to_gff3 sorted.bed
```

## Example minimal input triggering the problem
sorted.bed
which gives this message: Assertion failed: (start <= end), function gt_feature_node_new, file src/extended/feature_node.c, line 241.
This is a bug, please report it at

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
1.6.2

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
did not use any parameters

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu 7.5.0-3ubuntu1~18.04 x86_64",yumisims,https://github.com/genometools/genometools/issues/1012,genometools++genometools.csv
I_kwDOAKqP_M5WeL-P,"error: ignoring return value of 'fwrite', declared with attribute warn_unused_result [-Werror=unused-result]",CLOSED,2022-11-16T03:10:00Z,2023-04-05T06:03:52Z,2023-04-05T06:03:52Z,"## Problem description
error while make
![1fb940933bb3ed4ac3b1331dec83abd](https://user-images.githubusercontent.com/103233242/202073669-de83fc25-2af9-443c-ad29-7b1acba303f4.png)


## Exact command line call triggering the problem
make 64bit=yes threads=yes cairo=no -j4
[create obj/gt_config.h]
[compile sqlite3.o]
[compile array.o]
[compile alphabet.o]
[compile array2dim.o]
[compile array2dim_sparse.o]
[compile array3dim.o]
[compile basename.o]
[compile bioseq.o]
[compile bioseq_col.o]
[compile bioseq_iterator.o]
[compile bitbuffer.o]
src/core/bioseq.c: In function 'construct_bioseq_files':
src/core/bioseq.c:121:18: error: ignoring return value of 'fwrite', declared with attribute warn_unused_result [-Werror=unused-result]
  121 |       if (i > 0) fwrite(buf, 1, i, tmpfile);
      |                  ^~~~~~~~~~~~~~~~~~~~~~~~~~
src/core/bitbuffer.c: In function 'gt_bitbuffer_FILE_new':
src/core/bitbuffer.c:54:12: error: ignoring return value of 'fwrite', declared with attribute warn_unused_result [-Werror=unused-result]
   54 |     (void) fwrite(&writtenbits,sizeof writtenbits,(size_t) 1,outfp);
      |            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
src/core/bitbuffer.c:55:12: error: ignoring return value of 'fwrite', declared with attribute warn_unused_result [-Werror=unused-result]
   55 |     (void) fwrite(&bitsperentry8,sizeof bitsperentry8,(size_t) 1,outfp);
      |            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
src/core/bitbuffer.c: In function 'gt_bitbuffer_generic_write_FILE':
src/core/bitbuffer.c:92:14: error: ignoring return value of 'fwrite', declared with attribute warn_unused_result [-Werror=unused-result]
   92 |       (void) fwrite(&bb->currentbitbuffer,sizeof bb->currentbitbuffer,
      |              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   93 |                     (size_t) 1,bb->fp);
      |                     ~~~~~~~~~~~~~~~~~~
src/core/bitbuffer.c: In function 'gt_bitbuffer_flush':
src/core/bitbuffer.c:230:14: error: ignoring return value of 'fwrite', declared with attribute warn_unused_result [-Werror=unused-result]
  230 |       (void) fwrite(&bb->currentbitbuffer,
      |              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  231 |                     sizeof bb->currentbitbuffer,
      |                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  232 |                     (size_t) 1,bb->fp);
      |                     ~~~~~~~~~~~~~~~~~~
src/core/bitbuffer.c:237:16: error: ignoring return value of 'fwrite', declared with attribute warn_unused_result [-Werror=unused-result]
  237 |         (void) fwrite(&writtenbits,sizeof writtenbits,(size_t) 1,bb->fp);
      |                ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
[compile bitpackstringop.o]
cc1: all warnings being treated as errors
make: *** [Makefile:823: obj/src/core/bitbuffer.o] Error 1
make: *** Waiting for unfinished jobs....
cc1: all warnings being treated as errors
make: *** [Makefile:823: obj/src/core/bioseq.o] Error 1




## Example minimal input triggering the problem
make 64bit=yes threads=yes cairo=no -j4

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
1.6.2

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make 64bit=yes threads=yes cairo=no -j4

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
CentOS Linux release 7.2.1511  x86_64",ShirelyI,https://github.com/genometools/genometools/issues/1016,genometools++genometools.csv
I_kwDOAKqP_M5gjpub,LtrPipeline: GenomeTools failed to run ltrharvest. Error code: 139,CLOSED,2023-03-11T10:22:07Z,2023-03-11T11:40:22Z,2023-03-11T11:40:22Z,"![image](https://user-images.githubusercontent.com/126332368/224478895-fc6279b5-824b-4e72-991a-b1224225e1c4.png)
Hello,
Does anyone know how to fix this problem? Any help would be greatly appreciated.
",panpandzf,https://github.com/genometools/genometools/issues/1018,genometools++genometools.csv
I_kwDOAKqP_M5hbbQw,"gff3validator ""Sequence Ontology"" out of date?",CLOSED,2023-03-21T19:35:49Z,2023-03-22T14:08:28Z,2023-03-22T14:08:28Z,"## Problem description

The support team of the Saccharomyces Genome Database just wrote to me: ""Our current GFF3 file can be found here: https://sgd-prod-upload.s3.amazonaws.com/S000342616/saccharomyces_cerevisiae.20230315.gff.gz"".

I tried to validate this GFF with http://genometools.org/cgi-bin/gff3validator.cgi, but am getting the validation error:

```
Validation unsuccessful!

GenomeTools error: type ""uORF"" on line 164 in file ""/var/www/servers/genometools.org/htdocs/cgi-bin/gff3/saccharomyces_cerevisiae.20230315.gff"" is not a valid one
```

However, it looks like this is a valid Sequence Ontology term that was added in 2014:

https://github.com/The-Sequence-Ontology/SO-Ontologies/blob/07b30b453295147efa9f9f8c017907cd147fcaa9/Ontology_Files/so.obo#L18966-L18975

The gff3validator webpage also says ""Last update: 2015-01-25"", while the Sequence Ontology has received updates since then (although they don't seem to have (many) versioned releases: https://github.com/The-Sequence-Ontology/SO-Ontologies/issues/606 ). Could the online gff3validator be updated with a current copy of the Sequence Ontology?

## Exact command line call triggering the problem

N/A

## Example minimal input triggering the problem

- Download and extract https://sgd-prod-upload.s3.amazonaws.com/S000342616/saccharomyces_cerevisiae.20230315.gff.gz
- Validate the extracted saccharomyces_cerevisiae.20230315.gff file with http://genometools.org/cgi-bin/gff3validator.cgi with default settings

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

GFF3 online validator
Last update: 2015-01-25 

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

N/A

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

N/A
",rzelle-lallemand,https://github.com/genometools/genometools/issues/1019,genometools++genometools.csv
I_kwDOAKqP_M5iljso,Assertion error: gt_feature_node_remove_leaf,CLOSED,2023-04-04T14:32:35Z,2023-04-10T07:19:32Z,2023-04-10T07:19:32Z,"## Problem description
We have a lua script that utilises a gt.custom_stream_new_unsorted stream to iterate through feature nodes and their children. For the following gene and its mRNA children
![image](https://user-images.githubusercontent.com/11962461/229821419-d7207a97-87a8-4ee9-8640-d31b93ac9a19.png)
where c = mRNA3712 and cur_gene = gene3645, the below ""Exact command line call"" raises the following assertion error

> Assertion failed: (gt_feature_node_number_of_children(leafn) == 0), function gt_feature_node_remove_leaf, file src/extended/feature_node.c, line 1153.
This is a bug, please report it at
https://github.com/genometools/genometools/issues
Please make sure you are running the latest release which can be found at
http://genometools.org/pub/
You can check your version number with gt -version.
Aborted (core dumped)

It appears that the presence of a second mRNA transcript child of the gene is failing this assertion (because gt_feature_node_number_of_children(leafn) == 1 after mRNA3712 is removed). Is this a correct assumption? If so, is there a reason for this assertion to exist in light of alternative spliced genomes?

## Exact command line call triggering the problem

```
cur_gene:remove_leaf(c)
```

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
1.6.1

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
No

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Ubuntu 20.04",haessar,https://github.com/genometools/genometools/issues/1020,genometools++genometools.csv
I_kwDOAKqP_M5jPrPB,gt gff3 loss of intergenic regions,OPEN,2023-04-12T18:34:50Z,2023-04-16T10:03:04Z,,"I am interested in adding introns in my genome annotation mygenome.gff3. 
After running the command below, I obtain an output genome_with_introns.gff3 in which there is no ""intergenic_region"" annotation anymore.
Is there something I'm not considering, that would help me solving this issue?

**mygenome.gff3**
```
##gff-version 3
##sequence-region chr_00 1 18946431
chr_00	assembly	sequence_assembly	1	18946431	.	+	.	ID=chr_00;Ontology_term=SO:0000353
chr_00	ORCAE	intergenic_region	1	149	.	.	.	ID=inter:first;Name=first;Ontology_term=SO:0000605
chr_00	ORCAE	gene	150	6731	.	-	.	ID=Ec-00_000010;Name=Ec-00_000010;Alias=Esi_1000_0001,Esi1000_0001;length=6582
chr_00	ORCAE	mRNA	150	6731	.	-	.	ID=Ec-00_000010.1;Parent=Ec-00_000010;gene_id=Ec-00_000010.1;Name=Ec-00_000010.1;Alias=Esi_1000_0001,Esi1000_0001;length=1971
chr_00	ORCAE	exon	150	428	.	-	.	ID=Ec-00_000010.1.10;Parent=Ec-00_000010.1;gene_id=Ec-00_000010.1;Ontology_term=SO:0000202
chr_00	ORCAE	exon	898	1100	.	-	.	ID=Ec-00_000010.1.9;Parent=Ec-00_000010.1;gene_id=Ec-00_000010.1;Ontology_term=SO:0000004
chr_00	ORCAE	exon	1536	1674	.	-	.	ID=Ec-00_000010.1.8;Parent=Ec-00_000010.1;gene_id=Ec-00_000010.1;Ontology_term=SO:0000004
chr_00	ORCAE	exon	2092	2268	.	-	.	ID=Ec-00_000010.1.7;Parent=Ec-00_000010.1;gene_id=Ec-00_000010.1;Ontology_term=SO:0000004
```
**my command**
```
gt gff3 -retainids -addintrons my_genome.gff3  > my_genome_with_introns.gff3
```

**genome_with_introns.gff3**
```
chr_00  ORCAE   gene    150     6731    .       -       .       ID=Ec-00_000010;Name=Ec-00_000010;Alias=Esi_1000_0001,Esi1000_0001;length=6582
chr_00  ORCAE   mRNA    150     6731    .       -       .       ID=Ec-00_000010.1;Parent=Ec-00_000010;gene_id=Ec-00_000010.1;Name=Ec-00_000010.1;Alias=Esi_1000_0001,Esi1000_0001;length=1971
chr_00  ORCAE   exon    150     428     .       -       .       ID=Ec-00_000010.1.10;Parent=Ec-00_000010.1;gene_id=Ec-00_000010.1;Ontology_term=SO:0000202
chr_00  ORCAE   CDS     150     428     .       -       0       ID=CDS:Ec-00_000010.1;Parent=Ec-00_000010.1;gene_id=Ec-00_000010.1;Name=Ec-00_000010.1;Ontology_term=SO:0000202
chr_00  .       intron  429     897     .       -       .       Parent=Ec-00_000010.1
chr_00  ORCAE   exon    898     1100    .       -       .       ID=Ec-00_000010.1.9;Parent=Ec-00_000010.1;gene_id=Ec-00_000010.1;Ontology_term=SO:0000004
chr_00  ORCAE   CDS     898     1100    .       -       2       ID=CDS:Ec-00_000010.1;Parent=Ec-00_000010.1;gene_id=Ec-00_000010.1;Name=Ec-00_000010.1;Ontology_term=SO:0000004
chr_00  .       intron  1101    1535    .       -       .       Parent=Ec-00_000010.1
chr_00  ORCAE   exon    1536    1674    .       -       .       ID=Ec-00_000010.1.8;Parent=Ec-00_000010.1;gene_id=Ec-00_000010.1;Ontology_term=SO:0000004
```
gt -version 1.6.1
Linux x86_64
",edinatale,https://github.com/genometools/genometools/issues/1022,genometools++genometools.csv
I_kwDOAKqP_M5lue-y,sketch all non-overlapping genes on one track,CLOSED,2023-05-11T23:08:13Z,2023-05-14T08:25:05Z,2023-05-14T08:25:05Z,"## Problem description
I want to sketch all non-overlapping genes on one track. But it generates genes on three tracks.

## Exact command line call triggering the problem
gt sketch -format png output.png NC0130412.gff3

```
gt ...
```

##  NC0130412.gff3
##gff-version   3
##sequence-region foo 1 120000
foo     gth1    bibi    1       3579    .       +       .       ID=orf1
foo     gth1    bibi    4423    27223   .       +       .       ID=orf2
foo     gth1    bibi    28503   29811   .       +       .       ID=orf3
foo     gth1    bibi    30062   30427   .       +       .       ID=orf4
foo     gth1    bibi    30668   31633   .       -       .       ID=orf5
foo     gth1    bibi    109381  109980  .       +       .       ID=orf6
foo     gth1    bibi    110488  111174  .       +       .       ID=orf7
foo     gth1    bibi    111576  112682  .       +       .       ID=orf8
foo     gth1    bibi    112767  113663  .       -       .       ID=orf9


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)? 
gt (GenomeTools) 1.6.2

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
apt-get install genometools (https://github.com/genometools/genometools)

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

Distributor ID: Ubuntu
Description:    Ubuntu 20.04.5 LTS
Release:        20.04
Codename:       focal
",paristzou,https://github.com/genometools/genometools/issues/1023,genometools++genometools.csv
I_kwDOAKqP_M5mTtY2,-Werror is for CI + developer only,CLOSED,2023-05-19T00:34:17Z,2023-09-19T12:31:47Z,2023-09-19T12:31:47Z,"## Problem description
`-Werror` is enabled by default. You shouldn't cause issues for users that use a compiler that detects other things than you.
They are warnings by default for a reason, and while I sympathize that you try to have a code without warnings, it is unreasonable to expect compilers not to add new warnings.


## Exact command line call triggering the problem
```
make
```

## Example minimal input triggering the problem
Running any fedora, even the oldest supported one, has a to recent compiler to not detect potential errors in the code.

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?
v1.6.2

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
N/A

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
Fedora 36 on x86_64
gcc (GCC) 12.3.1 20230508 (Red Hat 12.3.1-1)",dschwoerer,https://github.com/genometools/genometools/issues/1024,genometools++genometools.csv
I_kwDOAKqP_M5vma_s,Fails to build on macOS Ventura / Xcode 14.x,CLOSED,2023-08-29T20:05:37Z,2023-09-11T07:36:53Z,2023-09-10T20:05:48Z,"## Problem description

genometools 1.6.2 fails to build on macOS Ventura (Intel) with Xcode 14.x, see below.

## Exact command line call triggering the problem

N/A

## Example minimal input triggering the problem

N/A

## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?

1.6.2

## Did you compile GenomeTools from source? If so, please state the `make` parameters used.

Yes. Just setting the prefix. See https://github.com/Homebrew/homebrew-core/blob/master/Formula/g/genometools.rb

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?

MacOS Ventura, but I think it's a more general issue with Xcode 14.x. Issue found on Intel Ventura.

```
[link libgenometools.a]
ar: creating archive lib/libgenometools.a
[link libbz2.a]
[link libz.a]
ar: creating archive lib/libbz2.a
ar: creating archive lib/libz.a
[link libgenometools.dylib]
[link gt]
[link custom_stream]
[link gff3sort]
[link gff3validator]
[link sketch_constructed]
[link noop]
[link sketch_parsed_with_ctrack]
[link sketch_parsed_with_ordering]
[link sketch_parsed]
ld: in lib/libgenometools.a(libsqlite.a), archive member 'libsqlite.a' with length 886432 is not mach-o or llvm bitcode file 'lib/libgenometools.a' for architecture x86_64
ld: in lib/libgenometools.a(libsqlite.a), archive member 'libsqlite.a' with length 886432 is not mach-o or llvm bitcode file 'lib/libgenometools.a' for architecture x86_64
ld: in lib/libgenometools.a(libsqlite.a), archive member 'libsqlite.a' with length 886432 is not mach-o or llvm bitcode file 'lib/libgenometools.a' for architecture x86_64
ld: in lib/libgenometools.a(libsqlite.a), archive member 'libsqlite.a' with length 886432 is not mach-o or llvm bitcode file 'lib/libgenometools.a' for architecture x86_64
ld: in lib/libgenometools.a(libsqlite.a), archive member 'libsqlite.a' with length 886432 is not mach-o or llvm bitcode file 'lib/libgenometools.a' for architecture x86_64
ld: in lib/libgenometools.a(libsqlite.a), archive member 'libsqlite.a' with length 886432 is not mach-o or llvm bitcode file 'lib/libgenometools.a' for architecture x86_64
ld: in lib/libgenometools.a(libsqlite.a), archive member 'libsqlite.a' with length 886432 is not mach-o or llvm bitcode file 'lib/libgenometools.a' for architecture x86_64
ld: in lib/libgenometools.a(libsqlite.a), archive member 'libsqlite.a' with length 886432 is not mach-o or llvm bitcode file 'lib/libgenometools.a' for architecture x86_64
ld: in lib/libgenometools.a(libsqlite.a), archive member 'libsqlite.a' with length 886432 is not mach-o or llvm bitcode file 'lib/libgenometools.a' for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
clang: error: linker command failed with exit code 1 (use -v to see invocation)
clang: error: linker command failed with exit code 1 (use -v to see invocation)
clang: error: linker command failed with exit code 1 (use -v to see invocation)
clang: error: linker command failed with exit code 1 (use -v to see invocation)
clang: error: linker command failed with exit code 1 (use -v to see invocation)
clang: error: linker command failed with exit code 1 (use -v to see invocation)
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *** [bin/examples/sketch_parsed_with_ordering] Error 1
make: *** Waiting for unfinished jobs....
make: *** [bin/examples/sketch_constructed] Error 1
make: *** [bin/examples/sketch_parsed_with_ctrack] Error 1
make: *** [bin/examples/gff3sort] Error 1
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *** [bin/examples/sketch_parsed] Error 1
make: *** [bin/gt] Error 1
make: *** [bin/examples/noop] Error 1
make: *** [bin/examples/gff3validator] Error 1
make: *** [bin/examples/custom_stream] Error 1
/usr/bin/env /usr/local/Homebrew/Library/Homebrew/shims/shared/git --version
/usr/bin/env /usr/local/Homebrew/Library/Homebrew/shims/shared/curl --version
/usr/local/Homebrew/Library/Homebrew/ignorable.rb:29:in `block in raise'
BuildError: Failed executing: make prefix=/usr/local/Cellar/genometools/1.6.2_1
```
",iMichka,https://github.com/genometools/genometools/issues/1025,genometools++genometools.csv
I_kwDOAKqP_M5y6y8t,New build warnings on GCC 13 turned errors are blocking builds,CLOSED,2023-10-05T11:05:38Z,2023-11-06T08:28:10Z,2023-11-06T08:28:09Z,"## Problem description

Debian testing has apparently introduced a new compiler version that does new static checks, causing builds to fail due to warnings: https://github.com/genometools/genometools/actions/runs/6418106818/job/17425238068

We need to address those by fixing them in the code. Users should not be impacted since we now skip these warnings by default instead of making them errors.
",satta,https://github.com/genometools/genometools/issues/1030,genometools++genometools.csv
I_kwDOAKqP_M6A4rAD,Build time issue with GenomeTools 1.5.9,CLOSED,2024-03-01T00:43:12Z,2024-03-03T07:41:04Z,2024-03-03T07:41:04Z,"              Also why is your software depending on that old version? That build time issue (which I guess w as caused by using a newer compiler version) was likely fixed in a later version.

_Originally posted by @satta in https://github.com/genometools/genometools/issues/983#issuecomment-1971210807_
            ",yuwanziaaa,https://github.com/genometools/genometools/issues/1038,genometools++genometools.csv
I_kwDOAKqP_M6TN6vP,fatal error: pango/pangocairo.h: No such file or directory,CLOSED,2024-08-16T09:39:05Z,2024-08-19T08:37:31Z,2024-08-19T08:37:31Z,"## Problem description
Many library can not be found in make.

## Exact command line call triggering the problem

```
gt ...
```

## Example minimal input triggering the problem


## What GenomeTools version are you reporting an issue for (as output by `gt -version`)?


## Did you compile GenomeTools from source? If so, please state the `make` parameters used.
make -j4

## What operating system (e.g. Ubuntu, Mac OS X), OS version (e.g. 15.10, 10.11) and platform (e.g. x86_64) are you using?
ubuntu 20.04",ruoyu1123,https://github.com/genometools/genometools/issues/1039,genometools++genometools.csv
MDU6SXNzdWUxNjM1MTAyNjc=,GFF and PTT parsers confused,OPEN,2016-07-02T09:23:03Z,2016-07-02T09:23:03Z,,"The enclosed GFF file is confused by the parser detection as PTT rather than GFF.

The cause is the double dot in the identifier of the contig.

[reproduce.zip](https://github.com/AbeelLab/genomeview/files/344475/reproduce.zip)
",thomasabeel,https://github.com/GenomeView/genomeview/issues/1,GenomeView++genomeview.csv
MDU6SXNzdWUzNTU1MjMxNjc=,All features from a BED file show as 'CDS' after tabbix indexing,OPEN,2018-08-30T10:28:49Z,2018-09-03T08:36:56Z,,"Compressed BED file with `bgzip `   
Indexing:   
```
tabbix -S 1 -p bed bed_file.gzip
```
All features will now be labeled as ""CDS"" instead of with the trackname or filename.

Uncompressed BED files will be shown correctly.",thpar,https://github.com/GenomeView/genomeview/issues/4,GenomeView++genomeview.csv
I_kwDOAxda1c5VOHDI,maf genome position ,OPEN,2022-10-31T12:25:38Z,2022-11-11T08:14:14Z,,"Hi, thanks for providing this useful tool.
It seems a small bug in genome position of maf
```
##maf version=1 
a score=262.0
s Xenopus_tropicalis.chr5           29721 13 + 164033575 CCCCCCGTTTGTT
s Ambystoma_mexicana.chr8q      150634379 13 + 886375962 TAATTCCTTTCTC
s Andrias_davidianus.ptg000471l   1972369 13 +   2026336 CCTTCTGCTTTCC
s Hynobius_yiwuensis.Contig128   31709499 13 -  45235456 CTTTTTAATTTCC
```
The corresponding result is 
![image](https://user-images.githubusercontent.com/38097726/199006968-e9815bf0-b549-4dca-9a1d-d5fd4fc192dd.png)

For example, the genomic position of Xenopus tropicalis should be 29722~29734 (13 bp).
",AlisaGU,https://github.com/GenomeView/genomeview/issues/6,GenomeView++genomeview.csv
I_kwDOIIKMPc5obV2B,Test run,OPEN,2023-06-12T06:29:13Z,2023-06-13T10:19:04Z,,"Hi,

Thanks for putting this together.
I'm following your example to do a test run, with one of my own genomes. I got the following error:

```
mamba activate genomeAnnotationPipeline

OUT_DIR=""/home/gnii0001/07_dsm/result/euk_annotation""
cd /home/gnii0001/tools/genomeAnnotationPipeline

snakemake -p -n -j 20 \
    --config sample_sheet=/home/gnii0001/07_dsm/074_merged/script/metadata/sample_sheet.txt \
             genemark_tar_gz=/home/gnii0001/tools/gmes/gmes_linux_64_4.tar.gz \
    -d $OUT_DIR
   
Building DAG of jobs...
MissingInputException in rule galba_run in file /fs04/rp24/gaofeng/tools/genomeAnnotationPipeline/workflows/galba.smk, line 36:
Missing input files for rule galba_run:
    output: Ophryoscolex caudatus/galba/augustus.hints.gff3, Ophryoscolex caudatus/galba/augustus.hints.aa
    wildcards: genome_id=Ophryoscolex caudatus
    affected files:
        /fs04/pc77/scratch_nobackup/gaofeng/07_dsm/result/euk_annotation/""""
```

I think I'm not fully understanding how the `sample_sheet.txt` file should be formatted. In my case, I have the genomic sequence, and species name being `Ophryoscolex caudatus`, and I don't have a reference proteome. Could you suggest how to proceed?
Attaching my sample_sheet
[sample_sheet.txt](https://github.com/glaParaBio/genomeAnnotationPipeline/files/11718724/sample_sheet.txt)

Many thanks!

Ps. previously I filled reference_proteome as NA, but it ran into the following issue, and therefore I used `""""` to circumvent that.
```
Building DAG of jobs...
InputFunctionException in rule galba_run in file /fs04/rp24/gaofeng/tools/genomeAnnotationPipeline/workflows/galba.smk, line 36:
Error:
  TypeError: expected str, bytes or os.PathLike object, not float64
Wildcards:
  genome_id=Ophryoscolex caudatus
Traceback:
  File ""/fs04/rp24/gaofeng/tools/genomeAnnotationPipeline/workflows/galba.smk"", line 41, in <lambda>
  File ""<frozen posixpath>"", line 398, in abspath
```",ganiatgithub,https://github.com/glaParaBio/genomeAnnotationPipeline/issues/2,glaParaBio++genomeAnnotationPipeline.csv
I_kwDODnzFQM5Ewkik,Python script not found,OPEN,2022-02-28T03:34:07Z,2022-02-28T11:07:58Z,,"Hello,

I am having issues running your analysis steps.
When running Analysis (~/CpGoe/1_Count_CpGoe.ipynb), you used part of a python script (~/dn_ds/Dn_Ds_CodeML.ipynb) to extract the longest CDS per gene, so I looked for it.
However, I could not find that python script.

Perhaps it is because the version of the directory is newer.

Where can I find the original python script?

Thank you.
Guillem Ylla",Ryuto-sanno,https://github.com/guillemylla/Crickets_Genome_Annotation/issues/2,guillemylla++Crickets_Genome_Annotation.csv
I_kwDOECJc2M5Ft_A_,Source code of filterBam-zlib-ng-2,CLOSED,2022-03-15T13:33:28Z,2022-06-28T11:25:53Z,2022-06-28T11:25:53Z,"Hi,

I am now filtering a large bam file, I found that filterBam cost me a long time to run. Do you want to public the source code of filterBam-zlib-ng-2 ?

Best,
Kun",xiekunwhy,https://github.com/harvardinformatics/GenomeAnnotation/issues/1,harvardinformatics++GenomeAnnotation.csv
I_kwDOECJc2M5UDCWh,Singularity Images,CLOSED,2022-10-15T07:40:23Z,2022-10-16T03:00:43Z,2022-10-16T03:00:43Z,"Hello, I was wondering at what point you were thinking of adding singularity images to this repo. 

I'm especially interested in the one for MAKER since I'm currently annotating some genomes and hoping to use it.",shjenkins94,https://github.com/harvardinformatics/GenomeAnnotation/issues/5,harvardinformatics++GenomeAnnotation.csv
I_kwDOECJc2M5ZyEBd,How to use this pipeline,CLOSED,2022-12-21T13:26:29Z,2024-04-10T14:03:35Z,2024-04-10T14:03:35Z,"Dear authors,

Thank you for your great contribution for this remarkable genome annotation pipeline!

Since there is no other genomeAnnotation pipeline people can follow, your great work means a lot for everyone like me who is new to this area. Although I read your wiki, I still don't know how to use or follow this pipeline. Should I install the related softwares one by one? Could you write a guideline or usage for this pipeline?

Merry Xmas!",lifan18,https://github.com/harvardinformatics/GenomeAnnotation/issues/6,harvardinformatics++GenomeAnnotation.csv
I_kwDOECJc2M6g7H2k,Running workflow using RefSeq genomes instead of Ensembl,OPEN,2024-11-27T21:17:38Z,2024-11-27T21:17:38Z,,"Great for your workflow, really useful guide to perform Genome Annotation.
Unfortunately, I got stuck in the step `4c. Create CDS-only annotation bed file`, because I only obtain empty files. I think that I know the reason, so here is my hypothesis.

I'm using genomes from `RefSeq`, and so far in a lot of examples, if not all, I found that the genome annotation relies on genomes from `Ensembl`, which of course have another notation related to the IDs.

So, I started running the script `WriteChromLengthBedFromFasta.py`, using a `*_genomic.fna` file from the following [link](https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/020/171/115/GCF_020171115.1_ASM_NN_V1/). For example, that file only contains a fasta file with the sequence of chromosome 1. After the conversion, my new `bed` file looks like this:
```
NC_000001.11	0	248956422
NT_187361.1	0	175055
NT_187362.1	0	32032
NT_187363.1	0	127682
NT_187364.1	0	66860
NT_187365.1	0	40176
NT_187366.1	0	42210
NT_187367.1	0	176043
NT_187368.1	0	40745
NT_187369.1	0	41717
```
The second column contains only **0**. This output made me understand that at some point I got an empty file because the information was incorrect, why I say that?, because other examples available contain **0 and other numbers**, so my question is:

- What do you think is happening? 
- Did anyone try to run this with RefSeq genomes too?
- Do I need to use another `.fna` file?

I really want to avoid changing to `Ensembl` genomes, because I had a lot of work already done with `RefSeq` data.
Any comment about what could be the source of the issue is more than welcome!",MauriAndresMU1313,https://github.com/harvardinformatics/GenomeAnnotation/issues/10,harvardinformatics++GenomeAnnotation.csv
I_kwDOGE43C85JHNYb,DATA unavailable,OPEN,2022-05-05T12:46:28Z,2024-03-17T06:43:00Z,,"Dear Dr. Yin
    I am a postgraduate from Hainan University. I am very honored to read the Camellia oleifera genome article recently published by your research groupwhich has greatly promoted the progress of its research. HoweverI could not download the data CON_genome_assembly_V1.0_final.zip even using ""git-lfs"". Is the data invalidCould you please re-upload this data

   Best whishes
                                                                                                                                                                                                      Sincerely
                                                                                                                                                                                                     Zheng Wei",1997Wei,https://github.com/Hengfu-Yin/CON_genome_data/issues/1,Hengfu-Yin++CON_genome_data.csv
MDU6SXNzdWU0Mjc3MDM3MzA=,error: -db_soft_mask 40,CLOSED,2019-04-01T13:24:58Z,2019-04-11T06:45:40Z,2019-04-11T06:45:40Z,"Process: makeblastdb

""Error: [makeblastdb] No sequences matched any of the masks provided.
Please ensure that the -parse_seqids option is used in the filtering program as well as makeblastdb. ""

Consequently the files .naa, .nab, .nac are not created.

Might be an issue with the version of blast+ used by repeatmasker",MontseTor,https://github.com/ikmb-denbi/genome-annotation/issues/4,ikmb-denbi++genome-annotation.csv
MDU6SXNzdWU0Mjc3MDY3MDc=,"if reads==false, trinity==false",CLOSED,2019-04-01T13:30:39Z,2019-04-11T06:45:05Z,2019-04-11T06:45:05Z,"""Trinity_exonerate_hints"" doesnt exist when reads==true and trinity==false. 

Should add condition: if no reads, trinity=false. Also will avoid the error at the start when trinity is not manually set to ""false"" but there are no hints.",MontseTor,https://github.com/ikmb-denbi/genome-annotation/issues/5,ikmb-denbi++genome-annotation.csv
MDU6SXNzdWU0Mjc3MDgwNTk=,blast2exonerate_targets.pl bit score,CLOSED,2019-04-01T13:33:20Z,2019-04-11T06:44:44Z,2019-04-11T06:44:44Z,"Usage says bit score threshold default is 50, code says 25.

Additionally, can it be set by the user?",MontseTor,https://github.com/ikmb-denbi/genome-annotation/issues/6,ikmb-denbi++genome-annotation.csv
MDU6SXNzdWU0Mjc3MDg0MTU=,Fully check singularity support,CLOSED,2019-04-01T13:34:01Z,2019-04-11T06:44:03Z,2019-04-11T06:44:02Z,We are having an issue where the scripts in /bin are not properly picked up for some reason when running in singularity,MontseTor,https://github.com/ikmb-denbi/genome-annotation/issues/7,ikmb-denbi++genome-annotation.csv
MDU6SXNzdWU0Mjc3MDg1ODM=,Fix the merging of hints files ,CLOSED,2019-04-01T13:34:22Z,2019-04-11T10:33:25Z,2019-04-11T10:33:25Z,"Empty hint files emit ""false"" that gets around my current check and then gets printed into the final file",MontseTor,https://github.com/ikmb-denbi/genome-annotation/issues/8,ikmb-denbi++genome-annotation.csv
MDU6SXNzdWU0Mjc3MDk0NTk=,Possible additions,OPEN,2019-04-01T13:36:01Z,2019-04-24T08:18:49Z,,"- [ ] Randomize scaffolds to split chunks of similar sizes

- [ ] Add PASA mapping for transcriptome

- [ ] Add re-training step

- [ ] Add functional annotation (only blast)",MontseTor,https://github.com/ikmb-denbi/genome-annotation/issues/9,ikmb-denbi++genome-annotation.csv
MDU6SXNzdWU0Mjc3Mjk2MzM=,Every process can be ignored,CLOSED,2019-04-01T14:13:52Z,2019-04-17T14:25:38Z,2019-04-17T14:25:38Z,We should allow the user to skip every single process.,MontseTor,https://github.com/ikmb-denbi/genome-annotation/issues/10,ikmb-denbi++genome-annotation.csv
MDU6SXNzdWU0Mjc3Mjk5MTU=,User provided hint files,OPEN,2019-04-01T14:14:22Z,2019-04-01T14:14:22Z,,Accept additional Hints file provided by the user,MontseTor,https://github.com/ikmb-denbi/genome-annotation/issues/11,ikmb-denbi++genome-annotation.csv
I_kwDOFpcvm85LYoXO,ABRicate table gets only first sample of batch,OPEN,2022-06-08T13:24:40Z,2022-06-08T13:24:40Z,,,domenico-simone,https://github.com/IZSPB-molbio/genome_assembly_pipeline/issues/1,IZSPB-molbio++genome_assembly_pipeline.csv
I_kwDOFpcvm85Ssjfz,Analyses to add,OPEN,2022-09-27T09:15:06Z,2022-09-28T15:07:52Z,,"rMLST
~~CheckM~~",domenico-simone,https://github.com/IZSPB-molbio/genome_assembly_pipeline/issues/2,IZSPB-molbio++genome_assembly_pipeline.csv
I_kwDOFpcvm85V1qS5,Failed analyses for single simples make collating fail,OPEN,2022-11-08T12:46:00Z,2022-11-08T13:00:49Z,,,domenico-simone,https://github.com/IZSPB-molbio/genome_assembly_pipeline/issues/3,IZSPB-molbio++genome_assembly_pipeline.csv
I_kwDOFpcvm85V8aK3,Test FastMLST,OPEN,2022-11-09T11:11:33Z,2022-11-09T11:11:33Z,,https://github.com/EnzoAndree/FastMLST ,domenico-simone,https://github.com/IZSPB-molbio/genome_assembly_pipeline/issues/4,IZSPB-molbio++genome_assembly_pipeline.csv
I_kwDOHZqK9s5SDscn,location of raw data,OPEN,2022-09-17T07:54:26Z,2022-09-17T07:54:26Z,,"The readme says the raw data is located at https://github.com/human-pangenomics/hpgp-data under HG00621. However, I don't see any data for HG00621 there. Can you help me find it?
aws --no-sign-request s3 ls s3://human-pangenomics/NHGRI_UCSC_panel/
                           PRE HG001/
                           PRE HG002/
                           PRE HG003/
                           PRE HG004/
                           PRE HG005/
                           PRE HG006/
                           PRE HG007/
                           PRE HG00733/
                           PRE HG01107/
                           PRE HG01108/
                           PRE HG01109/
                           PRE HG01241/
                           PRE HG01242/
                           PRE HG01243/
                           PRE HG01440/
                           PRE HG01441/
                           PRE HG01442/
                           PRE HG02053/
                           PRE HG02054/
                           PRE HG02055/
                           PRE HG02080/
                           PRE HG02081/
                           PRE HG02082/
                           PRE HG02107/
                           PRE HG02108/
                           PRE HG02109/
                           PRE HG02143/
                           PRE HG02144/
                           PRE HG02145/
                           PRE HG02721/
                           PRE HG02722/
                           PRE HG02723/
                           PRE HG03096/
                           PRE HG03097/
                           PRE HG03098/
                           PRE HG03490/
                           PRE HG03491/
                           PRE HG03492",droeatumn,https://github.com/JHUCCB/ChineseHanSouthGenome/issues/1,JHUCCB++ChineseHanSouthGenome.csv
MDU6SXNzdWU3MjA0NjUxMzc=,ab initio   Training ,OPEN,2020-10-13T15:57:55Z,2020-10-13T15:57:55Z,,"hello, thank you for your software. I have a question. I have 9  genomes  come from  a   same  specie.,it is a huge job. For SNAP Training, can I use only one scaffold to Train three times ,not the all genome fasta file? Then use the hmm file to annotation the all genome. Is it OK?
wish your help.thank you",,https://github.com/Joseph7e/MAKER-genome-annotations-tutorial/issues/1,Joseph7e++MAKER-genome-annotations-tutorial.csv
MDU6SXNzdWUxNjcxNTcyMDE=,Typo in kbase.yml owners,CLOSED,2016-07-23T00:41:22Z,2016-08-02T16:49:34Z,2016-08-02T16:49:34Z,"@scanon: Mike is written as ""mseddon"" here: https://github.com/kbase/genome_annotation_api/blob/master/kbase.yml#L14
",rsutormin,https://github.com/kbase/genome_annotation_api/issues/1,kbase++genome_annotation_api.csv
MDU6SXNzdWUxNzMwNzc1MDE=,Type inconsistency for Feature_data.feature_quality_score field,OPEN,2016-08-24T22:56:51Z,2016-08-24T23:09:00Z,,"This is where it's declared:
https://github.com/kbase/genome_annotation_api/blob/master/GenomeAnnotationAPI.spec#L113
It looks like data API returns string instead of list<string> for this field in some features (for instance when CDS features are requested for genome kbasetest:1466036531200/3702_Ensembl_chr2_genome_legacy, ref=8020/60/1 in CI).
Java client breaks with message:

```
com.fasterxml.jackson.databind.JsonMappingException: Can not deserialize instance of java.util.ArrayList out of VALUE_STRING token
 at [Source: us.kbase.common.service.JsonClientCaller$UnclosableInputStream@787582d3; line: 1, column: 2028] (through reference chain: us.kbase.common.service.JobState[""result""]->genomeannotationapi.GenomeAnnotationData[""feature_by_id_by_type""]->genomeannotationapi.FeatureData[""feature_quality_score""])
```
",rsutormin,https://github.com/kbase/genome_annotation_api/issues/11,kbase++genome_annotation_api.csv
MDU6SXNzdWUxNzMwNzkxNjE=,Type inconsistency for Summary_data,OPEN,2016-08-24T23:08:00Z,2016-08-24T23:21:20Z,,"Defined here:
https://github.com/kbase/genome_annotation_api/blob/master/GenomeAnnotationAPI.spec#L150-L187

Data API get_summary function returns value with different structure which looks like:

```
{
    annotation : {
        external_source=Genbank, 
        release=annotation release is not present, 
        external_source_date=10-JUN-2013, 
        feature_type_counts={gene=4418, CDS=4418}, 
        original_source_filename=genome.gbk
    }, 
    assembly : {
        assembly_source_id=genome.1_2016_08_18_17_47_36.fa, 
        assembly_source=Genbank, 
        contig_ids=[contig1], 
        num_contigs=1, 
        assembly_source_date=10-JUN-2013, 
        gc_content=0.0, dna_size=4274760
    }, 
    taxonomy : {
        kingdom=kingdom not present, 
        scientific_lineage=[Unknown], 
        scientific_name=Unknown, 
        genetic_code=0, 
        taxonomy_id=-1, 
        organism_aliases=[No organism aliases present]
    }
}
```

I added some work-around synchronizing data with expected type:
https://github.com/rsutormin/genome_annotation_api/blob/be04506aecef4b2aa8fc528df799456a9e3053ac/lib/GenomeAnnotationAPI/GenomeAnnotationAPIImpl.py#L974-L1000
",rsutormin,https://github.com/kbase/genome_annotation_api/issues/12,kbase++genome_annotation_api.csv
MDU6SXNzdWUxNzMwODEzMTI=,Error getting summary for one of public genomes,OPEN,2016-08-24T23:24:32Z,2016-08-24T23:24:39Z,,"Error is thrown when get_summary is requested for genome kbasetest:1466036531200/Red_Algae_Ensembl, ref=8020/39/1 in CI:

```
Traceback (most recent call last):
  File ""/kb/module/bin/../lib/GenomeAnnotationAPI/GenomeAnnotationAPIServer.py"", line 93, in _call_method
    result = method(ctx, *params)
  File ""/kb/module/lib/GenomeAnnotationAPI/GenomeAnnotationAPIImpl.py"", line 972, in get_combined_data
    summary = ga.get_summary()
  File ""/usr/local/lib/python2.7/dist-packages/doekbase/data_api/annotation/genome_annotation/api.py"", line 644, in get_summary
    return self.proxy.get_summary()
  File ""/usr/local/lib/python2.7/dist-packages/doekbase/data_api/annotation/genome_annotation/api.py"", line 2513, in get_summary
    latest_summary = refs[all_summary_types[-1]][0]
IndexError: list index out of range
```
",rsutormin,https://github.com/kbase/genome_annotation_api/issues/13,kbase++genome_annotation_api.csv
MDU6SXNzdWUxMjA0MDY4NTI=,How to run (locally),OPEN,2015-12-04T13:58:43Z,2021-01-13T23:59:48Z,,"Hi,

I am looking at the kbase repositories in order to run an annotation on our local server. Where can I find instructions to deploy the kbase system, including running the `rast-annotate-proteins-kmer-v1.pl` command locally (without making connections to the rast servers)?

Thanks!
",mdehollander,https://github.com/kbaseattic/genome_annotation/issues/2,kbaseattic++genome_annotation.csv
I_kwDOKl7w4M52LEVS,There is no ProtExcluder.pl,CLOSED,2023-11-08T02:39:58Z,2023-11-08T15:00:19Z,2023-11-08T15:00:19Z,"**Hi Dan, 
I keep getting the following error when running step 2 of the pipeline:** 

-----------------------------------------------------
Input is being processed as unpaired
Time:                           2.619 seconds.
Reads Processed:        570k    217.70k reads/sec
Bases Processed:        206m    78.72m bases/sec
Reads Out:          569888
Bases Out:          206062128
/home/krablab/Documents/CO_data/LT_repeats/Ref_genome//scripts/run_repeatMasker.sh: line 36: /home/krablab/Documents/apps/ProtExcluder1.2/ProtExcluder.pl: No such file or directory
RepeatMasker::setspecies: Could not find user specified library ../Lake_trout_RepeatModeler/Lake_trout_REPEAT_LIBRARY-families.fanoProtFinal, or the file is empty.
gzip: ./RMask_denovoPrediction_protFiltered/*.cat.gz: No such file or directory
gzip: ./RMask_denovoPlusDfam/*.cat.gz: No such file or directory
cat: './RMask_denovoPrediction_protFiltered/*.cat': No such file or directory
cat: './RMask_denovoPlusDfam/*.cat': No such file or directory
gzip: ./RMask_denovoPrediction_protFiltered/*.cat: No such file or directory
gzip: ./RMask_denovoPlusDfam/*.cat: No such file or directory
-----------------------------------------------------

**This issue is arising because there is no scripts/run_repeatMasker.sh file in the  the following directory :/home/krablab/Documents/apps/ProtExcluder/**

**Below is the command (Line 36 of the run_repeatMasker.sh**
-------------------------------------------------------
# note that ProtExcluder requires ""esl-sfetch"" from the Easel library
# on Bottlerocket, located at ""/home/krablab/miniconda2/envs/hmmer/bin/esl-sfetch""
/home/krablab/Documents/apps/ProtExcluder/ProtExcluder.pl ${SPECIES}_blastx_uniprot_TEfiltered_e10.out ../${SPECIES}_RepeatModeler/${REPEAT_LIBRARY_NAME}-families.fa_

**I tried downloading the ProtExcluder.pl script from this link https://github.com/NBISweden/ProtExcluder/blob/master/ProtExcluder.pl but even after adding that to the aforementioned directory and changing the file permissions, it still didn't work.**
-----------------------------------------------------
Executing driver.FilterReadsByName [in=uniprot_sprot.fasta, out=uniprot_sprot.TEfiltered.fasta, names=transposable,transposase, substring=name, ignorejunk]

Exception in thread ""main"" java.lang.AssertionError: File uniprot_sprot.TEfiltered.fasta exists and overwrite=false
        at shared.Tools.testOutputFiles(Tools.java:127)
        at driver.FilterReadsByName.<init>(FilterReadsByName.java:225)
        at driver.FilterReadsByName.main(FilterReadsByName.java:40)
sh: 1: matchtract.pl: not found
sh: 1: countaanu.pl: not found
sh: 1: rmlowcomplexitymathc.pl: not found
sh: 1: blastformatProt.pl: not found
sh: 1: rmlowcomfromBF.pl: not found
sh: 1: mergequeryBF.pl: not found
sh: 1: unmatchedregionBF.pl: not found
Can't exec ""mspesl-sfetch.pl"": No such file or directory at /home/krablab/Documents/apps/ProtExcluder1.2/ProtExcluder.pl line 33.
sh: 1: mergeunmatchedregion.pl: not found
sh: 1: GCcontent.pl: not found
sh: 1: rmshortseq_noN.pl: not found
sh: 1: getanycolumnuni.pl: not found
sh: 1: rmlistedseq.pl: not found
sh: 1: fasta-reformat.pl: not found
mkdir: cannot create directory RMask_denovoPrediction_protFiltered: File exists
RepeatMasker::setspecies: Could not find user specified library ../Lake_trout_RepeatModeler/Lake_trout_REPEAT_LIBRARY-families.fanoProtFinal, or the file is empty.
mkdir: cannot create directory RMask_denovoPlusDfam: File exists
mkdir: cannot create directory final_repeat_mask: File exists
gzip: ./RMask_denovoPrediction_protFiltered/*.cat.gz: No such file or directory
gzip: ./RMask_denovoPlusDfam/*.cat.gz: No such file or directory
cat: './RMask_denovoPrediction_protFiltered/*.cat': No such file or directory
cat: './RMask_denovoPlusDfam/*.cat': No such file or directory
gzip: ./RMask_denovoPrediction_protFiltered/*.cat: No such file or directory
gzip: ./RMask_denovoPlusDfam/*.cat: No such file or directory
-----------------------------------------------------",Ozzborne,https://github.com/KrabbenhoftLab/genome_annotation_pipeline/issues/1,KrabbenhoftLab++genome_annotation_pipeline.csv
I_kwDOKl7w4M57Vwth,Issues with getting Braker step to run,CLOSED,2024-01-07T21:41:14Z,2024-01-10T15:26:27Z,2024-01-10T15:26:27Z,"Hi Dan,

I am having trouble getting the Braker step of the pipeline to run on CCR. Below is the content of the BRAKER.err file from the logFiles directory.

If it helps, my annotation directory is here.
/projects/academic/tkrabben/Osborne/LT_annotations/SE08

mkdir: cannot create directory 'SE08_BRAKER': File exists
[WARN  tini (273493)] Tini is not running as PID 1 and isn't registered as a child subreaper.
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, use the -s option or set the environment variable TINI_SUBREAPER to register Tini as a child subreaper, or run Tini as PID 1.
#**********************************************************************************
#                               BRAKER CONFIGURATION
#**********************************************************************************
# BRAKER CALL: /opt/BRAKER/scripts/braker.pl --genome=Genome/SE08_Flye_Medaka_Pilon3_Purge_HiC_RagTag_GapCloser_Pilon1.masked.fasta --bam=SE08_HISAT2/SE08.sorted.rna.bam --prot_seq=/vscratch/grp-tkrabben/Osborne/LT>
# Sun Jan  7 16:35:35 2024: braker.pl version 3.0.6
# Sun Jan  7 16:35:35 2024:Both protein and RNA-Seq data in input detected. BRAKER will be executed in ETP mode (BRAKER3).
#*********
# Sun Jan  7 16:35:35 2024: Configuring of BRAKER for using external tools...
# Sun Jan  7 16:35:35 2024: Trying to set $AUGUSTUS_CONFIG_PATH...
# Sun Jan  7 16:35:35 2024: Found environment variable $AUGUSTUS_CONFIG_PATH.
# Sun Jan  7 16:35:35 2024: Checking /usr/share/augustus/config/ as potential path for $AUGUSTUS_CONFIG_PATH.
# Sun Jan  7 16:35:35 2024: Success! Setting $AUGUSTUS_CONFIG_PATH to /usr/share/augustus/config/!
# Sun Jan  7 16:35:35 2024: WARNING: in file /opt/BRAKER/scripts/braker.pl at line 1894
AUGUSTUS_CONFIG_PATH/species (in this case /usr/share/augustus/config//species) is not writeable. BRAKER will try to copy the AUGUSTUS config directory to a writeable location.
#**********************************************************************************
#                               BRAKER CONFIGURATION
#**********************************************************************************
# BRAKER CALL: /opt/BRAKER/scripts/braker.pl --genome=Genome/SE08_Flye_Medaka_Pilon3_Purge_HiC_RagTag_GapCloser_Pilon1.masked.fasta --bam=SE08_HISAT2/SE08.sorted.rna.bam --prot_seq=/vscratch/grp-tkrabben/Osborne/LT>
# Sun Jan  7 16:35:35 2024: braker.pl version 3.0.6
# Sun Jan  7 16:35:35 2024:Both protein and RNA-Seq data in input detected. BRAKER will be executed in ETP mode (BRAKER3).
#*********
# Sun Jan  7 16:35:35 2024: Configuring of BRAKER for using external tools...
# Sun Jan  7 16:35:35 2024: Trying to set $AUGUSTUS_CONFIG_PATH...
# Sun Jan  7 16:35:35 2024: Found environment variable $AUGUSTUS_CONFIG_PATH.
# Sun Jan  7 16:35:35 2024: Checking /usr/share/augustus/config/ as potential path for $AUGUSTUS_CONFIG_PATH.
# Sun Jan  7 16:35:35 2024: Success! Setting $AUGUSTUS_CONFIG_PATH to /usr/share/augustus/config/!
# Sun Jan  7 16:35:35 2024: WARNING: in file /opt/BRAKER/scripts/braker.pl at line 1894
AUGUSTUS_CONFIG_PATH/species (in this case /usr/share/augustus/config//species) is not writeable. BRAKER will try to copy the AUGUSTUS config directory to a writeable location.
# Sun Jan  7 16:35:35 2024: Trying to set $AUGUSTUS_BIN_PATH...
# Sun Jan  7 16:35:35 2024: Found environment variable $AUGUSTUS_BIN_PATH.
# Sun Jan  7 16:35:35 2024: Checking /usr/bin/ as potential path for $AUGUSTUS_BIN_PATH.
# Sun Jan  7 16:35:35 2024: Success! Setting $AUGUSTUS_BIN_PATH to /usr/bin/!
# Sun Jan  7 16:35:35 2024: Trying to set $AUGUSTUS_SCRIPTS_PATH...
# Sun Jan  7 16:35:35 2024: Found environment variable $AUGUSTUS_SCRIPTS_PATH.
# Sun Jan  7 16:35:35 2024: Checking /usr/share/augustus/scripts/ as potential path for $AUGUSTUS_SCRIPTS_PATH.
# Sun Jan  7 16:35:35 2024: Success! Setting $AUGUSTUS_SCRIPTS_PATH to /usr/share/augustus/scripts/!
# Sun Jan  7 16:35:35 2024: WARNING: BRAKER will copy the
 AUGUSTUS_CONFIG folder into your home directory!
# Sun Jan  7 16:35:35 2024: WARNING: $AUGUSTUS_CONFIG_PATH/species (in this case /usr/share/augustus/config//species ) is not writeable.
*** IMPORTANT: Resetting $AUGUSTUS_CONFIG_PATH=/projects/academic/tkrabben/Osborne/LT_annotations/SE08/.augustus because BRAKER requires a writable location!
# Sun Jan  7 16:35:35 2024: Trying to set $PYTHON3_PATH...
# Sun Jan  7 16:35:35 2024: Did not find environment variable $PYTHON3_PATH.
# Sun Jan  7 16:35:35 2024: Trying to guess PYTHON3_PATH from location of python3 executable that is available in your $PATH
# Sun Jan  7 16:35:35 2024: Checking /opt/conda/bin as potential path for $PYTHON3_PATH.
# Sun Jan  7 16:35:35 2024: Success! Setting $PYTHON3_PATH to /opt/conda/bin!
# Sun Jan  7 16:35:35 2024: Trying to set $GENEMARK_PATH...
# Sun Jan  7 16:35:35 2024: Found command line argument $GENEMARK_PATH.
# Sun Jan  7 16:35:35 2024: Checking /gmes as potential path for $GENEMARK_PATH.
#*********
# WARNING: /gmes is not a directory. Will not set $GENEMARK_PATH to /gmes!
****
#*********
# Sun Jan  7 16:35:35 2024: Found environment variable $GENEMARK_PATH.
# Sun Jan  7 16:35:35 2024: Checking /opt/ETP/bin as potential path for $GENEMARK_PATH.
# Sun Jan  7 16:35:35 2024: Success! Setting $GENEMARK_PATH to /opt/ETP/bin!
# Sun Jan  7 16:35:35 2024: Trying to set $BAMTOOLS_PATH...
# Sun Jan  7 16:35:35 2024: Did not find environment variable $BAMTOOLS_PATH.
# Sun Jan  7 16:35:35 2024: Trying to guess BAMTOOLS_PATH from location of bamtools executable that is available in your $PATH
# Sun Jan  7 16:35:35 2024: Checking /usr/bin as potential path for $BAMTOOLS_PATH.
# Sun Jan  7 16:35:35 2024: Success! Setting $BAMTOOLS_PATH to /usr/bin!
# Sun Jan  7 16:35:35 2024: Trying to set $SAMTOOLS_PATH...
# Sun Jan  7 16:35:35 2024: Did not find environment variable $SAMTOOLS_PATH.
# Sun Jan  7 16:35:35 2024: Trying to guess SAMTOOLS_PATH from location of samtools executable that is available in your $PATH
# Sun Jan  7 16:35:35 2024: Checking /usr/bin as potential path for $SAMTOOLS_PATH.
# Sun Jan  7 16:35:35 2024: Success! Setting $SAMTOOLS_PATH to /usr/bin!
# Sun Jan  7 16:35:35 2024: Trying to set $DIAMOND_PATH...
# Sun Jan  7 16:35:35 2024: Did not find environment variable $DIAMOND_PATH.
# Sun Jan  7 16:35:35 2024: Trying to guess DIAMOND_PATH from location of diamond executable that is available in your $PATH
# Sun Jan  7 16:35:35 2024: Checking /opt/ETP/tools as potential path for $DIAMOND_PATH.
# Sun Jan  7 16:35:35 2024: Success! Setting $DIAMOND_PATH to /opt/ETP/tools!
# Sun Jan  7 16:35:35 2024: Trying to set $PROTHINT_PATH...
# Sun Jan  7 16:35:35 2024: Did not find environment variable $PROTHINT_PATH.
# Sun Jan  7 16:35:35 2024: Trying to guess PROTHINT_PATH from location of prothint.py executable that is available in your $PATH
# Sun Jan  7 16:35:35 2024: Checking /opt/ETP/bin/gmes/ProtHint/bin as potential path for $PROTHINT_PATH.
# Sun Jan  7 16:35:35 2024: Success! Setting $PROTHINT_PATH to /opt/ETP/bin/gmes/ProtHint/bin!
# Sun Jan  7 16:35:35 2024: Trying to set $TSEBRA_PATH...
# Sun Jan  7 16:35:35 2024: Did not find environment variable $TSEBRA_PATH.
# Sun Jan  7 16:35:35 2024: Trying to guess TSEBRA_PATH from location of tsebra.py executable that is available in your $PATH
# Sun Jan  7 16:35:35 2024: Checking /opt/TSEBRA/bin as potential path for $TSEBRA_PATH.
# Sun Jan  7 16:35:35 2024: Success! Setting $TSEBRA_PATH to /opt/TSEBRA/bin!
# Sun Jan  7 16:35:35 2024: Trying to set $CDBTOOLS_PATH...
# Sun Jan  7 16:35:35 2024: Did not find environment variable $CDBTOOLS_PATH.
# Sun Jan  7 16:35:35 2024: Trying to guess CDBTOOLS_PATH from location of cdbfasta executable that is available in your $PATH
# Sun Jan  7 16:35:35 2024: Checking /opt/cdbfasta as potential path for $CDBTOOLS_PATH.
# Sun Jan  7 16:35:35 2024: Success! Setting $CDBTOOLS_PATH to /opt/cdbfasta!
# Sun Jan  7 16:35:36 2024: ERROR: in file /opt/BRAKER/scripts/braker.pl at line 3585
protein sequence file /vscratch/grp-tkrabben/Osborne/LT_genomes/orthodbv11_metazoan_Salmonidae_proteins_refseq.fasta does not exist.
[WARN  tini (273547)] Tini is not running as PID 1 and isn't registered as a child subreaper.
Zombie processes will not be re-parented to Tini, so zombie reaping won't work.
To fix the problem, use the -s option or set the environment variable TINI_SUBREAPER to register Tini as a child subreaper, or run Tini as PID 1.
### READING GENE PREDICTION: [SE08_BRAKER/braker.gtf]
Traceback (most recent call last):
  File ""/opt/TSEBRA/bin/tsebra.py"", line 235, in <module>
    main()
  File ""/opt/TSEBRA/bin/tsebra.py"", line 67, in main
    anno[-1].addGtf()
  File ""/opt/TSEBRA/bin/genome_anno.py"", line 297, in addGtf
    with open (self.path, 'r') as file:
FileNotFoundError: [Errno 2] No such file or directory: 'SE08_BRAKER/braker.gtf'
",Ozzborne,https://github.com/KrabbenhoftLab/genome_annotation_pipeline/issues/2,KrabbenhoftLab++genome_annotation_pipeline.csv
I_kwDOKl7w4M57WAyi,Issue running GeMoMa on CCr,CLOSED,2024-01-08T00:12:15Z,2024-01-08T17:16:02Z,2024-01-08T17:16:02Z,"Hi Dan, I am also having issues getting GeMoMa to run on CCR. Below is the error message I am getting.

Thank you

Exception in thread ""main"" de.jstacs.parameters.SimpleParameter$IllegalValueException: Error in parameter(ID): Parameter not permitted: value not valid: GCF_002021735.2_Okis_V2_genomic
String does not match \w*
        at de.jstacs.parameters.SimpleParameter.setValue(SimpleParameter.java:422)
        at de.jstacs.tools.ui.cli.CLI.setValue(CLI.java:606)
        at de.jstacs.tools.ui.cli.CLI.set(CLI.java:568)
        at de.jstacs.tools.ui.cli.CLI.set(CLI.java:564)
        at de.jstacs.tools.ui.cli.CLI.set(CLI.java:582)
        at de.jstacs.tools.ui.cli.CLI.setToolParameters(CLI.java:502)
        at de.jstacs.tools.ui.cli.CLI.run(CLI.java:404)
        at projects.gemoma.GeMoMa.main(GeMoMa.java:399)
Exception in thread ""main"" de.jstacs.parameters.SimpleParameter$IllegalValueException: Error in parameter(annotation): Parameter not permitted: File GeMoMa_combined/final_annotation.gff does not exist
        at de.jstacs.parameters.FileParameter.setValue(FileParameter.java:305)
        at de.jstacs.tools.ui.cli.CLI.setValue(CLI.java:606)
        at de.jstacs.tools.ui.cli.CLI.set(CLI.java:568)
        at de.jstacs.tools.ui.cli.CLI.setToolParameters(CLI.java:502)
        at de.jstacs.tools.ui.cli.CLI.run(CLI.java:404)
        at projects.gemoma.GeMoMa.main(GeMoMa.java:399)
mv: cannot stat 'GeMoMa_combined/proteins.fasta': No such file or directory
Parameters of tool ""Extractor"" (Extractor, version: 1.9):
a - annotation (Reference annotation file (GFF or GTF), which contains gene models annotated in the reference genome, type = gff,gff3,gtf,gff.gz,gff3.gz,gtf.gz)        = GeMoMa_combined/final_annotation.longest_iso>
g - genome (Reference genome file (FASTA), type = fasta,fa,fas,fna,fasta.gz,fa.gz,fas.gz,fna.gz)        = /projects/academic/tkrabben/Osborne/LT_annotations/SE08//Genome/SE08_Flye_Medaka_Pilon3_Purge_HiC_RagTag_Gap>
gc - genetic code (optional user-specified genetic code, type = tabular, OPTIONAL)      = null
p - proteins (whether the complete proteins sequences should returned as output, default = false)       = true
c - cds (whether the complete CDSs should returned as output, default = false)  = false
genomic - genomic (whether the genomic regions should be returned (upper case = coding, lower case = non coding), default = false)      = false
i - introns (whether introns should be extracted from annotation, that might be used for test cases, default = false)   = false
identical - identical (if CDS is identical Extractor only used one transcript. This parameter allows to return a table that lists in the first column the used transcript and in the second column the discarded trans>
u - upcase IDs (whether the IDs in the GFF should be upcased, default = false)  = false
r - repair (if a transcript annotation can not be parsed, the program will try to infer the phase of the CDS parts to repair the annotation, default = false)   = false
s - selected (The path to list file, which allows to make only a predictions for the contained transcript ids. The first column should contain transcript IDs as given in the annotation. Remaining columns will be ig>
Ambiguity - Ambiguity (This parameter defines how to deal with ambiguities in the DNA. There are 3 options: EXCEPTION, which will remove the corresponding transcript, AMBIGUOUS, which will use an X for the correspo>
d - discard pre-mature stop (if *true* transcripts with pre-mature stop codon are discarded as they often indicate misannotation, default = true)       = true
sefc - stop-codon excluded from CDS (A flag that states whether the reference annotation contains the stop codon in the CDS annotation or not, default = false) = false
f - full-length (A flag which allows for choosing between only full-length and all (i.e., full-length and partial) transcripts, default = true) = true
l - long fasta comment (whether a short (transcript ID) or a long (transcript ID, gene ID, chromosome, strand, interval) fasta comment should be written for proteins, CDSs, and genomic regions, default = false)    >
v - verbose (A flag which allows to output a wealth of additional information, default = false) = false
outdir - The output directory, defaults to the current working directory (.)    = GeMoMa_combined
mv: cannot stat 'GeMoMa_combined/proteins_1.fasta': No such file or directory
",Ozzborne,https://github.com/KrabbenhoftLab/genome_annotation_pipeline/issues/3,KrabbenhoftLab++genome_annotation_pipeline.csv
MDU6SXNzdWUyMzAxMzAxMDk=,Does ignoring blocks when using liftOver cause problem?,OPEN,2017-05-20T04:49:43Z,2017-05-20T04:49:43Z,,"While converting hg38 to hg19 with liftOver, columns with no. of blocks and block sizes were not considered. Does this affect hg19 coordinates when those blocks were split into individual rows?",ManavalanG,https://github.com/ManavalanG/UniProt-genome-annotations-hg19/issues/1,ManavalanG++UniProt-genome-annotations-hg19.csv
MDU6SXNzdWUxNDQ5NTMxOTA=,Genome version,CLOSED,2016-03-31T16:41:28Z,2016-04-05T15:12:28Z,2016-04-05T15:12:28Z,"practical refers to hg19, but output of Ensembl connection refers to GRCh37. Not obvious that these are the same thing
",markdunning,https://github.com/markdunning/GenomeAnnotation-Prac/issues/1,markdunning++GenomeAnnotation-Prac.csv
MDU6SXNzdWUxNDUxNTI0NjQ=,seqLevelsStyle,CLOSED,2016-04-01T11:16:09Z,2016-04-05T15:33:21Z,2016-04-05T15:33:21Z,"Use the genomeInfoDb to rename the chromosomes to UCSC style
",markdunning,https://github.com/markdunning/GenomeAnnotation-Prac/issues/2,markdunning++GenomeAnnotation-Prac.csv
I_kwDOFEf9is5Cd1M1,How to download Insect virus,OPEN,2022-01-26T14:58:31Z,2022-01-26T14:58:31Z,,"I didn't see the download-all button for the insect virus. Could you help me with that? Or can you please send me a list of accession or taxonomy id of these viruses? Thank you!

",JY-97,https://github.com/meiyang12/Genome-annotation-pipeline/issues/1,meiyang12++Genome-annotation-pipeline.csv
I_kwDOFEf9is5H-vrr,Can not get homolog_change_gff3.pl in this pipeline,OPEN,2022-04-19T02:12:49Z,2022-04-19T02:12:49Z,,"Dear Dr. Yang:
I can't find the scripts of ""homolog_change_gff3.pl"" in this pipeline, can you share this script here? Thx !",cccsnd,https://github.com/meiyang12/Genome-annotation-pipeline/issues/2,meiyang12++Genome-annotation-pipeline.csv
I_kwDOFEf9is5KQ2XU,How different methods on RepeatMasker running can lead to different results,OPEN,2022-05-24T03:28:39Z,2022-05-24T03:28:39Z,,"Hi! Thank you for providing this pipline to annotate a new assembling genome!

I run RepeatMasker on different libraries ( one is build by RepeatModeler, another is 'species' contained in the RepBase ) according to your command, but I add the parameter `-xsmall [returns repetitive regions in lowercase (rest capitals) rather than masked]` because I notice it is recommended that the braker runs on genomic sequences that have been softmasked for Repeats. And also the option `--softmasking` is suitable for softmasked genomes. The command looks like this:
```
RepeatMasker -pa 20 -lib 01_repeatModeler-denovo-repeat.lib/RM_*/consensi.fa.classified -html -gff -xsmall -dir 02_delete-denovo-lib-result genome.fa &>RepeatMasker_run.log1
RepeatMasker -pa 20 -species ""Lepidoptera"" -html -gff -xsmall -dir 03_delete-repeatmasker-lib-result 02_delete-denovo-lib-result/genome.fa.masked &>RepeatMasker_run.log2
RepeatMasker -pa 20 -species ""Lepidoptera"" -html -gff -xsmall -noint -dir 04_delete-repeamasker-noint-result 03_delete-repeatmasker-lib-result/genome.fa.masked.masked &>RepeatMasker_run.log3
```
I have compared the two masked genome generated by run 1 & 2, I see some sequences that is masked in the first run (with `-lib`) is unmasked in the second run (with `-species`). I think this case is caused by the option `-xsmall`, so I run again above commands but delete the option `-xsmall` and this problem is solved.

It is confusing that this pipeline use the genome.fa.masked.masked in `03_delete-repeatmasker-lib-result/genome.fa.masked.masked` directory rather than the genome.fa.masked.masked.masked in `04_delete-repeamasker-noint-result/genome.fa.masked.masked.masked` directory to run BRAKER. 

So what the meaning of run 3 ( with `-noint` ) ? If we run RepeatMasker in hardmasking model, I think the `braker.pl` shouldn't add the option `--softmasking`. If we run RepeatMasker in softmasking model, does the better way is to combine the libraries into one library as mentioned by jebrosen https://github.com/Dfam-consortium/TETools/issues/20#issuecomment-983927917 and then feed the genome.fa.masked ( soft-masking ) to BRAKER with `--softmasking` ?",yshcai,https://github.com/meiyang12/Genome-annotation-pipeline/issues/3,meiyang12++Genome-annotation-pipeline.csv
MDU6SXNzdWU1NDYwOTk0ODk=,0s for all the bins,OPEN,2020-01-07T06:08:59Z,2020-01-07T06:08:59Z,,"Have you ever encountered 0 values for every AED bin from running AED_cdf_generator.pl (except for the last)?  Just to note my previous iteration of Maker had a 92.6 for the 0.5 AED bin.

Do you know why that would be? or what that would mean?
",noor-albader,https://github.com/mscampbell/Genome_annotation/issues/1,mscampbell++Genome_annotation.csv
I_kwDOA1IIRc5yMvCn,Illegal division by zero,OPEN,2023-09-27T16:29:29Z,2023-09-27T16:29:29Z,,"I am trying to compare annotations with some gff file not created by maker, but ever time run the AED script with non-Maker annotations i get the following error:

Illegal division by zero at /scratch/users/juan/biotools/AED_cdf_generator.pl line 49.

Any ideas why this happens?

Thanks!",cerd9235,https://github.com/mscampbell/Genome_annotation/issues/2,mscampbell++Genome_annotation.csv
I_kwDOG-u-L85Fi6ea,Not sure if we should keep the password in the repo. Maybe as a parameter?,OPEN,2022-03-11T19:31:30Z,2022-03-11T19:31:30Z,,https://github.com/mskcc/genomeNexflow/blob/a93b4fa0fc2a58a6bce8941eb579d3e8634c369b/containers/genomeNexus/AwsSsl.truststore.password#L1,gongyixiao,https://github.com/mskcc/genomeNexflow/issues/1,mskcc++genomeNexflow.csv
I_kwDOGxVcrM5N1CrQ,Could not load nf-core/config profiles,CLOSED,2022-07-15T08:37:41Z,2023-11-14T21:53:08Z,2023-08-25T09:02:56Z,"### Description of the bug

When I launch the pipeline I get the following error 

cat nf.output
/var/spool/slurm/d/job35576642/slurm_script: ligne13: bioinfo/nfcore-Nextflow-v21.10.6: Aucun fichier ou dossier de ce type
N E X T F L O W  ~  version 0.17.3
Launching 'nf-core/genomeannotator' - revision: cbd878f799 [dev]
WARNING: Could not load nf-core/config profiles: https://raw.githubusercontent.com/nf-core/configs/master/nfcore_custom.config
Unknown configuration profile: 'genotoul'

Here is may command line : 
nextflow run nf-core/genomeannotator -r dev -profile genotoul --assemblyfirst_assembly.fasta --rnaseq_samples sample_sheet.csv --proteins proteins.fasta --outdir output --aug_species human

genotoul is one of the profiles found in https://raw.githubusercontent.com/nf-core/configs/master/nfcore_custom.config


### Command used and terminal output

```console
command used :
nextflow run nf-core/genomeannotator -r dev -profile genotoul --assemblyfirst_assembly.fasta --rnaseq_samples sample_sheet.csv 


cat .nextflow.log
juil.-15 10:30:04.213 [main] DEBUG nextflow.cli.Launcher - $> /home/klopp/save/bin/nextflow run nf-core/genomeannotator -r dev -profile genotoul --assembly Cyathomix_first_assembly.fasta --rnaseq_samples sample_sheet.csv --proteins proteins.fasta --outdir output --aug_species caenorhabditis
juil.-15 10:30:04.275 [main] INFO  nextflow.cli.CmdRun - N E X T F L O W  ~  version 0.17.3
juil.-15 10:30:04.911 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/klopp/.nextflow/assets/nf-core/genomeannotator/.git/config; branch: master; remote: origin; url: https://github.com/nf-core/genomeannotator.git
juil.-15 10:30:05.094 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/klopp/.nextflow/assets/nf-core/genomeannotator/.git/config; branch: master; remote: origin; url: https://github.com/nf-core/genomeannotator.git
juil.-15 10:30:05.777 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/klopp/.nextflow/assets/nf-core/genomeannotator/.git/config; branch: master; remote: origin; url: https://github.com/nf-core/genomeannotator.git
juil.-15 10:30:05.777 [main] INFO  nextflow.cli.CmdRun - Launching 'nf-core/genomeannotator' - revision: cbd878f799 [dev]
juil.-15 10:30:05.790 [main] DEBUG nextflow.config.ConfigBuilder - Found config base: /home/klopp/.nextflow/assets/nf-core/genomeannotator/nextflow.config
juil.-15 10:30:05.792 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /home/klopp/.nextflow/assets/nf-core/genomeannotator/nextflow.config
juil.-15 10:30:05.918 [main] DEBUG nextflow.config.ConfigBuilder - Setting config profile: 'genotoul'
juil.-15 10:30:06.338 [main] DEBUG nextflow.cli.Launcher - Operation aborted
nextflow.exception.AbortOperationException: Unknown configuration profile: 'genotoul'
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.codehaus.groovy.reflection.CachedConstructor.invoke(CachedConstructor.java:80)
	at org.codehaus.groovy.reflection.CachedConstructor.doConstructorInvoke(CachedConstructor.java:74)
	at org.codehaus.groovy.runtime.callsite.ConstructorSite$ConstructorSiteNoUnwrap.callConstructor(ConstructorSite.java:84)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallConstructor(CallSiteArray.java:60)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callConstructor(AbstractCallSite.java:235)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callConstructor(AbstractCallSite.java:247)
	at nextflow.config.ConfigBuilder.checkValidProfile(ConfigBuilder.groovy:309)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite$PogoCachedMethodSiteNoUnwrapNoCoerce.invoke(PogoMetaMethodSite.java:210)
	at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite.callCurrent(PogoMetaMethodSite.java:59)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:52)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:154)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:166)
	at nextflow.config.ConfigBuilder.buildConfig0(ConfigBuilder.groovy:285)
	at nextflow.config.ConfigBuilder$buildConfig0$2.callCurrent(Unknown Source)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:52)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:154)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:174)
	at nextflow.config.ConfigBuilder.buildConfig(ConfigBuilder.groovy:235)
	at nextflow.config.ConfigBuilder$buildConfig$1.callCurrent(Unknown Source)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:52)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:154)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:166)
	at nextflow.config.ConfigBuilder.build(ConfigBuilder.groovy:460)
	at nextflow.cli.CmdRun.run(CmdRun.groovy:175)
	at nextflow.cli.Launcher.run(Launcher.groovy:380)
	at nextflow.cli.Launcher.main(Launcher.groovy:529)
```


### Relevant files

_No response_

### System information

nfcore-Nextflow-v21.10.6
HPC
slurm",chklopp,https://github.com/nf-core/genomeannotator/issues/5,nf-core++genomeannotator.csv
I_kwDOGxVcrM5UwTX4,Could not run test using Docker,CLOSED,2022-10-25T06:49:47Z,2023-08-31T07:30:03Z,2023-08-31T07:30:03Z,"### Description of the bug

When I run test for genomeannotator, I got the following errror:


 ```
Error executing process > 'NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_STAGECONFIG (config)'

Caused by:
  Process `NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_STAGECONFIG (config)` terminated with an error exit status (1)

Command executed:

  mkdir -p augustus_config
  cp -R config/* augustus_config/

  cat <<-END_VERSIONS > versions.yml
  ""NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_STAGECONFIG"":
      augustus: $(echo $(augustus  | head -n1 | cut -f2 -d "" "" | sed ""s/[)]//"" | sed ""s/[(]//"" ))
  END_VERSIONS

Command output:
  (empty)

Command error:
  Unable to find image 'quay.io/biocontainers/augustus:3.4.0--pl5262h5a9fe7b_2' locally
  3.4.0--pl5262h5a9fe7b_2: Pulling from biocontainers/augustus
  c1a16a04cedd: Already exists
  4ca545ee6d5d: Already exists
  9045f8e140e3: Pulling fs layer
  9045f8e140e3: Verifying Checksum
  9045f8e140e3: Download complete
  9045f8e140e3: Pull complete
  Digest: sha256:db15c7f970ce92b36b5f657062bd948634d0c4c162b21fc67916b6ba23ea1770
  Status: Downloaded newer image for quay.io/biocontainers/augustus:3.4.0--pl5262h5a9fe7b_2
  cp: can't stat 'config/*': No such file or directory

```


### Command used and terminal output

```console
$ nextflow run nf-core/genomeannotator -r dev -profile test,docker --outdir genomeannotator_test_001
```


### Relevant files

_No response_

### System information

- Nextflow version version 22.04.4 build 5706
- executor: local
- Hardware: HPC
- Container engine: Docker
- OS: CentOS Linux 7",yuifu,https://github.com/nf-core/genomeannotator/issues/10,nf-core++genomeannotator.csv
I_kwDOGxVcrM5UwUtc,Could not run test using Singularity,CLOSED,2022-10-25T06:54:08Z,2023-08-31T07:29:26Z,2023-08-31T07:29:26Z,"### Description of the bug



```
Error executing process > 'NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_STAGECONFIG (config)'

Caused by:
  Failed to pull singularity image
  command: singularity pull  --name depot.galaxyproject.org-singularity-augustus-3.4.0--pl5262h5a9fe7b_2.img.pulling.1666680659902 https://depot.galaxyproject.org/singularity/augustus:3.4.0--pl5262h5a9fe7b_2 > /dev/null
  status : 255
  message:
    FATAL:   Error making http request: Head ""https://depot.galaxyproject.org/singularity/augustus:3.4.0--pl5262h5a9fe7b_2"": x509: certificate has expired or is not yet valid: current time 2022-10-25T15:51:00+09:00 is after 2021-09-30T14:01:15Z




Pulling Singularity image https://containers.biocontainers.pro/s3/SingImgsRepo/biocontainers/v1.2.0_cv1/biocontainers_v1.2.0_cv1.img [cache /data2/harukao/projects/2018/stRamDA/results/20221025_test_genomeannotator/work/singularity/containers.biocontainers.pro-s3-SingImgsRepo-biocontainers-v1.2.0_cv1-biocontainers_v1.2.0_cv1.img.img]
```

### Command used and terminal output

```console
$ nextflow run nf-core/genomeannotator -r dev -profile test,singularity --outdir genomeannotator_test_002
```


### Relevant files

_No response_

### System information

- Nextflow version version 22.04.4 build 5706
- executor: local
- Hardware: HPC
- Container engine: Singularity
- OS: CentOS Linux 7",yuifu,https://github.com/nf-core/genomeannotator/issues/11,nf-core++genomeannotator.csv
I_kwDOGxVcrM5jY_dj,TE annotation and soft masking,OPEN,2023-04-14T04:38:12Z,2023-04-14T04:38:12Z,,"### Description of feature

I noticed that you use Dfam as your repeat library. Could you consider to add  DNApipeTE and REPET which are tools for de novo annotation and soft masking of transposable elements (TEs) in genome assemblies, similar to The Extensive de novo TE Annotator (EDTA) and RepeatMasker.

DNApipeTE is a pipeline that includes several steps for TE annotation and soft masking, including repeat identification, classification, and masking. DNApipeTE utilizes several other tools, including RepeatModeler, RepeatMasker, and RepeatExplorer, to perform these tasks. The output of DNApipeTE includes a consensus library of repeat sequences, as well as annotations of putative TE locations in the genome, and a soft-masked genome assembly.

REPET is another pipeline that includes several steps for TE annotation and soft masking, including repeat identification, classification, clustering, and masking. REPET utilizes several other tools, including RepeatModeler, RepeatMasker, and PILER, to perform these tasks. The output of REPET includes a consensus library of repeat sequences, as well as annotations of putative TE locations in the genome, and a soft-masked genome assembly.

EDTA is a tool that is specifically designed for de novo annotation of transposable elements (TEs) in genome assemblies. The output of EDTA includes a consensus library of repeat sequences, as well as annotations of putative TE locations in the genome.

Both DNApipeTE and REPET provide similar functionalities to EDTA and RepeatMasker, and the output of these pipelines can be used for downstream analyses. However, the specific algorithms and parameters used by these pipelines may differ, resulting in different outputs and soft masking results. The choice of which tool to use will depend on the specific needs of the analysis and the characteristics of the genome assembly being analyzed.

Thank you for considering.

Best wishes,

Michal",mictadlo,https://github.com/nf-core/genomeannotator/issues/14,nf-core++genomeannotator.csv
I_kwDOGxVcrM5jZGED,Adding more RNA-Seq predictions,OPEN,2023-04-14T05:14:24Z,2023-08-25T08:57:51Z,,"### Description of feature

Hi,
I recently came across Mikado which is a pipeline to identify the most useful or best set of transcripts from multiple transcript assemblies. Our approach leverages transcript assemblies generated by multiple methods to define expressed loci, assign a representative transcript and return a set of gene models that selects against transcripts that are chimeric, fragmented or with short or disrupted CDS. Loci are first defined based on overlap criteria and each transcript therein is scored based on up to 50 available metrics relating to ORF and cDNA size, relative position of the ORF within the transcript, UTR length and presence of multiple ORFs. Mikado can also utilize blast data to score transcripts based on proteins similarity and to identify and split chimeric transcripts. Optionally, junction confidence data as provided by [Portcullis](https://github.com/maplesond/portcullis) can be used to improve the assessment. The best-scoring transcripts are selected as the primary transcripts of their respective gene loci; additionally, Mikado can bring back other valid splice variants that are compatible with the primary isoform.

![giy093fig1](https://user-images.githubusercontent.com/588297/231946974-c409f5db-f1a1-4b7a-aa49-d982571c5b38.jpeg)

Mikado uses GTF or GFF files as mandatory input. Non-mandatory but highly recommended input data can be generated by obtaining a set of reliable splicing junctions with Portcullis_, by locating coding ORFs on the transcripts using either [Transdecoder](https://github.com/TransDecoder/TransDecoder/) or [Prodigal](https://github.com/hyattpd/Prodigal), and by obtaining homology information through either [BLASTX](https://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastDocs&DOC_TYPE=Download) or [DIAMOND](https://github.com/bbuchfink/diamond/).

Could the output from Mikado be used to train Augustus, GlimmerHMM and SNAP?

Than you for considering.

Best wishes,

Michal",mictadlo,https://github.com/nf-core/genomeannotator/issues/15,nf-core++genomeannotator.csv
I_kwDOGxVcrM5vwU1H,Parallelize repeatmasking,OPEN,2023-08-31T07:24:03Z,2023-08-31T07:24:03Z,,"### Description of feature

Currently, RepeatMasker runs on chunks of the assembly, containing full scaffolds/chromosomes. For highly contiguous assemblies, this can mean excessively long run times. Investigate whether repeat masking can be performed on sub-regions of the scaffolds in parallel without losing repeat regions. ",marchoeppner,https://github.com/nf-core/genomeannotator/issues/17,nf-core++genomeannotator.csv
I_kwDOGxVcrM5v74ku,Pipeline fail at REPEATMASKER_STAGELIB,OPEN,2023-09-01T19:45:55Z,2024-07-12T15:39:01Z,,"### Description of the bug

I am running the most current version of @marchoeppner dev branch on Tower on a real dataset. The workflow passed repeat masking and produced the `consensi.fa` file but failed very quickly at the subsequent staging process with: 
```
cp: can't stat '/.nextflow/assets/marchoeppner/genomeannotator/assets/repeatmasker/my_genome.fa': No such file or directory
```
Since I ran this on Tower it's a little difficult to debug things in the `.nextflow/assets` directory so this isn't obvious to me yet where this `my_genome.fa` file was supposed to come from.

### Command used and terminal output

```console
nextflow run 'https://github.com/marchoeppner/genomeannotator' \
		 -name tick_annotation_test \
		 -params-file 'https://api.tower.nf/ephemeral/zSnWhzERlz_Z4e-E6h2gng.json' \
		 -with-tower \
		 -r dev \
		 -profile docker
Params:
pri_prot_target = 5
custom_config_base = https://raw.githubusercontent.com/nf-core/configs/master
evm_weights = /.nextflow/assets/marchoeppner/genomeannotator/assets/evm/weights.txt
plaintext_email = false
monochrome_logs = false
pasa_nmodels = 1000
spaln_q = 5
max_cpus = 16
spaln_taxon = ixodscap
pri_rnaseq = 4
max_multiqc_email_size = 25.MB
max_time = 240.h
aug_chunk_length = 3000000
nevm = 10
tracedir = ${params.outdir}/pipeline_info
validate_params = true
npart_size = 200000000
max_intron_size = 20000
aug_species = human
pri_wiggle = 2
version = false
spaln_options = -M
publish_dir_mode = copy
aug_training = false
t_prot = P
t_est = E
pasa_config_file = /.nextflow/assets/marchoeppner/genomeannotator/assets/pasa/alignAssembly.config
min_prot_length = 35
aug_options = --alternatives-from-evidence=on --minexonintronprob=0.08 --minmeanexonintronprob=0.4 --maxtracks=3
multiqc_title = test run
pri_trans = 4
pasa = false
custom_config_version = master
max_memory = 128.GB
dummy_gff = /.nextflow/assets/marchoeppner/genomeannotator/assets/empty.gff3
spaln_protein_id_targeted = 90
nproteins = 200
proteins = s3://nf-hifi2genome/tick_annotation/2023-08-25-all-tick-species-proteins.fasta
assembly = s3://nf-hifi2genome/tick_annotation/Arcadia_Amblyomma_americanum_asm001_purged_cleanedup1.fasta
pri_est = 4
pri_prot = 3
min_contig_size = 5000
evm = false
email = elizabeth.mcdaniel@arcadiascience.com
schema_ignore_params = genomes,saveReference,igenomes_base,igenomes_ignore,enable_conda,save-reference
genomes:
pasa_aligner = minimap2
ncrna = false
igenomes_ignore = true
outdir = s3://nf-hifi2genome/tick_annotation/genomeannotator
help = false
show_hidden_params = false
t_rnaseq = E
rm_db = https://www.dfam.org/releases/Dfam_3.5/families/Dfam_curatedonly.h5.gz
busco_lineage = arthropoda_odb10
trinity = false
spaln_protein_id = 60
```


### Relevant files

[nf-2ZIBaSqCJUU5ME.log](https://github.com/nf-core/genomeannotator/files/12501138/nf-2ZIBaSqCJUU5ME.log)


### System information

Run on Tower with Nextflow version 23.04.3, using Docker profile",elizabethmcd,https://github.com/nf-core/genomeannotator/issues/18,nf-core++genomeannotator.csv
I_kwDOGxVcrM58kEAG,rnaseq_align.nf error,OPEN,2024-01-19T07:31:25Z,2024-01-21T09:36:15Z,,"### Description of the bug

Hi! I'm using genomeannotator for the assembly annotation of a microalgae. As inputs I have the assembly, some RNA-Seq libraries and a protein database created by myself.

### Command used and terminal output

```console
nextflow run nf-core/genomeannotator -r cbd878f -profile docker --assembly ../Assembly/Canu/Pilon_results/pilon_pilon_3/pilon_pilon_3.fasta --proteins uniref90.fasta --rnaseq_samples ../RNASeq_fastq/rnaseq_samples.csv --max_intron_size 5000 --outdir . --aug_species toxoplasma --spaln_taxon toxogond --aug_config_dir . --aug_config_container . -c config_genomeannotator.txt

Nextflow 23.10.1 is available - Please consider updating your version to it
N E X T F L O W  ~  version 23.10.0
Launching `https://github.com/nf-core/genomeannotator` [jovial_brenner] DSL2 - revision: cbd878f7997d367ccbe952648e114ad25962963f


------------------------------------------------------
                                        ,--./,-.
        ___     __   __   __   ___     /,-._.--~'
  |\ | |__  __ /  ` /  \ |__) |__         }  {
  | \| |       \__, \__/ |  \ |___     \`-._,-`-,
                                        `._,._,'
  nf-core/genomeannotator v1.0dev
------------------------------------------------------
Core Nextflow options
  runName             : jovial_brenner
  containerEngine     : docker
  launchDir           : /media/Assembly_annotation
  workDir             : /media/Assembly_annotation/work
  projectDir          : /home/fperez/.nextflow/assets/nf-core/genomeannotator
  userName            : fperez
  profile             : docker
  configFiles         : /home/fperez/.nextflow/assets/nf-core/genomeannotator/nextflow.config, /media/Assembly_annotation/config_genomeannotator.txt

Input/output options
  assembly            : ../Assembly/Canu/Pilon_results/pilon_pilon_3/pilon_pilon_3.fasta
  outdir              : .
  rnaseq_samples      : ../RNASeq_fastq/rnaseq_samples.csv
  proteins            : uniref90.fasta

Options for pipeline behavior
  max_intron_size     : 5000
  dummy_gff           : /home/fperez/.nextflow/assets/nf-core/genomeannotator/assets/empty.gff3

Options for ab-initio gene finding
  aug_species         : toxoplasma
  aug_config_container: .
  aug_config_dir      : .

Options for protein data processing
  spaln_taxon         : toxogond

Options for PASA behavior
  pasa_config_file    : /home/fperez/.nextflow/assets/nf-core/genomeannotator/assets/pasa/alignAssembly.config

Options for EvidenceModeler behavior
  evm_weights         : /home/fperez/.nextflow/assets/nf-core/genomeannotator/assets/evm/weights.txt

!! Only displaying parameters that differ from the pipeline defaults !!
------------------------------------------------------
If you use nf-core/genomeannotator for your analysis please cite:

* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x

* Software dependencies
  https://github.com/nf-core/genomeannotator/blob/master/CITATIONS.md
------------------------------------------------------
executor >  local (3)
[0b/7e3452] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_STAGECONFIG (Assembly_annotation)                    [  0%] 0 of 1
executor >  local (4)
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_STAGECONFIG (Assembly_annotation)                                   -
[52/f5d136] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:ASSEMBLY_PREPROCESS:GAAS_ASSEMBLYFILTERBYSIZE (pilon_pilon_3)                [100%] 1 of 1, cached: 1 
[3d/6cb819] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:ASSEMBLY_PREPROCESS:GAAS_FASTACLEANER (pilon_pilon_3)                        [100%] 1 of 1, cached: 1 
[6e/2e3768] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:ASSEMBLY_PREPROCESS:GAAS_FASTASTATISTICS (pilon_pilon_3)                     [100%] 1 of 1, cached: 1 
[8f/5e4436] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:REPEATMODELER (pilon_pilon_3)                                                [  0%] 0 of 1
[69/78da24] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:REPEATMASKER:FASTASPLITTER (pilon_pilon_3 - pilon_pilon_3.filtered.clean.fa) [100%] 1 of 1, cached: 1 
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:REPEATMASKER:GUNZIP                                                          -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:REPEATMASKER:REPEATMASKER_STAGELIB                                           -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:REPEATMASKER:REPEATMASKER_REPEATMASK                                         -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:REPEATMASKER:REPEATMASKER_CAT_FASTA                                          -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:GAAS_FASTACLEANER (uniref90)                             -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:EXONERATE_FASTACLEAN                                     -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:GAAS_FASTAFILTERBYSIZE                                   -
[00/d29213] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:SPALN_MAKEINDEX (pilon_pilon_3)                          [100%] 1 of 1, cached: 1 
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:SPALN_ALIGN                                              -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:SPALN_MERGE                                              -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:AUGUSTUS_ALIGNTOHINTS                                    -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:HELPER_SPALNTOGMOD                                       -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:HELPER_SPALNTOEVM                                        -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:HELPER_SPALNTOTRAINING                                   -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:RNASEQ_ALIGN:STAR_INDEX (pilon_pilon_3)                                      -
[bd/e4c8f6] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:RNASEQ_ALIGN:SAMPLESHEET_CHECK (rnaseq_samples.csv)                          [100%] 1 of 1, cached: 1 
[eb/fb6e74] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:RNASEQ_ALIGN:FASTP (All)                                                     [100%] 1 of 1, cached: 1 
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:RNASEQ_ALIGN:CAT_FASTQ                                                       -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:RNASEQ_ALIGN:STAR_ALIGN_PASS_ONE                                             -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:RNASEQ_ALIGN:STAR_ALIGN_PASS_TWO                                             -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SAMTOOLS_MERGE                                                               -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_BAM2HINTS                                                           -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_PIPELINE:FASTASPLITTER                                              -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_PIPELINE:AUGUSTUS_AUGUSTUSBATCH                                     -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_PIPELINE:AUGUSTUS_FIXJOINGENES                                      -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_PIPELINE:AUGUSTUS_CREATEGFFIDS                                      -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_PIPELINE:AUGUSTUS_GFF2PROTEINS                                      -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:CUSTOM_DUMPSOFTWAREVERSIONS                                                  -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:MULTIQC                                                                      -
ERROR ~ fromIndex = -1

 -- Check script '/home/fperez/.nextflow/assets/nf-core/genomeannotator/./workflows/../subworkflows/local/rnaseq_align.nf' at line: 35 or see '.nextflow.log' file for more details
```


### Relevant files

The custom config file looks like this:

docker {
    enabled = true
    temp = ""/Genome/Assembly_annotation/tmp""
}

env {
   TMPDIR = ""/Genome/Assembly_annotation/tmp""
   TMP = ""/Genome/Assembly_annotation/tmp""
}

### System information

_No response_",fperezcobos,https://github.com/nf-core/genomeannotator/issues/22,nf-core++genomeannotator.csv
I_kwDOGxVcrM6LLKfP,Fail at a run using conda profile,OPEN,2024-06-05T05:50:14Z,2024-06-05T05:50:14Z,,"### Description of the bug

I conducted a run using the following command and nextflow.config.
conda activate nf-core
nextflow run nf-core/genomeannotator -r dev -profile conda

Command error:
.command.sh:  2: gaas_fasta_filter_by_size.pl: not found such a command

How can I install required executables including the gaas_fasta_filter_by_size.pl script?

P.S. I tried to run with 'nextflow run nf-core/genomeannotator -r dev -profile singularity' before using -profile conda.
But I encountered the same error as ""#18 Pipeline fail at REPEATMASKER_STAGELIB"".
In this case, several parameter settings, including singularity.runOptions/singularity.envWhitelist in nextflow.config and SINGULARITY_BIND, had no effect.

### Command used and terminal output

_No response_

### Relevant files

_No response_

### System information

_No response_",stat-lab,https://github.com/nf-core/genomeannotator/issues/28,nf-core++genomeannotator.csv
I_kwDOM2-kEM6Y2CDb,Add ncbigenomedownload module,CLOSED,2024-10-03T15:03:42Z,2024-10-06T20:53:18Z,2024-10-06T20:53:18Z,"The ncbigenomedownload module from nf-core requires a file with a list of accessions, and, therefore, needs a path as input. Excon, which I'm trying to mimic here, requires a value string as input.

To fix this problem, at least temporariIy, I added in ``modules/local/create_path.csv`` a module that creates one file per species which contains one single accession, which is then used as an input by ncbigenomedownload.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/2,nf-core++genomeqc.csv
I_kwDOM2-kEM6Y2HBz,Add all the modules,CLOSED,2024-10-03T15:12:48Z,2024-10-23T13:36:31Z,2024-10-23T13:36:30Z,Might be a good idea to add an item per module in the Todo list in the genomeqc plan Project.,FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/3,nf-core++genomeqc.csv
I_kwDOM2-kEM6Y2wGw,Branched channels can't be emitted,OPEN,2024-10-03T16:39:46Z,2024-10-03T16:39:46Z,,"Branched channels can't be emitted. In our case, the input channel with local and ncbi branches needs to be declared in ``workflows/genomeqc.nf``, instead of ``subworkflows/local/utils_nfcore_genomeqc_pipeline/main.nf``.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/4,nf-core++genomeqc.csv
I_kwDOM2-kEM6Y2xdO,Add input validation functions to main workflow,CLOSED,2024-10-03T16:43:02Z,2024-10-07T13:53:42Z,2024-10-07T13:53:42Z,"Copy input validation functions to ``workflows/genomeqc.nf``, as main input channel was declated here, instead of ``subworkflows/local/utils_nfcore_genomeqc_pipeline/main.nf``.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/5,nf-core++genomeqc.csv
I_kwDOM2-kEM6Y4fKY,Add test data,CLOSED,2024-10-03T20:26:50Z,2024-10-14T14:00:52Z,2024-10-14T14:00:52Z,"We need a small test dataset for the whole pipeline, following nf-core guides. 

I think this could be just two chromosomes (or parts of chromosomes that are orthologous). Could be super small, like 10000bp total. I am pretty sure all the code will work on tiny chromosomes. 
",chriswyatt1,https://github.com/nf-core/genomeqc/issues/6,nf-core++genomeqc.csv
I_kwDOM2-kEM6Y-Nkw,Validate input samplesheet,OPEN,2024-10-04T13:54:58Z,2024-10-25T15:13:57Z,,We need to think a way to validate the input sample sheet using ``validateInputSamplesheet()``. There is an RNAseq input sample sheet validation as example in ``subworkflows/local/utils_nfcore_genomeqc_pipeline/main.nf``.,FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/8,nf-core++genomeqc.csv
I_kwDOM2-kEM6Zf_og,Add BUSCO module,CLOSED,2024-10-09T09:10:22Z,2024-10-10T09:23:20Z,2024-10-10T09:23:20Z,,FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/9,nf-core++genomeqc.csv
I_kwDOM2-kEM6ZrEy8,Add Orthofinder module,CLOSED,2024-10-10T09:23:54Z,2024-10-14T13:52:29Z,2024-10-14T13:52:29Z,,FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/11,nf-core++genomeqc.csv
I_kwDOM2-kEM6Z4sg_,Problems with Orthofinder module,CLOSED,2024-10-11T16:36:51Z,2024-10-14T13:52:01Z,2024-10-14T13:52:01Z,"Can't seem to make orthofinder work. I think it's related to the ""prior run"" folder.

Changing one line solves the issue.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/12,nf-core++genomeqc.csv
I_kwDOM2-kEM6aJUKL,Add agat_sp_keep_longest_isoform.pl as local module,CLOSED,2024-10-14T13:55:51Z,2024-10-17T11:16:45Z,2024-10-17T11:16:44Z,Add local module for longest isoform filtering from the [synteny](https://github.com/Eco-Flow/synteny) pipeline.,FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/14,nf-core++genomeqc.csv
I_kwDOM2-kEM6aJUt4,Add GFFREAD module,CLOSED,2024-10-14T13:56:23Z,2024-10-17T11:16:27Z,2024-10-17T11:16:26Z,Add GFFREAD nf-core module.,FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/15,nf-core++genomeqc.csv
I_kwDOM2-kEM6aJhAJ,Plot for the phylogenetic tree plus stats (e.g. BUSCO),CLOSED,2024-10-14T14:15:34Z,2024-10-24T14:49:41Z,2024-10-24T14:49:41Z,"The idea here is to make a phylogenetic tree from the output of ""orthofinder"" (currently, but tree software could change), then add the statistics about each genome to the right (BUSCO, chromosome numbers, etc).

",chriswyatt1,https://github.com/nf-core/genomeqc/issues/16,nf-core++genomeqc.csv
I_kwDOM2-kEM6adaN_,Add subworkflows,CLOSED,2024-10-16T10:23:28Z,2024-10-21T08:34:12Z,2024-10-21T08:34:12Z,,FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/17,nf-core++genomeqc.csv
I_kwDOM2-kEM6aeJIZ,GFFREAD does not work with compressed files,CLOSED,2024-10-16T11:34:30Z,2024-10-17T11:16:08Z,2024-10-17T11:16:07Z,"GFFREAD from nf-core cannot deal with compressed files. For now, the nf-core module ``pigz_uncompressed`` is being used to deal with compressed files.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/18,nf-core++genomeqc.csv
I_kwDOM2-kEM6arXKw,unknown recognition error type,OPEN,2024-10-17T15:22:32Z,2024-10-21T08:35:23Z,,"I'm getting this error on start up everytime I run the pipeline:

```
unknown recognition error type: groovyjarjarantlr4.v4.runtime.LexerNoViableAltException
```

I see Simon mentioned the error [here](https://github.com/Eco-Flow/synteny/issues/11), in the synteny pipeline.

I'll look into it later.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/21,nf-core++genomeqc.csv
I_kwDOM2-kEM6arXi7,Add TIDK subworkflow,CLOSED,2024-10-17T15:23:15Z,2024-10-18T13:36:45Z,2024-10-18T13:36:44Z,,FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/22,nf-core++genomeqc.csv
I_kwDOM2-kEM6a04er,Add options to modules.config file,OPEN,2024-10-18T13:41:02Z,2024-10-18T13:41:04Z,,"For each module we should specify the publish directory, as well as other relevant options (e.g., arguments, prefix, etc.).

Add these to the ``modules.config`` file.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/25,nf-core++genomeqc.csv
I_kwDOM2-kEM6a2Zhf,Add modules version to workflow,OPEN,2024-10-18T16:33:24Z,2024-10-18T16:33:24Z,,,FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/27,nf-core++genomeqc.csv
I_kwDOM2-kEM6bGP6Q,Genome only mode,CLOSED,2024-10-21T10:36:37Z,2024-10-28T15:44:33Z,2024-10-28T15:44:33Z,Genome + GFF mode separate,chriswyatt1,https://github.com/nf-core/genomeqc/issues/29,nf-core++genomeqc.csv
I_kwDOM2-kEM6bGREj,Add busco on chromosome plot,CLOSED,2024-10-21T10:38:50Z,2024-11-06T16:03:39Z,2024-11-06T16:03:19Z,https://gitlab.com/ezlab/busco_protocol,chriswyatt1,https://github.com/nf-core/genomeqc/issues/30,nf-core++genomeqc.csv
I_kwDOM2-kEM6bQzwZ,Add AGAT spstatistics and QUAST modules,CLOSED,2024-10-22T09:40:23Z,2024-10-22T09:43:24Z,2024-10-22T09:42:40Z,,FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/31,nf-core++genomeqc.csv
I_kwDOM2-kEM6bSBnC,Quast doesn't cache every time,CLOSED,2024-10-22T11:39:17Z,2024-11-08T15:08:25Z,2024-11-08T15:08:22Z,"Seems to keep repeating previously done runs with `-resume`

My command:

`nextflow run main.nf -resume -profile docker,test --outdir results`",chriswyatt1,https://github.com/nf-core/genomeqc/issues/33,nf-core++genomeqc.csv
I_kwDOM2-kEM6bSDYA,Gitpod config doesn't work,OPEN,2024-10-22T11:41:37Z,2024-10-23T13:47:14Z,,"I get lots of errors using the config. 
The config is used to reduce the cpu requirements of orthofinder etc, so that it can run. 

But get error:

```
-[ecoflow/genomeqc] Pipeline completed with errors-
ERROR ~ Error executing process > 'ECOFLOW_GENOMEQC:GENOMEQC:QUAST (Vespa_velutina)'

Caused by:
  Process requirement exceeds available CPUs -- req: 6; avail: 4
```

when -profile gitpod   contains:

```
process {

    withName: 'ORTHOFINDER' {
        memory = '30.GB'
        cpus = 4
    }

    withName: 'QUAST' {
        memory = '30.GB'
        cpus = 4
    }

}
```",chriswyatt1,https://github.com/nf-core/genomeqc/issues/34,nf-core++genomeqc.csv
I_kwDOM2-kEM6bdYt5,BUSCO fails,OPEN,2024-10-23T10:59:24Z,2024-11-15T11:57:31Z,,"When running ``genomeqc`` on ``assests/samplesheet.csv`` (bees and wasps) BUSCO fails on the SEPP step with this warning message:

```
Placements failed. Try to rerun increasing the memory or select a lineage manually.
```

even though 72GB of RAM are being used.

SEPP is being used to automatically infer the lineage database. When the lineage database is explcitly set, BUSCO runs successfully.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/37,nf-core++genomeqc.csv
I_kwDOM2-kEM6bda-h,BUSCO runs on longest isoforms,CLOSED,2024-10-23T11:03:07Z,2024-11-18T12:21:24Z,2024-11-18T12:20:46Z,"For now, we are using the longest isoforms for each gene to run BUSCO. Might or might not be the proper way to run it",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/38,nf-core++genomeqc.csv
I_kwDOM2-kEM6bfIro,Add MultiQC compatible modules to correct channel,CLOSED,2024-10-23T13:31:22Z,2024-10-30T10:51:03Z,2024-10-30T10:51:03Z,We need to make sure that all the modules that can be sent to MultiQC are,chriswyatt1,https://github.com/nf-core/genomeqc/issues/39,nf-core++genomeqc.csv
I_kwDOM2-kEM6bfUKe,Add new module `HITE`,OPEN,2024-10-23T13:44:00Z,2024-10-29T14:14:51Z,,"HITE is already a series of modules (https://github.com/CSU-KangHu/HiTE), but we could add this either as a sub workflow,, or for now just a module with the main command.",chriswyatt1,https://github.com/nf-core/genomeqc/issues/40,nf-core++genomeqc.csv
I_kwDOM2-kEM6bfWu4,Add NCBI FCS GX module,OPEN,2024-10-23T13:47:30Z,2024-10-31T00:08:31Z,,Add nf-core module to both ``genome`` only and ``genome_and_annotation`` subworkflows.,FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/41,nf-core++genomeqc.csv
I_kwDOM2-kEM6bfcia,Add `merqury` to pipeline,CLOSED,2024-10-23T13:54:02Z,2024-10-29T16:13:32Z,2024-10-29T16:13:32Z,"Example from Usman: https://github.com/Plant-Food-Research-Open/assemblyqc

Used in genome only mode.  Already an nf-core module

",chriswyatt1,https://github.com/nf-core/genomeqc/issues/42,nf-core++genomeqc.csv
I_kwDOM2-kEM6bfesY,Add `Lai` to genome only mode,OPEN,2024-10-23T13:56:27Z,2024-10-24T20:07:27Z,,Add nf-core module for `lai` to genome only mode sub workflow,chriswyatt1,https://github.com/nf-core/genomeqc/issues/43,nf-core++genomeqc.csv
I_kwDOM2-kEM6boSX7,Test genome only download runs from NCBI DOWNLOAD,OPEN,2024-10-24T09:41:43Z,2024-10-24T09:41:43Z,,"I think it will be possible to run the pipeline potentially with Genbank accessions (GCA.......).

At the moment, either you supply the genome + annotation manually, or use NCBI DOWNLOAD on a Refseq ID (GCF......) to get the genome and annotation automatically. 

GCA accensions often only link to a genome wihtout a annotation in GFF, but these people may want to run. 

We should test if this is a possible feature to add",chriswyatt1,https://github.com/nf-core/genomeqc/issues/44,nf-core++genomeqc.csv
I_kwDOM2-kEM6bpYNe,Modules and tools ideas,OPEN,2024-10-24T11:44:35Z,2024-10-24T11:55:36Z,,"See [genomeqc ideas](https://docs.google.com/spreadsheets/d/11lY3jTASVW8wyn4viIEGu94huaSzH96nxYf6NsfDaWw/edit?gid=0#gid=0) spreadsheet.

### Genome only

- [x] BUSCO. Genome completness. Can be run on ""genome"" only mode (runs Augustus first) or in ""protein"" mode (fasta with protein sequences).
- [x] QUAST. Assembly contiguity (e.g. N50).
    - Also accepts GFF as input, but AGAT gives more complete statistics.

- [ ] HITE. Calculation of Transposable element content.
    - Not in nf-core 
- [ ] SVbyEye. Structural variation among whole genome assemblies.
- [x] TIDK. Telomere repeat identification.
   - Subworkflow
- [ ] LAI. Continuity of LTR sequences.
- [ ] NCBI FCS GX. Foreign contamination
- [ ] Merqury. Phasing assessment
- [ ] PLOTSR. Chromosome level summary synteny.
- [ ] MUMMER/DOTPLOT. Sequence level synteny.
- [ ] TEsorter. Captures TEs in protein domains.
- [ ] Asmgene. For evaluating gene completeness and duplication.
- [ ] calN50.js. Calculating N50 and L90
    - Probably redundant.

### Annotation only

- [x] AGAT. Genome basic statistics (gene length averages, etc).
- [ ] GenomeTools (Optional?).
- [ ] pangene. Gene variability using miniprot output.
- [ ] Liftoff. Lifting annotations

### Genome and Annotation

- [x] Orthofinder. Phylogenetic trees (or a better program, PHY ).
- [ ] MCSCanX. Synteny between two genomes (or other program).
- [ ] GENESPACE. Runs everything that the above does.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/45,nf-core++genomeqc.csv
I_kwDOM2-kEM6bqi0-,Add ability to turn off specific modules,OPEN,2024-10-24T13:27:35Z,2024-10-28T10:54:58Z,,"Some modules should be optional. 

We should add conditional flags/params in the pipeline",chriswyatt1,https://github.com/nf-core/genomeqc/issues/46,nf-core++genomeqc.csv
I_kwDOM2-kEM6brEo_,Add nf-test,OPEN,2024-10-24T14:21:29Z,2024-10-28T11:27:17Z,,"Once we have a first release pipeline, we need to make sure the nf-test part for whole pipeline is working, and check all the modules (etc).",chriswyatt1,https://github.com/nf-core/genomeqc/issues/48,nf-core++genomeqc.csv
I_kwDOM2-kEM6brLCN,Add a tree building method for genome only,OPEN,2024-10-24T14:29:04Z,2024-10-28T11:51:04Z,,"BUSCO protocol potentially may be able to do this. 

It would be great if we could get a tree plot plus stats for all the genome only modules, but start with BUSCO",chriswyatt1,https://github.com/nf-core/genomeqc/issues/49,nf-core++genomeqc.csv
I_kwDOM2-kEM6brON_,Logic for variable input types,CLOSED,2024-10-24T14:33:56Z,2024-11-06T17:58:43Z,2024-11-06T17:58:02Z,"It should work for genome only if there are only genome, or genome_annotation if only genomes with annotations. 

But we also need to test how the pipeline deals with mixed input. It run both subworkflows, and potentially all genomes separately.",chriswyatt1,https://github.com/nf-core/genomeqc/issues/50,nf-core++genomeqc.csv
I_kwDOM2-kEM6brUCY,Create tube map,OPEN,2024-10-24T14:41:14Z,2024-10-28T11:00:41Z,,"Might change a lot as the pipeline gets developed, but might be worth creating one now",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/51,nf-core++genomeqc.csv
I_kwDOM2-kEM6bxKpi,Remove unused bin scripts (from excon),CLOSED,2024-10-25T07:47:17Z,2024-10-25T09:04:04Z,2024-10-25T09:04:04Z,Most the bin is full of things we do not use in this pipeline. It should be cleared out,chriswyatt1,https://github.com/nf-core/genomeqc/issues/52,nf-core++genomeqc.csv
I_kwDOM2-kEM6bzQYM,Check linting,OPEN,2024-10-25T11:57:49Z,2024-10-25T11:57:49Z,,Check pipeline linting.,FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/54,nf-core++genomeqc.csv
I_kwDOM2-kEM6b08d-,Pipeline fails when running on input_myco_tiny.csv dataset.,OPEN,2024-10-25T14:56:04Z,2024-10-25T15:08:04Z,,"Pipeline fails on BUSCO step when running on testdata.

The problem seems to be related to the ``input_myco_tiny.csv`` dataset.

Choosing ``bacteria_odb10`` as lineage to run BUSCO fixes the issue, but we should probably have a look at other alternatives.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/55,nf-core++genomeqc.csv
I_kwDOM2-kEM6b-wNN,Check schema_input.json,OPEN,2024-10-27T22:37:18Z,2024-10-27T22:48:41Z,,"Check 'required' field in ``schema_input.json``, as right now only the 'species' field is mandatory in the samplesheet for input schema validation.

The reason why only 'species' is required right now is that input samplesheet is flexible, meaning it can accept samples with different field information -e.g., a sample can have a RefSeq ID while another sample can have local files.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/56,nf-core++genomeqc.csv
I_kwDOM2-kEM6cC9F5,Add meryl count,CLOSED,2024-10-28T10:37:51Z,2024-10-29T16:13:31Z,2024-10-29T16:13:31Z,"#42 merqury requires a meryl kmer db, which needs meryl count, already an nf-core module.

- exmaple: https://github.com/Plant-Food-Research-Open/assemblyqc/blob/main/workflows/assemblyqc.nf
- meryl module: https://nf-co.re/modules/meryl_count/",stephenturner,https://github.com/nf-core/genomeqc/issues/58,nf-core++genomeqc.csv
I_kwDOM2-kEM6cDUiP,Migrate to nf-schema,OPEN,2024-10-28T11:17:19Z,2024-10-28T11:18:45Z,,"Migrate from nf-validation to nf-schema. Check [migration guide](https://nextflow-io.github.io/nf-schema/latest/migration_guide/).

This related to #56.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/59,nf-core++genomeqc.csv
I_kwDOM2-kEM6cEbor,add meryl union sum,CLOSED,2024-10-28T13:18:54Z,2024-10-29T16:13:31Z,2024-10-29T16:13:31Z,"#42 merqury requires a meryl kmer db, which needs meryl union sum after count, already an nf-core module.

- exmaple: https://github.com/Plant-Food-Research-Open/assemblyqc/blob/main/workflows/assemblyqc.nf
- meryl unionsum module: https://nf-co.re/modules/meryl_unionsum/",stephenturner,https://github.com/nf-core/genomeqc/issues/60,nf-core++genomeqc.csv
I_kwDOM2-kEM6cEyOP,GFFREAD fails,OPEN,2024-10-28T13:54:23Z,2024-10-28T13:54:23Z,,The pipeline didn't work downloading the arbidopsis thaliana reference genome from ncbi (GCF_000001735.4). ,fperezcobos,https://github.com/nf-core/genomeqc/issues/61,nf-core++genomeqc.csv
I_kwDOM2-kEM6cFWnb,Optionally pass in reads,CLOSED,2024-10-28T14:47:44Z,2024-10-29T16:13:32Z,2024-10-29T16:13:32Z,"To run merqury you need reads. Update the workflow to have the ability to pass in reads (skip the process if you don't pass in reads). 

TODO:

- [x] download assemblies in samplesheet used in testdata: https://github.com/nf-core/test-datasets/blob/genomeqc/samplesheet/input_bacteria.csv
- [x] Simulate pacbio/ONT reads at low coverage from these assemblies -- add those to the tesdata directory in the https://github.com/nf-core/test-datasets/blob/genomeqc/ data dir, submit PR to test-datasets - get Chris or `mahesh-panchal` to review
- [x] add new column to samplesheet
- [x] add new info to assets/schema_input.json
- [x] update `subworkflows/local/utils_nfcore_genomeqc_pipeline/main.nf` `validateInputSamplesheet()` @chriswyatt1 @FernandoDuarteF 
- [x] update `workflows/genomeqc.nf` to pull fastq from samplesheet into channels
- [x] adjust downstream process cardinality
- [x] back to #42 -- check that fastq is not `null` before initiating merqury steps
- [x] edit test.config profile to turn `params.merqury_skip=false`
- [x] test with inputs without fastq defined",stephenturner,https://github.com/nf-core/genomeqc/issues/62,nf-core++genomeqc.csv
I_kwDOM2-kEM6cOMeb,Add new test_with_merqury profile,CLOSED,2024-10-29T11:32:09Z,2024-10-29T16:13:33Z,2024-10-29T16:13:32Z,"- [ ] Add new test_with_merqury profile that turns `merqury_skip` to false and uses the samplesheet with fastqs
- [ ] Revert changes to test.config that removes `merqury_skip=false`, and uses the samplesheet without without fastq files
- [ ] Add new test_with_merqury.conf to import in main nextflow.config",stephenturner,https://github.com/nf-core/genomeqc/issues/67,nf-core++genomeqc.csv
I_kwDOM2-kEM6cOMwS,Update README.md with merqury info,CLOSED,2024-10-29T11:32:45Z,2024-10-29T16:13:33Z,2024-10-29T16:13:33Z,"What's merqury, why, and how to run different test profiles

- #67 ",stephenturner,https://github.com/nf-core/genomeqc/issues/68,nf-core++genomeqc.csv
I_kwDOM2-kEM6cONzr,Input samplesheet with .meta operator instead of branch by size,OPEN,2024-10-29T11:35:00Z,2024-10-29T11:35:10Z,,"@LaurenHuet  :
It may be clearer if the input samplesheet used the .meta.gff or .meta.fasta notation, instead of the current:

```
        .branch {
            ncbi: it.size() == 2
            local: it.size() == 3
        }
```

As when we add new input columns it will mess things up",chriswyatt1,https://github.com/nf-core/genomeqc/issues/69,nf-core++genomeqc.csv
I_kwDOM2-kEM6cQhPc,Extract meryl+merqury subworkflow into modules,OPEN,2024-10-29T15:19:53Z,2024-10-30T09:45:12Z,,"PR #63 brings in changes that allow optionally passing in reads to support quality metrics that require them, such as using kmer counts from raw sequencing data to evaluate accuracy and completeness using Merqury (#42). @GallVp added a nice suggestion in #63 to extract a subworkflow into nf-core/modules that could be used across workflows. 

See also:
- https://github.com/nf-core/modules/issues/6905 (new subworkflow issue in nf-core/modules -- after this is finished, come back to genomeqc here to use the subworkflow module 

----

Would be great to support the trio mode with parental reads. This is supported by the `assemblyqc` pipeline. Maybe, we can extract a sub workflow, put it on nf-core/modules so that the two pipelines can benefit from shared development. Please see the workflow on the `assemblyqc` repo:

https://github.com/Plant-Food-Research-Open/assemblyqc/blob/cec2728d0785d97e0e9493558c83d83d0b48240e/workflows/assemblyqc.nf#L598-L771

_Originally posted by @GallVp in https://github.com/nf-core/genomeqc/issues/63#issuecomment-2442810796_
            ",stephenturner,https://github.com/nf-core/genomeqc/issues/71,nf-core++genomeqc.csv
I_kwDOM2-kEM6cY4pH,"Merqury inputs should use database+assembly (fasta, not fastq)",CLOSED,2024-10-30T11:24:21Z,2024-11-07T12:05:18Z,2024-11-07T12:05:17Z,"Merqury inputs should include the meryl db (created from reads), and the _assembly_. 

https://github.com/nf-core/genomeqc/blob/5e5f897730524eb771aa574920a42064876f1ea1/modules/nf-core/merqury/merqury/main.nf#L11-L12

Typo in the current implementation that joins to the reads (fasta), not the assembly.

https://github.com/nf-core/genomeqc/blob/5e5f897730524eb771aa574920a42064876f1ea1/workflows/genomeqc.nf#L127-L129

Need to change this to fasta, not fastq.

Also need to change this in the subworkflow nf-core/modules#6905",stephenturner,https://github.com/nf-core/genomeqc/issues/75,nf-core++genomeqc.csv
I_kwDOM2-kEM6cf-9d,Using `FASTA_GXF_BUSCO_PLOT ` sub workflow,OPEN,2024-10-31T00:04:43Z,2024-11-22T09:55:39Z,,"Hello Team!

I built a reusable sub workflow for performing BUSCO on genome alone, or on genome and annotation. I have used it in two other pipelines. It is currently sitting in my own modules repo:  https://github.com/GallVp/nxf-components/blob/7188d37139f8dbdfd73cbfb5b0e3f811d1993392/subworkflows/gallvp/fasta_gxf_busco_plot/main.nf#L7

I think we should be sharing this across pipelines. I can submit it to nf-core/modules and add it here. Checking if there is interest here and if there is need to modify it to suite the needs of this pipeline?

- Mentions, @FernandoDuarteF , @chriswyatt1, @stephenturner
- nf-core issue: https://github.com/nf-core/modules/issues/5584
- Other pipelines using it:
  - https://github.com/Plant-Food-Research-Open/assemblyqc/blob/cec2728d0785d97e0e9493558c83d83d0b48240e/workflows/assemblyqc.nf#L442
  - https://github.com/Plant-Food-Research-Open/genepal/blob/24a8f50e241105b98c88035fd9c2a0cad8ff728f/workflows/genepal.nf#L206",GallVp,https://github.com/nf-core/genomeqc/issues/77,nf-core++genomeqc.csv
I_kwDOM2-kEM6c5DIy,Check what needs to be in results,OPEN,2024-11-04T08:48:55Z,2024-11-04T08:48:55Z,,"Currently, the uncompressed ends up in results. There may be more results we don't need to publish",chriswyatt1,https://github.com/nf-core/genomeqc/issues/78,nf-core++genomeqc.csv
I_kwDOM2-kEM6dElH1,Run from GCA genome only IDs,OPEN,2024-11-05T11:41:54Z,2024-11-05T11:41:54Z,,We may want to run just from genome only IDs from NCBI,chriswyatt1,https://github.com/nf-core/genomeqc/issues/79,nf-core++genomeqc.csv
I_kwDOM2-kEM6dElZc,Run from GTF files (instead of GFF3),OPEN,2024-11-05T11:42:27Z,2024-11-05T11:42:27Z,,Some people may need this feature,chriswyatt1,https://github.com/nf-core/genomeqc/issues/80,nf-core++genomeqc.csv
I_kwDOM2-kEM6dFbGV,Make ``GENOME`` and ``GENOME_AND_ANNOTATION`` into workflows,OPEN,2024-11-05T13:17:49Z,2024-11-05T23:57:52Z,,"We should make our two main subworflows (``GENOME`` and ``GENOME_AND_ANNOTATION``) into workflows, as it makes more sense for the structure and modularization of the pipeline (we cannot use subworkflows inside subworflows).

For example, as for now, we would not be able to import the BUSCO subworkflow from #77 inside ``GENOME_AND_ANNOTATION`` subworkflow.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/81,nf-core++genomeqc.csv
I_kwDOM2-kEM6dSDAC,Pipeline fails if genome or gff are not gzipped,CLOSED,2024-11-06T17:28:28Z,2024-11-06T22:48:18Z,2024-11-06T22:48:18Z,"There should be a statement to divert non gzipped input directly to gffread, not try to uncompress it. 


e.g.
```
ERROR ~ Error executing process > 'ECOFLOW_GENOMEQC:GENOMEQC:UNCOMPRESS_GFF (5)'

Caused by:
  Process `ECOFLOW_GENOMEQC:GENOMEQC:UNCOMPRESS_GFF (5)` terminated with an error exit status (1)


Command executed:

  unpigz \
      -p 2 \
      -fk \
       \
      Polistes_fuscatus.GCF_010416935.1_CU_Pfus_HIC_genomic.fna
  
  cat <<-END_VERSIONS > versions.yml
  ""ECOFLOW_GENOMEQC:GENOMEQC:UNCOMPRESS_GFF"":
      pigz: $(echo $(pigz --version 2>&1) | sed 's/^.*pigz\w*//' ))
  END_VERSIONS

Command exit status:
  1

Command output:
  (empty)

Command error:
  INFO:    Environment variable SINGULARITYENV_TMP is set, but APPTAINERENV_TMP is preferred
  INFO:    Environment variable SINGULARITYENV_TMPDIR is set, but APPTAINERENV_TMPDIR is preferred
  INFO:    Environment variable SINGULARITYENV_NXF_TASK_WORKDIR is set, but APPTAINERENV_NXF_TASK_WORKDIR is preferred
  INFO:    Environment variable SINGULARITYENV_NXF_DEBUG is set, but APPTAINERENV_NXF_DEBUG is preferred
  unpigz: skipping: Polistes_fuscatus.GCF_010416935.1_CU_Pfus_HIC_genomic.fna does not have compressed suffix
```
",chriswyatt1,https://github.com/nf-core/genomeqc/issues/83,nf-core++genomeqc.csv
I_kwDOM2-kEM6da4vS,BUSCO fails due to rate limiter,OPEN,2024-11-07T13:41:29Z,2024-11-07T13:41:29Z,,"We should use the subworkflow used in MAG ideally to resolve this: 
https://github.com/nf-core/mag/blob/master/subworkflows/local/busco_qc.nf

As, we should provide the option to provide a database, so that it doesn't download one for each sample we send through the pipeline. 

This issue was raised here: 
https://github.com/nf-core/mag/issues/333",chriswyatt1,https://github.com/nf-core/genomeqc/issues/85,nf-core++genomeqc.csv
I_kwDOM2-kEM6eDd6A,``BUSCO_IDEOGRAM`` fails when using ``samplesheet.csv``,CLOSED,2024-11-12T10:16:16Z,2024-11-19T10:46:33Z,2024-11-19T10:46:33Z,"The attribute field (9th column) is not consistent between gff files. For this reason BUSCO Ideogram fails when using ``samplesheet.csv`` as input, but works on the test dataset.

The ``busco_create_table_for_plot.R`` script uses ``inner_join()`` to merge both ``full_table.tsv`` from BUSCO and the gff annotation into a single table, based on the first field of the attibute column of the gff. However, this field is not consistent among datasets.

Will have to modify the script or look for alternatives.

_Originally posted by @FernandoDuarteF in https://github.com/nf-core/genomeqc/issues/82#issuecomment-2470128095_
            ",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/86,nf-core++genomeqc.csv
I_kwDOM2-kEM6edq5F,`AGAT_CONVERTSPGXF2GXF` on myriad needs more memory,OPEN,2024-11-14T11:46:04Z,2024-11-14T11:46:04Z,,"When running **genomeqc** on the myriad cluster, I noticed that the process `AGAT_CONVERTSPGXF2GXF` requires more memory for some reason. Changing the label to `process_medium` solves the issue.

On local it runs fine.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/89,nf-core++genomeqc.csv
I_kwDOM2-kEM6eeSiZ,ideograms plot all contigs,OPEN,2024-11-14T13:00:54Z,2024-11-21T11:50:49Z,,"It would be great if the ideogram plot only plotted the main ortholoug chromosomes. Else you get images like:

![Image](https://github.com/user-attachments/assets/74baa9e7-01a9-49f3-a1ed-4e08815da954)
",chriswyatt1,https://github.com/nf-core/genomeqc/issues/90,nf-core++genomeqc.csv
I_kwDOM2-kEM6epU5C,Ideograms do not have a key,CLOSED,2024-11-15T10:57:53Z,2024-11-20T14:39:52Z,2024-11-20T14:39:51Z,It would be nice to have a key to explain the colours. ,chriswyatt1,https://github.com/nf-core/genomeqc/issues/91,nf-core++genomeqc.csv
I_kwDOM2-kEM6fC7T5,WIP: check `agat_sp_extract_sequences.pl` as an alternative to `GFFREAD`,CLOSED,2024-11-18T12:07:57Z,2024-11-20T14:39:20Z,2024-11-20T14:39:20Z,"I was checking the [BUSCO phylogenomic tree protocol](https://gitlab.com/ezlab/busco_protocol/-/blob/main/support_protocol3/rules/filter_isoforms.smk?ref_type=heads), and I noticed that they use the `agat_sp_extract_sequences.pl` script from **AGAT** to extract the proteins sequences from a filtered gff.

Might be worth trying.

This issue is related to #37.",FernandoDuarteF,https://github.com/nf-core/genomeqc/issues/92,nf-core++genomeqc.csv
I_kwDOM2-kEM6fpdca,New feature: Check for overlapping genes in GFF (bedtools intersect),OPEN,2024-11-21T07:55:47Z,2024-11-21T09:02:55Z,,"Another way we discussed to assess annotation quality is to look at overlapping genes, sense and antisense. 

You would expect that similar genomes would have the same rate of these classes, if not, there could have been a technical issue while building the gene annotation. So it is useful to know.",chriswyatt1,https://github.com/nf-core/genomeqc/issues/93,nf-core++genomeqc.csv
I_kwDOKcZwFs50c3yT,Add CAGE UTR to annotation,CLOSED,2023-10-20T07:43:19Z,2023-11-28T08:27:52Z,2023-11-28T08:27:52Z,,johannesnicolaus,https://github.com/oist/Oikopleuradioica_genomeannotation/issues/1,oist++Oikopleuradioica_genomeannotation.csv
I_kwDOKcZwFs50c4c9,Symlink for jbrowse2,OPEN,2023-10-20T07:45:15Z,2023-10-20T07:45:15Z,,"Currently if the name of the gff file changes, the jbrowse config needs to be changed, if there is a permanent symlink to any updated annotation, it will fix this requirement.",johannesnicolaus,https://github.com/oist/Oikopleuradioica_genomeannotation/issues/2,oist++Oikopleuradioica_genomeannotation.csv
I_kwDOKcZwFs50c6yn,Error message when searching for gene ID,CLOSED,2023-10-20T07:51:47Z,2023-10-30T22:13:17Z,2023-10-30T22:13:16Z,"Somehow there is an error message produced when searching for gene ID, but functionality is not broken",johannesnicolaus,https://github.com/oist/Oikopleuradioica_genomeannotation/issues/3,oist++Oikopleuradioica_genomeannotation.csv
I_kwDOKcZwFs50-Qr6,Add synteny tracks,CLOSED,2023-10-26T00:03:08Z,2023-10-30T22:12:44Z,2023-10-30T22:12:44Z,https://jbrowse.org/jb2/docs/config_guides/synteny_track/,johannesnicolaus,https://github.com/oist/Oikopleuradioica_genomeannotation/issues/4,oist++Oikopleuradioica_genomeannotation.csv
I_kwDOKcZwFs58TP0b,Add gene name,CLOSED,2024-01-17T05:26:28Z,2024-01-31T01:51:22Z,2024-01-31T01:51:22Z,"Currently, only gene ID is available and is very uninformative. Try to add gene name using eggnog based annotation",johannesnicolaus,https://github.com/oist/Oikopleuradioica_genomeannotation/issues/5,oist++Oikopleuradioica_genomeannotation.csv
MDU6SXNzdWUyMjc2MjMyMzM=,Avoiding to rezip chr-src/ in final steps,CLOSED,2017-05-10T09:44:38Z,2017-07-25T03:25:52Z,2017-07-25T03:25:52Z,"Hi,

Is it possible to avoid rezipping chr-src in the final steps?
This would speed up creating a new database, depending on the species this could be significant.

regards,
Evelyne",EvelyneC,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/1,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWUyMjgyMjI5OTk=,"Stuck on ""processing database"" - database not created",CLOSED,2017-05-12T08:32:01Z,2017-08-15T18:32:58Z,2017-08-15T18:32:58Z,"Copy/pasted from a SIFT user, using a MAC:

After a while it exists without creating the database with the following command:

** Checking query data and substitutions files **
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
* processing database part 157 (size ~0.25 GB): 85.00/100.00% **

And I realized that the homo sapiens small test file also runs until this step and stops without an error or warning and the database is not created either. It is my bad that I never checked the database created for the test files and assumed that it was ok as no error messages were printed.

I am thinking this could be due to RAM limitations. I am currently running this on my local computer (16 GB RAM). Do you think that would be the problem? I also tried installing this on our computing cluster, but sift4g is giving errors. Those are I think related to compiler version issues but I am using the version recommended (4.8). The error message (following) points to compiler version which according to stackoverflow can be fixed by compiling with 4.9. So I will try that. 

** Checking query data and substitutions files **
terminate called after throwing an instance of 'std::regex_error'
  what():  regex_error
Aborted

",pauline-ng,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/2,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWUyMjgyMjY5NzY=,GFF file format,CLOSED,2017-05-12T08:49:13Z,2017-05-12T08:49:53Z,2017-05-12T08:49:22Z,"Via email --- A GFF file for a new genome wasn't working.

Written by SIFT team:
I looked at your gff file and it's missing a few things.  Please look at the gtf examples like homo_sapiens_small or C.ruddii if the explanation below is unclear.

1) Add rows for ""start_codon"" and ""stop_codon""
We need this because the program has to demarcate when translation starts and stops (genes can have 5' and 3' UTRs in the exon). 

2) The 9th column is missing some fields that SIFT is looking for. 

2a) The program will look for a protein_id in the 9th column. If you don't have a protein_id, maybe use the transcript id which is usually a 1-1 mapping with a protein id.

2b) For each row, please specify the biotype. It can be protein_coding  
gene_biotype ""protein_coding"" or noncoding RNA (e.g. ""rRNA"", ""miRNA""), etc. SIFT will only predict on protein_coding rows.
Here's an example on how to change the 9th column:

OLD:
HanXRQCP    BioFileConverter    exon    98077    98226    .    -    .    transcript_id ""mRNA:HanXRQCPg0580291""; gene_id ""gene:HanXRQCPg0580291""; gene_name ""Ha
nXRQCPg0580291"";

NEW:
HanXRQCP    BioFileConverter    exon    98077    98226    .    -    .    transcript_id ""mRNA:HanXRQCPg0580291""; gene_id ""gene:HanXRQCPg0580291""; gene_name ""Ha
nXRQCPg0580291""; protein_id ""HanXRQCPg0580291""; gene_biotype ""protein_coding""
",pauline-ng,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/3,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWUyNDE1NzI4Nzg=,requirements gtf files,CLOSED,2017-07-10T00:43:22Z,2019-12-05T12:08:34Z,2017-11-22T15:31:01Z,"Hi Pauline,
This is not a issue, it is more a question about formatting. I'm trying to build a new database and I create my own gft file.
Which are the row mandatory (CDS, exon, gene, start_codon, stop_codon, transcript ...)?
In the readme you said that  the 9th column (attribute column) says gene_biotype ""protein_coding;"" and 2nd column in the gtf file says 'protein_coding'.
In the 2nd column in the Homo_sapiens.GRCh38.83_trimmed.gtf.gz specifies the database (ensemble, havana...) and I think is correct to leave like that.
in the 9th column, In which rows (CDS, exon, gene, start_codon, stop_codon, transcript ...) do I have to put the gene_biotype ""protein_coding""?
Best,

Marco
",fraca,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/4,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWUyNzAyNDYwMzk=,Bio::DB::IndexedBase::_strip_crnl redefined,CLOSED,2017-11-01T09:22:48Z,2019-11-12T02:54:21Z,2019-11-12T02:54:20Z,"Hi @pauline-ng,
While running the homo test,  I find there is a error log(repeat 3 times in whole test):
```
Subroutine Bio::DB::IndexedBase::_strip_crnl redefined at /public/home/lchen/software/ActivePerl-5.18.4/site/lib/Bio/DB/IndexedBase.pm line 304.
```
I'm very confused about that problem, and cannot find a way to sovle it. Hope can get some advise form you. By the way, I stiil get some results(such as below). 
```
ll GRCh38.83/
total 225881
-rw-r--r-- 1 lt bio       230954285 Nov  1 13:48 21.gz
-rw-r--r-- 1 lt bio       117688 Nov  1 13:47 21.regions
-rw-r--r-- 1 lt bio       442 Nov  1 13:53 21_SIFTDB_stats.txt
-rw-r--r-- 1 lt bio       242 Nov  1 13:50 CHECK_GENES.LOG
-rw-r--r-- 1 lt bio       926 Nov  1 13:53 homo_sapiens-test.txt
-rw-r--r-- 1 lt bio       230186 Nov  1 13:48 MT.gz
-rw-r--r-- 1 lt bio       444 Nov  1 13:48 MT.regions
-rw-r--r-- 1 lt bio       419 Nov  1 13:53 MT_SIFTDB_stats.txt
```

And thanks in advance",conniecl,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/5,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWUyNzU3MTkwNjk=,Problem creating genomic database for new organism,CLOSED,2017-11-21T13:51:44Z,2019-12-05T12:07:59Z,2019-11-12T02:56:19Z,"Dear SIFT 4G team

I followed the instructions from ""https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB"" to construct the database for a new organism. In my case, I am constructing the database for Cicer arietinum. I am getting the following error while running the script ""make-SIFT-db-all.pl"" using the following command:

Command:
perl make-SIFT-db-all.pl -config test_files/cicer_arietinum_config.txt

Log:
perl make-SIFT-db-all.pl -config test_files/cicer_arietinum_config.txt 
converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
cat: ./test_files/cicer_arietinum_genome/fasta/*.fasta: No such file or directory
/data/ngs/Programs_latest/SIFT4G_v2.0.0/bin/sift4g -d ./test_files/protein_db/uniref90.fasta -q ./test_files/cicer_arietinum_genome/all_prot.fasta --subst ./test_files/cicer_arietinum_genome/subst --out ./test_files/cicer_arietinum_genome/SIFT_predictions --sub-results 
** Checking query data and substitutions files **


** EXITING! No valid queries to process. **

I also tried running the same script for the test human dataset provided with the package, but I am observing a different error:

Command:
perl make-SIFT-db-all.pl -config test_files/homo_sapiens-test.txt 

Log:
converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
/data/ngs/Programs_latest/SIFT4G_v2.0.0/bin/sift4g -d ./test_files/protein_db/uniref90.fasta -q ./test_files/homo_sapiens_small/all_prot.fasta --subst ./test_files/homo_sapiens_small/subst --out ./test_files/homo_sapiens_small/SIFT_predictions --sub-results 
** Checking query data and substitutions files **
terminate called after throwing an instance of 'std::regex_error'
  what():  regex_error

My config file for the Cicer arietinum looks like:
GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=./test_files/cicer_arietinum_genome
ORG=cicer_arietinum
ORG_VERSION=v1.0
DBSNP_VCF_FILE=

#Running SIFT 4G
SIFT4G_PATH=/data/ngs/Programs_latest/SIFT4G_v2.0.0/bin/sift4g
PROTEIN_DB=./test_files/protein_db/uniref90.fasta
COMPUTER=mrna


GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord

I need help to resolve this error and construction of the database for my organism.

It would be really appreciable if I can be guided to resolve the error mentioned.

I would be thankful for all the help.

Best regards
Aamir",aamirwkhan06,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/6,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWUzOTAwMzU1NjA=,Issues creating database for new genome version,CLOSED,2018-12-12T02:15:04Z,2019-03-23T23:52:23Z,2019-03-23T23:52:23Z,"Hi,

I am trying to create a database for the EquCab3 version of our genome which is only present on NCBI. This is the code I am running:
```bash
perl make-SIFT-db-all.pl -config test_files/EquCab3_config.txt
```

This is the error that I get:
```bash
done making the fasta sequences
start siftsharp, getting the alignments
/home/mccuem/durwa004/.conda/envs/sift4g/bin/sift4g -d /home/mccuem/shared/Projects/HorseGenomeProject/Data/Variant_interpretation/sift4g/UniRef90/uniref90.fasta -q /home/mccuem/shared/Projects/HorseGenomeProject/Data/Variant_interpretation/sift4g/EquCab3_db_121018/all_prot.fasta --subst /home/mccuem/shared/Projects/HorseGenomeProject/Data/Variant_interpretation/sift4g/EquCab3_db_121018/subst --out /home/mccuem/shared/Projects/HorseGenomeProject/Data/Variant_interpretation/sift4g/EquCab3_db_121018/SIFT_predictions --sub-results 
** Checking query data and substitutions files **
terminate called after throwing an instance of 'std::regex_error'
  what():  regex_error
```
Prior to this error - I get a mixture of these 2 errors multiple times:
```bash
Use of uninitialized value $exon_num in concatenation (.) or string at generate-fasta-subst-files-BIOPERL.pl line 912.
Argument """" isn't numeric in addition (+) at generate-fasta-subst-files-BIOPERL.pl line 860.
```
It looks like some of the files are being produced - this is the total size of the files in my home directory:
```bash
32K	fasta.log
32K	Log2.txt
48K	EquCab3
48K	SIFT_alignments
48K	SIFT_predictions
48K	singleRecords_with_scores
64K	invalid.log
12M	.panfs.1b2d1f0a.1544496885706510000
30M	all_prot.fasta
37M	peptide.log
66M	gene-annotation-src
209M	EquCab3.gene.gtf
595M	fasta
2.1G	subst
2.7G	chr-src
90G	singleRecords
96G	total
```
I have been having issues with the .gtf but think I have it in the right format (I have attached it to the issue).
[EquCab3.gtf.gz](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/2670198/EquCab3.gtf.gz)

Thanks in advance for your assistance.

Sian
",durwa004,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/7,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU0MjQ1NTc0NzQ=,Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 301,CLOSED,2019-03-23T23:51:52Z,2023-04-23T09:35:34Z,2019-04-12T15:44:35Z,"@pauline-ng 
Hi Pauline
I encountered similar problem like Sian.
A big log file with repetitive warnings like ""Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 301.""

All input  data are from ensemblplant(ftp://ftp.ensemblgenomes.org/pub/plants/release-42/gtf/triticum_aestivum/     and     ftp://ftp.ensemblgenomes.org/pub/plants/release-42/fasta/triticum_aestivum/dna/) 

Any advice?

Thanks,
Lipeng

_Originally posted by @LipengKang in https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/7#issuecomment-475228113_",pauline-ng,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/8,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU0NDEzMDgwNDU=,regex_error when created database,CLOSED,2019-05-07T15:50:04Z,2019-05-09T01:36:23Z,2019-05-09T01:36:23Z,"Dear SIFT4G team

I followed the README.md to constructed the database for the test human genome in test_files, but I got an error:

converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
/public/sxzhang/tool/sift4g/bin/sift4g -d /public/sxzhang/tool/SIFT4G_Create_Genomic_DB/test_files/uniref90.fasta -q ./test_files/homo_sapiens_small/all_prot.fasta --subst ./test_files/homo_sapiens_small/subst --out ./test_files/homo_sapiens_small/SIFT_predictions --sub-results
** Checking query data and substitutions files **
terminate called after throwing an instance of 'std::regex_error'
  what():  regex_error

I have tried to solve this problem by updating my g++ version to 6.1.0, but I still got the same error.

Thanks in advance for your advice.",daxian248,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/9,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU0NTA1MTg3NDg=,Issues in creating a database for a new organism,CLOSED,2019-05-30T21:40:21Z,2019-06-03T23:00:34Z,2019-06-03T23:00:33Z,"Dear SIFT 4G team

Ia trying to create a SIFT database for a plant species. Follow the instructions ( https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/blob/master/README.md), I generated the files required and started to create the database using this command :

```
perl make-SIFT-db-all.pl -config Sevir_config.txt
```
The configuration file is like this :

```
GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=./Sevir
ORG=setaria_viridis
ORG_VERSION=JGI_v2.1
DBSNP_VCF_FILE=

#Running SIFT 4G
SIFT4G_PATH=../sift4g/bin/sift4g
PROTEIN_DB=./protein_db/uniref90.fasta
COMPUTER=GIS-KATNISS


# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord
```


However, the program stuck at the ""Selecting alignments with median threshold"" step for more than week without giving a warning or breaking message. As shown below: 

```
converting gene format to use-able input
done converting gene format
making single records file
Possible precedence issue with control flow operator at /share/apps/perlbrew/perls/perl-5.22.1/lib/site_perl/5.22.1/Bio/DB/IndexedBase.pm line 791.
done making single records template
making noncoding records file
Possible precedence issue with control flow operator at /share/apps/perlbrew/perls/perl-5.22.1/lib/site_perl/5.22.1/Bio/DB/IndexedBase.pm line 791.
done making noncoding records
make the fasta sequences
Possible precedence issue with control flow operator at /share/apps/perlbrew/perls/perl-5.22.1/lib/site_perl/5.22.1/Bio/DB/IndexedBase.pm line 791.
done making the fasta sequences
start siftsharp, getting the alignments
../sift4g/bin/sift4g -d ./protein_db/uniref90_test50000.fasta -q ./Sevir/all_prot.fasta --subst ./Sevir/subst --out ./Sevir/SIFT_predictions --sub-results 
** Checking query data and substitutions files **
* processing queries: 0.00/100.00% *
* processing queries: 0.01/100.00% *
* processing queries: 0.02/100.00% *
...
* processing queries: 99.99/100.00% *
* processing queries: 100.00/100.00% *
** Searching database for candidate sequences **
* processing database part 1 (size ~0.25 GB): 0.00/100.00% *
* processing database part 1 (size ~0.25 GB): 2.50/100.00% *
...
* processing database part 1 (size ~0.25 GB): 95.00/100.00% *
* processing database part 1 (size ~0.25 GB): 97.50/100.00% *
* processing database part 1 (size ~0.25 GB): 100.00/100.00% *

** Aligning queries with candidate sequences **
* processing database part 1 (size ~1.00 GB): 0.00/100.00% *
* processing database part 1 (size ~1.00 GB): 2.50/100.00% *
...
* processing database part 1 (size ~1.00 GB): 95.00/100.00% *
* processing database part 1 (size ~1.00 GB): 97.50/100.00% *
* processing database part 1 (size ~1.00 GB): 100.00/100.00% *
** Selecting alignments with median threshold: 2.75 **
(keep running forever)
```


I was trying to trouble shoot this by creating some test files. I truncated the ref90.fa file to a test file with only 500 lines and run the same command with it.  It can run through the program without this issue. 


```
...(same as above)
* processing queries: 100.00/100.00% *
* processing queries: 100.00/100.00% *
* processing queries: 100.00/100.00% *

done getting all the scores
populating databases
Unable to read from ./Sevir/singleRecords/scaffold_36.singleRecords_noncoding
checking the databases
zipping up ./Sevir/chr-src/*
All done!
```


Not sure why it get stuck on the original file. The memory allocated was 120G. 
Please help. Thanks.
",linf545,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/10,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU0NjczMDQyMzE=,"Use of uninitialized value within @adj_ends in subtraction (-) at make-single-records-BIOPERL.pl line 198, <IN_TX> line 792",CLOSED,2019-07-12T09:06:27Z,2019-11-12T03:01:32Z,2019-11-12T03:01:32Z,"
Hi, I'm trying to build a SIFT annotations database but it's proving to be a challenging endeavour. I read other issues that contained similar errors, but since they weren't exactly the same, I decided to post a new one. Sorry if it's redundant.

So this is what I'm getting:

`
converting gene format to use-able input
done converting gene format
making single records file
Possible precedence issue with control flow operator at /usr/share/perl5/Bio/DB/IndexedBase.pm line 845.
Subroutine Bio::DB::IndexedBase::_strip_crnl redefined at /usr/share/perl5/Bio/DB/IndexedBase.pm line 304.
Use of uninitialized value within @adj_ends in subtraction (-) at make-single-records-BIOPERL.pl line 198, <IN_TX> line 792.
Use of uninitialized value $exon_end in numeric lt (<) at make-single-records-BIOPERL.pl line 214.
Use of uninitialized value $exon_end in subtraction (-) at make-single-records-BIOPERL.pl line 226.
Use of uninitialized value $aa in string eq at make-single-records-BIOPERL.pl line 270.
Use of uninitialized value $aa in concatenation (.) or string at make-single-records-BIOPERL.pl line 276.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $exon_num in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $exon_num in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $exon_num in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $exon_num in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $exon_num in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $exon_num in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $exon_num in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $exon_num in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $exon_num in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $exon_num in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $exon_num in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Use of uninitialized value $exon_num in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
Argument """" isn't numeric in addition (+) at make-single-records-BIOPERL.pl line 520.
Argument """" isn't numeric in addition (+) at make-single-records-BIOPERL.pl line 520.
Argument """" isn't numeric in addition (+) at make-single-records-BIOPERL.pl line 520.
Argument """" isn't numeric in addition (+) at make-single-records-BIOPERL.pl line 520.
Argument """" isn't numeric in addition (+) at make-single-records-BIOPERL.pl line 520.
Argument """" isn't numeric in addition (+) at make-single-records-BIOPERL.pl line 520.
Argument """" isn't numeric in addition (+) at make-single-records-BIOPERL.pl line 520.
Argument """" isn't numeric in addition (+) at make-single-records-BIOPERL.pl line 520.
Argument """" isn't numeric in addition (+) at make-single-records-BIOPERL.pl line 520.
Argument """" isn't numeric in addition (+) at make-single-records-BIOPERL.pl line 520.
Argument """" isn't numeric in addition (+) at make-single-records-BIOPERL.pl line 520.
Argument """" isn't numeric in addition (+) at make-single-records-BIOPERL.pl line 520.
Use of uninitialized value $coord in concatenation (.) or string at make-single-records-BIOPERL.pl line 572.
`

From then on, chunks of line 572 and line 520 errors alternate till infinity.

I triple checked that all files are in their proper place and their path well indicated in the config file.

Could you give me some guidance?

Besides this, my gtf file is lacking the start_codon and stop_codon features, but according to this open issue https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/6, the error for that should appear later on. Do you know any tool that automatically edits the annotation file to include start_codon and stop_codon features?

Thank you very much for your time and help.",Arynio,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/11,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU1MjExMjY3MzU=,can't locate common-utils.pl in @INC,CLOSED,2019-11-11T18:51:11Z,2023-09-09T02:34:19Z,2019-11-12T15:16:48Z,"I am attempting to run the homo_sapiens-test before creating my own genome files.  Even though I am running the make-SIFT-db-all.pl script within the scripts_to_build_SIFT_db directory, the script doesn't seem to be able to locate the files.  If I move the dependency scripts to another location in @INC, it runs for longer, but eventually still fails.  The error I'm getting is below:


Can't locate common-utils.pl in @INC (@INC contains: /home/slo236/perl5/lib/perl                                            5 /opt/ohpc/pub/libs/gnu8/ccs/perl/5.30.0/lib/site_perl/5.30.0/x86_64-linux-thre                                            ad-multi /opt/ohpc/pub/libs/gnu8/ccs/perl/5.30.0/lib/site_perl/5.30.0 /opt/ohpc/                                            pub/libs/gnu8/ccs/perl/5.30.0/lib/5.30.0/x86_64-linux-thread-multi /opt/ohpc/pub                                            /libs/gnu8/ccs/perl/5.30.0/lib/5.30.0) at ensembl_gene_format_to_ucsc.pl line 5.
",sloux,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/12,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU1MjM5NjY1NjY=,Could I create database without download?,CLOSED,2019-11-17T10:37:35Z,2019-11-17T11:33:10Z,2019-11-17T11:33:10Z,"Hi,
    Could I give the path of .gff or .fa directly ? The server could not download directly. I want to create database locally.
    Thanks in advance.
Best Wishes.
Liu",ggoodstudydaydayup,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/13,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU1MjQzNzgyNzY=,How to create a database locally?,CLOSED,2019-11-18T13:46:27Z,2019-12-07T13:15:33Z,2019-11-25T09:07:58Z,"Hi,
I'm not sure when I support the .gtf and .fa (such as genome, pep) ,  should I have to gzip and change the name ? 
And I try to run the command, there was nothing in the fasta folder with an error.

""converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
cat: './test_files/malus/fasta/*.fasta': No such file or directory""

Thanks in advance.
Best Wishes.
Liu",ggoodstudydaydayup,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/14,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU1MjU4NDk3NTQ=,make-single-records error,CLOSED,2019-11-20T14:46:48Z,2019-12-16T09:37:00Z,2019-12-16T09:37:00Z,"Hi Pauline, 

I'm having a few more issues with the script.  I'm getting the following error: 
It will continue to run, but ends up ultimately failing.  Thanks for your help!

converting gene format to use-able input
done converting gene format
making single records file

Possible precedence issue with control flow operator at /opt/ohpc/pub/libs/gnu8/ccs/perl/5.30.0/lib/site_perl/5.30.0/Bio/DB/IndexedBase.pm line 845.
Subroutine Bio::DB::IndexedBase::_strip_crnl redefined at /opt/ohpc/pub/libs/gnu8/ccs/perl/5.30.0/lib/site_perl/5.30.0/Bio/DB/IndexedBase.pm line 304.
Use of uninitialized value $aa in string eq at make-single-records-BIOPERL.pl line 274.
Use of uninitialized value $aa in concatenation (.) or string at make-single-records-BIOPERL.pl line 280.

With an ultimate failure at:
** Aligning queries with candidate sequences **

* processing database part 39 (size ~1.00 GB): 7.50/100.00% * *
Alignment score and position are not consensus.15.00/100.00% *

",sloux,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/15,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU1MzgyODU2NjU=,Building database error with test data,CLOSED,2019-12-16T09:23:39Z,2019-12-16T10:16:01Z,2019-12-16T10:16:01Z,"Dear Pauline,
I cannot get prediction files for my data. To trace the error, I used the test data of Homo sapiens to build a database. I deleted the dbSNP and mitochondrial data because my data have no such data. I tested the command to build the database:
```bash
 perl make-SIFT-db-all.pl -config test_files/homo_sapiens_test.config
```
Although it produced the prediction files, the error shows like this:
```bash
Use of uninitialized value $fasta_subseq in concatenation (.) or string at make-single-records-BIOPERL.pl
Use of uninitialized value $fasta_subseq in concatenation (.) or string at generate-fasta-subst-files-BIOPERL.pl line 446, <IN_TX> line 1435.
Use of uninitialized value $fasta_subseq in concatenation (.) or string at generate-fasta-subst-files-BIOPERL.pl line 446, <IN_TX> line 1461.
done making the fasta sequences
start siftsharp, getting the alignments
/home/shiyong/software/SIFT4G/sift4g/bin/sift4g -d /home/shiyong/database/NCBI/UNIREF90/uniref90.fasta -q ./test_files/homo_sapiens_test/all_prot.fasta --subst ./test_files/homo_sapiens_test/subst --out ./test_files/homo_sapiens_test/SIFT_predictions --sub-results
** Checking query data and substitutions files **
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
* processing database part 194 (size ~0.25 GB): 100.00/100.00% *

** Aligning queries with candidate sequences **
* processing database part 49 (size ~1.00 GB): 100.00/100.00% *

** Selecting alignments with median threshold: 2.75 **
* processing queries: 100.00/100.00% *

** Generating SIFT predictions with sequence identity: 100.00% **
* processing queries: 100.00/100.00% *

done getting all the scores
populating databases
Traceback (most recent call last):
  File ""make_regions_file.py"", line 68, in <module>
    get_regions (chrom_file, out_file)
  File ""make_regions_file.py"", line 31, in get_regions
    pos = get_pos (first_line)
  File ""make_regions_file.py"", line 8, in get_pos
    return int (fields[0])
ValueError: invalid literal for int() with base 10: ''
checking the databases
zipping up ./test_files/homo_sapiens_test/chr-src/*
All done!
```
FIY, the config file (homo_sapiens_test.config) looks like this:
```bash
GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=./test_files/homo_sapiens_test
ORG=homo_sapiens
ORG_VERSION=GRCh38.83
DBSNP_VCF_FILE=

#Running SIFT 4G
SIFT4G_PATH=/home/shiyong/software/SIFT4G/sift4g/bin/sift4g
PROTEIN_DB=/home/shiyong/database/NCBI/UNIREF90/uniref90.fasta

# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord

```
I would be appreciated if you provide any suggestions.
My old post is [here](https://github.com/rvaser/sift4g/issues/5).
If you need more information, please feel free to contact me.

Best regards,
Sandy
",sandyplus,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/16,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU2MTkyMTUxMDA=,Run each chromosome/contig independently,CLOSED,2020-05-15T20:09:25Z,2020-06-09T04:05:28Z,2020-06-09T04:05:28Z,"Hi Pauline,

I am trying to create a database for a mammalian genome on RefSeq. The run time is quite long (several days), and occasionally the procedure fails due to various errors (out of memory, for instance). I am wondering if it would be okay to parallelize the database creation by running it independently for each chromosome/contig. Then, after all jobs have completed, I would keep the *.gz, *.regions, and *_SIFTDB_stats.txt from each <PARENT_DIR>/<ORG_VERSION>. Do you think this would be okay?

Thanks,
Jacqueline",jarobin,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/17,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU2MjEzMjkyNTc=,Error to build my own database,CLOSED,2020-05-19T22:40:08Z,2020-09-29T15:00:41Z,2020-09-29T15:00:41Z,"Hi, I am using your tool to build my own databases, but I have errors below:
```
cat: /home/liuq1/mysoftwares/sift/SIFT4G_Create_Genomic_DB/sift_myDB/fasta/*.fasta: No such file or directory
```

```
** Checking query data and substitutions files **


** EXITING! No valid queries to process. **
```

When I check `fasta.log`, it shows that
```
0 out of 12 translated to sequences that start with M and end with *
```

May I know what is wrong here? Thank you.

My input is 
```
GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
#MITO_GENETIC_CODE_TABLE=2
#MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=/home/liuq1/mysoftwares/sift/SIFT4G_Create_Genomic_DB/sift_myDB/
ORG=mytest
ORG_VERSION=mytest

#Running SIFT 4G
SIFT4G_PATH=/home/liuq1/mysoftwares/sift/sift4g/bin/sift4g
PROTEIN_DB=/home/liuq1/mysoftwares/sift/SIFT4G_Create_Genomic_DB/uniref90.fasta


# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord

```",liuqianhn,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/18,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU2MzI0NzQzOTQ=,What next after seeing X characters in my all_prot.fasta,CLOSED,2020-06-06T13:48:08Z,2020-09-15T00:21:10Z,2020-09-15T00:21:10Z,"Hi SIFT team,

I ran `cat all_prot.fasta | grep -v "">"" | grep X` and I got some output containing XXX as shown below:
```
MGLLSFVFGGLGFILIGAHEALLHSSPSSQNKKTKTLFSISLVLFSSFFILNSTLSLFDAHSSNDAVGAALQLQVLSIAFVFLFYSLLPLLSLSFTLPSPLLNLVGAFAFAEEFLLFYLXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXGDDHTPGG
MVEDGDEVDSMSAETARAIVGHGGVRPLVALCQTGDXXXXXXXXXXXXXXXXXXXXXXXXX XXXXXXXXXXXXXXXXXXXKEHAAECLQNLTASNENLRKSVISEGGVRSLLAYLDGPLPQESAVGALRNLVGLVPE
```

What should I do next in order to continue building the database. It seem @pauline-ng previously mentioned that cat cmd, should not print any output, in this case. Do I have to start from the beginning? If so will the files already created be overwritten? 

I am asking because it took a long time to reach this level. If not, how do I restart from where I am currently. I am stuck at:

```
** Checking query data and substitutions files **
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
* processing database part 200 (size ~0.25 GB): 0.00/100.00% * *
```
I also wonder how many parts there is with uniref90?  I divided the uniref90.fasta by 0.25, I got 188 but my sift4g run, indicated above, was processing part 200. Whats the correlation there? I had to run this for days to get to this point.",eyeamnice,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/19,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU2NjI0NTA3NDg=,"python scripts are in python2, giving users problems",CLOSED,2020-07-21T01:26:35Z,2020-12-06T23:50:17Z,2020-12-06T23:50:17Z,"A few .py scripts in the pipeline were written in python2. Users now using python3 as default, which results in database not being built. I should change to perl or python3.",pauline-ng,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/20,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU2NjUyNzE3MDk=,synonymous variants predicted deleterious by SIFT,CLOSED,2020-07-24T16:12:50Z,2020-07-24T16:12:59Z,2020-07-24T16:12:59Z,"Email thread from a SIFT user. Posted here for posterity:

Awesome Pauline, you have just saved me a lot of troubles. Thank you for your help indeed. I really really appreciate it. I will pass this on to my team and sorry for my bugging you with all these questions.

Best
Isaac

On Fri, Jul 24, 2020 at 9:48 AM Pauline Ng wrote:

    Hi Isaac,

    I think I get it! Does this happen for a small fraction, like <1% of your synonymous variants?

    When a synonymous amino acid is predicted deleterious, this means the amino acid in the protein sequence is dissimilar to the other protein homologues in the protein alignment.

    The not so interesting explanation is that there  is sequencing error in the reference genome and the reference amino acid is incorrect. The alternative interesting explanation is the amino acid in the protein sequence in your organism has mutated away from the norm. This could indicate a pseudogene if there are lots of deleterious synonymous variants in a given gene. If it's a single amino acid change in a protein, I thought positive evolution would be a possibility, but that's pure speculation.

    We actually use the % of reference amino acids damanging as a QC.  For the human genome, 0.1% of the reference amino acid is predicted damaging. Here's an example:
    https://sift.bii.a-star.edu.sg/sift4g/public//Homo_sapiens/GRCh37.74/2_SIFTDB_stats.txt

    Reference predictions % damaging: 0.1 2842/2341194

    This is generated for every chromosome in the <chr>_SIFTDB_stats.txt file

    Best,

    Pauline



    On Fri, Jul 24, 2020 at 9:57 PM Isaac  wrote:

        Hi Pauline,

        My input vcf is the same for both VEP and SIFT. You are absolutely right. The issue is the sift prediction score. All output from both VEP and SIFT matches. For that particular case and a few hundred more, SIFT predicts them to be deleterious but they are all synonymous transcripts. Synonymous transcripts will not be deleterious. I ran sift with option -t, which means to  annotate with all transcripts"" All Nonsynonymous calls from SIFT match with VEP. It is really concerning and your help will be greatly appreciated. If you need any file to troubleshoot, I will gladly provide them

        Thanks

        On Thu, Jul 23, 2020 at 1:17 AM Pauline Ng wrote:

            Hi Isacc,

            The output of SIFT matches VEP for nonsynonymous annotation? So this is not a build problem. Sometimes, there are alternative scripts and SIFT picks the one with the lowest score. Have you tried running it with the ""annotate with all transcripts"" option?

            I am a little confused because in one email you say: ""Although I looked and it seemed like the region we looked at is a region of the genome with no gene."" and in another email it says ""SIFT matches the output from VEP with the same amino acid changes"". So the issue is SIFT prediction scores, and not the gene annotation?


            Best,
            Pauline

            On Thu, Jul 23, 2020 at 3:11 AM Isaac  wrote:

                Hi Pauline,

                Given that I used the method of downloading data from Ensemble directly using the config file (see attached), I am positive it is not a genome build problem. Do you see any problem with my config file? The output from SIFT matches the output from VEP with the same amino acid changes except the SIFT called many synonymous variants deleterious. What else could be the issue?

                Thank you
                Isaac

                On Tue, Jul 21, 2020 at 7:05 PM Pauline Ng wrote:

                    Hi Isaac,

                    Sounds like a genome build discrepancy. I'd check that the Soy version is exactly the same as VEP, throughout your SIFT config file.

                    Thanks,
                    Pauline


                    On Wed, Jul 22, 2020 Isaac  wrote:

                        Hi Pauline,

                        I successfuly built a SIFT DB for soy. I ran vep and then ran SIFT4g. SIFT called the transcript synonymous and  deleterious, which may not be accurate. What do you think may have caused it? How does SIFT use the variant coordinates? Can there be an off by one error? Although I looked and it seemed like the region we looked at is a region of the genome with no gene. Do you also think it is an issue of SIFT not mapping the genomic location to the right transcript?

                        Thank you

                        -- 
                        Isaac ",pauline-ng,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/21,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3MDE1MDUxMzY=,How synonymous variants are predicted to be deleterious,CLOSED,2020-09-14T23:54:47Z,2020-09-29T05:04:17Z,2020-09-29T05:04:17Z,"
Hi @pauline-ng 
Once I run SIFT on my variant set, I see variant labelled as synonymous are predicted to be deleterious.
I understand why some amino acid changes would appear to be tolerated and others not.  But I dont understand how SIFT predict that no amino acid change (synonymous variants) can be problematic (deleterious)
Will you please explain it to me? 

chr1 | 3159715 | G | T | ENSBTAT00000016473 | ENSBTAG00000012412 | URB1 | CDS | SYNONYMOUS | S | S | 1576 | 0.02 | 3.09 | 161 | novel | DELETERIOUS
-- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --
chr1 | 5561002 | C | T | ENSBTAT00000052636 | ENSBTAG00000037933 | CDS | SYNONYMOUS | R | R | 84 | 0.03 | 2.68 | 303 | novel | DELETERIOUS

",Kalpi-ds,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/22,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3MzY1MzM0MTg=,"build a database ,but the SIFT numeric scores in columns 10-12 too many rows say ""NA"".",CLOSED,2020-11-05T01:23:07Z,2020-11-06T03:21:02Z,2020-11-06T03:21:02Z,"I have build a database,but the SIFT numeric scores in columns 10-12 too many rows say ""NA"". The CHECK_GENES.LOG is like this
```
Chr     Genes with SIFT Scores  Pos with SIFT scores    Pos with Confident Scores
Ghir_A01        0 (0/3764)      0 (0/10735334)  0(0/0)
Ghir_A02        0 (0/3196)      0 (0/9036410)   0(0/0)
Ghir_A03        0 (0/3915)      0 (0/10562169)  0(0/0)

ALL     0 (0/115644)    0 (0/317919423) 0(0/0)
```
I think this is a bad database. But i donot know how to solve it.maybe some input file is wrong or something else?",chaimol,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/23,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NDM1MTcwNDE=,Error in built my own database,CLOSED,2020-11-16T06:30:53Z,2021-11-23T05:58:05Z,2020-12-05T14:30:20Z,"Hi,SIFT4G team 
I had a problem in building my own database using sift4g tools. When execute the perl make-SIFT-db-all.pl -config Glymax_config.txt command, there will be in parent_Dir folder generates all_ prot.fasta file, but without generated a database and no error was return. I don't know where the problem is. Hope your answers, thank you.

My input files are shown below:
1. Glymax_config.txt
GENE_DOWNLOAD_SITE=/vol3/agis/wangli_group/sunshichao/soybean/P101SC17040637-01-F004/SIFT4G/Glycine_max/gene-annotation-src/Glycine_max.gene.gtf.gz
PEP_FILE=/vol3/agis/wangli_group/sunshichao/soybean/P101SC17040637-01-F004/SIFT4G/Glycine_max/gene-annotation-src/soybean.pep.fa
CHR_DOWNLOAD_SITE=/vol3/agis/wangli_group/sunshichao/soybean/P101SC17040637-01-F004/SIFT4G/database/Glycine_max.Glycine_max_v2.1.dna.toplevel.fa.gz

GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=11
MITO_GENETIC_CODE_TABLENAME=Plant Plastid Code

PARENT_DIR=/vol3/agis/wangli_group/sunshichao/soybean/P101SC17040637-01-F004/SIFT4G/PARENT_DIR
ORG=Glycine_max
ORG_VERSION=Gma2.v1

#Running SIFT 4G
SIFT4G_PATH=/vol3/agis/wangli_group/sunshichao/miniconda3/bin/sift4g
PROTEIN_DB=/vol3/agis/wangli_group/sunshichao/soybean/P101SC17040637-01-F004/SIFT4G/database/uniref90.fasta

# Sub-directories, don't need to change
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
FASTA_DIR=fasta
SUBST_DIR=subst
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords/
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord

2.  */chr-src/Glycine_max.Glycine_max_v2.1.dna.toplevel.fa
![image](https://user-images.githubusercontent.com/70623629/99219631-0bf71380-2818-11eb-9d6d-df0991b590c2.png)
3. */gene-annotation-src/Glycine_max.gene.gtf.gz
![image](https://user-images.githubusercontent.com/70623629/99219703-347f0d80-2818-11eb-930e-4d749ad9d6f8.png)
4. */gene-annotation-src/soybean.pep.fa
![image](https://user-images.githubusercontent.com/70623629/99219765-5082af00-2818-11eb-8880-5d9aa6ba6208.png)


",sunshichao0916,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/24,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NDQ1NDY5MjU=,I find a methods for speed the analysis in sift4g to build a new database,CLOSED,2020-11-17T09:04:37Z,2022-11-04T22:32:49Z,2022-03-22T23:17:54Z,"when i use sift4g to build my database , I found it is very slow in use `sift4g` predication . 
# Speed up the establishment of new databases
# we can add the threads in use sift4g. Only change file `make-SIFT-db-all.pl` line 109.just add threads before `-d`.
```
my $sift4g_command = $meta_hash{""SIFT4G_PATH""} .  "" -t 24 -d "" . $meta_hash{""PROTEIN_DB""} . "" -q "" . $meta_hash{""PARENT_DIR""} . ""/all_prot.fasta --subst "" .  $meta_hash{""PARENT_DIR""} . ""/"" . $meta_hash{""SUBST_DIR""} . "" --out "" .  $meta_hash{""PARENT_DIR""} . ""/"" . $meta_hash{""SIFT_SCORE_DIR""} . "" --sub-results "" ;
```
use `-t 24` can use 24 threads to analysis ,The default threads is 8.",chaimol,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/25,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NDc5MjE1OTA=,"error when construct database, and sift4g",CLOSED,2020-11-21T04:18:30Z,2020-11-22T03:35:28Z,2020-11-22T03:34:24Z,"Can we not use --subst ./test_files/homo_sapiens_small/subst  and --sub-results  when construct database? 

I met an error when construct the sift database. ""terminate called after throwing an instance of 'std::regex_error'
  what():  regex_error Aborted (core dumped)""

When I run 'perl make-SIFT-db-all.pl -config test_files/homo_sapiens-test.txt', it
report ""converting gene format to use-able input
done converting gene format
making single records file
Possible precedence issue with control flow operator at /usr/local/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.
done making single records template
making noncoding records file
Possible precedence issue with control flow operator at /usr/local/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.
done making noncoding records
make the fasta sequences
Possible precedence issue with control flow operator at /usr/local/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.
done making the fasta sequences
start siftsharp, getting the alignments
/workdir/yw2326/SIFT/sift4g/bin/sift4g -d /workdir/yw2326/SIFT/PROTEIN_DB/uniref90.fasta -q ./test_files/homo_sapiens_small/all_prot.fasta --subst ./test_files/homo_sapiens_small/subst --out ./test_files/homo_sapiens_small/SIFT_predictions --sub-results 
** Checking query data and substitutions files **
terminate called after throwing an instance of 'std::regex_error'
  what():  regex_error""

Then I go to sift4g, './bin/sift4g -q ./test_files/query.fasta --subst ./test_files/ -d ./test_files/sample_protein_database.fa' it run error ""** Checking query data and substitutions files **
terminate called after throwing an instance of 'std::regex_error'
  what():  regex_error
Aborted (core dumped)"". 
 If  don't use subst, ""./bin/sift4g -q ./test_files/query.fasta -d ./test_files/sample_protein_database.fa""  it works.
I have update the gcc to 7.3 version, it still report the error.",yywyaoyaowu,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/26,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NDkyNzIwNzA=,Is the database well constructed? Got ,CLOSED,2020-11-24T01:46:53Z,2020-12-17T14:37:58Z,2020-12-17T14:37:58Z,"Hi SIFT4G_Create_Genomic_DB team.

When I construct the database, I met warning and error. I have checked the data as 'Check the Database pipeline'. But I'm not sure if the database is well constructed. 
I go to  <PARENT_DIR>/<ORG_VERSION>/ and check the data, zcat <chr>.gz | more , zcat <chr>.gz | grep CDS | more  , CHECK_GENES.LOG seem are all well  produced. Then I checked the pre-files: 
**_ls -lt <PARENT_DIR>/singleRecords_with_scores/*  no files_** 
ls -lt <PARENT_DIR>/singleRecords/*  has files
`ls fasta/* has files
SIFT 4G Algorithm is running 
ls SIFT_predictions/* with files

is the 'singleRecords_with_scores' affect the database construction much???? Thanks very much!
The warning and error I got is : 
1. 'Use of uninitialized value $fasta_subseq in concatenation (.) or string at make-single-records-BIOPERL.pl line 210, <IN_TX> line 2132.'

2. Argument """" isn't numeric in numeric eq (==) at generate-fasta-subst-files-BIOPERL.pl line 465, <IN_TX> line 265.

3.  Unable to read from /workdir/yw2326/SIFT/SIFT4G_Create_Genomic_DB/Potato_A6_26/singleRecords/chr01.singleRecords_noncoding
  File ""make_regions_file.py"", line 61
    print 'check_SIFTDB.py <sorted file> <outfile>'
SyntaxError: Missing parentheses in call to 'print'. Did you mean print('check_SIFTDB.py <sorted file> <outfile>')?

4. cat: '/workdir/yw2326/SIFT/SIFT4G_Create_Genomic_DB/Potato_A6_26/singleRecords/contig_1381:::fragment_1:::debris.singleRecords':
Unable to read from /workdir/yw2326/SIFT/SIFT4G_Create_Genomic_DB/Potato_A6_26/singleRecords/contig_1328.singleRecords_noncoding

5. SyntaxError: Missing parentheses in call to 'print'. Did you mean print('check_SIFTDB.py <sorted file> <outfile>')?
rm: cannot remove '/workdir/yw2326/SIFT/SIFT4G_Create_Genomic_DB/Potato_E4_63/singleRecords_with_scores/contig_977:::debris_scores.Srecords': No such file or d
checking the databases
  File ""check_SIFTDB.py"", line 44
    if predicted_on > 0:
                       ^
TabError: inconsistent use of tabs and spaces in indentation
  File ""check_SIFTDB.py"", line 44
    if predicted_on > 0:

6. TabError: inconsistent use of tabs and spaces in indentation
zipping up /workdir/yw2326/SIFT/SIFT4G_Create_Genomic_DB/Potato_E4_63/chr-src/*
All done!
",yywyaoyaowu,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/27,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NTY3MjY0MjU=,Error while creating database,CLOSED,2020-12-04T01:42:22Z,2020-12-05T04:46:50Z,2020-12-05T04:46:50Z,"Hi,

I am not sure why this problem encounter during database formatting.
Error returned ""[ERROR]: missing option -q (query file)""

I follow the command line provided in the manual, which doesn't require query option (-q)
This is my command line that I used to create the genomic DB: 
perl make-SIFT-db-all.pl -config ./test_files/R498.txt 

![Uploading Screenshot from 2020-12-04 09-27-22.png]()

The fasta, single records and subst folders are not empty.



",ruru-adra,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/28,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NjEzODQyNjY=,Error when construct test database (homo sapiens),CLOSED,2020-12-10T16:22:49Z,2020-12-14T06:28:27Z,2020-12-14T06:28:27Z,"Hi Pauline

I am still fail to build my SIFT4G database. 
But then I tried to build the homo_sapiens_small sample database. It returned an error during ""making single records file"" 

Use of uninitialized value $fasta_subseq in concatenation (.) or string at make-single-records-BIOPERL.pl line 210, <IN_TX> line 2.
Use of uninitialized value $fasta_subseq in concatenation (.) or string at make-single-records-BIOPERL.pl line 210, <IN_TX> line 3.
.
The SIFT_alignments, SIFT_predictions folders, singleRecords_with_scores are empty. 
all_prot.fasta, fasta.log, invalid.log and peptide.log was generated. 

I tried ""../../../sift4g/bin/sift4g -d ../protdb/uniprot.fasta -q all_prot.fasta --out SIFT_predictions/"" , returned no error and generated files in the SIFT_prediction folder.

Then I tried SIFT4G,  ""./bin/sift4g -q ./test_files/query.fasta --subst ./test_files/ -d ./test_files/sample_protein_database.fa"". The SIFT4G programme works well. No error found using sample data.

My gcc version is  9.3.0.

Thank you
",ruru-adra,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/29,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NjgyMzcxMzU=,Process stop while creating the database,CLOSED,2020-12-15T21:55:35Z,2020-12-18T10:17:40Z,2020-12-18T10:17:40Z,"Hi Pauline,

![Screenshot from 2020-12-15 18-06-23](https://user-images.githubusercontent.com/3852095/102276515-e0279480-3f61-11eb-8ca3-502b13c3278e.png)

The command ""perl make-SIFT-db-all.pl -config <config_file>"" that I used for creating the database stopped at 75% without any warning or error.
Then I tried to run the SIFT4G command (as attached) to see whether it's work or not. However,  I got this warning ""Killedessing database part I etc"" and the process stopped at 72.5%.

Is that means the computer is out of memory while creating the database?
Please find attached the snapshot of command line that I used and warning.

Thanks,


",ruru-adra,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/30,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3Njg1MTI1ODg=,file not existed,CLOSED,2020-12-16T06:51:41Z,2020-12-18T01:02:43Z,2020-12-17T14:41:02Z,"Hi, may I ask is this file 'scripts_to_build_SIFT_db/test_files/homo_sapiens_small' functioning? Because When I click on it, it show me error 404 in the page. Thank you",zhansia,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/31,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3Njk1MzUwNjM=,Error in Annotate VCF files with the SIFT Database,CLOSED,2020-12-17T05:27:00Z,2022-06-26T23:13:13Z,2020-12-19T13:52:58Z,"Hi pauline,
      I'm sorry to disturb you again. When I use the `java -jar <Path to SIFT4G_Annotator> -c -i <Path to input vcf file> -d <Path to SIFT4G database directory> -r <Path to your results folder> -t `command, the program runs, and the output temporary file looks right. But when the final merge, there is no result file output. Did I do something wrong? Can you give me some advice?

Thank you,
Shichao",sunshichao0916,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/32,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NzAwODkwMzU=,Running error,CLOSED,2020-12-17T14:22:48Z,2020-12-17T23:35:18Z,2020-12-17T14:37:03Z,"Hi, pauline ng, sry for disturb u. When I run, I was getting this kind of error, can u check for me? Thank you...
Below is my error:

converting gene format to use-able input
Can't locate Switch.pm in @INC (you may need to install the Switch module) (@INC contains: /home/FYPuser/perl5/lib/perl5 /usr/local/lib/perl5/site_perl/5.32.0/x86_64-linux-thread-multi /usr/local/lib/perl5/site_perl/5.32.0 /usr/local/lib/perl5/5.32.0/x86_64-linux-thread-multi /usr/local/lib/perl5/5.32.0) at gff_gene_format_to_ucsc.pl line 4.
BEGIN failed--compilation aborted at gff_gene_format_to_ucsc.pl line 4.
done converting gene format
no DNA fasta files in ./test_files/coronavirus/chr-src

**Here is my config file:**

GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=./test_files/coronavirus
ORG=Severe Acute Respiratory Syndrome Coronavirus 2
ORG_VERSION=ASM985889v3
DBSNP_VCF_FILE=Homo_sapiens.vcf.gz

#Running SIFT 4G
SIFT4G_PATH=/bigdrive/sift4g/bin/sift4g
PROTEIN_DB=/bigdrive/SIFT_databases/uniprot_sprot.fasta


# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord
",zhansia,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/33,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NzA0OTQzMjI=,Error in running process,CLOSED,2020-12-18T01:27:04Z,2020-12-21T06:41:41Z,2020-12-21T06:31:29Z,"Hi, Pauline Ng, sry to disturb u again.  The previous error d solved, now I have another kind of error. The error is listed below:

I d put the DNA fasta file inside the chr-src directory, but it still pop out the error, can u help me to check on this? tq...
Below is the error:

converting gene format to use-able input
Unable to open  for reading
done converting gene format
no DNA fasta files in ./test_files/coronavirus/chr-src
",zhansia,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/34,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NzEzNzcyOTI=,protein_DB file,CLOSED,2020-12-19T13:03:25Z,2020-12-21T06:43:04Z,2020-12-21T06:32:23Z,"Hi, pauline ng, wanna ask that does we need to change the path for PROTEIN_DB? Thank you",zhansia,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/35,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NzEzNzg2NzM=,Error when building the sample database,CLOSED,2020-12-19T13:12:08Z,2020-12-21T06:43:47Z,2020-12-21T06:33:03Z,"Hi, pauline ng below is the error that I face while constructing the database, can u check for me, tq..

**Error:**
done making the fasta sequences
start siftsharp, getting the alignments
cat: './test_files/homo_sapiens_small/fasta/*.fasta': No such file or directory
/bigdrive/sift4g/bin/sift4g -d /bigdrive/SIFT_databases/uniprot_sprot.fasta -q ./test_files/homo_sapiens_small/all_prot.fasta --subst ./test_files/homo_sapiens_small/subst --out ./test_files/homo_sapiens_small/SIFT_predictions --sub-results
Can't exec ""/bigdrive/sift4g/bin/sift4g"": No such file or directory at make-SIFT-db-all.pl line 114.
",zhansia,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/36,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NzEzODUwOTE=,Error when run the SIFT Algorithm ,CLOSED,2020-12-19T13:53:51Z,2020-12-21T10:07:57Z,2020-12-21T10:07:57Z,"Hi, pauline ng , I am sry, I just realise that I didn't install the sift4g algorithm file, but when I run the command 'make', it pop out the error as below:

[CP] src/select_alignments.cpp
In file included from src/select_alignments.cpp:16:0:
src/select_alignments.hpp:15:29: fatal error: swsharp/swsharp.h: No such file or directory
compilation terminated.
Makefile:39: recipe for target 'obj/select_alignments.o' failed
make: *** [obj/select_alignments.o] Error 1
",zhansia,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/37,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NzIwNDY0MzY=,"I found SIFT_SCORE=NA, ""SIFT_MEDIAN=NA"", ""NUM_SEQS=NA"", ""SIFT_PREDICTION=NA"" in my output",CLOSED,2020-12-21T10:21:12Z,2021-01-23T05:40:35Z,2021-01-23T05:40:35Z,"Hi
  I tried to build the local database, and it showed ALL DONE. However, I tested my vcf files and found the  SIFT_SCORE=NA, ""SIFT_MEDIAN=NA"", ""NUM_SEQS=NA"", ""SIFT_PREDICTION=NA"" in my results. I don't know how to deal with it, could you give me hand?",wangnan9394,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/38,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NzIwNzUwNTI=,No output after building database,CLOSED,2020-12-21T11:04:25Z,2021-01-23T05:33:07Z,2021-01-23T05:33:07Z,"Hi, pauline ng, after I build the database, the output is empty in the output file, below is the error, can help me to check ah..

Error:
done making the fasta sequences
start siftsharp, getting the alignments
cat: './test_files/coronavirus/fasta/*.fasta': No such file or directory
/home/FYPuser/zhan/SIFT4G_Create_Genomic_DB-master/sift4g/bin/sift4g -d /home/FYPuser/zhan/SIFT4G_Create_Genomic_DB-master/uniprot-NC_045512.2.fasta -q ./test_files/coronavirus/all_prot.fasta --subst ./test_files/coronavirus/subst --out ./test_files/coronavirus/SIFT_predictions --sub-results
** Checking query data and substitutions files **


** EXITING! No valid queries to process. **
",zhansia,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/39,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NzI4NzAzNzQ=,Cannot create own database ,CLOSED,2020-12-22T11:24:18Z,2022-03-22T23:15:42Z,2022-03-22T23:15:42Z,"Hi, pauline ng, I managed to create the example database, but when it come to create my own database, it pop out this error as show in below, can u help me to check...

entered mkdir ./test_files/coronavirus/ASM985889v3
converting gene format to use-able input
Unable to open  for reading
done converting gene format
making single records file
can't open ./test_files/coronavirus/gene-annotation-src/protein_coding_genes.txt at make-single-records-BIOPERL.pl line 143.
done making single records template
making noncoding records file
can't open ./test_files/coronavirus/gene-annotation-src/noncoding.txt at make-single-records-noncoding.pl line 59.
done making noncoding records
make the fasta sequences
can't open ./test_files/coronavirus/gene-annotation-src/protein_coding_genes.txt at generate-fasta-subst-files-BIOPERL.pl line 387.
done making the fasta sequences
start siftsharp, getting the alignments
cat: './test_files/coronavirus/fasta/*.fasta': No such file or directory
/home/FYPuser/zhan/SIFT4G_Create_Genomic_DB-master/sift4g/bin/sift4g -d /home/FYPuser/zhan/SIFT4G_Create_Genomic_DB-master/uniref90.fasta -q ./test_files/coronavirus/all_prot.fasta --subst ./test_files/coronavirus/subst --out ./test_files/coronavirus/SIFT_predictions --sub-results
** Checking query data and substitutions files **


** EXITING! No valid queries to process. **
",zhansia,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/40,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NzI5MzQ5MTU=,config file checking,CLOSED,2020-12-22T13:09:54Z,2021-01-23T05:36:03Z,2021-01-23T05:36:03Z,"Hi, below is my config file, can u check for me if got any error? tq..

GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=/home/FYPuser/zhan/SIFT4G_Create_Genomic_DB-master/test_files/corona$
ORG=Severe Acute Respiratory Syndrome Coronavirus 2
ORG_VERSION=ASM985889v3
DBSNP_VCF_FILE=

#Running SIFT 4G
SIFT4G_PATH=/home/FYPuser/zhan/SIFT4G_Create_Genomic_DB-master/sift4g/bin/sift4g
PROTEIN_DB=/home/FYPuser/zhan/SIFT4G_Create_Genomic_DB-master/uniref90.fasta


# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
",zhansia,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/41,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3NzQ4MTE5NjI=,"annotate file error, no output",CLOSED,2020-12-26T02:45:43Z,2022-03-22T23:15:55Z,2022-03-22T23:15:55Z,"Hi, pauline Ng, I have successfully run the SIFT 4G annotater, but the output file is empty, below is the command while running:
can u give me some advise on how to solved this problem? tq

 
Chromosome      WithSIFT4GAnnotations   WithoutSIFT4GAnnotations        Progress
The following chromosomes (or scaffolds/contigs) are not found in the SIFT 4G database and will not be annotated:
1
Please contact us if you have any questions.
/home/FYPuser/zhan/SIFT4G_Create_Genomic_DB-master/test_files/SARS/ASM985889v3/1.regions does not exist
1                       0                       50                      Completed : 1/1

Merging temp files....
SIFT4G Annotation completed !
",zhansia,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/42,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3ODg2MTE0NTQ=,how to evaluate the siftddatabase? ,CLOSED,2021-01-19T00:05:15Z,2022-07-24T02:06:14Z,2021-01-19T23:03:00Z,"Hi, pauline
This is Yaoyao. When I use a new genome, I met a 'warning'. Then I checked the database. My question 1. is the warning affect the database construction?  
2. how to evaluate if the database is well constructed? 

1. This is the warning I got.  Bioperl for running DB::Fasta is quite important for sift database construction. But I don't see anything wrong. Is this oK?
**Possible precedence issue with control flow operator at /home/yw2326/software/miniconda3/lib/site_perl/5.26.2/Bio/DB/IndexedBase.pm line 805.
done making single records template
making noncoding records file**

2. When I check the database as you suggested in the website ""Check the database"". 
I use  zcat chr01.gz | grep CDS |  awk '($11!=""NA""){print}' | wc -l to check the sites with no sift score. I found 4.3% CDS sites were not with sift score. 
Then I got to ""CHECK_GENES.LOG"", I got ""ALL     98 (43865/44746)        99 (117728116/118341687)        87(102554181/117728116)"". And you said ""Your database is done if the percentages are high for the last 3 different columns."" I suppose 87% 99% is quite high, right? What's the number for good database?
Chr     Genes with SIFT Scores  Pos with SIFT scores    Pos with Confident Scores
chr01   98 (5715/5853)  99 (15569236/15662914)  87(13555622/15569236)
chr02   98 (4245/4324)  100 (11980016/12034306) 89(10612715/11980016)
chr03   98 (4342/4416)  99 (11824558/11885076)  89(10505875/11824558)
chr04   98 (3980/4062)  99 (10687933/10741726)  86(9207919/10687933)
chr05   99 (2917/2958)  100 (7889554/7918062)   87(6862649/7889554)
chr06   98 (3887/3955)  100 (9922134/9968730)   86(8492265/9922134)
chr07   97 (3059/3142)  99 (8457188/8515533)    88(7443496/8457188)
chr08   98 (3188/3269)  99 (8486670/8544174)    88(7441767/8486670)
chr09   98 (3194/3255)  100 (8552574/8591423)   88(7505256/8552574)
chr10   98 (3157/3211)  100 (7853302/7890876)   87(6813450/7853302)
chr11   98 (3029/3085)  100 (8336085/8374210)   85(7111593/8336085)
chr12   98 (3152/3216)  99 (8168866/8214657)    86(7001574/8168866)

ALL     98 (43865/44746)        99 (117728116/118341687)        87(102554181/117728116)
Look forward to your reply. Thanks very much!
 ",yywyaoyaowu,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/43,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU3OTAwNTYwMDA=,No  SIFT_score shows in chr*.gz file,CLOSED,2021-01-20T14:58:18Z,2021-01-23T05:30:54Z,2021-01-23T05:30:54Z,"Hi,
  I use this pipeline to build my datebase, ""All done!"". However, when i check the chr*.gz file, I found that NA in  ""SIFT_score"",NA in ""SIFT_median_sequence_info"". could you give me a hand?
Here is the pic
![image](https://user-images.githubusercontent.com/52204680/105192210-d4d41400-5b72-11eb-9b6b-781b590cd6cb.png)

I have checked my all files, it seems all right.
Thank you so much.",wangnan9394,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/44,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU4NTgwMzI0NzY=,Problem creating genomic database for new organism_1,CLOSED,2021-04-14T15:51:25Z,2022-03-22T23:16:23Z,2022-03-22T23:16:23Z,"Hi, Pauline

> ""In the gtf file, make sure the 9th column (attribute column) says gene_biotype ""protein_coding;"" for rows which are labelled as exon, CDS, stop_codon, and start_codon.""
> For each protein, you'll need to annotate exon, CDS, stop_codon, and start_codon. 

I have modified my gtf file to satisfy these criterions, but errors still exists.

```
converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
cat: /picb/evolgen/users/gushanshan/projects/probiotics/multiple_whole_genome_alignment/pairwise_combined/formalExper/homologousGroup/PS128_B21_BLS41_comparation/pairwise_multiz/mutationEffectPrediction/formal/sift4g_ps128_database/fasta/*.fasta: No such file or directory
/picb/evolgen/users/gushanshan/software/sift/sift4/bin/sift4g -d /picb/evolgen/users/gushanshan/database/uniref90/uniref90 -q /picb/evolgen/users/gushanshan/projects/probiotics/multiple_whole_genome_alignment/pairwise_combined/formalExper/homologousGroup/PS128_B21_BLS41_comparation/pairwise_multiz/mutationEffectPrediction/formal/sift4g_ps128_database/all_prot.fasta --subst /picb/evolgen/users/gushanshan/projects/probiotics/multiple_whole_genome_alignment/pairwise_combined/formalExper/homologousGroup/PS128_B21_BLS41_comparation/pairwise_multiz/mutationEffectPrediction/formal/sift4g_ps128_database/subst --out /picb/evolgen/users/gushanshan/projects/probiotics/multiple_whole_genome_alignment/pairwise_combined/formalExper/homologousGroup/PS128_B21_BLS41_comparation/pairwise_multiz/mutationEffectPrediction/formal/sift4g_ps128_database/SIFT_predictions --sub-results 
** Checking query data and substitutions files **


** EXITING! No valid queries to process. **

```
By the way, I managed to run test files for human.
Here is the directory structure:
```
-bash-4.2$ ls -lhtR
.:
total 39M
drwxr-xr-x 2 gushanshan evolgen  143 Apr 14 21:41 gene-annotation-src
-rw-r--r-- 1 gushanshan evolgen   68 Apr 14 21:26 fasta.log
-rw-r--r-- 1 gushanshan evolgen  544 Apr 14 21:26 invalid.log
-rw-r--r-- 1 gushanshan evolgen    0 Apr 14 21:26 peptide.log
drwxr-xr-x 2 gushanshan evolgen  101 Apr 14 21:26 chr-src
-rw-r--r-- 1 gushanshan evolgen    0 Apr 14 21:26 Log2.txt
drwxr-xr-x 2 gushanshan evolgen  389 Apr 14 21:25 singleRecords
-rw-r--r-- 1 gushanshan evolgen 1.3K Apr 14 14:34 sift4g_ps128_database_configure.txt
-rw-r--r-- 1 gushanshan evolgen    0 Apr 14 14:07 all_prot.fasta
drwxr-xr-x 2 gushanshan evolgen 3.2K Apr 14 14:07 subst
drwxr-xr-x 2 gushanshan evolgen    0 Apr 14 14:04 SIFT_predictions
drwxr-xr-x 2 gushanshan evolgen    0 Apr 14 14:04 singleRecords_with_scores
drwxr-xr-x 2 gushanshan evolgen    0 Apr 14 14:04 SIFT_alignments
drwxr-xr-x 2 gushanshan evolgen    0 Apr 14 14:04 fasta
drwxr-xr-x 2 gushanshan evolgen    0 Apr 14 14:04 LP_PS128
-rw-r--r-- 1 gushanshan evolgen  24M Apr 13 21:44 uniprot_sprot_species
drwxr-xr-x 2 gushanshan evolgen    0 Apr 13 21:28 dbSNP
-rw-r----- 1 gushanshan evolgen 3.5M Apr 13 21:26 ps128.gtf

./gene-annotation-src:
total 6.9M
-rw-r--r-- 1 gushanshan evolgen 229K Apr 14 21:25 noncoding.txt
-rw-r--r-- 1 gushanshan evolgen  145 Apr 14 21:25 protein_coding_genes.txt
-rw-r--r-- 1 gushanshan evolgen 4.0M Apr 14 21:18 ps128_format.gtf

./chr-src:
total 4.9M
-rw-r--r-- 1 gushanshan evolgen 1.0K Apr 14 21:26 directory.index.pag
-rw-r--r-- 1 gushanshan evolgen    0 Apr 14 21:26 directory.index.dir
-rw-r----- 1 gushanshan evolgen 3.3M Apr 13 21:25 ps128.fna

./singleRecords:
total 1.8G
-rw-r--r-- 1 gushanshan evolgen 1.3G Apr 14 21:26 NZ_LBHS01000002.1.singleRecords_noncoding
-rw-r--r-- 1 gushanshan evolgen 5.7M Apr 14 21:25 NZ_LBHS01000001.1.singleRecords_noncoding
-rw-r--r-- 1 gushanshan evolgen    0 Apr 14 21:25 NZ_LBHS01000002.1.singleRecords
-rw-r--r-- 1 gushanshan evolgen  16K Apr 14 16:36 NZ_LBHS01000001.1.singleRecords_proteins.fa
-rw-r--r-- 1 gushanshan evolgen  15K Apr 14 16:36 NZ_LBHS01000001.1.invalidRecords
-rw-r--r-- 1 gushanshan evolgen 4.8K Apr 14 16:36 NZ_LBHS01000002.1.singleRecords_proteins.fa
-rw-r--r-- 1 gushanshan evolgen 4.6K Apr 14 16:36 NZ_LBHS01000002.1.invalidRecords

./subst:
total 220K
-rw-r--r-- 1 gushanshan evolgen 0 Apr 14 16:36 WH27_RS00095.subst
... a lot of .subst files
-rw-r--r-- 1 gushanshan evolgen 0 Apr 14 16:36 WH27_RS03910.subst

./SIFT_predictions:
total 0

./singleRecords_with_scores:
total 0

./SIFT_alignments:
total 0

./fasta:
total 0

./LP_PS128:
total 0

./dbSNP:
total 0

```


genome, gtf  for creating database and some logs are deposited in supplementary files.

Could you give me some tips to avoid this situation?

Thanks,

Shanshan",AlisaGU,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/45,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU4OTA2MjM5NzY=,problem for constructing the database of test data,CLOSED,2021-05-13T01:41:08Z,2021-05-13T06:23:55Z,2021-05-13T06:23:55Z,"@pauline-ng Hi, we want to build database for pig. Firstly, we download the PROTEIN_DB from https://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref90/uniref90.fasta.gz, we run human_samll_test. But  we can't get the database. here is the output of our progress 

converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
/vol3/agis/likui_group/yinhongwei/software/miniconda/bin/sift4g -d /vol3/agis/likui_group/yinhongwei/pig/uniprot/uniref90.fasta -q ./test_files/homo_sapiens_small/all_prot.fasta --subst ./test_files/homo_sapiens_small/subst --out ./test_files/homo_sapiens_small/SIFT_predictions --sub-results

we check the dir of subst, it had results of transcipt  and it show likes
 head ENST00000342101.subst
M1V
M1L
M1L
M1T
M1K
M1R
M1I
M1I
M1I
M1M
when we checked the dir of SIFT_predictions, it was empty.
i didn't know what is the problem and could you give us some guidlines ?",yinhongwei4079,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/46,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU5MjQ3MzQxMjA=,no data,CLOSED,2021-06-18T09:45:00Z,2022-11-18T14:29:23Z,2021-06-20T09:31:57Z,,BaHole,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/47,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU5Mjg4OTYxMTI=,SIFT,CLOSED,2021-06-24T06:33:20Z,2022-11-18T11:14:39Z,2021-06-25T13:48:07Z,Hi,BaHole,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/48,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWU5ODg3NTc2NDM=,some error,CLOSED,2021-09-06T04:35:03Z,2022-11-18T11:15:03Z,2022-03-30T06:41:07Z,Hi,BaHole,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/49,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM4_jaXl,error,CLOSED,2021-11-29T16:33:05Z,2022-11-18T11:15:24Z,2022-03-22T23:15:19Z,H,BaHole,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/50,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5Fc5gY,can't open files,CLOSED,2022-03-10T13:09:13Z,2022-03-22T23:14:48Z,2022-03-22T23:14:48Z,"I have already installed swith.pm,and put all the files in the right place,can anyone help?Thanks.

converting gene format to use-able input
Can't locate Switch.pm in @INC (you may need to install the Switch module) (@INC contains: /home/jiayi/miniconda3/lib/perl5/5.32/site_perl /home/jiayi/miniconda3/lib/perl5/site_perl /home/jiayi/miniconda3/lib/perl5/5.32/vendor_perl /home/jiayi/miniconda3/lib/perl5/vendor_perl /home/jiayi/miniconda3/lib/perl5/5.32/core_perl /home/jiayi/miniconda3/lib/perl5/core_perl .) at gff_gene_format_to_ucsc.pl line 4.
BEGIN failed--compilation aborted at gff_gene_format_to_ucsc.pl line 4.
done converting gene format
making single records file
can't open /media/data2/jiayi/sift4g/scripts_to_build_SIFT_db/test_files/kandelia_obovata/gene-annotation-src/protein_coding_genes.txt at make-single-records-BIOPERL.pl line 143.
done making single records template
making noncoding records file
can't open /media/data2/jiayi/sift4g/scripts_to_build_SIFT_db/test_files/kandelia_obovata/gene-annotation-src/noncoding.txt at make-single-records-noncoding.pl line 59.
done making noncoding records
make the fasta sequences
can't open /media/data2/jiayi/sift4g/scripts_to_build_SIFT_db/test_files/kandelia_obovata/gene-annotation-src/protein_coding_genes.txt at generate-fasta-subst-files-BIOPERL.pl line 387.
done making the fasta sequences
start siftsharp, getting the alignments
cat: '/media/data2/jiayi/sift4g/scripts_to_build_SIFT_db/test_files/kandelia_obovata/fasta/*.fasta': No such file or directory
/media/data2/jiayi/sift4g/bin/sift4g -d /media/data2/jiayi/sift4g/scripts_to_build_SIFT_db/test_files/kandelia_obovata/gene-annotation-src/Kandelia_rename20210915.pro.fasta -q /media/data2/jiayi/sift4g/scripts_to_build_SIFT_db/test_files/kandelia_obovata/all_prot.fasta --subst /media/data2/jiayi/sift4g/scripts_to_build_SIFT_db/test_files/kandelia_obovata/subst --out /media/data2/jiayi/sift4g/scripts_to_build_SIFT_db/test_files/kandelia_obovata/SIFT_predictions --sub-results
** Checking query data and substitutions files **


** EXITING! No valid queries to process. **
",dodudoduding,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/51,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5F12gE,** Checking query data and substitutions files ** terminate called after throwing an instance of 'std::regex_error'   what():  regex_error Aborted (core dumped),CLOSED,2022-03-17T00:54:38Z,2022-03-22T23:17:25Z,2022-03-22T23:17:25Z,"my gcc version 9.4 and the update the g++ complier through conda,but the error exit, how could i do for this error? thanks",Jiangjiangzhang6,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/52,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5GS2e2,Errors while populating the databases; all files within singleRecords_with_scores folder removed,CLOSED,2022-03-24T10:58:53Z,2022-03-25T15:25:58Z,2022-03-25T15:25:58Z,"
Dear Pauline,

I'm running into some error messages (see at the end of this post) while creating my own SIFT database. The strangest thing is that I could see that files were being created in the singleRecords_with_scores folder, and they looked good, but after the programme is done running all contents from this folder are wiped out. I've attempted it once more with higher RAM in case memory was the problem, but I ran into the exact same issue (plus this time I also got warnings because all .fa files in the chr-src folder were already gzipped).

I can confirm there are neither ""X"" nor ""*"" characters (nor duplicate entries) in the all_prot.fasta file. However there are quite a few N characters in the .fa files (in case that matters).

Sorry if this issue has been reported before; I found two instances with similar error code, but they didn't help me.

Thank you very much for any help you may provide.

Best,

Daniel.

************************

Error code:

`populating databases
Traceback (most recent call last):
  File ""make_regions_file.py"", line 68, in <module>
    get_regions (chrom_file, out_file)
  File ""make_regions_file.py"", line 31, in get_regions
    pos = get_pos (first_line)
  File ""make_regions_file.py"", line 8, in get_pos
    return int (fields[0])
ValueError: invalid literal for int() with base 10: ''
Traceback (most recent call last):
  File ""make_regions_file.py"", line 68, in <module>
    get_regions (chrom_file, out_file)
  File ""make_regions_file.py"", line 31, in get_regions
    pos = get_pos (first_line)
  File ""make_regions_file.py"", line 8, in get_pos
    return int (fields[0])
ValueError: invalid literal for int() with base 10: ''
Traceback (most recent call last):
  File ""make_regions_file.py"", line 68, in <module>
    get_regions (chrom_file, out_file)
  File ""make_regions_file.py"", line 31, in get_regions
    pos = get_pos (first_line)
  File ""make_regions_file.py"", line 8, in get_pos
    return int (fields[0])
ValueError: invalid literal for int() with base 10: ''
Traceback (most recent call last):
  File ""make_regions_file.py"", line 68, in <module>
    get_regions (chrom_file, out_file)
  File ""make_regions_file.py"", line 31, in get_regions
    pos = get_pos (first_line)
  File ""make_regions_file.py"", line 8, in get_pos
    return int (fields[0])
ValueError: invalid literal for int() with base 10: ''
Traceback (most recent call last):
  File ""make_regions_file.py"", line 68, in <module>
    get_regions (chrom_file, out_file)
  File ""make_regions_file.py"", line 31, in get_regions
    pos = get_pos (first_line)
  File ""make_regions_file.py"", line 8, in get_pos
    return int (fields[0])
ValueError: invalid literal for int() with base 10: ''
Traceback (most recent call last):
  File ""make_regions_file.py"", line 68, in <module>
    get_regions (chrom_file, out_file)
  File ""make_regions_file.py"", line 31, in get_regions
    pos = get_pos (first_line)
  File ""make_regions_file.py"", line 8, in get_pos
    return int (fields[0])
ValueError: invalid literal for int() with base 10: ''
Traceback (most recent call last):
  File ""make_regions_file.py"", line 68, in <module>
    get_regions (chrom_file, out_file)
  File ""make_regions_file.py"", line 31, in get_regions
    pos = get_pos (first_line)
  File ""make_regions_file.py"", line 8, in get_pos
    return int (fields[0])
ValueError: invalid literal for int() with base 10: ''
checking the databases
zipping up /mnt/lustre/scratch/home/uvi/bg/dkr/sift4g_annotation/scripts_to_build_SIFT_db/test_files/nr_ancestral_dm6/chr-src/*
All done!`",Arynio,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/53,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5GWh_d,Database creation  cant open input files for new organism,CLOSED,2022-03-25T03:56:37Z,2022-04-01T08:09:06Z,2022-04-01T08:09:06Z,"Hi Pauline,

I have successfully created the trial human database but cant create a mango database using NCBI genome and GFF file [https://www.ncbi.nlm.nih.gov/genome/?term=txid29780[orgn](https://www.ncbi.nlm.nih.gov/genome/?term=txid29780%5borgn)]  

**GTF file**
I believe something is wrong with my GTF file but Im unsure how to fix it (error code below).  Here is my GTF file and the GFF file that was used to create it. 
[GCF_011075055.1_CATAS_Mindica_2.1_genomic.gff.gz](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/8347186/GCF_011075055.1_CATAS_Mindica_2.1_genomic.gff.gz)
[mangifera_indica.assembly_CATAS_Mindica_2.1_edited3.gtf.gz](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/8347191/mangifera_indica.assembly_CATAS_Mindica_2.1_edited3.gtf.gz)

This is what I have done:
1.	gene_biotype added: I have added = gene_biotype ""protein_coding"" to column 9 for CDS, exon and transcript (wasnt sure about this one so tried both). 
2.	I dont have start or stop codons in column 3 but I see you have updated the SIFT code to no longer require start/stop codon coordinates in order to build a database.
3.	I have checked read/write access with ls -l
4.	I have triple checked the folders are all in the right spot
5.	GFF vs GTF: In column 3, the GTF file only has exon, CDS and transcript, its missing the gene that is in the GFF file (along with other categories e.g. region, tRNA). Was there something wrong with the conversion from GFF to GTF? 

**Error code for:**
perl make-SIFT-db-all.pl -config mango_files/Alphonso_config.txt

entered mkdir /home/uqmwilk3/sift/scripts_to_build_SIFT_db/mango_files/mango_genome
/assembly_CATAS_Mindica_2.13/sift/scripts_to_build_SIFT_db/mango_files/mango_genome
converting gene format to use-able input
ls: cannot access /gene-annotation-src: No such file or directory
Unable to open  for reading
done converting gene format
/*.gz: No such file or directorys_to_build_SIFT_db/mango_files/mango_genome
DNA files do not exist or did not unzip properly
#####################################
**Genome fasta file**
- Does this error code also mean there is something wrong with my genome file?

#####################################
**No MT or plastid:**
I do not have a MT or plastid so do I just have to:
1. dna_protein_subs.pl - remove all the code for both the sub chr_is_plastid and sub chr_is_mito?
2. config file - remove these two lines:
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial
",Melanie-Wilkinson,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/54,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5GzHUa,Questions regarding Query IDs construction,CLOSED,2022-03-31T09:42:48Z,2022-04-12T15:06:08Z,2022-04-12T15:06:08Z,"Dear Pauline and Robert, 

I hope it is alright to ask these questions on here.

I have a question regarding the output.
The code results in a folder called SIFT_predictions, with alignment fasta files. If Ive understood it correctly those sequences are with Sw aligned, so pairwise and locally with the query sequence. The identity of the sequences are listed, but what about the query sequence? There is only the ID in the file name (i.e. : ENST000063518). 

1. Can you clarify how those ids come to be?
2. The sequences are aligned locally, so is it possible to get access to the full query sequence, just with its ID?
3. The SIFT.prediction files provide us with position specific sift scores for the newly constructed queries, how is this information significant to us? Can it be closed back to the original query? Or is the SIFT4g annotator the sole possibility to get position specific sift scores for the query sequence?

Thanks in advance,
Yakup",yaada100,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/55,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5HpPN0,Questions regarding the results,CLOSED,2022-04-12T15:08:58Z,2022-04-21T02:10:27Z,2022-04-21T02:10:27Z,"Hello Pauline,

I have a couple of questions regarding the protein alignment results.
If i have understood it correct, the queries(in SIFT_prediction folder) used in the files are acquired from the gtf file, right?
But they do vary from the sequences found in the gtf file. It seems, like there has been a sequence which has been inserted.

1. Can you explain to me or link me to an explanation on what change is done and how these sequences are created/chosen as query?
2. Also if the change that is done is just the longest increasing subsequence algorithm, then why does the start and end seem to not change?
3. Lastly, this Query sequence is locally pairwise aligned(SW) with the collected sequences and sift scores are calculated. But is this sequence, which is found in the files(*.aligned.fasta) the **whole** sequence? Because the whole sequence is aligned, it seems more like a global alignment.
For example as in here(Homo sapien file):

Found in ENST00000628202.aligned.fasta:
MAAIPALDPEAEPSMDVILVGSSELSSSVSPGTGRDLIAYEVKANQRNIEDICICCGSLQVHTQHPLFEGGICAPCKDKFLDALFLYDDDGYQSYCSICCSGETLLICGNPDCTRCYCFECVDSLVGPGTSGKVHAMSNWVCYLCLPSSRSGLLQRRRKWRSQLKAFYDRESENPLEMFETVPVWRRQPVRVLSLFEDIKKELTSLGFLESGSDPGQLKHVVDVTDTVRKDVEEWGPFDLVYGATPPLGHTCDRPPSWYLFQFHRLLQYARPKPGSPRPFFWMFVDNLVLNKEDLDVASRFLEMEPVTIPDVHGGSLQNAVRVWSNIPAIRSRHWALVSEEELSLLAQNKQSSKLAAKWPTKLVKNCFLPLREYFKYFSTELTSSL
length of sequences: 386

Found in Homo_sapiens.GRCh38.pep.all.fa:

ENSP00000486001.1 pep:known chromosome:GRCh38:21:44246352:44261890:-1 gene:ENSG00000142182.8 transcript:ENST00000628202.2 gene_biotype:protein_coding transcript_biotype:protein_coding

MAAIPALDPEAEPSMDVILVGSSELSSSVSPGTGRDLIAYEVKANQRNIEDICICCGSLQMAAIPALDPEAEPSMDVILVGSSELSSSVSPGTGRDLIAYEVKANQRNIEDICICCGSLQVHTQHPLFEGGICAPCKDKFLDALFLYDDDGYQSYCSICCSGETLLICGNPDCTRCYCFECVDSLVGPGTSGKVHAMSNWVCYLCLPSSRSGLLQRRRKWRSQLKAFYDRESENPLEMFETVPVWRRQPVRVLSLFEDIKKELTSLGFLESGSDPGQLKHVVDVTDTVRKDVEEWGPFDLVYGATPPLGHTCDRPPSWYLFQFHRLLQYARPKPGSPRPFFWMFVDNLVLNKEDLDVASRFLEMEPVTIPDVHGGSLQNAVRVWSNIPAIRSRHWALVSEEELSLLAQNKQSSKLAAKWPTKLVKNCFLPLREYFKYFSTELTSSL
length of sequences: 446

Insert : MAAIPALDPEAEPSMDVILVGSSELSSSVSPGTGRDLIAYEVKANQRNIEDICICCGSLQ",yaada100,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/56,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5JpJfP,How to address poor database statistics,CLOSED,2022-05-13T17:54:25Z,2022-06-07T08:25:55Z,2022-05-24T08:12:08Z,"Hi Pauline,

Thanks for developing this resource to create SIFT4G databases for any organism. It's quite easy to use. I am annotating a new bird genome, the Greater prairie chicken (Tympanuchus cupido). Unfortunately, my database statistics are quite low. When I use UniRef90 as the protein database, I get the following overall stats:

ALL     23 (4351/18874) 39 (16156279/41401234)  15(2441297/16156279)

I thought that maybe a larger database could help, so I tried using the ncbi non-redundant database, but that actually resulted in even worse statistics:

ALL     19 (3572/18874) 33 (13754937/41401234)  6(890807/13754937)

I started with a gff file, and used gffread to convert to gtf. I did not personally create the gff file, but it was created with Maker based on transcriptome data. I am not sure how to assess the quality of this gff. 

Do you have any ideas for how I could improve my overall SIFT database statistics on this organism? When I ran the test cases, I found very high database statistics, so I believe I am running everything correctly. I've pasted my config file below.

Best, 
Andrew

GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=./test_files/Tympanuchus_cupido_full
ORG=Typanuchus_cupido
ORG_VERSION=satsuma
#DBSNP_VCF_FILE=

#Running SIFT 4G
SIFT4G_PATH=/redser4/personal/andrew/src/sift4g/bin/sift4g
PROTEIN_DB=/redser4/personal/andrew/uniprot/uniref90.fasta


# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord

",andrewSharo,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/57,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5Ks0m6,processing database part 975 than finishand nothing generate,CLOSED,2022-05-31T02:36:57Z,2022-05-31T03:42:08Z,2022-05-31T03:42:08Z,,wpf95,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/58,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5Me-_L,"Use of uninitialized value $fasta_subseq in concatenation (.) or string at generate-fasta-subst-files-BIOPERL.pl line 446, <IN_TX> line 37345.",CLOSED,2022-06-24T02:45:32Z,2022-06-24T04:04:46Z,2022-06-24T04:04:46Z,"@pauline-ng
Hi Pauline

A big log file with repetitive warnings like ""Use of uninitialized value $fasta_subseq in concatenation (.) or string at generate-fasta-subst-files-BIOPERL.pl line 446, <IN_TX> line 37345."" 

When I run the sample files, SIFT4G databases created correctly.

I look in the fasta directory for my file , I see protein sequences.

This is my file tree:
|-- chr-src  genomic.fa.gz
|-- gene-annotation-src  genomic.gtf.gz
|-- dbSNP  xx.vcf.gz

My config-file:
GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=5
MITO_GENETIC_CODE_TABLENAME=Invertebrate Mitochondrial

PARENT_DIR=/public/home/lizhimin/biosoft/sift4g/scripts_to_build_SIFT_db/hefeishi_test/hefeishi
ORG=hefeishi
ORG_VERSION=GRCh38.83
# DBSNP_VCF_FILE=hefeishi.LDfilter-SRR-remove.vcf.gz

#Running SIFT 4G
SIFT4G_PATH=~/anaconda3/bin/sift4g
PROTEIN_DB=/public/home/lizhimin/biosoft/sift4g/scripts_to_build_SIFT_db/hefeishi_test/protein.faa

Any advice?

Thanks,
LiZhimin

",lizhiminlhy,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/59,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5Mltam,Issue making SIFT database from local genomic and gene annotation file (.gtf),CLOSED,2022-06-26T15:23:50Z,2022-08-15T00:23:19Z,2022-08-15T00:23:19Z,"Hello

I'm trying to make a SIFT database for chromosome 3 of Dictyostelium discoideum in order to analyse some VCF files of SNPs generated for certain genes among various strains. I have followed the protocol outlined for making a SIFT database with local genomic and gene attonation files (.gtf). I have installed all modules which I was prompted to install in order to run `perl make-SIFT-db-all.pl -config <config_file>`.  The script runs until the error `cat: 'test_files/output/fasta/*.fasta': No such file or directory`.  It then ends with 
`** Checking query data and substitutions files **


** EXITING! No valid queries to process. **` 
Are there any common errors I might be making?
Thank you",frankiefattorini,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/60,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5NJ-O1,SIFT4G_Create_Genomic_DB,CLOSED,2022-07-05T15:33:41Z,2022-07-30T12:47:28Z,2022-07-30T12:47:28Z,"Hello,

I tried with the test files. It's not working either.

 **princy_raagul@AG053360D-07006:/mnt/c/Users/josephine.p.johnson/Documents/Variant_dataset/SIFT/scripts_to_build_SIFT_db$ perl make-SIFT-db-all.pl -config test_files101/homo_sapiens-test.txt**
entered mkdir ./test_files101/homo_sapiens_small/
/GRCh38.83dir ./test_files101/homo_sapiens_small/
converting gene format to use-able input
ls: cannot access '/gene-annotation-src': No such file or directory
Unable to open  for reading
done converting gene format
/*.gz: No such file or directoryns_small/
DNA files do not exist or did not unzip properly

[homo_sapiens-test.txt](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/9047651/homo_sapiens-test.txt)
ot unzip properly",PrincyJohnson,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/61,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5NfUBs,mitochondrial code,CLOSED,2022-07-11T00:12:49Z,2022-07-11T00:14:44Z,2022-07-11T00:14:19Z,"By email from a user.

Hi,
I was wondering if your program takes into consideration the differences in mitochondrial genetic code and genomic code in order to make predictions in mus musculus.
Thanks,",pauline-ng,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/62,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5NfUPc,building database,CLOSED,2022-07-11T00:15:35Z,2022-11-04T22:30:30Z,2022-11-04T22:30:30Z,"*** Email from user***

 I went through the tutorial on github and created my own database for mus_musculus GRCm39.106. I then compared it to the one you have online (GRCm38.83), and I noticed that:

1. for most chromosomes the newer version had heavier files, which I think makes sense because they updated the genome
2. In the one online, there are a total of 137 files in the folder while in the one I created there are only 119
3. When running SIFT4g with the new database on previously ran samples, I get fewer hits. For example, in one VCF I tested, the old database resulted in 53 sites in the output while the new one was only 39

I have attached screenshots of the errors I got during database creation. It seems that some files (not sure what these are), weren't in the directory, so couldn't be processed. I also compared the ""CHECK_GENES.LOG"" file and there are six more of these GL or JH files, so that accounts for the 18 missing files as each records gets three files. My questions are:

1. what are these files and how are they important?
2. Any idea why I am missing six from the new assembly?

One suspicion I had was that my internet connection was too slow when downloading the ensembl files that maybe some were left out. I am planning to repeat at a place where I have better internet to test this. But I also wanted to check if you had any additional ideas.",pauline-ng,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/63,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5Nm5Q3,Issue annotating VCF files with SIFT database,CLOSED,2022-07-12T13:09:27Z,2022-07-14T03:11:04Z,2022-07-14T03:11:03Z,"Hello,

I've created a SIFT database for chromosome 3 of Dictyostelium discoideum using fasta and gff (converted to gtf) files. Running `more CHECK_GENES.LOG` gave the output:
 `Chr     Genes with SIFT Scores  Pos with SIFT scores    Pos with Confident Scores`
`DDB0232430      83 (3798/4567)  91 (14959896/16519059)  74(10997369/14959896)`
When attempting to annotate vcf files containing SNPs within my genes of interest, however, I received the output:
`Started Running .......`
`Running in Single transcripts mode`
`Chromosome      WithSIFT4GAnnotations   WithoutSIFT4GAnnotations        Progress`
`test_files/output/dicty_2.7/DDB0232430.regions does not exist`
`DDB0232430                      0                       450                     Completed : 1/1`
Both of my genes of interest seem to have been included in the various files produced for the alignment. I did not include the vcf file during in the 'dbSNP' file during the database creation process, so could this be the issue? If so, is there a way to create the SIFT database using several VCF files or a merged VCF file containing SNP information for different strains of an organism with different SNPs within the same gene sequence, as I wish to look at a few hundred VCF files and the SNP effects on protein structure.
Thank you",frankiefattorini,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/64,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5OnTfh,"'Pos with Confident Scores' is low in ""CHECK_GENES.LOG""",CLOSED,2022-07-27T02:00:12Z,2022-07-28T02:30:09Z,2022-07-28T02:30:09Z,"Hi, pauline
This is pengfei.  I constructed a new datavase. Then I checked the database.  I go to ""CHECK_GENES.LOG"", then got ""ALL     100 (37304/37410)       100 (148558782/148683715)       15(22342363/148558782)"". And you said ""Your database is done if the percentages are high for the last 3 different columns.""  But the 'Pos with Confident Scores' is  low.
Chr     Genes with SIFT Scores  Pos with SIFT scores    Pos with Confident Scores
1       99 (1536/1544)  100 (6106447/6111160)   17(1010023/6106447)
10      100 (1583/1586) 100 (6491552/6493442)   12(793428/6491552)
11      100 (1656/1661) 100 (6918920/6922883)   14(994782/6918920)
12      100 (621/623)   100 (2720527/2721496)   11(308259/2720527)
13      100 (1279/1284) 100 (4639379/4642032)   13(597783/4639379)
14      100 (786/787)   100 (3394346/3395503)   15(516357/3394346)
15      100 (1533/1537) 100 (5208466/5212123)   17(868543/5208466)
16      100 (1186/1188) 100 (5177871/5178717)   19(1002244/5177871)
17      100 (1078/1081) 100 (4690593/4693044)   10(450682/4690593)
18      100 (1952/1958) 100 (6976052/6981044)   25(1732116/6976052)
19      100 (2076/2076) 100 (8342833/8342833)   14(1182843/8342833)
2       100 (1593/1598) 100 (7236744/7242000)   9(664736/7236744)
20      100 (569/570)   100 (2484254/2485544)   12(307858/2484254)
21      100 (892/896)   99 (3738173/3766981)    15(556627/3738173)
22      100 (1027/1032) 100 (4520633/4525211)   10(456486/4520633)
23      100 (1152/1153) 100 (3866972/3868343)   18(709417/3866972)
24      100 (554/554)   100 (2515278/2515278)   10(251265/2515278)
25      100 (1182/1183) 100 (4439937/4440745)   17(755517/4439937)
26      100 (716/719)   100 (2842268/2844173)   10(293528/2842268)
27      100 (421/422)   100 (1802775/1803409)   17(301302/1802775)
28      99 (528/531)    100 (2425027/2426437)   12(286890/2425027)
29      100 (1043/1048) 100 (3824056/3834534)   17(644781/3824056)
3       100 (2121/2127) 100 (7798555/7805777)   17(1320641/7798555)
4       100 (1288/1292) 100 (5537040/5541068)   13(716239/5537040)
5       100 (2124/2127) 100 (8413279/8414984)   18(1488746/8413279)
6       100 (1027/1027) 100 (4114550/4114550)   13(552589/4114550)
7       100 (2062/2065) 100 (7961434/7965089)   17(1380150/7961434)
8       99 (1186/1195)  100 (4956491/4963221)   12(595398/4956491)
9       100 (881/882)   100 (3810505/3811393)   11(436621/3810505)
MT      0 (0/8) 0 (0/13964)     0(0/0)
NKLS02000056.1  100 (2/2)       100 (1997/1997) 97(1939/1997)
NKLS02000065.1  100 (1/1)       100 (483/483)   0(0/483)
NKLS02000090.1  100 (1/1)       100 (3012/3012) 0(0/3012)
NKLS02000101.1  100 (1/1)       100 (2267/2267) 100(2267/2267)
NKLS02000125.1  0 (0/0) 0 (0/0) 0(0/0)
NKLS02000137.1  0 (0/0) 0 (0/0) 0(0/0)
NKLS02000210.1  0 (0/0) 0 (0/0) 0(0/0)
NKLS02000218.1  100 (1/1)       100 (857/857)   0(0/857)
.
.
.
ALL     100 (37304/37410)       100 (148558782/148683715)       15(22342363/148558782)

Then I find your reply in this issue https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/43#issuecomment-762525915 and you say""your numbers look good to me. ""Genes with SIFT scores"" and ""Pos with SIFT Scores"" are > 95%."" 
So the database I constructed can be used
Look forward to your reply. Thanks very much!",wpf95,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/65,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5QpFYD,"Using human test files: 'Pos with Confident Scores' is low in ""CHECK_GENES.LOG""",CLOSED,2022-08-27T05:18:25Z,2022-08-28T23:05:48Z,2022-08-28T23:05:48Z,"Hi Pauline,

What does it mean when the 3rd column of CHECK_GENES.LOG is low for the human test?

Chr     Genes with SIFT Scores  Pos with SIFT scores    Pos with Confident Scores
21      99 (810/822)    100 (2261496/2263334)   68(1542519/2261496)
MT      100 (7/7)       100 (12241/12241)       18(2147/12241)

ALL     99 (817/829)    100 (2273737/2275575)   68(1544666/2273737)

There were no errors in the run (below) but no singleRecords_with_scores were created. 

entered mkdir ./test_files/homo_sapiens_small/GRCh38.83
converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
/g/data/ht96/Mel_UQ/sift2/sift4g/bin/sift4g -d /g/data/ht96/Mel_UQ/sift2/SIFT_database/uniref90.fasta -q ./test_files/homo_sapiens_small/all_prot.fasta --subst ./test_files/homo_sapiens_small/subst --out ./test_files/homo_sapiens_small/SIFT_predictions --sub-results
done getting all the scores
populating databases
checking the databases
zipping up ./test_files/homo_sapiens_small/chr-src/*
All done!",Melanie-Wilkinson,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/66,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5QpKr8,For the annotation of Indel?,CLOSED,2022-08-27T07:13:40Z,2022-08-27T10:42:39Z,2022-08-27T10:42:39Z,"Hello, I have tried this tools and got teh result successfully. But I founf there was no prediction results for small any InDels. I wonder if this tool can predict the impact of Indels? Or any other recommanded tools? 

Thank you very much for any help.",yilunhuangyue,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/67,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5SUvx-,"Use of uninitialized value $fasta_subseq in concatenation (.) or string at generate-fasta-subst-files-BIOPERL.pl line 446, <IN_TX> line 62209.",CLOSED,2022-09-21T16:03:28Z,2022-09-28T00:59:48Z,2022-09-28T00:59:47Z,"Hi pauline-ng, 

Can you please help me? I am getting the warning in the subject line repeatedly when attempting to generate a SIFT database for the Asian elephant genome. The program does not successfully generate a database. I believe it doesn't move past running ""make-single-records-BIOPERL.pl"". 

My genome fasta, gtf, and peptide fasta files are downloaded from NCBI here: https://www.ncbi.nlm.nih.gov/assembly/GCF_024166365.1. Attached you will find my config file and the file tree of the parent directory. 

Best regards,
Thuy

[elemax1_config.txt](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/9618345/elemax1_config.txt)

[elemax_tree.txt](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/9618369/elemax_tree.txt)

",thuynnguyen,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/68,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5SXmLR,Can not build my own SIFT database,CLOSED,2022-09-22T06:40:33Z,2022-09-23T13:58:44Z,2022-09-23T03:47:26Z,"Hi,

I have tried to use the SIFT4G to build my own SIFT database for many times, but it still was unsuccessful. can you help me to check it? The details as bellow:

** Searching database for candidate sequences **

processing database part 1 (size ~0.25 GB): 100.00/100.00% *
** Aligning queries with candidate sequences **

processing database part 1 (size ~1.00 GB): 100.00/100.00% *
** Selecting alignments with median threshold: 2.75 **

processing queries: 100.00/100.00% *
** Generating SIFT predictions with sequence identity: 100.00% **

processing queries: 100.00/100.00% *
done getting all the scores
populating databases
cat: /home/scripts_to_build_SIFT_db/test_files/singleRecords/Chr1.singleRecords: No such file or directory
can't open /home/scripts_to_build_SIFT_db/test_files/singleRecords/Chr1.singleRecords at map-scores-back-to-records.pl line 122.
Unable to read from /home/scripts_to_build_SIFT_db/test_files/singleRecords_with_scores/Chr1_scores.Srecords
cat: /home/scripts_to_build_SIFT_db/test_files/singleRecords/Chr1.singleRecords_noncoding.with_dbSNPid: No such file or directory
Traceback (most recent call last):
File ""make_regions_file.py"", line 68, in
get_regions (chrom_file, out_file)
File ""make_regions_file.py"", line 31, in get_regions
pos = get_pos (first_line)
File ""make_regions_file.py"", line 8, in get_pos
return int (fields[0])
ValueError: invalid literal for int() with base 10: ''
rm: cannot remove '/home/scripts_to_build_SIFT_db/test_files/singleRecords_with_scores/Chr1_scores.Srecords': No such file or directory

many thx.",XIAO2Mark,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/69,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5S6lVq,Errors in building my own database for rheMac10,CLOSED,2022-09-29T15:42:57Z,2022-12-06T16:19:24Z,2022-12-06T16:19:24Z,"Hello,

I have had errors in attempting to create a database for rheMac10 (or MMul_10). There already is a database for rheMac8 (MMul_8) for some reference. I have my own FASTA reference and gtf file and have successfully created a test database for the homo-sapiens_test provided as an examples in test_files. I've allowed the program to run in excess of 24 hours so I think I've gotten the maximal output possible so far.

I'll try my best to describe the errors and give my output and config. The latter should differ only from homo_sapiens-test.txt in the following lines:

PARENT_DIR=/home/npb0015/reinforcement_project/
ORG=macaca_mulatta
ORG_VERSION=Mmul_10.99

#Running SIFT 4G
SIFT4G_PATH=/tools/sift4g-1/bin/sift4g
PROTEIN_DB=/home/npb0015/reinforcement_project/Reference_files/uniprot_sprot.fasta

# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=Reference_files/
CHR_DOWNLOAD_DEST=Reference_files/

The error messages I receive are the following two lines repeated several times:

Use of uninitialized value $aa in string eq at make-single-records-BIOPERL.pl line 274.
Use of uninitialized value $aa in concatenation (.) or string at make-single-records-BIOPERL.pl line 280.

Then the following repeated several times:

Use of uninitialized value $orig_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $mutated_aa in string eq at make-single-records-BIOPERL.pl line 551.

Then the following repeated several times:

Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.

And are are at least a hundred thousand blocks like that. Then later on blocks of the following repeated:

Use of uninitialized value $mutated_aa in string eq at generate-fasta-subst-files-BIOPERL.pl line 894
Use of uninitialized value $aa2 in string eq at generate-fasta-subst-files-BIOPERL.pl line 621.
Use of uninitialized value $aa2 in string ne at generate-fasta-subst-files-BIOPERL.pl line 626.

When the program is done it seems to populate singleRecords, subst, and fasta folders with a substantive number of files looking correct. The main folder is populated with log files and the Reference_files directory does have txt files. All other directories in the config file and particularly the Mmul_10.99 is never populated. When I annotated a VCF using the directory it seems as though there's no SIFT annotations occuring.

I hope this has been sufficiently detailed and would greatly appreciate help.",npb596,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/70,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5VmJE0,Feature request - sift4g --thread ,CLOSED,2022-11-04T13:19:11Z,2022-11-04T22:34:13Z,2022-11-04T22:34:13Z,"Hi, thanks for your great work.

Can we pass thread num through config file to speed up sift4g process?",m3hdad,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/71,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5WWt6U,"SIFT4G Annotator Standalone annotates only ""NA"" in VCF file",CLOSED,2022-11-14T21:34:51Z,2022-11-29T00:54:06Z,2022-11-29T00:54:06Z,"Hi, 

I'm trying to use the SIFT4G annotator for my vcf file ( in the format requested). Once I feed it through the annotator and try to parse the results file, I only see ""NA"" in all the SIFT annotations. Any thoughts or suggestions would help!

Thanks!",mtejura,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/72,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5ZEGuJ,SIFT4G annotator ,CLOSED,2022-12-13T13:33:03Z,2023-08-31T14:19:43Z,2023-08-31T14:19:43Z,"Dear Pauline, 

I have wanted to use SIFT4G on the 11th chromosome of homo sapiens. 
To do that I am in need of a proper gene annotation file, so I used as suggested the SIFT4G Annotator.
The files I've used are basically the provided Database (https://sift.bii.a-star.edu.sg/sift4g/public/Homo_sapiens/GRCh38.83.chr/11.gz), 
and as for the .vcf file, I used variants provided by clinvar, trimmed for only the 11th chromosome.

I will include the vcf file (in two halfs and .txt) as a attachment. 

To get the gene annotation file, I have used the .jar graphical board as well, as the command option on linux
(java -jar SIFT4G_Annotator.jar -c -i annotator/eleven.vcf -d 11 -r annotator -t)

**The procedure results in empty files and such an answer:**

_Started Running .......                                                                                                                                                                                                                    Running in Multitranscripts mode                                                                                                                                                                                                                                                                                                                                                                                                                                                      Chromosome      WithSIFT4GAnnotations   WithoutSIFT4GAnnotations        Progress                                                                                                                                                           The following chromosomes (or scaffolds/contigs) are not found in the SIFT 4G database and will not be annotated:                                                                                                                          11                                                                                                                                                                                                                                         Please contact us if you have any questions.                                                                                                                                                                                               eleven/11.regions does not exist                                                                                                                                                                                                           11                      0                       92107                   Completed : 1/1                                                                                                                                                                                                                                                                                                                                                                                               Merging temp files....                                                                                                                                                                                                                     SIFT4G Annotation completed !                                                                                                                                                                                                              Output directory:annotator                                                                                                                                                                                                                 End Time for parallel code: Wed Dec 14 13:24:00 UTC 2022_ 


[eleven_vcf.txt_1.txt](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/10218331/eleven_vcf.txt_1.txt)
[eleven_vcf.txt_2.txt](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/10218335/eleven_vcf.txt_2.txt)

It seems like my variant file is the problem, do you have a suggestion for me how to acquire the proper file?

Best regards,
Yakup
",yaada100,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/73,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5a3Ipx,The database was not created successfully by SIFT4G_Create_Genomic_DB,CLOSED,2023-01-08T08:36:41Z,2023-08-31T14:18:59Z,2023-08-31T14:18:59Z,"I can't successfully create the database with the test file
The error log is detailed below
[run.sift4g.err.txt](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/10367980/run.sift4g.err.txt)

The out log is detailed below
[run.sift4g.out.txt](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/10367985/run.sift4g.out.txt)

The error log is detailed below
![image](https://user-images.githubusercontent.com/118544453/211187335-f31a024f-cebd-4de0-aa34-e55e1daa6b7a.png)

Where directory ASM1036v1.34directory SIFT_predictions and directory singleRecords_with_scores are empty directories
",danrans123,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/74,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5c5pgZ,files with lowercase nucleotides,OPEN,2023-01-26T18:56:41Z,2023-01-26T18:56:41Z,,"Dear Pauline,

I am wondering how SIFT4G_Create_Genomic_DB handle lowercase nucleotides included in the genomic fasta *.fa.gz and *.vcf.gz input files? I would prefer to keep *.fa.gz softmasked and the lowercase in *.vcf.gz provides some additional information as well, but if sift4g does not take lowercases on its analysis I will convert to uppercase beforehand. Thank you.

Rom ",romseg,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/75,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5em2-O,I can not creat database,CLOSED,2023-02-16T08:25:16Z,2023-09-23T22:37:42Z,2023-09-23T22:37:21Z,Hiwhile I creat a databasei recieve the massage said Unable to read from /home/zyi/program/sift/SIFT4G_Create_Genomic_DB/test_files/covid_19/singleRecords/MN908947.3.singleRecords_noncodingplease how can i go through. The issue come from the script named make_regions_file.py,NiklausMikaelson12138,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/76,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5hyBC5,Error in building database for new species,CLOSED,2023-03-25T12:37:19Z,2023-08-31T14:21:29Z,2023-08-31T14:21:29Z,"Hello,

I've had some issues generating a database for my species. I have managed to get sift4g to run and it appears it is working. For example this is the output from one of my runs:[superscaffold16.txt](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/files/11068867/superscaffold16.txt)

However, when I try to run Sift4G Annotator, I've realised that no .regions files are generated during my runs, no files populate my SIFT_alignments directory and there are no files in my singleRecords_with_scores directory at the end of the run. Here is what the PARENT_DIR for one of my runs looks like:

shawr@EI-HPC interactive Super-Scaffold_16_PARENTDIR]$ ls -lthr
total 1.1M
drwxrwx--- 2 shawr EI_ga011    0 Mar 25 11:19 SIFT_alignments
drwxrwx--- 2 shawr EI_ga011    0 Mar 25 11:19 dbSNP
-rwxrwx--- 1 shawr EI_ga011    0 Mar 25 11:20 invalid.log
-rwxrwx--- 1 shawr EI_ga011    0 Mar 25 11:20 Log2.txt
drwxrwx--- 2 shawr EI_ga011 6.0K Mar 25 11:20 subst
drwxrwx--- 2 shawr EI_ga011 4.9K Mar 25 11:20 fasta
-rwxrwx--- 1 shawr EI_ga011  49K Mar 25 11:20 peptide.log
-rwxrwx--- 1 shawr EI_ga011   71 Mar 25 11:20 fasta.log
-rwxrwx--- 1 shawr EI_ga011  51K Mar 25 11:20 all_prot.fasta
drwxrwx--- 2 shawr EI_ga011  12K Mar 25 12:09 SIFT_predictions
drwxrwx--- 2 shawr EI_ga011  291 Mar 25 12:09 singleRecords
drwxrwx--- 2 shawr EI_ga011  110 Mar 25 12:10 Super-Scaffold_16
drwxrwx--- 2 shawr EI_ga011    0 Mar 25 12:10 singleRecords_with_scores
drwxrwx--- 2 shawr EI_ga011   77 Mar 25 12:12 chr-src
drwxrwx--- 2 shawr EI_ga011  112 Mar 25 12:16 gene-annotation-src


I have also removed any protein sequences that had any unwanted characters - 'X', '*', '-' 


Any help would be really appreciated! 
Many thanks,

Becky",rebecca-sh,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/78,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5iLHvO,error in building database,OPEN,2023-03-30T07:40:23Z,2023-04-26T11:40:55Z,,"I was trying to create database for Candida tropicalis using genomic assembly fasta file and annotation file in gtf format. I created a config file named C_tropicalis_MYA3404.txt , which is located in test files folder. when i try to run the command :
**perl make-SIFT-db-all.pl -config test_files/C_tropicalis_MYA3404.txt**

I'm getting the followng error:

**entered mkdir /test_files/C_topicalis_MYA3404
No such file or directory at /home/mml/programs/scripts_to_build_SIFT_db/common-utils.pl line 80.**

I'm quite new to this, so it might be some very obvious problem. Kindly let me know if i can fix this.

",AmruthaJNC,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/79,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5lD1ge,* processing database part 1 (size ~0.25 GB): 100.00/100.00% *,CLOSED,2023-05-04T08:24:15Z,2023-05-14T05:59:39Z,2023-05-09T22:48:52Z,"Hi Pauline
I have some questions about the result I got when I make the SIFT4G database. Here is the result of the Homo sapiens example.

converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
/public1/home/sc60080/miniconda2/bin/sift4g -d /public1/home/sc60080/sc60080/ws2/scripts_to_build_SIFT_db/test_files/homo_sapiens_small/gene-annotation-src/Homo_sapiens.GRCh38.pep.all.fa -q /public1/home/sc60080/sc60080/ws2/scripts_to_build_SIFT_db/test_files/homo_sapiens_small/all_prot.fasta --subst /public1/home/sc60080/sc60080/ws2/scripts_to_build_SIFT_db/test_files/homo_sapiens_small/subst --out /public1/home/sc60080/sc60080/ws2/scripts_to_build_SIFT_db/test_files/homo_sapiens_small/SIFT_predictions --sub-results 
** Checking query data and substitutions files **
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
* processing database part 1 (size ~0.25 GB): 100.00/100.00% *

Is it all right? I haven't seen ""All done!"",so I doubt that if this is right.
And here is the result of my research object.

done making the fasta sequences
start siftsharp, getting the alignments
/public1/home/sc60080/miniconda2/bin/sift4g -d /public1/home/sc60080/sc60080/ws2/scripts_to_build_SIFT_db/test_files/Rehmannia_chingii/gene-annotation-src/N01_Chr_genome_final_gene.gff3.pep.fa -q /public1/home/sc60080/sc60080/ws2/scripts_to_build_SIFT_db/test_files/Rehmannia_chingii/all_prot.fasta --subst /public1/home/sc60080/sc60080/ws2/scripts_to_build_SIFT_db/test_files/Rehmannia_chingii/subst --out /public1/home/sc60080/sc60080/ws2/scripts_to_build_SIFT_db/test_files/Rehmannia_chingii/SIFT_predictions --sub-results 
** Checking query data and substitutions files **
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
* processing database part 1 (size ~0.25 GB): 100.00/100.00% *


It seems that I got the same result, but for my research object ,it takes about 30 minutes to making the database, it takes so short time that I can't believe it all done.

Any advice?
Thanks,
wangshuo",wanggshuoo,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/80,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5oFBF3,Possible fasta related errors with creating a database,CLOSED,2023-06-07T15:16:58Z,2023-09-23T22:36:47Z,2023-09-23T22:36:46Z,"Hello and thank you in advance for your time. 

I've been working to create a database for _Ursus americanus_ and have been getting error messages that seem to be related to fasta files. I will include my config file and the messages below.

This is what is contained in my config file: 

GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=/home/hrclndnn/SIFT/SIFT_databases/uamer
ORG=Ursus_americanus
ORG_VERSION=ASM334442v1

#Running SIFT 4G
SIFT4G_PATH=/home/hrclndnn/SIFT/sift4g/bin/sift4g
PROTEIN_DB=/home/hrclndnn/SIFT/SIFT_databases/uamer/protein-db/uniref90.fasta


# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord


An abbreviated version of the messages when I run perl /home/hrclndnn/SIFT/scripts_to_build_SIFT_db/make-SIFT-db-all.pl -config /home/hrclndnn/SIFT/scripts_to_build_SIFT_db/test_files/uamer_config.txt:

converting gene format to use-able input
done converting gene format
making single records file
Use of uninitialized value $fasta_subseq in concatenation (.) or string at make-single-records-BIOPERL.pl line 210, <IN_TX> line 1.
...
(this repeats with additional line numbers following <IN_TX>)
...
Use of uninitialized value $fasta_subseq in concatenation (.) or string at generate-fasta-subst-files-BIOPERL.pl line 446, <IN_TX> line 58026.
... 
(similarly, this message is repeated with other line numbers following <IN_TX>)
...
done making the fasta sequences
start siftsharp, getting the alignments
cat: /home/hrclndnn/SIFT/SIFT_databases/uamer/fasta/*.fasta: No such file or directory
/home/hrclndnn/SIFT/sift4g/bin/sift4g -d /home/hrclndnn/SIFT/SIFT_databases/uamer/protein-db/uniref90.fasta -q /home/hrclndnn/SIFT/SIFT_databases/uamer/all_prot.fasta --subst /home/hrclndnn/SIFT/SIFT_databases/uamer/subst --out /home/hrclndnn/SIFT/SIFT_databases/uamer/SIFT_predictions --sub-results 
** Checking query data and substitutions files **


** EXITING! No valid queries to process. **


Please let me know if there's any additional information you need or if you have any suggestions for resolving this issue. 

Thank you.",hclendenin,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/81,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5vy69X,has error during create new database for Culex Tarsalis (invalid chain data),CLOSED,2023-08-31T14:09:46Z,2023-09-01T17:26:04Z,2023-09-01T17:26:04Z,"I followed the steps following Making a SIFT database from local genomic and gene annotation file (.gtf).
This is the output of i run ""perl make-SIFT-db-all.pl -config /sift4g/culex_tarsalis_config.txt"" to create the database:

##### output ##################################

root@002ba04e1693:/scripts_to_build_SIFT_db# perl make-SIFT-db-all.pl -config /sift4g/culex_tarsalis_config.txt
converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
/sift4g/bin/sift4g -d /landscape_genetics/SIFT/uniref90.fasta.gz -q /sift4g/run_sift/all_prot.fasta --subst /sift4g/run_sift/subst --out /sift4g/run_sift/SIFT_predictions --sub-results 
** Checking query data and substitutions files **
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
[ERROR:src/chain.c:69]: invalid chain data
############################################


#### The config file I have is below###########
GENE_DOWNLOAD_SITE=ftp://ftp.ensemblgenomes.org/pub/bacteria/release-34/gtf//bacteria_11_collection/candidatus_carsonella_ruddii_pv/Candidatus_carsonella_ruddii_pv.ASM1036v1.34.gtf.gz
PEP_FILE=ftp://ftp.ensemblgenomes.org/pub/bacteria/release-34/fasta//bacteria_11_collection/candidatus_carsonella_ruddii_pv/pep/Candidatus_carsonella_ruddii_pv.ASM1036v1.34.pep.all.fa.gz
CHR_DOWNLOAD_SITE=ftp://ftp.ensemblgenomes.org/pub/bacteria/release-34/fasta//bacteria_11_collection/candidatus_carsonella_ruddii_pv/dna/

GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=1
MITO_GENETIC_CODE_TABLENAME=Standard

PARENT_DIR=/sift4g/run_sift
ORG=Culex Tarsalis
ORG_VERSION=v1.0.a1


#Running SIFT 4G
SIFT4G_PATH=/sift4g/bin/sift4g
PROTEIN_DB=/landscape_genetics/SIFT/uniref90.fasta.gz

# Sub-directories, don't need to change
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
FASTA_DIR=fasta
SUBST_DIR=subst
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords/
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord

###############################

Could you please help me with what is wrong?  Thank you very much!!!
",Afei99357,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/82,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5v6wYi,Making database for Culex Tarsalis ends without after processing queries with no warning or error,OPEN,2023-09-01T16:01:05Z,2024-10-22T14:03:21Z,,"Hello. thank you for help me with the previous issue. After address the issue, the processing continue to this then stop for no reasons? and I check the database in the <Organ_version> folder, there is no files there at all. Could you please help me with this issue?

#### here is the running code##
<img width=""855"" alt=""Screenshot 2023-09-01 at 11 57 18 AM"" src=""https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/assets/42871795/0aed9feb-cd24-42c9-9b25-76f80d3da45a"">

####### my config file########
GENE_DOWNLOAD_SITE=ftp://ftp.ensemblgenomes.org/pub/bacteria/release-34/gtf//bacteria_11_collection/candidatus_carsonella_ruddii_pv/Candidatus_carsonella_ruddii_pv.ASM1036v1.34.gtf.gz
PEP_FILE=ftp://ftp.ensemblgenomes.org/pub/bacteria/release-34/fasta//bacteria_11_collection/candidatus_carsonella_ruddii_pv/pep/Candidatus_carsonella_ruddii_pv.ASM1036v1.34.pep.all.fa.gz
CHR_DOWNLOAD_SITE=ftp://ftp.ensemblgenomes.org/pub/bacteria/release-34/fasta//bacteria_11_collection/candidatus_carsonella_ruddii_pv/dna/

GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=1
MITO_GENETIC_CODE_TABLENAME=Standard

PARENT_DIR=/sift4g/run_sift
ORG=Culex Tarsalis
ORG_VERSION=v1.0.a1


#Running SIFT 4G
SIFT4G_PATH=/sift4g/bin/sift4g
PROTEIN_DB=/landscape_genetics/SIFT/uniref90.fasta

# Sub-directories, don't need to change
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
FASTA_DIR=fasta
SUBST_DIR=subst
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords/
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord

",Afei99357,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/83,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5wYSl_,Creating SIFT database from local genomic and gtf file with test data does not work,CLOSED,2023-09-07T08:50:44Z,2023-09-07T13:11:53Z,2023-09-07T13:11:52Z,"Hi,
I am trying to run the homo sapiens test data but I am not managing to create the database.

I used this code: `perl make-SIFT-db-all.pl -config test_files/homo_sapiens-test.txt `

This is the output:

```
converting gene format to use-able input
Can't locate Switch.pm in @INC (you may need to install the Switch module) (@INC contains: /home/goliath/miniconda3/lib/site_perl/5.34.0/x86_64-linux-thread-multi /home/goliath/miniconda3/lib/site_perl/5.34.0 /home/goliath/miniconda3/lib/5.34.0/x86_64-linux-thread-multi /home/goliath/miniconda3/lib/5.34.0 .) at gff_gene_format_to_ucsc.pl line 4.
BEGIN failed--compilation aborted at gff_gene_format_to_ucsc.pl line 4.
done converting gene format
making single records file
Can't locate DBI.pm in @INC (you may need to install the DBI module) (@INC contains: /home/goliath/miniconda3/lib/site_perl/5.34.0/x86_64-linux-thread-multi /home/goliath/miniconda3/lib/site_perl/5.34.0 /home/goliath/miniconda3/lib/5.34.0/x86_64-linux-thread-multi /home/goliath/miniconda3/lib/5.34.0 .) at make-single-records-BIOPERL.pl line 22.
BEGIN failed--compilation aborted at make-single-records-BIOPERL.pl line 22.
done making single records template
making noncoding records file
Can't locate DBI.pm in @INC (you may need to install the DBI module) (@INC contains: /home/goliath/miniconda3/lib/site_perl/5.34.0/x86_64-linux-thread-multi /home/goliath/miniconda3/lib/site_perl/5.34.0 /home/goliath/miniconda3/lib/5.34.0/x86_64-linux-thread-multi /home/goliath/miniconda3/lib/5.34.0 .) at make-single-records-noncoding.pl line 12.
BEGIN failed--compilation aborted at make-single-records-noncoding.pl line 12.
done making noncoding records
make the fasta sequences
Can't locate DBI.pm in @INC (you may need to install the DBI module) (@INC contains: /home/goliath/miniconda3/lib/site_perl/5.34.0/x86_64-linux-thread-multi /home/goliath/miniconda3/lib/site_perl/5.34.0 /home/goliath/miniconda3/lib/5.34.0/x86_64-linux-thread-multi /home/goliath/miniconda3/lib/5.34.0 .) at generate-fasta-subst-files-BIOPERL.pl line 23.
BEGIN failed--compilation aborted at generate-fasta-subst-files-BIOPERL.pl line 23.
done making the fasta sequences
start siftsharp, getting the alignments
cat: './test_files/homo_sapiens_small/fasta/*.fasta': No such file or directory
/home/goliath/software/sift4g/bin/sift4g -d home/goliath/software/funannotate_florida/funannotate_db/uniprot_sprot.fasta -q ./test_files/homo_sapiens_small/all_prot.fasta --subst ./test_files/homo_sapiens_small/subst --out ./test_files/homo_sapiens_small/SIFT_predictions --sub-results 
[ERROR]: invalid database file path 'home/goliath/software/funannotate_florida/funannotate_db/uniprot_sprot.fasta'
```

And this is my homo-sapiens-test.txt file:

```
GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=./test_files/homo_sapiens_small
ORG=homo_sapiens
ORG_VERSION=GRCh38.83
DBSNP_VCF_FILE=Homo_sapiens.vcf.gz

#Running SIFT 4G
SIFT4G_PATH=/home/goliath/software/sift4g/bin/sift4g
PROTEIN_DB=home/goliath/software/funannotate_florida/funannotate_db/uniprot_sprot.fasta


# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord
```

I am using a uniport_sprot.fasta file from another package (funannotate) but I think it is the same dataset. 

Any help would be appreaciated!",gubrins,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/84,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5wp4rY,The build database ran successfully but there was no results file,CLOSED,2023-09-11T09:05:16Z,2023-09-21T01:48:46Z,2023-09-15T08:21:23Z,"Hi
When I tried to use the Partial Homo sapiens example to build a database, I encountered some weird issues. It ran successfully, but I didn't get any results in the <PARENT_DIR>/<ORG_VERSION> folder .

**The command line and end-of-run interface look like this:**

(sift4g) [root@localhost SIFT4G_Create_Genomic_DB-master]# perl make-SIFT-db-all.pl -config test_files/homo_sapiens-test.txt
entered mkdir ./test_files/homo_sapiens_small/GRCh38.83
converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
sift4g -d /nfs/LJH/zhushi/plants/nr.plant.fa  -q ./test_files/homo_sapiens_small/all_prot.fasta --subst ./test_files/homo_sapiens_small/subst --out ./test_files/homo_sapiens_small/SIFT_predictions --sub-results 
** Checking query data and substitutions files **
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
* processing database part 31 (size ~0.25 GB): 100.00/100.00% *


**This is the result file structure:**
![file structure](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/assets/89383725/4a626e6f-7365-4577-9f7d-04b304f462fa)


# In addition to the examples, I had the same problem running my own data.


**This is the homo_sapiens-test.txt**

GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=./test_files/homo_sapiens_small
ORG=homo_sapiens
ORG_VERSION=GRCh38.83
DBSNP_VCF_FILE=Homo_sapiens.vcf.gz

#Running SIFT 4G
SIFT4G_PATH=sift4g
PROTEIN_DB=/nfs/LJH/zhushi/plants/nr.plant.fa 

# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord



**This is the chr1D.txt of my data**
##
GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard

## 
PARENT_DIR=/nfs/LJH/TEST/sift/JYM/Chr1D

ORG=JYM
##
ORG_VERSION=chr1D

#Running SIFT 4G
## 
SIFT4G_PATH=sift4g

##
PROTEIN_DB=/mnt/SOFT/nr

## 
# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores

## 
# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log

I would greatly appreciate your assistance in resolving this issue. If possible, I would like to ask you to check where I might have made a mistake or why I am unable to obtain the result files. If you could provide some guidance or suggestions, I would be very grateful.

Thank you very much!

Best wishes
Jinhua Long








",abcdefghijklmn97,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/85,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5w8RFI,Perl problem test data,CLOSED,2023-09-13T16:10:03Z,2023-09-26T15:19:30Z,2023-09-14T07:28:18Z,"Hi,

I am running the test data to build a new database, this is the code I use: `perl make-SIFT-db-all.pl -config test_files/homo_sapiens-test.txt`

And this is my config file:

```
GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=/mnt/DiscoA/sift4g_2/scripts_to_build_SIFT_db/test_files/homo_sapiens_small
ORG=homo_sapiens
ORG_VERSION=GRCh38.83
DBSNP_VCF_FILE=Homo_sapiens.vcf.gz

#Running SIFT 4G
SIFT4G_PATH=/mnt/DiscoA/sift4g_2/bin/sift4g
PROTEIN_DB=/home/goliath/software/funannotate/uniprot_sprot.fasta


# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord

```

Being this the output:

```
converting gene format to use-able input
done converting gene format
making single records file
Possible precedence issue with control flow operator at /home/goliath/miniconda3/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.
done making single records template
making noncoding records file
Possible precedence issue with control flow operator at /home/goliath/miniconda3/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.
done making noncoding records
make the fasta sequences
Possible precedence issue with control flow operator at /home/goliath/miniconda3/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.
done making the fasta sequences
start siftsharp, getting the alignments
/mnt/DiscoA/sift4g_2/bin/sift4g -d /home/goliath/software/funannotate/uniprot_sprot.fasta -q /mnt/DiscoA/sift4g_2/scripts_to_build_SIFT_db/test_files/homo_sapiens_small/all_prot.fasta --subst /mnt/DiscoA/sift4g_2/scripts_to_build_SIFT_db/test_files/homo_sapiens_small/subst --out /mnt/DiscoA/sift4g_2/scripts_to_build_SIFT_db/test_files/homo_sapiens_small/SIFT_predictions --sub-results 
** Checking query data and substitutions files **
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
* processing database part 2 (size ~0.25 GB): 100.00/100.00% *

** Aligning queries with candidate sequences **
* processing database part 1 (size ~1.00 GB): 100.00/100.00% *

** Selecting alignments with median threshold: 2.75 **
* processing queries: 100.00/100.00% *

** Generating SIFT predictions with sequence identity: 100.00% **
* processing queries: 100.00/100.00% *

done getting all the scores
populating databases
checking the databases
zipping up /mnt/DiscoA/sift4g_2/scripts_to_build_SIFT_db/test_files/homo_sapiens_small/chr-src/*
All done!

```

As you can see, it seems it finishes, but I am not sure about the previous messages about the flow operators. Also, what are exactly the main outputs of this? The ones found in the GRCh38.83 folder?

Thanks in advance!",gubrins,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/86,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5xmYTE,No error message but nothing in results file,OPEN,2023-09-21T00:33:25Z,2023-09-25T22:13:47Z,,"I'm having this issue as well. I've updated my gcc (gcc (GCC) 10.3.0), reinstalled sift4g, and have made sure that I have loaded the updated gcc version before running, but it still does not create a results file.

Here is the command I'm running:
`perl make-SIFT-db-all.pl -config test_files/homo_sapiens-test.txt`

The homo_sapiens-test.txt file:
```
GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=./test_files/homo_sapiens_small
ORG=homo_sapiens
ORG_VERSION=GRCh38.83
DBSNP_VCF_FILE=Homo_sapiens.vcf.gz

#Running SIFT 4G
SIFT4G_PATH=/oak/stanford/groups/dpetrov/ksolari/SIFT/sift4g/bin/sift4g
PROTEIN_DB=/oak/stanford/groups/dpetrov/ksolari/SIFT/uniref90.fasta


# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord
```
The screen output:
```
converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
/oak/stanford/groups/dpetrov/ksolari/SIFT/sift4g/bin/sift4g -d /oak/stanford/groups/dpetrov/ksolari/SIFT/uniref90.fasta -q ./test_files/homo_sapiens_small/all_prot.fasta --subst ./test_files/homo_sapiens_small/subst --out ./test_files/homo_sapiens_small/SIFT_predictions --sub-results
** Checking query data and substitutions files **
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
```
contents of homo_sapiens_small output directory:
```
-rw-rw----+ 1 ksolari oak_dpetrov 362181 Sep 19 20:19 all_prot.fasta
drwxrws---+ 2 ksolari oak_dpetrov   4096 Sep 19 20:16 chr-src
drwxrws---+ 2 ksolari oak_dpetrov   4096 Sep 14 12:05 dbSNP
drwxrws---+ 2 ksolari oak_dpetrov  69632 Sep 18 11:09 fasta
-rw-rw----+ 1 ksolari oak_dpetrov     73 Sep 19 20:19 fasta.log
drwxrws---+ 2 ksolari oak_dpetrov   4096 Sep 18 10:16 gene-annotation-src
drwxrws---+ 2 ksolari oak_dpetrov   4096 Sep 18 10:16 GRCh38.83
-rw-rw----+ 1 ksolari oak_dpetrov  62026 Sep 19 20:19 invalid.log
-rw-rw----+ 1 ksolari oak_dpetrov      0 Sep 19 20:16 Log2.txt
-rw-rw----+ 1 ksolari oak_dpetrov 362434 Sep 19 20:19 peptide.log
drwxrws---+ 2 ksolari oak_dpetrov   4096 Sep 18 10:16 SIFT_alignments
drwxrws---+ 2 ksolari oak_dpetrov   4096 Sep 18 10:16 SIFT_predictions
drwxrws---+ 2 ksolari oak_dpetrov   4096 Sep 19 20:16 singleRecords
drwxrws---+ 2 ksolari oak_dpetrov   4096 Sep 18 10:16 singleRecords_with_scores
drwxrws---+ 2 ksolari oak_dpetrov 102400 Sep 18 11:09 subst
```
folder sizes:
```
4.0K	./SIFT_alignments
8.4G	./singleRecords
4.0K	./SIFT_predictions
4.0K	./singleRecords_with_scores
46M	./chr-src
4.0K	./GRCh38.83
3.4M	./fasta
25M	./dbSNP
21M	./subst
14M	./gene-annotation-src
8.5G	.
```

Any suggestions that anyone can offer will be much appreciated!
Thank you!!!

Katie",ksolari,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/87,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM5xpLE8,chr naming,CLOSED,2023-09-21T10:15:24Z,2023-09-21T10:32:50Z,2023-09-21T10:32:49Z,"@mb47

Please continue your issue here.",pauline-ng,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/88,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM57wTF6,error no such file or directory,CLOSED,2024-01-11T10:32:37Z,2024-01-11T12:36:34Z,2024-01-11T12:36:34Z,"I have read [this issue](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/79) as it is exactly the same problem but no matter how I changed the parent directory, it keeps throwing me ""No such file or directory"" error I am so frustrated. I hope anyone can let me know where I did wrong it has been two days of no luck. This is just trying to run the test files.

So the config file looks like this:
```
GENE_DOWNLOAD_SITE=ftp://ftp.ensemblgenomes.org/pub/bacteria/release-34/gtf//bacteria_11_collection/candidatus_carsonella_ruddii_pv/Candidatus_carsonella_ruddii_pv.ASM1036v1.34.gtf.gz
PEP_FILE=ftp://ftp.ensemblgenomes.org/pub/bacteria/release-34/fasta//bacteria_11_collection/candidatus_carsonella_ruddii_pv/pep/Candidatus_carsonella_ruddii_pv.ASM1036v1.pep.all.fa.gz
CHR_DOWNLOAD_SITE=ftp://ftp.ensemblgenomes.org/pub/bacteria/release-34/fasta//bacteria_11_collection/candidatus_carsonella_ruddii_pv/dna/

GENETIC_CODE_TABLE=11
GENETIC_CODE_TABLENAME=11
MITO_GENETIC_CODE_TABLE=0
MITO_GENETIC_CODE_TABLENAME=Unspecified

PARENT_DIR=/home/mdn487/db_test #prev: /bigdrive/SIFT_databases//candidatus_carsonella_ruddii_pv
ORG=candidatus_carsonella_ruddii_pv
ORG_VERSION=ASM1036v1.34


#Running SIFT 4G
SIFT4G_PATH=/home/mdn487/bin/sift4g/bin/sift4g

# protein database must be uncompressed
PROTEIN_DB=/maps/projects/bos/people/mdn487/pur_sel//SIFT4G_Create_Genomic_DB/uniprot_sprot.fasta #prev: /bigdrive/SIFT_databases/uniprot_sprot.fasta


# Sub-directories, don't need to change
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
FASTA_DIR=fasta
SUBST_DIR=subst
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords/
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord
```

And it looks like this when I ran the command.
![Screenshot 2024-01-11 at 11 26 18](https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/assets/28356594/7443da90-6c48-4b17-a19a-1583afd14ced)

Mind you that PARENT_DIR has been
```
/maps/projects/bos/people/mdn487/pur_sel//SIFT4G_Create_Genomic_DB/
/maps/projects/bos/people/mdn487/
```
And it still won't work.

`ls /home/mdn487` results in 
```
bin  db_test  ucph
```

So it has to be accessible for the program?

I am running out of ideas. Thanks in advance for everyone helping me!

",sagitaninta,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/90,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM6Aezs6,Problem with Creating Local Database,CLOSED,2024-02-27T03:11:03Z,2024-03-13T12:42:48Z,2024-03-13T12:42:48Z,"Hello, 

I have successfully created local databases and annotated the whole genome sequences of more than 50 species via SIFT4G. However, I encountered the following issues with four species. 

**1)** I am getting the ""Alignment score and position are not consensus"" error for one species.

* skipping protein [ rna-XM_016942145.3 ]: substitution list has a position out of bounds (line: M1064I, query length = 1063) *
* skipping protein [ rna-XM_054680350.1 ]: substitution list has a position out of bounds (line: T345T, query length = 344) *
* skipping protein [ rna-XM_054681160.1 ]: substitution list has a position out of bounds (line: E1093D, query length = 1092) *
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
* processing database part 337 (size ~0.25 GB): 100.00/100.00% *

** Aligning queries with candidate sequences **
Alignment score and position are not consensus.7.50/100.00% *

///////////////////////////////////////////////////////////////////////////////////////

**2)** For three species, the process of creating databases breaks without any error during the alignment: 

* skipping protein [ rna-XM_016925611.2 ]: substitution list has a position out of bounds (line: S176R, query length = 175) *
* skipping protein [ rna-XM_024345334.2 ]: substitution list has a position out of bounds (line: E348E, query length = 347) *
* skipping protein [ rna-XM_054681488.1 ]: substitution list has a position out of bounds (line: Q138Q, query length = 137) *
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
* processing database part 337 (size ~0.25 GB): 100.00/100.00% *

** Aligning queries with candidate sequences ** 


And here is the content of log file:

converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments

/////////////////////////////////////////////////////////////////////////////////////////////////

Any advice on these would be highly appreciated in advance!",VNF1981,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/91,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM6FcrIC,Reference genome,OPEN,2024-04-12T01:50:52Z,2024-04-12T05:49:13Z,,"Hi pauline-ng,
I have a question about using reference genome to build my SIFT database.
I have two species (SP1 and SP2, for example). SP1 has a reference genome, while SP2 does not. SNP calling for both species is based on SP1's genome.
My question is: can I use SP1's genome to build my SIFT database and then annotate VCF files for both species? Or should I only annotate SP1, while SP2 needs its own reference genome?
My aim is to compare the number of deleterious sites between the two species.
Maybe it's a very simple question. But I'm really confused as I don't understand the calculation theory well.
Thanks in advance for your attention and time.

Best,
Lu",liulu0827,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/92,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM6Gf0lt,cat: '/cluster/home/fanrong/perl5/scripts_to_build_SIFT_db/test_files/AK58V4MP/fasta/*.fasta': ,CLOSED,2024-04-22T13:03:11Z,2024-05-29T01:09:59Z,2024-05-29T01:09:59Z,"I have a question, how did the file in this error report get generated and what went wrong with my configuration?



(sift4G) perl make-SIFT-db-all.pl --config test_files/AK58V4MP.txt 
converting gene format to use-able input
Can't locate Switch.pm in @INC (you may need to install the Switch module) (@INC contains: /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/x86_64-linux-thread-multi /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0 /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/5.22.0/x86_64-linux-thread-multi /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/5.22.0 .) at gff_gene_format_to_ucsc.pl line 4.
BEGIN failed--compilation aborted at gff_gene_format_to_ucsc.pl line 4.
done converting gene format
making single records file
Possible precedence issue with control flow operator at /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.

------------- EXCEPTION -------------
MSG: Each line of the qual file must be less than 65,536 characters. Line 3 is 300037501 chars.
STACK Bio::DB::IndexedBase::_check_linelength /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:744
STACK Bio::DB::Fasta::_calculate_offsets /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/Fasta.pm:175
STACK Bio::DB::IndexedBase::_index_files /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:648
STACK Bio::DB::IndexedBase::index_dir /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:446
STACK Bio::DB::IndexedBase::new /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:361
STACK main::generateOutput make-single-records-BIOPERL.pl:147
STACK toplevel make-single-records-BIOPERL.pl:105
-------------------------------------

done making single records template
making noncoding records file
Possible precedence issue with control flow operator at /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.

------------- EXCEPTION -------------
MSG: Each line of the qual file must be less than 65,536 characters. Line 3 is 300037501 chars.
STACK Bio::DB::IndexedBase::_check_linelength /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:744
STACK Bio::DB::Fasta::_calculate_offsets /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/Fasta.pm:175
STACK Bio::DB::IndexedBase::_index_files /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:648
STACK Bio::DB::IndexedBase::index_dir /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:446
STACK Bio::DB::IndexedBase::new /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:361
STACK main::generateOutput make-single-records-noncoding.pl:62
STACK toplevel make-single-records-noncoding.pl:51
-------------------------------------

done making noncoding records
make the fasta sequences
Possible precedence issue with control flow operator at /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.

------------- EXCEPTION -------------
MSG: Each line of the qual file must be less than 65,536 characters. Line 3 is 300037501 chars.
STACK Bio::DB::IndexedBase::_check_linelength /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:744
STACK Bio::DB::Fasta::_calculate_offsets /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/Fasta.pm:175
STACK Bio::DB::IndexedBase::_index_files /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:648
STACK Bio::DB::IndexedBase::index_dir /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:446
STACK Bio::DB::IndexedBase::new /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:361
STACK main::generateOutput generate-fasta-subst-files-BIOPERL.pl:374
STACK toplevel generate-fasta-subst-files-BIOPERL.pl:178
-------------------------------------

done making the fasta sequences
start siftsharp, getting the alignments
cat: '/cluster/home/fanrong/perl5/scripts_to_build_SIFT_db/test_files/AK58V4MP/fasta/*.fasta': 
/cluster/home/fanrong/.conda/envs/sift4G/bin/sift4g -d /cluster/home/fanrong/perl5/scripts_to_build_SIFT_db/test_files/uniref90.fasta -q /cluster/home/fanrong/perl5/scripts_to_build_SIFT_db/test_files/AK58V4MP/all_prot.fasta --subst /cluster/home/fanrong/perl5/scripts_to_build_SIFT_db/test_files/AK58V4MP/subst --out /cluster/home/fanrong/perl5/scripts_to_build_SIFT_db/test_files/AK58V4MP/SIFT_predictions --sub-results 
** Checking query data and substitutions files **
",fan040,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/93,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM6KAHJR,"MSG: Each line of the qual file must be less than 65,536 characters. Line 3 is 604927368 chars. ",CLOSED,2024-05-24T12:25:12Z,2024-05-30T09:46:54Z,2024-05-30T09:46:54Z,"Hello, I would like to ask if the error here is caused by my genome is too large, about 14Gb, and I cannot build my own database.
""MSG: Each line of the qual file must be less than 65,536 characters. Line 3 is 604927368 chars. ""I suspect this is the cause of the errorI would like to ask how I should operate to solve this problem.

(sift4G) perl make-SIFT-db-all.pl -config test_files/AK58V4MP.txt 
converting gene format to use-able input
done converting gene format
making single records file
Possible precedence issue with control flow operator at /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.

------------- EXCEPTION -------------
STACK Bio::DB::IndexedBase::_check_linelength /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:744
STACK Bio::DB::Fasta::_calculate_offsets /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/Fasta.pm:175
STACK Bio::DB::IndexedBase::_index_files /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:648
STACK Bio::DB::IndexedBase::index_dir /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:446
STACK Bio::DB::IndexedBase::new /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:361
STACK main::generateOutput make-single-records-BIOPERL.pl:147
STACK toplevel make-single-records-BIOPERL.pl:105
-------------------------------------

done making single records template
making noncoding records file
Possible precedence issue with control flow operator at /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.

------------- EXCEPTION -------------
MSG: Each line of the qual file must be less than 65,536 characters. Line 3 is 604927368 chars.
STACK Bio::DB::IndexedBase::_check_linelength /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:744
STACK Bio::DB::Fasta::_calculate_offsets /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/Fasta.pm:175
STACK Bio::DB::IndexedBase::_index_files /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:648
STACK Bio::DB::IndexedBase::index_dir /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:446
STACK Bio::DB::IndexedBase::new /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:361
STACK main::generateOutput make-single-records-noncoding.pl:62
STACK toplevel make-single-records-noncoding.pl:51
-------------------------------------

done making noncoding records
make the fasta sequences
Possible precedence issue with control flow operator at /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.

------------- EXCEPTION -------------
MSG: Each line of the qual file must be less than 65,536 characters. Line 3 is 604927368 chars.
STACK Bio::DB::IndexedBase::_check_linelength /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:744
STACK Bio::DB::Fasta::_calculate_offsets /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/Fasta.pm:175
STACK Bio::DB::IndexedBase::_index_files /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:648
STACK Bio::DB::IndexedBase::index_dir /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:446
STACK Bio::DB::IndexedBase::new /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm:361
STACK main::generateOutput generate-fasta-subst-files-BIOPERL.pl:374
STACK toplevel generate-fasta-subst-files-BIOPERL.pl:178
-------------------------------------

done making the fasta sequences
start siftsharp, getting the alignments
cat: '/cluster/home/fanrong/perl5/scripts_to_build_SIFT_db/test_files/AK58V4MP/fasta/*.fasta': 
/cluster/home/fanrong/.conda/envs/sift4G/bin/sift4g -d /cluster/home/fanrong/perl5/scripts_to_build_SIFT_db/test_files/uniref90.fasta -q /cluster/home/fanrong/perl5/scripts_to_build_SIFT_db/test_files/AK58V4MP/all_prot.fasta --subst /cluster/home/fanrong/perl5/scripts_to_build_SIFT_db/test_files/AK58V4MP/subst --out /cluster/home/fanrong/perl5/scripts_to_build_SIFT_db/test_files/AK58V4MP/SIFT_predictions --sub-results 
** Checking query data and substitutions files **


** EXITING! No valid queries to process. **
",fan040,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/94,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM6KmFxp,Possible precedence issue with control flow operator at ,CLOSED,2024-05-30T09:51:20Z,2024-06-11T11:55:39Z,2024-06-11T11:55:39Z,"@pauline-ng Hi, i would like to ask which file of my error is wrong?Looking forward to your reply.

this is my prossess:
perl make-SIFT-db-all.pl -config test_files/AK58V4MP.txt 
converting gene format to use-able input
done converting gene format
making single records file
Possible precedence issue with control flow operator at /cluster/home/fanrong/.conda/envs/sift4G/lib/perl5/site_perl/5.22.0/Bio/DB/IndexedBase.pm line 791.
Use of uninitialized value $aa in string eq at make-single-records-BIOPERL.pl line 274.
Use of uninitialized value $aa in concatenation (.) or string at make-single-records-BIOPERL.pl line 280.
Use of uninitialized value $aa in string eq at make-single-records-BIOPERL.pl line 274.
Use of uninitialized value $aa in concatenation (.) or string at make-single-records-BIOPERL.pl line 280.
Use of uninitialized value $aa in string eq at make-single-records-BIOPERL.pl line 274.
Use of uninitialized value $aa in concatenation (.) or string at make-single-records-BIOPERL.pl line 280.
Use of uninitialized value $aa in string eq at make-single-records-BIOPERL.pl line 274.
Use of uninitialized value $aa in concatenation (.) or string at make-single-records-BIOPERL.pl line 280.
Use of uninitialized value $orig_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $mutated_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $orig_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $mutated_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $orig_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $mutated_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $orig_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $mutated_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $orig_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $mutated_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $orig_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $mutated_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $orig_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $mutated_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $orig_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value $mutated_aa in string eq at make-single-records-BIOPERL.pl line 551.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
",fan040,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/95,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM6OjMv9,Creating local database is always interrupted at aligning step,OPEN,2024-07-05T00:54:56Z,2024-08-04T13:15:18Z,,"Dear Pauline, 

I have been trying to use make-SIFT-db-all.pl to create a database. It all seems to be going well, and files are being created in the directories singleRecords, fasta and subst (the others are empty). However, I get an email saying the slurm job has failed. It says 'Exit code 255', usually after 11h-12h of run at the step of "" Aligning queries with candidate sequences "". Last time it advanced until: 

** Aligning queries with candidate sequences **
... processing database part 1 (size ~1.00 GB): 47.50/100.00% 

It doesn't seem to be a memory problem, as the jobs are using less memory than I requested. Any suggestion of what can happening?

Below is the config file I'm using. 

Thank you very much for your help!

Best wishes,
Clarissa-

--

GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial

PARENT_DIR=/n/holyscratch01/edwards_lab/cfcarvalho/Chiroxiphia/Antilophia/07.Non-synonymous/scripts_to_build_SIFT_db
ORG=chiroxiphia lanceolata
ORG_VERSION=bChiLan1
DBSNP_VCF_FILE=

SIFT4G_PATH=~/sift4g/bin/sift4g

PROTEIN_DB=/n/holyscratch01/edwards_lab/cfcarvalho/Chiroxiphia/Antilophia/07.Non-synonymous/scripts_to_build_SIFT_db/GCF_009829145.1/protein.faa

GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord",clavedec,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/96,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM6SHjWd,Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.,OPEN,2024-08-06T18:22:17Z,2024-08-07T16:54:06Z,,"Hello, My config contains the following lines:

```
GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=2
MITO_GENETIC_CODE_TABLENAME=Vertebrate Mitochondrial
PARENT_DIR=/home/Nicolas/SIFT
ORG=genus_species
ORG_VERSION=Species_v1.0
DBSNP_VCF_FILE=/home/Nicolas/SIFT/dbSNP/annotated_variants.vcf.gz
#Running SIFT4G, this path works for the Dockerfile
SIFT4G_PATH=/home/software/sift4g/bin/sift4g
#PROTEIN_DB needs to be uncompressed
PROTEIN_DB=/home/Nicolas/SNPEff/uniprot_sprot.fasta
```

Ive also created the following subdirectories within SIFT

```
mkdir chr-src #contains sequences.fa.gz
mkdir dbSNP #contains annotated_variants.vcf.gz
mkdir gene-annotation-src #contains genes.gtf.gz and protein.pep.all.fa.gz
```

I run the following commands:

```
docker run -it --user $(id -u):$(id -g) -v /home/Nicolas/SIFT:/home/Nicolas/SIFT sift4g_db /bin/bash

perl make-SIFT-db-all.pl -config /home/Nicolas/SIFT/Species_SIFT.config.txt
```

Following some initialized responses, I get these messages:

`Use of uninitialized value in concatenation (.) or string at make-single-records-BIOPERL.pl line 305.
`

My fasta folder remains empty along with my SIFT_prediction folder",NicMAlexandre,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/97,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM6SYVQF,Making database for soybean ends  without warning or error ,OPEN,2024-08-08T13:43:12Z,2024-08-08T13:43:12Z,,"Dear Author
I have encountered a problem 

** Searching database for candidate sequences **
processing database part 1 (size ~0.25 GB): 30.00/100.00%

Could you give me some suggestions and help?
Thank you very much.

best
Kwame",noobylf,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/98,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM6WYJyH,No valid queries to process using bacterial gtf to build database,OPEN,2024-09-12T16:59:54Z,2024-09-12T16:59:54Z,,"Hi Pauline,

I am trying to build a SIFT database for a strain of Neisseria gonorrhoeae that unfortunately is not present in EnsemblBacteria. I am using the gtf and chromosome files from the NCBI (from [here](https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/013/030/075/GCF_013030075.1_ASM1303007v1/)) but I keep running into the same error when trying to build the database. I've pasted the output below, but essentially when I look at the fasta.log file I get a message saying: ""0 out of 2283 translated to sequences that start with M and end with *"". 

I've manually checked and at least the first 2 sequences based on the gtf coordinates should work. I've double checked that the names match up between my chromosome file and my gtf file, I've double checked that they are using proper linux end of line characters, and I've made sure that my chromosome file is uncompressed and my gtf file is gzipped. 

I've looked through any issues here I can find that look similar, one suggested adding in an exon line since NCBI gtfs don't have an exon tag, I tried that as well and no luck. I am deleting all of the generated files in the directory between each try. I am able to run both of the test cases without issues, so I think this must be some kind of file compatibility issue?

Thanks,
Duncan

Config File:
```
GENETIC_CODE_TABLE=11
GENETIC_CODE_TABLENAME=11

PARENT_DIR=/scratch/j/jparkin/dcarru/ngo_WGS/IPNC/SIFT/ngo_sift_db
ORG=Neisseria gonorrhoeae
ORG_VERSION=ASM1303007v1

#Running SIFT4G, this path works for the Dockerfile
SIFT4G_PATH=/home/j/jparkin/dcarru/ngo_WGS/IPNC_data/SIFT/sift4g/bin/sift4g

#PROTEIN_DB needs to be uncompressed
PROTEIN_DB=/scratch/j/jparkin/dcarru/ngo_WGS/IPNC/SIFT/prot_db/uniref90.fasta


# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord
```
Output
```
converting gene format to use-able input
done converting gene format
making single records file
done making single records template
making noncoding records file
done making noncoding records
make the fasta sequences
done making the fasta sequences
start siftsharp, getting the alignments
cat: '/scratch/j/jparkin/dcarru/ngo_WGS/IPNC/SIFT/ngo_sift_db/fasta/*.fasta': No such file or directory
/home/j/jparkin/dcarru/ngo_WGS/IPNC_data/SIFT/sift4g/bin/sift4g -d /scratch/j/jparkin/dcarru/ngo_WGS/IPNC/SIFT/prot_db/uniref90.fasta -q /scratch/j/jparkin/dcarru/ngo_WGS/IPNC/SIFT/ngo_sift_db/all_prot.fasta --subst /scratch/j/jparkin/dcarru/ngo_WGS/IPNC/SIFT/ngo_sift_db/subst --out /scratch/j/jparkin/dcarru/ngo_WGS/IPNC/SIFT/ngo_sift_db/SIFT_predictions --sub-results
** Checking query data and substitutions files **


** EXITING! No valid queries to process. **
```
",dcarru01,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/99,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM6c3mXw,Pos with confident scores < 90%,OPEN,2024-11-04T04:41:59Z,2024-11-04T04:45:11Z,,"Hi Pauline,

Thank you for this resource to format SIFT4G databases. I'm attempting to create the human database using a recent ensembl release (GRCh38, v112). However, the `Pos with Confident Scores` are less than 90%. Following are the scores reported in `CHECK_GENES.LOG`

```
Chr	Genes with SIFT Scores	Pos with SIFT scores	Pos with Confident Scores
1	99 (9132/9191)	100 (27011926/27017955)	60(16255845/27011926)
10	100 (3666/3684)	100 (11267510/11269164)	57(6400632/11267510)
11	99 (6405/6443)	100 (16547144/16551938)	62(10293209/16547144)
12	99 (5430/5477)	100 (14496123/14500831)	58(8410615/14496123)
13	99 (1429/1437)	100 (5072825/5073770)	56(2837065/5072825)
14	99 (3503/3534)	100 (9893613/9896637)	59(5808266/9893613)
15	99 (3169/3208)	100 (9013810/9017834)	57(5160516/9013810)
16	99 (4712/4759)	100 (11385585/11391294)	68(7698045/11385585)
17	99 (6336/6392)	100 (16183935/16189331)	59(9623114/16183935)
18	99 (1612/1636)	100 (4666645/4669378)	57(2671224/4666645)
19	100 (6647/6680)	100 (16347154/16351116)	67(10939216/16347154)
2	99 (6645/6685)	100 (22971896/22975822)	52(12033057/22971896)
20	99 (2350/2367)	100 (6197276/6198167)	61(3764631/6197276)
21	99 (932/943)	100 (2792386/2793817)	63(1768235/2792386)
22	99 (2035/2046)	100 (5501794/5504166)	62(3400959/5501794)
3	99 (6155/6190)	100 (18213229/18216986)	57(10345147/18213229)
4	100 (3845/3863)	100 (12160063/12161965)	55(6718884/12160063)
5	99 (4223/4255)	100 (11855241/11858302)	60(7125778/11855241)
6	100 (4611/4634)	100 (13653872/13656835)	62(8426507/13653872)
7	100 (4469/4483)	100 (13028052/13029448)	57(7439183/13028052)
8	99 (3580/3608)	100 (9393778/9400870)	59(5582444/9393778)
9	99 (3434/3452)	100 (11081037/11082543)	63(6945343/11081037)
GL000009.2	100 (1/1)	100 (490/490)	0(0/490)
GL000194.1	100 (2/2)	100 (1665/1665)	57(956/1665)
GL000195.1	100 (1/1)	100 (769/769)	0(0/769)
GL000205.2	0 (0/0)	0 (0/0)	0(0/0)
GL000213.1	100 (2/2)	100 (6519/6519)	74(4813/6519)
GL000216.2	0 (0/0)	0 (0/0)	0(0/0)
GL000218.1	100 (1/1)	100 (1542/1542)	0(0/1542)
GL000219.1	100 (1/1)	100 (843/843)	81(687/843)
GL000220.1	0 (0/0)	0 (0/0)	0(0/0)
GL000225.1	0 (0/0)	0 (0/0)	0(0/0)
KI270442.1	0 (0/0)	0 (0/0)	0(0/0)
KI270711.1	100 (2/2)	100 (8394/8394)	80(6736/8394)
KI270713.1	100 (2/2)	100 (2225/2225)	0(0/2225)
KI270721.1	100 (1/1)	100 (1010/1010)	100(1010/1010)
KI270726.1	100 (2/2)	100 (1382/1382)	0(0/1382)
KI270727.1	100 (4/4)	100 (10658/10658)	85(9024/10658)
KI270728.1	100 (5/5)	100 (9606/9606)	0(0/9606)
KI270731.1	100 (1/1)	100 (2748/2748)	65(1782/2748)
KI270733.1	0 (0/0)	0 (0/0)	0(0/0)
KI270734.1	100 (4/4)	100 (11308/11308)	62(7033/11308)
KI270744.1	0 (0/0)	0 (0/0)	0(0/0)
KI270750.1	0 (0/0)	0 (0/0)	0(0/0)
MT	100 (7/7)	100 (12241/12241)	18(2147/12241)
X	100 (3611/3624)	100 (10755922/10757378)	59(6342125/10755922)
Y	98 (189/193)	100 (617316/617680)	48(295900/617316)

ALL	99 (98156/98820)	100 (280179532/280254627)	59(166320128/280179532)
```

`grep "">"" all_prot.fasta | wc -l   ##returns 98732`

[Uniref90](https://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref90/uniref90.fasta.gz) was utilized for the database creation. 



May I check if the human database is created okay? 

Secondly, I'm unable to load the [SIFT4G databases](https://sift.bii.a-star.edu.sg/sift4g/) to counter-check. Wondering if there's any issues with the web-site? 


Thank you very much for your advice and time. :)
",mmlian,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/100,pauline-ng++SIFT4G_Create_Genomic_DB.csv
I_kwDOBKAFmM6dK3RM,Making database for sugarcane ends without warning or error,OPEN,2024-11-06T02:20:32Z,2024-11-06T02:20:32Z,,"Hi Pauline,
      When I used SIFT4G_Create_Genomic_DB to create the sugarcane database, I encountered a problem. While creating databases for each chromosome in sugarcane, some chromosomes successfully created databases, but others did not. There were no warning or error messages for the failures. I don't know why this is happening. Here are the outputs when the process succeeded and failed:
the succeeded output message

** Checking query data and substitutions files **
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
* processing database part 364 (size ~0.25 GB): 100.00/100.00% *

** Aligning queries with candidate sequences **
* processing database part 91 (size ~1.00 GB): 100.00/100.00% *

** Selecting alignments with median threshold: 2.75 **
* processing queries: 100.00/100.00% *

** Generating SIFT predictions with sequence identity: 100.00% **
* processing queries: 100.00/100.00% *

the failed output message:

** Checking query data and substitutions files **
* processing queries: 100.00/100.00% *

** Searching database for candidate sequences **
* processing database part 364 (size ~0.25 GB): 100.00/100.00% *

Uniref90 was utilized for the database creation.
The config file:

GENETIC_CODE_TABLE=1
GENETIC_CODE_TABLENAME=Standard
MITO_GENETIC_CODE_TABLE=11
MITO_GENETIC_CODE_TABLENAME=Plant Plastid Code

PARENT_DIR=/xtdisk/apod/xiehx/Deleterious_variants/SIFT/Saccharum/SIFT_Database/Chr8D
ORG=Saccharum_spontaneum
ORG_VERSION=Np-X

#Running SIFT 4G
SIFT4G_PATH=/gpfs/biosoft/app2/python2024/envs/sift4g/bin/sift4g
PROTEIN_DB=/xtdisk/apod/xiehx/Deleterious_variants/SIFT/Saccharum/SIFT_Database/config/uniref90.fasta


# Sub-directories, don't need to change
GENE_DOWNLOAD_DEST=gene-annotation-src
CHR_DOWNLOAD_DEST=chr-src
LOGFILE=Log.txt
ZLOGFILE=Log2.txt
FASTA_DIR=fasta
SUBST_DIR=subst
ALIGN_DIR=SIFT_alignments
SIFT_SCORE_DIR=SIFT_predictions
SINGLE_REC_BY_CHR_DIR=singleRecords
SINGLE_REC_WITH_SIFTSCORE_DIR=singleRecords_with_scores
DBSNP_DIR=dbSNP

# Doesn't need to change
FASTA_LOG=fasta.log
INVALID_LOG=invalid.log
PEPTIDE_LOG=peptide.log
ENS_PATTERN=ENS
SINGLE_RECORD_PATTERN=:change:_aa1valid_dbsnp.singleRecord

Could you give me some suggestions and help?
Thank you very much for your advice and time!",Windyxia11,https://github.com/pauline-ng/SIFT4G_Create_Genomic_DB/issues/101,pauline-ng++SIFT4G_Create_Genomic_DB.csv
MDU6SXNzdWUzNjUxNzg1MTg=,Confirm that use of BLAST's `-max_target_seqs` is intentional,CLOSED,2018-09-30T00:29:43Z,2018-10-01T07:51:15Z,2018-10-01T07:51:15Z,"Hi there,

This is a semi-automated message from a fellow bioinformatician. Through a GitHub search, I found that the following source files make use of BLAST's `-max_target_seqs` parameter: 

- [R.padi_contaimination_filtering/clc_assembly.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/R.padi_contaimination_filtering/clc_assembly.sh)
- [R.padi_contaimination_filtering/clc_assembly_v5.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/R.padi_contaimination_filtering/clc_assembly_v5.sh)
- [RNAseq_analysis/Annotating_transcriptome/Rp_annotate.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/RNAseq_analysis/Annotating_transcriptome/Rp_annotate.sh)
- [R.padi_contaimination_filtering/clc_assembly_v2.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/R.padi_contaimination_filtering/clc_assembly_v2.sh)
- [R.padi_contaimination_filtering/clc_assembly_v3.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/R.padi_contaimination_filtering/clc_assembly_v3.sh)
- [R.padi_contaimination_filtering/clc_assembly_v4.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/R.padi_contaimination_filtering/clc_assembly_v4.sh)
- [R.padi_contaimination_filtering/clc_mapper.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/R.padi_contaimination_filtering/clc_mapper.sh)

Based on the recently published report, [Misunderstood parameter of NCBI BLAST impacts the correctness of bioinformatics workflows](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/bty833/5106166?redirectedFrom=fulltext), there is a strong chance that this parameter is misused in your repository.

If the use of this parameter was intentional, please feel free to ignore and close this issue but I would highly recommend to add a comment to your source code to notify others about this use case. If this is a duplicate issue, please accept my apologies for the redundancy as this simple automation is not smart enough to identify such issues.

Thank you!
-- Arman ([armish/blast-patrol](https://github.com/armish/blast-patrol))",armish,https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/issues/1,peterthorpe5++Methods_M.cerasi_R.padi_genome_assembly.csv
I_kwDOICa2K85xMStM,about liftover file,OPEN,2023-09-15T20:34:43Z,2023-09-15T20:34:43Z,,"Hi,
I am here to get blacklist file of rats, and I found that it's little bit different from what I made. I downloaded blacklist file of mm10 from here (https://github.com/Boyle-Lab/Blacklist/tree/master/lists) and uploaded it to https://genome.ucsc.edu/cgi-bin/hgLiftOver. What would be the difference between yours and what I made? Could you tell me your opinions please?",distilledchild,https://github.com/pfenninglab/custom_ArchR_genomes_and_annotations/issues/1,pfenninglab++custom_ArchR_genomes_and_annotations.csv
I_kwDOFeaGwM5S2fI0,TODO List,OPEN,2022-09-28T22:31:04Z,2023-02-14T05:29:36Z,,"- [x] Examine if the raw data can be downloaded directly from google drive to Ceres
- [x] Download and keep the raw data in Ceres. Google drive is preventing too many API downloads
- [x] Rearrange the files and folders in this repository
- [x] Create appropriate Dockerfiles and CWL tool scripts for reproducibility
    - [x] Create CWL tool script for the following general software: 
        - [x] gdrive
        - [x] samtools
        - [x] STAR
        - [x] bowtie2
        - [x] FGMP
    - [x] Genome assemblers
        - [x] masurca (http://www.genome.umd.edu/masurca.html)
        - [x] Megahit
        - [x] SOAPdenovo2
        - [x] ABySS 2.0 (https://genome.cshlp.org/content/27/5/768)
    - [x] Scaffolders
        - [x] Rascaf (file:///Users/gsfuerst/Downloads/tpg-9-3-plantgenome2016.03.0027.pdf) [Uses RNA-Seq reads]
        - [x] P_RNA_scaffolder (https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864.-018-4567-3?optIn=false)
        - [x] Create a wrapper for Rascaf to process from the tar.gz generated by ABySS
        - [x] Create a wrapper for P_RNA_scaffolder to process from the .tar.gz generated by ABySS
        - [x] Verify each scaffolder with dummy data
- [ ] Create the following workflows
  - [ ] Assemble reads into a draft assembly using multiple assemblers
  - [ ] Write CWL script for scaffolding the assembled reads
  - [ ] Merge assemblies, scaffolds, verification with FGMP and STAR alignments
- [x] Check the output generated by each assembler and name them properly to reflect the correct assembler and the parameters used to generate those. Repeat the same for scaffolders as well
- [x] Write a python script to read the outputs generated by STAR mapping and FGMP. Compile it into a single report
- [x] Write up a script to map denovo transcripts to corresponding genomic references. Also, use the stringtie transcriptome to detect genes/transcripts that could be elongated in this way.
- [ ] Add localizer, effectorP, signalP & BLASTp for functional analysis


",sagnikbanerjee15,https://github.com/sagnikbanerjee15/fungal_genome_assemblies_and_annotation/issues/1,sagnikbanerjee15++fungal_genome_assemblies_and_annotation.csv
MDU6SXNzdWUzMzcyMzAwMA==,exonerate_to_JBGFF3.rb parser bug,CLOSED,2014-05-17T04:15:47Z,2014-05-17T04:31:24Z,2014-05-17T04:31:24Z,"exonerate_to_JBGFF3.rb cannot parse exonerate output correctly.
",shujishigenobu,https://github.com/shujishigenobu/genome_annot/issues/1,shujishigenobu++genome_annot.csv
MDU6SXNzdWU1MTA2NDY0OA==,util/id_convert ?,OPEN,2014-12-05T05:24:49Z,2014-12-05T05:24:49Z,,"util/id_convert should be moved to 'converters' or other relevant directory.
",shujishigenobu,https://github.com/shujishigenobu/genome_annot/issues/2,shujishigenobu++genome_annot.csv
MDU6SXNzdWU1NTQzMjM3OA==,refact blast6_to_jbgff.rb,OPEN,2015-01-25T22:05:50Z,2015-01-25T22:05:50Z,,"blast6_to_jbgff.rb needs to be refactoring
",shujishigenobu,https://github.com/shujishigenobu/genome_annot/issues/3,shujishigenobu++genome_annot.csv
MDU6SXNzdWU2MzUxMzI5Mw==,refact: genemodel_revise_CjOR,OPEN,2015-03-22T09:16:55Z,2015-03-22T09:16:55Z,,"refact: tasks/genemodel_revise_CjOR
many ad hoc scripts remain
",shujishigenobu,https://github.com/shujishigenobu/genome_annot/issues/4,shujishigenobu++genome_annot.csv
MDU6SXNzdWUzMzM5MjUzMTc=,app/pilon want new utility script to count updated bases,OPEN,2018-06-20T05:04:47Z,2018-06-20T05:04:47Z,,"reading log file

grep ""^Corrected"" run_pilon_logs/run_pilon_MAO.job108.sh.o205203",shujishigenobu,https://github.com/shujishigenobu/genome_annot/issues/5,shujishigenobu++genome_annot.csv
MDU6SXNzdWUzNjUxNzkwMjM=,Confirm that use of BLAST's `-max_target_seqs` is intentional,OPEN,2018-09-30T00:39:07Z,2018-09-30T00:39:07Z,,"Hi there,

This is a semi-automated message from a fellow bioinformatician. Through a GitHub search, I found that the following source files make use of BLAST's `-max_target_seqs` parameter: 

- [tasks/rRNA_identification/run_megablast_SSU.sh](https://github.com/shujishigenobu/genome_annot/blob/cd18bd3d9cfb994a903d7fe391db2dca0c38f99d/tasks/rRNA_identification/run_megablast_SSU.sh)
- [util/gene_prediction_performance_evaluation/run_blastp.sh](https://github.com/shujishigenobu/genome_annot/blob/cd18bd3d9cfb994a903d7fe391db2dca0c38f99d/util/gene_prediction_performance_evaluation/run_blastp.sh)

Based on the recently published report, [Misunderstood parameter of NCBI BLAST impacts the correctness of bioinformatics workflows](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/bty833/5106166?redirectedFrom=fulltext), there is a strong chance that this parameter is misused in your repository.

If the use of this parameter was intentional, please feel free to ignore and close this issue but I would highly recommend to add a comment to your source code to notify others about this use case. If this is a duplicate issue, please accept my apologies for the redundancy as this simple automation is not smart enough to identify such issues.

Thank you!
-- Arman ([armish/blast-patrol](https://github.com/armish/blast-patrol))",armish,https://github.com/shujishigenobu/genome_annot/issues/6,shujishigenobu++genome_annot.csv
MDU6SXNzdWU4MjMwOTA0NDk=,how to assemble genomes with four fasta files?,CLOSED,2021-03-05T13:33:11Z,2021-03-05T19:44:37Z,2021-03-05T19:44:37Z,"HI @StephenFordham 
Very nice toolbox. Could I ask one question about the input for the genome assembly? Here, for one strain, we have four fasta files? Could we still use your nice toolbox?

<img width=""383"" alt=""Screenshot 2021-03-05 at 14 30 07"" src=""https://user-images.githubusercontent.com/31989005/110122110-7def6a80-7dbf-11eb-85e6-b765b6744db6.png"">

Thanks a lot!

Best regards,
Hongzhong",hongzhonglu,https://github.com/StephenFordham/BacGenomePipeline/issues/1,StephenFordham++BacGenomePipeline.csv
MDU6SXNzdWU4MTczNzIxNzk=,Repo contains pathnames to tsl directories,OPEN,2021-02-26T13:49:34Z,2021-02-26T13:49:34Z,,"Its probably best that explicit TSL HPC pathnames are not exposed on the public github. Please consider making this information accessible only within TSL.
",danmaclean,https://github.com/TeamMacLean/snpEff_add_genome_to_database/issues/1,TeamMacLean++snpEff_add_genome_to_database.csv
MDU6SXNzdWUzNDQ2MDI2MjQ=,Create NCBI compatible mapping dictionary,OPEN,2018-07-25T20:52:00Z,2018-07-25T20:53:37Z,,This is Gary's,olsonanl,https://github.com/TheSEED/genome_annotation/issues/2,TheSEED++genome_annotation.csv
MDU6SXNzdWUzNDQ2MDQ4NTk=,Fix partial protein on export to genbank,OPEN,2018-07-25T20:58:53Z,2018-07-25T20:59:05Z,,"To enable NCBI validation, we need to properly emit partial genes in the genbank file to eliminate these diagnostics:

```
ERROR: valid [SEQ_FEAT.NoStop] Missing stop codon FEATURE: CDS: hypothetical protein [lcl|NODE_8594_length_67_cov_14.75:c67-2] [lcl|NODE_8594_length_67_cov_14.75: raw, dna len= 67] -> [gnl|BPROD|BOB_13123]
ERROR: valid [SEQ_INST.BadProteinStart] gap symbol at start of protein sequence (BOB_13123 - hypothetical protein) BIOSEQ: gnl|BPROD|BOB_13123: raw, aa len= 22
```",olsonanl,https://github.com/TheSEED/genome_annotation/issues/3,TheSEED++genome_annotation.csv
MDU6SXNzdWUzNDQ2MDcyMTY=,Install p3x-eval-genomes,OPEN,2018-07-25T21:06:15Z,2018-07-25T21:06:15Z,,Remove checkm and simplify pipeline,olsonanl,https://github.com/TheSEED/genome_annotation/issues/4,TheSEED++genome_annotation.csv
MDU6SXNzdWUzNDQ2MDc1NzM=,Normalize binning pipeline,OPEN,2018-07-25T21:07:29Z,2018-07-25T21:07:29Z,,Make binning pipeline in PATRIC use the new wrapper-job mechanism as used in the CGA pipeline,olsonanl,https://github.com/TheSEED/genome_annotation/issues/5,TheSEED++genome_annotation.csv
MDU6SXNzdWUyMzM2NDQzNTE=,progress display,CLOSED,2017-06-05T16:39:26Z,2017-06-06T16:19:30Z,2017-06-06T16:19:30Z,"It would be useful to have the percentage progress displayed while the job is running, particularly for large jobs!",greglv93,https://github.com/UCLOrengoGroup/cath-tools-genomescan/issues/1,UCLOrengoGroup++cath-tools-genomescan.csv
MDU6SXNzdWUyNDU3MTkwMTg=,explain difference between conditional/independent evalue,CLOSED,2017-07-26T13:18:11Z,2019-02-26T15:44:40Z,2019-02-26T15:44:40Z,,sillitoe,https://github.com/UCLOrengoGroup/cath-tools-genomescan/issues/6,UCLOrengoGroup++cath-tools-genomescan.csv
MDU6SXNzdWUyNDU3MjA2Mzg=,get cath-resolve-hits compiling on Mac,CLOSED,2017-07-26T13:23:44Z,2017-07-31T11:58:10Z,2017-07-31T11:58:10Z,,sillitoe,https://github.com/UCLOrengoGroup/cath-tools-genomescan/issues/7,UCLOrengoGroup++cath-tools-genomescan.csv
MDU6SXNzdWUyNDU3MjM3OTQ=,add domain hmm library as well as funfams,OPEN,2017-07-26T13:34:14Z,2017-07-26T13:34:14Z,,,sillitoe,https://github.com/UCLOrengoGroup/cath-tools-genomescan/issues/8,UCLOrengoGroup++cath-tools-genomescan.csv
MDU6SXNzdWU0MjUyNTk2OTE=,Improving efficiency by setting hmmsearch --cpu 1 and running cath-genomescan.pl in parallel,CLOSED,2019-03-26T07:14:04Z,2019-03-29T14:49:29Z,2019-03-29T14:49:29Z,"Hello, 

Thank you so much for cath-tools-genomescan, I've found it very useful so far.  

I was running `cath-genomscan.pl` on all of the genes predicted in my metagenome samples. It was taking quite a while, mostly due to `hmmsearch`, which despite the default behavior to use all available cpus usually only uses a few.  I wanted to figure out how to parallelize it and came up with this strategy. 

1) added an argument to `hmmsearch` in `cath-genomescan.pl` to only use 1 cpu (`'--cpu 1'`)
2) split my amino acid fasta files into the number of cpus I wanted to use (in this case 48)
3) wrote the `cath-genomescan.pl` commands for each of the sub files to a text file
4) submitted that text file to be run in parallel (cpus=48)

This seemed to work pretty well and got the results I was looking for very quickly.  I of course had to clean up some intermediate files and parse/aggregate the results into single files.  I figured I'd share the strategy.  Not sure how easily it can be implemented for `cath-genomescan.pl`, but at least providing an argument to set the number of cpus used by `hmmsearch` could be helpful.  

Here is the nasty bash code I used inside a loop over my directories.  Tried to clean up a little to make it easier to read.
```
#get the headers from the faa file 
      grep ""^>"" min1000_faa > min1000_faa_headers.txt
#split into 48 chunks
      split --number=l/48 min1000_faa_headers.txt --additional-suffix=_headers_split
#remove the leading "">"" from the headers 
      sed -i 's/>//g' *_headers_split
#for each of the header chunks 
      for i in *_headers_split;
      do
#use pullseq to get the aa sequences for each chunk (https://github.com/bcthomas/pullseq)
        pullseq -i $min1000_faa -n $i > $i.faa
#append the cath-genomescan.pl command for that chunk to a text file
        echo ""/path/to/cath-tools-genomescan/apps/cath-genomescan.pl -i $PWD/$i.faa -l path/to/cath-tools-genomescan/data/funfam-hmm3.lib -o $PWD/$i.faa.out"" >> cath_genomescan_cluster_commands.txt
      done
#now send the cath-genomescan.pl commands to parallel with 48 cpus and pipe to qsub to submit to the cluster 
echo ""parallel -j48 < $PWD/cath_genomescan_cluster_commands.txt"" | qsub -V -N cath_${sample}
```

Cheers, 
Alex",alexdthomas,https://github.com/UCLOrengoGroup/cath-tools-genomescan/issues/12,UCLOrengoGroup++cath-tools-genomescan.csv
MDU6SXNzdWU0MjYyNDY4OTA=,retrieve_FunFam_aln_GO_anno_CATH-API.pl: No such file or directory,CLOSED,2019-03-28T01:02:25Z,2019-04-02T12:02:12Z,2019-04-02T12:02:11Z,"Hello again, 

Following the example here (https://github.com/UCLOrengoGroup/cath-tools-genomescan) to get the EC numbers and GO terms for a CATH FunFam model. With the test data, when I run `./apps/retrieve_FunFam_aln_GO_anno_CATH-API.pl 2.40.50.140/FF/58874 v4_1_0` in my project directory I get the following error `-bash: ./apps/retrieve_FunFam_aln_GO_anno_CATH-API.pl: No such file or directory`. 

Looking at `retrieve_FunFam_aln_GO_anno_CATH-API.pl` this makes sense, since on line 34 it seems to have a 'results' directory hardcoded to be in the parent directory of the current directory.  It also seems to be looking for `*.sto.aln` and `*.GO.anno` files there that I can't figure out where they would have been produced.  

On line 42 it does seem to construct a correct url to download the stockholm alignment file for the given FunFam and this file does contain the EC and GO metadata (as well as other useful information).  

As I have run `cath-genomescan.pl` on all of the proteins predicted in my metagenome, it seemed very inefficient for me and the CATH API server to query the server for the redundant set of CATH FunFams, so I generated a non-redundant list and downloaded all of the stockholm files for those.  I've been working on parsing out the metadata I am interested in, but keep hitting little text formatting and things I wasn't expecting...

Maybe I'm just incapable of finding it, but Is here is a table somewhere on the FTP (ftp://orengoftp.biochem.ucl.ac.uk/cath/releases/latest-release/) that has the CATH superfamily IDs, FunFam IDs, and associated ECs and GOs (maybe even accessions, definitions, descriptions, but that could be a bit much...)?  It would be really useful for users and might save some unnecessary traffic downloading thousands of alignments just to get the metadata.  I noticed in several publications (DOI 10.1093/nar/gkv488, 10.1093/bioinformatics/btv398) that the ability to connect FunFams to ECs is a feature of the FunFams, I've just had a hard time doing it efficiently and programmatically.  

Thanks, 
Alex",alexdthomas,https://github.com/UCLOrengoGroup/cath-tools-genomescan/issues/13,UCLOrengoGroup++cath-tools-genomescan.csv
MDU6SXNzdWU1MzkwOTAwNDc=,improve handling of discontinuous domains ,CLOSED,2019-12-17T14:10:24Z,2019-12-17T14:29:53Z,2019-12-17T14:29:53Z,"See discussion here:

https://github.com/UCLOrengoGroup/cath-tools/issues/71


",sillitoe,https://github.com/UCLOrengoGroup/cath-tools-genomescan/issues/15,UCLOrengoGroup++cath-tools-genomescan.csv
MDU6SXNzdWU2MzYxNzI5MzA=,Add snakemake pipeline,OPEN,2020-06-10T11:34:22Z,2020-06-10T11:34:22Z,,"We want to encapsulate the process of scanning sequences against FunFam HMMs into a simple workflow, eg [snakemake](https://snakemake.readthedocs.io/en/stable/).

Steps:
1. clone repo
1. create new branch
1. create directory with snakemake pipeline
1. add / change documention
1. create pull request (PR) of your new branch against master
1. code review
1. merge to master
",sillitoe,https://github.com/UCLOrengoGroup/cath-tools-genomescan/issues/16,UCLOrengoGroup++cath-tools-genomescan.csv
MDU6SXNzdWU2MzY5NjI1MjY=,Can't connect to www.cathdb.info:80,OPEN,2020-06-11T12:10:47Z,2020-06-11T17:53:52Z,,"Hi,

Apparently from my cluster I cannot reach the web to retrive GO terms:

`500 Can't connect to www.cathdb.info:80 (Temporary failure in name resolution) at /mnt/storage/home/tk19812/scratch/software/cath-tools-genomescan/apps/retrieve_FunFam_aln_GO_EC_anno_CATH-API.pl line 66.`

Would be possible to download the database? of is it too large?

Thanks a lot
Francesco",francicco,https://github.com/UCLOrengoGroup/cath-tools-genomescan/issues/17,UCLOrengoGroup++cath-tools-genomescan.csv
MDU6SXNzdWU4NDA2MzM4MTQ=,Funfams database compatibility problem with hmmsearch,OPEN,2021-03-25T07:11:38Z,2021-09-23T15:26:51Z,,"Hi,

While i can resolve this issue for myself, i'd like to point out that the hmmsearch part of the pipeline doesn't work with the latest funfams database. The first line is incompatible with hmmsearch. I refer to funfams in my protein function prediction pipeline and it would be great if i can direct users directly to your download of the latest funfams without adding an extra step in the installation process. I fixed it by just replacing the funfams v4.3 header with that of v4.2.

Kind regards,

Maarten",mreijnders,https://github.com/UCLOrengoGroup/cath-tools-genomescan/issues/18,UCLOrengoGroup++cath-tools-genomescan.csv
I_kwDOBWbuuM4-zLnQ,GO annotation,OPEN,2021-11-15T12:21:39Z,2021-11-15T12:21:39Z,,"Hi,

Do all the GO terms listed in the GO annotation file belong to the query gene?
Or do I have to select one among the lines listed in the file?

Cheers
F
",francicco,https://github.com/UCLOrengoGroup/cath-tools-genomescan/issues/19,UCLOrengoGroup++cath-tools-genomescan.csv
I_kwDOBWbuuM6FUjZ2,Error encountered when running Cath-resolve-hits.macos,OPEN,2024-04-11T01:48:33Z,2024-04-11T01:48:33Z,,"Hi,

I have set up the environment index the library and trying to run a the genomescan with test fast file.
Things look fine till there is an error says ! Error: encountered an error when running command /Users/kunmiao/myproject/apps/../bin/cath-resolve-hits.macos. 

Followed by STDERR: Can't exec ""/Users/kunmiao/myproject/apps/../bin/cath-resolve-hits.macos"": Permission denied at ./apps/cath-genomescan.pl line 172.

can you comment on this? (BTW I installed a macOS version of HMMER. Could that be causing the problem?)

Thanks,
House",housemiao,https://github.com/UCLOrengoGroup/cath-tools-genomescan/issues/20,UCLOrengoGroup++cath-tools-genomescan.csv
I_kwDOIjOq9c5hgoSw,Has this been compared with geta ,CLOSED,2023-03-22T14:59:38Z,2023-03-24T01:28:41Z,2023-03-24T01:28:41Z,"Hello, author. Is there any difference between this annotation process and geta? https://github.com/chenlianfu/getaHave you made a comparison?
Do you suggest that I continue to run EVM to integrate this result, so what should its score be set relative to PASA's result?",zhangwenda0518,https://github.com/unavailable-2374/Genome-Wide-Annotation-Pipeline/issues/1,unavailable-2374++Genome-Wide-Annotation-Pipeline.csv
I_kwDOIjOq9c6Xqm-c,failed to execute: srun ,OPEN,2024-09-24T07:02:46Z,2024-10-02T01:17:31Z,,"Thank you for your integrated annotation process.

 I encountered the following error during the annotation process. I used conda to install slrum on the server, but I still get an error. Can I use other code or software to replace the srun command?
```srun --mpi=pmi2 maker -base VP -fix_nucleotides new.ctl maker_bopts.ctl maker_exe.ctl```
``` srun --mpi=pmi2 maker -base VP -fix_nucleotides new.ctl maker_bopts.ctl maker_exe.ctl
srun: error: resolve_ctls_from_dns_srv: res_nsearch error: Unknown host
srun: error: fetch_config: DNS SRV lookup failed
srun: error: _establish_config_source: failed to fetch config
srun: fatal: Could not establish a configuration source
```
Best regards.
",sip123a,https://github.com/unavailable-2374/Genome-Wide-Annotation-Pipeline/issues/2,unavailable-2374++Genome-Wide-Annotation-Pipeline.csv
MDU6SXNzdWUyNjU3NTgwOA==,minIntronLength,CLOSED,2014-01-30T05:25:53Z,2014-05-21T23:34:14Z,2014-05-21T23:34:14Z,"For a complete data set from phytosome v0.9 shows min Intron length as ""negative"" which has to be tested with a large trusting GFF file, 
",vipints,https://github.com/vipints/genomeutils/issues/1,vipints++genomeutils.csv
MDU6SXNzdWUyNjYzMjQ4Mg==,GFFParser ,CLOSED,2014-01-30T20:55:28Z,2014-05-23T22:11:44Z,2014-05-23T22:11:44Z,"While dealing with ensembl_release-21 version GFF3 file, the programs throws an error message

/genomeutils/gfftools/GFFParser.py"", line 282, in _format_gene_models
    child_feat['exon'] = child_feat[ex_key_pattern[0]]

Add a test case with these files
",vipints,https://github.com/vipints/genomeutils/issues/2,vipints++genomeutils.csv
MDU6SXNzdWUyNjg0Njg5OQ==,sanity check for signal sequence ,CLOSED,2014-02-03T23:22:44Z,2014-05-21T23:36:08Z,2014-05-21T23:36:08Z,"only created the test for splice signals, include TIS and cdsStop
",vipints,https://github.com/vipints/genomeutils/issues/3,vipints++genomeutils.csv
MDU6SXNzdWUyNjg0NzI2OA==,random samples from the complete gene list ,CLOSED,2014-02-03T23:29:42Z,2014-02-10T16:31:50Z,2014-02-10T16:31:22Z,"may be some issues when dealing with coding-genes and single exons transcripts. 
The feature label depends on the type of genes and this has to consider while selecting the random gene list for downstream processing. 
generate_labels
",vipints,https://github.com/vipints/genomeutils/issues/4,vipints++genomeutils.csv
MDU6SXNzdWUzMjI2OTQzMw==,handling ncbi_sra_file download,CLOSED,2014-04-25T21:47:52Z,2015-01-22T02:25:08Z,2015-01-22T02:25:08Z,"For example when I try to download this RNA-seq run `SRR1024006`, it fails with assertion error that the length of the run exceeds 9 characters. 
",vipints,https://github.com/vipints/genomeutils/issues/5,vipints++genomeutils.csv
MDU6SXNzdWU1MTc0NzEyMTA=,Recent LTRs,CLOSED,2019-11-04T23:57:43Z,2020-01-26T21:43:18Z,2019-11-07T17:17:30Z,"Hi xvazquezc,

Thank you for having your repeat library construction pipeline public, it has been super helpful!

I have one question regarding the protocol: I have been successful in identifying MITEs in my fungal genome, and I have proceeded to identify LTRs. However, when I try to identify candidate elements for recent LTRs, the resulting gff99 file is empty, so I cannot go forward. I assumed that was because perhaps my data-set didn't have any, but I am not sure if this is true (there were not any errors reported). I then moved on to identified older LTRs, which produced a gff85 with data.
At some point in the pipeline, we need to run: 
perl ${DIR_CRL}/cleanRM.pl ${PREFIX}.outinner85.out ${PREFIX}.outinner85.masked > ${PREFIX}.outinner85.unmasked

However, in my case this does not work because i had no 99 output and it seems that cleanRM.pl requires it. So, I am confused as to how to proceed, which are my unmasked and cleaned files?

Thank you so much!

L. ",aberaslop,https://github.com/xvazquezc/genome_annotation_with_Maker2/issues/1,xvazquezc++genome_annotation_with_Maker2.csv
I_kwDOHDgL585GRDeK,123,CLOSED,2022-03-24T02:53:28Z,2022-03-24T03:01:07Z,2022-03-24T03:01:07Z,,ZhangLizhan,https://github.com/ZhangLizhan/Halomonas-Bluephagenesis-TD01-3rd-genomic-annotation-Tsinghua-University/issues/1,ZhangLizhan++Halomonas-Bluephagenesis-TD01-3rd-genomic-annotation-Tsinghua-University.csv
I_kwDOGdK4u86FRPVn,dependency installation doesn't work,OPEN,2024-04-10T15:31:52Z,2024-04-10T15:31:52Z,,"We have installed poetry (we don't have docker) on the server and I am trying to run the 'poetry install' command from the directory with the files from github and I get the following error:
[tool.poetry] section not found in /u/jhumann/Genome-Assembly-and-Annotation-Nomenclature_WG/pyproject.toml

",jhumann,https://github.com/AgBioData/Genome-Assembly-and-Annotation-Nomenclature_WG/issues/2,AgBioData++Genome-Assembly-and-Annotation-Nomenclature_WG.csv
I_kwDOHPSWtc5IelKt,**Basic server skills**,CLOSED,2022-04-26T13:39:21Z,2022-06-19T10:36:56Z,2022-06-19T10:29:02Z,"Instruction - https://docs.google.com/document/d/17qgOThkl8KD2XEOOxZJv7ETOYKK8N60ZFXbAbllQ00c/edit

- [x] Generate SSH-key
- [x] Connect to the server
- [x] Install jupyter notebook on server
- [x] Run jupyter notebook in screen (it's the Linux tool)
- [x] Connect server with you computer with tonnel",zilov,https://github.com/aglabx/boechera_genome/issues/1,aglabx++boechera_genome.csv
I_kwDOHPSWtc5I4UM9,** HiFi   BAM  FASTQ**,CLOSED,2022-05-02T10:25:31Z,2022-06-19T10:29:13Z,2022-06-19T10:29:13Z,": https://github.com/PacificBiosciences/bam2fastx
:   BAM   /media/eternus1/data/plants/boechera_falcata/raw_reads/hifi
:    /media/eternus1/data/plants/boechera_falcata/users/burdaeva/hifi_fastq

 :  ,         ( [boechera_assembly_lab_journal.ipynb](https://github.com/aglabx/boechera_genome/blob/main/boechera_assembly_lab_journal.ipynb))

 :  HiFi        ,    10 Kbp.          BAM.      =>     .       ,    fasta  fastq.      .",zilov,https://github.com/aglabx/boechera_genome/issues/2,aglabx++boechera_genome.csv
I_kwDOHPSWtc5I4Vk9,      ,CLOSED,2022-05-02T10:32:20Z,2022-06-19T10:29:08Z,2022-06-19T10:29:08Z,":
1)    
2)  ,       boechera_assembly_lab_journal.ipynb
3)         
4)   git  ()    (    '')",zilov,https://github.com/aglabx/boechera_genome/issues/3,aglabx++boechera_genome.csv
I_kwDOHPSWtc5MDnrU,     FASTQC,CLOSED,2022-06-19T10:28:25Z,2022-07-16T14:58:47Z,2022-07-16T14:58:47Z,"    ,               .

 -  html    ,   fastqc      fastqc. 

+           ",zilov,https://github.com/aglabx/boechera_genome/issues/6,aglabx++boechera_genome.csv
I_kwDOHPSWtc5MDoDs,  -   GenomeScope,CLOSED,2022-06-19T10:35:46Z,2022-08-09T20:17:59Z,2022-07-16T14:58:45Z," :
- [ ]          
- [ ]  Jellyfish count    -
- [ ]  Jellyfish histo    -
- [ ]  Genomescope     -
- [ ]           (   ,   ,  ,     )

 -     genomescope    genomescope  .

    -https://en.wikipedia.org/wiki/K-mer, https://youtu.be/DyZvATM9Hr8, https://bioinfologics.github.io/post/2018/09/17/k-mer-counting-part-i-introduction/",zilov,https://github.com/aglabx/boechera_genome/issues/7,aglabx++boechera_genome.csv
I_kwDOHPSWtc5MDoW_, Smudgeplot,CLOSED,2022-06-19T10:41:40Z,2022-07-16T14:58:34Z,2022-07-16T14:58:34Z,"     Jellyfish  GenomeScope,       https://github.com/KamilSJaron/smudgeplot

- [ ]  
- [ ]    ,     

     genomescope  ",zilov,https://github.com/aglabx/boechera_genome/issues/8,aglabx++boechera_genome.csv
I_kwDOHPSWtc5N5KKl, ,OPEN,2022-07-16T14:59:06Z,2022-07-16T15:15:53Z,,"    ,                  .

 :
1) LJA (https://github.com/AntonBankevich/LJA)
2) Hifiasm
3) Canu
4) Falcon
5)        HiFi 

*      ,          ( https://github.com/dfguan/purge_dups)

       ,      :
1)    QUAST
2) - c  BUSCO (   /media/eternus1/nfs/projects/shared/databases/busco)
          

       [   ](https://docs.google.com/spreadsheets/d/1FeYK-oIFX5Gjc8w9Y93YdnkQcxDknQ_PTg7Af2crN4g/edit?usp=sharing),             .",zilov,https://github.com/aglabx/boechera_genome/issues/11,aglabx++boechera_genome.csv
I_kwDOI6P9Gc5gVuT7,Error when running part1,CLOSED,2023-03-09T02:52:59Z,2023-03-14T22:32:37Z,2023-03-14T22:32:37Z,"Hi,

I am trying to run your pipeline, but a got following errors, do you know why?
Time to convert matrix 13.637509822845459
Time to condensed matrix 0.884394645690918
Time to cluster 5.115649700164795
Traceback (most recent call last):
  File ""/Bio/User/kxie/pipeline/genome/anchor/apps/HIC_ASSEMBLER/run_hicAssembler.py"", line 212, in <module>
    part1.runPipeline(varDict[""hicProBedFile""],varDict[""hicProBiasFile""],varDict[""hicProMatrixFile""],varDict[""hicProScaffSizeFile""],
  File ""/Bio/User/kxie/pipeline/genome/anchor/apps/HIC_ASSEMBLER/scaffoldToChromosomes.py"", line 596, in runPipeline
    plotModule.plotContactMap(adjMat,resolution=resolution,highlightChroms=False,showPlot=False,savePlot=avgClusterPlot)
  File ""/Bio/User/kxie/pipeline/genome/anchor/apps/HIC_ASSEMBLER/plotContactMaps.py"", line 25, in plotContactMap
    vmin=numpy.percentile(adjMat,lP),
  File ""<__array_function__ internals>"", line 180, in percentile
  File ""/Bio/User/kxie/software/anaconda3/envs/hicassembler/lib/python3.10/site-packages/numpy/lib/function_base.py"", line 4166, in percentile
    return _quantile_unchecked(
  File ""/Bio/User/kxie/software/anaconda3/envs/hicassembler/lib/python3.10/site-packages/numpy/lib/function_base.py"", line 4424, in _quantile_unchecked
    r, k = _ureduce(a,
  File ""/Bio/User/kxie/software/anaconda3/envs/hicassembler/lib/python3.10/site-packages/numpy/lib/function_base.py"", line 3725, in _ureduce
    r = func(a, **kwargs)
  File ""/Bio/User/kxie/software/anaconda3/envs/hicassembler/lib/python3.10/site-packages/numpy/lib/function_base.py"", line 4593, in _quantile_ureduce_func
    result = _quantile(arr,
  File ""/Bio/User/kxie/software/anaconda3/envs/hicassembler/lib/python3.10/site-packages/numpy/lib/function_base.py"", line 4710, in _quantile
    result = _lerp(previous,
  File ""/Bio/User/kxie/software/anaconda3/envs/hicassembler/lib/python3.10/site-packages/numpy/lib/function_base.py"", line 4529, in _lerp
    lerp_interpolation = asanyarray(add(a, diff_b_a * t, out=out))
  File ""/Bio/User/kxie/software/anaconda3/envs/hicassembler/lib/python3.10/site-packages/numpy/matrixlib/defmatrix.py"", line 218, in __mul__
    return N.dot(self, asmatrix(other))
  File ""<__array_function__ internals>"", line 180, in dot
ValueError: shapes (1,115648516) and (1,1) not aligned: 115648516 (dim 1) != 1 (dim 0)

Best,
Kun",xiekunwhy,https://github.com/AO33/HiC_Genome_Assembler/issues/1,AO33++HiC_Genome_Assembler.csv
MDU6SXNzdWU0MTc4NTM3MjE=,cpDNAExtraction/longRead/2_resultParse.py produce an empty file,CLOSED,2019-03-06T15:12:43Z,2019-03-13T00:14:19Z,2019-03-13T00:14:19Z,"I have run blasr (5.3) : 
```
blasr \
reads_pacbio_5kb.fastq \
ref_cp_double.fasta \
--nproc 20 \
--bestn 1 \
-m 1 \
--minMatch 15 \
--minAlnLength 5000 \
--out blasr_cp.out
```

But when I run getRead.py with : 
```
    inputFile   = 'blasr_cp.out'
    reference   = 'ref_cp_double.fasta'
    outputFile  = 'blasr_marouch_ref_cp_reads.fasta'
```

It produces an empty file without any error

",agroppi,https://github.com/asdcid/Chloroplast-genome-assembly/issues/1,asdcid++Chloroplast-genome-assembly.csv
MDU6SXNzdWU0MjAwNzEzNjI=,Question : Post-assembly steps after hybrid protocol ?,CLOSED,2019-03-12T16:05:17Z,2019-03-13T10:14:24Z,2019-03-13T10:14:24Z,"My inputs : 
Pacbio reads and illumina reads
I have run all the steps of the hybrid-assembly protocol  until assembly.
But now the post assembly steps are unclear.
Can you be more specific, taking in account that I use Pacbio reads as Longreads and not ONT reads.

Thnaks you very much for your help
",agroppi,https://github.com/asdcid/Chloroplast-genome-assembly/issues/2,asdcid++Chloroplast-genome-assembly.csv
MDU6SXNzdWU0MjE1NzMwNzI=,Question phylogeny_analysis step hard coded coordinates ?,CLOSED,2019-03-15T15:23:29Z,2019-05-23T03:18:03Z,2019-05-23T03:18:03Z,"I had a lok in the script ""1_gb_gff_fasta.py""
I noticed that some genomic coordinates are ""hard coded"" in the script : 

```
def grandis_add_missGene(data) :
    
    data.append([9718, 9740, '+', 'tRNA-Gly', 1])
    data.append([10485, 10533, '+', 'tRNA-Gly', 2])

    data.append([5075, 5268, '-', 'rps16', 2])
    data.append([6145, 6184, '-', 'rps16', 1])

    data.append([17880, 22057, '-', 'rpoC2', ''])

    data.append([22223, 23838, '-', 'rpoc1', 2])
    data.append([24572, 25024, '-', 'rpoc1', 1])
    
    data.append([53530, 54382, '-', 'ndhK', ''])

    data.append([81097, 81104, '+', 'petD', 1])
    data.append([81875, 82349, '+', 'petD', 2])

    data.append([61165, 62659, '+', 'accD', ''])

    data.append([129216, 134841, '-', 'ycf1', ''])

    data.append([88932, 89365, '-', 'rpl2', 2])
    data.append([90030, 90420, '-', 'rpl2', 1])

    data.append([125058, 125598, '-', 'ndhA', 2])
    data.append([126659, 127209, '-', 'ndhA', 1])

    data.append([158590, 158980, '+', 'rpl2', 1])
    data.append([159645, 160078, '+', 'rpl2', 2])
```
Are they species specific (Eucalyptus) ? 

Do they have to be adpated in the case of another species ?

Thanks

",agroppi,https://github.com/asdcid/Chloroplast-genome-assembly/issues/3,asdcid++Chloroplast-genome-assembly.csv
MDU6SXNzdWU5MDg3ODM4Njg=,IndexError on the direction.py script,OPEN,2021-06-01T22:40:38Z,2021-06-05T23:39:57Z,,"Hi, I am runing the post assembly script direction.py using an assembly from canu and found the following error:

[root@localhost genomas_cedrela]$ python3.8 direction.py /canu_results/c_odor_contigs.fasta
Traceback (most recent call last):
  File ""direction.py"", line 193, in <module>
    main()
  File ""direction.py"", line 182, in main
    outputFile  = sys.argv[2]
IndexError: list index out of range

My three contigs on the inputFile are 120, 23 and 55 kb, so dont know if this has something to do with the error

Im on the basics of programming and have no clue how to solve this

I  would appreciate your help
",jsimba-99,https://github.com/asdcid/Chloroplast-genome-assembly/issues/4,asdcid++Chloroplast-genome-assembly.csv
I_kwDOBV0nAc6CijdE,ask fasta,OPEN,2024-03-16T15:21:46Z,2024-03-16T15:21:46Z,,"threads=40
ref='ref/cp_double_up_combine.fasta'
minMatch=15
minAlnLength=5000


ref this mean must havev refrenrce fasta file ? ",azfarwisnu,https://github.com/asdcid/Chloroplast-genome-assembly/issues/5,asdcid++Chloroplast-genome-assembly.csv
MDU6SXNzdWU5MDk5ODA2MDU=,conda install issue,OPEN,2021-06-03T00:21:07Z,2021-06-04T02:15:25Z,,"Hi there,
I am trying install the asdcid but I faced with the following issue related to conda env:
(base) -bash-4.2$ conda env create -f environment.yml
Collecting package metadata (repodata.json): done
Solving environment: failed

ResolvePackageNotFound:
  - genometools-genometools==1.5.10=h470a237_1

Do you have any idea to solve the problem. In addition, genometools  is available on our server and I can load genometools using module load genometools but I am not sure if it can help. ",Karimi-81,https://github.com/asdcid/Genome_Assembly_Assessment/issues/2,asdcid++Genome_Assembly_Assessment.csv
I_kwDODGGXws5aj4iD,Cgal error,OPEN,2023-01-04T17:44:11Z,2023-01-05T01:43:02Z,,"Hi 
I was running Genome Assembly Assesement and every thing went well but cgal analysis fails a couple of times. It gives an error 137 Segmentation fault which associated with Bowtie.  How this problem can be solved?

Best",mergi-2674,https://github.com/asdcid/Genome_Assembly_Assessment/issues/3,asdcid++Genome_Assembly_Assessment.csv
I_kwDOIYq0o86F84dH,Missing RO-Crate workflow file,CLOSED,2024-04-17T04:09:39Z,2024-04-19T00:37:05Z,2024-04-19T00:37:05Z,<b>Issue ID:</b> <code>repo_layout.MissingROCrateWorkflowFile</code><br><br><b>Description:</b><br>The workflow file declared on RO-Crate metadata is missing in this repository.,lifemonitor,https://github.com/AustralianBioCommons/Genome-assessment-post-assembly/issues/6,AustralianBioCommons++Genome-assessment-post-assembly.csv
MDU6SXNzdWUzNTE4NzM3ODI=,cer,OPEN,2018-08-19T04:45:05Z,2018-08-19T04:45:05Z,,"<img width=""794"" alt=""default"" src=""https://user-images.githubusercontent.com/33269462/44305590-1b413b00-a349-11e8-8839-915bfda8b2af.png"">
",BessieChen,https://github.com/BessieChen/Coursera-Genome-Assembly-Programming-Challenge/issues/1,BessieChen++Coursera-Genome-Assembly-Programming-Challenge.csv
MDU6SXNzdWUzNTE4NzM4NzI=,px,OPEN,2018-08-19T04:47:09Z,2018-08-19T04:47:09Z,,"<img width=""259"" alt=""default"" src=""https://user-images.githubusercontent.com/33269462/44305606-65c2b780-a349-11e8-9ee5-ccb3e108aa3c.png"">
",BessieChen,https://github.com/BessieChen/Coursera-Genome-Assembly-Programming-Challenge/issues/2,BessieChen++Coursera-Genome-Assembly-Programming-Challenge.csv
MDU6SXNzdWUzNjUxNzE4MzQ=,Confirm that use of BLAST's `-max_target_seqs` is intentional,OPEN,2018-09-29T22:25:03Z,2018-09-29T22:25:03Z,,"Hi there,

This is a semi-automated message from a fellow bioinformatician. Through a GitHub search, I found that the following source files make use of BLAST's `-max_target_seqs` parameter: 

- [assembly-scripts/blastx-nr.sh](https://github.com/bethsheets/Population-Genomics-via-RNAseq/blob/178296217dd0da1c625a836589a94ae59b47876e/assembly-scripts/blastx-nr.sh)
- [assembly-scripts/blastx-uniprot.sh](https://github.com/bethsheets/Population-Genomics-via-RNAseq/blob/178296217dd0da1c625a836589a94ae59b47876e/assembly-scripts/blastx-uniprot.sh)
- [assembly-scripts/example_tBLASTx_localdb_customout_mkm.sbatch](https://github.com/bethsheets/Population-Genomics-via-RNAseq/blob/178296217dd0da1c625a836589a94ae59b47876e/assembly-scripts/example_tBLASTx_localdb_customout_mkm.sbatch)

Based on the recently published report, [Misunderstood parameter of NCBI BLAST impacts the correctness of bioinformatics workflows](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/bty833/5106166?redirectedFrom=fulltext), there is a strong chance that this parameter is misused in your repository.

If the use of this parameter was intentional, please feel free to ignore and close this issue but I would highly recommend to add a comment to your source code to notify others about this use case. If this is a duplicate issue, please accept my apologies for the redundancy as this simple automation is not smart enough to identify such issues.

Thank you!
-- Arman ([armish/blast-patrol](https://github.com/armish/blast-patrol))",armish,https://github.com/bethsheets/Population-Genomics-via-RNAseq/issues/2,bethsheets++Population-Genomics-via-RNAseq.csv
MDU6SXNzdWUyNjkyMTg3ODY=,Attach seqlengths to mapToTranscripts() return value,CLOSED,2017-10-27T19:59:05Z,2018-02-04T23:33:29Z,2018-02-04T23:33:29Z,"The result of `mapToTranscripts()` treats the transcripts as the sequences. We know the lengths of the transcripts, but these are not carried over into the result. We should probably do that. I would be happy to help review this change, if desired.
",lawremi,https://github.com/Bioconductor/GenomicFeatures/issues/1,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWUyNzU2NzQ4Nzk=,"extractTranscriptSeqs, needs extra check",CLOSED,2017-11-21T11:19:37Z,2019-10-22T09:37:29Z,2019-10-22T09:37:29Z,"I spent 5 hours debugging extractTranscriptSeqs for faFile, GRangesList

When the GTF file and the fasta file have different naming on chromosomes, like chr1 in fasta vs 1 in gtf(which is the case for zebrafish genome danRer10), this error occurs:

```
extractTranscriptSeqs(faFile(""./danRer10.fa""),grl)

Error in (function (classes, fdef, mtable)  : 
  unable to find an inherited method for function scanFa for signature ""FaFile"", ""character""
```

This error told me very little, so I went into source code for some hours and the suddenly realized the chromsome naming differed.

Is it possible to make a test on this, that if no seqnames match, it should stop, and give propper error, if it exists it did not catch this example at least.
",Roleren,https://github.com/Bioconductor/GenomicFeatures/issues/2,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWUyNzk3NzUzMDE=,'names' attribute [211] must be the same length as the vector [209],CLOSED,2017-12-06T14:36:54Z,2017-12-08T23:47:23Z,2017-12-08T23:47:23Z,"hg19.refseq.db<-GenomicFeatures::makeTxDbFromUCSC(genome=""hg19"", table=""refGene"")
Error in names(trackIds) <- sub(""^ "", """", sapply(nodes, xmlValue)) : 
  'names' attribute [211] must be the same length as the vector [209]

Any idea on how to go about solving this? Is this a common issue? 
I'm running R 3.4.3 and tried reinstalling the package in addition to R, from scratch.  The issue still remains.",jamesdalg,https://github.com/Bioconductor/GenomicFeatures/issues/3,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWUyODM0MDU4NTE=,GenomicFeatures fails to install on CentOS 7.4 w MariaDB,CLOSED,2017-12-19T23:48:03Z,2017-12-20T02:02:33Z,2017-12-20T02:02:32Z,"See [this issue][1], originally opened on VariantAnnotation.

[1]: https://github.com/Bioconductor/VariantAnnotation/issues/1",mtmorgan,https://github.com/Bioconductor/GenomicFeatures/issues/4,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWUzMTc3NTcwODE=,"coverageByTranscript, seqlevels",CLOSED,2018-04-25T19:10:52Z,2019-10-22T05:13:44Z,2018-05-09T13:41:05Z,"We used this function extensivly in our package: https://github.com/JokingHero/ORFik

And found some scary behaviors of the seqlevels:
In our packages we made our own coverageByTranscript, which in ORFik is called 
coverageByWindow

In our version we use data.table syntax, so in this gist, we swapped this for base functions, but they are slow, 
i.g. aggregate etc, that should be swapped out. 

A list of fixes we did for consistent behavior is here:
https://gist.github.com/JokingHero/3eb1d69c7fe1adbebc2c1cabc48d8ecb

Let me know what you think.
Thank you. ",Roleren,https://github.com/Bioconductor/GenomicFeatures/issues/6,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWUzMzUxNDkzNjM=,"the ""phase"" metadata column must contain 0, 1, or 2, for all the CDS features",CLOSED,2018-06-24T04:12:05Z,2018-08-14T14:53:41Z,2018-08-14T14:53:41Z,"When use makeTxdbFromGff(), I met this issue.But I check my gtf file,there is no problem with the 8th col. It contains only 0,1,2 for all CDS features.Could you please tell me what's the problem?
Regards
Alex",AlexWanghaoming,https://github.com/Bioconductor/GenomicFeatures/issues/7,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWUzMzY1ODAyNjc=,How does GenomicFeature calculate 3'UTR?,CLOSED,2018-06-28T11:22:56Z,2018-06-29T02:27:16Z,2018-06-29T02:27:16Z,"Hi, I download gencode V19 gtf file from [gencode ](https://www.gencodegenes.org/releases/19.html) 
(Comprehensive gene annotation, CHG region) then I load it into R with GenomicFeature using this:
`gencode_v19 = makeTxDbFromGFF(gtfFile,
                    format = 'gtf',
                    dataSource = 'gencode',
                    organism = 'Homo sapiens',
                    chrominfo = chromInfo)`
I extract 5'UTR and 3'UTR using fiveUTRsByTranscript() and threeUTRsByTranscript() like this:
`utr5 = fiveUTRsByTranscript(gencode_v19,use.names=TRUE)`
But the UTR I get is  slightly different from UTR annotation in gencode v19 gtf file. It seems that GenomicFeatures doesn't regard stop codon  as part of 3'UTR. Here is an example: ENST00000370584. Is this right ? If it's right, where should I change in raw codes to include stop codon when calculate 3'UTR ? 
Also total UTR regions (the sum of 5'UTR and 3'UTR) generated by GenomicFeatures is only 280400 while total UTR regions in gtf file is 284573. I use the following steps to count UTR regions generated by GenomicFeatures. Let's regard utr5 and utr3 as the result of fiveUTRsByTranscript() and threeUTRsByTranscript() respectively. Then I transform utr5 and utr3 to dataframe with as.data.frame() and use nrow() to count UTR regions. I count UTR regions in gencode gtf files simply using `awk '$3~/UTR/{print}' gencode.v19.gtf | wc -l `. I think this two number should be the same but apparently they are not. So why is there small difference ?
Thank you very much for helping me !",lss1227,https://github.com/Bioconductor/GenomicFeatures/issues/8,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWUzNTA0NjU0OTY=,"Make cdsBy(txdb, by=""tx"") return the CDS phase",OPEN,2018-08-14T14:55:08Z,2018-08-14T14:55:08Z,,See https://support.bioconductor.org/p/101245/,hpages,https://github.com/Bioconductor/GenomicFeatures/issues/9,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWUzNjE2ODQ0MTY=,pmapFromTranscripts strange behaviour,OPEN,2018-09-19T10:36:07Z,2019-02-08T12:00:57Z,,"There is some strange behavour on how it handles names in the transcripts:
Sorry for bad test data, made this quickly:

tx is a GRangesList of 100.000 transcripts:
ranges is 600.000 ORFs on the transcripts as IRanges
orfs$index is the index for each orf which transcript it came from

See how the time is different:
1. Without names:

```
grl <- tx 
names(grl) <- NULL
system.time(pmapFromTranscripts(x = ranges, transcripts = grl[orfs$index]))
   user  system elapsed 
 19.661   1.701  21.355 

```
2. With names:

```
grl <- tx
system.time(pmapFromTranscripts(x = ranges, transcripts = grl[orfs$index]))
   user  system elapsed 
 74.474   3.616  78.071 
```

3. Without names, and set them afterwards, so result is same as 2. 
```
names(grl) <- NULL
system.time({genomic <- pmapFromTranscripts(x = ranges, transcripts = grl[orfs$index]);
                     names(genomic) <- names(tx)[orfs$index] })
   user  system elapsed 
 19.963   1.634  21.591 
```

So this means that 2. is almost 4 times slower, while we could have done  3 , which is as fast a 1. 

Is this intentional ?

sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: CentOS Linux 7 (Core)

Matrix products: default
BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats4    parallel  stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] GenomicFeatures_1.33.2   GenomicRanges_1.33.13    IRanges_2.15.17            
     
...",Roleren,https://github.com/Bioconductor/GenomicFeatures/issues/10,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWUzNzE5ODk2OTk=,makeTxDbFromEnsembl() is broken,CLOSED,2018-10-19T14:46:56Z,2019-03-15T17:47:26Z,2019-03-15T17:47:26Z,"```
library(GenomicFeatures)
txdb <- makeTxDbFromEnsembl()
# Fetch transcripts and genes from Ensembl ... OK
# Fetch exons and CDS from Ensembl ... OK
# Fetch chromosome names and lengths from Ensembl ...Error in .fetch_Ensembl_chrominfo(dbconn, # seq_region_ids = seq_region_ids,  : 
#   identical(colnames(seq_region), joined_columns) is not TRUE
```
```
> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.5 LTS

Matrix products: default
BLAS: /home/hpages/R/R-3.5.1/lib/libRblas.so
LAPACK: /home/hpages/R/R-3.5.1/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats4    parallel  stats     graphics  grDevices utils     datasets 
[8] methods   base     

other attached packages:
[1] GenomicFeatures_1.32.3 AnnotationDbi_1.42.1   Biobase_2.40.0        
[4] GenomicRanges_1.32.7   GenomeInfoDb_1.16.0    IRanges_2.14.12       
[7] S4Vectors_0.18.3       BiocGenerics_0.26.0   

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.19                compiler_3.5.1             
 [3] XVector_0.20.0              prettyunits_1.0.2          
 [5] bitops_1.0-6                tools_3.5.1                
 [7] progress_1.2.0              zlibbioc_1.26.0            
 [9] biomaRt_2.36.1              digest_0.6.18              
[11] bit_1.1-14                  lattice_0.20-35            
[13] RSQLite_2.1.1               memoise_1.1.0              
[15] pkgconfig_2.0.2             rlang_0.2.2                
[17] Matrix_1.2-14               DelayedArray_0.6.6         
[19] DBI_1.0.0                   GenomeInfoDbData_1.1.0     
[21] RMariaDB_1.0.6              rtracklayer_1.40.6         
[23] stringr_1.3.1               httr_1.3.1                 
[25] Biostrings_2.48.0           hms_0.4.2                  
[27] grid_3.5.1                  bit64_0.9-7                
[29] R6_2.3.0                    XML_3.98-1.16              
[31] BiocParallel_1.14.2         blob_1.1.1                 
[33] magrittr_1.5                matrixStats_0.54.0         
[35] Rsamtools_1.32.3            GenomicAlignments_1.16.0   
[37] SummarizedExperiment_1.10.1 assertthat_0.2.0           
[39] stringi_1.2.4               RCurl_1.95-4.11            
[41] crayon_1.3.4               
```",hpages,https://github.com/Bioconductor/GenomicFeatures/issues/11,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWUzNzc3MzEwMTA=,extractTranscriptSeqs fails reconstructing transcripts on minus strand,CLOSED,2018-11-06T08:01:56Z,2018-11-07T17:22:26Z,2018-11-07T17:22:26Z,"When working on my favourite genome, I have noticed that extractTranscriptSeqs assembles cds in wrong order, when trying to reconstruct transcripts located on tthe minus strand. 

In order to demonstrate this issue, I have a test script developed on random coordinates on chr2 of the Human genome.

`#load libraries
library(""GenomicFeatures"")
library(""Biostrings"")
library(""BSgenome.Hsapiens.UCSC.hg19"")
#load genome
genome <- BSgenome.Hsapiens.UCSC.hg19
#build GRanges object: let's say there are 2 genes (named match), the first with just one 'exon' (match_part), 
#and the second with 3 exons, two of which are overlapping. 
( gr <- GRanges(Rle(rep(""chr2"", 6)),
              IRanges(start=c(11874,11874,14874,14874,15374,15674), end=c(12874,12874,15874,15474,15574,15874)),
              Rle(strand(c(""-"")), c(6)),
              type=c(""match"",""match_part"",""match"",""match_part"",""match_part"",""match_part""),
              target=c(""A"",""A"",""B"",""B"",""B"",""B""),
              parentFix=c(""a-A"",""a-A"",""b-B"",""b-B"",""b-B"",""b-B"")
    ))

#Select MATCHES, create GRangesList object, run merge -- non expecting any merge --, 
#extract the genomic sequence based on Iranges
( gr.m <- gr[gr$type == ""match""] )
( gr.m.grl = split(gr.m, as.factor(gr.m$parentFix)) )
( mergers.m.minus <- IRanges::reduce(gr.m.grl, with.revmap=TRUE) )
( cds.m.minus <- extractTranscriptSeqs(genome, mergers.m.minus) )
#Select MATCH_PARTS, create GRangesList object, run merge -- expecting overlap between feature 1 and 2 --, 
#extract the genomic sequence based on Iranges
( gr.mp <- gr[gr$type == ""match_part""] )
( gr.mp.grl = split(gr.mp, as.factor(gr.mp$parentFix)) )
( mergers.mp.minus <- IRanges::reduce(gr.mp.grl, with.revmap=TRUE) )
( cds.mp.minus <- extractTranscriptSeqs(genome, mergers.mp.minus) )
#COMMENT ON THE RESULT: The first transcript (one cds) has been correctly extracted, while the cds' of the second transcript have been mounted in the wrong order. 
#To fix this issue the following line helps: sort coordiantes in decreasing order.
( cds.mp.minus <- extractTranscriptSeqs(genome, sort(mergers.mp.minus,decreasing=T)) )
`
As stated in documentation:
[..] For a transcript located on the minus strand, the exons will typically (but not necessarily) be ordered by descending position on the reference genome. 

...but it's not working at the moment.

",sghignone,https://github.com/Bioconductor/GenomicFeatures/issues/12,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU0MDIxNzExOTE=,makeTxDbFromGFF not working with GFF3File object,CLOSED,2019-01-23T10:30:32Z,2019-01-25T19:59:20Z,2019-01-25T19:59:19Z,"This does not work:

```
gff <- GFF3File(""sacCer3.gff"")
makeTxDbFromGFF(gff)
```

This works
```
gff <- GFF3File(""sacCer3.gff"")
makeTxDbFromGFF(path(gff))
```
[sacCer3.zip](https://github.com/Bioconductor/GenomicFeatures/files/2786763/sacCer3.zip)

```
> sessionInfo()
R version 3.5.2 (2018-12-20)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252    LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                    LC_TIME=German_Germany.1252    

attached base packages:
[1] parallel  stats4    stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] Rsamtools_1.34.0            Biostrings_2.50.2           XVector_0.22.0              RPFTools_0.0.1              SummarizedExperiment_1.12.0 DelayedArray_0.8.0         
 [7] BiocParallel_1.16.5         matrixStats_0.54.0          GenomicFeatures_1.34.1      AnnotationDbi_1.44.0        Biobase_2.42.0              rtracklayer_1.42.1         
[13] GenomicRanges_1.34.0        GenomeInfoDb_1.18.1         IRanges_2.16.0              S4Vectors_0.20.1            BiocGenerics_0.28.0        

loaded via a namespace (and not attached):
  [1] assertive.base_0.0-7       colorspace_1.3-2           colorRamps_2.3             ggridges_0.5.1             htmlTable_1.13             base64enc_0.1-3           
  [7] rstudioapi_0.8             assertive.sets_0.0-3       ggrepel_0.8.0              bit64_0.9-7                assertive.data.uk_0.0-2    codetools_0.2-16          
 [13] splines_3.5.2              geneplotter_1.60.0         knitr_1.21                 SuppDists_1.1-9.4          Formula_1.2-3              assertive_0.3-5           
 [19] assertive.data.us_0.0-2    rJava_0.9-10               annotate_1.60.0            cluster_2.0.7-1            GO.db_3.7.0                graph_1.60.0              
 [25] compiler_3.5.2             httr_1.4.0                 backports_1.1.3            GOstats_2.48.0             assertthat_0.2.0           Matrix_1.2-15             
 [31] lazyeval_0.2.1             cli_1.0.1                  htmltools_0.3.6            acepack_1.4.1              prettyunits_1.0.2          tools_3.5.2               
 [37] bindrcpp_0.2.2             gtable_0.2.0               glue_1.3.0                 GenomeInfoDbData_1.2.0     Category_2.48.0            reshape2_1.4.3            
 [43] dplyr_0.7.8                Rcpp_1.0.0                 xtail_1.1.5                gdata_2.18.0               assertive.files_0.0-2      assertive.datetimes_0.0-2 
 [49] assertive.models_0.0-2     xfun_0.4                   stringr_1.3.1              gtools_3.8.1               XML_3.98-1.16              zlibbioc_1.28.0           
 [55] scales_1.0.0               hms_0.4.2                  RBGL_1.58.1                RColorBrewer_1.1-2         assertive.matrices_0.0-2   assertive.strings_0.0-3   
 [61] yaml_2.2.0                 memoise_1.1.0              RDAVIDWebService_1.20.0    gridExtra_2.3              ggplot2_3.1.0              UpSetR_1.3.3              
 [67] rpart_4.1-13               biomaRt_2.38.0             latticeExtra_0.6-28        stringi_1.2.4              RSQLite_2.1.1              genefilter_1.64.0         
 [73] checkmate_1.8.5            caTools_1.17.1.1           rlang_0.3.0.1              pkgconfig_2.0.2            bitops_1.0-6               lattice_0.20-38           
 [79] assertive.data_0.0-3       purrr_0.2.5                bindr_0.1.1                htmlwidgets_1.3            GenomicAlignments_1.18.1   assertive.properties_0.0-4
 [85] bit_1.1-14                 tidyselect_0.2.5           GSEABase_1.44.0            assertive.code_0.0-3       AnnotationForge_1.24.0     plyr_1.8.4                
 [91] magrittr_1.5               DESeq2_1.22.2              R6_2.3.0                   Hmisc_4.1-1                gplots_3.0.1               DBI_1.0.0                 
 [97] withr_2.1.2                foreign_0.8-71             pillar_1.3.1               assertive.numbers_0.0-2    nnet_7.3-12                survival_2.43-3           
[103] RCurl_1.95-4.11            tibble_1.4.2               crayon_1.3.4               assertive.types_0.0-3      KernSmooth_2.23-15         kSamples_1.2-8            
[109] progress_1.2.0             locfit_1.5-9.1             grid_3.5.2                 data.table_1.11.8          blob_1.1.1                 Rgraphviz_2.26.0          
[115] digest_0.6.18              xtable_1.8-3               munsell_0.5.0              assertive.reflection_0.0-4 sessioninfo_1.1.1      
```",FelixErnst,https://github.com/Bioconductor/GenomicFeatures/issues/13,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU0MDMzOTk1Nzg=,Question: error in makeTxDbFromUCSC,CLOSED,2019-01-26T03:18:33Z,2019-01-28T06:04:00Z,2019-01-28T04:58:50Z,"Hi GenomicFeatures support,

I am a phD student at the University of Tokyo, using GenomicFeatures for ChIPSeeker. 

After I run
txdb=makeTxDbFromUCSC(genome=""hg19"",tablename=""refGene"")

I got this error.

Download the refGene table ... OK
Download the hgFixed.refLink table ... OK
Extract the 'transcripts' data frame ... OK
Extract the 'splicings' data frame ... OK
Download and preprocess the 'chrominfo' data frame ... OK
Prepare the 'metadata' data frame ... OK
**Make the TxDb object ... Error in .check_foreign_key(transcripts_tx_chrom, NA, ""transcripts$tx_chrom"",  : 
  all the values in 'transcripts$tx_chrom' must be present in 'chrominfo$chrom'**

**I consider the problem is that refGene version was upgraded last November,however, GenomicFeatures haven't done corresponding changes to the new refGene release.** 

**Genomefeatures** ""x"" ""1"" ""chr1"" ""2"" ""chr1gl000191random"" ""3"" ""chr1gl000192random"" ""4"" ""chr10"" ""5"" ""chr11"" ""6"" ""chr11gl000202random"" ""7"" ""chr12"" ""8"" ""chr13"" ""9"" ""chr14"" ""10"" ""chr15"" ""11"" ""chr16"" ""12"" ""chr17"" ""13"" ""chr17ctg5hap1"" ""14"" ""chr17gl000203random"" ""15"" ""chr17gl000204random"" ""16"" ""chr17gl000205random"" ""17"" ""chr17gl000206random"" ""18"" ""chr18"" ""19"" ""chr18gl000207random"" ""20"" ""chr19"" ""21"" ""chr19gl000208random"" ""22"" ""chr19gl000209random"" ""23"" ""chr2"" ""24"" ""chr20"" ""25"" ""chr21"" ""26"" ""chr21gl000210random"" ""27"" ""chr22"" ""28"" ""chr3"" ""29"" ""chr4"" ""30"" ""chr4ctg9hap1"" ""31"" ""chr4gl000193random"" ""32"" ""chr4gl000194random"" ""33"" ""chr5"" ""34"" ""chr6"" ""35"" ""chr6apdhap1"" ""36"" ""chr6coxhap2"" ""37"" ""chr6dbbhap3"" ""38"" ""chr6mannhap4"" ""39"" ""chr6mcfhap5"" ""40"" ""chr6qblhap6"" ""41"" ""chr6sstohap7"" ""42"" ""chr7"" ""43"" ""chr7gl000195random"" ""44"" ""chr8"" ""45"" ""chr8gl000196random"" ""46"" ""chr8gl000197random"" ""47"" ""chr9"" ""48"" ""chr9gl000198random"" ""49"" ""chr9gl000199random"" ""50"" ""chr9gl000200random"" ""51"" ""chr9gl000201random"" ""52"" ""chrM"" ""53"" ""chrUngl000211"" ""54"" ""chrUngl000212"" ""55"" ""chrUngl000213"" ""56"" ""chrUngl000214"" ""57"" ""chrUngl000215"" ""58"" ""chrUngl000216"" ""59"" ""chrUngl000217"" ""60"" ""chrUngl000218"" ""61"" ""chrUngl000219"" ""62"" ""chrUngl000220"" ""63"" ""chrUngl000221"" ""64"" ""chrUngl000222"" ""65"" ""chrUngl000223"" ""66"" ""chrUngl000224"" ""67"" ""chrUngl000225"" ""68"" ""chrUngl000226"" ""69"" ""chrUngl000227"" ""70"" ""chrUngl000228"" ""71"" ""chrUngl000229"" ""72"" ""chrUngl000230"" ""73"" ""chrUngl000231"" ""74"" ""chrUngl000232"" ""75"" ""chrUngl000233"" ""76"" ""chrUngl000234"" ""77"" ""chrUngl000235"" ""78"" ""chrUngl000236"" ""79"" ""chrUngl000237"" ""80"" ""chrUngl000238"" ""81"" ""chrUngl000239"" ""82"" ""chrUngl000240"" ""83"" ""chrUngl000241"" ""84"" ""chrUngl000242"" ""85"" ""chrUngl000243"" ""86"" ""chrUngl000244"" ""87"" ""chrUngl000245"" ""88"" ""chrUngl000246"" ""89"" ""chrUngl000247"" ""90"" ""chrUngl000248"" ""91"" ""chrUn_gl000249"" ""92"" ""chrX"" ""93"" ""chrY""

**UCSCrefgene** ""x"" ""1"" ""chr1"" ""2"" ""chr1gl000191random"" ""3"" ""chr1gl000192random"" ""4"" ""chr1gl383519alt"" ""5"" ""chr1gl949741fix"" ""6"" ""chr1jh636052fix"" ""7"" ""chr1jh636054fix"" ""8"" ""chr10"" ""9"" ""chr10gl383543fix"" ""10"" ""chr10jh591181fix"" ""11"" ""chr10jh636060fix"" ""12"" ""chr11"" ""13"" ""chr11gl949744fix"" ""14"" ""chr11jh159138fix"" ""15"" ""chr11jh159142fix"" ""16"" ""chr12"" ""17"" ""chr13"" ""18"" ""chr14"" ""19"" ""chr14kb021645fix"" ""20"" ""chr15"" ""21"" ""chr16"" ""22"" ""chr17"" ""23"" ""chr17ctg5hap1"" ""24"" ""chr17gl000205random"" ""25"" ""chr17gl383560fix"" ""26"" ""chr17gl582976fix"" ""27"" ""chr17jh159145fix"" ""28"" ""chr18"" ""29"" ""chr18gl383571alt"" ""30"" ""chr19"" ""31"" ""chr19gl000209random"" ""32"" ""chr19gl383575alt"" ""33"" ""chr19gl582977fix"" ""34"" ""chr19gl949746alt"" ""35"" ""chr19gl949747alt"" ""36"" ""chr19gl949748alt"" ""37"" ""chr19gl949749alt"" ""38"" ""chr19gl949750alt"" ""39"" ""chr19gl949751alt"" ""40"" ""chr19gl949752alt"" ""41"" ""chr19gl949753alt"" ""42"" ""chr19jh159149fix"" ""43"" ""chr19kb021647fix"" ""44"" ""chr2"" ""45"" ""chr2kb663603fix"" ""46"" ""chr20"" ""47"" ""chr20gl582979fix"" ""48"" ""chr21"" ""49"" ""chr21ke332506fix"" ""50"" ""chr22"" ""51"" ""chr22gl383582alt"" ""52"" ""chr22jh720449fix"" ""53"" ""chr3"" ""54"" ""chr3gl383523fix"" ""55"" ""chr3jh159132fix"" ""56"" ""chr4"" ""57"" ""chr4ctg9hap1"" ""58"" ""chr4gl000193random"" ""59"" ""chr4gl000194random"" ""60"" ""chr4gl877872fix"" ""61"" ""chr4ke332496fix"" ""62"" ""chr5"" ""63"" ""chr5gl339449alt"" ""64"" ""chr5jh159133fix"" ""65"" ""chr5ke332497fix"" ""66"" ""chr6"" ""67"" ""chr6apdhap1"" ""68"" ""chr6coxhap2"" ""69"" ""chr6dbbhap3"" ""70"" ""chr6jh636056fix"" ""71"" ""chr6kb663604fix"" ""72"" ""chr6mannhap4"" ""73"" ""chr6mcfhap5"" ""74"" ""chr6qblhap6"" ""75"" ""chr6sstohap7"" ""76"" ""chr7"" ""77"" ""chr7gl000195random"" ""78"" ""chr7gl582971fix"" ""79"" ""chr7jh159134fix"" ""80"" ""chr8"" ""81"" ""chr8gl383535fix"" ""82"" ""chr8gl383536fix"" ""83"" ""chr9"" ""84"" ""chr9gl339450fix"" ""85"" ""chrM"" ""86"" ""chrUngl000211"" ""87"" ""chrUngl000212"" ""88"" ""chrUngl000213"" ""89"" ""chrUngl000215"" ""90"" ""chrUngl000218"" ""91"" ""chrUngl000219"" ""92"" ""chrUngl000220"" ""93"" ""chrUngl000222"" ""94"" ""chrUngl000223"" ""95"" ""chrUngl000224"" ""96"" ""chrUngl000227"" ""97"" ""chrUngl000228"" ""98"" ""chrUngl000241"" ""99"" ""chrX"" ""100"" ""chrXjh159150fix"" ""101"" ""chrXjh806587fix"" ""102"" ""chrXjh806590fix"" ""103"" ""chrXjh806593fix"" ""104"" ""chrXjh806594fix"" ""105"" ""chrXjh806595fix"" ""106"" ""chrXjh806597fix"" ""107"" ""chrXjh806599fix"" ""108"" ""chrXjh806600fix"" ""109"" ""chrXjh806601fix"" ""110"" ""chrXkb021648_fix"" ""111"" ""chrY""

**If anyone have any clues, please let me know. Your help is much appreciated. Thank you so much!**

sessionInfo()
R version 3.5.2 (2018-12-20)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17134)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252    

attached base packages:
[1] parallel  stats4    stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] cowplot_0.9.4          reshape_0.8.8          ggplot2_3.1.0          clusterProfiler_3.10.1 GenomicFeatures_1.34.1
 [6] GenomicRanges_1.34.0   GenomeInfoDb_1.18.1    org.Hs.eg.db_3.7.0     AnnotationDbi_1.44.0   IRanges_2.16.0        
[11] S4Vectors_0.20.1       Biobase_2.42.0         BiocGenerics_0.28.0    ChIPseeker_1.18.0",AlanchenJP,https://github.com/Bioconductor/GenomicFeatures/issues/14,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU0MjA2Mzc2NjU=,makeFeatureDbFromUCSC  not populating database correctly,CLOSED,2019-03-13T17:51:30Z,2019-03-25T16:52:13Z,2019-03-25T14:43:57Z,"See the details in the following support site post:
https://support.bioconductor.org/p/119066/

as James pointed out the `.adjustChromStarts` function reorders the columns. 
and as I pointed out the `insert_data_into_table` doesn't take into account a different ordering and populates the database incorrectly
",lshep,https://github.com/Bioconductor/GenomicFeatures/issues/15,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU0MzMzMTYwOTI=,makeTxDbFromUCSC fails with with RMariaDB error,CLOSED,2019-04-15T14:33:00Z,2019-08-27T19:55:59Z,2019-08-27T19:55:59Z,"```
> makeTxDbFromUCSC()
Download the knownGene table ... Error in result_fetch(res@ptr, n = n) : Error fetching buffer: 
OK
```
I googled it and it pointed me to connector/c libs in MariaDb. On Debian I have libmariadb-dev 10.3.13 and libmariadb-dev-compat 10.3.13 installed. On Arch I have mariadb-libs 10.3.14 installed. I am not using RMariaDb directly and do not intend to.
I installed github version of RMariaDb, now the error message changed slightly:
```
> makeTxDbFromUCSC()
Download the knownGene table ... Error: Error fetching buffer:
OK
```
I have also installed github version of Bioconductor/GenomicFeatures. It did not change anything
I ran out of ideas. Is there a workaroud? Can I use sqlite instead?

```
> traceback()
11: stop(list(message = ""Error fetching buffer: "", call = result_fetch(res@ptr, 
        n = n), cppstack = list(file = """", line = -1L, stack = c(""/usr/local/lib/R/site-library/RMariaDB/libs/RMariaDB.so(Rcpp::exception::exception(char const*, bool)+0x74) [0x7f37a7770064]"", 
    ""/usr/local/lib/R/site-library/RMariaDB/libs/RMariaDB.so(void Rcpp::stop<char const*>(char const*, char const*&&)+0x4f) [0x7f37a7771cdf]"", 
    ""/usr/local/lib/R/site-library/RMariaDB/libs/RMariaDB.so(+0x22535) [0x7f37a777a535]"", 
    ""/usr/local/lib/R/site-library/RMariaDB/libs/RMariaDB.so(MariaRow::value_string(int)+0x3a) [0x7f37a777a57a]"", 
    ""/usr/local/lib/R/site-library/RMariaDB/libs/RMariaDB.so(MariaRow::set_list_value(SEXPREC*, int, int)+0x117) [0x7f37a777a777]"", 
    ""/usr/local/lib/R/site-library/RMariaDB/libs/RMariaDB.so(MariaResultPrep::fetch(int)+0x1b0) [0x7f37a7777c80]"", 
    ""/usr/local/lib/R/site-library/RMariaDB/libs/RMariaDB.so(DbResult::fetch(int)+0x3d) [0x7f37a77744ed]"", 
    ""/usr/local/lib/R/site-library/RMariaDB/libs/RMariaDB.so(result_fetch(DbResult*, int)+0x1d) [0x7f37a77864dd]"", 
    ""/usr/local/lib/R/site-library/RMariaDB/libs/RMariaDB.so(_RMariaDB_result_fetch+0x61) [0x7f37a7781941]"", 
    ""/usr/lib/R/lib/libR.so(+0x12da6c) [0x7f37b7365a6c]"", ""/usr/lib/R/lib/libR.so(Rf_eval+0x190) [0x7f37b7370170]"", 
    ""/usr/lib/R/lib/libR.so(+0x139d9f) [0x7f37b7371d9f]"", ""/usr/lib/R/lib/libR.so(Rf_eval+0x347) [0x7f37b7370327]"", 
    ""/usr/lib/R/lib/libR.so(+0x13c988) [0x7f37b7374988]"", ""/usr/lib/R/lib/libR.so(Rf_eval+0x5c9) [0x7f37b73705a9]"", 
    ""/usr/lib/R/lib/libR.so(+0x13b756) [0x7f37b7373756]"", ""/usr/lib/R/lib/libR.so(Rf_eval+0x5c9) [0x7f37b73705a9]"", 
    ""/usr/lib/R/lib/libR.so(+0x139d9f) [0x7f37b7371d9f]"", ""/usr/lib/R/lib/libR.so(+0x12edbe) [0x7f37b7366dbe]"", 
    ""/usr/lib/R/lib/libR.so(Rf_eval+0x190) [0x7f37b7370170]"", ""/usr/lib/R/lib/libR.so(+0x139d9f) [0x7f37b7371d9f]"", 
    ""/usr/lib/R/lib/libR.so(R_execMethod+0x25a) [0x7f37b7372eba]"", 
    ""/usr/lib/R/library/methods/libs/methods.so(+0x4efd) [0x7f37b1584efd]"", 
    ""/usr/lib/R/lib/libR.so(+0x17a2cc) [0x7f37b73b22cc]"", ""/usr/lib/R/lib/libR.so(+0x128282) [0x7f37b7360282]"", 
    ""/usr/lib/R/lib/libR.so(Rf_eval+0x190) [0x7f37b7370170]"", ""/usr/lib/R/lib/libR.so(+0x139d9f) [0x7f37b7371d9f]"", 
    ""/usr/lib/R/lib/libR.so(Rf_eval+0x347) [0x7f37b7370327]"", ""/usr/lib/R/lib/libR.so(+0x13b756) [0x7f37b7373756]"", 
    ""/usr/lib/R/lib/libR.so(Rf_eval+0x5c9) [0x7f37b73705a9]"", ""/usr/lib/R/lib/libR.so(+0x139d9f) [0x7f37b7371d9f]"", 
    ""/usr/lib/R/lib/libR.so(+0x12edbe) [0x7f37b7366dbe]"", ""/usr/lib/R/lib/libR.so(Rf_eval+0x190) [0x7f37b7370170]"", 
    ""/usr/lib/R/lib/libR.so(+0x139d9f) [0x7f37b7371d9f]"", ""/usr/lib/R/lib/libR.so(R_execMethod+0x25a) [0x7f37b7372eba]"", 
    ""/usr/lib/R/library/methods/libs/methods.so(+0x4efd) [0x7f37b1584efd]"", 
    ""/usr/lib/R/lib/libR.so(+0x17a2cc) [0x7f37b73b22cc]"", ""/usr/lib/R/lib/libR.so(+0x128282) [0x7f37b7360282]"", 
    ""/usr/lib/R/lib/libR.so(Rf_eval+0x190) [0x7f37b7370170]"", ""/usr/lib/R/lib/libR.so(+0x139d9f) [0x7f37b7371d9f]"", 
    ""/usr/lib/R/lib/libR.so(+0x12edbe) [0x7f37b7366dbe]"", ""/usr/lib/R/lib/libR.so(Rf_eval+0x190) [0x7f37b7370170]"", 
    ""/usr/lib/R/lib/libR.so(+0x139d9f) [0x7f37b7371d9f]"", ""/usr/lib/R/lib/libR.so(+0x12edbe) [0x7f37b7366dbe]"", 
    ""/usr/lib/R/lib/libR.so(Rf_eval+0x190) [0x7f37b7370170]"", ""/usr/lib/R/lib/libR.so(+0x139d9f) [0x7f37b7371d9f]"", 
    ""/usr/lib/R/lib/libR.so(+0x12edbe) [0x7f37b7366dbe]"", ""/usr/lib/R/lib/libR.so(Rf_eval+0x190) [0x7f37b7370170]"", 
    ""/usr/lib/R/lib/libR.so(+0x139d9f) [0x7f37b7371d9f]"", ""/usr/lib/R/lib/libR.so(Rf_eval+0x347) [0x7f37b7370327]"", 
    ""/usr/lib/R/lib/libR.so(Rf_ReplIteration+0x2a2) [0x7f37b73a0722]"", 
    ""/usr/lib/R/lib/libR.so(+0x168ad1) [0x7f37b73a0ad1]"", ""/usr/lib/R/lib/libR.so(run_Rmainloop+0x48) [0x7f37b73a0b88]"", 
    ""/usr/lib/R/bin/exec/R(main+0x1b) [0x56407ed7207b]"", ""/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb) [0x7f37b6ff409b]"", 
    ""/usr/lib/R/bin/exec/R(_start+0x2a) [0x56407ed720ba]""))))
10: result_fetch(res@ptr, n = n)
9: .local(res, n, ...)
8: dbFetch(rs, n = n, ...)
7: dbFetch(rs, n = n, ...)
6: .local(conn, statement, ...)
5: dbGetQuery(dbconn, SQL)
4: dbGetQuery(dbconn, SQL)
3: UCSC_dbselect(genome, tablename, columns = columns, where = where)
2: .fetch_UCSC_txtable(genome(session), tablename, transcript_ids = transcript_ids)
1: makeTxDbFromUCSC()
```

```
> sessionInfo()
R version 3.5.2 (2018-12-20)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Debian GNU/Linux buster/sid

Matrix products: default
BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3
LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so

locale:
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_DK.UTF-8        LC_COLLATE=C              
 [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8   
 [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] parallel  stats4    stats     graphics  grDevices utils     datasets 
[8] methods   base     

other attached packages:
[1] GenomicFeatures_1.34.6 GenomicRanges_1.34.0   GenomeInfoDb_1.18.2   
[4] AnnotationDbi_1.44.0   IRanges_2.16.0         S4Vectors_0.20.1      
[7] Biobase_2.42.0         BiocGenerics_0.28.0   

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.1                  compiler_3.5.2             
 [3] XVector_0.22.0              prettyunits_1.0.2          
 [5] bitops_1.0-6                tools_3.5.2                
 [7] zlibbioc_1.28.0             progress_1.2.0             
 [9] biomaRt_2.38.0              digest_0.6.18              
[11] bit_1.1-14                  lattice_0.20-38            
[13] RSQLite_2.1.1               memoise_1.1.0              
[15] pkgconfig_2.0.2             rlang_0.3.2                
[17] Matrix_1.2-17               DelayedArray_0.8.0         
[19] DBI_1.0.0                   GenomeInfoDbData_1.2.0     
[21] RMariaDB_1.0.6              rtracklayer_1.42.2         
[23] stringr_1.4.0               httr_1.4.0                 
[25] Biostrings_2.50.2           hms_0.4.2                  
[27] grid_3.5.2                  bit64_0.9-7                
[29] R6_2.4.0                    XML_3.98-1.19              
[31] BiocParallel_1.16.6         blob_1.1.1                 
[33] magrittr_1.5                matrixStats_0.54.0         
[35] GenomicAlignments_1.18.1    Rsamtools_1.34.1           
[37] SummarizedExperiment_1.12.0 assertthat_0.2.1           
[39] stringi_1.4.3               RCurl_1.95-4.12            
[41] crayon_1.3.4 
```

EDIT: I just booted a Windows machine and tested there. No errors. I got a txDb object.
",balwierz,https://github.com/Bioconductor/GenomicFeatures/issues/16,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU0ODU5OTczODQ=,threeUTRsByTranscript per gene,CLOSED,2019-08-27T19:41:24Z,2019-08-27T19:49:48Z,2019-08-27T19:49:47Z,"How do I get the 3' UTR sequence per gene rather than transcript? Online resources suggest using columns=""gene_name"" parameter but it doesn't seem to be functional anymore.",asmagen,https://github.com/Bioconductor/GenomicFeatures/issues/17,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU1Mjk4MjI2MzY=,Crash with failed memory allocation/mapping,CLOSED,2019-11-28T10:24:15Z,2024-03-23T00:54:42Z,2024-03-23T00:54:42Z,"Despite 800 GB from 1 TB RAM available, the program crashes with a segmentation fault.

```
Download the refGene table ...
 *** caught segfault ***
address (nil), cause 'memory not mapped'

Traceback:
 1: result_release(res@ptr)
 2: dbClearResult(rs)
 3: dbClearResult(rs)
 4: dbExecute(conn, ""SET time_zone = '+00:00'"")
 5: dbExecute(conn, ""SET time_zone = '+00:00'"")
 6: .local(drv, ...)
 7: dbConnect(RMariaDB::MariaDB(), dbname = dbname, username = ""genome"",     host = server, port = 3306)
 8: dbConnect(RMariaDB::MariaDB(), dbname = dbname, username = ""genome"",     host = server, port = 3306)
 9: UCSC_dbselect(genome, tablename, columns = columns, where = where)
10: .fetch_UCSC_txtable(genome(session), tablename, transcript_ids = transcript_ids)
11: makeTxDbFromUCSC(genome = ""hg19"", table = ""refGene"")
An irrecoverable exception occurred. R is aborting now ...
```

Could you please print out, how much RAM you tried to allocate?",paulmenzel,https://github.com/Bioconductor/GenomicFeatures/issues/18,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU1NTgxMTMwOTc=,coverageByTranscript weights ?,OPEN,2020-01-31T12:49:34Z,2021-06-25T07:34:16Z,,"For human data, using human NGS reads (1.4GB) as GRanges:

```
# Using reduced data that has a score column for duplicated reads,
#  every unique read is only once.
system.time(withWeights <- coverageByTranscript(a, cds, weight = ""score""))
   user  system elapsed 
  3.987   0.683   4.667 
# Using raw data, without reducing the data-set by not creating 
# a $score column for number of duplicated reads
> system.time(withoutWeights <- coverageByTranscript(b, cds))
   user  system elapsed 
 37.956  21.586  59.547 
> identical(d, dd)
[1] TRUE

```
I just changed the coverageByTranscript function to allow weights, maybe a possible improvement?",Roleren,https://github.com/Bioconductor/GenomicFeatures/issues/19,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU2MzU5NzM0OTk=,How to get promoter  sequences,CLOSED,2020-06-10T06:39:46Z,2020-06-10T16:04:56Z,2020-06-10T16:04:56Z,"Hello, i have a question on the getPromoterSeq function. I have several variants of a particular genome and i wish to get promoters from all of these variants. Is there a way to get promoter sequences from the fasta file of each genome directly without using BSgenome to forge a package.",FritzPeleke,https://github.com/Bioconductor/GenomicFeatures/issues/21,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU2NTAwNTQzNTQ=,makeTxDbFromUCSC fails for hg38,CLOSED,2020-07-02T16:14:55Z,2020-07-10T05:06:03Z,2020-07-10T05:06:03Z,"Hey, I was trying to use the command makeTxDbFromUCSC() on hg38 and it seems to be failing. I'm trying to retrieve the knownGenes. A little investigation, supportedUCSCtables() returns ""knownGeneOld8"", but even specifying that in the tablename argument fails. 

```
TxDb_hg38 <- makeTxDbFromUCSC(genome = ""hg38"", tablename = ""knownGene"")
Error in .tablename2track(tablename, session) : 
  UCSC table ""knownGene"" is not supported
```
```
supportedUCSCtables(genome = ""hg38"")
               tablename          track          subtrack
1          knownGeneOld8 Old UCSC Genes              <NA>
2          knownGeneOld7 Old UCSC Genes              <NA>
3          knownGeneOld6 Old UCSC Genes              <NA>
4          knownGeneOld4 Old UCSC Genes              <NA>
5          knownGeneOld3 Old UCSC Genes              <NA>
6               ccdsGene           CCDS              <NA>
7                refGene    NCBI RefSeq       UCSC RefSeq
8            xenoRefGene   Other RefSeq              <NA>
9                sibGene      SIB Genes              <NA>
10               sgpGene      SGP Genes              <NA>
11                geneid   Geneid Genes              <NA>
12               genscan  Genscan Genes              <NA>
13            ncbiRefSeq    NCBI RefSeq        RefSeq All
14     ncbiRefSeqCurated    NCBI RefSeq    RefSeq Curated
15       ncbiRefSeqOther    NCBI RefSeq      RefSeq Other
16         ncbiRefSeqPsl    NCBI RefSeq RefSeq Alignments
17   ncbiRefSeqPredicted    NCBI RefSeq  RefSeq Predicted
18 ncbiRefSeqGenomicDiff    NCBI RefSeq      RefSeq Diffs
```
```
TxDb_hg38 <- makeTxDbFromUCSC(genome = ""hg38"", tablename = ""knownGeneOld8"")
Error in .tablename2track(tablename, session) : 
  UCSC table ""knownGeneOld8"" does not exist for genome ""hg38"", sorry
```
",Austin-s-h,https://github.com/Bioconductor/GenomicFeatures/issues/22,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU2ODkxMTMyNzg=,Bug in merge_seqinfo_and_infer_missing_seqlengths for GAlignmentPairs,CLOSED,2020-08-31T10:54:59Z,2020-08-31T13:43:51Z,2020-08-31T13:43:51Z,"Forget this, was an error on my end. ",Roleren,https://github.com/Bioconductor/GenomicFeatures/issues/23,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU3ODU0NjMyNjU=,TxDb from NCBI RefSeq GCF_000001405.39_GRCh38.p13 is failing,CLOSED,2021-01-13T21:17:07Z,2023-03-15T17:33:28Z,2023-03-15T17:33:27Z,"I'm trying to load transcript metadata for NCBI `GCF_000001405.39_GRCh38.p13` into a `TxDb` object. GenomicFeatures is currently having trouble parsing the build from RefSeq:

```r
packageVersion(""GenomicFeatures"")
## [1] 1.42.1
library(GenomicFeatures)
file <- ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13/GCF_000001405.39_GRCh38.p13_genomic.gtf.gz""
txdb <- makeTxDbFromGFF(file = file)
```

```
Import genomic features from the file as a GRanges object ... trying URL 'ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13/GCF_000001405.39_GRCh38.p13_genomic.gtf.gz'
Content type 'unknown' length 41463702 bytes (39.5 MB)
==================================================
OK
Prepare the 'metadata' data frame ... OK
Make the TxDb object ... Warning in .get_cds_IDX(mcols0$type, mcols0$phase) :
  The ""phase"" metadata column contains non-NA values for features of type
  stop_codon. This information was ignored.
Calls: makeTxDbFromGFF -> makeTxDbFromGRanges -> .get_cds_IDX
Error in .make_splicings(exons, cds, stop_codons) :
  some CDS cannot be mapped to an exon
Calls: makeTxDbFromGFF -> makeTxDbFromGRanges -> .make_splicings
```",mjsteinbaugh,https://github.com/Bioconductor/GenomicFeatures/issues/26,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU3OTMzODk1MDU=,Large discrepancy seen when parsing Ensembl GTF vs. GFF3 files,CLOSED,2021-01-25T13:37:52Z,2021-03-12T16:56:41Z,2021-03-12T16:56:41Z,"`TxDb` generation currently differs quite significantly between Ensembl GTF and GFF3 files. Parsing the files directly with rtracklayer can return the same number of genes and transcripts in the Ensembl GFF3 file as seen in the GTF, which is correct.

```r
suppressPackageStartupMessages({
    library(GenomicFeatures)
})
gtf <- paste0(
    ""ftp://ftp.ensembl.org/pub/release-102/gtf/"",
    ""homo_sapiens/Homo_sapiens.GRCh38.102.gtf.gz""
)
gff3 <- paste0(
    ""ftp://ftp.ensembl.org/pub/release-102/gff3/"",
    ""homo_sapiens/Homo_sapiens.GRCh38.102.gff3.gz""
)
suppressWarnings({
    suppressMessages({
        txdb_gtf <- makeTxDbFromGFF(file = gtf)
        txdb_gff3 <- makeTxDbFromGFF(file = gff3)
    })
})

print(txdb_gtf)
## TxDb object:
## # Db type: TxDb
## # Supporting package: GenomicFeatures
## # Data source: ftp://ftp.ensembl.org/pub/release-102/gtf/homo_sapiens/Homo_sapiens.GRCh38.102.gtf.gz
## # Organism: Homo sapiens
## # Taxonomy ID: 9606
## # miRBase build ID: NA
## # Genome: NA
## # Nb of transcripts: 232024
## # Db created by: GenomicFeatures package from Bioconductor
## # Creation time: 2021-01-25 08:31:27 -0500 (Mon, 25 Jan 2021)
## # GenomicFeatures version at creation time: 1.42.1
## # RSQLite version at creation time: 2.2.3
## # DBSCHEMAVERSION: 1.2

print(txdb_gff3)
## TxDb object:
## # Db type: TxDb
## # Supporting package: GenomicFeatures
## # Data source: ftp://ftp.ensembl.org/pub/release-102/gff3/homo_sapiens/Homo_sapiens.GRCh38.102.gff3.gz
## # Organism: Homo sapiens
## # Taxonomy ID: 9606
## # miRBase build ID: NA
## # Genome: NA
## # Nb of transcripts: 230447
## # Db created by: GenomicFeatures package from Bioconductor
## # Creation time: 2021-01-25 08:32:59 -0500 (Mon, 25 Jan 2021)
## # GenomicFeatures version at creation time: 1.42.1
## # RSQLite version at creation time: 2.2.3
## # DBSCHEMAVERSION: 1.2

length(genes(txdb_gtf))
## [1] 60675
## CORRECT.

suppressMessages({
    length(genes(txdb_gff3))
})
## [1] 35216
## INCORRECT.

length(transcripts(txdb_gtf))
## [1] 232024
## CORRECT.

length(transcripts(txdb_gff3))
## [1] 230447
## INCORRECT.
```",mjsteinbaugh,https://github.com/Bioconductor/GenomicFeatures/issues/28,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU4MDEyMDAxNTc=,Unable to parse bacterial GFF files,CLOSED,2021-02-04T11:35:39Z,2022-05-11T01:51:31Z,2022-05-11T01:51:31Z,"When trying to import a gff for Mycobacterium tuberculosis from the NCBI, the following error is received:

Import genomic features from the file as a GRanges object ... OK
Prepare the 'metadata' data frame ... OK
Make the TxDb object ... OK
Warning message:
In .extract_transcripts_from_GRanges(tx_IDX, gr, mcols0$type, mcols0$ID,  :
  The following transcripts have multiple parts that were merged: gene-Rv3216

Code:

txdb <-makeTxDbFromGFF(""/path/to/file/GCA_000195955.2_ASM19595v2_genomic.gff"", organism=""Mycobacterium tuberculosis"")

Link to annotation and genome:

https://www.ncbi.nlm.nih.gov/assembly/GCF_000195955.2/
",jambler24,https://github.com/Bioconductor/GenomicFeatures/issues/30,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU4NTUxODg3Njg=,Get gene_name column from GENCODE GTF?,CLOSED,2021-04-11T00:45:22Z,2021-04-12T11:56:52Z,2021-04-12T11:56:51Z,"Hi, I wonder whether it's possible to import columns other than ""gene_id"" from a GTF file to a TxDb?
To be specific, what I'm doing now is:
```r
gencode <- makeTxDbFromGFF(""gencode.gtf"", format = ""gtf"")
gene_gr <- genes(gencode, columns = ""gene_id"")
```
I want to do
```r
gene_gr <- genes(gencode, columns = c(""gene_id"", ""gene_name""))
```

The `gene_name` entry in GENCODE GTF is basically the gene symbol. I want to have both information so I can work on ENSG ID and also to look at the gene symbol at the same time to get a better sense of the genes.

Right now it seems impossible to do this, or is there a way to do it?

Thanks in advance!",Zepeng-Mu,https://github.com/Bioconductor/GenomicFeatures/issues/31,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU5NDIxMzQ2MTY=,Fail to add stop_codon through makeTxDbFromGRanges,CLOSED,2021-07-12T14:39:37Z,2021-08-27T02:12:12Z,2021-08-27T02:12:12Z,"Hi,
    I'm not sure the function of drop.stop.codons in makeTxDbFromGRanges. 
    I could not add stop_codon to TxDb, when drop.stop.codons is FALSE.
    Thanks in advance.
Best wishes,
Liu",ggoodstudydaydayup,https://github.com/Bioconductor/GenomicFeatures/issues/32,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWU5NzA5NjA4NTA=,protein_coding_gene not recognized as valid gene feature,CLOSED,2021-08-14T17:28:43Z,2021-08-17T02:33:13Z,2021-08-17T02:33:13Z,"This genome from fungiDB:

https://fungidb.org/fungidb/app/record/dataset/NCBITAXON_235443

uses ""protein_coding_gene"" one of 3 top level features in column 3 of the gff3. The others are ncRNA_gene and pseudogene.

`makeTxDbFromGff` seems to recognize ncRNA_gene and pseudogene, but does not recognize protein_coding_gene. When I substituted 'gene' for 'protein_coding_gene' in the gff, `makeTxDbFromGff` worked as expected and parsed the gff correctly.

I'm actually not sure what the generally accepted source of truth is for the feature ontology, but I use this site:

http://www.sequenceontology.org/browser/current_release/term/SO:0001217

which indicates that protein_coding_gene is a valid feature at the same level as ncRNA_gene and pseudogene.

I can see this being addressed either in the code -- by adding protein_coding_gene as a 'gene' equivalent -- or in the documentation to make it clear what the expected ontology is.",cmatKhan,https://github.com/Bioconductor/GenomicFeatures/issues/33,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs8491z-o,`makeTxDbFromUCSC` fails with `!anyNA(m32) is not TRUE`,CLOSED,2021-10-27T14:47:50Z,2021-11-05T13:20:23Z,2021-11-05T13:20:23Z,"Hi,

I've been trying to create a txdb file with

```r
txdb_hg38 <- makeTxDbFromUCSC(genome = ""hg38"", tablename = ""knownGene"")
```

It fails with an output

```r
> txdb_hg38 <- makeTxDbFromUCSC(genome = ""hg38"", tablename = ""knownGene"")
Download the knownGene table ... OK
Download the knownToLocusLink table ... OK
Extract the 'transcripts' data frame ... OK
Extract the 'splicings' data frame ... Warning in .extract_cds_locs_from_UCSC_txtable(ucsc_txtable) :
  UCSC data anomaly in 21969 transcript(s): the cds cumulative length is not a multiple of 3 for transcripts
  ENST00000341065.8 ENST00000455979.1 ENST00000466300.1 ENST00000624652.1 ENST00000434641.5
  ENST00000462097.5 ENST00000475119.5 ENST00000480643.1 ENST00000673999.1 ENST00000486379.1
  ENST00000403997.2 ENST00000509720.5 ENST00000422076.5 ENST00000488418.2 ENST00000379099.3
  ENST00000467712.1 ENST00000527383.5 ENST00000434694.6 ENST00000527719.5 ENST00000530031.5
  ENST00000534345.5 ENST00000498476.6 ENST00000470679.3 ENST00000525285.1 ENST00000488011.1
  ENST00000482621.5 ENST00000497013.1 ENST00000475091.2 ENST00000339113.9 ENST00000400830.4
  ENST00000510793.5 ENST00000503789.5 ENST00000514234.5 ENST00000472264.1 ENST00000435358.5
  ENST00000479362.1 ENST000004 [... truncated]
OK
Download and preprocess the 'chrominfo' data frame ... Error in .order_seqlevels(chrom_sizes[, ""chrom""]) : 
  !anyNA(m32) is not TRUE
OK
```

Traceback:
```r
Error in .order_seqlevels(chrom_sizes[, ""chrom""]) : 
!anyNA(m32) is not TRUE
9.
stop(simpleError(msg, call = if (p <- sys.parent(1L)) sys.call(p)))
8.
stopifnot(!anyNA(m32)) at hg38.R#36
7.
.order_seqlevels(chrom_sizes[, ""chrom""]) at hg38.R#67
6.
GET_CHROM_SIZES(goldenPath.url = goldenPath.url)
5.
.get_chrom_info_for_registered_UCSC_genome(script_path, assembled.molecules.only = assembled.molecules.only, 
map.NCBI = map.NCBI, add.ensembl.col = add.ensembl.col, goldenPath.url = goldenPath.url, 
recache = recache)
4.
getChromInfoFromUCSC(genome, goldenPath.url = goldenPath.url)
3.
.make_UCSC_chrominfo(genome, circ_seqs, goldenPath.url)
2.
.make_TxDb_from_UCSC_txtable(ucsc_txtable, txname2geneid$genes, 
genome, tablename, track, txname2geneid$gene_id_type, full_dataset = is.null(transcript_ids), 
circ_seqs = circ_seqs, goldenPath.url = goldenPath.url, taxonomyId = taxonomyId, 
miRBaseBuild = miRBaseBuild)
1.
makeTxDbFromUCSC(genome = ""hg38"", tablename = ""knownGene"")
```

Platform and R versions. The package version is the latest.
```
> version                     
platform       x86_64-conda-linux-gnu      
arch           x86_64                      
os             linux-gnu                   
system         x86_64, linux-gnu           
...             
version.string R version 4.1.1 (2021-08-10)
```

It's the first time I'm using this package (I need it to run `ORFik`).
Any help will be appreciated!
",edikedik,https://github.com/Bioconductor/GenomicFeatures/issues/34,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs84-vCWs,Why 'downstream' is set to 200 by default in getPromoterSeq(),CLOSED,2021-11-13T02:04:29Z,2022-05-07T16:01:12Z,2022-05-06T19:16:10Z,"@paul-shannon Paul?

https://support.bioconductor.org/p/9140532/#9140650

Thanks,
H.

",hpages,https://github.com/Bioconductor/GenomicFeatures/issues/35,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs84-yB0m,"makeTxDbFromGFF() how to handle entries lacking or duplicated ""transcript_id"" attribute  ",CLOSED,2021-11-15T07:24:46Z,2021-11-15T23:17:16Z,2021-11-15T23:12:05Z,"Hi, I'm getting these warnings when making a TxDb from a gff, which I rather avoid for my downstream analyses. 
How should I handle these instances, especially the ones that carry out as NA?
I checked and these entries are indeed there in the gff. I would rather save them if at all possible, but also ok with dropping the ones containing NA in the next step of my pipe `txdb.cds_by_transcript <- cdsBy(txdb, by=""tx"", use.names = TRUE) %>% drop_na(cds_name)` but `drop_na()` it's not applicable to that kind of object either.
```
> txdb <- makeTxDbFromGFF(""BFgenomic.gff"", format=""gff"")
Import genomic features from the file as a GRanges object ... OK
Prepare the 'metadata' data frame ... OK
Make the TxDb object ... OK
Warning messages:
1: In .extract_transcripts_from_GRanges(tx_IDX, gr, mcols0$type, mcols0$ID,  :
  some transcripts have no ""transcript_id"" attribute ==> their name (""tx_name"" column in
  the TxDb object) was set to NA
2: In .extract_transcripts_from_GRanges(tx_IDX, gr, mcols0$type, mcols0$ID,  :
  the transcript names (""tx_name"" column in the TxDb object) imported from the
  ""transcript_id"" attribute are not unique
```
Thank you,
-madza ",madzafv,https://github.com/Bioconductor/GenomicFeatures/issues/36,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85AIY0L,GENE IDs are not loaded from UCSC tables using makeTxDbPackageFromUCSC,CLOSED,2021-12-09T19:46:34Z,2021-12-13T21:40:23Z,2021-12-11T10:28:15Z,"Hi,

I am trying to make a TxDb package for sus scrofa using UCSC tables by makeTxDbPackageFromUCSC; but for an unknown reason, the generated package(s) do not have any Gene IDs. Steps to reproduce:
 
```
require(biomaRt)
require(GenomicFeatures)

makeTxDbPackageFromUCSC(""0.0.1"", genome = ""susScr11"", tablename=""ncbiRefSeq"", circ_seqs=""chrM"")

```
 OUTPUT:
```
TxDb object:
# Db type: TxDb
# Supporting package: GenomicFeatures
# Data source: UCSC
# Genome: susScr11
# Organism: Sus scrofa
# Taxonomy ID: 9823
# UCSC Table: ncbiRefSeq
# UCSC Track: NCBI RefSeq
# Resource URL: http://genome.ucsc.edu/
# Type of Gene ID: no gene ids
# Full dataset: yes
# miRBase build ID: NA
# Nb of transcripts: 77708
# Db created by: GenomicFeatures package from Bioconductor
# Creation time: 2021-12-08 10:10:57 -0800 (Wed, 08 Dec 2021)
# GenomicFeatures version at creation time: 1.42.3
# RSQLite version at creation time: 2.2.4
# DBSCHEMAVERSION: 1.2

```

```
install.packages(""TxDb.Sscrofa.UCSC.susScr11.ncbiRefSeq"", repos = NULL, type = ""source"")


require(TxDb.Sscrofa.UCSC.susScr11.ncbiRefSeq)
txdb <- TxDb.Sscrofa.UCSC.susScr11.ncbiRefSeq
k <- keys(txdb, keytype = ""TXNAME"")
tx2gene <- select(txdb, k, ""GENEID"", ""TXNAME"")
head(tx2gene)

```

OUTPUT:
```
          TXNAME GENEID
1 XM_021085497.1   <NA>
2 NM_001244353.1   <NA>
3 XM_003353151.4   <NA>
4 XM_013992416.2   <NA>
5 XM_021085522.1   <NA>
6 XM_005659096.3   <NA>
```

I know in the UCSC table(s) listed here, there are GENE IDs: 

- ncbiRefSeq: [Details here](https://genome.ucsc.edu/cgi-bin/hgTables?db=susScr11&hgta_group=genes&hgta_track=refSeqComposite&hgta_table=ncbiRefSeq&hgta_doSchema=1)
- ncbiRefSeqPredicted: [Details here](https://genome.ucsc.edu/cgi-bin/hgTables?hgsid=1232667219_0KJa2AQ4SX3vlVusxbdQATrAn6rk&hgta_doSchemaDb=susScr11&hgta_doSchemaTable=ncbiRefSeqPredicted)

```
> sessionInfo()
R version 4.0.4 (2021-02-15)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19044)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] parallel  stats4    stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] TxDb.Sscrofa.UCSC.susScr11.ncbiRefSeq_0.0.1         
 [2] TxDb.Sscrofa.UCSC.susScr11.ncbiRefSeqPredicted_0.0.1
 [3] GenomicFeatures_1.42.3                              
 [4] AnnotationDbi_1.52.0                                
 [5] Biobase_2.50.0                                      
 [6] rtracklayer_1.49.5                                  
 [7] GenomicRanges_1.42.0                                
 [8] GenomeInfoDb_1.26.4                                 
 [9] IRanges_2.24.1                                      
[10] S4Vectors_0.28.1                                    
[11] BiocGenerics_0.36.0                                 

loaded via a namespace (and not attached):
 [1] MatrixGenerics_1.2.1        httr_1.4.2                  splines_4.0.4              
 [4] bit64_4.0.5                 R.utils_2.10.1              assertthat_0.2.1           
 [7] DO.db_2.9                   askpass_1.1                 BiocManager_1.30.15        
[10] BiocFileCache_1.14.0        blob_1.2.1                  GenomeInfoDbData_1.2.4     
[13] Rsamtools_2.6.0             progress_1.2.2              pillar_1.6.1               
[16] RSQLite_2.2.4               lattice_0.20-41             glue_1.4.2                 
[19] XVector_0.30.0              qvalue_2.22.0               colorspace_2.0-1           
[22] R.oo_1.24.0                 plyr_1.8.6                  Matrix_1.3-4               
[25] XML_3.99-0.6                pkgconfig_2.0.3             biomaRt_2.46.3             
[28] zlibbioc_1.36.0             purrr_0.3.4                 GO.db_3.12.1               
[31] scales_1.1.1                BiocParallel_1.24.1         tibble_3.1.0               
[34] openssl_1.4.4               generics_0.1.0              ggplot2_3.3.3              
[37] ellipsis_0.3.2              cachem_1.0.4                SummarizedExperiment_1.20.0
[40] magrittr_2.0.1              crayon_1.4.1                memoise_2.0.0              
[43] DOSE_3.16.0                 R.methodsS3_1.8.1           fansi_0.4.2                
[46] xml2_1.3.2                  RMariaDB_1.1.2              tools_4.0.4                
[49] data.table_1.14.0           prettyunits_1.1.1           hms_1.0.0                  
[52] lifecycle_1.0.0             matrixStats_0.58.0          stringr_1.4.0              
[55] munsell_0.5.0               DelayedArray_0.16.3         Biostrings_2.58.0          
[58] compiler_4.0.4              rlang_0.4.10                grid_4.0.4                 
[61] RCurl_1.98-1.3              rstudioapi_0.13             rappdirs_0.3.3             
[64] bitops_1.0-6                gtable_0.3.0                DBI_1.1.1                  
[67] curl_4.3                    reshape2_1.4.4              R6_2.5.0                   
[70] lubridate_1.7.10            gridExtra_2.3               GenomicAlignments_1.26.0   
[73] dplyr_1.0.6                 fastmap_1.1.0               bit_4.0.4                  
[76] utf8_1.2.1                  fastmatch_1.1-0             fgsea_1.16.0               
[79] stringi_1.6.2               GOSemSim_2.16.1             Rcpp_1.0.7                 
[82] vctrs_0.3.8                 dbplyr_2.1.1                tidyselect_1.1.1   
```

Is this a bug or am I doing something wrong? 

Thank you.",farshadf,https://github.com/Bioconductor/GenomicFeatures/issues/37,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85A1xFS,makeTxDbFromUCSC failing on check of txtable,CLOSED,2021-12-23T16:06:57Z,2021-12-23T23:14:34Z,2021-12-23T16:23:48Z,"DBI/RMariaDB is now returning a `blob` instead of a `list` for the exon starts and stops, so the check that the exon starts and stops column are `list` is failing.",jmacdon,https://github.com/Bioconductor/GenomicFeatures/issues/38,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85BeYcq,promoters() returns out of range indicies,CLOSED,2022-01-10T23:14:08Z,2022-01-11T02:13:32Z,2022-01-11T02:13:32Z,"Should `promoters()` be allowed to return negative indicies?


When trying to use `getPromoterSeq()`, I received the following error:

```
Error in value[[3L]](cond) : 
   record 6097 (CP022322.1:-380-19) was truncated
  file: /home/chase/projects/brentlab/kn99_database/genome_files/kn99/KN99_fungiDB/FungiDB-53_CneoformansKN99_Genome.fasta
```

Upon inspecting the promoter regions with the same setting , `upstream = 400`, as I had used in `getPromoterSeq`, I discovered that there are two genes which, with this promoter definition, return negative values due to the fact that they are annotated at the very beginning of the chromosome such that 400bp upstream causes the promoter range to be returned as a negative value:

```
> promoters[promoters@ranges@start < 0]
GRanges object with 2 ranges and 2 metadata columns:
                      seqnames    ranges strand |     tx_id           tx_name
                         <Rle> <IRanges>  <Rle> | <integer>       <character>
  CKF44_06802-t26_1 CP022322.1  -380-219      + |      1106 CKF44_06802-t26_1
  CKF44_09000-t26_1 CP022335.1  -380-219      + |      9174 CKF44_09000-t26_1 
```

I confirmed that this was, in fact, the cause of the error in  `getPromoterSeq()` by setting `upstream` to 20 or less, so that no negative values are returned, and  `getPromoterSeq()` returned without error.

Possibly in the `promoters` function, a warning should be issued? Alternatively, if the definition of the promoter places the upstream/downstream indicies out of range of the chromosome, maybe setting to the chromosome limit (0 or length(chromosome)) would be appropriate? Maybe this should be an argument, something like, `handle_out_of_bound_indicies = TRUE` by default?",cmatKhan,https://github.com/Bioconductor/GenomicFeatures/issues/40,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85B6pxG,error unknown,CLOSED,2022-01-17T14:01:34Z,2022-01-20T03:40:44Z,2022-01-20T03:40:44Z,"tried
`db <- makeFeatureDbFromUCSC(genome=""hg38"",tablename=""ncbiRefSeq"",track=""NCBI RefSeq"")`
got
`Error: near ""'none'"": syntax error`
same effect with
`UCSCFeatureDbTableSchema()`
although supported by
`supportedUCSCFeatureDbTables(genome=""hg38"", track=""NCBI RefSeq"") `",under-score,https://github.com/Bioconductor/GenomicFeatures/issues/41,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85GB2oA,exonsBy Option to Resize Exons for Splicing Donor and Acceptor Regions,CLOSED,2022-03-21T05:00:03Z,2022-03-22T04:44:23Z,2022-03-22T04:44:23Z,"Could `exonsBy` get an option that resizes the exons so that the GT/AG donor/acceptor regions are also included (i.e. two bases into the introns)? This would involve special handing of the first and last exon. Then, the resulting list would be directly useful as the `which` parameter for `ScanVcfParam` if attempting to annotate coding and splice site mutations with whole genome sequencing data but wanting to avoid all of the variants that are intronic or intergenic for computation time.",DarioS,https://github.com/Bioconductor/GenomicFeatures/issues/43,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85IZNpo,threeUTRsByTranscript() and fiveUTRsByTranscript() are not working correctly on minus strand,CLOSED,2022-04-25T14:08:19Z,2023-03-15T17:25:16Z,2023-03-15T17:25:16Z,"After making txdb out of a GTF file, when making UTR ranges of a gene on minus strand, the functions switch 3UTR and 5UTR around and only return a single exon. Additionally, if the UTR is composed of a single exon, it's not shown at all. I've attached example GTF files containing a single gene:

[good_UTRs_plus_strand.gtf.txt](https://github.com/Bioconductor/GenomicFeatures/files/8555213/good_UTRs_plus_strand.gtf.txt) - works well
[bad_UTRs_minus_strand.gtf.txt](https://github.com/Bioconductor/GenomicFeatures/files/8555211/bad_UTRs_minus_strand.gtf.txt) - switches UTRs
[bad_UTRs_minus_strand_single_exon.gtf.txt](https://github.com/Bioconductor/GenomicFeatures/files/8555212/bad_UTRs_minus_strand_single_exon.gtf.txt)  - returns no UTRs

This is the code I run:
```
ref_gff_file_fixed = file.path(WORK_FOLDER,'/bad_UTRs_minus_strand_single_exon.gtf')
txdb = makeTxDbFromGFF(ref_gff_file_fixed,chrominfo = chrominfo)
threeUTRs_by_tx = threeUTRsByTranscript(txdb,use.names=T)
fiveUTRs_by_tx = fiveUTRsByTranscript(txdb,use.names=T)
```

R version 3.6.3 (2020-02-29)
package version: 1.38.2

Thanks!",anmej,https://github.com/Bioconductor/GenomicFeatures/issues/44,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85IcsVe,ExtractTranscriptSeqs extracted sequences with non-base,CLOSED,2022-04-26T06:48:22Z,2022-04-26T15:22:52Z,2022-04-26T15:22:51Z,"Hi, 

I want to use extractTranscriptSeqs to extract the CDS sequence corresponding to SNP and get the corresponding protein sequence, and the following is my code:
```
ref_genome <- BSgenome.Hsapiens.UCSC.hg38
alt_genome <- injectSNPs(ref_genome, SNPlocs.Hsapiens.dbSNP141.GRCh38)

cds<-cdsBy(txdb, by=""tx"", use.names=TRUE)
extractcds<-extractTranscriptSeqs(alt_genome,cds)
```
I found that if I do this, the final sequence will have many non-bases, such as ""R"", ""W"", ""S"", etc. I don't understand what kind of information these letters represent? How should I modify the code if I want to use the translate function of Biostrings?

Thanks,
LeeLee",lbwfff,https://github.com/Bioconductor/GenomicFeatures/issues/45,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85IyRwz,How to find the reference to an organism in the organism database?,CLOSED,2022-04-29T15:53:59Z,2022-04-29T16:27:35Z,2022-04-29T16:05:46Z,"Hi - I've created a txdb object using makeTxDbFromEnsembl(organism = ""Equus caballus"", release=103) but I can't create a gene annotation file from this. Specifically, I'm using the ArchR function createGeneAnnotation which has as parameters the txdb object previously created and OrgDb, which their docs says is ""An OrgDb object (organism database) from Bioconductor."" How do I find a list of OrgDb objects (or, better yet, how do I find the name of the object I need for Equus caballus)?",prmunn,https://github.com/Bioconductor/GenomicFeatures/issues/46,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85I9xK_,Find coordinates of all known transcription start and termination sites (TSS TTS) for a gene,CLOSED,2022-05-03T14:04:19Z,2022-06-09T18:52:11Z,2022-06-09T15:11:46Z,"The extractUpstreamSeqs(FaFile, x) function where x is either a transcript-wise or gene-wise GRanges object gives tss_genes metadata column which is expected to give the coordinates of the transcription splice site (TSS) per transcript or gene, depending on the input. However, in case of transcript-wise GRanges as input, this output TSS coordinate is same as the start of the first exon of that transcript, when in fact the TSS must be upstream this loci. [For gene-wise GRanges input, the TSS is the first (i.e. most upstream) of all transcript-wise TSSs.]

Given a list of transcripts of gene (ensembl IDs such as ENSTxxx and ENSGxxx), I wish to find all TSS within that gene and subsequently group transcripts sharing a common TSS. Could you guide me if such an analysis is possible via GenomicFeatures package? Furthermore, could a similar set-up be performed for transcription termination sites (TTS) for transcripts of a gene?",pgupta3005,https://github.com/Bioconductor/GenomicFeatures/issues/47,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85JVIbc,makeTxDbFromBiomart error when querying fungi hosts,CLOSED,2022-05-09T21:34:50Z,2022-05-19T19:03:00Z,2022-05-19T17:47:32Z,"Related to an issue with `useEnsembl`  caching reported at https://github.com/grimbough/biomaRt/issues/64: 

```r
> yeast_txdb <- makeTxDbFromBiomart(biomart=""fungi_mart"",
+                                   dataset=""scerevisiae_eg_gene"",
+                                   host=""https://fungi.ensembl.org"")
Error in useEnsembl(biomart = biomart, dataset = dataset, host = host) : 
  Incorrect BioMart name, use the listMarts function to see which BioMart databases are available
Calls: makeTxDbFromBiomart -> .useMart2 -> useEnsembl
Execution halted
```
",LiNk-NY,https://github.com/Bioconductor/GenomicFeatures/issues/48,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85KiQsK,makeTxDbFromEnsembl for Ensembl AnnotationHub objects?,CLOSED,2022-05-27T08:34:19Z,2022-05-27T16:36:44Z,2022-05-27T16:36:44Z,"Hi,

I was trying to make txdb object from `AnnotationHub` Ensembl releases using the  `makeTxDbFromEnsembl` function, as this is what I thought this function did from its description line.

> The makeTxDbFromEnsembl function creates a TxDb object for a given organism by importing the genomic locations of its transcripts, exons, CDS, and genes from an Ensembl database.

```r
ens106 = AnnotationHub::AnnotationHub()[[""AH100643""]]
txdb = GenomicFeatures::makeTxDbFromEnsembl(ens106)
# Error in .normarg_organism(organism) : 'organism' must be a single string
```

Reading the documentation more carefully (hence the edit), I realize that this function is not supposed to work on `AnnotationHub` objects.

However, would it make sense to provide this functionality?

<details>
<summary>sessionInfo</summary>

```
R version 4.2.0 (2022-04-22)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.4 LTS

other attached packages:
 [1] ensembldb_2.20.1        AnnotationFilter_1.20.0
 [3] GenomicFeatures_1.48.1  AnnotationDbi_1.58.0
 [5] Biobase_2.56.0          GenomicRanges_1.48.0
 [7] GenomeInfoDb_1.32.2     IRanges_2.30.0
 [9] S4Vectors_0.34.0        BiocGenerics_0.42.0
```

</details>",mschubert,https://github.com/Bioconductor/GenomicFeatures/issues/49,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85LLsBR,makeTxDbFromUCSC fails to connect to UCSC server,CLOSED,2022-06-06T05:06:35Z,2022-06-30T23:23:53Z,2022-06-30T23:23:52Z,"Hi, I have been getting this error and am unsure how to resolve it as I don't seem to see anyone else encountering this issue.
```
> hg38.refseq.db <- makeTxDbFromUCSC(genome=""hg38"", table=""refGene"")
Download the refGene table ... Error: Failed to connect: Can't connect to server on 'genome-mysql.soe.ucsc.edu' (10061)
OK
```

Apologies if it is a trivial issue but I have tried updating everything and restarting my sessions yet nothing seems to be working. I don't think it is a wifi issue since I am able to run `browseUCSCtrack(""hg38"", ""refGene"")` fine, though I'm not sure how else to check it. I am currently using GenomicFeatures version 1.48.3 on R version 4.2.0 if it is relevant. ",ameliaregina,https://github.com/Bioconductor/GenomicFeatures/issues/50,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85LmHBq,"makeTxDbFromGFF fails, possibly due to download.file / restfulr?",CLOSED,2022-06-11T13:48:04Z,2023-03-15T17:23:32Z,2023-03-15T17:23:32Z,"Hi wonderful GenomicFeatures people,

Genomic features isn't working as expected for me. We found this through a tximeta step which broke (which I reportted here https://github.com/mikelove/tximeta/issues/65). Hope I have included enough here to figure out what is going on.

> BiocManager::valid()
[1] TRUE

> library(GenomicFeatures)

> txdb <- makeTxDbFromGFF(""ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M28/gencode.vM28.annotation.gtf.gz"") #
Import genomic features from the file as a GRanges object ... Error in (function (classes, fdef, mtable)  : 
  unable to find an inherited method for function 'download.file' for signature '""character""'
> 

restfulr could the problem.

restfulr::download.file(""ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M28/gencode.vM28.annotation.gtf.gz"")
Error in (function (classes, fdef, mtable) :
unable to find an inherited method for function download.file for signature ""character""



> sessionInfo()
R version 4.2.0 (2022-04-22)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Monterey 12.3.1

Matrix products: default
LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib

locale:
[1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8

attached base packages:
[1] stats4    stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] GenomicFeatures_1.49.5 AnnotationDbi_1.59.1   Biobase_2.57.1         GenomicRanges_1.49.0   GenomeInfoDb_1.33.3    IRanges_2.31.0         S4Vectors_0.35.1      
 [8] BiocGenerics_0.43.0    restfulr_0.0.14        tximeta_1.15.0         workflowr_1.7.0       

loaded via a namespace (and not attached):
  [1] rjson_0.2.21                  ellipsis_0.3.2                rprojroot_2.0.3               XVector_0.37.0                fs_1.5.2                     
  [6] rstudioapi_0.13               remotes_2.4.2                 bit64_4.0.5                   interactiveDisplayBase_1.35.0 fansi_1.0.3                  
 [11] xml2_1.3.3                    codetools_0.2-18              tximport_1.25.0               cachem_1.0.6                  knitr_1.39                   
 [16] pkgload_1.2.4                 jsonlite_1.8.0                Rsamtools_2.13.3              dbplyr_2.2.0                  png_0.1-7                    
 [21] shiny_1.7.1                   readr_2.1.2                   BiocManager_1.30.18           compiler_4.2.0                httr_1.4.3                   
 [26] lazyeval_0.2.2                assertthat_0.2.1              Matrix_1.4-1                  fastmap_1.1.0                 cli_3.3.0                    
 [31] later_1.3.0                   htmltools_0.5.2               prettyunits_1.1.1             tools_4.2.0                   glue_1.6.2                   
 [36] GenomeInfoDbData_1.2.8        dplyr_1.0.9                   rappdirs_0.3.3                Rcpp_1.0.8.3                  vctrs_0.4.1                  
 [41] Biostrings_2.65.1             rtracklayer_1.57.0            xfun_0.31                     stringr_1.4.0                 ps_1.7.0                     
 [46] brio_1.1.3                    testthat_3.1.4                mime_0.12                     lifecycle_1.0.1               ensembldb_2.21.1             
 [51] devtools_2.4.3                XML_3.99-0.10                 AnnotationHub_3.5.0           getPass_0.2-2                 zlibbioc_1.43.0              
 [56] vroom_1.5.7                   ProtGenerics_1.29.0           hms_1.1.1                     promises_1.2.0.1              MatrixGenerics_1.9.0         
 [61] parallel_4.2.0                SummarizedExperiment_1.27.1   AnnotationFilter_1.21.0       yaml_2.3.5                    curl_4.3.2                   
 [66] memoise_2.0.1                 biomaRt_2.53.2                stringi_1.7.6                 RSQLite_2.2.14                BiocVersion_3.16.0           
 [71] BiocIO_1.7.1                  desc_1.4.1                    filelock_1.0.2                pkgbuild_1.3.1                BiocParallel_1.31.8          
 [76] rlang_1.0.2                   pkgconfig_2.0.3               bitops_1.0-7                  matrixStats_0.62.0            lattice_0.20-45              
 [81] evaluate_0.15                 purrr_0.3.4                   GenomicAlignments_1.33.0      bit_4.0.4                     processx_3.6.0               
 [86] tidyselect_1.1.2              magrittr_2.0.3                R6_2.5.1                      generics_0.1.2                DelayedArray_0.23.0          
 [91] DBI_1.1.2                     pillar_1.7.0                  whisker_0.4                   withr_2.5.0                   KEGGREST_1.37.2              
 [96] RCurl_1.98-1.7                tibble_3.1.7                  crayon_1.5.1                  utf8_1.2.2                    BiocFileCache_2.5.0          
[101] tzdb_0.3.0                    rmarkdown_2.14                progress_1.2.2                usethis_2.1.6                 grid_4.2.0                   
[106] blob_1.2.3                    callr_3.7.0                   git2r_0.30.1                  digest_0.6.29                 xtable_1.8-4                 
[111] httpuv_1.6.5                  sessioninfo_1.2.2  

",AMChalkie,https://github.com/Bioconductor/GenomicFeatures/issues/51,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85SFrFh,makeTxDbPackageFromUCSC failed ,CLOSED,2022-09-18T23:53:22Z,2023-03-15T17:21:24Z,2023-03-15T17:21:23Z,"It doesn't even run for the example:
```
makeTxDbPackageFromUCSC(version=""0.01"",
                        maintainer=""Some One <so@someplace.org>"",
                        author=""Some One <so@someplace.com>"",
                        genome=""sacCer2"",
                        tablename=""ensGene"")
```

It gives the following error: 
```
Error in makeTxDbPackageFromUCSC(version = ""0.01"", maintainer = ""Some One <so@someplace.org>"",  : 
  'circ_seqs' must be supplied as a named character vector.
```

The following line seems to cause the problem: 
```
    if(!is.character(circ_seqs) || length(circ_seqs)<1){
        stop(""'circ_seqs' must be supplied as a named character vector."")}
```

The default value for `circ_seqs` (NULL) won't pass this line. 
",haowulab,https://github.com/Bioconductor/GenomicFeatures/issues/52,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85YPX5J,Create custom TxDb Package from NCBI GFF file,CLOSED,2022-12-06T23:08:35Z,2022-12-07T11:22:54Z,2022-12-07T11:22:54Z,"
Hi,
I am trying to build a custom TxDb package but having errors at makeTxDbpackage step. Please, could you help with resolving the errors?  Code used below. Thanks.

> dir <- ""C:/Users/XX/AppData/Local/R/win-library/4.2/GenomicFeatures/extdata/seq""
> gffmodel <- file.path(dir,""GCF_009819885.2_bCatUst1.pri.v2_genomic.gff"")
> (txdb <- makeTxDbFromGFF(file=""GCF_009819885.2_bCatUst1.pri.v2.gff"", format=""gff3"", dataSource = ""https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/009/819/885/GCF_009819885.2_bCatUst1.pri.v2/"", organism = ""Catharus ustulatus""))

Import genomic features from the file as a GRanges object ... OK
Prepare the 'metadata' data frame ... OK
Make the TxDb object ... OK
TxDb object:
# Db type: TxDb
# Supporting package: GenomicFeatures
# Data source: https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/009/819/885/GCF_009819885.2_bCatUst1.pri.v2/
# Organism: Catharus ustulatus
# Taxonomy ID: 91951
# miRBase build ID: NA
# Genome: NA
# Nb of transcripts: 40735
# Db created by: GenomicFeatures package from Bioconductor
# Creation time: 2022-12-06 16:31:04 -0600 (Tue, 06 Dec 2022)
# GenomicFeatures version at creation time: 1.50.2
# RSQLite version at creation time: 2.2.19
# DBSCHEMAVERSION: 1.2
Warning messages:
1: In .extract_transcripts_from_GRanges(tx_IDX, gr, mcols0$type, mcols0$ID,  :
  some transcripts have no ""transcript_id"" attribute ==> their
  name (""tx_name"" column in the TxDb object) was set to NA
2: In .extract_transcripts_from_GRanges(tx_IDX, gr, mcols0$type, mcols0$ID,  :
  the transcript names (""tx_name"" column in the TxDb object)
  imported from the ""transcript_id"" attribute are not unique

> txdb
TxDb object:
# Db type: TxDb
# Supporting package: GenomicFeatures
# Data source: https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/009/819/885/GCF_009819885.2_bCatUst1.pri.v2/
# Organism: Catharus ustulatus
# Taxonomy ID: 91951
# miRBase build ID: NA
# Genome: NA
# Nb of transcripts: 40735
# Db created by: GenomicFeatures package from Bioconductor
# Creation time: 2022-12-06 16:31:04 -0600 (Tue, 06 Dec 2022)
# GenomicFeatures version at creation time: 1.50.2
# RSQLite version at creation time: 2.2.19
# DBSCHEMAVERSION: 1.2

> saveDb(txdb, file=""Custulatus.sqlite"")
TxDb object:
# Db type: TxDb
# Supporting package: GenomicFeatures
# Data source: https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/009/819/885/GCF_009819885.2_bCatUst1.pri.v2/
# Organism: Catharus ustulatus
# Taxonomy ID: 91951
# miRBase build ID: NA
# Genome: NA
# Nb of transcripts: 40735
# Db created by: GenomicFeatures package from Bioconductor
# Creation time: 2022-12-06 16:31:04 -0600 (Tue, 06 Dec 2022)
# GenomicFeatures version at creation time: 1.50.2
# RSQLite version at creation time: 2.2.19
# DBSCHEMAVERSION: 1.2
> con <- dbconn(txdb)
> DBI::dbGetQuery(con, ""INSERT INTO metadata VALUES ('Resource URL', 'https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/009/819/885/GCF_009819885.2_bCatUst1.pri.v2/');"")
data frame with 0 columns and 0 rows
Warning message:
In result_fetch(res@ptr, n = n) :
  SQL statements must be issued with dbExecute() or dbSendStatement() instead of dbGetQuery() or dbSendQuery().

> makeTxDbPackage(txdb, version=""1.2"", maintainer=""X X <X@zzz.edu>"", author=""X X"", destDir= ""C:/Users/X/AppData/Local/R/win-library/4.2/GenomicFeatures/exdata/seq"")
Error in createPackage(pkgname = pkgname, destinationDir = destDir, originDir = template_path,  : 
  'destinationDir' must be a directory (C:/Users/X/AppData/Local/R/win-library/4.2/GenomicFeatures/exdata/seq)",sopeadeniji,https://github.com/Bioconductor/GenomicFeatures/issues/53,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85bSHaU,mapToTranscripts reports incorrect regions when supplied GRangesList containing some empty transcripts,OPEN,2023-01-12T23:12:01Z,2023-01-12T23:12:01Z,,"I experienced an error similar to one reported on the [support site](https://support.bioconductor.org/p/9141351/). Incorrect annotations are returned when calling a VariantAnnotation function (`locateVariants()` with  `region = IntronVariants()` ) that internally uses `mapToTranscripts` .  

I believe this error is caused by passing a list containing some empty transcripts to the `transcripts` argument of `mapToTranscripts()`.  This can be fixed by removing the empty transcripts, but perhaps it might be useful to signal an error to the user in this condition or handle this internally? As far as i can tell, the erroneous mapping occurs in the `.orderElementsByTranscription` function.

Here is a reprex using the example provided on the support site and an example of how  `.orderElementsByTranscription` will reorder/duplicate transcripts in the presence of empty list elements. 

``` r
library(TxDb.Hsapiens.UCSC.hg19.knownGene)
library(GenomicFeatures)
txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene

# generate a grl with some zero length entries
grl <- intronsByTranscript(txdb)
sum(elementNROWS(grl) == 0)
#> [1] 10556

gr <- GRanges(seqnames = ""chr5"",
              ranges = IRanges(start = 20298238,
                               end = 20298238))
genome(gr) <- ""hg19""

tx <- mapToTranscripts(gr, grl)
tx
#> GRanges object with 1 range and 2 metadata columns:
#>       seqnames    ranges strand |     xHits transcriptsHits
#>          <Rle> <IRanges>  <Rle> | <integer>       <integer>
#>   [1]    19778    277333      - |         1           19778
#>   -------
#>   seqinfo: 82960 sequences from an unspecified genome

## wrong transcript is mapped
grl[[seqnames(tx)]]
#> GRanges object with 3 ranges and 0 metadata columns:
#>       seqnames              ranges strand
#>          <Rle>           <IRanges>  <Rle>
#>   [1]     chr4 110610725-110612005      -
#>   [2]     chr4 110612166-110615680      -
#>   [3]     chr4 110615857-110624511      -
#>   -------
#>   seqinfo: 93 sequences (1 circular) from hg19 genome

## should map to last entry (14) in this transcript
grl[[subjectHits(findOverlaps(gr, grl))]]
#> GRanges object with 14 ranges and 0 metadata columns:
#>        seqnames            ranges strand
#>           <Rle>         <IRanges>  <Rle>
#>    [1]     chr5 19473826-19483409      -
#>    [2]     chr5 19483662-19503100      -
#>    [3]     chr5 19503219-19520765      -
#>    [4]     chr5 19520888-19543977      -
#>    [5]     chr5 19544115-19571687      -
#>    ...      ...               ...    ...
#>   [10]     chr5 19747346-19838867      -
#>   [11]     chr5 19839352-19981168      -
#>   [12]     chr5 19981288-19991981      -
#>   [13]     chr5 19992124-20255552      -
#>   [14]     chr5 20255615-20575570      -
#>   -------
#>   seqinfo: 93 sequences (1 circular) from hg19 genome

## removing empty entries returns correct transcript
grl_no_zero  <- grl[elementNROWS(grl) > 0]
tx2 <- mapToTranscripts(gr, grl_no_zero)
grl_no_zero[[seqnames(tx2)]]
#> GRanges object with 14 ranges and 0 metadata columns:
#>        seqnames            ranges strand
#>           <Rle>         <IRanges>  <Rle>
#>    [1]     chr5 19473826-19483409      -
#>    [2]     chr5 19483662-19503100      -
#>    [3]     chr5 19503219-19520765      -
#>    [4]     chr5 19520888-19543977      -
#>    [5]     chr5 19544115-19571687      -
#>    ...      ...               ...    ...
#>   [10]     chr5 19747346-19838867      -
#>   [11]     chr5 19839352-19981168      -
#>   [12]     chr5 19981288-19991981      -
#>   [13]     chr5 19992124-20255552      -
#>   [14]     chr5 20255615-20575570      -
#>   -------
#>   seqinfo: 93 sequences (1 circular) from hg19 genome

## looks like .orderElementsByTranscription changes the order of elements 
## in the `grl` list when zero-length elements are in grl?
## e.g. the transcript in grl[[7]] != the transcript in ord_grl[[7]]
ord_grl <- GenomicFeatures:::.orderElementsByTranscription(grl)

# list with 1 empty entry 
grl[c(3,4,7)]
#> GRangesList object of length 3:
#> $`3`
#> GRanges object with 2 ranges and 0 metadata columns:
#>       seqnames      ranges strand
#>          <Rle>   <IRanges>  <Rle>
#>   [1]     chr1 12228-12645      +
#>   [2]     chr1 12698-13220      +
#>   -------
#>   seqinfo: 93 sequences (1 circular) from hg19 genome
#> 
#> $`4`
#> GRanges object with 0 ranges and 0 metadata columns:
#>    seqnames    ranges strand
#>       <Rle> <IRanges>  <Rle>
#>   -------
#>   seqinfo: 93 sequences (1 circular) from hg19 genome
#> 
#> $`7`
#> GRanges object with 2 ranges and 0 metadata columns:
#>       seqnames        ranges strand
#>          <Rle>     <IRanges>  <Rle>
#>   [1]     chr1 322229-324287      +
#>   [2]     chr1 324346-324438      +
#>   -------
#>   seqinfo: 93 sequences (1 circular) from hg19 genome

# first entry is duplicated at position 3
GenomicFeatures:::.orderElementsByTranscription(grl[c(3,4,7)])
#> GRangesList object of length 3:
#> $`3`
#> GRanges object with 2 ranges and 1 metadata column:
#>       seqnames      ranges strand | unordered
#>          <Rle>   <IRanges>  <Rle> | <integer>
#>   [1]     chr1 12228-12645      + |         1
#>   [2]     chr1 12698-13220      + |         2
#>   -------
#>   seqinfo: 93 sequences (1 circular) from hg19 genome
#> 
#> $`4`
#> GRanges object with 0 ranges and 1 metadata column:
#>    seqnames    ranges strand | unordered
#>       <Rle> <IRanges>  <Rle> | <integer>
#>   -------
#>   seqinfo: 93 sequences (1 circular) from hg19 genome
#> 
#> $`7`
#> GRanges object with 2 ranges and 1 metadata column:
#>       seqnames      ranges strand | unordered
#>          <Rle>   <IRanges>  <Rle> | <integer>
#>   [1]     chr1 12228-12645      + |         1
#>   [2]     chr1 12698-13220      + |         2
#>   -------
#>   seqinfo: 93 sequences (1 circular) from hg19 genome
```

<sup>Created on 2023-01-12 with [reprex v2.0.2](https://reprex.tidyverse.org)</sup>

<details style=""margin-bottom:10px;"">
<summary>
Session info
</summary>

``` r
sessioninfo::session_info()
#>  Session info 
#>  setting  value
#>  version  R Under development (unstable) (2022-10-30 r83209)
#>  os       macOS Monterey 12.2.1
#>  system   aarch64, darwin20
#>  ui       X11
#>  language (EN)
#>  collate  en_US.UTF-8
#>  ctype    en_US.UTF-8
#>  tz       America/Denver
#>  date     2023-01-12
#>  pandoc   2.19.2 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)
#> 
#>  Packages 
#>  package                           * version   date (UTC) lib source
#>  AnnotationDbi                     * 1.61.0    2022-11-01 [1] Bioconductor
#>  assertthat                          0.2.1     2019-03-21 [1] CRAN (R 4.3.0)
#>  Biobase                           * 2.59.0    2022-11-01 [1] Bioconductor
#>  BiocFileCache                       2.7.1     2022-12-09 [1] Bioconductor
#>  BiocGenerics                      * 0.45.0    2022-11-01 [1] Bioconductor
#>  BiocIO                              1.9.1     2022-11-24 [1] Bioconductor
#>  BiocParallel                        1.33.9    2022-12-23 [1] Bioconductor
#>  biomaRt                             2.55.0    2022-11-01 [1] Bioconductor
#>  Biostrings                          2.67.0    2022-11-01 [1] Bioconductor
#>  bit                                 4.0.5     2022-11-15 [1] CRAN (R 4.3.0)
#>  bit64                               4.0.5     2020-08-30 [1] CRAN (R 4.3.0)
#>  bitops                              1.0-7     2021-04-24 [1] CRAN (R 4.3.0)
#>  blob                                1.2.3     2022-04-10 [1] CRAN (R 4.3.0)
#>  cachem                              1.0.6     2021-08-19 [1] CRAN (R 4.3.0)
#>  cli                                 3.6.0     2023-01-09 [1] CRAN (R 4.3.0)
#>  codetools                           0.2-18    2020-11-04 [1] CRAN (R 4.3.0)
#>  crayon                              1.5.2     2022-09-29 [1] CRAN (R 4.3.0)
#>  curl                                5.0.0     2023-01-12 [1] CRAN (R 4.3.0)
#>  DBI                                 1.1.3     2022-06-18 [1] CRAN (R 4.3.0)
#>  dbplyr                              2.2.1     2022-06-27 [1] CRAN (R 4.3.0)
#>  DelayedArray                        0.25.0    2022-11-01 [1] Bioconductor
#>  digest                              0.6.31    2022-12-11 [1] CRAN (R 4.3.0)
#>  dplyr                               1.0.10    2022-09-01 [1] CRAN (R 4.3.0)
#>  ellipsis                            0.3.2     2021-04-29 [1] CRAN (R 4.3.0)
#>  evaluate                            0.19      2022-12-13 [1] CRAN (R 4.3.0)
#>  fansi                               1.0.3     2022-03-24 [1] CRAN (R 4.3.0)
#>  fastmap                             1.1.0     2021-01-25 [1] CRAN (R 4.3.0)
#>  filelock                            1.0.2     2018-10-05 [1] CRAN (R 4.3.0)
#>  fs                                  1.5.2     2021-12-08 [1] CRAN (R 4.3.0)
#>  generics                            0.1.3     2022-07-05 [1] CRAN (R 4.3.0)
#>  GenomeInfoDb                      * 1.35.10   2023-01-03 [1] Bioconductor
#>  GenomeInfoDbData                    1.2.9     2022-11-08 [1] Bioconductor
#>  GenomicAlignments                   1.35.0    2022-11-01 [1] Bioconductor
#>  GenomicFeatures                   * 1.51.4    2022-12-23 [1] Bioconductor
#>  GenomicRanges                     * 1.51.4    2022-12-15 [1] Bioconductor
#>  glue                                1.6.2     2022-02-24 [1] CRAN (R 4.3.0)
#>  highr                               0.10      2022-12-22 [1] CRAN (R 4.3.0)
#>  hms                                 1.1.2     2022-08-19 [1] CRAN (R 4.3.0)
#>  htmltools                           0.5.4     2022-12-07 [1] CRAN (R 4.3.0)
#>  httr                                1.4.4     2022-08-17 [1] CRAN (R 4.3.0)
#>  IRanges                           * 2.33.0    2022-11-01 [1] Bioconductor
#>  KEGGREST                            1.39.0    2022-11-01 [1] Bioconductor
#>  knitr                               1.41      2022-11-18 [1] CRAN (R 4.3.0)
#>  lattice                             0.20-45   2021-09-22 [1] CRAN (R 4.3.0)
#>  lifecycle                           1.0.3     2022-10-07 [1] CRAN (R 4.3.0)
#>  magrittr                            2.0.3     2022-03-30 [1] CRAN (R 4.3.0)
#>  Matrix                              1.5-3     2022-11-11 [1] CRAN (R 4.3.0)
#>  MatrixGenerics                      1.11.0    2022-11-01 [1] Bioconductor
#>  matrixStats                         0.63.0    2022-11-18 [1] CRAN (R 4.3.0)
#>  memoise                             2.0.1     2021-11-26 [1] CRAN (R 4.3.0)
#>  pillar                              1.8.1     2022-08-19 [1] CRAN (R 4.3.0)
#>  pkgconfig                           2.0.3     2019-09-22 [1] CRAN (R 4.3.0)
#>  png                                 0.1-8     2022-11-29 [1] CRAN (R 4.3.0)
#>  prettyunits                         1.1.1     2020-01-24 [1] CRAN (R 4.3.0)
#>  progress                            1.2.2     2019-05-16 [1] CRAN (R 4.3.0)
#>  purrr                               1.0.1     2023-01-10 [1] CRAN (R 4.3.0)
#>  R.cache                             0.16.0    2022-07-21 [1] CRAN (R 4.3.0)
#>  R.methodsS3                         1.8.2     2022-06-13 [1] CRAN (R 4.3.0)
#>  R.oo                                1.25.0    2022-06-12 [1] CRAN (R 4.3.0)
#>  R.utils                             2.12.2    2022-11-11 [1] CRAN (R 4.3.0)
#>  R6                                  2.5.1     2021-08-19 [1] CRAN (R 4.3.0)
#>  rappdirs                            0.3.3     2021-01-31 [1] CRAN (R 4.3.0)
#>  Rcpp                                1.0.9     2022-07-08 [1] CRAN (R 4.3.0)
#>  RCurl                               1.98-1.9  2022-10-03 [1] CRAN (R 4.3.0)
#>  reprex                              2.0.2     2022-08-17 [1] CRAN (R 4.3.0)
#>  restfulr                            0.0.15    2022-06-16 [1] CRAN (R 4.3.0)
#>  rjson                               0.2.21    2022-01-09 [1] CRAN (R 4.3.0)
#>  rlang                               1.0.6     2022-09-24 [1] CRAN (R 4.3.0)
#>  rmarkdown                           2.19      2022-12-15 [1] CRAN (R 4.3.0)
#>  Rsamtools                           2.15.1    2022-12-30 [1] Bioconductor
#>  RSQLite                             2.2.20    2022-12-22 [1] CRAN (R 4.3.0)
#>  rstudioapi                          0.14      2022-08-22 [1] CRAN (R 4.3.0)
#>  rtracklayer                         1.59.1    2022-12-27 [1] Bioconductor
#>  S4Vectors                         * 0.37.3    2022-12-07 [1] Bioconductor
#>  sessioninfo                         1.2.2     2021-12-06 [1] CRAN (R 4.3.0)
#>  stringi                             1.7.12    2023-01-11 [1] CRAN (R 4.3.0)
#>  stringr                             1.5.0     2022-12-02 [1] CRAN (R 4.3.0)
#>  styler                              1.8.1     2022-11-07 [1] CRAN (R 4.3.0)
#>  SummarizedExperiment                1.29.1    2022-11-04 [1] Bioconductor
#>  tibble                              3.1.8     2022-07-22 [1] CRAN (R 4.3.0)
#>  tidyselect                          1.2.0     2022-10-10 [1] CRAN (R 4.3.0)
#>  TxDb.Hsapiens.UCSC.hg19.knownGene * 3.2.2     2023-01-12 [1] Bioconductor
#>  utf8                                1.2.2     2021-07-24 [1] CRAN (R 4.3.0)
#>  vctrs                               0.5.1     2022-11-16 [1] CRAN (R 4.3.0)
#>  withr                               2.5.0     2022-03-03 [1] CRAN (R 4.3.0)
#>  xfun                                0.36      2022-12-21 [1] CRAN (R 4.3.0)
#>  XML                                 3.99-0.13 2022-12-04 [1] CRAN (R 4.3.0)
#>  xml2                                1.3.3     2021-11-30 [1] CRAN (R 4.3.0)
#>  XVector                             0.39.0    2022-11-01 [1] Bioconductor
#>  yaml                                2.3.6     2022-10-18 [1] CRAN (R 4.3.0)
#>  zlibbioc                            1.45.0    2022-11-01 [1] Bioconductor
#> 
#>  [1] /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library
#> 
#> 
```

</details>
",kriemo,https://github.com/Bioconductor/GenomicFeatures/issues/54,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85g6rUr,Add 'genome' argument to makeTxDbFromGFF(),CLOSED,2023-03-15T17:50:34Z,2024-03-23T00:41:55Z,2024-03-23T00:41:55Z,"### Edit: All `makeTxDb*()` functions have moved to the new **txdbmaker** package. So I re-created this issue [there](https://github.com/Bioconductor/txdbmaker/issues/2) and I'm closing this one.

Right now (as of **GenomicFeatures** 1.51.4) `makeTxDbFromGFF()` produces a TxDb object that has an unspecified genome by default. To change this, one needs to explicitely set the genome on the TxDb object returned by `makeTxDbFromGFF()`, e.g. with `genome(txdb) <- ""T2T-CHM13v2.0""` (it's important to use the official name of the assembly otherwise the `seqlevelsStyle()` setter won't be able to switch the sequence naming style to UCSC or RefSeq). Alternatively one can specify the genome at creation time with `makeTxDbFromGFF(..., metadata=data.frame(name=""Genome"", value=""T2T-CHM13v2.0""))` but this is admitedly poorly documented and not very convenient.

So let's add a `genome` argument to `makeTxDbFromGFF()`.
",hpages,https://github.com/Bioconductor/GenomicFeatures/issues/55,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85ieFBB,`makeTxDbFromGFF` fails with (bacterial) genome GTF files from NCBI,CLOSED,2023-04-03T13:14:10Z,2024-03-23T00:45:45Z,2024-02-01T13:13:27Z,"Dear maintainers, I noticed recently that making a Txdb object from a GFF (or GTF) file from bacteria can be difficult.
I downloaded several genome assemblies from the NCBI genomes website, all of them the reference genomes for widely used model bacteria such as Salmonella or Bacillus. When I try to make the txdb object, the function throws the following error:

```
> GenomicFeatures::makeTxDbFromGFF("".../genomes/s_enterica/GCF_000006945.2/genomic.gtf"")

Import genomic features from the file as a GRanges object ... OK
Prepare the 'metadata' data frame ... OK
Make the TxDb object ... Error in .make_splicings(exons, cds, stop_codons) : 
  some CDS cannot be mapped to an exon
In addition: Warning message:
In .get_cds_IDX(mcols0$type, mcols0$phase) :
  The ""phase"" metadata column contains non-NA values for features of type
  stop_codon. This information was ignored.
```

The problem here seems that there are some underlying assumptions about the structure of genes. Bacteria don't have exons, so ideally the function should not throw an error when exon information is missing. Also, bacteria can have multiple CDS on one transcript (operon structure), I'm not sure if this is also related to the error above. I am willing to make a PR to fiy this bug if I know where to look for.

Thank you!
Michael",m-jahn,https://github.com/Bioconductor/GenomicFeatures/issues/56,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85lM-He,`makeTxDbFromBiomart()` on the Ensembl archive version failed ,CLOSED,2023-05-05T16:42:48Z,2024-02-01T18:02:45Z,2024-02-01T18:02:45Z,"Hi there,
I'm having trouble with `makeTxDbFromBiomart()` on the archive version of the Ensembl Plant.

I hope to use a older version of maize genome at *https://nov2020-plants.ensembl.org*. Below is my function call:

```r
zmv4_txdb <- makeTxDbFromBiomart(dataset=""zmays_eg_gene"", 
                             biomart=""plants_mart"",
                             host=""https://nov2020-plants.ensembl.org"")
zmv4_txdb
```

Although it says **Ensembl Plants Genes 49** which uses **RefGen_v4**, the content is actually the newest version from **Zm-B73-REFERENCE-NAM-5.0** (as you can see below). I wonder how to let `makeTxDbFromBiomart()` work on the older version of Ensembl Plant if possible?

```
TxDb object:
# Db type: TxDb
# Supporting package: GenomicFeatures
# Data source: BioMart
# Organism: Zea mays
# Taxonomy ID: 4577
# Resource URL: plants.ensembl.org:443
# BioMart database: plants_mart
# BioMart database version: Ensembl Plants Genes 49
# BioMart dataset: zmays_eg_gene
# BioMart dataset description: Zea mays genes (Zm-B73-REFERENCE-NAM-5.0)
# BioMart dataset version: Zm-B73-REFERENCE-NAM-5.0
# Full dataset: yes
# miRBase build ID: NA
# Nb of transcripts: 77341
# Db created by: GenomicFeatures package from Bioconductor
# Creation time: 2023-05-05 12:37:16 -0400 (Fri, 05 May 2023)
# GenomicFeatures version at creation time: 1.50.4
# RSQLite version at creation time: 2.2.18
# DBSCHEMAVERSION: 1.2
```

The search call returned the correct version.

```r
listMarts(host=""https://nov2020-plants.ensembl.org"")
datasets <- listDatasets(useMart(biomart=""plants_mart"",
                                 host=""https://nov2020-plants.ensembl.org""))
subset(datasets, grepl(""mays"", dataset, ignore.case=TRUE))

#         dataset                    description       version
# 96 zmays_eg_gene Zea mays genes (B73 RefGen_v4) B73 RefGen_v4
```
Thanks!
Ji ",timedreamer,https://github.com/Bioconductor/GenomicFeatures/issues/57,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85lisvy,installation issue,CLOSED,2023-05-10T10:22:14Z,2023-05-11T15:56:50Z,2023-05-11T15:56:50Z,"I am trying to install GenomicFeatures but I received and error that seems to be related to the version of DelayedArray I am using. 

```
BiocManager::install(""GenomicFeatures"", force= TRUE)
library(""GenomicFeatures"")
Error: package or namespace load failed for GenomicFeatures in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
 namespace DelayedArray 0.25.0 is being loaded, but >= 0.26.1 is required

sessionInfo() 
R version 4.3.0 (2023-04-21)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS Ventura 13.3.1

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: Europe/Zurich
tzcode source: internal

other attached packages:
 [1] DelayedArray_0.25.0   MatrixGenerics_1.12.0 matrixStats_0.63.0   
 [4] Matrix_1.5-4          BiocManager_1.30.20   AnnotationDbi_1.62.1 
 [7] Biobase_2.60.0        GenomicRanges_1.52.0  GenomeInfoDb_1.36.0  
[10] IRanges_2.34.0        S4Vectors_0.38.1      BiocGenerics_0.46.0  
```

I can see I have DelayedArray_0.25.0 but 
```
BiocManager::install(""DelayedArray"")

Warning: unable to access index for repository https://bioconductor.org/packages/3.17/data/annotation/bin/macosx/big-sur-arm64/contrib/4.3:
  cannot open URL 'https://bioconductor.org/packages/3.17/data/annotation/bin/macosx/big-sur-arm64/contrib/4.3/PACKAGES'
trying URL 'https://bioconductor.org/packages/3.17/bioc/bin/macosx/big-sur-arm64/contrib/4.3/DelayedArray_0.25.0.tgz'
```
",LliliansCalvo,https://github.com/Bioconductor/GenomicFeatures/issues/58,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85oQBT9,fiveUTRsByTranscript() and threeUTRsByTranscript() give incorrect UTRs,CLOSED,2023-06-09T03:09:37Z,2023-06-24T04:03:21Z,2023-06-24T04:03:20Z,"If exon feature contains ID attribute in gff, it will make incorrect UTR annotations.
```
# gff data is downloaded from https://solgenomics.net/ftp/tomato_genome/annotation/ITAG4.1_release/
>gff=""ITAG4.1_gene_models.gff"" 
>gff.gr<-import(gff)

>gtf=""ITAG4.1_gene_models.gtf"" # covert gff into gtf by gffread -T 
>gtf.gr<-import(gtf)

>table(gff.gr$type)
           gene            mRNA            exon             CDS three_prime_UTR  five_prime_UTR 
          34688           34688          164368          156076           21858           23098

>table(gtf.gr$type)
     transcript       exon        CDS 
          34688     164368     156076

>txdb.gff<-makeTxDbFromGRanges(gr = gff.gr)
>UTR5.gff.gr <- fiveUTRsByTranscript(txdb.gff)
>UTR3.gff.gr <- threeUTRsByTranscript(txdb.gff)

>txdb.gtf<-makeTxDbFromGRanges(gr = gtf.gr)
>UTR5.gtf.gr <- fiveUTRsByTranscript(txdb.gtf)
>UTR3.gtf.gr <- threeUTRsByTranscript(txdb.gtf)

>sapply(list(""three_prime_UTR""=UTR3.gff.gr,""five_prime_UTR""=UTR5.gff.gr),function(x) sum(elementNROWS(x)))
three_prime_UTR  five_prime_UTR 
          15127           14800
>sapply(list(""three_prime_UTR""=UTR3.gtf.gr,""five_prime_UTR""=UTR5.gtf.gr),function(x) sum(elementNROWS(x)))
three_prime_UTR  five_prime_UTR
          21859           23099
```

The number of UTRs is largely different between the two txdb objects, so I try to remove ID value of exon in GRanges.
And it gives the same number as txdb from gtf file.
```
>gff.noID.gr <- copy(gff.gr)
>gff.noID.gr[gff.noID.gr$type %in% c(""exon"")]$ID<-NA
>txdb.noID.gff    <- makeTxDbFromGRanges(gr = gff.noID.gr)
>UTR5.gff.noID.gr <- fiveUTRsByTranscript(txdb.noID.gff)
>UTR3.gff.noID.gr <- threeUTRsByTranscript(txdb.noID.gff)
>sapply(list(""three_prime_UTR""=UTR3.gff.noID.gr,""five_prime_UTR""=UTR5.gff.noID.gr),function(x) sum(elementNROWS(x)))
three_prime_UTR  five_prime_UTR 
          21859           23099
```

Example:
The ""Solyc00g007330.1.1""  information in gff file:
```
SL4.0ch00	maker_ITAG	gene	2379604	2380807	.	-	.	ID=gene:Solyc00g007330.1;Alias=Solyc00g007330;Name=Solyc00g007330.1;length=1203
SL4.0ch00	maker_ITAG	mRNA	2379604	2380807	.	-	.	ID=mRNA:Solyc00g007330.1.1;Parent=gene:Solyc00g007330.1;Name=Solyc00g007330.1.1;Note=Zinc finger transcription factor 1;_AED=1.00;_QI=373|0|0|0|0|0|2|0|171;_eAED=1.00
SL4.0ch00	maker_ITAG	CDS	2379604	2380119	.	-	0	ID=CDS:Solyc00g007330.1.1.1;Parent=mRNA:Solyc00g007330.1.1
SL4.0ch00	maker_ITAG	exon	2379604	2380324	.	-	.	ID=exon:Solyc00g007330.1.1.1;Parent=mRNA:Solyc00g007330.1.1
SL4.0ch00	maker_ITAG	five_prime_UTR	2380120	2380324	.	-	.	ID=five_prime_UTR:Solyc00g007330.1.1.0;Parent=mRNA:Solyc00g007330.1.1
SL4.0ch00	maker_ITAG	exon	2380640	2380807	.	-	.	ID=exon:Solyc00g007330.1.1.2;Parent=mRNA:Solyc00g007330.1.1
SL4.0ch00	maker_ITAG	five_prime_UTR	2380640	2380807	.	-	.	ID=five_prime_UTR:Solyc00g007330.1.1.1;Parent=mRNA:Solyc00g007330.1.1
```
The transcript has five_prime_UTR only, but txdb of gff file gives incorrect results
```
> UTR5.gff.gr[""Solyc00g007330.1.1""]
GRangesList object of length 1:
$Solyc00g007330.1.1
GRanges object with 1 range and 3 metadata columns:
       seqnames          ranges strand |   exon_id            exon_name exon_rank
          <Rle>       <IRanges>  <Rle> | <integer>          <character> <integer>
  [1] SL4.0ch00 2380120-2380324      - |       815 Solyc00g007330.1.1.1         1
  -------
  seqinfo: 13 sequences from an unspecified genome; no seqlengths
> UTR3.gff.gr[""Solyc00g007330.1.1""]
GRanges object with 1 range and 3 metadata columns:
       seqnames          ranges strand |   exon_id            exon_name exon_rank
          <Rle>       <IRanges>  <Rle> | <integer>          <character> <integer>
  [1] SL4.0ch00 2380640-2380807      - |       816 Solyc00g007330.1.1.2         2
  -------
  seqinfo: 13 sequences from an unspecified genome; no seqlengths
```

",a92932000,https://github.com/Bioconductor/GenomicFeatures/issues/59,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85pnNaj,Extracting exons result is different from manual extraction,CLOSED,2023-06-23T18:15:03Z,2023-08-22T02:09:58Z,2023-08-22T02:09:58Z,"If I try to extract the length of all exons (also those overlapping) using your package with this code and [this gencode file](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.basic.annotation.gff3.gz)
```
library(GenomicFeatures)
txdb <- makeTxDbFromGFF(""tables/gencode.v43.basic.annotation.gtf.gz"",
                        format = ""gtf"")

exons.list.per.gene <- exonsBy(txdb, by = ""gene"")
sort(width(exons.list.per.gene)[[""ENSG00000000003.15""]])
```
the result is `[1]   75   84   99  108  135  189  189  199  312 2878 2879` (11 exons).
If I do it manually (with cleaning the file first using `gzcat gencode.v43.basic.annotation.gff3.gz | grep -v # > gencode.v43.basic.annotation.clean.gff`
```
library(data.table)
gencode_file_gff3 <- fread(""tables/gencode.v43.basic.annotation.clean.gff"",
                           header = FALSE)
gencode_file_gff3 <- gencode_file_gff3[V3 == ""exon""] # filtering for exons
gencode_file_gff3[, gene_id := gsub("".*gene_id=(.*);transcript_id.*"", ""\\1"", V9)] # extractin ENSG number
gencode_file_gff3 <- gencode_file_gff3[, c(""V4"", ""V5"", ""gene_id"")] # reducing to start, end and gene_id
gencode_file_gff3[, length := V5 - (V4 - 1)] # calculating length
gencode_file_gff3 <- unique(gencode_file_gff3) # removing identical exons from HAVANA and ENSEMBL
sort(gencode_file_gff3[gene_id == ""ENSG00000000003.15""]$length)
```
The result is `[1]   75   84   99  108  135  189  199  312 2878 2879` (10 exons). Without the unique command I retain 15 exons. So both is different from yours. I can't figure out where you got that additional exon from. the unique command is necessary if two exons from `HAVANA` and `ENSEMBL` are exactly identical. I am not able to reproduce the results from your package manually.

This i just exemplary, but I get slightly different numbers for most genes.",gernophil,https://github.com/Bioconductor/GenomicFeatures/issues/60,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85sg6xI,makeTxDbFromUCSC failed for mm9,CLOSED,2023-07-25T15:13:22Z,2023-09-28T21:21:05Z,2023-08-22T02:08:41Z,"Hello,

Previous I have used mm9.refseq.db <- makeTxDbFromUCSC(genome=""mm9"", tablename = ""refGene"") and it worked very well, but today it suddenly not working, shows error message ""Error in .tablename2track(tablename, session) : 
  UCSC table ""refGene"" is not supported""

I have checked UCSC table browser, they still have refGene track for mm9.

I tried GenomicFeatures version 1.50.4 and 1.52.1, both are not working. Could you help me with this? Thank you very much!",Moonriver1988,https://github.com/Bioconductor/GenomicFeatures/issues/61,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85uBHby, makeTxDbFromUCSC failed for susScr11,CLOSED,2023-08-10T19:40:11Z,2023-08-22T02:08:27Z,2023-08-22T02:08:27Z,"Hello,

I am having some issues creating a TxDb object for susScr11 (Pig, 2017). I have used makeTxDbFromUCSC in the past to create a TxDb object for this genome, but on a different device. I didn't run into any issues there, but I am now no longer able to create a TxDb for susScr11.

`makeTxDbFromUCSC(genome=""susScr11"")` returns the error ""Error in normArgTrack(track, trackids) : 'track' must be a single string.""

`supportedUCSCtables(genome=""susScr11"")` returns only one entry under the _tablename_ variable: knownGene, and both the 'track' and 'subtrack' values for this are ""NA"".

I'm not sure what happened in the interim between when I initially created a TxDb for susScr11 ~12 months ago without issue, but I would really appreciate some guidance on this. For what it's worth, I attempted to create a TxDb using the older pig genomes available from USCS, and the same outputs resulted. 

>sessionInfo()
R version 4.2.0 (2022-04-22 ucrt)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19044)

>Matrix products: default

>locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252    

>attached base packages:
[1] stats4    grid      stats     graphics  grDevices utils     datasets  methods   base     

>other attached packages:
 [1] TxDb.Sscrofa.UCSC.susScr11.refGene_3.12.0 biomaRt_2.54.1                           
 [3] clusterProfiler_4.6.2                     org.Ss.eg.db_3.16.0                      
 [5] RMariaDB_1.2.2                            GenomicFeatures_1.50.4                   
 [7] AnnotationDbi_1.60.2                      Biobase_2.58.0                           
 [9] AnnotationHub_3.6.0                       BiocFileCache_2.6.1                      
[11] dbplyr_2.3.3                              ChIPseeker_1.34.1                        
[13] ChIPpeakAnno_3.32.0                       rtracklayer_1.58.0                       
[15] GenomicRanges_1.50.2                      GenomeInfoDb_1.34.9                      
[17] IRanges_2.32.0                            S4Vectors_0.36.2                         
[19] BiocGenerics_0.44.0                       venneuler_1.1-3                          
[21] rJava_1.0-6                               VennDiagram_1.7.3                        
[23] futile.logger_1.4.3                       lubridate_1.9.2                          
[25] forcats_1.0.0                             stringr_1.5.0                            
[27] dplyr_1.1.2                               purrr_1.0.1                              
[29] readr_2.1.4                               tidyr_1.3.0                              
[31] tibble_3.2.1                              ggplot2_3.4.2                            
[33] tidyverse_2.0.0                           BiocManager_1.30.21.1                    

>loaded via a namespace (and not attached):
  [1] utf8_1.2.3                              tidyselect_1.2.0                        RSQLite_2.3.1                          
  [4] BiocParallel_1.32.6                     scatterpie_0.2.1                        munsell_0.5.0                          
  [7] codetools_0.2-18                        withr_2.5.0                             colorspace_2.1-0                       
 [10] GOSemSim_2.24.0                         filelock_1.0.2                          knitr_1.43                             
 [13] rstudioapi_0.15.0                       DOSE_3.24.2                             labeling_0.4.2                         
 [16] MatrixGenerics_1.10.0                   GenomeInfoDbData_1.2.9                  polyclip_1.10-4                        
 [19] bit64_4.0.5                             farver_2.1.1                            downloader_0.4                         
 [22] vctrs_0.6.3                             treeio_1.22.0                           generics_0.1.3                         
 [25] gson_0.1.0                              lambda.r_1.2.4                          xfun_0.39                              
 [28] timechange_0.2.0                        regioneR_1.30.0                         R6_2.5.1                               
 [31] graphlayouts_1.0.0                      AnnotationFilter_1.22.0                 bitops_1.0-7                           
 [34] cachem_1.0.8                            fgsea_1.24.0                            gridGraphics_0.5-1                     
 [37] DelayedArray_0.24.0                     promises_1.2.0.1                        BiocIO_1.8.0                           
 [40] scales_1.2.1                            ggraph_2.1.0                            enrichplot_1.18.4                      
 [43] gtable_0.3.3                            tidygraph_1.2.3                         ensembldb_2.22.0                       
 [46] rlang_1.1.1                             splines_4.2.0                           lazyeval_0.2.2                         
 [49] yaml_2.3.7                              reshape2_1.4.4                          httpuv_1.6.11                          
 [52] qvalue_2.30.0                           RBGL_1.74.0                             tools_4.2.0                            
 [55] ggplotify_0.1.1                         ellipsis_0.3.2                          gplots_3.1.3                           
 [58] RColorBrewer_1.1-3                      Rcpp_1.0.11                             plyr_1.8.8                             
 [61] progress_1.2.2                          zlibbioc_1.44.0                         RCurl_1.98-1.12                        
 [64] prettyunits_1.1.1                       viridis_0.6.4                           cowplot_1.1.1                          
 [67] SummarizedExperiment_1.28.0             ggrepel_0.9.3                           magrittr_2.0.3                         
 [70] data.table_1.14.8                       futile.options_1.0.1                    ProtGenerics_1.30.0                    
 [73] matrixStats_1.0.0                       evaluate_0.21                           xtable_1.8-4                           
 [76] mime_0.12                               hms_1.1.3                               patchwork_1.1.2                        
 [79] HDO.db_0.99.1                           XML_3.99-0.14                           gridExtra_2.3                          
 [82] compiler_4.2.0                          KernSmooth_2.23-20                      crayon_1.5.2                           
 [85] shadowtext_0.1.2                        htmltools_0.5.5                         later_1.3.1                            
 [88] ggfun_0.1.1                             tzdb_0.4.0                              aplot_0.1.10                           
 [91] DBI_1.1.3                               tweenr_2.0.2                            formatR_1.14                           
 [94] MASS_7.3-56                             rappdirs_0.3.3                          boot_1.3-28                            
 [97] Matrix_1.4-1                            cli_3.6.1                               parallel_4.2.0                         
[100] igraph_1.5.0.1                          pkgconfig_2.0.3                         TxDb.Hsapiens.UCSC.hg19.knownGene_3.2.2
[103] GenomicAlignments_1.34.1                xml2_1.3.5                              InteractionSet_1.26.1                  
[106] ggtree_3.6.2                            multtest_2.54.0                         XVector_0.38.0                         
[109] yulab.utils_0.0.6                       digest_0.6.33                           graph_1.76.0                           
[112] Biostrings_2.66.0                       rmarkdown_2.23                          fastmatch_1.1-3                        
[115] tidytree_0.4.4                          restfulr_0.0.15                         curl_5.0.1                             
[118] shiny_1.7.4.1                           Rsamtools_2.14.0                        gtools_3.9.4                           
[121] rjson_0.2.21                            lifecycle_1.0.3                         nlme_3.1-157                           
[124] jsonlite_1.8.7                          viridisLite_0.4.2                       BSgenome_1.66.3                        
[127] fansi_1.0.4                             pillar_1.9.0                            lattice_0.20-45                        
[130] KEGGREST_1.38.0                         fastmap_1.1.1                           httr_1.4.6                             
[133] plotrix_3.8-2                           survival_3.3-1                          GO.db_3.16.0                           
[136] interactiveDisplayBase_1.36.0           glue_1.6.2                              png_0.1-8                              
[139] BiocVersion_3.16.0                      bit_4.0.5                               ggforce_0.4.1                          
[142] stringi_1.7.12                          blob_1.2.4                              caTools_1.18.2                         
[145] memoise_2.0.1                           ape_5.7-1                              ",sinnis007,https://github.com/Bioconductor/GenomicFeatures/issues/62,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85uCU6x,GenomicFeature error with mm10,CLOSED,2023-08-11T02:14:45Z,2023-08-22T02:07:41Z,2023-08-22T02:07:41Z,"Hi,
 
I am getting a error when I am using the makeTxDbFromUCSC() function in GenomicFeatures for mm10 genome. 
 
library(GenomicFeatures)
mm10.refseq.db <- makeTxDbFromUCSC(genome = ""mm10"", tablename = ""knownGene"")
Error in normArgTrack(track, trackids) : 'track' must be a single string
 
It does the same with the example code from help. I checked the supportedUCSCtables() function.
 
>supportedUCSCtables(genome=""mm10"", url=http://genome.ucsc.edu/cgi-bin/)
  tablename track subtrack
1 knownGene  <NA>     <NA>

 Kindly let me know if I missed something here. 

Sincerely, 
Murli",MurliNair,https://github.com/Bioconductor/GenomicFeatures/issues/63,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs85ySjxt,Installation requires vctrs ( 0.6.0),CLOSED,2023-09-28T12:43:08Z,2023-10-02T17:41:20Z,2023-10-02T17:41:20Z,"Hey,
I install this package as part of a package that I'm developing.
Until recently, this was not an issue.
However, in the last few days, I encounter errors due to vctrs ( 0.6.0) (see attached screenshot).
This was a surprise to me since your package does not require vctrs directly. I looked for the actual problem and I think it rises from the installation of dplyr (ver. 1.1.3). Older version did not require vctrs ( 0.6.0) so I didn't have this issue. I still don't understand why dplyr (ver. 1.1.3) is even required since you don't mention it in the dependencies.

Please help me figuring this out.
Thanks

![genomicFeaturesBug](https://github.com/Bioconductor/GenomicFeatures/assets/107349233/b799d167-c170-42f6-a96e-a68029279421)


",amitfrishberg,https://github.com/Bioconductor/GenomicFeatures/issues/64,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs855f6Bw,How to make a TxDb object for the T2T-CHM13v2.0 genome (telomere to telomere Human genome),CLOSED,2023-12-12T19:18:05Z,2024-03-23T00:42:47Z,2024-03-22T21:57:35Z,"[Moved to https://github.com/Bioconductor/txdbmaker/issues/1 on March 22, 2024]
",hpages,https://github.com/Bioconductor/GenomicFeatures/issues/65,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs8576SQX,Feature Request: Implementation of getTerminatorSeq() Function,CLOSED,2024-01-12T13:40:56Z,2024-02-16T20:00:23Z,2024-01-23T18:53:40Z,"Currently, the package includes the getPromoterSeq() function, which is very useful for retrieving promoter sequences. But, there is currently no equivalent function for retrieving terminator sequences.",JavierMenRev,https://github.com/Bioconductor/GenomicFeatures/issues/66,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs86CsTdn,GenomicFeatures:::load_package_gracefully apparently fails on BBS,CLOSED,2024-03-18T16:12:51Z,2024-03-20T00:56:31Z,2024-03-20T00:56:30Z,"Hi,

I got several build warnings on BBS with Bioc 3.19 during testing, which all look kind of the same:

From [RNAmodR](https://master.bioconductor.org/checkResults/3.19/bioc-LATEST/RNAmodR.ML/nebbiolo1-checksrc.html) package
```
Backtrace
      
   1. RNAmodR::End5SequenceData(files, annotation = annotation, sequences = sequences) at test-0SequenceData.R:37:3
   2.   RNAmodR:::.new_SequenceData(...)
   3.     RNAmodR:::.norm_annotation(annotation, className)
   4.       GenomicFeatures::makeTxDbFromGFF(annotation)
   5.         GenomicFeatures:::call_fun_in_txdbmaker(""makeTxDbFromGFF"", ...)
   6.           GenomicFeatures:::load_package_gracefully(...)`
```

From [RNAmodR.ML](https://master.bioconductor.org/checkResults/3.19/bioc-LATEST/RNAmodR.ML/nebbiolo1-checksrc.html) package
```
Last 13 lines of output:
    3.    testthat (local) .capture(...)
    4.     base::withCallingHandlers(...)
    5.    rlang::eval_bare(quo_get_expr(.quo), quo_get_env(.quo))
    6. RNAmodR.ML (local) ModMLExample(files, annotation, sequences)
    7.   RNAmodR:::Modifier(...) at test-RNAmodR.ML.R:16:5
    8.   RNAmodR:::Modifier(...)
    9.     RNAmodR:::.new_ModFromCharacter(...)
   10.       RNAmodR:::.norm_annotation(annotation, className)
   11.         GenomicFeatures::makeTxDbFromGFF(annotation)
   12.           GenomicFeatures:::call_fun_in_txdbmaker(""makeTxDbFromGFF"", ...)
   13.             GenomicFeatures:::load_package_gracefully(...)
```

I see that there are some recent changes from last week. I looked at changes and it seems that there is a new packlage 'txdbmaker' with a redirection to functions from that package.

@hpages Should I fix it in those packages or is this something you would like to address?
Thanks for any advice on how to fix this issue long term best.

Felix

edit: It might be a linux specific issue and/or timing related. Any advice would be much appreciated.",FelixErnst,https://github.com/Bioconductor/GenomicFeatures/issues/67,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs86FS9w6,How to import pseudogenes from GFF3 file as GRanges object?,OPEN,2024-04-10T20:04:32Z,2024-04-10T20:04:32Z,,"Thank you for developing such a powerful package for working with genomes in R. My questions is how do I import pseudogenes, e.g. MTCO2P2, from a NCBI RefSeq human assembly GFF3 file `TxDb` as `GRanges` object using `GenomicFeatures` functions? This entry was not found in the output `GRanges` objects of functions `transcripts`, `exons`, `cds`, or `genes`.

Pseudogene MTCO2P2 is on line 3862455 of GFF3 file GCF_000001405.40_GRCh38.p14_genomic.gff:
`# NC_000018.10    Curated Genomic pseudogene      47853230        47853472        .       -       .       ID=gene-MTCO2P2;Dbxref=GeneID:100873202,HGNC:HGNC:25354;Name=MTCO2P2;description=MT-CO2 pseudogene 2;gbkey=Gene;gene=MTCO2P2;gene_biotype=pseudogene;gene_synonym=HsT4010;pseudo=true`

The GFF3 file (Last modified: 2023-10-11 12:39) was downloaded from here: https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.40_GRCh38.p14/GCF_000001405.40_GRCh38.p14_genomic.gff.gz

```
library(GenomicFeatures)
db <- makeTxDbFromGFF(""GCF_000001405.40_GRCh38.p14_genomic.gff"")

# Import genomic features from the file as a GRanges object ... OK
# Prepare the 'metadata' data frame ... OK
# Make the TxDb object ... OK
# Warning messages:
# 1: In .extract_transcripts_from_GRanges(tx_IDX, gr, mcols0$type, mcols0$ID,  :
#     some transcripts have no ""transcript_id"" attribute ==> their
#     name (""tx_name"" column in the TxDb object) was set to NA
# 2: In .extract_transcripts_from_GRanges(tx_IDX, gr, mcols0$type, mcols0$ID,  :
#     the transcript names (""tx_name"" column in the TxDb object)
#     imported from the ""transcript_id"" attribute are not unique
# 3: In .find_exon_cds(exons, cds) :
#     The following transcripts have exons that contain more than
#     one CDS (only the first CDS was kept for each exon):
#     rna-NM_001134939.1, rna-NM_001172437.2, rna-NM_001184961.1,
#     rna-NM_001301020.1, rna-NM_001301302.1, rna-NM_001301371.1,
#     rna-NM_002537.3, rna-NM_004152.3, rna-NM_015068.3,
#     rna-NM_016178.2

tx <- transcripts(db, columns = c(""tx_id"", ""tx_name"", ""gene_id""))
ex <- exons(db, columns = c(""exon_id"", ""gene_id""))
cds <- cds(db, columns = c(""cds_id"", ""gene_id""))
ge <- genes(db)

txdf <- as.data.frame(tx)
exdf <- as.data.frame(ex)
cdsdf <- as.data.frame(cds)
gedf <- as.data.frame(ge)

""MTCO2P2"" %in% txdf$gene_id
# [1] FALSE
47853230 %in% txdf$start
# [1] FALSE
47853472 %in% txdf$end
# [1] FALSE

""MTCO2P2"" %in% exdf$gene_id
# [1] FALSE
47853230 %in% exdf$start
# [1] FALSE
47853472 %in% exdf$end
# [1] FALSE

""MTCO2P2"" %in% cdsdf$gene_id
# [1] FALSE
47853230 %in% cdsdf$start
# [1] FALSE
47853472 %in% cdsdf$end
# [1] FALSE

""MTCO2P2"" %in% gedf$gene_id
# [1] FALSE
47853230 %in% gedf$start
# [1] FALSE
47853472 %in% gedf$end
# [1] FALSE
```
```
sessionInfo()
R version 4.3.2 (2023-10-31)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS Sonoma 14.4.1

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/New_York
tzcode source: internal

attached base packages:
[1] stats4    stats     graphics  grDevices utils     datasets 
[7] methods   base     

other attached packages:
[1] GenomicFeatures_1.54.1 AnnotationDbi_1.64.1  
[3] Biobase_2.62.0         GenomicRanges_1.54.1  
[5] GenomeInfoDb_1.38.2    IRanges_2.36.0        
[7] S4Vectors_0.40.2       BiocGenerics_0.48.1   

loaded via a namespace (and not attached):
 [1] KEGGREST_1.42.0             SummarizedExperiment_1.32.0
 [3] xfun_0.41                   rjson_0.2.21               
 [5] lattice_0.22-5              vctrs_0.6.5                
 [7] tools_4.3.2                 bitops_1.0-7               
 [9] generics_0.1.3              curl_5.2.0                 
[11] parallel_4.3.2              tibble_3.2.1               
[13] fansi_1.0.6                 RSQLite_2.3.4              
[15] blob_1.2.4                  pkgconfig_2.0.3            
[17] Matrix_1.6-4                dbplyr_2.4.0               
[19] lifecycle_1.0.4             GenomeInfoDbData_1.2.11    
[21] compiler_4.3.2              stringr_1.5.1              
[23] Rsamtools_2.18.0            Biostrings_2.70.1          
[25] progress_1.2.3              codetools_0.2-19           
[27] htmltools_0.5.7             RCurl_1.98-1.13            
[29] yaml_2.3.8                  pillar_1.9.0               
[31] crayon_1.5.2                BiocParallel_1.36.0        
[33] DelayedArray_0.28.0         cachem_1.0.8               
[35] abind_1.4-5                 tidyselect_1.2.0           
[37] digest_0.6.33               stringi_1.8.3              
[39] dplyr_1.1.4                 restfulr_0.0.15            
[41] grid_4.3.2                  biomaRt_2.58.0             
[43] fastmap_1.1.1               SparseArray_1.2.2          
[45] cli_3.6.2                   magrittr_2.0.3             
[47] S4Arrays_1.2.0              XML_3.99-0.16              
[49] utf8_1.2.4                  prettyunits_1.2.0          
[51] filelock_1.0.3              rappdirs_0.3.3             
[53] bit64_4.0.5                 rmarkdown_2.25             
[55] XVector_0.42.0              httr_1.4.7                 
[57] matrixStats_1.2.0           bit_4.0.5                  
[59] png_0.1-8                   hms_1.1.3                  
[61] evaluate_0.23               memoise_2.0.1              
[63] knitr_1.45                  BiocIO_1.12.0              
[65] BiocFileCache_2.10.1        rtracklayer_1.62.0         
[67] rlang_1.1.2                 glue_1.6.2                 
[69] DBI_1.1.3                   xml2_1.3.6                 
[71] rstudioapi_0.15.0           R6_2.5.1                   
[73] MatrixGenerics_1.14.0       GenomicAlignments_1.38.0   
[75] zlibbioc_1.48.0    
```

Thank you",zhewa,https://github.com/Bioconductor/GenomicFeatures/issues/68,Bioconductor++GenomicFeatures.csv
I_kwDOBhavs86XWu-G,`makeTxDbFromEnsembl` no longer connects to the right Ensembl database for Homo sapiens,OPEN,2024-09-20T17:36:10Z,2024-09-20T17:36:32Z,,"Relatively recently, `GenomicFeatures::makeTxDbFromEnsembl` stopped working for Human. I'm using 1.54.1, but the relevant code hasn't haven in 1.56 or in txdbmaker

```
txdb <- GenomicFeatures::makeTxDbFromEnsembl('homo_sapiens')
Error: Failed to connect: Unknown database 'homo_sapiens_core_112_37'
```

The issue appears to be in `GenomicFeatures:::.lookup_dbname_fix`. It loads the cor_dirs from the FTP which contains ...core_37 and core_38

```
core_dirs <- Ensembl_listMySQLCoreDirs(mysql_url, release = release)
.... ""homo_sapiens_core_112_37"". ""homo_sapiens_core_112_38""   ....
```

It then uses match to pick the first value, which is `homo_sapiens_core_112_37`:
```
i <- match(prefix, substr(core_dirs, 1L, nchar(prefix)))
```

But this is not a valid database for `makeTxDbFromEnsembl`. Replacing the DB with `homo_sapiens_core_112_38` manually, or replacing the above line with the following to choose the later value fixes the issue 
```
i <- max(which(prefix == substr(core_dirs, 1L, nchar(prefix))))
```",divibisan,https://github.com/Bioconductor/GenomicFeatures/issues/69,Bioconductor++GenomicFeatures.csv
MDU6SXNzdWUzNDQ3NjAzMTc=,Error in Readme,OPEN,2018-07-26T09:14:15Z,2018-07-26T09:14:15Z,,"Just a little issue, the readme says ecoli is an option for database - this doesn't work, instead seems to work with escherichia",tomhayes,https://github.com/C-Connor/EnterobaseGenomeAssemblyDownload/issues/1,C-Connor++EnterobaseGenomeAssemblyDownload.csv
I_kwDOCEtmiM6M1HCm,Some alterations to the code to make it work for myself,OPEN,2024-06-19T16:12:05Z,2024-06-19T16:12:05Z,,"1. I could not get the API token via the log in details so I blocked this section out and added a hard coded variable called API_TOKEN where I pasted my API token into:

```
#prompt for loging details
#ENTEROBASE_USERNAME = raw_input(""Please enter Enterobase username: "")
#ENTEROBASE_PASSWORD = getpass.getpass(""Please enter Enterobase password: "")

ENTEROBASE_SERVER = 'https://enterobase.warwick.ac.uk'
#apiaddress = '%s/api/v2.0/login?username=%s&password=%s' %(ENTEROBASE_SERVER, ENTEROBASE_USERNAME, ENTEROBASE_PASSWORD)

#get API token
print('Retrieving API token.')
#try:
#    response = urllib2.urlopen(apiaddress)
#    data = json.load(response)
#    API_TOKEN = data['api_token']
#except urllib2.HTTPError as Response_error:
#    print(""Connection error ocurred:"")
#    print '%d %s.\n Reason: %s' %(Response_error.code, Response_error.msg, Response_error.read())
#    sys.exit()

API_TOKEN = '<copy_API_here>'
```
------------------------------------------------

2. in the barcode_search function
The function is looking for a header called 'Assembly barcode' - in my file the 'b' in the barcode was capitalised so I altered this line to:
`if header_line.split('\t')[count].strip() == 'Assembly Barcode':`

----------------------------------------------

3. In the accession_search function:
I alter the line looking for the Data Source column header to mirror what was in the my downloaded file:
`if header_line.split('\t')[count].strip() == 'Data Source(Accession No.;Sequencing Platform;Sequencing Library;Insert Size;Experiment;Bases;Average Length;Status)':`

---------------------------------------------
",a-damC,https://github.com/C-Connor/EnterobaseGenomeAssemblyDownload/issues/2,C-Connor++EnterobaseGenomeAssemblyDownload.csv
MDU6SXNzdWUzNjE3NDk0NDI=,What is the proper fasta file to use for 1.bwamem-link.pl?,OPEN,2018-09-19T13:28:14Z,2019-03-31T14:07:09Z,,"When running the 1.bwamem-link.pl script, what does the ""gene.fa"" file on line 10 refer to? Is this a FASTA format file of the nucleotide sequences corresponding to all RNA features annotated on the assembly, based on the genome sequence? Thanks for your help!

#!/usr/bin/perl -w
#2017/4/20  

$gene_structure=$ARGV[0];  #""gene.stucture.new"";
$ref_genome=$ARGV[1];      # the second genome  (Mo17/B73)
$cds_seq=$ARGV[2]:         #""gene-full-cds-double.new.fa"";
$cds_loc=$ARGV[3];         #""cds.loc"" 
$script_dir=$ARGV[4];      

`bwa mem -t 1  $ref_genome   gene.fa > aln.sam `;",cmcninch,https://github.com/caulai/Mo17_genome_assembly/issues/1,caulai++Mo17_genome_assembly.csv
MDU6SXNzdWU0MjgzMTM1OTk=,How do I understand the final output?,OPEN,2019-04-02T16:01:37Z,2019-04-11T18:50:47Z,,"Hi,
    When I get the clustalw.out.checked.filtered.structure file, how can I do statistics for it? For example, the number of gene with large structural variations.
    Thanks a lot!

Regards,
Jiaming",jmsong2,https://github.com/caulai/Mo17_genome_assembly/issues/2,caulai++Mo17_genome_assembly.csv
MDU6SXNzdWU3NTUyNjM5MTM=,"how to use ""Gene-SV"" to explore the genetic variation between genomes",OPEN,2020-12-02T13:14:04Z,2020-12-02T13:14:04Z,,"Hi
We are very interested in your script about exploring genetic variation between genomes recently. However, we do not have any experience with such projects and lack of a good basis of biological information. Can you write an useage about ""Gene-SV""?

Thank you for the help.

Best 
JX",jinxin112233,https://github.com/caulai/Mo17_genome_assembly/issues/3,caulai++Mo17_genome_assembly.csv
MDU6SXNzdWU5NDUzODkzMDU=,add adapter trimming to short read assembly,CLOSED,2021-07-15T13:37:54Z,2021-11-01T21:08:04Z,2021-11-01T21:08:04Z,,nreid,https://github.com/CBC-UCONN/Genome_Assembly/issues/1,CBC-UCONN++Genome_Assembly.csv
MDU6SXNzdWU5NDUzOTAwMDM=,shasta/flye long read assemblies,OPEN,2021-07-15T13:38:38Z,2021-07-15T13:38:38Z,,they are dramatically different. need to follow up. ,nreid,https://github.com/CBC-UCONN/Genome_Assembly/issues/2,CBC-UCONN++Genome_Assembly.csv
MDU6SXNzdWU5OTEzNTE3ODc=,Questions re: Centrifuge,OPEN,2021-09-08T17:07:31Z,2021-09-08T17:07:31Z,,"In Section 3.3.1, Centrifuge is used to filter long reads for contaminants that came from bacterial, archael, viral, or human DNA rather than the target species. 
Question 1: The tutorial says a python script is used to remove reads classified as contaminants, but it is not clear if that script uses any particular threshold level of contamination, or simply removes any read marked as classified. If it simply removes all classified reads, is the output from using the --un-gz option (save unclassified reads to gzip-compressed file) equivalent?
Question 2: Is there a risk of removing too much data? A single 50-nt match might occur by chance in a highly-conserved coding sequence (e.g. histones for eukaryotic species) to create false-positive hits that don't really reflect contamination. ",rwhetten,https://github.com/CBC-UCONN/Genome_Assembly/issues/3,CBC-UCONN++Genome_Assembly.csv
I_kwDODoGz085AlgTJ,hybrid assembly of a viral genome,OPEN,2021-12-17T19:54:46Z,2021-12-17T19:54:46Z,,"Hi,
I am looking to make a hybrid assembly of a viral genome. I have got paired-end reads from Illumina and long reads from MinION from a viral sample. Please suggest a pipeline for making viral hybrid genome assembly. I am using Unicycler for bacteria and SPAdes for Illumina but these did not work for viral assembly. I came to know about MaSuRCA, CABOG and Wengan assember, but sure if they are appropriate for viral hybrid genome assembly.
Any suggestion will be appreciated.",sekhwal,https://github.com/CBC-UCONN/Genome_Assembly/issues/4,CBC-UCONN++Genome_Assembly.csv
I_kwDODoGz085JC2JJ,Updates,OPEN,2022-05-04T14:45:16Z,2022-05-04T14:45:16Z,,"- e coli - spades and soap
- box elder - masurca, soap
- Add wengan to hybrid assembly
- Add haplotig purging to hybrid assembly - purge_haplotigs
- Add polishing to wengan hybrid assembly - pilon
- move moss to the end. ",nreid,https://github.com/CBC-UCONN/Genome_Assembly/issues/5,CBC-UCONN++Genome_Assembly.csv
I_kwDODoGz085J157X,centrifuge classification is too lenient,OPEN,2022-05-17T16:07:59Z,2022-05-17T16:07:59Z,,,nreid,https://github.com/CBC-UCONN/Genome_Assembly/issues/6,CBC-UCONN++Genome_Assembly.csv
I_kwDODoGz085J9RSk,add adapter trimming to all short read steps,OPEN,2022-05-19T00:15:24Z,2022-05-19T00:15:24Z,,,nreid,https://github.com/CBC-UCONN/Genome_Assembly/issues/7,CBC-UCONN++Genome_Assembly.csv
I_kwDODoGz085ws3CE,add merqury for eval,OPEN,2023-09-11T15:52:50Z,2023-09-11T15:52:50Z,,,nreid,https://github.com/CBC-UCONN/Genome_Assembly/issues/8,CBC-UCONN++Genome_Assembly.csv
I_kwDOD94Zvc5S1Ziu,pretextview step not working in GAP_hic_map7,OPEN,2022-09-28T17:42:42Z,2022-09-28T17:42:55Z,,Not working due to the .sam format that is output from `chromap`. Try to use a .pairs format instead.,conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/1,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5WUoSo,remove the fasta file from the output directory containing cool/mcool files. it has things named by JBAT,OPEN,2022-11-14T15:14:16Z,2022-11-14T15:14:16Z,,,conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/2,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5e0AXW,remove seaborn dependencies,OPEN,2023-02-19T13:38:45Z,2023-02-19T13:38:45Z,,"it causes too many problems, with GAP_annotate_miniprot for example",conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/3,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5gqejo,remove pretextmap from hic_map7 or implement pairs,OPEN,2023-03-13T15:38:25Z,2023-03-13T15:38:25Z,,"pretextmap now uses pairs as well, change to use this",conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/4,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5gs-JL,GAP_sort_scaffolds_by_hic_insert drops scaffolds,OPEN,2023-03-13T22:53:31Z,2023-03-13T23:03:29Z,,"Some of the scaffolds disappear, presumably because they lack Hi-C data",conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/5,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5kVBpy,make a chromap install snakemake script,OPEN,2023-04-25T13:59:39Z,2023-04-25T13:59:39Z,,used in GAP_sort_scaffolds_by_hic_insert,conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/6,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5r9veq,remove pysam dependency - add fasta,OPEN,2023-07-19T07:35:31Z,2023-07-19T07:35:46Z,,"There is a dependency on pysam in `bin/assembly-from-fasta.py`, remove the dependency and replace it with a prepackaged fasta parser",conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/7,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5sAOpM,max-threads vs cores,OPEN,2023-07-19T13:50:38Z,2023-07-19T13:50:38Z,,"In principle either should work. The usage of both is just to specify the maximum number of threads that should be used for SMPs, while most other things are limited to one thread.

One improvement could be to make these redundant through a runtime check to set whichever of this is present to a global variable within each snakemake script.",conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/8,conchoecia++genome_assembly_pipelines.csv
I_kwDOD94Zvc5sSyZG,check if zlib is installed for chromap,OPEN,2023-07-22T19:01:34Z,2023-07-22T19:01:34Z,,currently fails if zlib is not installed.,conchoecia,https://github.com/conchoecia/genome_assembly_pipelines/issues/9,conchoecia++genome_assembly_pipelines.csv
I_kwDOIaU67s5mVJnK,refactor seqstats script,CLOSED,2023-05-19T08:02:47Z,2023-05-26T13:26:44Z,2023-05-26T13:26:44Z,dump records in batches of size ~100k to temp file or store as table in HDF (preferred),ptrebert,https://github.com/core-unit-bioinformatics/workflow-smk-genome-hybrid-assembly/issues/1,core-unit-bioinformatics++workflow-smk-genome-hybrid-assembly.csv
I_kwDOJBARDc5gDPAx,Feedback on repo,CLOSED,2023-03-06T13:43:58Z,2023-10-26T10:44:29Z,2023-10-26T10:44:29Z,"Hi!
Very nice repo and good description in the readme. You could consider numbering the dirs so they will appear in the order you generated the results ie 1_fastqc so that it would come before the denovo_asm.

All good!
Dag",dagahren,https://github.com/dominiquefastus/De-Novo-Genome-Sequencing-project/issues/1,dominiquefastus++De-Novo-Genome-Sequencing-project.csv
MDU6SXNzdWUyNzIxMjMxNzI=,,OPEN,2017-11-08T09:05:31Z,2017-11-09T14:00:08Z,,,dongxuemin666,https://github.com/dongxuemin666/genome-assembly/issues/1,dongxuemin666++genome-assembly.csv
MDU6SXNzdWUzODk1MDUzMDg=,Detect local nr database,OPEN,2018-12-10T22:00:32Z,2018-12-10T22:00:32Z,,"Need to figure out how to call the local nr database already defined in the $BLASTDB.

Path is now hard coded. Would like to call it by only using ""nr""",duceppemo,https://github.com/duceppemo/bacteria_genome_assembly/issues/2,duceppemo++bacteria_genome_assembly.csv
MDU6SXNzdWUzODk5OTAzMTA=,BDA.py -> write blast xml output to file,OPEN,2018-12-11T22:56:09Z,2018-12-11T22:56:09Z,,"Should write the blast xml output to file, as a backup, in case something goes wrong after the blast. You don't want to wait hours again for that part if it was right to begin with.",duceppemo,https://github.com/duceppemo/bacteria_genome_assembly/issues/3,duceppemo++bacteria_genome_assembly.csv
MDU6SXNzdWUzODk5OTExNDg=,DBA.py -> add support for xml as additional input file,OPEN,2018-12-11T22:58:48Z,2018-12-11T22:58:48Z,,"Sometimes the blast has already been run and you want to skip that part of the script if the xml file is submitted as an additional input.

Related to issue #3 ",duceppemo,https://github.com/duceppemo/bacteria_genome_assembly/issues/4,duceppemo++bacteria_genome_assembly.csv
MDU6SXNzdWUzOTAyNDczMzk=,kmeans warning,OPEN,2018-12-12T14:21:44Z,2018-12-12T14:21:44Z,,"/usr/local/lib/python3.6/dist-packages/sklearn/cluster/k_means_.py:968: ConvergenceWarning: Number of distinct clusters (5) found smaller than n_clusters (6). Possibly due to duplicate points in X.
  return_n_iter=True)

It wold ne nice to modify the code to prevent that warning from happening.",duceppemo,https://github.com/duceppemo/bacteria_genome_assembly/issues/5,duceppemo++bacteria_genome_assembly.csv
MDU6SXNzdWUyMDM5ODg2Mjc=,TypeError: data type not understood,CLOSED,2017-01-30T11:45:43Z,2017-02-21T12:34:53Z,2017-02-21T12:34:53Z,"I get the following error when I try to start in a fresh folder. 

```
genome_update -g Brucella
Adding new species: Brucella abortus to yaml file
Adding new isolate S19 to species: Brucella abortus
Adding new isolate 2308 to species: Brucella abortus
Adding new isolate 870 to species: Brucella abortus
Adding new isolate 292 to species: Brucella abortus
...
.
...
Adding new isolate CMUL 029 to species: Brucella sp.
Traceback (most recent call last):
  File ""/mnt/powervault/bin/conda/bin/genome_update"", line 11, in <module>
    sys.exit(main())
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/genome_update/__main__.py"", line 82, in main
    update_yaml(yaml, NCBI, args.genus, args.species_taxid, args.taxid, args.output, args.input)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/genome_update/__main__.py"", line 99, in update_yaml
    dictonary.update_dictonary(isolates, genus)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/genome_update/dictonary_handler.py"", line 48, in update_dictonary
    self.handler.write(self.output_path,local)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/genome_update/yaml_handler.py"", line 7, in write
    yaml.dump(data,yam)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/__init__.py"", line 200, in dump
    return dump_all([data], stream, Dumper=Dumper, **kwds)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/__init__.py"", line 188, in dump_all
    dumper.represent(data)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 26, in represent
    node = self.represent_data(data)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 47, in represent_data
    node = self.yaml_representers[data_types[0]](self, data)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 203, in represent_dict
    return self.represent_mapping('tag:yaml.org,2002:map', data)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 116, in represent_mapping
    node_value = self.represent_data(item_value)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 47, in represent_data
    node = self.yaml_representers[data_types[0]](self, data)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 203, in represent_dict
    return self.represent_mapping('tag:yaml.org,2002:map', data)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 116, in represent_mapping
    node_value = self.represent_data(item_value)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 47, in represent_data
    node = self.yaml_representers[data_types[0]](self, data)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 203, in represent_dict
    return self.represent_mapping('tag:yaml.org,2002:map', data)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 116, in represent_mapping
    node_value = self.represent_data(item_value)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 51, in represent_data
    node = self.yaml_multi_representers[data_type](self, data)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 342, in represent_object
    return self.represent_sequence(tag+function_name, args)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 91, in represent_sequence
    node_item = self.represent_data(item)
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 33, in represent_data
    if self.ignore_aliases(data):
  File ""/mnt/powervault/bin/conda/lib/python3.5/site-packages/yaml/representer.py"", line 135, in ignore_aliases
    if data in [None, ()]:
TypeError: data type not understood
```
",druvus,https://github.com/Emisam/genome_update/issues/1,Emisam++genome_update.csv
MDU6SXNzdWUyMDM5ODkwNDc=,Version number argument,CLOSED,2017-01-30T11:47:52Z,2017-01-31T08:10:02Z,2017-01-31T08:06:02Z,I would be nice if it would be possible to see the used version. Either print it by default (in the help text) or add version argument. ,druvus,https://github.com/Emisam/genome_update/issues/2,Emisam++genome_update.csv
MDU6SXNzdWUyMDkxNjAxMjg=,Overwritten information,CLOSED,2017-02-21T14:24:45Z,2017-03-08T13:54:46Z,2017-03-08T13:54:46Z,Currently information in yaml file is overwritten if file exist and `-u` is not used. It would be better to give a warning that the file already exists.,druvus,https://github.com/Emisam/genome_update/issues/3,Emisam++genome_update.csv
MDU6SXNzdWUyMTI3NDEwOTY=,Planned reconstruction of code for easier maintenance,OPEN,2017-03-08T13:58:13Z,2017-03-08T13:58:13Z,,Some of the code is messy and hard to maintain. So I've planned to reconstruct the code within near future.,Emisam,https://github.com/Emisam/genome_update/issues/4,Emisam++genome_update.csv
MDU6SXNzdWUyMTI3NDI5OTA=,Add code for checking if files in yaml exists and update if not,OPEN,2017-03-08T14:05:13Z,2017-03-08T14:05:13Z,,"Currently if file locations exist in the columns for fasta, gbk and gff files within isolates in the yaml file it ignores the isolate. So I've planned to add code that checks if they exist and if not download them again. This is mainly for the download command.",Emisam,https://github.com/Emisam/genome_update/issues/5,Emisam++genome_update.csv
MDU6SXNzdWUyMzQ0NzA1MjI=,cPickle.PicklingError,OPEN,2017-06-08T09:47:39Z,2017-06-08T11:50:21Z,,"I installed genome_update with pip as showed in the README : 
pip install genome_update
pip install genome_update --upgrade

but when I try to download genomes, I get this error \:

genome_update -g ""Brucella"" -p 8  

_...
Adding new isolate CMUL 031 to species: Brucella sp.
Adding new isolate CMUL 035 to species: Brucella sp.
Adding new isolate CMUL 034 to species: Brucella sp.
Downloading jobs....
Traceback (most recent call last):
  File ""/usr/local/bin/genome_update"", line 11, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python2.7/dist-packages/genome_update/__main__.py"", line 92, in main
    download(yaml, args.name, args.name, args.output, args.parallel)
  File ""/usr/local/lib/python2.7/dist-packages/genome_update/__main__.py"", line 102, in download
    newdict = dwon.download_jobs(parallel, job)
  File ""/usr/local/lib/python2.7/dist-packages/genome_update/downloader.py"", line 42, in download_jobs
    pool.map(self.download, jobs)
  File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 251, in map
    return self.map_async(func, iterable, chunksize).get()
  File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get
    raise self._value
cPickle.PicklingError: Can't pickle <type 'instancemethod'>: attribute lookup __builtin__.instancemethod failed_

same with genome_update -g ""Brucella"" ",dpchris,https://github.com/Emisam/genome_update/issues/6,Emisam++genome_update.csv
I_kwDOE8ZAk85FaSxC,"I don't know if the program completed? Nevermind, it didn't complete because of a disc issue. Please delete this issue",CLOSED,2022-03-09T22:42:49Z,2022-03-09T22:48:37Z,2022-03-09T22:47:27Z,,evautumn,https://github.com/emyounglab/prymetime_genomes/issues/1,emyounglab++prymetime_genomes.csv
MDU6SXNzdWUyMTU3NjYzODE=,Ensembl REST API docker to be implemented,CLOSED,2017-03-21T14:51:47Z,2023-09-15T09:37:36Z,2023-09-15T09:37:36Z,Inform https://issues.jalview.org/browse/JAL-2458 when done,sujaikumar,https://github.com/genomehubs/genomehubs/issues/1,genomehubs++genomehubs.csv
MDU6SXNzdWUyMTU3Njc0MDE=,Expose endpoints for Ensembl REST API ,CLOSED,2017-03-21T14:54:37Z,2017-03-21T14:55:23Z,2017-03-21T14:55:23Z,"The Ensembl REST API (https://github.com/Ensembl/ensembl-rest) provides a lightweight programmatic interface for locus query, sequence and annotation retrieval, and is consumed by a growing number of clients. Exposure of these endpoints would enable access to data warehoused in GenomeHubs by these clients.
",foreveremain,https://github.com/genomehubs/genomehubs/issues/2,genomehubs++genomehubs.csv
MDU6SXNzdWUyMjg3Mzc4NTE=,Hide download folders that only used by genomehubs platform,CLOSED,2017-05-15T14:42:20Z,2023-09-15T09:37:36Z,2023-09-15T09:37:36Z,"In the downloads server:
hide
- provider
- json
- ini
(they will still be accessible to anyone who wants them)
",sujaikumar,https://github.com/genomehubs/genomehubs/issues/3,genomehubs++genomehubs.csv
MDU6SXNzdWUyNDA4NDAyMDQ=,Bacterial Genomes,OPEN,2017-07-06T04:16:12Z,2017-07-06T15:38:24Z,,"Can I use the Genome Hub with Ensembl bacterial genomes? How would you set the SPECIES_DB_URL and SPECIES_DBS options in this case?

Unlike eukaryotic genomes, bacterial and fungal genomes are not divided by folder by species. How would you create a Genome Hub for a specific group?",fabianomenegidio,https://github.com/genomehubs/genomehubs/issues/4,genomehubs++genomehubs.csv
MDU6SXNzdWUyNjMxNzM2Mzc=,ensembl gene tree page not loading at ensembl.caenorhabditis.org,OPEN,2017-10-05T15:42:56Z,2017-10-05T16:16:23Z,,http://ensembl.caenorhabditis.org/Caenorhabditis_elegans/Gene/Summary?db=core;g=WBGene00004893;r=X:944939-948885;t=F53H8.4,ajo2995,https://github.com/genomehubs/genomehubs/issues/5,genomehubs++genomehubs.csv
MDU6SXNzdWUyNzk3NTgyMTk=,ERROR 2005,CLOSED,2017-12-06T13:46:38Z,2021-01-21T16:10:23Z,2021-01-21T16:10:23Z,"Hej I am following your guide to release 89

and when running the database.sh script in a genomehubs/easy-mirror Docker container:
I get tons of the following error.

```mysqlimport: Error: 2005 Unknown MySQL server host '172.17.0.0/255.255.0.0' (0)```

What can I do to fix this. 

And btw when are you supporting release 90? ",jhagberg,https://github.com/genomehubs/genomehubs/issues/6,genomehubs++genomehubs.csv
MDU6SXNzdWUyOTQ0MTk2OTI=,Support for biomart interface for programmatic access,OPEN,2018-02-05T14:52:10Z,2018-02-05T14:52:10Z,,"Hi, do you plan to support biomart within your containerized mini-ensembl-server? Looks really promising already!",holgerbrandl,https://github.com/genomehubs/genomehubs/issues/7,genomehubs++genomehubs.csv
MDU6SXNzdWU0MzcyMjEwMjk=,v93 importing interproscan,CLOSED,2019-04-25T14:09:44Z,2019-05-31T10:56:19Z,2019-05-31T10:56:19Z,"Running through with example data.  Having generated and check interpro and blastp we tried to import analysis.  Importing gave this error:

Use of uninitialized value $transcript_id in concatenation (.) or string at /ensembl/easy-import/core/../modules/EasyImport/Xref.pm line 419, <> line 1.
DBD::mysql::st execute failed: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AND ensembl_object_type LIKE 'Translation' AND analysis_id = 3 AND xref_id = 1' at line 1 at /ensembl/easy-import/core/../modules/EasyImport/Xref.pm line 420, <> line 1.
Use of uninitialized value $transcript_id in concatenation (.) or string at /ensembl/easy-import/core/../modules/EasyImport/Xref.pm line 425, <> line 1.
DBD::mysql::db do failed: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ''Translation',3)' at line 2 at /ensembl/easy-import/core/../modules/EasyImport/Xref.pm line 425, <> line 1.
DBD::mysql::st execute failed: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'AND ensembl_object_type LIKE 'Translation' AND analysis_id = 3 AND xref_id = 1' at line 1 at /ensembl/easy-import/core/../modules/EasyImport/Xref.pm line 431, <> line 1.
DBD::mysql::st fetchrow_arrayref failed: fetch() without execute() at /ensembl/easy-import/core/../modules/EasyImport/Xref.pm line 432, <> line 1.
Can't use an undefined value as an ARRAY reference at /ensembl/easy-import/core/../modules/EasyImport/Xref.pm line 432, <> line 1.
cp: cannot stat '/import/download/Operophtera_brumata_Obru1/interproscan/Operophtera_brumata_Obru1.proteins.fa.interproscan.tsv.gz': No such file or directory
ERROR: could not cp /import/download/Operophtera_brumata_Obru1/interproscan/Operophtera_brumata_Obru1.proteins.fa.interproscan.tsv.gz to Operophtera_brumata_Obru1.proteins.fa.interproscan.tsv.gz
",IainPerry,https://github.com/genomehubs/genomehubs/issues/8,genomehubs++genomehubs.csv
MDU6SXNzdWU2Njk4MTQ5NzM=,Write init options to config,CLOSED,2020-07-31T13:25:03Z,2023-04-04T10:37:53Z,2023-04-04T10:37:52Z,Add `genomehubs init` option to write command line options to a YAML format config file ,rjchallis,https://github.com/genomehubs/genomehubs/issues/9,genomehubs++genomehubs.csv
MDU6SXNzdWU2Njk4MzE0NzY=,Normalise config options,CLOSED,2020-07-31T13:43:04Z,2020-09-01T13:54:15Z,2020-09-01T13:54:15Z,"make all CLI options compatible with nested yaml config file, e.g.:

```
common:
  docker:
    es:
      container: ghubs-es
```

```
GenomeHubs init --docker-es-container ghubs-es ...
```",rjchallis,https://github.com/genomehubs/genomehubs/issues/10,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTA5MzY0NDQ=,Add depth field to lineage,CLOSED,2020-08-21T07:54:11Z,2021-01-21T11:34:31Z,2021-01-21T11:34:31Z,Lineage entries need a depth field to allow querying specific levels from a root taxon. Could be added to information returned by Tolkien (see tolkit/tolkein#4) or use lineage index when indexing.,rjchallis,https://github.com/genomehubs/genomehubs/issues/13,genomehubs++genomehubs.csv
MDU6SXNzdWU3MjYwODM5NjY=,Error in search container,CLOSED,2020-10-21T02:44:52Z,2021-10-26T03:04:04Z,2021-10-26T03:04:04Z,"Hi! 
I've been setting up GenomeHubs for my genomes and I seem to get the following error during the gene search.

```
Reference: 697f030ec2
Error: Module &#39;ORM::EnsEMBL::DB::Session::Object::Ses 
```
Is this a missing module?

Thanks in advance!
",abs-yy,https://github.com/genomehubs/genomehubs/issues/12,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTA5ODU0NTQ=,Create new index templates,CLOSED,2021-01-21T11:39:26Z,2023-04-04T10:37:54Z,2023-04-04T10:37:53Z,"- [x] #19 (create file index)
- [ ] tree index
- [ ] feature index
- [x] #21 analysis index",rjchallis,https://github.com/genomehubs/genomehubs/issues/14,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTA5ODk3OTk=,Add file index method,CLOSED,2021-01-21T11:44:24Z,2023-04-04T10:37:08Z,2023-04-04T10:37:07Z,"Index files (not content) to support download listing and to allow display of images/summary data tables

- [x] index single file
- [ ] index local directory
- [x] index remote file
- [ ] index remote directory",rjchallis,https://github.com/genomehubs/genomehubs/issues/15,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTA5OTE4MTg=,Add tree index method,CLOSED,2021-01-21T11:46:45Z,2023-04-04T10:37:08Z,2023-04-04T10:37:08Z,Index gene and species trees,rjchallis,https://github.com/genomehubs/genomehubs/issues/16,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTA5OTMzMTA=,Add feature index methods,CLOSED,2021-01-21T11:48:31Z,2023-04-04T10:37:09Z,2023-04-04T10:37:09Z,"- [ ] unstructured features (e.g.bigwig tracks)
- [ ] structured features (e.g. GFF)",rjchallis,https://github.com/genomehubs/genomehubs/issues/17,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTEwMDQ3OTQ=,Add GenomeHubs launch command,CLOSED,2021-01-21T12:02:26Z,2023-04-04T10:37:54Z,2023-04-04T10:37:54Z,"Launch Sequenceserver, Ensembl and Downloads from GenomeHubs command line",rjchallis,https://github.com/genomehubs/genomehubs/issues/18,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTExMjQzMTk=,Create file index,CLOSED,2021-01-21T14:03:40Z,2021-01-21T14:43:24Z,2021-01-21T14:43:24Z,"Component of #14 (create new index templates)

needs top level properties for common file metadata:
- name
- location/URL
- thumbnail filename/location
- size (bytes, lines, records)
- checksum
- format/extension/mime-type
- description
- comment
- source

Leave nested attributes in index template but no plans to use these initially.

Links to other indices:
- assembly_id
- taxon_id
- analysis_id",rjchallis,https://github.com/genomehubs/genomehubs/issues/19,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTIwMTkxNjg=,Move GenomeHubs 2 to default branch and archive GenomeHubs 1 in legacy branch,CLOSED,2021-01-22T13:49:00Z,2023-04-04T10:37:55Z,2023-04-04T10:37:54Z,"- [x] make new legacy branch from main
- [x] update gitbook docs to build from legacy
- [ ] update Wordpress to point to legacy branch for old source code
- [ ] review continuous integration setup and packaging for Genomehubs2
- [x] merge develop branch into main",rjchallis,https://github.com/genomehubs/genomehubs/issues/20,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTIxNDY3MTU=,Create analysis index,CLOSED,2021-01-22T16:37:42Z,2021-01-26T15:48:27Z,2021-01-26T15:48:27Z,Index template to contain information about analyses. Required by #15. ,rjchallis,https://github.com/genomehubs/genomehubs/issues/21,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTIxNTA0MDc=,Add analysis index method,CLOSED,2021-01-22T16:42:51Z,2021-02-22T14:45:03Z,2021-02-22T14:45:02Z,Required by #15,rjchallis,https://github.com/genomehubs/genomehubs/issues/22,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTMxNzkxMjA=,Migrate Molluscdb to Sanger,OPEN,2021-01-25T08:53:58Z,2021-01-25T12:41:16Z,,"- [ ] Request new sanger openstack tenancy in parallel Same as: #24 
- [ ] Follow rjchallis notes to set up lxcs and dockers on Sanger Openstack infrastructure (existing team301-gh tenancy while waiting for new one)
- [ ] Request sanger IT to open ports on OpenStack
- [ ] Test with domain name mapped to ports
- [ ] migrate molluscdb.org domain name to Sanger",sujaikumar,https://github.com/genomehubs/genomehubs/issues/23,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTMxODE0MzA=,Request new sanger openstack tenancy,CLOSED,2021-01-25T08:56:58Z,2021-01-27T16:03:37Z,2021-01-27T16:03:37Z,"- [x] Calculate requirements
- [x] Email helpdesk (esp Pete Clapham, see Ken Haugh email and slack from 2021-01-21)
- [x] Check if FCE allocation done",sujaikumar,https://github.com/genomehubs/genomehubs/issues/24,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTMxOTI4MDQ=,Migrate Lepbase to Sanger,OPEN,2021-01-25T09:11:18Z,2021-01-25T09:11:27Z,,"- [ ] Export existing databases
- [ ] Set up new lxc and dockers on Openstack
- [ ] New species:
  - [ ] Chanchal Hooktip Moth Drepana arcuata
  - [ ] Suriya Bicyclus anynana
  - [ ] Look up genomes on pubmed/NCBI
  - [ ] Make list of DTOL leps to be added
",sujaikumar,https://github.com/genomehubs/genomehubs/issues/25,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTQwNjk5NTk=,Migrate GoaT host to OpenStack from Edinburgh,CLOSED,2021-01-26T09:22:07Z,2023-09-15T09:37:36Z,2023-09-15T09:37:36Z,"- [x] Create hosts on Openstack using command line
- [ ] Follow rich notes to set up new host and GoaT instance",sujaikumar,https://github.com/genomehubs/genomehubs/issues/26,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTUwMjMxMTk=,Implement alternate backbone taxonomies,CLOSED,2021-01-27T11:34:56Z,2023-04-04T10:37:55Z,2023-04-04T10:37:55Z,"Supporting alternate backbone taxonomies during import requires re-parsing common files or writing concurrently to multiple indices. Alternatively re-indexing to add alternate taxonomy indices after importing under the default taxonomy may be possible given a mapping between the default and alternate taxon IDs.

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/29,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTUwODU5MDQ=,check taxon_id(s) and assembly_id(s) exist in database when importing files,CLOSED,2021-01-27T13:07:25Z,2021-02-22T14:45:03Z,2021-02-22T14:45:03Z,when importing files and analyses,rjchallis,https://github.com/genomehubs/genomehubs/issues/30,genomehubs++genomehubs.csv
MDU6SXNzdWUxMjI0MjAzMTgw,Functions should be documented,OPEN,2021-01-29T08:56:20Z,2022-05-03T14:46:29Z,,All functions need more inline documentation and comments.,rjchallis,https://github.com/genomehubs/genomehubs/issues/132,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTkxNzAzMTI=,Generate text file previews,OPEN,2021-02-02T10:56:15Z,2021-02-02T10:56:15Z,,"Create a preview file when indexing (gzipped) text files

Assignees: @rjchallis
Labels: enhancement

https://github.com/genomehubs/genomehubs/blob/7bd00dbae1be55d60973e4441013554e8a3b62ee/src/genomehubs/lib/files.py#L131-L131

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/32,genomehubs++genomehubs.csv
MDU6SXNzdWU3OTkxODgwMDY=,include lineage summary in analysis index,CLOSED,2021-02-02T11:18:56Z,2021-02-22T14:45:03Z,2021-02-22T14:45:03Z,"Add a list of ancestors to analysis index to allow testing of single vs double lookup to find analyses by taxon.

Assignees: @rjchallis
Labels: enhancement

https://github.com/genomehubs/genomehubs/blob/7bd00dbae1be55d60973e4441013554e8a3b62ee/src/genomehubs/lib/files.py#L319-L319

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/33,genomehubs++genomehubs.csv
MDU6SXNzdWU4MDkxMDU1MDU=,Include external links to resources such as NBN and BOLD in index,OPEN,2021-02-16T08:42:23Z,2021-02-24T16:03:55Z,,Would be useful to be able to check for entries in external resources for all taxa in the index and add links where relevant. Example resources to link to include [NBN](https://nbn.org.uk) and [BOLD](https://www.boldsystems.org),rjchallis,https://github.com/genomehubs/genomehubs/issues/35,genomehubs++genomehubs.csv
MDU6SXNzdWU4MTQ0MjkxNzE=,Add a BlobToolKit parser,CLOSED,2021-02-23T12:42:18Z,2021-02-23T17:11:15Z,2021-02-23T17:11:15Z,"Would be good to be able to add BTK analyses and plots to a GenomeHub.

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/37,genomehubs++genomehubs.csv
MDU6SXNzdWU4MTY0NjMzNDU=,parallelise fill,CLOSED,2021-02-25T13:59:59Z,2021-03-01T09:21:00Z,2021-03-01T09:21:00Z,"`genomehubs fill` is single threaded but it should be possible to run the command simultaneously on separate subtrees as the lineages will be independent. 

This could be done manually by running separate commands for separate subtrees, but a final command to join the subtrees would still traverse the whole tree. A quick solution could be to allow the `max_depth` relative to the root to be set as a command line parameter.

A more complete solution would query the tree to find subtree roots, then use python multiprocessing to run fill in parallel before joining the subtrees with a `max_depth` parameter automatically set to the depth of the subtree roots.

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/40,genomehubs++genomehubs.csv
MDU6SXNzdWU4MTg2OTE4ODA=,No files visible at download.mealybug.org,CLOSED,2021-03-01T09:53:40Z,2022-01-14T14:52:35Z,2021-03-01T12:34:19Z,"Hi,
I am trying to download some files from the MealyBugBase but I cannot see any. Are they only currently not available?

Thanks for help.",mjutersek,https://github.com/genomehubs/genomehubs/issues/42,genomehubs++genomehubs.csv
MDU6SXNzdWU4MTg2OTgwMzI=,Get assembly stats from EBI,CLOSED,2021-03-01T10:01:05Z,2022-10-27T14:35:00Z,2022-10-27T14:35:00Z,"We used to get this from NCBI datasets but given that it doesn't always run fully, we should have a backup that we can get from EBI",sujaikumar,https://github.com/genomehubs/genomehubs/issues/43,genomehubs++genomehubs.csv
MDU6SXNzdWU4MTk4MTgzODg=,Get assembly data from NCBI datasets summary,CLOSED,2021-03-02T09:19:45Z,2022-06-29T13:50:37Z,2022-06-29T13:50:37Z,"Fetching assembly summary data from NCBI datasets works more reliably than fetching dehydrated bags (the current default). Need a method to fetch and parse NCBI datasets summaries based on a root taxonID. Removes the immediate need to parse ENA browser (#43)

@sujaikumar suggests implementing as:

```
genomehubs parse --ncbi-datasets-summary <TAXID>
```

which should call:

```
datasets summary genome taxon <TAXID>
```

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/44,genomehubs++genomehubs.csv
MDU6SXNzdWU4MjA4NzU0NzA=,Write successful imports to file,CLOSED,2021-03-03T08:26:45Z,2021-03-03T09:14:58Z,2021-03-03T09:14:58Z,"Mirroring the exceptions files for successfully imported records will make it easier to consolidate imports where some records need manual cleaning to fix exceptions

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/45,genomehubs++genomehubs.csv
MDU6SXNzdWU4MjQyOTA5OTQ=,Check all names / synonyms while indexing new data in GoaT,CLOSED,2021-03-08T07:59:11Z,2022-10-27T14:31:49Z,2022-10-27T14:31:49Z,"Currently, if there is a taxon_id provided, then new metadata being indexed using `genomehubs index` is hung on the node with that taxon_id. If there is no taxon_id (which is usually the case, eg for legislation, species target lists etc) then the species name in the data to be indexed is only checked against the scientific name of taxa in GoaT. Ideally we should check ALL names/synonyms for each taxon.

If there are two taxa in GoaT that match the same name (usually the case with subspecies, eg ""genus species subspecies"" and ""genus subspecies"" both exist, or else the same ""genus species"" names are in two totally different phyla), the ambiguity could be resolved by checking lineages from most specific specific to least. For each lineage provided in the new data file being indexed, all lineage synonyms should be checked too.

If still ambiguous, then the new data should be reported in the exceptions folder.",sujaikumar,https://github.com/genomehubs/genomehubs/issues/47,genomehubs++genomehubs.csv
MDU6SXNzdWU4MjQyOTg2MDA=,Check if Elastic Search speeds up when installed with multiple nodes,OPEN,2021-03-08T08:08:48Z,2021-03-08T08:08:48Z,,"ES takes several hours for `genomehubs fill --traverse-root 2759 --traverse-infer-descendants`. The amount of time seems to be identical even when using parallelised code in #40 suggesting that the bottleneck is es api calls.

Check if es installed on multiple nodes is faster than es installed on a single node ",sujaikumar,https://github.com/genomehubs/genomehubs/issues/48,genomehubs++genomehubs.csv
MDU6SXNzdWU4MjQzNjYzMTU=,Change hardcoded api url in goat-ui,CLOSED,2021-03-08T09:25:00Z,2021-03-23T10:21:45Z,2021-03-23T10:21:45Z,,sujaikumar,https://github.com/genomehubs/genomehubs/issues/49,genomehubs++genomehubs.csv
MDU6SXNzdWU4MjQ1NzQ4Nzg=,keep descendant nodes in memory during fill,CLOSED,2021-03-08T13:44:05Z,2021-03-19T11:53:15Z,2021-03-19T11:53:15Z,Current run time of `genomehubs fill --traverse-inder-descendants` is very slow with rich metadata for all NCBI taxa (GoaT use case). Keeping descendant taxa in memory should significantly reduce the number of elasticsearch queries.,rjchallis,https://github.com/genomehubs/genomehubs/issues/50,genomehubs++genomehubs.csv
MDU6SXNzdWU4MjU2MDg0MDE=,include ancestral rank in aggregation source,CLOSED,2021-03-09T09:30:41Z,2021-08-06T15:43:56Z,2021-08-06T15:43:56Z,https://github.com/genomehubs/genomehubs/blob/589966768f6dfe8f26a21cc8f872ef54d626eef0/src/genomehubs/lib/fill.py#L322-L322,rjchallis,https://github.com/genomehubs/genomehubs/issues/51,genomehubs++genomehubs.csv
MDU6SXNzdWU4MzUwMTk0NDc=,catch traverse limits when limit rank is missing,CLOSED,2021-03-18T16:25:23Z,2021-08-06T15:43:56Z,2021-08-06T15:43:56Z,"Attrbutes may fill past taxa with no ancestor at a traverse_limit rank. Need to use a rank hierarchy to avoid this.

Assignees: 
Labels: 

https://github.com/genomehubs/genomehubs/blob/638dd3226d62638fc8adbc2c3a6a82e485eb4a65/src/genomehubs/lib/fill.py#L257-L257

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/53,genomehubs++genomehubs.csv
MDU6SXNzdWU4MzUwMjY1NjI=,add comment character(s) to names/types.yaml to ignore when indexing,CLOSED,2021-03-18T16:33:19Z,2021-08-06T15:43:56Z,2021-08-06T15:43:56Z,"Defaults can be ""#"", and ""//"", with perhaps the possibility of adding new ones in yaml?",sujaikumar,https://github.com/genomehubs/genomehubs/issues/54,genomehubs++genomehubs.csv
MDU6SXNzdWU4MzU4OTkwMDM=,Load taxon names as xrefs,CLOSED,2021-03-19T11:52:05Z,2021-08-06T15:43:55Z,2021-08-06T15:43:55Z,"<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/55,genomehubs++genomehubs.csv
MDU6SXNzdWU4MzYxOTg4ODE=,Check spelling when indexing,CLOSED,2021-03-19T17:01:08Z,2021-08-06T15:43:56Z,2021-08-06T15:43:56Z,"Currently, index.py checks if taxonomy in file to be indexed matches exactly. However, many user-provided files have misspellings/extra spaces.

If species name does not match exactly, then index.py could use lookup / suggest options already implemented and if exactly 1 species is returned, then that should be used, else the record to be imported can go into exceptions.",sujaikumar,https://github.com/genomehubs/genomehubs/issues/58,genomehubs++genomehubs.csv
MDU6SXNzdWU4Mzg2NzY0ODI=,Use preferred values in aggregation,CLOSED,2021-03-23T12:30:26Z,2021-08-06T15:43:57Z,2021-08-06T15:43:57Z,"When summarising multiple values for a taxon, often one of the values can be labelled as the preferred value (e.g. `prime_value` field in Kew plant c values. 

Need a summary option to use this value if available (e.g. give column header and check if value is true or false)",rjchallis,https://github.com/genomehubs/genomehubs/issues/62,genomehubs++genomehubs.csv
MDU6SXNzdWU4NTEyNDA0MTY=,Set default traverse limit to class in genomehubs fill command line,CLOSED,2021-04-06T09:32:12Z,2021-08-06T15:43:57Z,2021-08-06T15:43:57Z,,sujaikumar,https://github.com/genomehubs/genomehubs/issues/64,genomehubs++genomehubs.csv
MDU6SXNzdWU4NTIxNTIxMjU=,Write taxon IDs to imported/exceptions files,CLOSED,2021-04-07T08:21:05Z,2021-08-06T15:43:57Z,2021-08-06T15:43:57Z,"Storing a list of taxon_id/scientific_name matches alongside spellchecked or imported taxa will help speed up importing of updated files by creating lists that can be placed in a names directory to remove the need for taxon_id lookups.

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/66,genomehubs++genomehubs.csv
MDU6SXNzdWU4NTIxNzAzNzQ=,In memory taxon name lookup,CLOSED,2021-04-07T08:42:06Z,2021-08-06T15:43:58Z,2021-08-06T15:43:58Z,"Taxon lookup is slow due to the number of search queries generated. Using in-memory lookups should be much faster

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/68,genomehubs++genomehubs.csv
MDU6SXNzdWU4NTIyMjEyOTg=,Add a reports index,CLOSED,2021-04-07T09:38:24Z,2021-11-29T14:21:55Z,2021-11-29T14:21:55Z,"In order to allow different hubs to show different reports, it would be useful to have a reports index to contain the report metadata and relevant queries.

For example, to report on a large-scale sequencing project progress, the index could define, a bar plot, with stackedc bars showing total number of target taxa, number with assemblies and number with high quality assemblies for species, genus and family.
<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/69,genomehubs++genomehubs.csv
MDU6SXNzdWU4NTQ1NjczNTE=,Calculate EBP metrics,CLOSED,2021-04-09T14:16:40Z,2023-04-04T10:38:35Z,2023-04-04T10:38:35Z,"Useful to show EBP metrics for the primary assembly for each taxon. Should be calculated while parsing assembly metadata.

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/72,genomehubs++genomehubs.csv
MDU6SXNzdWU4NTQ1NzA0OTQ=,Add a pages index,CLOSED,2021-04-09T14:20:20Z,2021-11-29T14:21:01Z,2021-11-29T14:21:01Z,"Support localisation of geneomehubs by adding a pages index to store descriptive Markdown (e.g. an about page, search examples, etc.)

Also need to define sets of reports, so may be appropriate to have an single index for localisation or may be better to place different data in dedicated indices.

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/73,genomehubs++genomehubs.csv
MDU6SXNzdWU5MTQ0OTkwMDY=,use enum position to prioritise values during traverse,CLOSED,2021-06-08T07:42:48Z,2021-08-06T15:43:58Z,2021-08-06T15:43:58Z,"Filling values such as assembly_level requires ranking to determine which value to propagate. This ranking could be taken from the associated enum, e.g.:

```
assembly_level:
    ...
    constraint:
      enum:
        - chromosome
        - scaffold
        - contig
    summary: enum
    traverse: enum
    traverse_direction: up
    ...
```

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/74,genomehubs++genomehubs.csv
MDU6SXNzdWU5MTYxMTc4ODg=,add genomehubs parse --gbif,CLOSED,2021-06-09T11:56:21Z,2023-04-04T10:38:52Z,2023-04-04T10:38:52Z,"The GBIF taxonomy backbone can be downloaded like this:
```
wget https://hosted-datasets.gbif.org/datasets/backbone/backbone-current.zip
unzip backbone-current.zip
head .meta/Taxon.tsv
```
Taxon.tsv has about 6.8 million rows, which look like this:
```
taxonID   datasetID                              parentNameUsageID   acceptedNameUsageID   originalNameUsageID   scientificName                                             scientificNameAuthorship          canonicalName                 genericName             specificEpithet   infraspecificEpithet   taxonRank   nameAccordingTo   namePublishedIn                                                                                                                                                                                                                                                                                                                      taxonomicStatus     nomenclaturalStatus   taxonRemarks                                                                                  kingdom          phylum                class               order              family              genus
0         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   incertae sedis                                                                               incertae sedis                incertae sedis                                                   kingdom                                                                                                                                                                                                                                                                                                                                                            doubtful                                                                                                                                incertae sedis                                                                                    
1         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Animalia                                                                                     Animalia                      Animalia                                                         kingdom                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia                                                                                          
2         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Archaea                                                                                      Archaea                       Archaea                                                          kingdom                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Archaea                                                                                           
3         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Bacteria                                                                                     Bacteria                      Bacteria                                                         kingdom                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Bacteria                                                                                          
4         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Chromista                                                                                    Chromista                     Chromista                                                        kingdom                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Chromista                                                                                         
5         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Fungi                                                                                        Fungi                         Fungi                                                            kingdom                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Fungi                                                                                             
6         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Plantae                                                                                      Plantae                       Plantae                                                          kingdom                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Plantae                                                                                           
7         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Protozoa                                                                                     Protozoa                      Protozoa                                                         kingdom                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Protozoa                                                                                          
8         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Viruses                                                                                      Viruses                       Viruses                                                          kingdom                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Viruses                                                                                           
9         daacce49-b206-469b-8dc2-2257719f3afa   6                                                               Marchantiophyta                                                                              Marchantiophyta               Marchantiophyta                                                  phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Plantae          Marchantiophyta                                                                  
11        daacce49-b206-469b-8dc2-2257719f3afa   6                   7707728                                     Ginkgophyta                                                                                  Ginkgophyta                   Ginkgophyta                                                      phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Plantae          Tracheophyta                                                                     
12        daacce49-b206-469b-8dc2-2257719f3afa   6                   7707728                                     Lycopodiophyta                                                                               Lycopodiophyta                Lycopodiophyta                                                   phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Plantae          Tracheophyta                                                                     
13        7ddf754f-d193-4cc9-b351-99906754a03b   6                                                               Anthocerotophyta                                                                             Anthocerotophyta              Anthocerotophyta                                                 phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Plantae          Anthocerotophyta                                                                 
14        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Tardigrada                                                                                   Tardigrada                    Tardigrada                                                       phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Tardigrada                                                                       
18        7ddf754f-d193-4cc9-b351-99906754a03b   5                                                               Glomeromycota                                                                                Glomeromycota                 Glomeromycota                                                    phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Fungi            Glomeromycota                                                                    
19        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Phoronida                                                                                    Phoronida                     Phoronida                                                        phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Phoronida                                                                        
22        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Gastrotricha                                                                                 Gastrotricha                  Gastrotricha                                                     phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Gastrotricha                                                                     
25        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10841181                                    Acidobacteria                                                                                Acidobacteria                 Acidobacteria                                                    phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Acidobacteriota                                                                  
26        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10813635                                    Actinobacteria                                                                               Actinobacteria                Actinobacteria                                                   phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Actinobacteriota                                                                 
28        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10831091                                    Deferribacteres                                                                              Deferribacteres               Deferribacteres                                                  phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Deferribacterota                                                                 
29        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10733136                                    Fibrobacteres                                                                                Fibrobacteres                 Fibrobacteres                                                    phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Fibrobacterota                                                                   
30        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10725132                                    Gemmatimonadetes                                                                             Gemmatimonadetes              Gemmatimonadetes                                                 phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Gemmatimonadota                                                                  
31        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10773962                                    Lentisphaerae                                                                                Lentisphaerae                 Lentisphaerae                                                    phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Verrucomicrobiota                                                                
32        7ddf754f-d193-4cc9-b351-99906754a03b   4                                                               Oomycota                                                                                     Oomycota                      Oomycota                                                         phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Chromista        Oomycota                                                                         
33        7ddf754f-d193-4cc9-b351-99906754a03b   7                                                               Mycetozoa                                                                                    Mycetozoa                     Mycetozoa                                                        phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Protozoa         Mycetozoa                                                                        
34        7ddf754f-d193-4cc9-b351-99906754a03b   5                                                               Basidiomycota                                                                                Basidiomycota                 Basidiomycota                                                    phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Fungi            Basidiomycota                                                                    
35        daacce49-b206-469b-8dc2-2257719f3afa   6                                                               Bryophyta                                                                                    Bryophyta                     Bryophyta                                                        phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Plantae          Bryophyta                                                                        
36        daacce49-b206-469b-8dc2-2257719f3afa   6                                                               Chlorophyta                                                                                  Chlorophyta                   Chlorophyta                                                      phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Plantae          Chlorophyta                                                                      
37        7ea21580-4f06-469d-995b-3f713fdcc37c   6                                                               Glaucophyta                                                                                  Glaucophyta                   Glaucophyta                                                      phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Plantae          Glaucophyta                                                                      
38        7ea21580-4f06-469d-995b-3f713fdcc37c   4                                                               Cercozoa                                                                                     Cercozoa                      Cercozoa                                                         phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Chromista        Cercozoa                                                                         
41        7ea21580-4f06-469d-995b-3f713fdcc37c   7                                                               Euglenozoa                                                                                   Euglenozoa                    Euglenozoa                                                       phylum                        Cavalier-Smith, T. (1981). Eukaryote kingdoms: Seven or nine?. Biosystems. 14(3-4): 461-481.                                                                                                                                                                                                                                         accepted                                                                                                                                Protozoa         Euglenozoa                                                                       
42        daacce49-b206-469b-8dc2-2257719f3afa   1                                                               Annelida                                                                                     Annelida                      Annelida                                                         phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Annelida                                                                         
43        daacce49-b206-469b-8dc2-2257719f3afa   1                                                               Cnidaria                                                                                     Cnidaria                      Cnidaria                                                         phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Cnidaria                                                                         
44        daacce49-b206-469b-8dc2-2257719f3afa   1                                                               Chordata                                                                                     Chordata                      Chordata                                                         phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Chordata                                                                         
45        7ddf754f-d193-4cc9-b351-99906754a03b   5963076             10868220                                    Cycliophora                                                                                  Cycliophora                   Cycliophora                                                      phylum                        Funch, P. and R. M. Kristensen. Cycliophora is a new phylum with affinities to Entoprocta and Ectoprocta. Nature, vol. 378, no. 6558. (1995).                                                                                                                                                                                        synonym                                                                                                                                 Animalia         Kamptozoa             Cycliophora                                                
46        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10719742                                    Thermodesulfobacteria                                                                        Thermodesulfobacteria         Thermodesulfobacteria                                            phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Desulfobacterota                                                                 
47        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10897891                                    Thermotogae                                                                                  Thermotogae                   Thermotogae                                                      phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Thermotogota                                                                     
48        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10773962                                    Verrucomicrobia                                                                              Verrucomicrobia               Verrucomicrobia                                                  phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Verrucomicrobiota                                                                
49        daacce49-b206-469b-8dc2-2257719f3afa   6                   7707728                                     Magnoliophyta                                                                                Magnoliophyta                 Magnoliophyta                                                    phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Plantae          Tracheophyta                                                                     
50        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Echinodermata                                                                                Echinodermata                 Echinodermata                                                    phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Echinodermata                                                                    
51        daacce49-b206-469b-8dc2-2257719f3afa   1                                                               Ctenophora                                                                                   Ctenophora                    Ctenophora                                                       phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Ctenophora                                                                       
52        daacce49-b206-469b-8dc2-2257719f3afa   1                                                               Mollusca                                                                                     Mollusca                      Mollusca                                                         phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Mollusca                                                                         
53        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Bryozoa                                                                                      Bryozoa                       Bryozoa                                                          phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Bryozoa                                                                          
54        daacce49-b206-469b-8dc2-2257719f3afa   1                                                               Arthropoda                                                                                   Arthropoda                    Arthropoda                                                       phylum                        von Siebold, C.T. & Stannius, H. Lehrbuch der vergleichenden Anatomie der Wirbellosen Thiere, Erster Theil. 1-679 (1848).                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda                                                                       
55        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Chaetognatha                                                                                 Chaetognatha                  Chaetognatha                                                     phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Chaetognatha                                                                     
56        7ddf754f-d193-4cc9-b351-99906754a03b   7                                                               Sarcomastigophora                                                                            Sarcomastigophora             Sarcomastigophora                                                phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Protozoa         Sarcomastigophora                                                                
59        daacce49-b206-469b-8dc2-2257719f3afa   6                   7707728                                     Pteridophyta                                                                                 Pteridophyta                  Pteridophyta                                                     phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Plantae          Tracheophyta                                                                     
60        daacce49-b206-469b-8dc2-2257719f3afa   6                   7707728                                     Psilophyta                                                                                   Psilophyta                    Psilophyta                                                       phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Plantae          Tracheophyta                                                                     
61        daacce49-b206-469b-8dc2-2257719f3afa   6                   7707728                                     Equisetophyta                                                                                Equisetophyta                 Equisetophyta                                                    phylum                        In: Stud. Foss. Pl. 13, 489, 492, 493 (Division). (1900).                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Plantae          Tracheophyta                                                                     
62        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Onychophora                                                                                  Onychophora                   Onychophora                                                      phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Onychophora                                                                      
63        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Nemertea                                                                                     Nemertea                      Nemertea                                                         phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Nemertea                                                                         
64        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Nematomorpha                                                                                 Nematomorpha                  Nematomorpha                                                     phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Nematomorpha                                                                     
66        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Myxozoa                                                                                      Myxozoa                       Myxozoa                                                          phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Myxozoa                                                                          
67        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Acanthocephala                                                                               Acanthocephala                Acanthocephala                                                   phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Acanthocephala                                                                   
68        a97f36e5-ded1-49cc-bdec-ac6170fc7b9c   3                                                               Cyanobacteria                                                                                Cyanobacteria                 Cyanobacteria                                                    phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Bacteria         Cyanobacteria                                                                    
69        daacce49-b206-469b-8dc2-2257719f3afa   4                                                               Cryptophyta                                                                                  Cryptophyta                   Cryptophyta                                                      phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Chromista        Cryptophyta                                                                      
70        7ea21580-4f06-469d-995b-3f713fdcc37c   4                                                               Haptophyta                                                                                   Haptophyta                    Haptophyta                                                       phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Chromista        Haptophyta                                                                       
73        7ddf754f-d193-4cc9-b351-99906754a03b   5                                                               Blastocladiomycota                                                                           Blastocladiomycota            Blastocladiomycota                                               phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Fungi            Blastocladiomycota                                                               
74        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Sipuncula                                                                                    Sipuncula                     Sipuncula                                                        phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Sipuncula                                                                        
75        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Hemichordata                                                                                 Hemichordata                  Hemichordata                                                     phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Hemichordata                                                                     
76        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Placozoa                                                                                     Placozoa                      Placozoa                                                         phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Placozoa                                                                         
77        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Gnathostomulida                                                                              Gnathostomulida               Gnathostomulida                                                  phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Gnathostomulida                                                                  
78        daacce49-b206-469b-8dc2-2257719f3afa   6                   7707728                                     Gnetophyta                                                                                   Gnetophyta                    Gnetophyta                                                       phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Plantae          Tracheophyta                                                                     
79        aa1bc573-f338-482d-b6aa-f371d57f20f5   2                   10807497                                    Crenarchaeota                                                                                Crenarchaeota                 Crenarchaeota                                                    phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Archaea          Thermoproteota                                                                   
80        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10810028                                    Aquificae                                                                                    Aquificae                     Aquificae                                                        phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Aquificota                                                                       
81        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10707955                                    Bacteroidetes                                                                                Bacteroidetes                 Bacteroidetes                                                    phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Bacteroidota                                                                     
82        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10828670                                    Chlamydiae                                                                                   Chlamydiae                    Chlamydiae                                                       phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Verrucomicrobiota_A                                                              
83        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10707955                                    Chlorobi                                                                                     Chlorobi                      Chlorobi                                                         phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Bacteroidota                                                                     
84        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10690675                                    Chloroflexi                                                                                  Chloroflexi                   Chloroflexi                                                      phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Chloroflexota                                                                    
85        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10779861                                    Dictyoglomi                                                                                  Dictyoglomi                   Dictyoglomi                                                      phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Dictyoglomota                                                                    
87        a97f36e5-ded1-49cc-bdec-ac6170fc7b9c   3                                                               Firmicutes                                                                                   Firmicutes                    Firmicutes                                                       phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Bacteria         Firmicutes                                                                       
88        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10685384                                    Fusobacteria                                                                                 Fusobacteria                  Fusobacteria                                                     phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Fusobacteriota                                                                   
90        aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10815135                                    Planctomycetes                                                                               Planctomycetes                Planctomycetes                                                   phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Planctomycetota                                                                  
91        7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Rotifera                                                                                     Rotifera                      Rotifera                                                         phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Rotifera                                                                         
94        7ddf754f-d193-4cc9-b351-99906754a03b   5                                                               Chytridiomycota                                                                              Chytridiomycota               Chytridiomycota                                                  phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Fungi            Chytridiomycota                                                                  
95        daacce49-b206-469b-8dc2-2257719f3afa   5                                                               Ascomycota                                                                                   Ascomycota                    Ascomycota                                                       phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Fungi            Ascomycota                                                                       
96        7ddf754f-d193-4cc9-b351-99906754a03b   5                                                               Zygomycota                                                                                   Zygomycota                    Zygomycota                                                       phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Fungi            Zygomycota                                                                       
97        7ddf754f-d193-4cc9-b351-99906754a03b   7                                                               Choanozoa                                                                                    Choanozoa                     Choanozoa                                                        phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Protozoa         Choanozoa                                                                        
98        7ea21580-4f06-469d-995b-3f713fdcc37c   4                                                               Ochrophyta                                                                                   Ochrophyta                    Ochrophyta                                                       phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Chromista        Ochrophyta                                                                       
103       daacce49-b206-469b-8dc2-2257719f3afa   6                   7707728                                     Cycadophyta                                                                                  Cycadophyta                   Cycadophyta                                                      phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Plantae          Tracheophyta                                                                     
104       7ea21580-4f06-469d-995b-3f713fdcc37c   36                  336                                         Prasinophyta                                                                                 Prasinophyta                  Prasinophyta                                                     phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Plantae          Chlorophyta           Prasinophyceae                                             
105       7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Porifera                                                                                     Porifera                      Porifera                                                         phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Porifera                                                                         
106       7ea21580-4f06-469d-995b-3f713fdcc37c   6                                                               Rhodophyta                                                                                   Rhodophyta                    Rhodophyta                                                       phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Plantae          Rhodophyta                                                                       
108       7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Platyhelminthes                                                                              Platyhelminthes               Platyhelminthes                                                  phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Platyhelminthes                                                                  
110       7ddf754f-d193-4cc9-b351-99906754a03b   1                                                               Brachiopoda                                                                                  Brachiopoda                   Brachiopoda                                                      phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Animalia         Brachiopoda                                                                      
111       a97f36e5-ded1-49cc-bdec-ac6170fc7b9c   3                                                               Proteobacteria                                                                               Proteobacteria                Proteobacteria                                                   phylum                                                                                                                                                                                                                                                                                                                                                             accepted                                                                                                                                Bacteria         Proteobacteria                                                                   
112       aa1bc573-f338-482d-b6aa-f371d57f20f5   3                   10707403                                    Spirochaetes                                                                                 Spirochaetes                  Spirochaetes                                                     phylum                                                                                                                                                                                                                                                                                                                                                             synonym                                                                                                                                 Bacteria         Spirochaetota                                                                    
116       7ddf754f-d193-4cc9-b351-99906754a03b   7509337                                                         Lobosa                                                                                       Lobosa                        Lobosa                                                           class                                                                                                                                                                                                                                                                                                                                                              accepted                                                                                                                                Protozoa         Amoebozoa             Lobosa                                                     
118       7ddf754f-d193-4cc9-b351-99906754a03b   56                                                              Zoomastigophora                                                                              Zoomastigophora               Zoomastigophora                                                  class                                                                                                                                                                                                                                                                                                                                                              accepted                                                                                                                                Protozoa         Sarcomastigophora     Zoomastigophora                                            
119       7ddf754f-d193-4cc9-b351-99906754a03b   44                                                              Myxini                                                                                       Myxini                        Myxini                                                           class                                                                                                                                                                                                                                                                                                                                                              accepted                                                                                                                                Animalia         Chordata              Myxini                                                     
120       7ddf754f-d193-4cc9-b351-99906754a03b   44                                                              Holocephali                                                                                  Holocephali                   Holocephali                                                      class                                                                                                                                                                                                                                                                                                                                                              accepted                                                                                                                                Animalia         Chordata              Holocephali                                                
121       7ddf754f-d193-4cc9-b351-99906754a03b   44                                                              Elasmobranchii                                                                               Elasmobranchii                Elasmobranchii                                                   class                                                                                                                                                                                                                                                                                                                                                              accepted                                                                                                                                Animalia         Chordata              Elasmobranchii                                             
125       7ddf754f-d193-4cc9-b351-99906754a03b   9                                                               Marchantiopsida                                                                              Marchantiopsida               Marchantiopsida                                                  class                                                                                                                                                                                                                                                                                                                                                              accepted                                                                                                                                Plantae          Marchantiophyta       Marchantiopsida                                            
126       7ddf754f-d193-4cc9-b351-99906754a03b   9                                                               Jungermanniopsida                                                                            Jungermanniopsida             Jungermanniopsida                                                class                                                                                                                                                                                                                                                                                                                                                              accepted                                                                                                                                Plantae          Marchantiophyta       Jungermanniopsida                                          
127       7ddf754f-d193-4cc9-b351-99906754a03b   9                                                               Haplomitriopsida                                                                             Haplomitriopsida              Haplomitriopsida                                                 class                                                                                                                                                                                                                                                                                                                                                              accepted                                                                                                                                Plantae          Marchantiophyta       Haplomitriopsida                                           
131       daacce49-b206-469b-8dc2-2257719f3afa   44                                                              Amphibia                                                                                     Amphibia                      Amphibia                                                         class                                                                                                                                                                                                                                                                                                                                                              accepted                                                                                                                                Animalia         Chordata              Amphibia                                                   
132       7ddf754f-d193-4cc9-b351-99906754a03b   13                                                              Anthocerotopsida                                                                             Anthocerotopsida              Anthocerotopsida                                                 class                                                                                                                                                                                                                                                                                                                                                              accepted                                                                                                                                Plantae          Anthocerotophyta      Anthocerotopsida                                           
133       7ddf754f-d193-4cc9-b351-99906754a03b   14                                                              Mesotardigrada                                                                               Mesotardigrada                Mesotardigrada                                                   class                                                                                                                                                                                                                                                                                                                                                              accepted                                                                                                                                Animalia         Tardigrada            Mesotardigrada                                             
134       7ddf754f-d193-4cc9-b351-99906754a03b   14                                                              Eutardigrada                                                                                 Eutardigrada                  Eutardigrada                                                     class                                                                                                                                                                                                                                                                                                                                                              accepted                                                                                                                                Animalia         Tardigrada            Eutardigrada                                               
2210693   7ddf754f-d193-4cc9-b351-99906754a03b   4571                                                            Globarcturus Kussakin & Vasina, 1994                       Kussakin & Vasina, 1994           Globarcturus                  Globarcturus                                                     genus                         Kussakin, O. G. and Vasina, G. S. (1994) Description of Globarcturus angelikae gen. et sp. n., the first hadal arcturid from the South Sandwich Trench (Crustacea, Isopoda: Arcturidae). Zoosystematica Rossica 2 (2): 241-245.                                                                                                      accepted                                                                                                                                Animalia         Arthropoda            Malacostraca        Isopoda            Antarcturidae       Globarcturus
2241204   7ddf754f-d193-4cc9-b351-99906754a03b   7611668             5181196                                     Plumohalichondria papillosa Arnesen, 1903                  Arnesen, 1903                     Plumohalichondria papillosa   Plumohalichondria       papillosa                                species                       Arnesen, E. Spongien von der norwegischen Kste. II. Monaxonida: Halichondrina. Bergens Museum arbog. 1903: 1-30, pls I-VII. (1903).                                                                                                                                                                                                synonym                                                                                                                                 Animalia         Porifera              Demospongiae        Poecilosclerida    Hymedesmiidae       Phorbas
1925613   7ddf754f-d193-4cc9-b351-99906754a03b   1925584                                                         Anthene hewitsoni (Aurivillius, 1899)                      (Aurivillius, 1899)               Anthene hewitsoni             Anthene                 hewitsoni                                species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Lepidoptera        Lycaenidae          Anthene
2242270   7ddf754f-d193-4cc9-b351-99906754a03b   2242355                                   5181367               Mycale tunicata (Schmidt, 1862)                            (Schmidt, 1862)                   Mycale tunicata               Mycale                  tunicata                                 species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Porifera              Demospongiae        Poecilosclerida    Mycalidae           Mycale
2371487   7ddf754f-d193-4cc9-b351-99906754a03b   2371485             2371486                                     Haplochromis annectans (Regan, 1922)                       (Regan, 1922)                     Haplochromis annectans        Haplochromis            annectans                                species                                                                                                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Animalia         Chordata              Actinopterygii      Perciformes        Cichlidae           Protomelas
1052704   7ddf754f-d193-4cc9-b351-99906754a03b   1052530                                                         Neoserica semipubescens Ahrens, 2003                       Ahrens, 2003                      Neoserica semipubescens       Neoserica               semipubescens                            species                       Ahrens D. Zur identitt der gattung Neoserica, nebst revision und beschreibung neuer arten. Koleopterologische Rundschau 73:169-226. (2003).                                                                                                                                                                                         accepted                                                                                                                                Animalia         Arthropoda            Insecta             Coleoptera         Melolonthidae       Neoserica
2252311   7ddf754f-d193-4cc9-b351-99906754a03b   2252089                                                         Discodermia irregularis Hoshino, 1976                      Hoshino, 1976                     Discodermia irregularis       Discodermia             irregularis                              species                       Hoshino, T. (1976). Demosponges from the western coast of Kii Peninsula, Japan. <em>Zoological Magazine.</em> 85: 248-261.                                                                                                                                                                                                           accepted                                                                                                                                Animalia         Porifera              Demospongiae        Tetractinellida    Theonellidae        Discodermia
1624758   7ddf754f-d193-4cc9-b351-99906754a03b   1624754             1624757                                     Conionota fracta Munro, 1947                               Munro, 1947                       Conionota fracta              Conionota               fracta                                   species                                                                                                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Diptera            Tephritidae         Afraciura
1536168   a6c6cead-b5ce-4a4e-8cf5-1542ba708dec   1536144             5071107                                     Musca fallax Linnaeus, 1758                                Linnaeus, 1758                    Musca fallax                  Musca                   fallax                                   species                                                                                                                                                                                                                                                                                                                                                            homotypic synonym                                                                                                                       Animalia         Arthropoda            Insecta             Diptera            Syrphidae           Blera
1977180   7ddf754f-d193-4cc9-b351-99906754a03b   1977179                                                         Thinopteryx praetoraria Felder, 1873                       Felder, 1873                      Thinopteryx praetoraria       Thinopteryx             praetoraria                              species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Lepidoptera        Geometridae         Thinopteryx
1854721   7ddf754f-d193-4cc9-b351-99906754a03b   4406686                                                         Melasina linicoma Meyrick, 1914                            Meyrick, 1914                     Melasina linicoma             Melasina                linicoma                                 species                                                                                                                                                                                                                                                                                                                                                            doubtful                                                                                                                                Animalia         Arthropoda            Insecta             Lepidoptera        Psychidae           Typhonia
1252818   7ddf754f-d193-4cc9-b351-99906754a03b   1252663             1252814                                     Blacus lactucaphis (Fitch, 1855)                           (Fitch, 1855)                     Blacus lactucaphis            Blacus                  lactucaphis                              species                       Fitch, A. First report on the noxious, beneficial and other insects of the state of New York made to the State Agricultural Society, persuant to an approbation for this purpose from the Legislature of the State. Transactions of the New York State Agricultural Society. 14:705-880. [Cornell (Mann) microfiche 2088]. (1855).   synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Hymenoptera        Braconidae          Blacus
1421053   7ddf754f-d193-4cc9-b351-99906754a03b   7768                                                            Trigoniophthalmus Verhoeff, 1910                           Verhoeff, 1910                    Trigoniophthalmus             Trigoniophthalmus                                                genus                         Zool. Anz., 36                                                                                                                                                                                                                                                                                                                       accepted                                                                                                                                Animalia         Arthropoda            Insecta             Archaeognatha      Machilidae          Trigoniophthalmus
1091351   7ddf754f-d193-4cc9-b351-99906754a03b   1089294                                                         Onthophagus transisthmius Howden & Young, 1981             Howden & Young, 1981              Onthophagus transisthmius     Onthophagus             transisthmius                            species                       Howden H. & Young O.P. Panamanian Scarabaeinae Taxonomie distribution and habits. Contributions American Entomological Institute 18(1):1-204. (1981).                                                                                                                                                                                accepted                                                                                                                                Animalia         Arthropoda            Insecta             Coleoptera         Scarabaeidae        Onthophagus
1198769   7ddf754f-d193-4cc9-b351-99906754a03b   1198696                                                         Baridius viridanus Boheman, 1836                           Boheman, 1836                     Baridius viridanus            Baridius                viridanus                                species                                                                                                                                                                                                                                                                                                                                                            accepted                                  Possible variant of Baridius viridana C.H.Boheman, 1836                                       Animalia         Arthropoda            Insecta             Coleoptera         Curculionidae       Baridius
1999598   7ddf754f-d193-4cc9-b351-99906754a03b   1999593                                   1999599               Shelfordina longealata (Hanitsch, 1923)                    (Hanitsch, 1923)                  Shelfordina longealata        Shelfordina             longealata                               species                       Hanitsch. Malayan Blattidae. Part II. Journal of the Malayan Branch of the Royal Asiatic Society 1:393-474. (1923).                                                                                                                                                                                                                  accepted                                                                                                                                Animalia         Arthropoda            Insecta             Blattodea          Ectobiidae          Shelfordina
1594150   7ddf754f-d193-4cc9-b351-99906754a03b   3338                                                            Parkiamyia Maia & Fernandes, 2006                          Maia & Fernandes, 2006            Parkiamyia                    Parkiamyia                                                       genus                         Revista Brasileira de Entomologia 50                                                                                                                                                                                                                                                                                                 accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Cecidomyiidae       Parkiamyia
2213617   7ddf754f-d193-4cc9-b351-99906754a03b   2213611             2213616                                     Serolis serratus Brandt, 1988                              Brandt, 1988                      Serolis serratus              Serolis                 serratus                                 species                       Brandt, A. (1988). Antarctic Serolidae and Cirolanidae (Crustaceae, Isopoda): New Genera, Species and Redescriptions. <em>Theses Zoologicae, Koeltz Scientific Books, Koenigstein.</em> 10: 1-172.                                                                                                                                   synonym                                                                                                                                 Animalia         Arthropoda            Malacostraca        Isopoda            Serolidae           Ceratoserolis
1470212   7ddf754f-d193-4cc9-b351-99906754a03b   1470177                                                         Dinera angustifrons Zhang, Wang & Liu, 2006                Zhang, Wang & Liu, 2006           Dinera angustifrons           Dinera                  angustifrons                             species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Tachinidae          Dinera
1488405   9ca92552-f23a-41a8-a140-01abaa31c931   1488203             1488404                                     Neosciara sexdentata Pettey, 1918                          Pettey, 1918                      Neosciara sexdentata          Neosciara               sexdentata                               species                                                                                                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Diptera            Sciaridae           Bradysia
1833492   7ddf754f-d193-4cc9-b351-99906754a03b   1833484                                                         Calicotis animula Meyrick, 1911                            Meyrick, 1911                     Calicotis animula             Calicotis               animula                                  species                       Meyrick E. Tortricina and Tineina. Results of the Percy Sladen Trust Expedition to the Indian Ocean in 1905. Transactions of the Linnean Society of London 1911d                                                                                                                                                                     accepted                                                                                                                                Animalia         Arthropoda            Insecta             Lepidoptera        Oecophoridae        Calicotis
1545501   7ddf754f-d193-4cc9-b351-99906754a03b   1545388                                                         Apocephalus catholicus Brown, 2000                         Brown, 2000                       Apocephalus catholicus        Apocephalus             catholicus                               species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Phoridae            Apocephalus
2210494   7ddf754f-d193-4cc9-b351-99906754a03b   8880                                                            Ceratothoa Dana, 1852                                      Dana, 1852                        Ceratothoa                    Ceratothoa                                                       genus                         Dana, J.D. (1852). On the classification of the Crustacea Choristopoda or Tetradecapoda. <em>American Journal of Science and Arts.</em> Series 2, 14: 297-316.                                                                                                                                                                       accepted                                                                                                                                Animalia         Arthropoda            Malacostraca        Isopoda            Cymothoidae         Ceratothoa
2222494   2d59e5db-57ad-41ff-97d6-11f5fb264527   8658                                                            Chlorotocus A.Milne-Edwards, 1882                          A.Milne-Edwards, 1882             Chlorotocus                   Chlorotocus                                                      genus                         Milne-Edwards, H. (1882). Rapport sur les Travaux de la Commission charge par M. le Ministre de l'Instruction Publique d'tudier la faune sous-marine dans les grandes profondeurs de la Mditerrane et de l'Ocan Atlantique. <em>Archives des missions scientifiques et littraires.</em> 9(3): 1-59.                            accepted                                                                                                                                Animalia         Arthropoda            Malacostraca        Decapoda           Pandalidae          Chlorotocus
1624702   7ddf754f-d193-4cc9-b351-99906754a03b   1624699                                                         Trypanaresta valdesiana Gandolfo & Norrbom, 1997           Gandolfo & Norrbom, 1997          Trypanaresta valdesiana       Trypanaresta            valdesiana                               species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Tephritidae         Trypanaresta
2186592   7ddf754f-d193-4cc9-b351-99906754a03b   2186588                                                         Typhlodromus lootsi Schultz, 1972                          Schultz, 1972                     Typhlodromus lootsi           Typhlodromus            lootsi                                   species                       Schultz, F.W. Three new species of the family Phytoseiidae (Acari: Mesostigmata) from South Africa. Phytophylactica, South Africa, 4, 1318. (1972).                                                                                                                                                                                 accepted                                                                                                                                Animalia         Arthropoda                                Mesostigmata       Phytoseiidae        Typhlodromus
1358240   7ddf754f-d193-4cc9-b351-99906754a03b   1345710                                                         Andrena perimelas Cockerell, 1905                          Cockerell, 1905                   Andrena perimelas             Andrena                 perimelas                                species                       Cockerell, T. D. A. New Bees of the Genera Osmia and Andrena. The Canadian Entomologist, vol. 37, no. 11. (1905).                                                                                                                                                                                                                    accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hymenoptera        Andrenidae          Andrena
1158100   7ddf754f-d193-4cc9-b351-99906754a03b   1157805                                                         Obereopsis subobsoleta Breuning, 1953                      Breuning, 1953                    Obereopsis subobsoleta        Obereopsis              subobsoleta                              species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Coleoptera         Cerambycidae        Obereopsis
1884264   7ddf754f-d193-4cc9-b351-99906754a03b   3257220                                                         Catoptria margaritaceus Fabricius, 1798                    Fabricius, 1798                   Catoptria margaritaceus       Catoptria               margaritaceus                            species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Lepidoptera        Crambidae           Catoptria
1718151   7ddf754f-d193-4cc9-b351-99906754a03b   1718150                                                         Aphonoides medvedevi Gorochov, 1985                        Gorochov, 1985                    Aphonoides medvedevi          Aphonoides              medvedevi                                species                       Gorochov. 1985. In Medvedev, L.N. [Ed.]. On the Orthoptera subfamilies Itarinae, Podoscirtinae and Nemobiinae (Gryllidae) from eastern Indochina. Fauna i ekologiya nasekomykh Vetnama [The fauna and ecology of insects of Vietnam], Nauka, Moscow 17-25                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Orthoptera         Gryllidae           Aphonoides
1260536   7ddf754f-d193-4cc9-b351-99906754a03b   1260531                                   1261335               Parahormius secundus (Viereck, 1905)                       (Viereck, 1905)                   Parahormius secundus          Parahormius             secundus                                 species                       Viereck, H.L. Notes and descriptions of Hymenoptera from the western United States, in the collection of the University of Kansas. Transactions of the Kansas Academy of Science. 19:264-326. (1905).                                                                                                                                accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hymenoptera        Braconidae          Parahormius
2084740   7ddf754f-d193-4cc9-b351-99906754a03b   2084738             9535491                                     Rugaspidiotus tamaricicola Balachowsky, 1953               Balachowsky, 1953                 Rugaspidiotus tamaricicola    Rugaspidiotus           tamaricicola                             species                                                                                                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Hemiptera          Diaspididae         Prodiaspis
1579053   7ddf754f-d193-4cc9-b351-99906754a03b   1578968                                                         Ptecticus somereni James, 1952                             James, 1952                       Ptecticus somereni            Ptecticus               somereni                                 species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Stratiomyidae       Ptecticus
1044038   9ca92552-f23a-41a8-a140-01abaa31c931   4764380             7501112               8329861               Nesapterus puncticollis (Scott, 1908)                      (Scott, 1908)                     Nesapterus puncticollis       Nesapterus              puncticollis                             species                                                                                                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Coleoptera         Nitidulidae         Prosopeus
1148712   7ddf754f-d193-4cc9-b351-99906754a03b   1148300                                                         Eunidia subnigra Breuning, 1955                            Breuning, 1955                    Eunidia subnigra              Eunidia                 subnigra                                 species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Coleoptera         Cerambycidae        Eunidia
1179463   90d9e8a6-0ce1-472d-b682-3451095dbc5a   4407231             7436817                                     Barypithes sphaeroides Seidlitz, 1868                      Seidlitz, 1868                    Barypithes sphaeroides        Barypithes              sphaeroides                              species                                                                                                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Coleoptera         Curculionidae       Mylacomorphus
2029903   7ddf754f-d193-4cc9-b351-99906754a03b   9647                                                            Pedionis Hamilton, 1980                                    Hamilton, 1980                    Pedionis                      Pedionis                                                         genus                         Canadian Ent. 112 (9)                                                                                                                                                                                                                                                                                                                accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hemiptera          Cicadellidae        Pedionis
1507784   7ddf754f-d193-4cc9-b351-99906754a03b   1507759                                                         Dolichopeza taiwania (Alexander, 1923)                     (Alexander, 1923)                 Dolichopeza taiwania          Dolichopeza             taiwania                                 species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Tipulidae           Dolichopeza
2172712   7ddf754f-d193-4cc9-b351-99906754a03b   2172706                                                         Prostheclina bulburin Richardson & Zabka, 2007             Richardson & Zabka, 2007          Prostheclina bulburin         Prostheclina            bulburin                                 species                       Richardson, B. J., abka, M. A revision of the Australian jumping spider genus Prostheclina Keyserling, 1892 (Araneae: Salticidae). Records of the Australian Museum 59: 79-96. (2007).                                                                                                                                              accepted                                                                                                                                Animalia         Arthropoda                                Araneae            Salticidae          Prostheclina
1848845   7ddf754f-d193-4cc9-b351-99906754a03b   1848843                                                         Metzneria hastella Chrtien, 1916                          Chrtien, 1916                    Metzneria hastella            Metzneria               hastella                                 species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Lepidoptera        Gelechiidae         Metzneria
2306537   7ddf754f-d193-4cc9-b351-99906754a03b   2306523                                   5728581               Ischnochiton variegatus (H.Adams & Angas, 1864)            (H.Adams & Angas, 1864)           Ischnochiton variegatus       Ischnochiton            variegatus                               species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Mollusca              Polyplacophora      Chitonida          Ischnochitonidae    Ischnochiton
1708267   7ddf754f-d193-4cc9-b351-99906754a03b   1708251             7197599               1701371               Stenobothrus biguttulus (Linnaeus, 1758)                   (Linnaeus, 1758)                  Stenobothrus biguttulus       Stenobothrus            biguttulus                               species                                                                                                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Orthoptera         Acrididae           Chorthippus
2095217   7ddf754f-d193-4cc9-b351-99906754a03b   2081087             8229355                                     Pseudococcus syringae Fernald, 1903                        Fernald, 1903                     Pseudococcus syringae         Pseudococcus            syringae                                 species                                                                                                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Hemiptera          Pseudococcidae      Pseudococcus
2125516   7ddf754f-d193-4cc9-b351-99906754a03b   2125513                                   4553624               Balkanoroncus boldorii (Beier, 1931)                       (Beier, 1931)                     Balkanoroncus boldorii        Balkanoroncus           boldorii                                 species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Arachnida           Pseudoscorpiones   Neobisiidae         Balkanoroncus
1266831   7ddf754f-d193-4cc9-b351-99906754a03b   1266475                                                         Chelonus bifoveolatus Szepligeti, 1914                     Szepligeti, 1914                  Chelonus bifoveolatus         Chelonus                bifoveolatus                             species                       Szepligeti, G. Afrikanische Braconiden des Konigl. Zoologischen Museums in Berlin. Mitteilungen aus dem Zoologischen Museum in Berlin. 7:153-230. (1914).                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hymenoptera        Braconidae          Chelonus
2195427   7ddf754f-d193-4cc9-b351-99906754a03b   2195423                                                         Hexachaetoniella contigua Hunt, 1996                       Hunt, 1996                        Hexachaetoniella contigua     Hexachaetoniella        contigua                                 species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda                                Sarcoptiformes     Licnodamaeidae      Hexachaetoniella
1716984   7ddf754f-d193-4cc9-b351-99906754a03b   1716957                                                         Gryllopsis capitata Chopard, 1951                          Chopard, 1951                     Gryllopsis capitata           Gryllopsis              capitata                                 species                       Chopard. 1951. Contribution  l'tude des gryllides du Congo belge. Revue de Zoologie et de Botanique Africaines (Rev. Zool. Bot. Afr.) 44:297-312                                                                                                                                                                                   accepted                                                                                                                                Animalia         Arthropoda            Insecta             Orthoptera         Gryllidae           Gryllopsis
1616285   7ddf754f-d193-4cc9-b351-99906754a03b   1616183                                                         Boletina onegensis Polevoi, 1995                           Polevoi, 1995                     Boletina onegensis            Boletina                onegensis                                species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Mycetophilidae      Boletina
1323198   7ddf754f-d193-4cc9-b351-99906754a03b   1323128                                                         Tetramorium pilosum Emery, 1893                            Emery, 1893                       Tetramorium pilosum           Tetramorium             pilosum                                  species                       Emery, C. (1893): Voyage de M. E. Simon  l'le de Ceylan (janvier - fvrier 1892). 3 e Mmoire. Formicides. Annales de la Socit Entomologique de France 62: 239-258, URL: http://antbase.org/ants/publications/3767/3767.pdf                                                                                                      accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hymenoptera        Formicidae          Tetramorium
1041227   7ddf754f-d193-4cc9-b351-99906754a03b   1041209                                   10067769              Batrisodes ionae (J.L.LeConte, 1849)                       (J.L.LeConte, 1849)               Batrisodes ionae              Batrisodes              ionae                                    species                       LeConte, J. L. On the Pselaphidae of the United States. Boston Journal of Natural History, 6: 64-110. (1849).                                                                                                                                                                                                                        accepted                                                                                                                                Animalia         Arthropoda            Insecta             Coleoptera         Staphylinidae       Batrisodes
1538367   7ddf754f-d193-4cc9-b351-99906754a03b   1538366                                                         Spheginobaccha vandoesburgi Thompson, 1974                 Thompson, 1974                    Spheginobaccha vandoesburgi   Spheginobaccha          vandoesburgi                             species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Syrphidae           Spheginobaccha
1553653   7ddf754f-d193-4cc9-b351-99906754a03b   1553283                                                         Liriomyza furva Spencer, 1976                              Spencer, 1976                     Liriomyza furva               Liriomyza               furva                                    species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Agromyzidae         Liriomyza
1357334   7ddf754f-d193-4cc9-b351-99906754a03b   1345710                                                         Andrena florea Fabricius, 1793                             Fabricius, 1793                   Andrena florea                Andrena                 florea                                   species                       Fabricius, Johann C. 1793. Entomologia systematica emendata et aucta. Secundum classes, ordines, genera, species, adjectis synonimis, locis, observationibus, descriptionibus. C.G. Proft, Fil. et Soc., Hafniae. Vol. 2: 1-519.                                                                                                     accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hymenoptera        Andrenidae          Andrena
2321590   7ddf754f-d193-4cc9-b351-99906754a03b   2321584                                                         Poecilochaetus serpens Allen, 1904                         Allen, 1904                       Poecilochaetus serpens        Poecilochaetus          serpens                                  species                       Allen, E. J. (1904). The anatomy of Poecilochaetus, Claparde. <em>Quarterly Journal of Microscopical Science, London.</em> 48: 79-151.                                                                                                                                                                                              accepted                                                                                                                                Animalia         Annelida              Polychaeta          Spionida           Poecilochaetidae    Poecilochaetus
1219944   7ddf754f-d193-4cc9-b351-99906754a03b   1219907                                                         Tyrannion pictipennis Champion, 1905                       Champion, 1905                    Tyrannion pictipennis         Tyrannion               pictipennis                              species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Coleoptera         Curculionidae       Tyrannion
1624219   7ddf754f-d193-4cc9-b351-99906754a03b   1623884                                   1624220               Campiglossa deserta (Hering, 1939)                         (Hering, 1939)                    Campiglossa deserta           Campiglossa             deserta                                  species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Tephritidae         Campiglossa
1549920   7ddf754f-d193-4cc9-b351-99906754a03b   1549881                                                         Phalacrotophora beuki Disney, 1997                         Disney, 1997                      Phalacrotophora beuki         Phalacrotophora         beuki                                    species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Phoridae            Phalacrotophora
1407935   7ddf754f-d193-4cc9-b351-99906754a03b   1407108                                                         Baetis notos Allen & Murvosh, 1987                         Allen & Murvosh, 1987             Baetis notos                  Baetis                  notos                                    species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Ephemeroptera      Baetidae            Baetis
1438287   7ddf754f-d193-4cc9-b351-99906754a03b   1438158                                                         Polyplectropus alkyone Malicky & Chantaramongkol, 1997     Malicky & Chantaramongkol, 1997   Polyplectropus alkyone        Polyplectropus          alkyone                                  species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Trichoptera        Polycentropodidae   Polyplectropus
1586111   7ddf754f-d193-4cc9-b351-99906754a03b   1586094                                                         Roederiodes chvalai Horvat, 1994                           Horvat, 1994                      Roederiodes chvalai           Roederiodes             chvalai                                  species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Empididae           Roederiodes
2278145   7ddf754f-d193-4cc9-b351-99906754a03b   2278137                                                         Amphipholis sigillata Cherbonnier & Guille, 1978           Cherbonnier & Guille, 1978        Amphipholis sigillata         Amphipholis             sigillata                                species                       Cherbonnier, G.; Guille, A. (1978). Echinodermes: Ophiurides. <em>Faune de Madagascar, 48.</em> Editions du Centre National de la Recherche Scientifique (CNRS): Paris. ISBN 2-222-02341-6. 272 pp.                                                                                                                                  accepted                                                                                                                                Animalia         Echinodermata         Ophiuroidea         Amphilepidida      Amphiuridae         Amphipholis
2101093   7ddf754f-d193-4cc9-b351-99906754a03b   2101090             2101091                                     Dimares nummatus Navs, 1912                               Navs, 1912                       Dimares nummatus              Dimares                 nummatus                                 species                       Navs, L. Myrmlonides (Ins. Nvr.) nouveaux ou peu connus. Annales de la Socit Scientifique de Bruxelles 36(pt. 2):203-248. (1912).                                                                                                                                                                                              synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Neuroptera         Myrmeleontidae      Millerleon
1251858   7ddf754f-d193-4cc9-b351-99906754a03b   1251802             1251854                                     Alabagrus citreistigma Enderlein, 1920                     Enderlein, 1920                   Alabagrus citreistigma        Alabagrus               citreistigma                             species                       Enderlein, G. Zur Kenntnis aussereuropaischer Braconiden. Archiv fur Naturgeschichte. 84(A)11(1918):51-224. (1920).                                                                                                                                                                                                                  synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Hymenoptera        Braconidae          Alabagrus
1587922   a6c6cead-b5ce-4a4e-8cf5-1542ba708dec   1587912             1587921                                     Limosina antennata Duda, 1918                              Duda, 1918                        Limosina antennata            Limosina                antennata                                species                                                                                                                                                                                                                                                                                                                                                            homotypic synonym                         Originally found in sources as heterotypic synonym of Pullimosina moesta (Villeneuve, 1918)   Animalia         Arthropoda            Insecta             Diptera            Sphaeroceridae      Pullimosina
1841386   7ddf754f-d193-4cc9-b351-99906754a03b   1841334                                                         Chlamydastis melanonca Meyrick, 1915                       Meyrick, 1915                     Chlamydastis melanonca        Chlamydastis            melanonca                                species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Lepidoptera        Oecophoridae        Chlamydastis
1647400   7ddf754f-d193-4cc9-b351-99906754a03b   1647062                                                         Tomosvaryella troangulatus Kapoor, Grewal & Sharma, 1987   Kapoor, Grewal & Sharma, 1987     Tomosvaryella troangulatus    Tomosvaryella           troangulatus                             species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Pipunculidae        Tomosvaryella
1648957   7ddf754f-d193-4cc9-b351-99906754a03b   1648921                                                         Toxorhynchites wolfsi Ribeiro, 2005                        Ribeiro, 2005                     Toxorhynchites wolfsi         Toxorhynchites          wolfsi                                   species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Culicidae           Toxorhynchites
1551129   7ddf754f-d193-4cc9-b351-99906754a03b   1551101                                                         Paracladura patagonica Alexander, 1929                     Alexander, 1929                   Paracladura patagonica        Paracladura             patagonica                               species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Trichoceridae       Paracladura
2154558   7ddf754f-d193-4cc9-b351-99906754a03b   2154522                                                         Anyphaena bryantae Roewer, 1951                            Roewer, 1951                      Anyphaena bryantae            Anyphaena               bryantae                                 species                       Roewer, C. F. Neue Namen einiger Araneen-Arten. Abhandlungen des Naturwissenschaftlichen Vereins zu Bremen 32: 437-456. (1951).                                                                                                                                                                                                      accepted                                                                                                                                Animalia         Arthropoda                                Araneae            Anyphaenidae        Anyphaena
2087979   7ddf754f-d193-4cc9-b351-99906754a03b   2087961                                                         Aonidia maroccana Balachowsky, 1949                        Balachowsky, 1949                 Aonidia maroccana             Aonidia                 maroccana                                species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hemiptera          Diaspididae         Aonidia
2031706   7ddf754f-d193-4cc9-b351-99906754a03b   2031670             2031705                                     Tamaricella applanta                                                                         Tamaricella applanta          Tamaricella             applanta                                 species                                                                                                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Hemiptera          Cicadellidae        Tamaricella
1334030   7ddf754f-d193-4cc9-b351-99906754a03b   1334023                                                         Paragymnomerus excelsus (Kostylev, 1935)                   (Kostylev, 1935)                  Paragymnomerus excelsus       Paragymnomerus          excelsus                                 species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hymenoptera        Eumenidae           Paragymnomerus
2017633   7ddf754f-d193-4cc9-b351-99906754a03b   2017630             2017631                                     Tomaspis dominicana Distant, 1909                          Distant, 1909                     Tomaspis dominicana           Tomaspis                dominicana                               species                                                                                                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Hemiptera          Cercopidae          Panabrus
1636506   7ddf754f-d193-4cc9-b351-99906754a03b   1636260                                                         Stilobezzia huberti Gupta & Wirth, 1968                    Gupta & Wirth, 1968               Stilobezzia huberti           Stilobezzia             huberti                                  species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Ceratopogonidae     Stilobezzia
2003534   7ddf754f-d193-4cc9-b351-99906754a03b   2001440                                                         Nemoura hamulata Zhiltzova, 1971                           Zhiltzova, 1971                   Nemoura hamulata              Nemoura                 hamulata                                 species                       Zhiltzova. 1971. [On the knowlegde of Plecoptera from Middle Asia. New and little-known species of the family Nemouridae]. Entomologicheskoe Obozrenie (Entomol. Obozr.) 50(2):347-365                                                                                                                                               accepted                                                                                                                                Animalia         Arthropoda            Insecta             Plecoptera         Nemouridae          Nemoura
1553175   7ddf754f-d193-4cc9-b351-99906754a03b   1552947                                   1553176               Ophiomyia coniceps (Malloch, 1915)                         (Malloch, 1915)                   Ophiomyia coniceps            Ophiomyia               coniceps                                 species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Agromyzidae         Ophiomyia
1463865   9ca92552-f23a-41a8-a140-01abaa31c931   6918                1464433                                     Phoranthella Townsend, 1915                                Townsend, 1915                    Phoranthella                  Phoranthella                                                     genus                         Proc. Biol. Soc. Washington, 28                                                                                                                                                                                                                                                                                                      synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Diptera            Tachinidae          Phasia
1067498   7ddf754f-d193-4cc9-b351-99906754a03b   1067483                                                         Dellacasiellus griffini Gordon & Skelley, 2007             Gordon & Skelley, 2007            Dellacasiellus griffini       Dellacasiellus          griffini                                 species                       Gordon R.D. & Skelley P.E. A monograph of the Aphodiini inhabiting the United States and Canada. Memoirs of the American Entomological Institute 79:1-580. (2007).                                                                                                                                                                   accepted                                                                                                                                Animalia         Arthropoda            Insecta             Coleoptera         Aphodiidae          Dellacasiellus
1473365   7ddf754f-d193-4cc9-b351-99906754a03b   6918                                                            Iconofrontina Townsend, 1931                               Townsend, 1931                    Iconofrontina                 Iconofrontina                                                    genus                         Rev. Ent. So Paulo, 1                                                                                                                                                                                                                                                                                                               accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Tachinidae          Iconofrontina
1249120   7ddf754f-d193-4cc9-b351-99906754a03b   1249072                                                         Hyptia fuchi Ashmead, 1901                                 Ashmead, 1901                     Hyptia fuchi                  Hyptia                  fuchi                                    species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hymenoptera        Evaniidae           Hyptia
2116975   7ddf754f-d193-4cc9-b351-99906754a03b   10122307                                                        Mesocyclops splendidus Lindberg, 1943                      Lindberg, 1943                    Mesocyclops splendidus        Mesocyclops             splendidus                               species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Hexanauplia         Cyclopoida         Cyclopidae          Mesocyclops
1593526   9ca92552-f23a-41a8-a140-01abaa31c931   1593524             1593525                                     Porricondyla diervillae Felt, 1907                         Felt, 1907                        Porricondyla diervillae       Porricondyla            diervillae                               species                                                                                                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Diptera            Cecidomyiidae       Isocolpodia
2197886   7ddf754f-d193-4cc9-b351-99906754a03b   2197882                                                         Plakoribates scutatus Hammer, 1979                         Hammer, 1979                      Plakoribates scutatus         Plakoribates            scutatus                                 species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda                                Sarcoptiformes     Tegoribatidae       Plakoribates
1821467   7ddf754f-d193-4cc9-b351-99906754a03b   9078901                                                         Euproctis conistica Collenette, 1935                       Collenette, 1935                  Euproctis conistica           Euproctis               conistica                                species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Lepidoptera        Erebidae            Euproctis
1396959   7ddf754f-d193-4cc9-b351-99906754a03b   9447                                                            Calolelaps Timberlake, 1925                                Timberlake, 1925                  Calolelaps                    Calolelaps                                                       genus                         Proc. Hawaiian Ent. Soc., 6                                                                                                                                                                                                                                                                                                          accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hymenoptera        Pteromalidae        Calolelaps
1363843   7ddf754f-d193-4cc9-b351-99906754a03b   1361549             1363840               1363842               Spilochalcis delira (Cresson, 1872)                        (Cresson, 1872)                   Spilochalcis delira           Spilochalcis            delira                                   species                                                                                                                                                                                                                                                                                                                                                            synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Hymenoptera        Chalcididae         Conura
1957179   7ddf754f-d193-4cc9-b351-99906754a03b   1957177                                                         Plegapteryx obscura Holland, 1892                          Holland, 1892                     Plegapteryx obscura           Plegapteryx             obscura                                  species                       Holland W. J. New species of West African Drepanulidae. Entomological News 1893e                                                                                                                                                                                                                                                     accepted                                                                                                                                Animalia         Arthropoda            Insecta             Lepidoptera        Geometridae         Plegapteryx
2318704   7ddf754f-d193-4cc9-b351-99906754a03b   2318702                                                         Jereminella quadrisulcata Yu & Wang, 1981                  Yu & Wang, 1981                   Jereminella quadrisulcata     Jereminella             quadrisulcata                            species                       Yu, Chang min and Wang, Hui ji 1979. [Some tube-like fossils from the early tertiary of northern Jiangsu]. Acta palaeontologica sinica, 20(5): 414-417.                                                                                                                                                                              accepted                                                                                                                                Animalia         Annelida              Polychaeta                                                 Jereminella
1983653   7ddf754f-d193-4cc9-b351-99906754a03b   1982367                                                         Eupithecia inexplicabilis Vojnits, 1982                    Vojnits, 1982                     Eupithecia inexplicabilis     Eupithecia              inexplicabilis                           species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Lepidoptera        Geometridae         Eupithecia
1946076   7ddf754f-d193-4cc9-b351-99906754a03b   1946075                                                         Chamunda chamunda Moore, 1865                              Moore, 1865                       Chamunda chamunda             Chamunda                chamunda                                 species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Lepidoptera        Hesperiidae         Chamunda
1002441   7ddf754f-d193-4cc9-b351-99906754a03b   1002167                                                         Lecane schraederi Wulfert, 1966                            Wulfert, 1966                     Lecane schraederi             Lecane                  schraederi                               species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Rotifera              Eurotatoria         Ploima             Lecanidae           Lecane
2078416   0938172b-2086-439c-a1dd-c21cb0109ed5   3042                                                            Glabromyzus Richards, 1960                                 Richards, 1960                    Glabromyzus                   Glabromyzus                                                      genus                         Can. Ent. 92                                                                                                                                                                                                                                                                                                                         doubtful                                                                                                                                Animalia         Arthropoda            Insecta             Hemiptera          Aphididae           Glabromyzus
1490018   7ddf754f-d193-4cc9-b351-99906754a03b   1490011                                   1490021               Incertella dorsata (Loew, 1872)                            (Loew, 1872)                      Incertella dorsata            Incertella              dorsata                                  species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Diptera            Chloropidae         Incertella
1347207   7ddf754f-d193-4cc9-b351-99906754a03b   1347206                                                         Chalybion gracile Hensen, 1988                             Hensen, 1988                      Chalybion gracile             Chalybion               gracile                                  species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hymenoptera        Sphecidae           Chalybion
2058303   7ddf754f-d193-4cc9-b351-99906754a03b   2058274                                                         Mnemosyne oblongostriata Van Stalle, 1987                  Van Stalle, 1987                  Mnemosyne oblongostriata      Mnemosyne               oblongostriata                           species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hemiptera          Cixiidae            Mnemosyne
1375964   7ddf754f-d193-4cc9-b351-99906754a03b   1375934             1375959                                     Trichomasthus rhizococci Trjapitzin, 1978                  Trjapitzin, 1978                  Trichomasthus rhizococci      Trichomasthus           rhizococci                               species                       Trjapitzin, V.A. Hymenoptera II. Chalcidoidea 7. Encyrtidae. JOURBOOK: Opredeliteli Nasekomykh Evropeyskoy Chasti SSR VOLUME: 3 PAGES: 236-328. (1978).                                                                                                                                                                              synonym                                                                                                                                 Animalia         Arthropoda            Insecta             Hymenoptera        Encyrtidae          Aschitus
2029112   7ddf754f-d193-4cc9-b351-99906754a03b   2029103                                                         Equeefa natalia Naud, 1929                                Naud, 1929                       Equeefa natalia               Equeefa                 natalia                                  species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Hemiptera          Cicadellidae        Equeefa
1433424   7ddf754f-d193-4cc9-b351-99906754a03b   1433231                                                         Hydroptila lonchera Blickle & Morse, 1954                  Blickle & Morse, 1954             Hydroptila lonchera           Hydroptila              lonchera                                 species                                                                                                                                                                                                                                                                                                                                                            accepted                                                                                                                                Animalia         Arthropoda            Insecta             Trichoptera        Hydroptilidae       Hydroptila
```
The columns are defined here https://dwc.tdwg.org/terms/#taxon
1. **taxonID - gbif id, use ""GBIF<taxonID>"" as alt_taxon_id if no NCBI match/synonym found**
2. datasetID - ignore for now for GenomeHubs
3. **parentNameUsageID - parent taxon id to establish parent-child links**; An identifier for the name usage of the direct, most proximate higher-rank parent taxon (in a classification) of the most specific element of the scientificName
4. **acceptedNameUsageID - Use to establish synonyms**; An identifier for the name usage of the currently valid (zoological) or accepted (botanical) taxon.
5. **originalNameUsageID - Use this to establish synonyms**; An identifier for the name usage in which the terminal element of the scientificName was originally established under the rules of the associated nomenclaturalCode
6. scientificName - use to manually resolve conflicts; The full scientific name, with authorship and date information if known
7. scientificNameAuthorship - use to manually resolve conflicts; The authorship information for the scientificName formatted according to the conventions of the applicable nomenclaturalCode
8. **canonicalName - Use this for comparing to NCBI names/synonyms** . The canonical form of the name. This form has no authorship or more than 3 name parts. 
9. genericName - Ignore for now for GenomeHubs
10. specificEpithet - Ignore for now for GenomeHubs; The name of the first or species epithet of the scientificName.
11. infraspecificEpithet - Ignore for now for GenomeHubs; The name of the lowest or terminal infraspecific epithet of the scientificName, excluding any rank designation
12. **taxonRank**
13. nameAccordingTo - Ignore for now for GenomeHubs; The reference to the source in which the specific taxon concept circumscription is defined or implied - traditionally signified by the Latin ""sensu"" or ""sec."" (from secundum, meaning ""according to""). For taxa that result from identifications, a reference to the keys, monographs, experts and other sources should be given.
14. namePublishedIn - Ignore for now for GenomeHubs; A reference for the publication in which the scientificName was originally established under the rules of the associated nomenclaturalCode.
15. **taxonomicStatus**
16. nomenclaturalStatus
17. taxonRemarks
18. **kingdom**
19. **phylum**
20. **class**
21. **order**
22. **family**
23. **genus**

Desc of fields:

* Col  1. taxonID - all have taxonID
* Col 3. parentNameUsageID - all have parents except 17:
```
taxonID   datasetID                              parentNameUsageID   acceptedNameUsageID   originalNameUsageID   scientificName       scientificNameAuthorship   canonicalName        genericName          specificEpithet   infraspecificEpithet   taxonRank   nameAccordingTo   namePublishedIn   taxonomicStatus   nomenclaturalStatus   taxonRemarks   kingdom          phylum   class   order   family   genus
0         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   incertae sedis                                  incertae sedis       incertae sedis                                                kingdom                                         doubtful                                               incertae sedis                                     
1         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Animalia                                        Animalia             Animalia                                                      kingdom                                         accepted                                               Animalia                                           
2         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Archaea                                         Archaea              Archaea                                                       kingdom                                         accepted                                               Archaea                                            
3         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Bacteria                                        Bacteria             Bacteria                                                      kingdom                                         accepted                                               Bacteria                                           
4         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Chromista                                       Chromista            Chromista                                                     kingdom                                         accepted                                               Chromista                                          
5         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Fungi                                           Fungi                Fungi                                                         kingdom                                         accepted                                               Fungi                                              
6         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Plantae                                         Plantae              Plantae                                                       kingdom                                         accepted                                               Plantae                                            
7         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Protozoa                                        Protozoa             Protozoa                                                      kingdom                                         accepted                                               Protozoa                                           
8         d7dddbf4-2cf0-4f39-9b2a-bb099caae36c                                                                   Viruses                                         Viruses              Viruses                                                       kingdom                                         accepted                                               Viruses                                            
3237615   9ca92552-f23a-41a8-a140-01abaa31c931                       3                                           Achromatiaceae                                  Achromatiaceae       Achromatiaceae                                                family                                          synonym                                                Bacteria                                           
3295774   9ca92552-f23a-41a8-a140-01abaa31c931                       5                                           Agonomycetaceae                                 Agonomycetaceae      Agonomycetaceae                                               family                                          synonym                                                Fungi                                              
4306232   9ca92552-f23a-41a8-a140-01abaa31c931                       3                                           Azotobacteraceae                                Azotobacteraceae     Azotobacteraceae                                              family                                          synonym                                                Bacteria                                           
4306242   9ca92552-f23a-41a8-a140-01abaa31c931                       3                                           Achromobacteraceae                              Achromobacteraceae   Achromobacteraceae                                            family                                          synonym                                                Bacteria                                           
4306417   9ca92552-f23a-41a8-a140-01abaa31c931                       3                                           Thiobacteriaceae                                Thiobacteriaceae     Thiobacteriaceae                                              family                                          synonym                                                Bacteria                                           
4306418   9ca92552-f23a-41a8-a140-01abaa31c931                       3                                           Nitrobacteraceae                                Nitrobacteraceae     Nitrobacteraceae                                              family                                          synonym                                                Bacteria                                           
4306455   9ca92552-f23a-41a8-a140-01abaa31c931                       3                                           Archangiaceae                                   Archangiaceae        Archangiaceae                                                 family                                          synonym                                                Bacteria                                           
4306484   9ca92552-f23a-41a8-a140-01abaa31c931                       3                                           Actinoplanaceae                                 Actinoplanaceae      Actinoplanaceae                                               family                                          synonym                                                Bacteria                                           
```
* Col 4. acceptedNameUsageID: 4,056,385 null; 2,726,287 non-null; (991,387 unique)   
* Col 5. originalNameUsageID: 5,703,305 null; 1,079,367 non-null; (747,035 unique)
* Col 8. canonicalName: 760,300 null / have no canonicalName; 6,022,372 non-null; (5,459,658 unique)
* Col 12. taxonRank
```
cut -f12 Taxon.tsv | sort | uniq -c
    727 class
  31317 family
  73414 form
 520818 genus
      9 kingdom
   2656 order
    301 phylum
4668426 species
 351208 subspecies
      1 taxonRank
 781379 unranked
 352416 variety
```
",sujaikumar,https://github.com/genomehubs/genomehubs/issues/76,genomehubs++genomehubs.csv
MDU6SXNzdWU5NjY0ODMxOTg=,Use synonyms when adding alt_taxon_id,CLOSED,2021-08-11T11:05:20Z,2021-10-13T10:21:17Z,2021-10-13T10:21:17Z,"When adding new taxa to an existing taxonomy, taxon lookup needs to allow for use of synonyms at any rank in the provided lineage.



<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/78,genomehubs++genomehubs.csv
MDU6SXNzdWU5ODk3NDIzNjc=,Warning OR error if YAML references an attribute value that doesn't exist in column file,CLOSED,2021-09-07T08:44:05Z,2021-12-16T14:29:22Z,2021-12-16T14:29:22Z,,sujaikumar,https://github.com/genomehubs/genomehubs/issues/80,genomehubs++genomehubs.csv
MDU6SXNzdWU5OTIyMTg5OTY=,genomehubs index needs a --dry-run flag,CLOSED,2021-09-09T13:22:42Z,2021-10-13T10:21:17Z,2021-10-13T10:21:17Z,"It would be useful to be able to run the validation steps in genomehubs index without saving records to the database.

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/81,genomehubs++genomehubs.csv
I_kwDOBMYwiM48RGGX,add new taxa from ena api before indexing,CLOSED,2021-09-29T15:33:34Z,2021-10-13T10:21:17Z,2021-10-13T10:21:17Z,https://github.com/genomehubs/genomehubs/blob/8ddb9b2524b3c4f5cf8342591c84e84cbccb8ff0/src/genomehubs/lib/init.py#L95-L95,rjchallis,https://github.com/genomehubs/genomehubs/issues/83,genomehubs++genomehubs.csv
I_kwDOBMYwiM5I99az,Add link out to blobtoolkit viewer in Analyses section,CLOSED,2021-10-06T12:45:20Z,2022-05-12T13:33:37Z,2022-05-12T13:33:37Z,"Eg https://goat.genomehubs.org/records?record_id=GCA_910591435.1&result=assembly&taxonomy=ncbi#GCA_910591435.1 

Under Analyses has images indexed from Blobtoolkit Viewer, but no linkout to the viewer for that assembly.",sujaikumar,https://github.com/genomehubs/genomehubs/issues/131,genomehubs++genomehubs.csv
I_kwDOBMYwiM49O1dC,Unable to import subspecies from jsonl,CLOSED,2021-10-15T10:18:26Z,2022-04-07T09:29:14Z,2022-04-07T09:29:14Z,"lineage provided from ENA API for subspecies does not include species so would be added with genus as direct parent. Code currently skips subspecies to avoid this happening. 

```
{  ""taxId"" : ""1715679"",  ""scientificName"" : ""Anthoscopus caroli"",  ""commonName"" : ""African penduline-tit"",  ""formalName"" : ""true"",  ""rank"" : ""species"",  ""division"" : ""VRT"",  ""lineage"" : ""Eukaryota; Metazoa; Chordata; Craniata; Vertebrata; Euteleostomi; Archelosauria; Archosauria; Dinosauria; Saurischia; Theropoda; Coelurosauria; Aves; Neognathae; Passeriformes; Paridae; Anthoscopus; "",  ""geneticCode"" : ""1"",  ""mitochondrialGeneticCode"" : ""2"",  ""submittable"" : ""true""}
{  ""taxId"" : ""1715680"",  ""scientificName"" : ""Anthoscopus caroli robertsi"",  ""formalName"" : ""true"",  ""rank"" : ""subspecies"",  ""division"" : ""VRT"",  ""lineage"" : ""Eukaryota; Metazoa; Chordata; Craniata; Vertebrata; Euteleostomi; Archelosauria; Archosauria; Dinosauria; Saurischia; Theropoda; Coelurosauria; Aves; Neognathae; Passeriformes; Paridae; Anthoscopus; "",  ""geneticCode"" : ""1"",  ""mitochondrialGeneticCode"" : ""2"",  ""submittable"" : ""true""}

```",rjchallis,https://github.com/genomehubs/genomehubs/issues/85,genomehubs++genomehubs.csv
I_kwDOBMYwiM490MzI,Separate YAML for generic attribute settings,CLOSED,2021-10-27T07:55:56Z,2021-12-16T14:29:22Z,2021-12-16T14:29:22Z,Currently an import/index YAML is linked to an importable file. Can we have a single (or separate YAMLs) that only define attribute settings for display and indexing and filling etc?,sujaikumar,https://github.com/genomehubs/genomehubs/issues/86,genomehubs++genomehubs.csv
I_kwDOBMYwiM4-posy,Make genomehubs subcommands give error if config-file not found,CLOSED,2021-11-11T15:33:17Z,2021-12-16T14:29:22Z,2021-12-16T14:29:22Z,"eg:
```
genomehubs init --taxonomy-source ncbi --config-file goat.yaml
```
should exit with error if goat.yaml does not exist in current directory",sujaikumar,https://github.com/genomehubs/genomehubs/issues/87,genomehubs++genomehubs.csv
I_kwDOBMYwiM4_i5-l,Include external links with files and analyses,CLOSED,2021-11-29T14:36:24Z,2022-05-12T13:33:15Z,2022-05-12T13:33:15Z,,rjchallis,https://github.com/genomehubs/genomehubs/issues/91,genomehubs++genomehubs.csv
I_kwDOBMYwiM4_i7Ox,Include taxonomy in identifiers and attributes indices,CLOSED,2021-11-29T14:41:09Z,2022-01-25T16:07:22Z,2022-01-25T16:07:22Z,Index names should include the taxonomy name to associate with taxon and assembly indices for the same taxonomy,rjchallis,https://github.com/genomehubs/genomehubs/issues/92,genomehubs++genomehubs.csv
I_kwDOBMYwiM5AR14S,Direct values should be preferred over descendant,CLOSED,2021-12-13T11:33:17Z,2022-04-07T09:29:46Z,2022-04-07T09:29:46Z,"e.g. if species is on list 1 and subspecies is on list 2, fill currently sets species source as descendant, not direct. Both values are included in list of values. 

Need to determine what happens to numeric values ",rjchallis,https://github.com/genomehubs/genomehubs/issues/93,genomehubs++genomehubs.csv
I_kwDOBMYwiM5AR2mh,Separate taxonomy format from taxonomy name,CLOSED,2021-12-13T11:36:35Z,2021-12-16T14:29:23Z,2021-12-16T14:29:23Z,Need flexibility to import taxonomies with different names so not tied to one taxonomy per format,rjchallis,https://github.com/genomehubs/genomehubs/issues/94,genomehubs++genomehubs.csv
I_kwDOBMYwiM5AR272,Throw error when tsv file contains duplicate headers,CLOSED,2021-12-13T11:38:07Z,2021-12-16T14:29:23Z,2021-12-16T14:29:23Z,Currently any file with duplicate headers will use the first matching value only. Need error to prevent wrong data being inadvertently loaded,rjchallis,https://github.com/genomehubs/genomehubs/issues/95,genomehubs++genomehubs.csv
I_kwDOBMYwiM5AR3UU,Parse Newick trees,OPEN,2021-12-13T11:39:51Z,2021-12-13T11:39:51Z,,"Need flexibility to use trees in place of backbone taxonomy. current workaround would be to covert to ncbi taxonomy format, but that loses branch length information",rjchallis,https://github.com/genomehubs/genomehubs/issues/96,genomehubs++genomehubs.csv
I_kwDOBMYwiM5CCisM,source_slug not getting indexed in some cases,CLOSED,2022-01-19T11:05:46Z,2022-01-25T16:07:22Z,2022-01-25T16:07:22Z,"Works in https://github.com/genomehubs/genomehubs/blob/develop/src/genomehubs/templates/btk.types.yaml but not in https://github.com/genomehubs/genomehubs/blob/develop/src/genomehubs/templates/assembly.types.yaml

i.e. btk link out works, but ncbi datasets linkout doesn't on a taxon page like https://goat.genomehubs.org/records?record_id=9657&result=taxon&taxonomy=ncbi#Lutra%20lutra (api shows source_slug only in btk attributes https://goat.genomehubs.org/api/v0.0.1/record?recordId=9657&result=taxon&taxonomy=ncbi )",sujaikumar,https://github.com/genomehubs/genomehubs/issues/101,genomehubs++genomehubs.csv
I_kwDOBMYwiM5DxnK5,type: should only need to be set once per attribute YAML,CLOSED,2022-02-14T10:17:59Z,2022-05-06T11:59:57Z,2022-05-06T11:59:57Z,"There is one ATTR yaml per display group in a subfolder (eg ATTR_karyotype.types.yaml and ATTR_genome_size.types.yaml) and multiple FILE_*.types.yaml corresponding to each file.

In an ideal world the only thing for an attribute in a FILE yaml would be things specific to the file such as
```
header: 
separator: 
```
but when I run it this way, it gives me a 'type' error.

Example:
```
2022-02-11 14:45:12.195 [INFO] Loading configuration options
2022-02-11 14:45:12.208 [INFO] ElasticSearch is already running
2022-02-11 14:45:12.465 [INFO] Validating YAML file test/ATTR_genome_size.types.yaml
2022-02-11 14:45:12.492 [INFO] Indexing types
2022-02-11 14:45:12.494 [INFO] Indexing attribute
5.00 records [00:00, 72.1k records/s]
2022-02-11 14:45:17.515 [INFO] Validating YAML file test/ATTR_karyotype.types.yaml
2022-02-11 14:45:17.526 [INFO] Indexing types
2022-02-11 14:45:17.529 [INFO] Indexing attribute
4.00 records [00:00, 71.4k records/s]
2022-02-11 14:45:22.546 [INFO] Validating YAML file test/FILE_apidae-2021-07-07.types.yaml
2022-02-11 14:45:22.556 [INFO] Indexing types
2022-02-11 14:45:22.558 [INFO] Indexing attribute
3.00 records [00:00, 45.1k records/s]
2022-02-11 14:45:27.577 [INFO] Indexing apidae-2021-07-07.csv
2022-02-11 14:45:27.583 [INFO] Processing rows   
0it [00:00, ?it/s]'type'
'type'
'type'
'type'
'type'
'type'
```
So I put type: in the FILE*yaml too:
```
header: 
separator: 
type: 
```
and now it runs fine.

Am guessing thats not by design because I think type should be set once per attribute.
",sujaikumar,https://github.com/genomehubs/genomehubs/issues/103,genomehubs++genomehubs.csv
I_kwDOBMYwiM5HMZR9,Histogram date labels not correctly displayed,CLOSED,2022-04-06T10:33:03Z,2022-04-07T16:11:51Z,2022-04-07T16:11:51Z,"Two cases where time is displayed instead of date.

First is for monthly progress over year: https://goat.genomehubs.org/report?report=histogram&x=max%28assembly_date%29%3E2022%20AND%20bioproject%3DPRJNA533106&rank=species&result=taxon&cat=assembly_level%3Dcontig%2Cscaffold%2Cchromosome%2Ccomplete%20genome&excludeAncestral%5B0%5D=bioproject&excludeMissing%5B0%5D=bioproject&stacked=true&xOpts=2022-January%2C2022-December%2C%2C%2CAssembly%20date%20%28month%29&caption=Cumulative%20number%20of%20assemblies%20for%20eukaryotic%20species%20generated%20by%20EBP%20affiliates%20over%20time&taxonomy=ncbi&includeEstimates=false&yScale=linear

![Screenshot 2022-04-06 at 11 23 32](https://user-images.githubusercontent.com/13206220/161954455-5959ad26-f047-4915-ba5d-959bbc2eb1fa.png)

Second might be a cache problem from user, but could not confirm (report on EBP project page):
https://goat.genomehubs.org/projects/EBP
![image](https://user-images.githubusercontent.com/13206220/161955537-04d4501c-fdb0-4ec1-94f2-c67e1bf8fc08.png)


",ccaio,https://github.com/genomehubs/genomehubs/issues/118,genomehubs++genomehubs.csv
I_kwDOBMYwiM5HRmcy,Generate a tabular report,CLOSED,2022-04-07T09:46:40Z,2022-10-27T14:38:04Z,2022-10-27T14:38:03Z,"Generate a report of counts by group by re-using the term/ histogram aggregations from the histogram and scatter reports.

Table presentation will show the numbers directly for reporting and number of bins need not be constrained by plotting considerations",rjchallis,https://github.com/genomehubs/genomehubs/issues/120,genomehubs++genomehubs.csv
I_kwDOBMYwiM5H_vQc,scatter heat map should have scale,CLOSED,2022-04-19T07:31:54Z,2022-05-04T11:30:38Z,2022-05-04T11:30:38Z,Need to display heat map z range as a scale legend,rjchallis,https://github.com/genomehubs/genomehubs/issues/121,genomehubs++genomehubs.csv
I_kwDOBMYwiM5H_vz-,Lookup endpoint does not work on new es host,CLOSED,2022-04-19T07:34:11Z,2022-05-06T11:59:57Z,2022-05-06T11:59:57Z,Lookup endpoint uses elastic search scripts that are not being uploaded by default during indexing. Will be best to refactor lookup to generate full queries rather than rely on templates ,rjchallis,https://github.com/genomehubs/genomehubs/issues/122,genomehubs++genomehubs.csv
I_kwDOBMYwiM5IKk2a,API does not return scatter points when categories are set,CLOSED,2022-04-21T09:02:07Z,2022-05-09T07:41:15Z,2022-05-09T07:41:15Z,,rjchallis,https://github.com/genomehubs/genomehubs/issues/126,genomehubs++genomehubs.csv
I_kwDOBMYwiM5I9vrk,Add toggle switches to hide/display reports on GoaT-ui,CLOSED,2022-05-03T13:59:06Z,2022-05-04T15:32:48Z,2022-05-04T15:32:48Z,"Add switches on project pages that allow people to opt in or out of displaying specific plots: 
- could make a toggle component accessible from markdown to allow grid rows to be switched on or off",ccaio,https://github.com/genomehubs/genomehubs/issues/129,genomehubs++genomehubs.csv
I_kwDOBMYwiM5I9zyB,Need schema for import YAML,OPEN,2022-05-03T14:13:22Z,2022-05-03T14:13:22Z,,Import YAML files have many options so a schema will help to document these and allow validation ahead of import,rjchallis,https://github.com/genomehubs/genomehubs/issues/130,genomehubs++genomehubs.csv
I_kwDOBMYwiM5I-XYL,Allow relabelling of categories on reports,CLOSED,2022-05-03T16:11:49Z,2022-06-23T12:53:01Z,2022-06-23T12:53:01Z,"Ex: Project acronym instead of bioproject IDs:

https://goat.genomehubs.org/search?result=taxon&includeEstimates=true&summaryValues=count&taxonomy=ncbi&offset=0&query=max%28assembly_date%29%20AND%20bioproject%3DPRJNA533106%20AND%20tax_rank%28species%29&fields=c_value%2Cgenome_size%2Cgenome_size_kmer%2Cgenome_size_draft%2Cassembly_level%2Cassembly_span%2Cbusco_completeness%2Cgc_percent%2Cchromosome_number%2Chaploid_number%2Csequencing_status%2Csample_acquired%2Cin_progress%2Cinsdc_submitted%2Cinsdc_open%2Cpublished%2Csample_collected%2Csample_collected_by%2Clong_list%2Cother_priority%2Cfamily_representative&names=&ranks=&report=histogram&rank=species&cat=bioproject%5B9%2B%5D&cumulative=true#max(assembly_date)%20AND%20bioproject%3DPRJNA533106%20AND%20tax_rank(species)
",ccaio,https://github.com/genomehubs/genomehubs/issues/133,genomehubs++genomehubs.csv
I_kwDOBMYwiM5I-boY,Levels not expanding for some taxa,CLOSED,2022-05-03T16:29:13Z,2022-05-12T09:53:14Z,2022-05-12T09:53:14Z,"In the EBP tree, for most families (ex: bats), nodes can expand all the way to species, but not for Ephemeridae:

http://localhost:8884/search?result=taxon&includeEstimates=true&treeStyle=rect&levels=subspecies%2Cspecies%2Cgenus%2Cfamily%2Corder%2Cclass%2Cphylum&collapseMonotypic=true&yOpts=10000%2C100000000000&caption=Orders%20with%20at%20least%20one%20species%20sequenced%20by%20the%20Earth%20Biogenome%20Project.%20Orange%20highlights%20represent%20clades%20with%20at%20least%20one%20genome%20already%20published%20by%20EBP%20under%20the%20BioProject%20ID%20PRJEB40665.%20Tap%20tree%20nodes%20to%20see%20taxon%20records%20or%20long-press%20to%20expand%20each%20branch.&taxonomy=ncbi&treeThreshold=2000&query=tax_tree%2850581%29%20AND%20tax_rank%28family%29%20AND%20bioproject%3DPRJNA533106&fields=c_value%2Cassembly_level%2Cassembly_span%2Cbusco_completeness%2Cgc_percent%2Cchromosome_number%2Chaploid_number%2Cgenome_size%2Cgenome_size_kmer%2Cgenome_size_draft%2Cbioproject&report=tree&y=assembly_span%3E0%20AND%20bioproject%3DPRJNA533106#tax_tree(Ephemeridae)%20AND%20tax_rank(family)%20AND%20bioproject%3DPRJNA533106

",ccaio,https://github.com/genomehubs/genomehubs/issues/134,genomehubs++genomehubs.csv
I_kwDOBMYwiM5I-elw,Add map-based queries and reporting,OPEN,2022-05-03T16:41:55Z,2022-05-03T16:41:56Z,,"Ex: Add distribution and sample location data from databases; report sequencing effort per geo location, etc.",ccaio,https://github.com/genomehubs/genomehubs/issues/135,genomehubs++genomehubs.csv
I_kwDOBMYwiM5I-h_v,Safari - problems with caching,CLOSED,2022-05-03T16:51:45Z,2022-05-06T12:02:51Z,2022-05-06T12:00:31Z,unable to pickup goat-ui updates,ccaio,https://github.com/genomehubs/genomehubs/issues/136,genomehubs++genomehubs.csv
I_kwDOBMYwiM5JCKVr,Fill missing levels in variables for `goat-cli`,CLOSED,2022-05-04T12:29:03Z,2022-05-04T13:00:13Z,2022-05-04T13:00:13Z,"In pulling the public JSON:

```bash
curl -X 'GET' \
'https://goat.genomehubs.org/api/v0.0.1/resultFields?result=taxon&taxonomy=ncbi' \
-H 'accept: application/json' > vars.json 2> /dev/null
```

I can get all of the variables which is nice. Some variables, which I will list, have no constraint enums. This hinders some useful parsing in `goat-cli`. Full list:
- bioproject
- biosample
- busco_lineage
- in_progress
- insdc_open
- insdc_submitted
- published
- sample_acquired
- sample_collected
- sample_collected_by
- sample_sex
- sex_determination

To be explicit, biosample (rendered in md) has a length of 32 on constraint, but no actual fields:

|group|name|constraint|display_group|organelle|separator|source|source_url_stub|type|display_level|display_name|key|summary|traverse|traverse_direction|
|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|
|taxon|biosample|{len: 32}|assembly|nucleus|[;]|NCBI Datasets|https://www.ncbi.nlm.nih.gov/assembly/|keyword|2|Biosample|biosample|[list]|list|up|

whereas family_representative does:

|group|name|display_group|display_level|constraint|summary|traverse|traverse_direction|type|
|-|-|-|-|-|-|-|-|-|
|taxon|family_representative|target_lists|2|{enum: [asg, cbp, ebpn, cfgp, dtol, ebpn, endemixit, erga, eurofish, gaga, squalomix, metainvert, vgp, agi, arg, gap, gbr, omg, tsi, b10k]}|list|list|up|keyword|",Euphrasiologist,https://github.com/genomehubs/genomehubs/issues/137,genomehubs++genomehubs.csv
I_kwDOBMYwiM5JMIxI,genomehubs index --file-metadata should check existing files,CLOSED,2022-05-06T14:09:46Z,2022-10-27T14:31:02Z,2022-10-27T14:31:02Z,"Currently:
```
genomehubs index --taxonomy-source ncbi --config-file goat.yaml --file-metadata btk/btk.files.yaml
```
indexes all files in btk.files.yaml and puts them in config --hub-path/files

It would be useful to check if the file to be indexed already exists in the expected location so it does not have to be downloaded again.",sujaikumar,https://github.com/genomehubs/genomehubs/issues/142,genomehubs++genomehubs.csv
I_kwDOBMYwiM5JYBBy,add a tax_lineage search option,CLOSED,2022-05-10T11:46:05Z,2022-05-12T09:53:14Z,2022-05-12T09:53:14Z,"Would be useful to be able to return all ancestors of a taxon using a query like
```
tax_lineage(9612)
```",rjchallis,https://github.com/genomehubs/genomehubs/issues/145,genomehubs++genomehubs.csv
I_kwDOBMYwiM5JZha0,Filling of homonyms on GoaT propagates wrong estimates,CLOSED,2022-05-10T16:44:07Z,2022-05-16T14:17:54Z,2022-05-16T14:17:54Z,"Melanotus sp. can refer to a fungi or beetle (Coleoptera) species. There is no Melanotus sp. as a Coleoptera on NCBI taxonomy, but there are multiple fungi Melanotus sp. (taxon IDs - 2659796, 2659797, 2659798, 2282672, 2282677, 2282691, 2282667). GoaT is filling the fungi Melanotus sp. karyotype attributes with data from the Coleoptera database and propagating it across fungi instead of throwing the the entry to the exceptions file.

Taxon record here:
[https://goat.genomehubs.org/records?record_id=2041008&result=taxon&taxonomy=ncbi#Melanotus%20sp.%20(in%3A%20Fungi)](url)

Source file here:
[https://github.com/genomehubs/goat-data/blob/main/sources/genomesize_karyotype/coleo-2021-07-28.csv](url)",ccaio,https://github.com/genomehubs/genomehubs/issues/147,genomehubs++genomehubs.csv
I_kwDOBMYwiM5JfEdl,Unable to generate scatter for assembly index,CLOSED,2022-05-11T16:05:52Z,2022-05-12T09:53:15Z,2022-05-12T09:53:15Z,"Got an unexpected error when trying to generate a contig x scaffold N50 scatter for VGP assemblies:

""timestamp"": ""2022-05-11T15:47:39.359Z"",

**queryString:** ""result=assembly&includeEstimates=false&taxonomy=ncbi&report=scatter&y=scaffold_n50%20AND%20bioproject_accession%3DPRJNA489243&rank=species&zScale=sqrt&xOpts=100%2C1000000000%2C8&yOpts=1000%2C1000000000%2C7&scatterThreshold=10000&x=contig_n50%20AND%20bioproject_accession%3DPRJNA489243"",
  ""scatter"": {}",ccaio,https://github.com/genomehubs/genomehubs/issues/149,genomehubs++genomehubs.csv
I_kwDOBMYwiM5JhvPZ,generate container versions without release,CLOSED,2022-05-12T07:45:19Z,2022-05-12T09:53:15Z,2022-05-12T09:53:15Z,Would be useful to add a workflow to update containers on demand to allow testing of features in a containerised environment without requiring a full release,rjchallis,https://github.com/genomehubs/genomehubs/issues/151,genomehubs++genomehubs.csv
I_kwDOBMYwiM5JiVRg,allow synonyms for attribute keys,CLOSED,2022-05-12T09:50:17Z,2022-05-31T15:52:39Z,2022-05-31T15:52:39Z,"At present, changing an attribute key is a breaking change so allowing synonyms will provide a way to update attribute keys while offering a fallback for queries using the old names.

would be convenient to specify this in the yaml like:
```
attributes:
  bioproject:
    ...
    synonyms:
      - bioproject_accession
    type: keyword
```",rjchallis,https://github.com/genomehubs/genomehubs/issues/153,genomehubs++genomehubs.csv
I_kwDOBMYwiM5Jvg3n,duplicate values in assembly index,CLOSED,2022-05-16T13:48:58Z,2022-05-16T14:18:13Z,2022-05-16T14:18:13Z,"When adding attributes to the assembly index, existing entries are being duplicated causing assembly counts to be elevated in histogram/scatter reports",rjchallis,https://github.com/genomehubs/genomehubs/issues/154,genomehubs++genomehubs.csv
I_kwDOBMYwiM5J5bC2,create an API endpoint to describe available values and valid operators,OPEN,2022-05-18T11:02:43Z,2023-05-23T14:58:58Z,,"```
      # TODO: create an additional endpoint to describe available values and valid operators
```

https://github.com/genomehubs/genomehubs/blob/3f2d5a13259f79b9e334099098c7caf01109a035/src/genomehubs-api/src/api-v2.yaml#L195",rjchallis,https://github.com/genomehubs/genomehubs/issues/157,genomehubs++genomehubs.csv
I_kwDOBMYwiM5J5fwG,Improve API documentation,CLOSED,2022-05-18T11:20:38Z,2022-06-15T08:27:22Z,2022-06-15T08:27:22Z,"API spec should include full descriptions and examples

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/158,genomehubs++genomehubs.csv
I_kwDOBMYwiM5KBO6P,Add an API endpoint to list valid taxonomic ranks,OPEN,2022-05-19T14:00:59Z,2022-05-19T14:00:59Z,,"```
      #TODO: Add an API endpoint to list valid taxonomic ranks
```

https://github.com/genomehubs/genomehubs/blob/cbfb00302a8f0c441bf70fcbb5ad65465209be0b/src/genomehubs-api/src/api-v2.yaml#L10",rjchallis,https://github.com/genomehubs/genomehubs/issues/160,genomehubs++genomehubs.csv
I_kwDOBMYwiM5KTsym,Unable to sort search result by column,CLOSED,2022-05-24T14:49:22Z,2022-05-26T09:06:32Z,2022-05-26T09:06:32Z,"Cannot sort list by attribute (ex: lowest to highest c-value).  Clicking on the arrows to sort the column returns zero hits:

Ex:
https://goat.genomehubs.org/search?result=taxon&fields=assembly_span%2Cchromosome_number%2Chaploid_number%2Csex_determination%2Cploidy%2Cc_value%2Cgenome_size%2Clong_list&includeEstimates=true&summaryValues=count&taxonomy=ncbi&offset=0&query=tax_tree%28Viridiplantae%29%20AND%20tax_rank%28species%29%20AND%20long_list%3DDTOL&excludeMissing%5B0%5D=c_value&excludeAncestral%5B0%5D=c_value#tax_tree(Viridiplantae)%20AND%20tax_rank(species)%20AND%20long_list%3DDTOL

",ccaio,https://github.com/genomehubs/genomehubs/issues/161,genomehubs++genomehubs.csv
I_kwDOBMYwiM5Kt4vP,Back arrow on browser does not take to previous page,CLOSED,2022-05-31T08:48:04Z,2022-05-31T15:52:10Z,2022-05-31T15:52:10Z,"On assembly index searches: when clicking the back arrow on the browser, after viewing one assembly record, the page does not go back to the search result. Instead, it displays the assembly ID on the search box, but no results
[https://goat.genomehubs.org/search?includeEstimates=true&offset=0&query=tax_tree%28can[]20AND%20tax_rank%28species%29&result=assembly&taxonomy=ncbi](https://goat.genomehubs.org/search?includeEstimates=true&offset=0&query=tax_tree%28canidae%29%20AND%20tax_rank%28species%29&result=assembly&taxonomy=ncbi#tax_tree(canidae)%20AND%20tax_rank(species))
![Screenshot 2022-05-30 at 17 59 10](https://user-images.githubusercontent.com/13206220/171132547-22480b5a-0010-488b-893c-c8f7bec1faa2.png)


",ccaio,https://github.com/genomehubs/genomehubs/issues/165,genomehubs++genomehubs.csv
I_kwDOBMYwiM5KuLh3,Use cookies to store preferred column headings/filters,CLOSED,2022-05-31T09:51:52Z,2022-06-15T08:26:49Z,2022-06-15T08:26:49Z,"Currently the URL stores which column headings are shown on the search page. But it might be good to ask users if they want to store preferences in a cookie.

- Need to be aware of privacy issues, so give users an option to deny cookies, or to clear them easily

A temporary workaround to suggest to end users would be to get the display looking as they want it, and then bookmark the URL and reuse that URL with new search terms as the URL stores all the selected column headings, sort order etc",sujaikumar,https://github.com/genomehubs/genomehubs/issues/166,genomehubs++genomehubs.csv
I_kwDOBMYwiM5KuS_6,Query builder - index = Assembly is not sticking,CLOSED,2022-05-31T10:17:49Z,2022-05-31T15:52:10Z,2022-05-31T15:52:10Z,Query builder - index = Assembly does not stay between searches,sujaikumar,https://github.com/genomehubs/genomehubs/issues/167,genomehubs++genomehubs.csv
I_kwDOBMYwiM5KueQc,tax_name(tolid_prefix) not working,CLOSED,2022-05-31T10:59:54Z,2022-05-31T15:52:10Z,2022-05-31T15:52:10Z,"eg:
https://goat.genomehubs.org/search?query=tax_name%28qmTraRath%29&result=taxon&taxonomy=ncbi#tax_name(qmTraRath) returns 0 results, but adding `tax_name(tol_id:qmTraRath)` works",sujaikumar,https://github.com/genomehubs/genomehubs/issues/168,genomehubs++genomehubs.csv
I_kwDOBMYwiM5K16di,Missing category labels when sorting on x axis ,CLOSED,2022-06-01T10:43:10Z,2022-06-01T16:16:37Z,2022-06-01T16:16:37Z,"When trying to sort categories on the x axis (histogram reports), the category labels (and different colours) do not appear. 

ex: [histo link](https://goat.genomehubs.org/search?query=tax_tree%28eukaryota%29%20AND%20sequencing_status_vgp%20AND%20tax_rank%28species%29&result=taxon&fields=assembly_level%2Cassembly_span%2Cbusco_completeness%2Cgc_percent%2Cchromosome_number%2Chaploid_number%2Cc_value%2Cgenome_size%2Cgenome_size_kmer%2Cgenome_size_draft%2Csample_acquired%2Cin_progress%2Cinsdc_submitted%2Cinsdc_open%2Cpublished%2Csample_collected%2Csample_collected_by%2Csequencing_status%2Csequencing_status_b10k%2Csequencing_status_cbp%2Csequencing_status_cfgp%2Csequencing_status_dtol%2Csequencing_status_ebpn%2Csequencing_status_endemixit%2Csequencing_status_erga%2Csequencing_status_eurofish%2Csequencing_status_gaga%2Csequencing_status_metainvert%2Csequencing_status_squalomix%2Csequencing_status_vgp%2Clong_list%2Cother_priority%2Cfamily_representative&includeEstimates=true&summaryValues=count&taxonomy=ncbi&excludeMissing%5B0%5D=sequencing_status_vgp&report=histogram&rank=species&xOpts=sample_collected%2Csample_acquired%2Cin_progress%2Cinsdc_submitted%2Cinsdc_open%3B#tax_tree(eukaryota)%20AND%20sequencing_status_vgp%20AND%20tax_rank(species))",ccaio,https://github.com/genomehubs/genomehubs/issues/174,genomehubs++genomehubs.csv
I_kwDOBMYwiM5K18c8,Term disappears when using autocomplete to edit reports,CLOSED,2022-06-01T10:47:06Z,2022-06-01T15:51:47Z,2022-06-01T15:51:47Z,When trying to use autocomplete function to edit reports (ex: define categories for histograms) clicking on the suggested term results in a blank field.,ccaio,https://github.com/genomehubs/genomehubs/issues/175,genomehubs++genomehubs.csv
I_kwDOBMYwiM5Luct1,Fix label display/ fitting for histograms,CLOSED,2022-06-14T08:48:57Z,2022-06-23T12:53:02Z,2022-06-23T12:53:02Z,"Large text of labels currently overlap instead of creating new line (assembly index reports):

[Histo example](https://goat.genomehubs.org/report?report=scatter&x=contig_n50%20AND%20bioproject_accession%3DPRJNA489243&y=scaffold_n50&cat=assembly_type&result=assembly&xOpts=10000%2C1000000000%2C11%2Clog10&yOpts=10000%2C1000000000%2C11%2Clog10&scatterThreshold=10000&highlightArea=1000000%2C10000000%2C1000000000%2C1000000000%2CEBP%20metric%20zone&caption=Contiguity%20assessment%20of%20VGP%20assemblies.%20EBP%20metric%20zone%20defines%20the%20EBP%20assembly%20quality%20standards%20of%20a%20contig%20N50%20%3E%201Mb%20and%20a%20scaffold%20N50%20%3E%2010Mb&taxonomy=ncbi&includeEstimates=false)


",ccaio,https://github.com/genomehubs/genomehubs/issues/178,genomehubs++genomehubs.csv
I_kwDOBMYwiM5Lu2ZZ,link from n=? in attribute table to matching records,CLOSED,2022-06-14T10:10:46Z,2022-06-15T08:26:49Z,2022-06-15T08:26:49Z,Currently requires multiple steps to find which are the direct descendants contributing to a value,rjchallis,https://github.com/genomehubs/genomehubs/issues/179,genomehubs++genomehubs.csv
I_kwDOBMYwiM5LzziV,add a sample index,CLOSED,2022-06-15T08:32:46Z,2022-06-23T12:54:45Z,2022-06-23T12:54:45Z,"currently the assembly index approximates a sample index for samples with an assembly, but it would be useful to be able to include metadata for samples more directly, e.g. for samples without assemblies and to break the 1:1 link between sample and assembly as samples will increasingly have 2 primary and alternate haplotype assemblies in addition to any assembly iterations. 

The sample index can be based on the existing assembly index both sample_id and a list of assembly IDs. The assembly index should be updated to include sample_id.",rjchallis,https://github.com/genomehubs/genomehubs/issues/182,genomehubs++genomehubs.csv
I_kwDOBMYwiM5L1wcz,add query validation API endpoint,OPEN,2022-06-15T15:12:06Z,2022-06-15T15:12:06Z,,,rjchallis,https://github.com/genomehubs/genomehubs/issues/183,genomehubs++genomehubs.csv
I_kwDOBMYwiM5L5RJu,support regex-based constraint for keyword values,OPEN,2022-06-16T09:32:16Z,2022-06-16T09:32:16Z,,,rjchallis,https://github.com/genomehubs/genomehubs/issues/184,genomehubs++genomehubs.csv
I_kwDOBMYwiM5L6lKX,Fix mismatch between scatter points and category legends,CLOSED,2022-06-16T14:31:51Z,2022-06-30T07:31:25Z,2022-06-30T07:31:25Z,"Scatter points not matching the categories in specific cases ([example](https://goat.genomehubs.org/search?includeEstimates=true&offset=0&query=contig_n50%20AND%20tax_tree%28Nematoda%29%20AND%20tax_rank%28species%29&result=assembly&taxonomy=ncbi&report=scatter&y=scaffold_n50%20AND%20tax_tree%28Nematoda%29&rank=species&cat=bioproject_accession%3DPRJEB40665%2C%2B&xOpts=1000%2C10000000%2C9%2Clog10&yOpts=10000%2C100000000%2C9%2Clog10&scatterThreshold=1000&fields=assembly_level%2Cassembly_type%2Cbioproject_accession%2Cbiosample_accession%2Cebp_metric_date%2Cisolate%2Clast_updated%2Crefseq_category%2Csample_sex%2Csubmitter%2Csample_location%2Cassembly_span%2Cchromosome_count%2Ccontig_count%2Ccontig_n50%2Cscaffold_count%2Cscaffold_n50%2Cgc_percent%2Cn_percent%2Cgene_count%2Cbusco_completeness&names=&ranks=family%2Cclass%2Cphylum#contig_n50%20AND%20tax_tree(Nematoda)%20AND%20tax_rank(species)) of no matches for DTOL Bioproject PRJEB40655), but [binned scatters](https://goat.genomehubs.org/search?includeEstimates=true&offset=0&query=contig_n50%20AND%20tax_tree%28Nematoda%29%20AND%20tax_rank%28species%29&result=assembly&taxonomy=ncbi&report=scatter&y=scaffold_n50%20AND%20tax_tree%28Nematoda%29&rank=species&cat=bioproject_accession%3DPRJEB40665%2C%2B&xOpts=1000%2C10000000%2C9%2Clog10&yOpts=10000%2C100000000%2C9%2Clog10&scatterThreshold=10&fields=assembly_level%2Cassembly_type%2Cbioproject_accession%2Cbiosample_accession%2Cebp_metric_date%2Cisolate%2Clast_updated%2Crefseq_category%2Csample_sex%2Csubmitter%2Csample_location%2Cassembly_span%2Cchromosome_count%2Ccontig_count%2Ccontig_n50%2Cscaffold_count%2Cscaffold_n50%2Cgc_percent%2Cn_percent%2Cgene_count%2Cbusco_completeness&names=&ranks=family%2Cclass%2Cphylum#contig_n50%20AND%20tax_tree(Nematoda)%20AND%20tax_rank(species)) are ok. 

""_Misalignment seems to be happening because the binned and point scatters handle out-of-range values differently. Might be solved by copying x/yOpts limits into the search query to make sure things match up. Would also allow limits to be less than the full range of values_."" (RC)",ccaio,https://github.com/genomehubs/genomehubs/issues/185,genomehubs++genomehubs.csv
I_kwDOBMYwiM5MAffC,standardise doc id prefixes,CLOSED,2022-06-17T15:44:07Z,2022-07-12T14:04:27Z,2022-07-12T14:04:27Z,"https://github.com/genomehubs/genomehubs/blob/8465594c6e41f6cc6955457245253c3d661a151b/src/genomehubs-api/src/api/v2/functions/getRecordsById.js#L15

taxon doc IDs are currently prefixed with taxon_id, all others are prefixed with index name.

Needs to be changed in both index and API code

<!-- Edit the body of your new issue then click the  ""Create Issue"" button in the top right of the editor. The first line will be the issue title. Assignees and Labels follow after a blank line. Leave an empty line before beginning the body of the issue. -->",rjchallis,https://github.com/genomehubs/genomehubs/issues/186,genomehubs++genomehubs.csv
I_kwDOBMYwiM5MLg_O,Normalise case before translate,CLOSED,2022-06-21T08:27:26Z,2022-06-23T08:41:26Z,2022-06-23T08:41:26Z,"https://github.com/genomehubs/genomehubs/blob/c0a57e846d8f7f7aa480c7ae4f65e75f76a3f914/src/genomehubs/lib/hub.py#L470

",sujaikumar,https://github.com/genomehubs/genomehubs/issues/187,genomehubs++genomehubs.csv
I_kwDOBMYwiM5MRr5g,"Print attribute name that fails during fill, KeyError: None",CLOSED,2022-06-22T07:39:03Z,2022-06-23T08:41:25Z,2022-06-23T08:41:25Z,eg: https://github.com/genomehubs/goat-data/runs/6991516878?check_suite_focus=true#step:4:86,sujaikumar,https://github.com/genomehubs/genomehubs/issues/190,genomehubs++genomehubs.csv
I_kwDOBMYwiM5McXIM,rename xInY plots,CLOSED,2022-06-23T14:31:34Z,2022-08-26T13:58:24Z,2022-08-26T13:58:24Z,"The xInY report title is not very user friendly so it would be good to rename to something that conveys the plot rainbow and donut plot shapes that it is used to generate. Will be important to ensure that the existing name is mapped to the new plot name to ensure old URLs remain valid.

Thanks to @Euphrasiologist for suggesting `arc`.",rjchallis,https://github.com/genomehubs/genomehubs/issues/196,genomehubs++genomehubs.csv
I_kwDOBMYwiM5My0JU,add a geographic report,CLOSED,2022-06-29T08:56:55Z,2022-07-08T15:16:23Z,2022-07-08T15:16:23Z,Need to be able to plot all sample locations for a given query. Would be good to support categories and allow binned as well as point data to be shown on a map.,rjchallis,https://github.com/genomehubs/genomehubs/issues/197,genomehubs++genomehubs.csv
I_kwDOBMYwiM5NKIbw,Allow selecting result columns before assembly index search,CLOSED,2022-07-05T16:12:56Z,2022-07-07T08:16:27Z,2022-07-07T08:16:27Z,"Allow the following behaviour for Assembly index queries on GoaT UI:

1. select assembly index using query builder (page resets)
2. select the result columns for display (before performing a search)
3. use query builder or search box to complete search

",ccaio,https://github.com/genomehubs/genomehubs/issues/198,genomehubs++genomehubs.csv
I_kwDOBMYwiM5NKJmR,make tax_rank(species) a default term in assembly index queries,CLOSED,2022-07-05T16:17:47Z,2023-03-20T15:42:07Z,2023-03-20T15:42:07Z,"As assembly index queries will always retrieve species-level lists, it would be more straightforward if tax_rank=species was a default query term for the index.",ccaio,https://github.com/genomehubs/genomehubs/issues/199,genomehubs++genomehubs.csv
I_kwDOBMYwiM5NKM4Z,Allow transposing of results from one index as input in queries of different index,CLOSED,2022-07-05T16:32:04Z,2022-10-27T14:29:53Z,2022-10-27T14:29:53Z,"Users might see value in using one type of query to refine a search that can only be done in a different GoaT index. Perhaps allowing transposition between indices might help.

**Use case example:** refine query results using genome size (taxon index) to retrieve a list of taxa to be used as input in queries in the assembly index.




",ccaio,https://github.com/genomehubs/genomehubs/issues/200,genomehubs++genomehubs.csv
I_kwDOBMYwiM5NPhFU,Unable to search from EBP histograms,CLOSED,2022-07-06T14:18:51Z,2022-07-07T08:16:28Z,2022-07-07T08:16:28Z,"clicking on bins does not return new search (different reasons, depending on X).

Ex: [invalid date](https://goat.genomehubs.org/report?report=histogram&x=max%28assembly_date%29%20AND%20bioproject%3DPRJNA533106&rank=species&result=taxon&cat=assembly_level%3Dcontig%2Cscaffold%2Cchromosome%2Ccomplete%20genome&includeEstimates=true&excludeAncestral%5B0%5D=bioproject&excludeMissing%5B0%5D=bioproject&stacked=true&cumulative=true&xOpts=2006%2C2023%2C2%2C%2CAssembly%20date&caption=Cumulative%20number%20of%20assemblies%20for%20eukaryotic%20species%20generated%20by%20EBP%20affiliates%20over%20time&taxonomy=ncbi) and [operator in tax_rank](https://goat.genomehubs.org/report?report=histogram&x=max%28assembly_date%29%3E2022%20AND%20bioproject%3DPRJNA533106&rank=family&result=taxon&cat=assembly_level%3Dcontig%2Cscaffold%2Cchromosome%2Ccomplete%20genome&includeEstimates=true&excludeAncestral%5B0%5D=bioproject&excludeMissing%5B0%5D=bioproject&stacked=true&xOpts=2022-01%2C2022-12%2C%2C%2CAssembly%20date%20%28month%29&caption=Number%20of%20assemblies%20for%20eukaryotic%20families%20generated%20by%20EBP%20affiliates%20each%20month%20in%202022&taxonomy=ncbi) error.

",ccaio,https://github.com/genomehubs/genomehubs/issues/202,genomehubs++genomehubs.csv
I_kwDOBMYwiM5Olkuo,unable to fill values in query box,CLOSED,2022-07-26T16:13:17Z,2022-08-08T09:49:41Z,2022-08-08T09:49:41Z,"after selecting operator, cannot fill in values for some attributes. Ex: genome_size, chromosome number and ploidy:
![Screenshot 2022-07-26 at 17 09 36](https://user-images.githubusercontent.com/13206220/181057102-8bd18aa4-28af-4c76-b70e-48ca68ddc64b.png)

",ccaio,https://github.com/genomehubs/genomehubs/issues/211,genomehubs++genomehubs.csv
I_kwDOBMYwiM5RhRsq,Suggestion to separate direct and descendent values from ancestral estimates,CLOSED,2022-09-09T11:14:23Z,2023-03-20T15:41:27Z,2023-03-20T15:41:27Z,"Mark suggested that it would be useful to do a list that had (a) direct and descendant estimates and (b) inferred from ancestor estimates, as (a) are more credible than (b).

Is that possible in one query in GoaT (ie have a column represented twice in the output, with different filters)?

Alternatively, would it be possible to generate a column displaying the aggregation source next to the attribute values?
",ccaio,https://github.com/genomehubs/genomehubs/issues/214,genomehubs++genomehubs.csv
I_kwDOBMYwiM5Tbp5P,Allow mode as a primary/transverse value when multiple sources,CLOSED,2022-10-06T14:32:34Z,2022-10-27T14:41:04Z,2022-10-27T14:41:04Z,"For many karyotype attributes on GoaT, the mode would be a best representation of the data and primary/transverse values should be set accordingly.
Selecting mode when there is a list of values from a single source returns the first value from the list, which is less accurate than the current `median_high` selected as primary. 

So, it would be nice to have a `mode_median_high` option that could pick the mode if possible, otherwise default to median_high.",ccaio,https://github.com/genomehubs/genomehubs/issues/221,genomehubs++genomehubs.csv
I_kwDOBMYwiM5Th2LP,Scatter report does not return correct TSV,OPEN,2022-10-07T15:50:21Z,2022-10-10T16:43:31Z,,"        @rjchallis 

I'm trying to implement scatter, with a CLI API:

```bash
goat-cli taxon scatter -x assembly_span -y gc_percent -t Eukaryota -u
```

All good. Returns what I think it the URL should return as well:

```txt
GoaT lookup API URL:	https://goat.genomehubs.org/api/v2/report?result=taxon&includeEstimates=false&taxonomy=ncbi&report=table&rank=species&x=tax_tree%28Eukaryota%29%20AND%20assembly_span&y=gc_percent
```

But! It does not return the TSV I expect.

Try:

```bash
curl -X 'GET' ""https://goat.genomehubs.org/api/v2/report?result=taxon&includeEstimates=false&summaryValues=count&taxonomy=ncbi&report=table&y=gc_percent&rank=species&x=tax_tree%28lamiales%29%20and%20assembly_span"" -H ""accept: text/tab-separated-values""
```

JSON looks good to me though:

```bash
curl -X 'GET' ""https://goat.genomehubs.org/api/v2/report?result=taxon&includeEstimates=false&summaryValues=count&taxonomy=ncbi&report=table&y=gc_percent&rank=species&x=tax_tree%28lamiales%29%20and%20assembly_span"" -H ""accept: application/json""
```

I could implement something my side to parse the JSON but I presume this will want to be fixed for future?

Thought this was a good cross-over genomehubs issue.

_Originally posted by @Euphrasiologist in https://github.com/genomehubs/goat-cli/issues/15#issuecomment-1264665031_
      ",Euphrasiologist,https://github.com/genomehubs/genomehubs/issues/222,genomehubs++genomehubs.csv
I_kwDOBMYwiM5Tyrt5,Set assemblies as primary and flag potentially partial / symbiont assemblies,OPEN,2022-10-12T08:30:30Z,2022-10-27T14:28:29Z,,"We are currently using refseq = true to set assemblies as primary, but this unintentionally import multiple versions of an assembly as primary.

We need to establish criteria to set assemblies as primary, and create a script to parse multiple conditions for eukaryotic reference assemblies.

**Some useful criteria**

For primary:
1. suffix of assembly ID
2. assembly level = chromosome or complete genome

Flag as partial / symbiont / ""not reliable value"":
1. look if partial flag exists in ncbi datasets
2. assembly span < 1M
3. Instances we know symbionts were actually labeled/submitted as hosts ",ccaio,https://github.com/genomehubs/genomehubs/issues/223,genomehubs++genomehubs.csv
I_kwDOBMYwiM5TzM6W,Linking organelle assemblies to corresponding nuclear assembly ID,OPEN,2022-10-12T10:04:09Z,2023-04-11T13:17:11Z,,"Initiated as a discussion on how to report organelle metrics on genome notes linked to specific DToL assembly submission.

- In the assembly index we could chain query from an assembly id to retrieve all data linked to an individual biosample;
- that would return one assembly ID per row, including organellar ids and associated attribute values (e.g. span, GC%);
- assembly_type should specify if nuclear or organelle (MT, CP)
 
what we need:
1. Source for non refseq_organelles (ftp source)
2. Set that as primary
3. linked organelle column would unambiguously retrieve what we want (biosample is temporary)",ccaio,https://github.com/genomehubs/genomehubs/issues/224,genomehubs++genomehubs.csv
I_kwDOBMYwiM5VVdh9,Sampling location dots on map not linking out,CLOSED,2022-11-01T16:08:59Z,2022-11-24T15:55:21Z,2022-11-24T15:55:13Z,"Clicking on dots on the maps from sample location [searches](https://goat.genomehubs.org/search?query=tax_name%28carnivora%29&result=taxon&fields=sample_location%2Clong_list%2Cother_priority%2Cfamily_representative&includeEstimates=true&summaryValues=count&ranks=phylum%2Ckingdom%2Csuperkingdom&taxonomy=ncbi&size=10&report=map&offset=0&names=#tax_name(carnivora)) returns  a [random css](https://goat.genomehubs.org/search/undefined/search?query=tax_tree%2833554%29%20AND%20sample_location%3D77.78527798131108%2C%20-70.63138900324702&result=sample&taxonomy=ncbi). 

Opening [map url first ](https://goat.genomehubs.org/reporturl?result=taxon&fields=sample_location%2Clong_list%2Cother_priority%2Cfamily_representative&includeEstimates=true&summaryValues=count&ranks=phylum%2Ckingdom%2Csuperkingdom&taxonomy=ncbi&size=10&report=map&offset=0&names=&x=tax_name%28carnivora%29)and then clicking on the location point leads to an unresponsive page.

Add a 404 page to handle this as a temporary measure.
",ccaio,https://github.com/genomehubs/genomehubs/issues/227,genomehubs++genomehubs.csv
I_kwDOBMYwiM5XI4SM,UI - query builder - can't type depth,CLOSED,2022-11-23T15:16:53Z,2022-11-24T10:57:56Z,2022-11-24T10:57:56Z,"At goat.genomehubs.org - clicking Query Builder doesn't allow one to type anything in the depth field
![image](https://user-images.githubusercontent.com/333876/203582335-83b06557-37e2-4e80-b435-51ce126aae8a.png)
",sujaikumar,https://github.com/genomehubs/genomehubs/issues/233,genomehubs++genomehubs.csv
I_kwDOBMYwiM5XL6qI,Search table values - clicking once does not show popup sometimes,CLOSED,2022-11-24T04:28:17Z,2022-11-24T10:57:57Z,2022-11-24T10:57:57Z,"Sometimes, when clicking on a value in the search table, the source pop up does not show up after one click.

The maximum number of clicks I have needed so far is 3. In some cases it took only 2 or 1.

Once a value has been clicked on, it does work as expected (1 click) the next time.

But if you reload the same page/search and click again, it again takes 3 clicks (ie it is not likely to be an api-caching issue)",sujaikumar,https://github.com/genomehubs/genomehubs/issues/234,genomehubs++genomehubs.csv
I_kwDOBMYwiM5beOMK,"Toggle ""include descendants"" on assembly index search page not working",CLOSED,2023-01-16T10:06:51Z,2023-01-30T09:38:46Z,2023-01-30T09:38:46Z,,sujaikumar,https://github.com/genomehubs/genomehubs/issues/247,genomehubs++genomehubs.csv
I_kwDOBMYwiM5clqts,unable to select rank and name columns for tax_lineage,CLOSED,2023-01-23T16:16:40Z,2023-01-30T09:38:46Z,2023-01-30T09:38:46Z,from [here](https://goat.genomehubs.org/search?query=tax_lineage%2879949%5BNorway%20lemming%5D%29&result=taxon&includeEstimates=false&summaryValues=count&taxonomy=ncbi&offset=0&fields=none&names=&ranks=&size=100#tax_lineage(79949%5BNorway%20lemming%5D)) I am unable to select name or rank columns. Other attribute columns seem fine.,ccaio,https://github.com/genomehubs/genomehubs/issues/248,genomehubs++genomehubs.csv
I_kwDOBMYwiM5c3WSi,unable to sort results or build queries using organelle attribute,CLOSED,2023-01-26T11:41:44Z,2023-01-30T09:38:16Z,2023-01-30T09:38:16Z,"Assembly index queries using the organelle attribute values do not return results (invalid value for organelle in organelle=nucleus). 

Sorting a valid query result using the organelle field returns a 0 hits page: ""Could not load search/ search_phase_execution_exception"". ",ccaio,https://github.com/genomehubs/genomehubs/issues/249,genomehubs++genomehubs.csv
I_kwDOBMYwiM5c442D,Assembly index: unable to use names and ranks in search,CLOSED,2023-01-26T16:25:08Z,2023-01-30T09:39:27Z,2023-01-30T09:39:27Z,"We are currently unable to expand the `names` under assembly index using the UI, so columns such as `tolid_prefix` cannot be selected.  The curl command seem to work  when including `names=tolid_prefix `, but retrieves a [] around it.
Probably related to it, columns under `ranks` are not filled in the assembly index like they are for the taxon index results.",ccaio,https://github.com/genomehubs/genomehubs/issues/250,genomehubs++genomehubs.csv
I_kwDOBMYwiM5d05X5,Add bioproject_description during genomehubs-parse --ncbi-datasets-genome,CLOSED,2023-02-07T11:19:57Z,2023-03-01T10:59:47Z,2023-03-01T10:59:47Z,,sujaikumar,https://github.com/genomehubs/genomehubs/issues/255,genomehubs++genomehubs.csv
I_kwDOBMYwiM5eED0y,Reduce log messages in some genomehubs commands,CLOSED,2023-02-09T15:33:52Z,2023-02-16T15:05:03Z,2023-02-16T14:51:01Z,"Request to reduce the frequency of logs (eg every minute instead of second), or every 10000 records instead of every 1 or 10 or 100 records)

In all cases - nice to have log msg at start, every Nth record/row (10,000?), end

* genomehubs parse --refseq-organelles
* genomehubs init
  * fetch taxdump.tar.gz uses tolkit so I think any file fetch should be at the start and maybe after every 10MB and the end?
  * init reports every 500 records, can that be every 10000 records?
* genomehubs index
  * processing rows - i can't tell what the unit of reporting is, but could easily be every 10,000 rows
  * indexing reports every 500 records, can that be every 10000 records as well
* genomehubs fill
  * reports every 500 records, can be made 10000

One thought - the default could be 10,000 - with the option to change, or switch off completely?",sujaikumar,https://github.com/genomehubs/genomehubs/issues/257,genomehubs++genomehubs.csv
I_kwDOBMYwiM5gMZlh,Trees showing additional taxa compared to query,CLOSED,2023-03-07T17:05:56Z,2023-03-20T15:35:50Z,2023-03-20T15:35:50Z,"Ive been trying to restrict the EBP tree report to show only the orders that have something sequenced under their bioproject. Query is fine (184 order), but tree is showing [all Eukaryote orders](https://goat.genomehubs.org/search?query=bioproject%3DPRJNA533106%20AND%20tax_rank%28order%29&result=taxon&includeEstimates=true&summaryValues=count&taxonomy=ncbi&size=100&report=tree&treeStyle=ring&treeThreshold=2000&pointSize=15&offset=0&fields=c_value%2Cgenome_size%2Cgenome_size_kmer%2Cgenome_size_draft%2Cassembly_level%2Cassembly_span%2Cbioproject%2Cchromosome_number%2Chaploid_number&names=&ranks=&collapseMonotypic=true#bioproject=PRJNA533106%20AND%20tax_rank(order)). 

Similarly example for [tree](https://goat.genomehubs.org/search?result=taxon&taxonomy=ncbi&includeEstimates=true&treeStyle=rect&levels=%2Csubspecies%2Cspecies%2Cgenus%2Cfamily%2Corder%2Cclass%2Cphylum&collapseMonotypic=true&yOpts=1000000%2C100000000000&caption=%2A%2ATree%20representing%20the%20target%20list%20of%20Canada%20Biogenome%20Project.%2A%2A%20Orange%20highlights%20represent%20clades%20with%20at%20least%20one%20genome%20already%20available%20under%20the%20Bioproject%20ID%20PRJNA813333.%20Species%20with%20assemblies%20generated%20by%20the%20project%20are%20highlighted%20in%20green%3B%20red%20highlights%20represent%20species%20without%20assemblies%20on%20INSDC%3B%20target%20species%20with%20assemblies%20available%20under%20other%20bioproject%20IDs%20are%20shown%20in%20grey.%20Bars%20correspond%20to%20assembly%20span%20values%20for%20each%20species.%20Colours%20of%20bars%20correspond%20to%20ancestrally-derived%20%28red%29%20or%20descendant-derived%20%28orange%29%20estimates%20and%20direct%20%28green%20or%20grey%29.%20Tap%20tree%20nodes%20to%20browse%20taxa%20or%20long-press%20to%20search.&treeThreshold=2000&query=long_list%3Dcanbp%20AND%20tax_rank%28species%29&fields=c_value%2Cgenome_size%2Cgenome_size_kmer%2Cgenome_size_draft%2Cassembly_level%2Cassembly_span%2Cbioproject%2Cbusco_completeness%2Cgc_percent%2Cchromosome_number%2Chaploid_number%2Clong_list%2Cother_priority%2Cfamily_representative%2Ccontributing_project_lab&report=tree&y=assembly_span%20AND%20bioproject%3DPRJNA813333&summaryValues=count&size=100&offset=0&names=&ranks=&sortBy=scientific_name&sortOrder=asc#long_list%3Dcanbp%20AND%20tax_rank(species)) on CANBP and trees on other project pages.

Temporary measure:
use` bioproject AND` or `long_list AND` at the start of query, as [shown here](https://goat.genomehubs.org/search?result=taxon&taxonomy=ncbi&includeEstimates=true&treeStyle=rect&levels=%2Csubspecies%2Cspecies%2Cgenus%2Cfamily%2Corder%2Cclass%2Cphylum&collapseMonotypic=true&yOpts=1000000%2C100000000000&caption=%2A%2ATree%20representing%20the%20target%20list%20of%20Canada%20Biogenome%20Project.%2A%2A%20Orange%20highlights%20represent%20clades%20with%20at%20least%20one%20genome%20already%20available%20under%20the%20Bioproject%20ID%20PRJNA813333.%20Species%20with%20assemblies%20generated%20by%20the%20project%20are%20highlighted%20in%20green%3B%20red%20highlights%20represent%20species%20without%20assemblies%20on%20INSDC%3B%20target%20species%20with%20assemblies%20available%20under%20other%20bioproject%20IDs%20are%20shown%20in%20grey.%20Bars%20correspond%20to%20assembly%20span%20values%20for%20each%20species.%20Colours%20of%20bars%20correspond%20to%20ancestrally-derived%20%28red%29%20or%20descendant-derived%20%28orange%29%20estimates%20and%20direct%20%28green%20or%20grey%29.%20Tap%20tree%20nodes%20to%20browse%20taxa%20or%20long-press%20to%20search.&treeThreshold=2000&query=long_list%20AND%20long_list%3Dcanbp%20AND%20tax_rank%28species%29&fields=c_value%2Cgenome_size%2Cgenome_size_kmer%2Cgenome_size_draft%2Cassembly_level%2Cassembly_span%2Cbioproject%2Cbusco_completeness%2Cgc_percent%2Cchromosome_number%2Chaploid_number%2Clong_list%2Cother_priority%2Cfamily_representative%2Ccontributing_project_lab&report=tree&y=assembly_span%20AND%20bioproject%3DPRJNA813333&summaryValues=count&size=100&offset=0&names=&ranks=&sortBy=scientific_name&sortOrder=asc#long_list%20AND%20long_list%3Dcanbp%20AND%20tax_rank(species)).",ccaio,https://github.com/genomehubs/genomehubs/issues/261,genomehubs++genomehubs.csv
I_kwDOBMYwiM5il-CG,Inconsistent behaviour of pop-ups,CLOSED,2023-04-04T15:32:04Z,2023-04-05T08:08:20Z,2023-04-05T08:08:20Z,"From a search [like this](https://goat.genomehubs.org/search?query=tax_tree%28phyllostomidae%29%20AND%20tax_rank%28species%29&result=taxon&includeEstimates=true&summaryValues=count&taxonomy=ncbi&size=100#tax_tree(phyllostomidae)%20AND%20tax_rank(species)), clicking on values will generate a pop-up with the row of records for that attribute.

After using the icon to show/hide subset columns, the [pop up](https://goat.genomehubs.org/search?query=tax_tree%28phyllostomidae%29%20AND%20tax_rank%28species%29&result=taxon&includeEstimates=true&summaryValues=count&taxonomy=ncbi&size=100&offset=0&fields=haploid_number%2Chaploid_number%3Adirect%2Chaploid_number%3Aancestor%2Chaploid_number%3Adescendant#tax_tree(phyllostomidae)%20AND%20tax_rank(species)) changes to the box where subset values can be selected.

After subsets have been selected once, there is no consistency of which pop-up box will appear. For example, the subset selection pop-up will sometimes appear when I do the following steps:
1. query only tax_tree,  
2. select haploid_number subset 
3. go back on the page to original search, 
4. click to see the records for a genome size entry (see pic)
<img width=""1257"" alt=""Screenshot 2023-04-04 at 16 01 05"" src=""https://user-images.githubusercontent.com/13206220/229842485-47d4724f-2269-4f82-9f29-de93b1278be1.png"">


Going back to previous search does not solve the problem, but copying the original search link and opening on a new tab seems to solve it.

",ccaio,https://github.com/genomehubs/genomehubs/issues/264,genomehubs++genomehubs.csv
I_kwDOBMYwiM5iqu67,Add a multi search endpoint,OPEN,2023-04-05T10:37:33Z,2023-04-05T10:38:07Z,,"Current multiline search combines all entries into a single search with OR so there is no way to know which rows have a match and which don't.

Need to support true multi search and return at least one row per query for questions such as which of these taxa have data have been collected, e.g. this set of 10 names only returns 9 rows:
```
Acanthocardia echinata
Acanthochitona crinita
Acanthochitona facicularis
Acrocnida brachiata
Actinia equina
Actinia fragacea
Actinia prasina
Adalaria proxima
Aeolidia papillosa
Aequipecten opercularis
```

Missing result for `acanthochitona facicularis` likely due to spelling, but that is not checked in existing search - need to add spellcheck to multi search if no results",rjchallis,https://github.com/genomehubs/genomehubs/issues/267,genomehubs++genomehubs.csv
I_kwDOBMYwiM5jFevs,selecting alternate column summaries makes default columns disappear,CLOSED,2023-04-11T12:32:31Z,2023-05-23T15:27:34Z,2023-05-23T15:27:34Z,"Selecting, e.g., min and max to display for one of the default columns causes other default columns to disappear as they are only shown when the field list is empty.

Need to use default list when adding summary values to an empty field list",rjchallis,https://github.com/genomehubs/genomehubs/issues/268,genomehubs++genomehubs.csv
I_kwDOBMYwiM5jFfxX,Upgrade to ElasticSearch 8.6,CLOSED,2023-04-11T12:35:33Z,2023-06-12T10:04:27Z,2023-06-12T10:04:27Z,"Genomehubs currently running on v7.10-oss, but need to use flattened datatype (not in OSS release) to be able to add different types of ancestral unit without mapping explosion. Should also be useful for reducing number of attributes associated with sequencing status.",rjchallis,https://github.com/genomehubs/genomehubs/issues/269,genomehubs++genomehubs.csv
I_kwDOBMYwiM5jF5C4,import prokaryotes,OPEN,2023-04-11T13:28:46Z,2023-09-19T13:43:05Z,,,rjchallis,https://github.com/genomehubs/genomehubs/issues/270,genomehubs++genomehubs.csv
I_kwDOBMYwiM5kV38Y,Histograms with dates not expanding,CLOSED,2023-04-25T16:02:29Z,2023-08-04T08:18:14Z,2023-08-04T08:18:14Z,Histograms based on min(assembly_date) or max(assembly_date) do not expand to search - [example 1](https://goat.genomehubs.org/projects/EBP);Those that don't need min(assembly_date) are expanding fine - [example 2](https://goat.genomehubs.org/report?report=histogram&x=assembly_date&rank=species&cat=assembly_level&stacked=true&includeEstimates=true&excludeAncestral%5B0%5D=assembly_span&excludeMissing%5B0%5D=assembly_span&caption=Progress%20of%20genome%20assemblies%20published%20on%20INSDC%20over%20time%2C%20by%20assembly%20level&taxonomy=ncbi&result=taxon).,ccaio,https://github.com/genomehubs/genomehubs/issues/271,genomehubs++genomehubs.csv
I_kwDOBMYwiM5pdWT-,Tree report ignoring `includeEstimates`,CLOSED,2023-06-22T09:31:39Z,2023-08-04T08:18:13Z,2023-08-04T08:18:13Z,"Trees with no fields show all taxa regardless of `includeEstimates` toggle, e.g. https://goat.genomehubs.org/search?query=tax_tree%289608%5BCanidae%5D%29&result=taxon&summaryValues=count&taxonomy=ncbi&report=tree&treeStyle=rect&treeThreshold=2000&pointSize=15&offset=0&fields=assembly_level%2Cassembly_span%2Cbusco_completeness%2Cgc_percent%2Cc_value%2Cgenome_size%2Cgenome_size_kmer%2Cchromosome_number%2Chaploid_number&names=&ranks=&includeEstimates=false#tax_tree(9608[Canidae])",rjchallis,https://github.com/genomehubs/genomehubs/issues/277,genomehubs++genomehubs.csv
I_kwDOBMYwiM5qivVH,"Unable to retrieve TSV data after sorting columns: ""message"":""response should NOT have a body""",CLOSED,2023-07-04T09:03:27Z,2023-09-15T09:36:01Z,2023-09-15T09:36:01Z," Filtering and sorting data from query sometimes generate a TSV with no data and the following message:

{""message"":""response should NOT have a body"",""errors"":[{""path"":""/response"",""message"":""response should NOT have a body""}]}
Example l[ink 1](https://goat.genomehubs.org/search?result=taxon&includeEstimates=true&summaryValues=count&taxonomy=ncbi&offset=0&query=tax_tree%287088%5BLepidoptera%5D%29%20AND%20long_list%3D%3Ddtol&fields=c_value%2Csample_collected%2Cchromosome_number%2Chaploid_number%2Clong_list&names=&ranks=&excludeDescendant%5B0%5D=long_list&excludeDirect%5B0%5D=sample_collected&size=50&sortBy=scientific_name&sortOrder=asc#tax_tree(7088%5BLepidoptera%5D)%20AND%20long_list%3D%3Ddtol).

A way around it is to remove the sorting from the query [link](https://goat.genomehubs.org/search?result=taxon&includeEstimates=true&summaryValues=count&taxonomy=ncbi&offset=0&query=tax_tree%287088%5BLepidoptera%5D%29%20AND%20long_list%3D%3Ddtol&fields=c_value%2Csample_collected%2Cchromosome_number%2Chaploid_number%2Clong_list&names=&ranks=&excludeDescendant%5B0%5D=long_list&excludeDirect%5B0%5D=sample_collected&size=50&tax_tree(7088%5BLepidoptera%5D)%20AND%20long_list%3D%3Ddtol).

",ccaio,https://github.com/genomehubs/genomehubs/issues/281,genomehubs++genomehubs.csv
I_kwDOBMYwiM5rUvQs,tree not matching table data,CLOSED,2023-07-12T09:47:37Z,2023-08-04T08:18:14Z,2023-08-04T08:18:14Z,"trees sometimes contain more tips than the result table, e.g. https://goat-dev.genomehubs.org/search?result=taxon&summaryValues=count&taxonomy=ncbi&size=50&sortBy=sequencing_status_asg&offset=0&sortOrder=asc&fields=assembly_level%2Cassembly_span%2Cchromosome_count%2Ccontig_count%2Cscaffold_count%2Cbusco_completeness%2Cgc_percent%2Cc_value%2Cgenome_size%2Cgenome_size_kmer%2Cgenome_size_draft%2Csequencing_status_asg%2Csequencing_status_dtol%2Cchromosome_number%2Chaploid_number&names=&ranks=&report=tree&treeStyle=rect&treeThreshold=2000&pointSize=15&query=tax_tree%28cnidaria%29%20AND%20tax_rank%28species%29%20AND%20assembly_level%3D%3Dchromosome&includeEstimates=false&collapseMonotypic=true&y=assembly_level#tax_tree(cnidaria)%20AND%20tax_rank(species)%20AND%20assembly_level==chromosome",rjchallis,https://github.com/genomehubs/genomehubs/issues/282,genomehubs++genomehubs.csv
I_kwDOBMYwiM5rdNCy,UI result columns selection,CLOSED,2023-07-13T11:28:58Z,2023-09-12T10:16:31Z,2023-09-12T10:16:31Z,"Unselecting all needs usability improvement.

Often users are interested either on genome/assembly metadata _or_ target lists and status. In cases where switching between  them happens often, unselecting becomes an important feature.

Currently the selection box opens scrolled to the bottom, so we could improve how we unselect columns for display to avoid scrolling up and down with every search.",ccaio,https://github.com/genomehubs/genomehubs/issues/284,genomehubs++genomehubs.csv
I_kwDOBMYwiM5rdN5U,Allow selecting palettes with buttons,CLOSED,2023-07-13T11:31:13Z,2023-08-04T08:18:15Z,2023-08-04T08:18:15Z,For more colourful UI and reports,ccaio,https://github.com/genomehubs/genomehubs/issues/285,genomehubs++genomehubs.csv
I_kwDOBMYwiM5vEf3v,Reports for use cases not appearing,CLOSED,2023-08-23T14:20:25Z,2023-09-12T10:16:32Z,2023-09-12T10:16:32Z,"Reports of use cases 5, 10, 11 and 12 stopped appearing on https://goat.genomehubs.org/help.

Removing xOpts restore some. However not all reports have xOpts.

`success: false, error: ""unexpected error at 8/23/2023, 2:03:19 PM`",ccaio,https://github.com/genomehubs/genomehubs/issues/294,genomehubs++genomehubs.csv
I_kwDOBMYwiM5wAEQg,"Allow cat: ""sequencing_status_{{project}}""",CLOSED,2023-09-03T11:49:16Z,2023-09-06T17:29:18Z,2023-09-06T17:29:18Z,"I am trying to create histogram templates for sequencing status reports (see DToL project page for [working example](https://goat.genomehubs.org/report?report=histogram&x=long_list%3DDTOL%20AND%20sequencing_status_dtol&rank=species&result=taxon&cat=sequencing_status_dtol%3Dsample_collected%2Csample_acquired%2Cin_progress%2Cinsdc_open&excludeAncestral%5B0%5D=long_list&excludeMissing%5B0%5D=long_list&xOpts=%2C%2C1%2C%2CSequencing%20Status&caption=Current%20sequencing%20status%20of%20DToL%20targets&taxonomy=ncbi)).

It looks like `cat` cannot recognise `{{project}}` placeholder inside `sequencing_status_{{project}}`.

While histo with cat above can't load, the code below returns a histo, but not with the correct counts for the projects:

```report
report: histogram
x: ""long_list={{project}} AND sequencing_status_{{project}}""
y: ""sequencing_status_{{project}}""
rank: species
cat: ""sequencing_status=sample_collected,sample_acquired,in_progress,open,insdc_open""
includeEstimates: false
excludeAncestral: sequencing_status_{{project}}
excludeMissing: sequencing_status_{{project}}
xOpts: "",,1,,Sequencing Status""
caption: ""Current status of {{project}} target species""
item: true
xs: 4
```
",ccaio,https://github.com/genomehubs/genomehubs/issues/296,genomehubs++genomehubs.csv
I_kwDOBMYwiM5wxqql,Missing summary plots,CLOSED,2023-09-12T09:22:45Z,2023-09-12T10:16:32Z,2023-09-12T10:16:32Z,"When clicking click to view summary plot on e.g. https://goat.genomehubs.org/explore?taxon_id=1226587&result=taxon&taxonomy=ncbi&field_id=assembly_span only grey boxes appear, not plots.",kerstinhowe,https://github.com/genomehubs/genomehubs/issues/298,genomehubs++genomehubs.csv
I_kwDOBMYwiM5xb_w5,Switching rainbow plots inside out,OPEN,2023-09-19T14:48:54Z,2023-09-19T15:40:48Z,,Please switch the taxonomy rainbow plots around to show phylum in the centre and species on the outer ring.,kerstinhowe,https://github.com/genomehubs/genomehubs/issues/302,genomehubs++genomehubs.csv
I_kwDOBMYwiM5xcbfr,showing tolids in a better way,OPEN,2023-09-19T15:48:47Z,2023-09-19T15:48:47Z,,"Species/assembly pages currently show tolid prefixes twice, once as tolid_prefix and once as tol_id. Both link to the gitlab page with the raw data.

I suggest to drop tol_id as it's a duplication and link tolid_prefix to the more helpful id.tol.sanger.ac.uk, not the gitlab page.",kerstinhowe,https://github.com/genomehubs/genomehubs/issues/303,genomehubs++genomehubs.csv
I_kwDOBMYwiM50v24G,Add ribbon plots to UI for BoaT,CLOSED,2023-10-24T07:50:57Z,2024-11-19T10:38:19Z,2024-11-19T10:38:19Z,"Ribbon plots would be a complement to Oxford plots for displaying synteny and could be generated in the UI based on the data returned by 'report=oxford` in the API, or a slightly modified form.",rjchallis,https://github.com/genomehubs/genomehubs/issues/307,genomehubs++genomehubs.csv
I_kwDOBMYwiM55Q3Hu,Newick error,CLOSED,2023-12-10T17:33:32Z,2023-12-11T20:12:13Z,2023-12-11T20:12:13Z,"Can't work out what's wrong with this query:

https://goat.genomehubs.org/api/v2/report?result=taxon&report=tree&x=tax_rank%28genus%29%20AND%20tax_tree%28Orobanchaceae%29&includeEstimates=true&taxonomy=ncbi&queryId=goat_cli_U2vILcHe4peH3XQ

It comes back with a 'number_format_exception'? But I don't know what that refers too. ",Euphrasiologist,https://github.com/genomehubs/genomehubs/issues/310,genomehubs++genomehubs.csv
I_kwDOBMYwiM55Q60y,Unhelpful error in report table API,OPEN,2023-12-10T18:17:40Z,2023-12-11T08:34:02Z,,"https://goat.genomehubs.org/api/v2/report?result=taxon&includeEstimates=false&taxonomy=ncbi&report=table&rank=species&x=tax_tree%28Orobanchaceae%29%20AND%20assembly_span&cat=assembly_span%5B10%5D

Has an unhelpful error I can't debug!",Euphrasiologist,https://github.com/genomehubs/genomehubs/issues/311,genomehubs++genomehubs.csv
I_kwDOBMYwiM55vHEm,Allow single report to compare attribute subsets,OPEN,2023-12-14T20:02:21Z,2023-12-15T09:26:02Z,,"I've been asked if it was possible to create reports that would show the number of species collected out of the total number of targets for many taxa at once. They would like to display bars for each taxon side by side, instead of having the taxon names as categories.

I was not able to get there with available types of reports.
- The best I came up with then was to generate [2 histograms side by side](https://docs.google.com/document/d/1fEZAnvzAWA8jcHkTT5uTsSkKXQ7wrj941npGKYpRuQU/edit) to compare the data.

**Is it possible to create a single report to compare across a taxonomic level?** 
-how many out of a projects target list have reach a specific status?

In my head it would work somewhat like:
- pick a tax_tree (e.g. Chiroptera)
- set the xField to a particular category like tax_rank (e.g. Families - in the case of Chiroptera will have around 20 bins)
- set the max Y as the count of one attribute (e.g. long_list=dtol and tax_rank(species)
- set the real Y as the nested attribute (e.g. sample_acquired=dtol and tax_rank(species))
- (these last 2 would appear as a xInY report, but displayed as a single bar

Some suggestions: from the users also included:
- an arc report that would report xPerTaxon instead of xPerRank
- The total would be normalised to % to allow a rainbow plot regardless of total",ccaio,https://github.com/genomehubs/genomehubs/issues/312,genomehubs++genomehubs.csv
I_kwDOBMYwiM58Yj3o,outlinks to UCSC genome browser,OPEN,2024-01-17T19:12:08Z,2024-01-17T19:12:08Z,,"I've mentioned this feature before to different GoaT contacts, but wanted to renew this request.

There is a text tab separated file you could use for this function:

  https://hgdownload.soe.ucsc.edu/hubs/UCSC_GI.assemblyHubList.txt

This file continuously updates as new assemblies are added to this system.
Pick up the file periodically to create these outlinks.

Using the first column, the GCx (x == [AF]) accession name, an out link to the UCSC
geonome browser can be constructed, e.g. GCx_012345678.9 as:

   https://genome.ucsc.edu/h/GCx_012345678.9

Please feel free to contact me for clarification:  hclawson at ucsc dot edu

--Hiram Clawson",NullModel,https://github.com/genomehubs/genomehubs/issues/314,genomehubs++genomehubs.csv
I_kwDOBMYwiM6BnvrD,Saved queries go to blank page,CLOSED,2024-03-07T19:59:32Z,2024-03-08T09:16:28Z,2024-03-08T09:16:28Z,"Hi, I have a number of bookmarked queries, but when I try to open them, I see the query box briefly and then a blank browser window. These have worked in the past, and I can still get to the standard GoaT pages through the main page and links (https://goat.genomehubs.org/). I've tried the saved query links in two browsers (Safari and Chrome), and two computers (Macbook Pro and Windows), with the same results. 

Some of the saved queries:
https://goat.genomehubs.org/search?query=assembly_span%20AND%20tax_tree%289721%29%20AND%20tax_rank%28species%29&result=taxon&includeEstimates=false&fields=assembly_level%2Cscaffold_n50%2Cebp_metric_date%2Cbioproject%2Csequencing_status&summaryValues=count&taxonomy=ncbi&report=tree&offset=0&names=common_name&ranks=&y=scaffold_n50&rank=species&plotRatio=auto&pointSize=10&size=100&xField=assembly_span&treeStyle=rect&treeThreshold=2000#assembly_span%20AND%20tax_tree(9721)%20AND%20tax_rank(species)

https://goat.genomehubs.org/search?query=tax_tree%289721%29%20AND%20tax_rank%28species%29%20AND%20scaffold_n50%3E%3D100000000%20AND%20assembly_level%20AND%20sequencing_status%20AND%20ebp_standard_date%3E%3D2019-01-01&result=taxon&includeEstimates=false&summaryValues=count&taxonomy=ncbi&offset=0&fields=ebp_standard_date%2Cassembly_level%2Cscaffold_n50%2Cbusco_completeness%2Cchromosome_number%2Csequencing_status&names=common_name&ranks=&size=25&sortBy=scientific_name&sortOrder=asc#tax_tree(9721)%20AND%20tax_rank(species)%20AND%20scaffold_n50%3E%3D100000000%20AND%20assembly_level%20AND%20sequencing_status%20AND%20ebp_standard_date%3E%3D2019-01-01

https://goat.genomehubs.org/search?result=taxon&includeEstimates=false&fields=assembly_level%2Cscaffold_n50%2Cebp_metric_date%2Cbioproject%2Csequencing_status&summaryValues=count&taxonomy=ncbi&report=tree&offset=0&names=common_name&ranks=&y=scaffold_n50&rank=species&plotRatio=auto&pointSize=15&sortBy=scientific_name&query=tax_tree%289721%29%20AND%20tax_rank%28species%29%20AND%20scaffold_n50%20AND%20assembly_level%3D%3Dchromosome%20AND%20sequencing_status&size=25&sortOrder=asc#tax_tree(9721)%20AND%20tax_rank(species)%20AND%20scaffold_n50%20AND%20assembly_level%3D%3Dchromosome%20AND%20sequencing_status

https://goat.genomehubs.org/search?query=assembly_span%20AND%20tax_tree%289721%29%20AND%20tax_rank%28species%29&result=taxon&includeEstimates=false&fields=mitochondrion_assembly_span%2Cscaffold_n50%2Ccontig_n50%2Cebp_metric_date%2Clong_list%2Csequencing_status_canbp%2Csequencing_status_cgp%2Csequencing_status_dtol%2Csequencing_status_vgp&summaryValues=count&taxonomy=ncbi&report=tree&offset=0&names=common_name&ranks=&y=scaffold_n50&rank=species&plotRatio=auto&pointSize=10&size=100&xField=assembly_span&treeStyle=rect&treeThreshold=2000&sortBy=scientific_name&sortOrder=asc#assembly_span%20AND%20tax_tree(9721)%20AND%20tax_rank(species)",PAMorin,https://github.com/genomehubs/genomehubs/issues/318,genomehubs++genomehubs.csv
I_kwDOBMYwiM6JGP9W,Allow download of large query result files ,OPEN,2024-05-16T11:15:24Z,2024-05-16T11:15:24Z,,"Downloading any file type from larger queries on UI returns a file with a error message from Sanger Servers (see image).

It would be good to still allow large data downloads for UI users that are not familiar with the API and CLI.

![Screenshot 2024-05-16 at 12 11 15](https://github.com/genomehubs/genomehubs/assets/13206220/2a161205-63f2-47bd-9c69-07efa36ff569)",ccaio,https://github.com/genomehubs/genomehubs/issues/320,genomehubs++genomehubs.csv
I_kwDOBMYwiM6LDw78,Add support for creating and modifying lists,OPEN,2024-06-04T09:25:07Z,2024-08-27T13:29:06Z,,"Saving search results and subsets of results as lists will be essential for integrating analyses such as KinFin. 

Will need integration with table and report views to create lists from all results, filtered subsets, categories, etc. Need to be able to select/deselect records from table and/or tree using checkboxes.

List retrieval should be based on taxon/assembly IDs with option to update to latest results for equivalent search.",rjchallis,https://github.com/genomehubs/genomehubs/issues/321,genomehubs++genomehubs.csv
I_kwDOBMYwiM6cbkOY,Repeat content display,OPEN,2024-10-30T15:25:16Z,2024-10-30T15:25:16Z,,It would be great if GoaT could report repeat content -- where accessible. Thanks!,kerstinhowe,https://github.com/genomehubs/genomehubs/issues/342,genomehubs++genomehubs.csv
I_kwDOBMYwiM6fdjEq,Add a skip-validation flag to genomehubs import,OPEN,2024-11-20T10:22:24Z,2024-11-20T10:32:40Z,,,rjchallis,https://github.com/genomehubs/genomehubs/issues/346,genomehubs++genomehubs.csv
I_kwDOBMYwiM6gmqsK,Handle other names from ENA taxonomy JSONL,OPEN,2024-11-26T12:24:34Z,2024-11-26T12:25:02Z,,`genomehubs init` needs to be able to load `otherNames` from ENA JSONL to import `authority` and any additional names,rjchallis,https://github.com/genomehubs/genomehubs/issues/347,genomehubs++genomehubs.csv
I_kwDOFoRbJM5jERA7,cafetutorial_report_analysis.py,CLOSED,2023-04-11T09:07:05Z,2023-05-09T12:40:56Z,2023-05-09T12:40:56Z,"
cafetutorial_report_analysis.py193175
ValueError: invalid literal for int() with base 10: '_0'
cafe'_0'1_0'_0'
ValueError: invalid literal for int() with base 10: ''
",zhouyu98,https://github.com/Github-Yilei/genome-assembly/issues/1,Github-Yilei++genome-assembly.csv
I_kwDODa8avc5KgHkW,"2, Digital Normalisation",CLOSED,2022-05-26T18:59:43Z,2024-01-12T14:32:24Z,2024-01-12T14:32:24Z,This section is missing!!! D'oh.,guyleonard,https://github.com/guyleonard/genomics_adventure/issues/2,guyleonard++genomics_adventure.csv
I_kwDODa8avc5KgNBS,chapter 2 task 10,CLOSED,2022-05-26T19:24:01Z,2023-05-13T09:54:40Z,2023-05-13T09:54:40Z,tutorial should be workhsop,guyleonard,https://github.com/guyleonard/genomics_adventure/issues/3,guyleonard++genomics_adventure.csv
I_kwDODa8avc578m-M,X11 Port Forwarding on Mac and Windows,OPEN,2024-01-12T18:48:40Z,2024-01-12T20:48:18Z,,"It doesn't work.

It used to on Macs.

Sigh",guyleonard,https://github.com/guyleonard/genomics_adventure/issues/6,guyleonard++genomics_adventure.csv
I_kwDODa8avc579Z3R,"Chapter 2, task 13",OPEN,2024-01-12T20:49:04Z,2024-01-12T20:49:04Z,,"Hello! 

I could not find the following regions in the assembly:
U00096.3:2,108,392-2,133,153
U00096.3:3,662,049-3,663,291
U00096.3:4,296,249-4,296,510
U00096.3:565,965-566,489

I think they do not match any e. coli chr ID",mylena-s,https://github.com/guyleonard/genomics_adventure/issues/7,guyleonard++genomics_adventure.csv
I_kwDODa8avc58hAxI,Measurement,OPEN,2024-01-18T20:50:24Z,2024-01-18T20:50:25Z,,Measure how far students get through the chapters by submission to tally numbers and engagement. ,guyleonard,https://github.com/guyleonard/genomics_adventure/issues/8,guyleonard++genomics_adventure.csv
I_kwDODa8avc5_xwkl,Help! Stuck with ssh -Y ip_address,OPEN,2024-02-20T07:57:01Z,2024-02-21T16:52:40Z,,"Hi,

This is not an issue but a comment asking for help.

I want to practice and learn through this genomics adventure course. I am new to command-line and Linux. I am using windows wsl.
I am currently stuck with ""ssh -Y ip_address"". Could you guide me on how to log in and access course files?

Thank you.",SlowSD,https://github.com/guyleonard/genomics_adventure/issues/9,guyleonard++genomics_adventure.csv
I_kwDOD90Dms6LBt5G,Reorganize files,OPEN,2024-06-04T03:53:32Z,2024-06-04T03:53:32Z,,"Since we have a Jupyter notebook version, we could move some of the older content into a separate space.  ",cjfields,https://github.com/HPCBio/Mayo-Genome-Assembly/issues/1,HPCBio++Mayo-Genome-Assembly.csv
I_kwDOD90Dms6LBuMa,Test other assemblers,OPEN,2024-06-04T03:55:01Z,2024-06-04T03:55:02Z,,"Though hifiasm works, it may not be the best assembler for bacterial assemblies.  We should test flye or possibly Canu as an alternative, though Canu doesn't generate the nice GFA files.  ",cjfields,https://github.com/HPCBio/Mayo-Genome-Assembly/issues/2,HPCBio++Mayo-Genome-Assembly.csv
I_kwDOB8l18s6OjORl,mira error: C++,OPEN,2024-07-05T01:02:56Z,2024-07-05T01:02:56Z,,"Hey Ian, 

I found an error and a workaround. 

On some machines the pre-compiled library of mira throws an error in the log file:

```
==============
 ITERATION 1
==============
Jul  5 09:38:54


quick option baits reads from provided reference in iteration 0

fishing readpool using mirabait (k = 31)

mirabait: loadlocale.c:130: _nl_intern_locale_data: Assertion `cnt < (sizeof (_nl_value_type_LC_TIME) / sizeof (_nl_value_type_LC_TIME[0]))' failed.

your readpool does not contain any reads with reasonable match (k = 31) to your reference - Maybe you ll want to try different settings or even a different reference?

```

I investigated further and it seems like this is a known bug reported on the mira sourceforge page [here](https://sourceforge.net/p/mira-assembler/tickets/40/). [Bastien Chevreux](https://sourceforge.net/u/bach/profile/) the author of MIRA wrote 

```
A bug of the C++ libraries which I learned to circumvent in later versions of MIRA. Should you insist on using 4.0.2, the workaround is:
export LC_ALL=C
in the shell, then it will work.
```

For the time being, I recommend modifying `mtGenome_Assembly_Nick.R`:

```
final.call <- paste(change.to.directory, "";"", ""export LC_ALL=C"", "";"", mitobim.call)
      system(final.call)
```",stiatragul,https://github.com/IanGBrennan/mitoGenome_Assembly/issues/1,IanGBrennan++mitoGenome_Assembly.csv
I_kwDODhic1c5VUlmO,Gene annotattion file,OPEN,2022-11-01T13:46:55Z,2022-11-01T13:46:55Z,,"I downloaded two genome files from NCBI, but I couldn't find gene annotation files (GFF). Could you please provide the download link?",zhanglingkui,https://github.com/icruz1989/Datura-stramonium-genome-project/issues/2,icruz1989++Datura-stramonium-genome-project.csv
I_kwDOGIq7I848SPab,Flow cytometry reference ,CLOSED,2021-09-29T20:29:04Z,2021-09-30T21:39:19Z,2021-09-30T21:39:19Z,"Need to get the doi number for (Pellicer & Leitch, 2014)",maa146,https://github.com/IGBB/rohu-genome/issues/1,IGBB++rohu-genome.csv
I_kwDOGIq7I848STOr,Check author info,CLOSED,2021-09-29T20:49:55Z,2023-08-14T19:38:50Z,2023-08-14T19:38:50Z,"- [x] Mark A Arick II 
- [ ] Chuan-Yu Hsu 
- [ ] Zenaida Magbanua 
- [x] Corrinne E Grover 
- [ ] Emma Miller 
- [ ] Olga Pechanova 
- [x] Adam Thrash 
- [ ] Ramey C Youngblood 
- [ ] Lauren Ezzell  
- [ ] Samsul Alam 
- [ ] John Benzie 
- [ ] Matthew Hamilton 
- [ ] Attila Karsi 
- [ ] Mark L Lawrence 
- [ ] Daniel G Peterson ",maa146,https://github.com/IGBB/rohu-genome/issues/2,IGBB++rohu-genome.csv
I_kwDOGIq7I848ZsQz,Refactor nanopore trimming,CLOSED,2021-10-01T13:45:13Z,2021-10-01T19:48:07Z,2021-10-01T19:48:07Z,Move nanopore trimming code from raw/readme.org to trim/readme.org. ,maa146,https://github.com/IGBB/rohu-genome/issues/4,IGBB++rohu-genome.csv
I_kwDOGIq7I848lfi_,Add affiliation list in manuscript,CLOSED,2021-10-05T15:21:28Z,2023-08-14T19:38:44Z,2023-08-14T19:38:44Z,,maa146,https://github.com/IGBB/rohu-genome/issues/5,IGBB++rohu-genome.csv
I_kwDOGIq7I849nrEg,compare with published rohu,CLOSED,2021-10-22T17:35:46Z,2022-04-06T14:33:50Z,2022-04-06T14:33:50Z,"- [x] dotplot
- [x] genome busco
- [ ] transcriptome busco
- [x] assembly stats",maa146,https://github.com/IGBB/rohu-genome/issues/6,IGBB++rohu-genome.csv
I_kwDOHHdO6s51R61V,Juicer input file,OPEN,2023-10-30T06:51:47Z,2023-10-30T06:51:47Z,,"Hello, I have a question. Should the input file for Juicer be the merged file of hap1.fa/hap2.fa or the merged file of hap1.ragtag.fa/hap1.ragtag.fa after RagTag? Because according to your diagram, it seems that RagTag should be used first.",ErickTong,https://github.com/Immortal2333/Haplotype_Genome_Assembly/issues/1,Immortal2333++Haplotype_Genome_Assembly.csv
I_kwDOHHdO6s6HJn2E,output of step 4,OPEN,2024-04-28T09:11:12Z,2024-04-28T09:11:12Z,,"Dear author,
Thanks for writing the useful assembly pipline. Recently, I used this pipline to performed a haplotype genome assembly. However,  I met a problem in step 4 3d-dna. when I performed run-assembly-visualizer.sh with hap0.assembly and merged_nodups.txt, there is no _final.assembly output, but only output hap0.0.hic file. Meanwhile, two other files of 'hap0_asm.superscaf_track.txt' and 'hap0_asm.scaffold_track.txt' have been outputted. The log file was attached. 
![](https://github.com/Immortal2333/Haplotype_Genome_Assembly/assets/49520396/99b0fd42-09be-48b5-a2bd-a9e82315fb23)

Could you give some advices? Thank you for your assistance.",tzjingyang,https://github.com/Immortal2333/Haplotype_Genome_Assembly/issues/2,Immortal2333++Haplotype_Genome_Assembly.csv
I_kwDOFpcvm85LYoXO,ABRicate table gets only first sample of batch,OPEN,2022-06-08T13:24:40Z,2022-06-08T13:24:40Z,,,domenico-simone,https://github.com/IZSPB-molbio/genome_assembly_pipeline/issues/1,IZSPB-molbio++genome_assembly_pipeline.csv
I_kwDOFpcvm85Ssjfz,Analyses to add,OPEN,2022-09-27T09:15:06Z,2022-09-28T15:07:52Z,,"rMLST
~~CheckM~~",domenico-simone,https://github.com/IZSPB-molbio/genome_assembly_pipeline/issues/2,IZSPB-molbio++genome_assembly_pipeline.csv
I_kwDOFpcvm85V1qS5,Failed analyses for single simples make collating fail,OPEN,2022-11-08T12:46:00Z,2022-11-08T13:00:49Z,,,domenico-simone,https://github.com/IZSPB-molbio/genome_assembly_pipeline/issues/3,IZSPB-molbio++genome_assembly_pipeline.csv
I_kwDOFpcvm85V8aK3,Test FastMLST,OPEN,2022-11-09T11:11:33Z,2022-11-09T11:11:33Z,,https://github.com/EnzoAndree/FastMLST ,domenico-simone,https://github.com/IZSPB-molbio/genome_assembly_pipeline/issues/4,IZSPB-molbio++genome_assembly_pipeline.csv
MDU6SXNzdWU3MjU1NzEzMDk=,"Describir que reads utilizas (Ilumina, nanopore)",OPEN,2020-10-20T13:10:26Z,2020-10-20T13:11:30Z,,,VeronicaGlez,https://github.com/JavierUrban/Genome-assembly-of-the-copepod-Leptodiaptomus/issues/1,JavierUrban++Genome-assembly-of-the-copepod-Leptodiaptomus.csv
MDU6SXNzdWU3MzUwODMwMTA=,Difficulties to use databases running BLAST,CLOSED,2020-11-03T07:18:36Z,2020-11-25T00:16:38Z,2020-11-25T00:16:38Z,"Do you need to create databases or is there a better option?

I created a database for copepods:

```
makeblastdb -in ../blastpacope/genomas_copepods/ncbi_dataset/data/db_all_copepods.fna -dbtype nucl -parse_seqids -out my_refrence2.fa
```
But they weigh a lot and running the BLAST is very slow.

To run BLAST use: 

```
blastn -db my_refrence2.fa -query ../blastpacope/minion/minion_carmen.fa -out results_allgenomes_tab.out -outfmt ""6 sframe qseqid sseqid evalue pident mismatch"" 
```
The function `-outfmt ""6 <options>""` shows results in a tab separated table.  And although it's hard to see, the line of identity percentage in general it looks higher than 80%, so I think that maybe it is not so contaminated, however, I think it makes a BLAST with many databases it will take longer and be more difficult, so I would like to know if anyone knows a more easier way to run BLAST?

<img width=""587"" alt=""results_blast"" src=""https://user-images.githubusercontent.com/59941891/97955698-6b5f1900-1d6c-11eb-9e64-d33db3717250.png"">

Or if it will be a better option to start testing assemblers with different parameters? 
The first draft I have seems to be fragmented

<img width=""1058"" alt=""busco_quast"" src=""https://user-images.githubusercontent.com/59941891/97956356-0c020880-1d6e-11eb-97c7-52f2547ca614.png"">


",JavierUrban,https://github.com/JavierUrban/Genome-assembly-of-the-copepod-Leptodiaptomus/issues/3,JavierUrban++Genome-assembly-of-the-copepod-Leptodiaptomus.csv
MDU6SXNzdWU3Nzg2ODYxMzg=,denovo_map.pl: Aborted because the last command failed (Error: Unable to load data),OPEN,2021-01-05T07:44:54Z,2021-01-05T16:00:15Z,,"My problem is that I can't finish running **[denovo_map.pl.](https://catchenlab.life.illinois.edu/stacks/comp-v1/denovo_map.php)**

I am using stacks on my local computer from a docker container with the following script [stacks.denovo_map.prueba.sh](https://github.com/JavierUrban/Genome-assembly-of-the-copepod-Leptodiaptomus/blob/main/bin/stacks.denovo_map.prueba.sh)

**denovomap.pl** is a program that is used to construct loci and to call SNPs de novo, this is used when there is no reference genome.

I want to run `denovo_map.pl` to identify SNPs in 93 samples with 23 and 22 individuals from 4 populations, but before I wanted to perform a test with 3 individuals from each population but I could not finish the process for these samples the program starts to run, but when you with to continue the analysis of sample 2, the process stops and displays an aborted message: `denovo_map.pl: Aborted because the last command failed (1); see log file.`

I first ran [`process_radtags`](https://catchenlab.life.illinois.edu/stacks/comp/process_radtags.php), this is a program that checks the raw data from illumina and demultiplexes the samples for quality and cutoff sites of the restriction enzymes

I run the command as follows:

```
stacks process_radtags -P -p ../stacks/isuue2/GBS_raw/ --interleaved \
-b ../stacks/isuue2/barcodes_copes_iss.tsv -o ../stacks/isuue2/process_map_res/ \
-c -q -r --index_index --renz_1 mspI --renz_2 nsiI
```
The following image is an example of the raw data format and this is the [barcode file](https://github.com/JavierUrban/Genome-assembly-of-the-copepod-Leptodiaptomus/blob/main/meta-data/barcodes_copes_iss.tsv) that I use.

![image](https://user-images.githubusercontent.com/59941891/103620107-88dd6a00-4ef8-11eb-836f-50ab16631f2b.png)

The output of `process_radtags` generates 4 different files .1 and .2 which are used to run` denovo_map.pl`
![image](https://user-images.githubusercontent.com/59941891/103621066-4321a100-4efa-11eb-956d-566d0bf19499.png)

And then run `denovo_map.pl`:

```
stacks denovo_map.pl --samples ../stacks/isuue2/process_map_res/ \
--popmap ../stacks/isuue2/popmap_tarea_issue.tsv -o ../stacks/isuue2/denovo_map_re2 \
-M 3 -n 2 -m 3 -X ""populations: -r 0.50 --min_maf 0.01 --genepop""

```
Here is the [population map](https://github.com/JavierUrban/Genome-assembly-of-the-copepod-Leptodiaptomus/blob/main/meta-data/popmap_tarea_issue.tsv) file i use

And the following happens, showing the following message: **denovo_map.pl: Aborted because the last command failed (1); [see log file.](https://github.com/JavierUrban/Genome-assembly-of-the-copepod-Leptodiaptomus/blob/main/meta-data/denovo_map.log)**

![image](https://user-images.githubusercontent.com/59941891/103620007-5af82580-4ef8-11eb-85f9-cd080b45080c.png)

I tried looking for the error, and saw that it could be due to my computer's memory, but I also ran it on a cluster, and got the same error, I also saw that it could probably be due to the ID of the samples, but I tried to change them and they still do not finish the process, and I'm still confused because I don't know if I'm using some command or parameter wrong",JavierUrban,https://github.com/JavierUrban/Genome-assembly-of-the-copepod-Leptodiaptomus/issues/4,JavierUrban++Genome-assembly-of-the-copepod-Leptodiaptomus.csv
MDU6SXNzdWU3ODE0MTk0NjQ=,better explain metadata,OPEN,2021-01-07T16:00:12Z,2021-01-07T16:00:12Z,,"Your metadata directory should only contain metadata info, but currently it also has images and other files related to issues or examples of the class. Please clean this and have a separate directory for non metadata files.",AliciaMstt,https://github.com/JavierUrban/Genome-assembly-of-the-copepod-Leptodiaptomus/issues/5,JavierUrban++Genome-assembly-of-the-copepod-Leptodiaptomus.csv
MDU6SXNzdWU3ODMwMjYxMjc=,"Comments to improve repo organization, scritps and final project",OPEN,2021-01-11T02:42:04Z,2021-01-28T06:32:33Z,,"Your repo is looking good, but the following points need attention:


- [x] README: It would be clearer if you could briefly state in which order one needs to run **all** of your scripts. Notice that all scripts in `/bin` should be mentioned in the README, this is currently not the case.
- [x] README: not all of the programs you used are mentioned in ""Software versions used"", for instance bwa is missing.
- [x] README: specify if your Illumina data is single end or pair end and whether it was already demultiplexed
- [x] README: briefly explain the contents of all of the files in `/meta-data`. In the case of files with columns, please briefly mention what does each column mean.
- [x] Script `DeNovo_assembly.sh` line 43 and script `pilon.sh` line 6: `mkadir` is not a command, correct it for `mkdir`. Since the directories where not being created, also check that this was not causing an error.
- [x] Scripts: When you use `mkdir` in an script, is good practice to add the flag `-p` so that the script can be run several times without causing an error because the directory already exists. Please use `mkdir -p` in all your scripts that currently use `mkdir`
- [x] Don't forget to add a short summary explaining your main results, this can be part of the README or a separate md file.
- [x] Don't forget to add a R figure and the code used to make it. This can be done a simple plot of your number of reads or any data you already have.
- [x] When making commits, don't forget to add **relevant** short messages indicating what did you change.
",AliciaMstt,https://github.com/JavierUrban/Genome-assembly-of-the-copepod-Leptodiaptomus/issues/6,JavierUrban++Genome-assembly-of-the-copepod-Leptodiaptomus.csv
MDU6SXNzdWU3ODg3NzMyNzU=,Database download in KRAKEN2 ,CLOSED,2021-01-19T07:17:21Z,2021-01-19T16:23:19Z,2021-01-19T16:23:19Z,"I want to identify if there are bacteria or viruses common that could be in my sequences and for this I would like to use [KRAKEN2](https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown) and its databases

KRAKEN2 I'm running it from Docker with the repository: [`tbattaglia/kraken2:latest`](https://hub.docker.com/r/tbattaglia/kraken2/tags?page=1&ordering=last_updated)

I ran the program correctly, but I could not download the databases, try to follow the manual. 

This is the help of KRAKEN2

```
Usage: kraken2-build [task option] [options]

Task options (exactly one must be selected):
  --download-taxonomy        Download NCBI taxonomic information
  --download-library TYPE    Download partial library
                             (TYPE = one of ""archaea"", ""bacteria"", ""plasmid"",
                             ""viral"", ""human"", ""fungi"", ""plant"", ""protozoa"",
                             ""nr"", ""nt"", ""env_nr"", ""env_nt"", ""UniVec"",
                             ""UniVec_Core"")
  --special TYPE             Download and build a special database
                             (TYPE = one of ""greengenes"", ""silva"", ""rdp"")
  --add-to-library FILE      Add FILE to library
  --build                    Create DB from library
                             (requires taxonomy d/l'ed and at least one file
                             in library)
  --clean                    Remove unneeded files from a built database
  --standard                 Download and build default database
  --help                     Print this message
  --version                  Print version information

Options:
  --db NAME                  Kraken 2 DB name (mandatory except for
                             --help/--version)
  --threads #                Number of threads (def: 1)
  --kmer-len NUM             K-mer length in bp/aa (build task only;
                             def: 35 nt, 15 aa)
  --minimizer-len NUM        Minimizer length in bp/aa (build task only;
                             def: 31 nt, 12 aa)
  --minimizer-spaces NUM     Number of characters in minimizer that are
                             ignored in comparisons (build task only;
                             def: 7 nt, 0 aa)
  --protein                  Build a protein database for translated search
  --no-masking               Used with --standard/--download-library/
                             --add-to-library to avoid masking low-complexity
                             sequences prior to building; masking requires
                             dustmasker or segmasker to be installed in PATH,
                             which some users might not have.
  --max-db-size NUM          Maximum number of bytes for Kraken 2 hash table;
                             if the estimator determines more would normally be
                             needed, the reference library will be downsampled
                             to fit. (Used with --build/--standard/--special)
  --use-ftp                  Use FTP for downloading instead of RSYNC; used with
                             --download-library/--download-taxonomy/--standard.
  --skip-maps                Avoids downloading accession number to taxid maps,
                             used with --download-taxonomy.
                                                          
```                             
I used this command line:`kraken2-build --standard --db ""bacteria""`

But i get this error: 
```
Downloading taxonomy tree data.../kraken2-2.0.8-beta/download_taxonomy.sh: line 27: rsync: command not found
```

I think the command: rsync is to give data download permissions, but I have doubts if I would have to install it in the Docker image or if I only have to give some permission from my computer or in the same image",JavierUrban,https://github.com/JavierUrban/Genome-assembly-of-the-copepod-Leptodiaptomus/issues/7,JavierUrban++Genome-assembly-of-the-copepod-Leptodiaptomus.csv
I_kwDOHZqK9s5SDscn,location of raw data,OPEN,2022-09-17T07:54:26Z,2022-09-17T07:54:26Z,,"The readme says the raw data is located at https://github.com/human-pangenomics/hpgp-data under HG00621. However, I don't see any data for HG00621 there. Can you help me find it?
aws --no-sign-request s3 ls s3://human-pangenomics/NHGRI_UCSC_panel/
                           PRE HG001/
                           PRE HG002/
                           PRE HG003/
                           PRE HG004/
                           PRE HG005/
                           PRE HG006/
                           PRE HG007/
                           PRE HG00733/
                           PRE HG01107/
                           PRE HG01108/
                           PRE HG01109/
                           PRE HG01241/
                           PRE HG01242/
                           PRE HG01243/
                           PRE HG01440/
                           PRE HG01441/
                           PRE HG01442/
                           PRE HG02053/
                           PRE HG02054/
                           PRE HG02055/
                           PRE HG02080/
                           PRE HG02081/
                           PRE HG02082/
                           PRE HG02107/
                           PRE HG02108/
                           PRE HG02109/
                           PRE HG02143/
                           PRE HG02144/
                           PRE HG02145/
                           PRE HG02721/
                           PRE HG02722/
                           PRE HG02723/
                           PRE HG03096/
                           PRE HG03097/
                           PRE HG03098/
                           PRE HG03490/
                           PRE HG03491/
                           PRE HG03492",droeatumn,https://github.com/JHUCCB/ChineseHanSouthGenome/issues/1,JHUCCB++ChineseHanSouthGenome.csv
I_kwDOFeq_N85Npei-,Truncated File Issue After Generating Flanking Seqs Step,CLOSED,2022-07-12T23:25:22Z,2022-07-14T14:46:02Z,2022-07-14T14:46:02Z,"Any clue why this might be happening?  I'm running VCF_2_Fasta_v1.1.py with no reported errors.  But the mapping step keeps kicking out this ""truncated file"" error.  Like this:  

[M::mem_process_seqs] Processed 49752 reads in 10.999 CPU sec, 10.926 real sec
[M::process] read 49752 sequences (10000152 bp)...
[M::mem_process_seqs] Processed 49752 reads in 11.168 CPU sec, 11.104 real sec
[E::sam_parse1] query name too long
[W::sam_read1_sam] Parse error at line 987047
samtools sort: truncated file. Aborting",kellybarr,https://github.com/KrisChristensen/MapVCF2NewGenome/issues/1,KrisChristensen++MapVCF2NewGenome.csv
I_kwDOFeq_N854Mwgx,error while running the CheckMappingVCF.v1.0.py,CLOSED,2023-11-29T13:35:06Z,2023-11-29T14:54:57Z,2023-11-29T14:54:57Z,"Hi, I am having problems generating the old2new.positions_filtered.txt

Everything ran correctly until step 5 (below), but then I got this error regarding the location of a key ""KeyError: 'CAE02294'"", but old2new.positions.txt contains the mentioned key. Any idea of what it can be?

Is it possible to add some dummy data so that I can test the different steps?
I have tried with other data sets without success either.

I am attaching the files here too. 
[Test.zip](https://github.com/KrisChristensen/MapVCF2NewGenome/files/13501024/Test.zip)

Thanks for your help.


python CheckMappingVCF.v1.0.py -map old2new.positions.txt -fasta1 flankingSeqs.fasta -fai1 flankingSeqs.fasta.fai -fasta2 newGenome.fasta -fai2 newGenome.fasta.fai -flanking 20 -output most > old2new.positions.filtered.txt


Running CheckMappingVCF version: 1.0 with the following parameters:
        -map: old2new.positions.txt
        -fasta1: flankingSeqs.fasta
        -fasta2: newGenome.fasta
        -fai1: flankingSeqs.fasta.fai
        -fai2: newGenome.fasta.fai
        -flanking: 20
        -output: most
        -verbose: NA

Opened index of fasta file (fai1): flankingSeqs.fasta.fai
        Finished reading scaffold fasta fai file: Found 37 sequence(s)
        Total Nucleotide(s): 7437

Opened index of fasta file (fai2): newGenome.fasta.fai
        Finished reading scaffold fasta fai file: Found 1115 sequence(s)
        Total Nucleotide(s): 1863494

Opened map file: old2new.positions.txt
Traceback (most recent call last):
  File ""/env/export/cns_n02_proj/proj21/q_seq_lab/Angelina/M2/SOIL/Genetic_Variability/VCF/MapVCF2NewGenome-main/Test/CheckMappingVCF.v1.0.py"", line 202, in <module>
    open_map = OpenFile(args.map, ""map"", ""1"")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/env/export/cns_n02_proj/proj21/q_seq_lab/Angelina/M2/SOIL/Genetic_Variability/VCF/MapVCF2NewGenome-main/Test/CheckMappingVCF.v1.0.py"", line 38, in __init__
    self.readLinesMap(self.file)
  File ""/env/export/cns_n02_proj/proj21/q_seq_lab/Angelina/M2/SOIL/Genetic_Variability/VCF/MapVCF2NewGenome-main/Test/CheckMappingVCF.v1.0.py"", line 72, in readLinesMap
    if ((int(self.start1) > 0 and int(Variables.sequences1[self.contig1]) >= int(self.end1)) and
                                      ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'CAE02294'
",angi-bvg,https://github.com/KrisChristensen/MapVCF2NewGenome/issues/2,KrisChristensen++MapVCF2NewGenome.csv
I_kwDOFeq_N854dSQi,Empty old2new.positions.txt file. ,OPEN,2023-12-01T14:03:12Z,2023-12-01T14:45:19Z,,"Hi, I get an empty file during certain runs. Do you have an explanation?

I don't understand why the ""old2new.positions.txt"" file is empty (bad_run), when all the previous steps produce no errors.
I know that the codes are working, because I get results on one of my data (good_run).

I am attaching the files here.
[good_run.zip](https://github.com/KrisChristensen/MapVCF2NewGenome/files/13527406/good_run.zip)
[bad_run.zip](https://github.com/KrisChristensen/MapVCF2NewGenome/files/13527408/bad_run.zip)

Thanks for your help.
",angi-bvg,https://github.com/KrisChristensen/MapVCF2NewGenome/issues/3,KrisChristensen++MapVCF2NewGenome.csv
MDU6SXNzdWUyMTIzOTk5MzE=,input file error,OPEN,2017-03-07T11:05:58Z,2017-03-07T11:05:58Z,,"Hi am trying to detect the haplotypes from genome, when i run this code its producing the following error,

*** Initiating program ...

*** Step 1 of 6 : Checking files and executables ...

  * /usr/ajeyadata/DAGCHAINER/run_DAG_chainer.pl is working.

  * blastn is working.

  * makeblastdb is working.

  * Error : Input fasta file must not contain ""|"" symbol !!!

*** Exiting ***

whereas my fasta file doesnt contain ""|"" symbol anywhere",madhubioinfo,https://github.com/melissamlwong/Find2genomehaplo/issues/1,melissamlwong++Find2genomehaplo.csv
I_kwDOGrPvwM5od698,please add shasta,CLOSED,2023-06-12T12:35:42Z,2023-08-08T13:13:41Z,2023-08-08T13:13:41Z,"hello, thanks for a nice repo.

Can you please add shasta to the noisy long read section (ONT). 

https://github.com/paoloshasta/shasta

Thanks,
Colin",colindaven,https://github.com/nadegeguiglielmoni/genome_assembly_tools/issues/3,nadegeguiglielmoni++genome_assembly_tools.csv
MDU6SXNzdWUzODM5NzYyODE=,Pipeline to run analyses,CLOSED,2018-11-24T10:07:10Z,2023-09-15T19:18:38Z,2023-09-15T19:18:38Z,The preparation material should have a pipeline to generate all the downstream data and test software needed for exercise works in the way we intend.,mahesh-panchal,https://github.com/NBISweden/workshop-genome_assembly/issues/1,NBISweden++workshop-genome_assembly.csv
I_kwDOCL88cM5HiMm2,Pipeline command enter and err code: -9,OPEN,2022-04-11T15:31:57Z,2022-04-19T10:49:27Z,,"Hi, I'm new to using SPAdes so I don't know how to enter some commands
Could someone tell me how to add the pipeline commands, I already ran my sequence, it stayed in k55 and it sends this error message

== Error ==  system call for: &quot;[&apos;/usr/lib/spades/bin/spades-core&apos;, &apos;/home/javier/Descargas/SPAdes-3.15.4-Linux/bin/Secuences/SRS2737848_s/K55/configs/config.info&apos;]&quot; finished abnormally, err code: -9

======= SPAdes pipeline finished abnormally and WITH WARNINGS!

=== Error correction and assembling warnings:
 * 2:03:30.757   724M / 1G    WARN    General                 (simplification.cpp        : 479)   The determined erroneous connection coverage threshold may be determined improperly
 * 2:22:45.785   948M / 1G    WARN    General                 (kmer_coverage_model.cpp   : 218)   Too many erroneous kmers, the estimates might be unreliable
 * 2:23:05.838   948M / 1G    WARN    General                 (kmer_coverage_model.cpp   : 327)   Valley value was estimated improperly, reset to 3
======= Warnings saved to /home/javier/Descargas/SPAdes-3.15.4-Linux/bin/Secuences/SRS2737848_s/warnings.log

=== ERRORs:
 * system call for: &quot;[&apos;/usr/lib/spades/bin/spades-core&apos;, &apos;/home/javier/Descargas/SPAdes-3.15.4-Linux/bin/Secuences/SRS2737848_s/K55/configs/config.info&apos;]&quot; finished abnormally, err code: -9

I would greatly appreciate your help
",AbadJavier,https://github.com/NBISweden/workshop-genome_assembly/issues/2,NBISweden++workshop-genome_assembly.csv
I_kwDOGxVcrM5N1CrQ,Could not load nf-core/config profiles,CLOSED,2022-07-15T08:37:41Z,2023-11-14T21:53:08Z,2023-08-25T09:02:56Z,"### Description of the bug

When I launch the pipeline I get the following error 

cat nf.output
/var/spool/slurm/d/job35576642/slurm_script: ligne13: bioinfo/nfcore-Nextflow-v21.10.6: Aucun fichier ou dossier de ce type
N E X T F L O W  ~  version 0.17.3
Launching 'nf-core/genomeannotator' - revision: cbd878f799 [dev]
WARNING: Could not load nf-core/config profiles: https://raw.githubusercontent.com/nf-core/configs/master/nfcore_custom.config
Unknown configuration profile: 'genotoul'

Here is may command line : 
nextflow run nf-core/genomeannotator -r dev -profile genotoul --assemblyfirst_assembly.fasta --rnaseq_samples sample_sheet.csv --proteins proteins.fasta --outdir output --aug_species human

genotoul is one of the profiles found in https://raw.githubusercontent.com/nf-core/configs/master/nfcore_custom.config


### Command used and terminal output

```console
command used :
nextflow run nf-core/genomeannotator -r dev -profile genotoul --assemblyfirst_assembly.fasta --rnaseq_samples sample_sheet.csv 


cat .nextflow.log
juil.-15 10:30:04.213 [main] DEBUG nextflow.cli.Launcher - $> /home/klopp/save/bin/nextflow run nf-core/genomeannotator -r dev -profile genotoul --assembly Cyathomix_first_assembly.fasta --rnaseq_samples sample_sheet.csv --proteins proteins.fasta --outdir output --aug_species caenorhabditis
juil.-15 10:30:04.275 [main] INFO  nextflow.cli.CmdRun - N E X T F L O W  ~  version 0.17.3
juil.-15 10:30:04.911 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/klopp/.nextflow/assets/nf-core/genomeannotator/.git/config; branch: master; remote: origin; url: https://github.com/nf-core/genomeannotator.git
juil.-15 10:30:05.094 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/klopp/.nextflow/assets/nf-core/genomeannotator/.git/config; branch: master; remote: origin; url: https://github.com/nf-core/genomeannotator.git
juil.-15 10:30:05.777 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/klopp/.nextflow/assets/nf-core/genomeannotator/.git/config; branch: master; remote: origin; url: https://github.com/nf-core/genomeannotator.git
juil.-15 10:30:05.777 [main] INFO  nextflow.cli.CmdRun - Launching 'nf-core/genomeannotator' - revision: cbd878f799 [dev]
juil.-15 10:30:05.790 [main] DEBUG nextflow.config.ConfigBuilder - Found config base: /home/klopp/.nextflow/assets/nf-core/genomeannotator/nextflow.config
juil.-15 10:30:05.792 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /home/klopp/.nextflow/assets/nf-core/genomeannotator/nextflow.config
juil.-15 10:30:05.918 [main] DEBUG nextflow.config.ConfigBuilder - Setting config profile: 'genotoul'
juil.-15 10:30:06.338 [main] DEBUG nextflow.cli.Launcher - Operation aborted
nextflow.exception.AbortOperationException: Unknown configuration profile: 'genotoul'
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.codehaus.groovy.reflection.CachedConstructor.invoke(CachedConstructor.java:80)
	at org.codehaus.groovy.reflection.CachedConstructor.doConstructorInvoke(CachedConstructor.java:74)
	at org.codehaus.groovy.runtime.callsite.ConstructorSite$ConstructorSiteNoUnwrap.callConstructor(ConstructorSite.java:84)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallConstructor(CallSiteArray.java:60)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callConstructor(AbstractCallSite.java:235)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callConstructor(AbstractCallSite.java:247)
	at nextflow.config.ConfigBuilder.checkValidProfile(ConfigBuilder.groovy:309)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite$PogoCachedMethodSiteNoUnwrapNoCoerce.invoke(PogoMetaMethodSite.java:210)
	at org.codehaus.groovy.runtime.callsite.PogoMetaMethodSite.callCurrent(PogoMetaMethodSite.java:59)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:52)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:154)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:166)
	at nextflow.config.ConfigBuilder.buildConfig0(ConfigBuilder.groovy:285)
	at nextflow.config.ConfigBuilder$buildConfig0$2.callCurrent(Unknown Source)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:52)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:154)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:174)
	at nextflow.config.ConfigBuilder.buildConfig(ConfigBuilder.groovy:235)
	at nextflow.config.ConfigBuilder$buildConfig$1.callCurrent(Unknown Source)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:52)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:154)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:166)
	at nextflow.config.ConfigBuilder.build(ConfigBuilder.groovy:460)
	at nextflow.cli.CmdRun.run(CmdRun.groovy:175)
	at nextflow.cli.Launcher.run(Launcher.groovy:380)
	at nextflow.cli.Launcher.main(Launcher.groovy:529)
```


### Relevant files

_No response_

### System information

nfcore-Nextflow-v21.10.6
HPC
slurm",chklopp,https://github.com/nf-core/genomeannotator/issues/5,nf-core++genomeannotator.csv
I_kwDOGxVcrM5UwTX4,Could not run test using Docker,CLOSED,2022-10-25T06:49:47Z,2023-08-31T07:30:03Z,2023-08-31T07:30:03Z,"### Description of the bug

When I run test for genomeannotator, I got the following errror:


 ```
Error executing process > 'NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_STAGECONFIG (config)'

Caused by:
  Process `NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_STAGECONFIG (config)` terminated with an error exit status (1)

Command executed:

  mkdir -p augustus_config
  cp -R config/* augustus_config/

  cat <<-END_VERSIONS > versions.yml
  ""NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_STAGECONFIG"":
      augustus: $(echo $(augustus  | head -n1 | cut -f2 -d "" "" | sed ""s/[)]//"" | sed ""s/[(]//"" ))
  END_VERSIONS

Command output:
  (empty)

Command error:
  Unable to find image 'quay.io/biocontainers/augustus:3.4.0--pl5262h5a9fe7b_2' locally
  3.4.0--pl5262h5a9fe7b_2: Pulling from biocontainers/augustus
  c1a16a04cedd: Already exists
  4ca545ee6d5d: Already exists
  9045f8e140e3: Pulling fs layer
  9045f8e140e3: Verifying Checksum
  9045f8e140e3: Download complete
  9045f8e140e3: Pull complete
  Digest: sha256:db15c7f970ce92b36b5f657062bd948634d0c4c162b21fc67916b6ba23ea1770
  Status: Downloaded newer image for quay.io/biocontainers/augustus:3.4.0--pl5262h5a9fe7b_2
  cp: can't stat 'config/*': No such file or directory

```


### Command used and terminal output

```console
$ nextflow run nf-core/genomeannotator -r dev -profile test,docker --outdir genomeannotator_test_001
```


### Relevant files

_No response_

### System information

- Nextflow version version 22.04.4 build 5706
- executor: local
- Hardware: HPC
- Container engine: Docker
- OS: CentOS Linux 7",yuifu,https://github.com/nf-core/genomeannotator/issues/10,nf-core++genomeannotator.csv
I_kwDOGxVcrM5UwUtc,Could not run test using Singularity,CLOSED,2022-10-25T06:54:08Z,2023-08-31T07:29:26Z,2023-08-31T07:29:26Z,"### Description of the bug



```
Error executing process > 'NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_STAGECONFIG (config)'

Caused by:
  Failed to pull singularity image
  command: singularity pull  --name depot.galaxyproject.org-singularity-augustus-3.4.0--pl5262h5a9fe7b_2.img.pulling.1666680659902 https://depot.galaxyproject.org/singularity/augustus:3.4.0--pl5262h5a9fe7b_2 > /dev/null
  status : 255
  message:
    FATAL:   Error making http request: Head ""https://depot.galaxyproject.org/singularity/augustus:3.4.0--pl5262h5a9fe7b_2"": x509: certificate has expired or is not yet valid: current time 2022-10-25T15:51:00+09:00 is after 2021-09-30T14:01:15Z




Pulling Singularity image https://containers.biocontainers.pro/s3/SingImgsRepo/biocontainers/v1.2.0_cv1/biocontainers_v1.2.0_cv1.img [cache /data2/harukao/projects/2018/stRamDA/results/20221025_test_genomeannotator/work/singularity/containers.biocontainers.pro-s3-SingImgsRepo-biocontainers-v1.2.0_cv1-biocontainers_v1.2.0_cv1.img.img]
```

### Command used and terminal output

```console
$ nextflow run nf-core/genomeannotator -r dev -profile test,singularity --outdir genomeannotator_test_002
```


### Relevant files

_No response_

### System information

- Nextflow version version 22.04.4 build 5706
- executor: local
- Hardware: HPC
- Container engine: Singularity
- OS: CentOS Linux 7",yuifu,https://github.com/nf-core/genomeannotator/issues/11,nf-core++genomeannotator.csv
I_kwDOGxVcrM5jY_dj,TE annotation and soft masking,OPEN,2023-04-14T04:38:12Z,2023-04-14T04:38:12Z,,"### Description of feature

I noticed that you use Dfam as your repeat library. Could you consider to add  DNApipeTE and REPET which are tools for de novo annotation and soft masking of transposable elements (TEs) in genome assemblies, similar to The Extensive de novo TE Annotator (EDTA) and RepeatMasker.

DNApipeTE is a pipeline that includes several steps for TE annotation and soft masking, including repeat identification, classification, and masking. DNApipeTE utilizes several other tools, including RepeatModeler, RepeatMasker, and RepeatExplorer, to perform these tasks. The output of DNApipeTE includes a consensus library of repeat sequences, as well as annotations of putative TE locations in the genome, and a soft-masked genome assembly.

REPET is another pipeline that includes several steps for TE annotation and soft masking, including repeat identification, classification, clustering, and masking. REPET utilizes several other tools, including RepeatModeler, RepeatMasker, and PILER, to perform these tasks. The output of REPET includes a consensus library of repeat sequences, as well as annotations of putative TE locations in the genome, and a soft-masked genome assembly.

EDTA is a tool that is specifically designed for de novo annotation of transposable elements (TEs) in genome assemblies. The output of EDTA includes a consensus library of repeat sequences, as well as annotations of putative TE locations in the genome.

Both DNApipeTE and REPET provide similar functionalities to EDTA and RepeatMasker, and the output of these pipelines can be used for downstream analyses. However, the specific algorithms and parameters used by these pipelines may differ, resulting in different outputs and soft masking results. The choice of which tool to use will depend on the specific needs of the analysis and the characteristics of the genome assembly being analyzed.

Thank you for considering.

Best wishes,

Michal",mictadlo,https://github.com/nf-core/genomeannotator/issues/14,nf-core++genomeannotator.csv
I_kwDOGxVcrM5jZGED,Adding more RNA-Seq predictions,OPEN,2023-04-14T05:14:24Z,2023-08-25T08:57:51Z,,"### Description of feature

Hi,
I recently came across Mikado which is a pipeline to identify the most useful or best set of transcripts from multiple transcript assemblies. Our approach leverages transcript assemblies generated by multiple methods to define expressed loci, assign a representative transcript and return a set of gene models that selects against transcripts that are chimeric, fragmented or with short or disrupted CDS. Loci are first defined based on overlap criteria and each transcript therein is scored based on up to 50 available metrics relating to ORF and cDNA size, relative position of the ORF within the transcript, UTR length and presence of multiple ORFs. Mikado can also utilize blast data to score transcripts based on proteins similarity and to identify and split chimeric transcripts. Optionally, junction confidence data as provided by [Portcullis](https://github.com/maplesond/portcullis) can be used to improve the assessment. The best-scoring transcripts are selected as the primary transcripts of their respective gene loci; additionally, Mikado can bring back other valid splice variants that are compatible with the primary isoform.

![giy093fig1](https://user-images.githubusercontent.com/588297/231946974-c409f5db-f1a1-4b7a-aa49-d982571c5b38.jpeg)

Mikado uses GTF or GFF files as mandatory input. Non-mandatory but highly recommended input data can be generated by obtaining a set of reliable splicing junctions with Portcullis_, by locating coding ORFs on the transcripts using either [Transdecoder](https://github.com/TransDecoder/TransDecoder/) or [Prodigal](https://github.com/hyattpd/Prodigal), and by obtaining homology information through either [BLASTX](https://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastDocs&DOC_TYPE=Download) or [DIAMOND](https://github.com/bbuchfink/diamond/).

Could the output from Mikado be used to train Augustus, GlimmerHMM and SNAP?

Than you for considering.

Best wishes,

Michal",mictadlo,https://github.com/nf-core/genomeannotator/issues/15,nf-core++genomeannotator.csv
I_kwDOGxVcrM5vwU1H,Parallelize repeatmasking,OPEN,2023-08-31T07:24:03Z,2023-08-31T07:24:03Z,,"### Description of feature

Currently, RepeatMasker runs on chunks of the assembly, containing full scaffolds/chromosomes. For highly contiguous assemblies, this can mean excessively long run times. Investigate whether repeat masking can be performed on sub-regions of the scaffolds in parallel without losing repeat regions. ",marchoeppner,https://github.com/nf-core/genomeannotator/issues/17,nf-core++genomeannotator.csv
I_kwDOGxVcrM5v74ku,Pipeline fail at REPEATMASKER_STAGELIB,OPEN,2023-09-01T19:45:55Z,2024-07-12T15:39:01Z,,"### Description of the bug

I am running the most current version of @marchoeppner dev branch on Tower on a real dataset. The workflow passed repeat masking and produced the `consensi.fa` file but failed very quickly at the subsequent staging process with: 
```
cp: can't stat '/.nextflow/assets/marchoeppner/genomeannotator/assets/repeatmasker/my_genome.fa': No such file or directory
```
Since I ran this on Tower it's a little difficult to debug things in the `.nextflow/assets` directory so this isn't obvious to me yet where this `my_genome.fa` file was supposed to come from.

### Command used and terminal output

```console
nextflow run 'https://github.com/marchoeppner/genomeannotator' \
		 -name tick_annotation_test \
		 -params-file 'https://api.tower.nf/ephemeral/zSnWhzERlz_Z4e-E6h2gng.json' \
		 -with-tower \
		 -r dev \
		 -profile docker
Params:
pri_prot_target = 5
custom_config_base = https://raw.githubusercontent.com/nf-core/configs/master
evm_weights = /.nextflow/assets/marchoeppner/genomeannotator/assets/evm/weights.txt
plaintext_email = false
monochrome_logs = false
pasa_nmodels = 1000
spaln_q = 5
max_cpus = 16
spaln_taxon = ixodscap
pri_rnaseq = 4
max_multiqc_email_size = 25.MB
max_time = 240.h
aug_chunk_length = 3000000
nevm = 10
tracedir = ${params.outdir}/pipeline_info
validate_params = true
npart_size = 200000000
max_intron_size = 20000
aug_species = human
pri_wiggle = 2
version = false
spaln_options = -M
publish_dir_mode = copy
aug_training = false
t_prot = P
t_est = E
pasa_config_file = /.nextflow/assets/marchoeppner/genomeannotator/assets/pasa/alignAssembly.config
min_prot_length = 35
aug_options = --alternatives-from-evidence=on --minexonintronprob=0.08 --minmeanexonintronprob=0.4 --maxtracks=3
multiqc_title = test run
pri_trans = 4
pasa = false
custom_config_version = master
max_memory = 128.GB
dummy_gff = /.nextflow/assets/marchoeppner/genomeannotator/assets/empty.gff3
spaln_protein_id_targeted = 90
nproteins = 200
proteins = s3://nf-hifi2genome/tick_annotation/2023-08-25-all-tick-species-proteins.fasta
assembly = s3://nf-hifi2genome/tick_annotation/Arcadia_Amblyomma_americanum_asm001_purged_cleanedup1.fasta
pri_est = 4
pri_prot = 3
min_contig_size = 5000
evm = false
email = elizabeth.mcdaniel@arcadiascience.com
schema_ignore_params = genomes,saveReference,igenomes_base,igenomes_ignore,enable_conda,save-reference
genomes:
pasa_aligner = minimap2
ncrna = false
igenomes_ignore = true
outdir = s3://nf-hifi2genome/tick_annotation/genomeannotator
help = false
show_hidden_params = false
t_rnaseq = E
rm_db = https://www.dfam.org/releases/Dfam_3.5/families/Dfam_curatedonly.h5.gz
busco_lineage = arthropoda_odb10
trinity = false
spaln_protein_id = 60
```


### Relevant files

[nf-2ZIBaSqCJUU5ME.log](https://github.com/nf-core/genomeannotator/files/12501138/nf-2ZIBaSqCJUU5ME.log)


### System information

Run on Tower with Nextflow version 23.04.3, using Docker profile",elizabethmcd,https://github.com/nf-core/genomeannotator/issues/18,nf-core++genomeannotator.csv
I_kwDOGxVcrM58kEAG,rnaseq_align.nf error,OPEN,2024-01-19T07:31:25Z,2024-01-21T09:36:15Z,,"### Description of the bug

Hi! I'm using genomeannotator for the assembly annotation of a microalgae. As inputs I have the assembly, some RNA-Seq libraries and a protein database created by myself.

### Command used and terminal output

```console
nextflow run nf-core/genomeannotator -r cbd878f -profile docker --assembly ../Assembly/Canu/Pilon_results/pilon_pilon_3/pilon_pilon_3.fasta --proteins uniref90.fasta --rnaseq_samples ../RNASeq_fastq/rnaseq_samples.csv --max_intron_size 5000 --outdir . --aug_species toxoplasma --spaln_taxon toxogond --aug_config_dir . --aug_config_container . -c config_genomeannotator.txt

Nextflow 23.10.1 is available - Please consider updating your version to it
N E X T F L O W  ~  version 23.10.0
Launching `https://github.com/nf-core/genomeannotator` [jovial_brenner] DSL2 - revision: cbd878f7997d367ccbe952648e114ad25962963f


------------------------------------------------------
                                        ,--./,-.
        ___     __   __   __   ___     /,-._.--~'
  |\ | |__  __ /  ` /  \ |__) |__         }  {
  | \| |       \__, \__/ |  \ |___     \`-._,-`-,
                                        `._,._,'
  nf-core/genomeannotator v1.0dev
------------------------------------------------------
Core Nextflow options
  runName             : jovial_brenner
  containerEngine     : docker
  launchDir           : /media/Assembly_annotation
  workDir             : /media/Assembly_annotation/work
  projectDir          : /home/fperez/.nextflow/assets/nf-core/genomeannotator
  userName            : fperez
  profile             : docker
  configFiles         : /home/fperez/.nextflow/assets/nf-core/genomeannotator/nextflow.config, /media/Assembly_annotation/config_genomeannotator.txt

Input/output options
  assembly            : ../Assembly/Canu/Pilon_results/pilon_pilon_3/pilon_pilon_3.fasta
  outdir              : .
  rnaseq_samples      : ../RNASeq_fastq/rnaseq_samples.csv
  proteins            : uniref90.fasta

Options for pipeline behavior
  max_intron_size     : 5000
  dummy_gff           : /home/fperez/.nextflow/assets/nf-core/genomeannotator/assets/empty.gff3

Options for ab-initio gene finding
  aug_species         : toxoplasma
  aug_config_container: .
  aug_config_dir      : .

Options for protein data processing
  spaln_taxon         : toxogond

Options for PASA behavior
  pasa_config_file    : /home/fperez/.nextflow/assets/nf-core/genomeannotator/assets/pasa/alignAssembly.config

Options for EvidenceModeler behavior
  evm_weights         : /home/fperez/.nextflow/assets/nf-core/genomeannotator/assets/evm/weights.txt

!! Only displaying parameters that differ from the pipeline defaults !!
------------------------------------------------------
If you use nf-core/genomeannotator for your analysis please cite:

* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x

* Software dependencies
  https://github.com/nf-core/genomeannotator/blob/master/CITATIONS.md
------------------------------------------------------
executor >  local (3)
[0b/7e3452] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_STAGECONFIG (Assembly_annotation)                    [  0%] 0 of 1
executor >  local (4)
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_STAGECONFIG (Assembly_annotation)                                   -
[52/f5d136] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:ASSEMBLY_PREPROCESS:GAAS_ASSEMBLYFILTERBYSIZE (pilon_pilon_3)                [100%] 1 of 1, cached: 1 
[3d/6cb819] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:ASSEMBLY_PREPROCESS:GAAS_FASTACLEANER (pilon_pilon_3)                        [100%] 1 of 1, cached: 1 
[6e/2e3768] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:ASSEMBLY_PREPROCESS:GAAS_FASTASTATISTICS (pilon_pilon_3)                     [100%] 1 of 1, cached: 1 
[8f/5e4436] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:REPEATMODELER (pilon_pilon_3)                                                [  0%] 0 of 1
[69/78da24] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:REPEATMASKER:FASTASPLITTER (pilon_pilon_3 - pilon_pilon_3.filtered.clean.fa) [100%] 1 of 1, cached: 1 
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:REPEATMASKER:GUNZIP                                                          -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:REPEATMASKER:REPEATMASKER_STAGELIB                                           -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:REPEATMASKER:REPEATMASKER_REPEATMASK                                         -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:REPEATMASKER:REPEATMASKER_CAT_FASTA                                          -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:GAAS_FASTACLEANER (uniref90)                             -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:EXONERATE_FASTACLEAN                                     -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:GAAS_FASTAFILTERBYSIZE                                   -
[00/d29213] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:SPALN_MAKEINDEX (pilon_pilon_3)                          [100%] 1 of 1, cached: 1 
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:SPALN_ALIGN                                              -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:SPALN_MERGE                                              -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:AUGUSTUS_ALIGNTOHINTS                                    -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:HELPER_SPALNTOGMOD                                       -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:HELPER_SPALNTOEVM                                        -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SPALN_ALIGN_PROTEIN:HELPER_SPALNTOTRAINING                                   -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:RNASEQ_ALIGN:STAR_INDEX (pilon_pilon_3)                                      -
[bd/e4c8f6] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:RNASEQ_ALIGN:SAMPLESHEET_CHECK (rnaseq_samples.csv)                          [100%] 1 of 1, cached: 1 
[eb/fb6e74] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:RNASEQ_ALIGN:FASTP (All)                                                     [100%] 1 of 1, cached: 1 
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:RNASEQ_ALIGN:CAT_FASTQ                                                       -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:RNASEQ_ALIGN:STAR_ALIGN_PASS_ONE                                             -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:RNASEQ_ALIGN:STAR_ALIGN_PASS_TWO                                             -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:SAMTOOLS_MERGE                                                               -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_BAM2HINTS                                                           -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_PIPELINE:FASTASPLITTER                                              -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_PIPELINE:AUGUSTUS_AUGUSTUSBATCH                                     -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_PIPELINE:AUGUSTUS_FIXJOINGENES                                      -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_PIPELINE:AUGUSTUS_CREATEGFFIDS                                      -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:AUGUSTUS_PIPELINE:AUGUSTUS_GFF2PROTEINS                                      -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:CUSTOM_DUMPSOFTWAREVERSIONS                                                  -
[-        ] process > NFCORE_GENOMEANNOTATOR:GENOMEANNOTATOR:MULTIQC                                                                      -
ERROR ~ fromIndex = -1

 -- Check script '/home/fperez/.nextflow/assets/nf-core/genomeannotator/./workflows/../subworkflows/local/rnaseq_align.nf' at line: 35 or see '.nextflow.log' file for more details
```


### Relevant files

The custom config file looks like this:

docker {
    enabled = true
    temp = ""/Genome/Assembly_annotation/tmp""
}

env {
   TMPDIR = ""/Genome/Assembly_annotation/tmp""
   TMP = ""/Genome/Assembly_annotation/tmp""
}

### System information

_No response_",fperezcobos,https://github.com/nf-core/genomeannotator/issues/22,nf-core++genomeannotator.csv
I_kwDOGxVcrM6LLKfP,Fail at a run using conda profile,OPEN,2024-06-05T05:50:14Z,2024-06-05T05:50:14Z,,"### Description of the bug

I conducted a run using the following command and nextflow.config.
conda activate nf-core
nextflow run nf-core/genomeannotator -r dev -profile conda

Command error:
.command.sh:  2: gaas_fasta_filter_by_size.pl: not found such a command

How can I install required executables including the gaas_fasta_filter_by_size.pl script?

P.S. I tried to run with 'nextflow run nf-core/genomeannotator -r dev -profile singularity' before using -profile conda.
But I encountered the same error as ""#18 Pipeline fail at REPEATMASKER_STAGELIB"".
In this case, several parameter settings, including singularity.runOptions/singularity.envWhitelist in nextflow.config and SINGULARITY_BIND, had no effect.

### Command used and terminal output

_No response_

### Relevant files

_No response_

### System information

_No response_",stat-lab,https://github.com/nf-core/genomeannotator/issues/28,nf-core++genomeannotator.csv
I_kwDOEWRVu85IE3xw,The graph traversal script needs to start with the longest contig,OPEN,2022-04-20T06:48:03Z,2022-04-20T06:48:03Z,,"Sometimes in the gfa file the longest contig is not the first contig, and this can change the path and how the path is traversed. Need to add this function 

Also add a step to confirm the path at the end has coverage by running jellyfish",npbhavya,https://github.com/npbhavya/bacterial-genome-assembly/issues/1,npbhavya++bacterial-genome-assembly.csv
MDU6SXNzdWU0NjcwODY3NTA=,document missing,CLOSED,2019-07-11T20:17:42Z,2020-12-04T16:12:48Z,2020-12-04T16:12:48Z,"I get GitHub 404 for this link 
https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/master/docs/annotated.html
from this page 
https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/master/docs/README-SDK.md

I guess the generated HTML is not checked in?
",cschin,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/33,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0Njk3Mjc0NTU=,Path Missing CMakeLists.txt,CLOSED,2019-07-18T11:54:20Z,2020-03-27T07:51:36Z,2019-07-19T11:38:35Z,"I tried to install Claragenomics in ubuntu 18.04 using command cmake .. -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=install,but I'm getting this error
The source directory /home/vaibhavcurl/ClaraGenomicsAnalysis-master/3rdparty/bioparser
does not contain a CMakeLists.txt file.
The source directory

    /home/vaibhavcurl/ClaraGenomicsAnalysis-master/3rdparty/spdlog

  does not contain a CMakeLists.txt file.

",vaibhaw1994kumar,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/40,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0NzA0ODg3NDE=,Hitting graph size larger than allowed GPU limits,CLOSED,2019-07-19T18:55:00Z,2019-07-22T14:18:52Z,2019-07-22T14:18:52Z,Observed a graph overflowing the max edges count during a run. Reported in #44 by @SamStudio8,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/45,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0NzA3NjY5ODU=,Kernel Error:: Node count exceeded maximum nodes per window,CLOSED,2019-07-21T10:36:27Z,2019-08-06T10:56:15Z,2019-08-06T10:56:14Z,"Observed this error on my `stderr` while running `racon-gpu`, not sure if related to #45? It's [raised by the code here](https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/master/cudapoa/src/cudapoa_batch.cpp#L204).",SamStudio8,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/47,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0NzM4NzM3MjI=,Unable to clone,CLOSED,2019-07-29T06:32:09Z,2019-07-29T08:42:46Z,2019-07-29T08:31:31Z,"Hi, 
The clone command fails with access right error.
```
$ git clone --recursive git@github.com:clara-genomics/ClaraGenomicsAnalysis.git
Cloning into 'ClaraGenomicsAnalysis'...
The authenticity of host 'github.com (140.82.114.3)' can't be established.
RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'github.com,140.82.114.3' (RSA) to the list of known hosts.
git@github.com: Permission denied (publickey).
fatal: Could not read from remote repository.

Please make sure you have the correct access rights
and the repository exists.
```
Any thought?",mahmoodn,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/53,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0NzM5MjY0NTI=,About singlebatch ,CLOSED,2019-07-29T08:46:01Z,2019-07-30T12:14:08Z,2019-07-30T12:14:08Z,"I went to `build/install/benchmarks/cudapoa/` and when I run `singlebatch`, I get the following output

```
$ ./singlebatch
2019-07-29 13:14:25
Running ./singlebatch
Run on (16 X 3600 MHz CPU s)
CPU Caches:
  L1 Data 32K (x8)
  L1 Instruction 64K (x8)
  L2 Unified 512K (x8)
  L3 Unified 8192K (x2)
Load Average: 0.33, 0.15, 0.16
***WARNING*** CPU scaling is enabled, the benchmark real time measurements may be noisy and will incur extra overhead.
------------------------------------------------------------------
Benchmark                        Time             CPU   Iterations
------------------------------------------------------------------
BM_SingleBatchTest/1          1594 ms         1593 ms            1
BM_SingleBatchTest/4          2429 ms         2427 ms            1
BM_SingleBatchTest/16         2687 ms         2685 ms            1
BM_SingleBatchTest/64         3231 ms         3228 ms            1
BM_SingleBatchTest/256        8233 ms         8225 ms            1
terminate called after throwing an instance of 'std::runtime_error'
  what():  GPU Error:: out of memory /home/mahmood/cactus/cl/ClaraGenomicsAnalysis/cudapoa/src/allocate_block.cpp 46
Aborted (core dumped)
```

I would like to test a specific batch size and not variable sizes. It seems that singlebatch is a binary file. Any idea for that?",mahmoodn,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/54,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0NzQ1NjkzODc=,Still about single batch,CLOSED,2019-07-30T12:57:07Z,2019-08-29T14:59:35Z,2019-08-29T14:59:35Z,"For my GPU analyses, I tried running single-batch with nv profiler. It seems that there are two kernels only where the dominant one is `generatePOAKernel`.  The other is `generateConsensusKernel` which is not important. So, this benchmark is not going to solve the problem and is only good for generating the graph. Am I right? I am not expert in this field and want to analyze some GPU things. I don't know if that graph generation is a big problem. 

A single run of batch=256, takes 
  Time = 8094 ms
  CPU = 8092 ms
  Iterations = 1
So, where is GPU in the results? ",mahmoodn,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/57,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODcwMTE2NzY=,`IndexGenerator` and `Matcher` unable to allocate memory on GPU when number of reads too large,CLOSED,2019-08-29T14:58:21Z,2019-09-19T20:41:37Z,2019-09-19T20:41:37Z,"When running overlaps with a FASTA/FASTQ that is too large (e.g >500MB) the following error is encountered:

```
terminate called after throwing an instance of 'claragenomics::device_memory_allocation_exception'
  what():  Could not allocate device memory!
```

This happens because on-device memory requirements of `IndexGenerator` and `Matcher` scale with size of the input reads.

The solution is to implement a ""chunked"" version of `IndexGenerator` and `Matcher`.",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/94,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODcwNDIwMjE=,create conda builds for C++ libraries and python modules,OPEN,2019-08-29T15:49:42Z,2020-04-09T15:31:46Z,,"1. Create conda recipes for C++ libs
2. Create conda recipes for pyclaragenomics
3. Host releases in conda channel",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/95,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODcxNTY0NTA=,revert CGA_CU_CHECK_ERR to abort on error,CLOSED,2019-08-29T20:17:39Z,2019-09-05T14:29:06Z,2019-09-05T14:29:06Z,"Revert the CGA_CU_CHECK_ERR functionality to abort on error for Release builds, and `assert(false)` and then abort for Debug builds.

Potentially add cudaDeviceSynchronize in debug builds to catch errors when they occur",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/96,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODczNTkzNDE=,`IndexGenerator` needs chunked implementation,CLOSED,2019-08-30T08:34:50Z,2019-08-30T23:28:00Z,2019-08-30T23:27:16Z,As solving part of #94 a low-memory (chunked) implementation of `InexGenerator` is required.,vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/98,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODc0NjE0NjY=,Add build dependencies to Conda for GPUCI builds,CLOSED,2019-08-30T12:38:14Z,2019-08-30T17:16:53Z,2019-08-30T17:16:53Z,"Some recent GPUCI failures have revealed that (eg [this one](https://gpuci.gpuopenanalytics.com/blue/organizations/jenkins/gpuCI-private%2Fclara-genomics-analysis%2Fprb%2Fclara-genomics-analysis-cpu-build/detail/clara-genomics-analysis-cpu-build/1457/pipeline)) have revealed that we are sensitive to what packages are installed on GPUCI VM/docker instances we are running.

Conda should be used as much as possible to allow our tests to run on a clean CI instance. This includes at a minimum:

1. Cmake
2. Flake",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/101,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODc3MDI4NzY=,Solve performance regression caused by chunked Index Generator,CLOSED,2019-08-30T23:31:01Z,2019-09-18T09:47:56Z,2019-09-18T09:47:56Z,#100 allows indexing of an arbitarily-large set of sequences but introduces a performance regression. This is caused because several sorted lists of SketchElements now need to be merged together. The merging is not being performed in an optimal way and can be improved by multithreading to run in ~log(N) time. There is also the possibility of performing this on GPU.,vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/103,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODc3MDMyMjk=,`Matcher` needs chunked implementation,CLOSED,2019-08-30T23:33:28Z,2019-10-29T16:49:00Z,2019-10-29T16:49:00Z,As solving part of #94 a low-memory (chunked) implementation of `Matcher` is required.,vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/104,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2ODQyOTQ=,Sample app for cuda aligner,CLOSED,2019-09-03T15:46:13Z,2019-10-28T12:59:11Z,2019-10-28T12:59:11Z,Write a sample application for cuda aligner,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/106,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2ODU5MTQ=,cuda aligner API to take in max available memory and max ref/query sizes,OPEN,2019-09-03T15:49:04Z,2021-01-26T16:52:25Z,,"1. each aligner batch to take in max memory and max ref/query sizes and determine how many how alignments can be performed in the batch.
2. provide api to check max alignments possible
3. actual max alignments may me larger based on inputs processed so far, and actual max can be determined by continually adding and checking return value of add alignment api call
 ",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/107,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTA3ODU=,Add python API for cuda aligner,CLOSED,2019-09-03T15:58:01Z,2019-10-28T13:10:33Z,2019-10-28T13:10:33Z,,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/108,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTE0NTQ=,Enable style check for cudamapper,CLOSED,2019-09-03T15:59:18Z,2019-10-28T12:57:36Z,2019-10-28T12:57:35Z,Would just require the CMakeLists.txt in cudamapper folder to have one more line as specified here https://gitlab-master.nvidia.com/genomics/GenomeWorks/blob/master/cudapoa/CMakeLists.txt#L67,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/109,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTIxMDA=,Acceleration improvements for Hirschberg,CLOSED,2019-09-03T16:00:30Z,2019-10-29T16:50:39Z,2019-10-29T16:50:39Z,,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/110,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTMwNDc=,Evaluate nvBowTie import into CGA,OPEN,2019-09-03T16:02:19Z,2019-09-03T16:02:19Z,,Import nvBowTie into ClaraGenomicsAnalysis SDK from NVBio repo,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/111,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTYzNjY=,Increase cudaaligner singlealignment sweep to 1 Mb,OPEN,2019-09-03T16:09:02Z,2019-09-10T21:01:06Z,,Update Myers + Hirschberg benchmark sweep to end at 1 Mb,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/112,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTcxNTg=,"Make SDK functions ""current device""-neutral",CLOSED,2019-09-03T16:10:33Z,2019-09-11T14:34:26Z,2019-09-11T14:34:26Z,"If we assume our users use CUDA also outside of our library, we should also ensure that our methods are ""current device""-neutral, i.e. that we reset the device (cudaSetDevice) at the end of each method to the value it had when it entered the method.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/113,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTc4ODg=,clang-format: fix member initializer formatting,CLOSED,2019-09-03T16:12:08Z,2019-10-29T11:58:52Z,2019-10-29T11:58:52Z,"clang-format formats the member initializer of a constructor as a single long line regardless of the length of this line.
For long lines clang-format should introduce line breaks in some sensible way.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/114,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTg2NDc=,Improve README for different various parts of the SDK,CLOSED,2019-09-03T16:13:42Z,2020-12-04T16:13:52Z,2020-12-04T16:13:52Z,"Currently READMEs are not setup in an easy to use manner. The following needs to be done - 
Proper README for each section (main, benchmarks, samples, APIs, tests)
Link all READMEs from main one to provide connected information from single location",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/115,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODkyMjk0MDY=,pycga setup.py should run from any folder,CLOSED,2019-09-04T15:20:45Z,2019-09-05T10:39:55Z,2019-09-05T10:39:55Z,Right now `setup.py` only runs from the `pyclaragenomics` folder. This should be runnable from any directory,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/118,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODk2NjQ5MTY=,Index should accept SketchElement implementation as tempalte parameter,CLOSED,2019-09-05T10:24:44Z,2019-09-13T14:57:42Z,2019-09-13T14:57:42Z,"Currently `Index` works with pointers to `SketchElement`, meaning we have to use `std::vector<std::unique_ptr<SketchElement>>` which is bad for performance and makes it hard to use that data on the GPU.
Change the implementation so that `Index` (or it's constructor) accepts one implementation of `SketchElement` and then work with `std::vector<SketchElementImpl>`",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/122,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTAyOTQ0NTU=,Shared objects not being detected by python when importing `claragenomics.bindings`,CLOSED,2019-09-06T12:14:01Z,2019-09-09T13:17:11Z,2019-09-09T13:17:11Z,"When installing pyclaragenomics with venv, the following error is happening when running samples/tests:


```
Traceback (most recent call last):
  File ""./sample_cudapoa"", line 18, in <module>
    from claragenomics.bindings import cudapoa
ImportError: liblogging.so: cannot open shared object file: No such file or directory
```


it seems that if `ClaraGenomicsAnalysis/pyclaragenomics/cga_build/install/lib/` is added to `LD_LIBRARY_PATH` this problem is resolved.

This error does not seem to occur when running in a Conda environment, but does in a venv (as reported by @mimaric ).",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/127,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTAzNDMxNjk=,genome_simulator slow on large genomes,OPEN,2019-09-06T13:58:33Z,2019-09-06T13:58:50Z,,"After `genome_simulator` prints out

```Simulating genome:
100%|| 120/120 [05:41<00:00,  1.76s/it]
Simulating reads:
100%|| 120/120 [06:54<00:00,  3.46s/it]
```

If running with a large genome (e.g 100MB @ 30x) there is a very long period where a single CPU is at 100% utilisation. This can probably be sped up through multiprocessing and/or other means.",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/128,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTMzMzIzMTU=,After PR #131 results of cudamapper are different,CLOSED,2019-09-13T13:41:28Z,2019-09-25T17:20:15Z,2019-09-25T17:20:15Z,"For a 10 megabases 30x coverage input cudamapper returns different results than before the merge of #131 
Please investigate and unittest to cover that case.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/133,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTMzNjM1NDE=,Do final steps of index generation in IndexGPU on GPU,CLOSED,2019-09-13T14:41:54Z,2019-12-04T15:13:28Z,2019-12-04T15:13:28Z,"As specified in PR #134 last part of building index in `IndexGPU`  (done in `details::index_gpu::build_index()`) is still done on the CPU and takes about half of the total time execution time of `IndexGPU` generation.

Look for a way to move it to the GPU",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/135,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTMzNjk0MTk=,SketchElementImpl::ReadidPositionDirection became new SketchElement,OPEN,2019-09-13T14:53:14Z,2019-12-09T09:19:29Z,,"`SketchElement`/`Minimizer` objects are not used anymore. `IndexGPU` internally relies on `SketchElementImpl::ReadidPositionDirection`. Its output consists of the content of `SketchElementImpl::ReadidPositionDirection` split into three separate arrays.

Look into ways to:
1) Change the interface of `Index` so that `SketchElementImpl::ReadidPositionDirection` does not have to be split into three arrays
2) Refactor the code to reflect the current state of not using `SketchElement` objects",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/136,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTMzNzA5ODE=,Improve exception handling in python bindings,OPEN,2019-09-13T14:56:08Z,2020-04-28T14:59:43Z,,"Currently error codes are simply converted to python RuntimeErrors, whereas it might be more appropriate to throw some of them as ValueErrors based on the type of error status",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/138,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTMzODQ2NTU=,Create Error class for python bindings,OPEN,2019-09-13T15:22:42Z,2020-05-04T22:03:22Z,,Wrap the C++ error enums into an error class that has a to `__str__` function and can be thrown from within the binding classes,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/139,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTM0MjMwNzc=,Move enums back to enum classes in C++ CGA,OPEN,2019-09-13T16:49:34Z,2019-09-13T16:49:34Z,,"Because of cython limitations, C++ enum classes had to be converted to enums for compatibility. However, there seem to be some workarounds in cython land to make up for that limitation. Worth investigating those WARs to avoid violating good C++ coding guidelines",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/140,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTQxMjgyODQ=,[cudaaligner] FormattedAlignment should include `|` and `x` symbols,CLOSED,2019-09-16T15:39:01Z,2019-12-02T13:27:52Z,2019-12-02T13:27:52Z,"`FormattedAlignment` in cudaaligner returns aligned strings in the following format:

```
ACCGTCA
ACGC--A
```

This would be preferable:

```
ACCGTCA
||xx  |
ACGC--A
```",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/141,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTQxNjM3NzU=,[cudaaligner] Add character set check to API,OPEN,2019-09-16T16:50:24Z,2021-01-26T16:53:20Z,,"The cudaaligner API only supports `ATCG` alphabet, but the API doesn't check for this in input strings right now, leading to undefined behavior.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/142,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTU4ODc1Mzc=,[cudapoa] combine benchmarks into single application,CLOSED,2019-09-19T15:52:50Z,2019-10-31T13:44:04Z,2019-10-31T13:44:04Z,Combine cudapoa benchmarks into a single application instead of two. google benchmarks provides a way to select which benchmarks to run based on filters,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/147,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTU4ODc4NTQ=,[cudaaligner] combine benchmarks into single application,CLOSED,2019-09-19T15:53:29Z,2019-11-04T19:04:16Z,2019-11-04T19:04:16Z,Use google bench filters instead to choose which set of benchmarks to run,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/148,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTYwMTUzNzQ=,Add CIGAR alignments to cudamapper using cudaaligner,CLOSED,2019-09-19T20:39:50Z,2020-03-06T23:46:07Z,2020-03-06T23:46:07Z,"* Add optional `cigar` attribute to `Overlap` objects.
* Add `-a` flag to cudamapper for the option of computing alignments
* Once overlapping is complete, alignments can be completed in batches using cudaaligner.
* If alignments are computed, they should be added to the `PAF` file (the relevant modification needs to be performed in the `print_paf` function).",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/150,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTY0ODA3NDg=,[tests] test_wrappers.py test fails without minimap2 and racon in env,CLOSED,2019-09-20T18:06:39Z,2020-12-04T16:14:45Z,2020-12-04T16:14:45Z,"the test_wrappers.py script always fails if minimap2 and racon are not present in the environment, and our documentation currently doesn't require those to be installed. we need to update documentation to take care of that.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/152,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTcyMDY3Njc=,Use pip to install pyclaragenomics instead of setup.py,CLOSED,2019-09-23T16:37:29Z,2019-11-11T14:14:22Z,2019-11-11T14:14:22Z,There are several benefits to using `pip` to install custom packages instead of running `setup.py` directly. A good summary can be found here - https://stackoverflow.com/questions/15724093/difference-between-python-setup-py-install-and-pip-install/15731459,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/153,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTg5NTY3MzE=,Graph representation in python and serialization methods,CLOSED,2019-09-26T15:22:52Z,2020-01-13T19:58:11Z,2020-01-13T19:58:11Z,"The python bindings are very helpful to perform alignments and consensus calls, but there currently isn't a good way to work with the resulting graph structures in python.  The structures are available in C++, but there are some nuances to them.  It would be nice if there were some examples (with documentation) of working with the resulting graphs in C++ and some bindings (or a new interface) to work with them in python as well.

It would also be helpful if there were a method that can be called after performing an alignment or consensus call that would serialize the graph (in DOT or some similar format) so it can be easily inspected / visualized after creation. ",jonn-smith,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/157,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTk0NTgzNTM=,improve alignment error handling in kernel,OPEN,2019-09-27T13:50:12Z,2019-09-27T13:50:12Z,,"In CUDA aligner, some times valid inputs can lead to errors in processing e.g. when the hirschberg processing stack is full. We should have an error handling mechanism which reports when certain alignments could not be processed correctly so they can be reported back to the caller.


Specific case - cudaaligner/src/hirschberg_myers_gpu.cu has a `printf(ERROR: Stack full)` case.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/159,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MDA3NDI2NDk=,python build fails when Doxygen not present,CLOSED,2019-10-01T08:29:47Z,2019-10-01T14:56:57Z,2019-10-01T14:56:56Z,"When setup.py first runs `cmake` it is noted that:

```-- Could NOT find Doxygen (missing: DOXYGEN_EXECUTABLE)
-- Doxygen not found. Doc gen disabled.
```

but the subsequent `cmake --build ... docs install` call fails.",cjw85,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/162,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MDI1MDQxNjU=,[cudapoa]  Lost lines in MSA output,CLOSED,2019-10-04T08:33:17Z,2019-11-01T00:39:04Z,2019-11-01T00:39:04Z,"In the example `pyclaragenomics/samples/sample_cudapoa`, the maximum sequences per poa is specified as 100, though the outputs are only 99 long. Changing the maximum sequences to 50, results in outputs of length 49. In appears that it is the final input sequence that is lost.",cjw85,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/169,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MDI1MTE0MTA=,[cudapoa] Expose compile-time constants as parameters,CLOSED,2019-10-04T08:49:21Z,2020-04-10T21:03:10Z,2020-04-10T21:03:10Z,There are several constants defined in `cudapoa_kernels.cuh` which control various maximum sizes of graph properties. It would be useful to vary these at runtime.,cjw85,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/170,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MDI1MTQ4MzI=,[cudapoa] CudaPoaBatch.get_msa() incorrectly reports success on failure with large inputs,CLOSED,2019-10-04T08:56:26Z,2019-11-05T16:20:15Z,2019-11-05T16:20:15Z,"The results of at least the python binding can be unexpected when the maximum MSA width is surpassed (default 1024 from `cudapoa_kernels.cuh`). Ive observed the status be reported as 0 but the results be slightly mangled.

For example Ive input 70 sequences of ~660bases, the status is 0, and the lengths of the strings returned for the MSA are not equal (often the first being longer than the rest). Taking a one/a few bases away from the inputs gives MSA lines uniformly of length 1023.",cjw85,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/171,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MDI1MzkwMTE=,[cudamapper] Number of overlaps generated has dependency on `index_size`,OPEN,2019-10-04T09:47:18Z,2019-10-04T09:47:18Z,,"A regression appears to have been introduced whereby whatever `index_size` variable is set to affects the number of overlaps comptued. This results in very small differences between the number of overlaps detected prior and after read-level chunking. Example:

```wc -l res_*
   899904 res_new.out
   899973 res_old.out```
```

This is likely to be an off-by-one error at some point in the read-level chunking",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/172,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MDI5NTkzNDI=,Setting the cuda toolkit location with PyClaraGenomics,CLOSED,2019-10-05T12:49:13Z,2019-10-06T20:58:33Z,2019-10-06T20:58:33Z,"It would be useful to override the `CUDA_TOOLKIT_ROOT_DIR` when building the Python bindings. The patch below passes the environment variable `CUDA_TOOLKIT_ROOT_DIR` to CMake if it is set, let me know if you want a P.R for this.

```diff
--- a/pyclaragenomics/setup.py
+++ b/pyclaragenomics/setup.py
@@ -35,6 +35,7 @@ class CMakeWrapper():
         self.cmake_root_dir = os.path.abspath(cmake_root_dir)
         self.cmake_install_dir = os.path.join(self.build_path, ""install"")
         self.cmake_extra_args = cmake_extra_args
+        self.cuda_toolkit_root_dir = os.environ.get(""CUDA_TOOLKIT_ROOT_DIR"")
 
     def run_cmake_cmd(self):
         cmake_args = ['-DCMAKE_INSTALL_PREFIX=' + self.cmake_install_dir,
@@ -42,6 +43,9 @@ class CMakeWrapper():
                       '-DCMAKE_INSTALL_RPATH=' + os.path.join(self.cmake_install_dir, ""lib"")]
         cmake_args += [self.cmake_extra_args]
 
+        if self.cuda_toolkit_root_dir:
+            cmake_args += [""-DCUDA_TOOLKIT_ROOT_DIR=%s"" % self.cuda_toolkit_root_dir]
+
         if not os.path.exists(self.build_path):
             os.makedirs(self.build_path)
```
",iiSeymour,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/175,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MTAxNTU4ODM=,Remove Ubuntu dependency,CLOSED,2019-10-21T17:45:45Z,2019-10-28T12:54:55Z,2019-10-28T12:54:55Z,"On Linux distributions which aren't Ubuntu or CentOS, building the source code fails with the 'unrecognized distro' fatal error. This error occurs in Packaging, which is not relevant to building the rest of the code to use on a given machine and should not block this.",kellyrowland,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/193,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MTA4MjM2NzA=,[common] fasta file I/O performance,OPEN,2019-10-22T18:14:05Z,2019-10-22T18:14:05Z,,"Look into other libraries to improve fasta file I/O performance.
Eric suggested https://github.com/cartoonist/kseqpp",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/195,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MTc2NzI2Njg=,[common] Option to disable doc build,CLOSED,2019-11-05T10:08:38Z,2019-11-13T00:28:34Z,2019-11-13T00:28:34Z,"Please add an option `cga_build_documentation` (or similar) to the cmake options, such that you can opt-out of building the documentation.

Right now the documentation is built if cmake finds doxygen and I'm not aware of any way to turn it off.",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/205,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MTgwODE0MzI=,[CI] Add support for executing gpuCI tests locally through nvidia-docker,CLOSED,2019-11-05T22:13:10Z,2019-11-13T15:39:05Z,2019-11-13T15:39:05Z,Follow https://github.com/rapidsai/cudf/tree/branch-0.11/ci/local,ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/206,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjMwMzI4MDE=,[cudapoa] Add alignment checks to cudapoa host allocation,OPEN,2019-11-14T18:34:37Z,2019-11-14T18:34:37Z,,Right now cudapoa host allocations don't take into account alignment of datatype like uint16_t. This can lead to problems if the offset becomes odd at any point (till now avoided because sizes are all even),tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/215,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjQ1NzE0NzU=,[cudamapper] cub cmake setup,CLOSED,2019-11-18T19:29:54Z,2020-05-07T15:02:42Z,2020-05-07T15:02:41Z,The usage of `cub` in CMake can be improved by making the `cub` folder an interface target (similar to what we have to the `utils` folder).,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/218,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjQ5MjYwMjQ=,[cudaaligner] Mismatch in formatted alignment when running sample,CLOSED,2019-11-19T10:45:12Z,2019-12-07T21:04:37Z,2019-12-07T21:04:36Z,"Steps to reproduce:
- Fetch pull request #219 changes. 
- Build CGA and run 'sample_cudaaligner -p'
- The pairing string does not correspond to the query & target strings.

@tijyojwad reported that when setting query length to 50 and target length to 60 in the sample, then alignments come out fine. But when increasing those to 100 and 110 respectively, then the issue arises.",ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/220,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjUxNDQ2NTY=,[cudamapper] re-architected indexer and matcher,CLOSED,2019-11-19T17:08:47Z,2019-11-27T19:05:16Z,2019-11-27T19:05:16Z,Indexer and matcher re-architected to be a shared component to remove a GPU -> CPU -> GPU copy between the two stages.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/221,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjUxNDYwNzY=,[cudamapper] optimize overlapper,CLOSED,2019-11-19T17:11:25Z,2019-12-23T23:27:55Z,2019-12-23T23:27:55Z,Optimize the overlapper in cudamapper to keep anchors generated from matcher in GPU memory when finding overlaps. Also port the overlap detection algorithm to GPU completely.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/222,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjUxNDcyMzc=,[cudamapper] add better hash function for minimizer,CLOSED,2019-11-19T17:13:33Z,2019-11-19T17:14:04Z,2019-11-19T17:14:04Z,Add a better hashing function for the minimizers so that minimizers within a window are better distributed.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/223,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjUxNTQxNzk=,"[CI] PR tests are marked as pass, even if unit tests fails",CLOSED,2019-11-19T17:26:20Z,2019-11-20T14:19:54Z,2019-11-20T14:19:54Z,"It was observed in https://github.com/clara-genomics/ClaraGenomicsAnalysis/pull/216.

If we take a look at the details of gpuCI/clara-genomics-analysis/gpu-test/ubuntu18.04-cuda10.1:
https://gpuci.gpuopenanalytics.com/blue/organizations/jenkins/clara-genomics%2Fgpuci%2Fclara-genomics-analysis%2Fprb%2Fclara-genomics-analysis-gpu-build/detail/clara-genomics-analysis-gpu-build/342/pipeline
We can see that some of the unit tests fail.
",ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/224,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjcyMDc3NzQ=,[pyclaragenomics] libcudapoa.so not found after sucessful build,CLOSED,2019-11-22T13:53:10Z,2019-11-22T18:38:18Z,2019-11-22T18:38:18Z,"After building `pyclaragenomics` and running `sample_cudapoa` the following error is thrown.

> ImportError: libcudapoa.so: cannot open shared object file: No such file or directory

Build log -

```bash
$ python setup_pyclaragenomics.py --build_output_folder build/
-- Building ClaraGenomicsAnalysis libraries as shared objects
-- Using CUDA 10.1 from /usr/local/cuda-10.1
-- Build type: Release
-- Package generator - DEB
-- Using CUDA 10.1 from /usr/local/cuda-10.1
-- Enabling Doxygen documentation generation
-- Could NOT find Doxygen (missing: DOXYGEN_EXECUTABLE) 
-- Doxygen not found. Doc gen disabled.
-- clang-format not found. Auto-formatting disabled.
-- Configuring done
-- Generating done
-- Build files have been written to: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build
[  9%] Built target cudamapper_utils
[  9%] Built target cgaio
[ 13%] Built target logging
[ 15%] Linking CXX static library libminimizer.a
[ 17%] Linking CXX shared library libcudapoa.so
[ 19%] Linking CXX shared library libcudaaligner.so
[ 21%] Linking CXX static library libmatcher_gpu.a
[ 23%] Linking CXX static library libmatcher.a
[ 25%] Linking CXX static library liboverlapper_triggerred.a
[ 26%] Built target minimizer
[ 28%] Built target matcher_gpu
[ 30%] Built target matcher
[ 32%] Built target overlapper_triggerred
[ 34%] Linking CXX static library libindex_gpu.a
[ 36%] Linking CXX static library libindex_gpu_two_indices.a
[ 42%] Built target index_gpu
[ 51%] Built target cudapoa
[ 59%] Built target index_gpu_two_indices
[ 61%] Linking CXX executable sample_cudapoa
[ 82%] Built target cudaaligner
[ 84%] Linking CXX executable sample_cudaaligner
[ 86%] Linking CXX executable cudamapper
[ 88%] Built target sample_cudapoa
[ 90%] Built target sample_cudaaligner
[100%] Built target cudamapper
Install the project...
Install the project...
-- Install configuration: ""Release""
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/lib/liblogging.so
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/logging
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/logging/logging.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/logging.cmake
-- Installing: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/logging-release.cmake
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/device_buffer.cuh
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/cudautils.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/stringutils.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/genomeutils.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/graph.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/mathutils.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/cudaversions.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/limits.cuh
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/signed_integer_utils.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/utils.cmake
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/lib/libcgaio.so
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/io
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/io/fasta_parser.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cgaio.cmake
-- Installing: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cgaio-release.cmake
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/lib/libcudapoa.so
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudapoa
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudapoa/cudapoa.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudapoa/batch.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cudapoa.cmake
-- Installing: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cudapoa-release.cmake
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/benchmarks/cudapoa/README.md
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/samples/sample_cudapoa
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/bin/cudamapper
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cudamapper.cmake
-- Installing: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cudamapper-release.cmake
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/lib/libcudaaligner.so
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudaaligner
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudaaligner/alignment.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudaaligner/cudaaligner.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudaaligner/aligner.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cudaaligner.cmake
-- Installing: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cudaaligner-release.cmake
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/benchmarks/cudaaligner/README.md
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/samples/sample_cudaaligner
Processing /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics
Building wheels for collected packages: pyclaragenomics
  Building wheel for pyclaragenomics (setup.py) ... done
  Created wheel for pyclaragenomics: filename=pyclaragenomics-0.3.0-cp36-cp36m-linux_x86_64.whl size=494354 sha256=42b9d0e80d2cea78ab6f539771d3f2e2ec9043b5f4a742c3151224f2856c54da
  Stored in directory: /tmp/pip-ephem-wheel-cache-mcsgz45e/wheels/f2/90/27/0a912d86c66c3b8fc0e1b1bb30b233fe9bff7063c960a64c1f
Successfully built pyclaragenomics
Installing collected packages: pyclaragenomics
  Found existing installation: pyclaragenomics 0.3.0
    Uninstalling pyclaragenomics-0.3.0:
      Successfully uninstalled pyclaragenomics-0.3.0
Successfully installed pyclaragenomics-0.3.0
pyclaragenomics was successfully setup in installation mode!
```

Putting `build/install/lib` on the `LD_LIBRARY_PATH` results in `sample_cudapoa` running successfully. 

```bash
$ python samples/sample_cudapoa
Traceback (most recent call last):
  File ""samples/sample_cudapoa"", line 17, in <module>
    from claragenomics.bindings import cuda
ImportError: libcudapoa.so: cannot open shared object file: No such file or directory
$ LD_LIBRARY_PATH=./build/install/lib/ python samples/sample_cudapoa 
Processed group 0 - 999
```

Extra Info -

os - Ubuntu 16.04
branch - dev-v0.4.0
commit - 226834941d9ff7b3f0219ec17a1acdde1fe0fb29",iiSeymour,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/230,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1Mjc2ODYyMjk=,[pyclaragenomics] Generate a Python wheel for pyclaragenomics,CLOSED,2019-11-24T11:45:48Z,2019-11-27T23:18:55Z,2019-11-27T23:18:55Z,,ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/237,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1Mjg4NTM5MDE=,[pyclaragenomics] Improve setup script support for generating wheel package,CLOSED,2019-11-26T16:57:20Z,2019-11-27T23:18:56Z,2019-11-27T23:18:56Z,"As discussed in PR #238 comments:
1. Use data_files instead of package_data.
2. Copy the shared libraries in setup.py and not in setup_pyclaragenomics.py
3.  generate a wheel using pip command",ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/240,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MzAxMDk2ODI=,[pyclaragenomics] Python 3.5 wheels not on PyPi,CLOSED,2019-11-29T00:47:13Z,2019-11-29T22:01:23Z,2019-11-29T22:01:23Z,"Hey Guys, Thank you for sorting out wheels, it's a huge help. I can successfully install the 3.6 wheels with pip but I don't think the 3.5 wheels are on PyPi.

```bash
(venv3.5) $ python --version
Python 3.5.2
(venv3.5)  $ pip show pyclaragenomics-cuda10-1
WARNING: Package(s) not found: pyclaragenomics-cuda10-0
(venv3.6) $ python --version
Python 3.6.8
(venv3.6) pip show pyclaragenomics-cuda10-1
Name: pyclaragenomics-cuda10-1
Version: 0.4.0
Summary: NVIDIA genomics python libraries and utiliites
Home-page: https://github.com/clara-genomics/ClaraGenomicsAnalysis
Author: NVIDIA Corporation
Author-email: None
License: Apache License 2.0
Location: .../venv3.6/lib/python3.6/site-packages
Requires: quast, numpy, flake8, networkx, matplotlib, pytest, tqdm, Cython, sortedcollections
Required-by: 
```",iiSeymour,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/247,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MzI3NTE3MTA=,[cudamapper] Filter out most common representations,CLOSED,2019-12-04T15:17:28Z,2019-12-11T09:19:06Z,2019-12-11T09:19:06Z,Implement a functionality which lets the user pass a `filtering_parameter` and then in each index remove all sketch elements with representations such that `number_of_sketch_elements_with_that_representation_in_that_index/total_number_of_sketch_elements_in_that_index >= filtering_parameter`,mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/254,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MzQ0NTIxNjg=,[sdk] add htslib as submodule,CLOSED,2019-12-07T21:00:03Z,2020-04-10T20:32:02Z,2020-04-10T20:32:01Z,add htslib as submodule to tie to specific version for stability,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/261,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NDA1NTU3MTU=,[cudamapper] Optimize sorting in overlapper,CLOSED,2019-12-19T20:46:29Z,2020-02-17T15:04:05Z,2020-02-17T15:04:05Z,"cudamapper spends most of its execution time doing sorting at the beginning of the `Overlapper`. This is because `Matcher` groups anchors by representation and `Overlapper` needs them to be grouped by pairs of query and target read_ids

Think of a way to avoid this sort and harmonize the interface between `Matcher` and `Overlapper`.

Alternatively look for ways to reduce the sorting time.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/265,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NDYxOTcyMDM=,[cudamapper] data race in cudamapper,CLOSED,2020-01-07T10:14:42Z,2020-01-08T12:25:54Z,2020-01-08T11:01:13Z,"There is a data race in cudamapper's main.cu, which may result in an out-of-bound read

When the atomic variable `ranges_idx` is `query_target_ranges.size()-1`, two (or more) threads may enter the loop
https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/67ff96c80bc7fcce589c2af83d93e73bfc7015f4/cudamapper/src/main.cu#L306
before one of the threads increments `ranges_idx` in next line:
https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/67ff96c80bc7fcce589c2af83d93e73bfc7015f4/cudamapper/src/main.cu#L308
For the other thread(s) entering the loop, this will result in a `range_idx` value >= `query_target_ranges.size()` and result in an out-of-bound memory access in line
https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/67ff96c80bc7fcce589c2af83d93e73bfc7015f4/cudamapper/src/main.cu#L312",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/272,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NDkxNDcyMzA=,[pyclaragenomics] add native namespace packaging to cga,CLOSED,2020-01-13T19:55:43Z,2020-04-10T20:36:03Z,2020-04-10T20:36:03Z,"Update pcga to use native namespace packaging to allow multiple clara genomics repos to share the same namespace

https://packaging.python.org/guides/packaging-namespace-packages/#native-namespace-packages",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/275,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NDkxNDc4MDE=,[cudaaligner] add banding to Myers global alignment,CLOSED,2020-01-13T19:56:57Z,2020-04-17T15:26:19Z,2020-04-17T15:26:19Z,Add banding support to myers bit vector global alignment implementation,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/276,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NDkxNDkyMTE=,[sdk] add cached CUDA allocator,CLOSED,2020-01-13T19:59:57Z,2020-02-10T22:39:39Z,2020-02-10T22:39:39Z,Cached CUDA allocated in CGA to optimize device allocations,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/277,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NTAzODgwNzE=,[CI][pyclaragenomics] Build artifacts distribution,CLOSED,2020-01-15T19:37:39Z,2020-05-04T22:02:25Z,2020-05-04T22:02:25Z,"1. As part of adding a nightly build job, we would like the artifacts(wheel/conda packages) created in that job to be uploaded to PyPI directly. An issue was raised for the rapids ops team to support this:
https://github.com/rapidsai/ops/issues/618
1.1 Once this job is up and running, we will need our PyPI credentials to be configured as environment variables and add the upload commands to the build script. 

2. We would like the tests to be focused on the GPU, the modified test cases should be  as described in https://github.com/rapidsai/ops/issues/617 & https://github.com/rapidsai/ops/issues/618#issuecomment-573852496

",ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/278,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NTcwNjM2ODQ=,[cudamapper] gaps between GPU kernels in cudamapper,CLOSED,2020-01-29T19:20:03Z,2020-02-26T14:50:06Z,2020-02-26T14:50:06Z,profiling cudamapper indicates some gaps between GPU kernels caused by CPU blocking calls. The causes of these gaps need to be identified and resolved where applicable. ,r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/286,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NjE0NDcyMTY=,About BM_SingleBatchAlignment,CLOSED,2020-02-07T06:28:51Z,2020-03-28T05:27:49Z,2020-03-28T05:27:49Z,May I know more information about `BM_SingleBatchAlignment<AlignerGlobalUkkonen>/256/4096`? What are those 2 numbers?,mahmoodn,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/289,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NjMwNjA4NjA=,[cga] Centralize compilation flags,CLOSED,2020-02-11T09:05:10Z,2021-02-12T23:00:34Z,2021-02-12T23:00:34Z,"Currently every module defines its own compilation flags. In some cases this is the wanted behavior, but in others (C++ standard, warning level..) it causes confusion.

Think about which flags should be set for the whole SDK.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/291,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NjUzNzU5Njc=,[cga] Adapt custom allocator and buffer to be more in line with STL,CLOSED,2020-02-14T14:54:32Z,2020-02-25T08:23:08Z,2020-02-25T08:23:08Z,"DeviceAllocator should have `T* DeviceAllocator<T>::allocate()` instead of `void* DeviceAllocator::allocate()`. This is required in order to use DeviceAllocator for internal temporary arrays in Thrust's algorithms.
Doing so will enable us to allocate more memory for caching allocator and also reduce time Thrust spends allocating temporary arrays.

This requires substantial changes to design and adaptation of existing usages of `device_buffer` in cudamapper",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/292,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzA3MzI4MTQ=,[pyclaragenomics] Increase the maximum sequence length limit,CLOSED,2020-02-25T17:43:15Z,2020-07-01T14:37:19Z,2020-07-01T14:37:19Z,"The 1,000 base limit with POA interface makes it quite restrictive for long-read applications and I've only been able to use it for proof of concept ideas. It would great to see this limit removed.",iiSeymour,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/299,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzQ2NTY4NTE=,[cudamapper] Implement multi-layered cache,CLOSED,2020-03-03T13:09:44Z,2020-03-03T17:41:09Z,2020-03-03T17:41:09Z,Host cache currently starts filling at the same time as device cache. therefore if cudamapper is run with the arguments `-c 10 -C 10` host RAM is used but host cache is not used. If cudamapper is run with the arguments `-c 10 -C 15` effective host cache is 5 indices since for the first 10 indices device cache is always used for reads. Host cache should only be invoked when device cache is full.,vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/302,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzQ2OTc2Mjc=,[cudamapper] segfault when running with multi GPU,CLOSED,2020-03-03T14:14:13Z,2020-06-09T19:57:23Z,2020-06-09T19:57:23Z,"Running with multi-GPU on any sizeable dataset (e.g 20k human ONT reads) is resulting in a segfault:

```
time /home/mike/dev/ClaraGenomicsAnalysis/cmake-build-release/cudamapper/cudamapper /data/20k_reads_shuffled-chrX.fasta /data/20k_reads_shuffled-chrX.fasta -i 30 -w 5 -k 15 -c 30 -F 1e-5 -d 2 > out 

NOTE - Since query and target files are same, activating all_to_all mode. Query index size used for both files.
Query /data/20k_reads_shuffled-chrX.fasta index 20000
Target /data/20k_reads_shuffled-chrX.fasta index 20000
Processing query range: (0 - 1116)
Processing query range: (1117 - 2230)
Processing query range: (2231 - 3257)
Processing query range: (3258 - 4370)
Processing query range: (4371 - 5444)
Processing query range: (5445 - 6539)
Processing query range: (6540 - 7597)
Processing query range: (7598 - 8664)
Processing query range: (8665 - 9710)
[2]    5992 segmentation fault (core dumped)  /home/mike/dev/ClaraGenomicsAnalysis/cmake-build-release/cudamapper/cudamappe
/home/mike/dev/ClaraGenomicsAnalysis/cmake-build-release/cudamapper/cudamappe  36.29s user 4.13s system 531% cpu 7.611 total
```",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/304,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzQ3ODY1OTI=,[cudamapper] `CachingDeviceAllocator` causing segfault when running with multi-GPU and cache eviction.,CLOSED,2020-03-03T16:25:28Z,2020-03-05T15:00:59Z,2020-03-05T15:00:59Z,"When running with multiple GPUs, a segfault is resulting if CGA is compiled with the flag `-Dcga_enable_allocator=ON`

Command I am running with: `cudamapper /data/20k_reads_shuffled-chrX.fasta /data/20k_reads_shuffled-chrX.fasta -i 30 -w 5 -k 15 -c 30 -F 1e-5 -d 2 >out`

Interestingly, if [device-side cache eviction](https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/dev-v0.5.0/cudamapper/src/main.cu#L351) is disabled, the segfault disappears.

When compiling with  `-Dcga_enable_allocator=OFF` there is no segfault.

Stderr:

```
 time /home/mike/dev/ClaraGenomicsAnalysis/cmake-build-release/cudamapper/cudamapper /data/20k_reads_shuffled-chrX.fasta /data/20k_reads_shuffled-chrX.fasta -i 30 -w 5 -k 15 -c 30 -F 1e-5 -d 2 > out
NOTE - Since query and target files are same, activating all_to_all mode. Query index size used for both files.
Query /data/20k_reads_shuffled-chrX.fasta index 20000
Target /data/20k_reads_shuffled-chrX.fasta index 20000
Processing query range: (0 - 1116)
Processing query range: (1117 - 2230)
Processing query range: (2231 - 3257)
Processing query range: (3258 - 4370)
Processing query range: (4371 - 5444)
[2]    28589 segmentation fault (core dumped)  /home/mike/dev/ClaraGenomicsAnalysis/cmake-build-release/cudamapper/cudamappe
/home/mike/dev/ClaraGenomicsAnalysis/cmake-build-release/cudamapper/cudamappe  21.83s user 2.21s system 353% cpu 6.806 total
```",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/306,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzUwOTExNzc=,[cudamapper] remove self-mapped reads,CLOSED,2020-03-04T02:28:19Z,2020-03-06T23:46:07Z,2020-03-06T23:46:07Z,Self-mapped reads should be filtered out by GPU filtering.,vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/308,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzUwOTIxODg=,[cudamapper] no useful error message when cudamapper pointed to non-existent file.,CLOSED,2020-03-04T02:29:47Z,2020-04-01T15:42:25Z,2020-04-01T15:42:25Z,"A useful error is needed. Right now application does not crash but ends with:

```
Processing query range (0 - -1)
```",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/309,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzUzNTU3MzU=,[cudamapper] code clean-up related to fuse_overlaps,CLOSED,2020-03-04T12:17:06Z,2020-06-25T18:50:32Z,2020-06-25T18:50:32Z,"there are some files and tests associated with deprecated `fuse_overlaps` function. Assuming `fuse_overlaps` is no longer used, they can be removed.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/311,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzU1MTMwNTA=,[cudapoa] make max sequence and graph size configurable,CLOSED,2020-03-04T15:39:44Z,2020-04-08T01:56:08Z,2020-04-08T01:56:08Z,currently the max sizes for sequence and graph are all hard coded based on empirical observations while running racon. these should instead of parameters passed during construction of the cudapoa batch object.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/312,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzY0MDgzNDk=,[cga] Implement preallocating device allocator,CLOSED,2020-03-05T17:14:36Z,2020-03-09T15:57:34Z,2020-03-09T15:57:34Z,"(De)allocating device memory is expensive. We are currently using `cub::CachingDeviceAllocator` which caches smaller array (see #277), but large arrays (> 500MB) are still being constantly allocated and deallocated.

Implement an allocator which allocates a big chunk of device memory in the beginning and then assigns parts of it, meaning it only has to allocate device memory once in the beginning and deallocate it once at the end",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/315,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzY0MjQwOTM=,[cudamapper] Have all work for one iteration in one stream,CLOSED,2020-03-05T17:42:09Z,2020-03-12T09:51:10Z,2020-03-12T09:51:10Z,"Currently different kernels of one query - target read pair (iteration) use different streams without a specific need for that.

Make all kernels of one iteration use the same stream. This will
- prevent possible bugs due to incorrectly synchronized streams
- enable us to to use stream sync deallocations in caching allocators
- make it easier to overlap fetching indices from host cache with matcher-overlapper calculations
- make the profiles cleaner",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/317,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzY0MjY2NjM=,[cudamapper] Overlap fetching indices from host memory with matcher+overlapper,CLOSED,2020-03-05T17:46:54Z,2020-10-22T14:37:45Z,2020-10-22T14:37:45Z,"Fetch new target index from host cache while matcher+overlapper work on current target index.

On current benchmarks fetching index from device cache takes approximately the same amount of time as doing mathcer + overlapper for it, so it makes sense to overlap those two activities.

Work on this issue can start after issue #317 has been done",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/318,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzY0MzA0OTk=,[cga] Implement host pool allocator,OPEN,2020-03-05T17:53:53Z,2020-03-05T17:53:53Z,,"Allocating/resizing some host arrays (e.g. when creating host copies of indices) takes a significant amount of time.

Implement host pool allocator.
Also evaluate the possibility of using implementations from Thrust 1.9.4 or C++17. Currently those do not look like viable options due minimally system requirements on CGA's side.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/319,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzgwNDQ0MTE=,[cudamapper] CIGAR integration,CLOSED,2020-03-09T16:46:39Z,2020-04-22T15:11:29Z,2020-04-22T15:11:29Z,"CIGAR part uses a custom stream and does not use `device_buffer`/preallocating allocator.

Revisit that implementation, identify necessary changes and implement them

See:
#307 
#313 
#316 
#318 
#320 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/321,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1Nzk0NTM3MjU=,[cudamapper] debug accuracy issues for drosophila,CLOSED,2020-03-11T18:12:15Z,2020-04-07T14:29:27Z,2020-04-07T14:29:27Z,,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/322,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1Nzk0NjEwOTc=,[cudamapper] add end2end binary run test,OPEN,2020-03-11T18:26:01Z,2020-05-06T15:41:33Z,,"Currently we only have unit tests for cudamapper, but nothing that runs the bianry on a dataset end to end. This should be added to gpuCI runs as well, for both single and multi GPU configurations",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/323,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1Nzk5NTg0NDc=,cudamapper does not fail with invalid input path,CLOSED,2020-03-12T13:58:49Z,2020-03-13T00:53:00Z,2020-03-13T00:53:00Z,"If you pass an invalid path as fasta input, cudamapper does not report any error.
(Instead it creates an empty index.)",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/324,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1ODM5NTA4ODE=,[cga] Automatically determine compute capability,CLOSED,2020-03-18T19:22:07Z,2020-03-23T19:53:53Z,2020-03-23T19:53:53Z,"Currently we are compiling for default compute capability (I believe sm_35).

For cudamapper one can specify higher compute capability by adding it to `CMakeLists.txt` (https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/317bce9591cc72285785e8bfc937ac149c44515c/cudamapper/CMakeLists.txt#L22), for example for Volta `-arch=compute_70 -code=sm_70`, but this is not a flexible solution. Setting the value manually brings significant improvements to cudamapper's performance.

Goal: Use `CUDA_SELECT_NVCC_ARCH_FLAGS` (https://cmake.org/cmake/help/v3.10/module/FindCUDA.html) to set this value per default. Ideally have it set on SDK level, but for now just cudammaper would work. I would suggest using `Auto` option, although I'm not sure how this works when using a machine without a GPU or building and packaging it.

Also see issue #291 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/326,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1ODgwMDQ2OTU=,[cudamapper] output overlaps in BAM,CLOSED,2020-03-25T21:33:32Z,2020-10-16T23:24:07Z,2020-10-16T23:24:07Z,Support output the overlaps in both PAF and BAM format. Similar to the `-a` option in `minimap2` (described in https://github.com/lh3/minimap2#general-usage),tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/335,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1ODkwNTM1Nzg=,Can not find cudaaligner executable after compiling,CLOSED,2020-03-27T11:01:58Z,2020-04-01T15:14:41Z,2020-04-01T15:14:41Z,"Hello,

I want to run `cudaaligner` but after compiling successfully I am unable to find the executable.
For instance, the `cudamapper` tool is found in the `../ClaraGenomicsAnalysis/build/install/bin` folder. However I have ran `find ../ClaraGenomicsAnalysis -name ""cudaaligner"" -executable -type f` and nothing shows. Can you please help? Thank you.
BTW: I am not running as sudo as I have no permissions",estebanpw,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/339,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1ODk1MzU2NTU=,[cudamapper] example API usage,CLOSED,2020-03-28T08:45:46Z,2020-07-24T17:48:41Z,2020-07-24T17:48:41Z,"Hi!

I really appreciated the example API usage for cudapoa and would like to ask for something similar for cudamapper.

Thanks!
Armin",armintoepfer,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/340,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1ODk4ODA3NDE=,performance drop-down related to CUDA_NVCC_FLAGS,CLOSED,2020-03-29T20:40:36Z,2020-07-08T17:53:12Z,2020-07-08T17:53:12Z,"cudapoa_benchmark seems to be ~10% slower which this line is added to `cmake/CUDA.cmake`:
`set(CUDA_NVCC_FLAGS ""${CUDA_NVCC_FLAGS} ${ARCH_FLAGS}"")`   ([link here](https://github.com/r-mafi/ClaraGenomicsAnalysis/commit/2b5d632fa66f5471b7ac3c27106af721bf4530a1#diff-d77f46a67237a37b9c4eae17e6a1b741R27))

![image](https://user-images.githubusercontent.com/59714522/77860190-c8459000-71db-11ea-919d-fe9b20d54557.png)

",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/341,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTEyMTM5ODU=,[cudaaligner] add cudaaligner binary for pairwise global alignment,OPEN,2020-03-31T15:42:54Z,2020-03-31T15:43:23Z,,"A binary to compute pairwise alignment for a set of inputs

Example - Emboss needle app

Raised by @estebanpw in #339 ",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/345,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTE5MzQ3NTk=,unexpected behavior in cudautils::align,CLOSED,2020-04-01T13:53:12Z,2020-04-14T05:57:10Z,2020-04-14T05:57:10Z,"`cudautils::align<int32_t, 4>` function makes any input a divisible by 4, if it is already divisible by 4, it still adds 4, e.g. `align<int32_t, 4>(1023) = 1024`, `align<int32_t, 4>(1024) = 1028` or `align<int32_t, 4>(0) = 4`. This seems a bit unexpected, we probably do not need to change an input which is already divisible by 4 in this example.

Note: if this behavior changes, `claragenomics::cudapoa::BatchSize` constructors needs to get modified as well, since it is defined based on this current behavior.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/346,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTE5OTI3MTM=,[cudamapper] read to reference mapping capability,CLOSED,2020-04-01T15:12:06Z,2021-01-26T16:56:06Z,2021-01-26T16:56:06Z,Add support for read to reference mapping to `cudamapper`. Initially assigning to @vellamike ,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/349,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTY3MDA5NzE=,[cudamapper] package cudamapper components into libcudamapper,CLOSED,2020-04-08T16:20:27Z,2020-04-20T13:28:59Z,2020-04-20T13:28:59Z,"Current cmake structure create separate private libs for indexer, matcher and overlapper. Would be good to combine all of them into a single `libcudamapper` object that the `cudamapper` application links against.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/352,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTc0OTg0Mzc=,[cudaaligner] use device_copy_n,OPEN,2020-04-09T19:18:58Z,2020-04-09T19:18:58Z,,"cudaaligner uses many `cudaMemcpy`, many (if not all) can be replaced with `device_copy_n`.",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/355,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTc2NTQ3NTM=,[cudapoa] expose configurable cudapoa sizes to python API,CLOSED,2020-04-10T02:14:17Z,2020-04-29T15:13:31Z,2020-04-29T15:13:31Z,Update cudapoa python API to expose variable sizes for sequences and graphs ,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/356,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTgwNzIzMTY=,[cudapoa] Remove `exceeded_batch_size` error,CLOSED,2020-04-10T20:14:43Z,2020-05-04T18:10:06Z,2020-05-04T18:10:06Z,"There's a redundancy in error codes in `cudapoa` when it comes to max POAs. POAs can be limited either by the heuristic calculation that accounts for max possible POAs, and also by how much space is left for the scoring matrices. These two currently return different error codes if surpassed, whereas semantically they're the same (i.e. limit how many POAs can be processed in a batch), so they should return the same error.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/358,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDA0MTk4MzE=,[cga] Move cgalogging and cgaconfig to libcgabase,CLOSED,2020-04-15T16:14:03Z,2020-04-20T13:25:27Z,2020-04-20T13:25:27Z,PR #359 introduces `libcgabase`. `cgalogging` and `cgaconfig` should also be part of it.,mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/369,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDQ4NTU1OTc=,[cudaaligner] reduce memory footprint of banded myers implementation,CLOSED,2020-04-22T15:36:49Z,2020-08-04T14:24:25Z,2020-08-04T14:24:25Z,Reduce the memory requirements for banded Myers implementation to fit more alignments per batch,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/380,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDQ4NjQ0ODY=,[pyclaragenomics] Add python API for cudamapper components ,OPEN,2020-04-22T15:49:00Z,2020-04-22T15:49:00Z,,"Add python bindings for `cudamapper` components - `indexer`, `matcher` and `overlapper`",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/381,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDQ4NjUxNzc=,[cudamapper] generate shared library for cudamapper,OPEN,2020-04-22T15:50:00Z,2020-04-22T15:50:00Z,,Currently only a static `cudamapper` library is generated. Add support for shared library generation as well. A prerequisite for #381 ,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/382,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUwMTQxNTA=,[README] PyPI pycga link broken in README,CLOSED,2020-04-22T19:37:11Z,2020-04-22T22:52:18Z,2020-04-22T22:52:18Z,The link on the `pyclaragenomics` readme that points to the PyPI packages is broken. This needs to be merged to master,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/385,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUwMTcwMDY=,[pyclaragenomics] upload pyclaragenomics API documentation,CLOSED,2020-04-22T19:41:49Z,2020-08-31T14:14:38Z,2020-08-31T14:14:38Z,publish pyclaragenomics API documentation to public location,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/386,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUwOTg2NDI=,[cudapoa] Automatic selection for max_sequence_size and max_sequences_per_poa,CLOSED,2020-04-22T21:52:54Z,2020-12-02T15:59:15Z,2020-12-02T15:59:15Z,"Currently cudapoa requires user input to define maximum sequence size as well as maximum number of sequences per POA. In other words, considering a window of reads, its width and height should be defined by the user. A conservative choice of these parameters can result in sub-optimal memory usage, and potentially reducing GPU occupancy. An optimal value for these parameters can be extracted based on input data.

The initial motivation for the current implementation was to reuse allocated buffers between multiple iterations. But using pre-allocated buffers, we should be able to compute batch size dynamically and more optimally.

This is a suggestion to allow automatic selection of  `max_sequence_size` and `max_sequences_per_poa` after integrating pre-allocated buffers in cudapoa.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/390,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUxMzIxMTI=,[cudapoa] Reconcile cudapoa BatchSize API between C++ and Python,OPEN,2020-04-22T23:16:40Z,2020-04-22T23:16:40Z,,"Python API takes in several params as optional, but C++ API only exposes 2 constructors. That means if only some optional args are provided in python API, the rest need to heuristically calculated on the python side. However, heuristics are already implemented on the C++ side and they may diverge over time. Feature request is to update C++ API so it's most seamless compatible with needs of the python API",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/391,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUxMzMzMjQ=,[pyclaragenomics] increase cudapoa test coverage,OPEN,2020-04-22T23:19:48Z,2020-04-22T23:23:10Z,,"Add more tests covering the following in pycga cudapoa - 

1. use of different output types
2. use of different values for alignment
3. use of custom sizes for sequence and graph sizes

and other parts of the API that are untested",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/392,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUxMzQyODg=,[common] Wrapping CUDA stream in another class to catch stream destruction,CLOSED,2020-04-22T23:22:24Z,2020-08-27T14:05:37Z,2020-08-27T14:05:37Z,,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/393,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUxMzUyMTg=,[cudamapper] investigate output minimap2 index from cudamapper,CLOSED,2020-04-22T23:24:56Z,2021-01-26T16:57:09Z,2021-01-26T16:57:08Z,minimap2 provides an `index` interface through the `minimap2 index` data structure. investigate if the data structure can be generated through cudamapper so it can plug into the minimap2 flow seamlessly.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/394,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDc2ODQ4MzA=,[cudapoa] keep member type and allocation size in sync,CLOSED,2020-04-27T16:29:39Z,2020-06-08T14:43:06Z,2020-06-08T14:43:06Z,"The way cudapoa allocates buffers right now is by calculating the size based on type of the struct elements. However, the sizing calculation uses the type explicitly instead of drawing it from the member element directly. This means the type has to be specified in two places, and more importantly updated in two places concurrently, which is the source of many problems.

It would be a good idea to use something like http://www.cplusplus.com/reference/typeinfo/type_info/name/ to keep the types in sync so they only need to be updated in one place.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/396,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDkxMDQ0MDY=,[cudapoa] Error code 8 on some cases of Bonito sample,CLOSED,2020-04-29T14:30:20Z,2020-05-11T15:26:59Z,2020-05-11T15:26:59Z,"In bonito sample dataset, for about 7 cases, generate consensus in `cudapoa` fails to run successfully. It exits with Error code 8. Would be helpful to investigate why it fails, whether it's a bug or not, and how to fix.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/398,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDkxMDY4MjE=,[common] remove CUB caching allocator,CLOSED,2020-04-29T14:33:38Z,2020-05-01T16:43:32Z,2020-05-01T16:43:32Z,"Since CUB caching allocator is not being actively used in the SDK and there are semantic differences in how the CUB and preallocator allocator APIs behave, we decided to remove the CUB allocator for now. If need be, it can be brought back from git history.

For some insight into CUB semantics issue, please see https://github.com/clara-genomics/ClaraGenomicsAnalysis/pull/379",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/399,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDkxNjM4NzM=,[gpuCI] enable CGA nightly tests,CLOSED,2020-04-29T15:48:30Z,2020-06-05T10:19:11Z,2020-06-05T10:19:11Z,Enable nightly tests for `master` and default `dev-vX.Y.Z` branch in CGA repo.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/402,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTA3OTk0MDU=,[cudapoa] add and use an error code for add_alignment,CLOSED,2020-05-01T15:09:22Z,2020-12-02T16:06:23Z,2020-12-02T16:06:23Z,"`addAlignmentToGraph` in `cudapoa_add_alignment.cu` returns an error code, but this error code is not used and not passed along to the caller functions.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/405,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTA3OTk4OTQ=,[cudapoa] add and use error code in addAlignmentKernel,CLOSED,2020-05-01T15:10:23Z,2020-05-01T15:11:30Z,2020-05-01T15:11:30Z,"`addAlignmentToGraph` in `cudapoa_add_alignment.cu` returns an error code, but this error code is not used and not passed along to the caller functions.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/406,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTE5MzYwNzc=,[cudapoa] Replace the usage of `void*` with templated args,CLOSED,2020-05-04T14:51:22Z,2020-06-15T03:52:04Z,2020-06-15T03:52:04Z,"https://github.com/clara-genomics/ClaraGenomicsAnalysis/pull/397 introduces functions that take in `void *` arguments in the kernel host wrappers. A restructuring of the source files in cudapoa can potentially remove this requirement as this is requiring duplication of logic in some files (i.e. heuristics to choose between different sizer types).

example attempt in https://github.com/tijyojwad/ClaraGenomicsAnalysis/tree/jdaw/template-structure-changes",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/407,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTIwOTA0Njc=,[cudamapper] Improve PAF generation,CLOSED,2020-05-04T18:49:53Z,2020-05-13T15:54:02Z,2020-05-13T15:54:02Z,"New implementation of index caching (#318) is bottlenecked by generation of strings for PAF files (not writing to files themselves). We currently copy read names and lengths into `Overlap` objects using `Overlapper::update_read_names()` and then use `Overlapper::print_paf()`.

Remove read name and length from `Overlap` object and parallelize `Overlapper::print_paf()` for better performance.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/410,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTI3NTI5NDM=,[cga] Support multiple streams in device_buffer and DevicePreallocatedAllocator,CLOSED,2020-05-05T16:57:36Z,2020-06-26T20:10:57Z,2020-06-26T20:10:57Z,"`DevicePreallocatedAllocator::DeviceAllocate()` currently accept `cudaStream_t`. `DevicePreallocatedAllocator::DeviceFree()` waits on that stream before actually deallocating memory in order to prevent the memory from being deallocated before all work that uses it is done.
In cases when the same buffer is used by two or more streams it is not possible to wait on all of them and the user has to make sure that all other streams have finished.

The goal it to support associating one allocation with multiple streams.

This should also be supported by `device_buffer`/`buffer`.

Consider using variadic template to pass one or more streams, store them in a `vector` internally and loop over them in `DevicePreallocatedAllocator::DeviceFree()`

This issue is part of issue #318 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/414,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTM0MjI3MTM=,[cudapoa] analyze accuracy of cudaPOA on long read data,CLOSED,2020-05-06T15:46:14Z,2020-05-19T02:56:32Z,2020-05-19T02:56:32Z,Need to evaluate the accuracy of cudaPOA consensus with long reads against CPU equivalent using Pomoxis metrics.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/416,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTQwODQ1Mzc=,[pycga] enable doc generation test for pyclaragenomics,OPEN,2020-05-07T14:04:27Z,2020-05-07T14:10:38Z,,Python doc generation only happens successfully when the bindings have been built. However the current sphinx command doesn't fail when bindings aren't built. This issue is to investigate the right way to build sphinx based documentation and enable it in the tests so doc generation is validated on every PR.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/419,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTU0MTgzNTI=,[SDK] rename SDK to GenomeWorks,CLOSED,2020-05-10T15:42:31Z,2020-06-26T17:34:48Z,2020-06-26T17:34:48Z,Description to be updated once final name of repo is decided,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/424,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTYwMDI3MDc=,[cudapoa] Re mixed usage of local and global index in banded NW,OPEN,2020-05-11T16:08:29Z,2020-05-11T16:08:29Z,,"In Banded NW in cudaPOA, there are some kernels such as `get_score()` or `set_score()` that accept column index both as local-index (cases such as [here](https://github.com/clara-parabricks/ClaraGenomicsAnalysis/blob/dev-v0.5.0/cudapoa/src/cudapoa_nw_banded.cu#L238), where 0 is passed for column index) or global-index.
It helps to avoid possible bugs and better maintenance of the code if we make a clear distinction between local and global indices, or simply unify the usage to one case.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/425,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTY3MDg4ODU=,[cudamapper] Move overlaps post-processing to GPU,OPEN,2020-05-12T14:36:37Z,2020-06-25T18:43:50Z,,"Currently `Overlapper::post_process_overlaps()` and new functionality to be added in PR #422 run on CPU. They should be moved to GPU.

There are two reason for that:
a) One matcher + overlapper iteration on our benchmark currently takes around 115ms (that number will likely be cut at least in half in the future) and generate 220k overlaps. If done on CPU those overlaps should ideally be post-processed during next matcher + overlapper iteration, giving around 0.5us to process each overlap. Even if we use multiple threads this will still not give us more than 3 - 5us per overlap.
b) Output generation is likely to move to GPU and for that we would need the overlaps to remain on device. Also, if we decide to pass the data directly to the next application in the pipeline we would also like to avoid having to copy the data back to host just to copy it back to device",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/428,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTczMjAyNzQ=,[common] Use int32_t for position_in_read_t and number_of_basepairs_t.,OPEN,2020-05-13T10:09:04Z,2020-05-13T10:09:04Z,,"In order to avoid mixing signed and unsigned arithmetic, we should make change the type of `position_in_read_t` and `number_of_basepairs_t` from `uint32_t` to `int32_t`.
This should not lead to any problems, as we don't expect reads larger than 2x10^9.",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/429,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTg1MTE2NzE=,[cudapoa] add cudapoa binary for generating msa or consensus,CLOSED,2020-05-14T20:22:08Z,2020-06-30T00:08:47Z,2020-06-30T00:08:47Z,"a binary that takes one or multiple fasta/text files as input and outputs consensus  or MSA or both.
Improving single-window performance is probably a prerequisite.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/431,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjA0OTc5MTI=,[CI] Support different image combinations for pull request branch and master/dev branch,OPEN,2020-05-18T20:50:34Z,2020-05-18T20:50:34Z,,,ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/433,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjA2NjYyNTQ=,[bindings] replace cython with SWIG for python bindings,CLOSED,2020-05-19T04:23:30Z,2020-12-04T16:25:02Z,2020-12-04T16:25:02Z,"Replace cython based python bindings generation with SWIG. 

Based on analysis by @rilango , SWIG provides more generic language extension framework and support multiple target languages such as python, Java, etc. Helpful in scaling CGA bindings to multiple languages through a single frameworks.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/435,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjE4NzY1NjY=,[cudapoa] increase bandwidth in banded cudapoa,CLOSED,2020-05-20T15:56:54Z,2020-05-27T20:14:48Z,2020-05-27T20:14:48Z,Current implementation of cudapoa banded uses a fixed band width of 128 elements. Investigate ways to increase the fixed band width.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/440,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjIxMjIwNTQ=,[cudapoa] adding PO-PO alignment,CLOSED,2020-05-20T22:26:00Z,2020-11-30T17:05:19Z,2020-11-30T17:05:19Z,"the current cudaPOA is mainly based on original POA algorithm [[POA 2002](https://doi.org/10.1093/bioinformatics/18.3.452)]. Same author in  another paper [[POA 2004](https://doi.org/10.1093/bioinformatics/bth126)] proposes an extension of the algorithm that allows aligning POA graphs to each other.
This extension is useful for polishing and MSA applications. It can increase cudaPOA parallelism and help to improve performance of MSA/consensus problems for a single window with large number of sequences.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/441,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjIxMjQyMDg=,[cudapoa] improve estimation of maximum graph length,CLOSED,2020-05-20T22:31:35Z,2020-12-02T16:25:38Z,2020-12-02T16:25:37Z,"POA graph length depends on the differences between multiple sequences in a window. As this difference can potentially grow by increasing the number of sequences in a window, we can modify heuristics to estimate the maximum graph length in `BatchSize` constructor to take this parameter into account. Using a fixed formula for maximum graph length can be wasteful in some cases and insufficient for some others.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/442,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjI0ODgzNjk=,[pycga] Pass arguments to setup.py from setup_pyclaragenomics.py directly,OPEN,2020-05-21T13:09:28Z,2020-05-21T14:28:51Z,,"Currently, we are passing these parameters as environment variables to the subprocess, they should be passed directly through pip. (see https://stackoverflow.com/a/49609956)",ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/443,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjU4MDE1MzY=,[cudapoa] error types in cudaPOA,CLOSED,2020-05-27T15:35:22Z,2020-12-04T00:55:54Z,2020-12-04T00:55:54Z,"There is no use of `StatusType::seq_len_exceeded_maximum_nodes_per_window` and can be removed.

On the same note, there is a subtle difference between maximum number of nodes per window and maximum graph dimension. The latter needs to be multiple of 4. We can remove `max_nodes_per_window` in `BatchSize` and only use `max_matrix_graph_dimension`. Same applies for banded version of the variables.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/446,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjY5MTIyNzM=,Install from source needed for dev functionality,CLOSED,2020-05-29T00:15:47Z,2020-08-05T14:58:48Z,2020-08-05T14:58:48Z,"In order to be able to run cudapoa, it is necessary to install the pyclaragenomics package from source. TODO: Updated documentation on this. ",rahulmohan,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/447,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MzAxNDQ0ODU=,[cudapoa] investigate adaptive banding in cudapoa,CLOSED,2020-06-03T16:29:07Z,2020-08-05T00:14:41Z,2020-08-05T00:14:41Z,design algorithm for adaptive banding suitable for cudapoa implementation.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/448,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MzE1OTY1NDA=,[cudamapper] Perform range-check on program arguments.,OPEN,2020-06-05T13:38:58Z,2020-06-05T13:38:58Z,,"cudamapper takes a series of program arguments parsed with `getopt_long`. For many arguments the program checks if the argument is within valid range, but not for all. Especially checks for negative values, which are invalid for most arguments, are missing.
We need to go through the arguments and make similar range checks for all arguments.
",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/451,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MzU4NDcyOTY=,[cudapoa] graph output in cudaPOA,CLOSED,2020-06-10T00:49:02Z,2020-12-02T15:44:42Z,2020-12-02T15:44:42Z,adding `.png` format to export POA graph for a given POA group can be useful. That is a convenient way to visualize pretty large graphs.,r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/454,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2Mzg0NjM5OTM=,[logging] remove spdlog as logger dependency,CLOSED,2020-06-15T00:29:27Z,2020-12-14T15:15:33Z,2020-12-14T15:15:33Z,"We have added a lot of hacks to support the logging library for CUDA < 10.0 because `spdlog` uses uninitialized constructors which doesn't play well with old `nvcc`. `spdlog` is also heavily based on templates, which means the library headers spill into the install folder of GenomeWorks, and hence requires `spdlog` to also be shipped in the `install` folder.

Best thing would be to remove `spdlog` as a logger library and instead use a simpler one for now which resolves all of these issues.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/459,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2Mzg0NjQyNDI=,[sdk] add CI for CUDA 11 and validate support,CLOSED,2020-06-15T00:30:49Z,2020-10-07T19:46:10Z,2020-10-07T19:46:10Z,Add a CUDA 11 Ubuntu 18.04 test to gpuCI for GenomeWorks,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/460,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2Mzg0NjQ0NjA=,[sdk] remove cuda 9.x support,CLOSED,2020-06-15T00:31:54Z,2020-12-04T21:44:05Z,2020-12-04T21:44:05Z,"After CUDA 11 support (issue #460) is officially added, remove explicit CUDA 9 support from SDK.
",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/461,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MzkyNTE3Mzk=,[cudapoa] toward DRY code by merging estimate_max_poas() and calculate_space_per_poa(),OPEN,2020-06-15T23:26:56Z,2020-06-15T23:26:56Z,,"`estimate_max_poas()` and `calculate_space_per_poa()` in `BatchBlock` class, share some similar logic and with some effort, they can be unified.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/466,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NDA1OTAxOTU=,[tests] upgrade CI harness scripts to be more robust,OPEN,2020-06-17T16:44:09Z,2020-06-17T16:44:09Z,,"Our CI scripts currently written in `bash`, and use a lot of env vars and positional arguments. But this setup is ripe for bugs and errors. It's important to upgrade the scripts to be more robust so our testing system itself doesn't silently break.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/469,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NDE1NzkzMjg=,Permission denied (publickey). fatal: Could not read from remote repository.,CLOSED,2020-06-18T22:11:16Z,2020-06-22T12:45:55Z,2020-06-22T12:45:55Z,"Error on executing the following command:
$ git clone --recursive git@github.com:clara-genomics/ClaraGenomicsAnalysis.git
Cloning into 'ClaraGenomicsAnalysis'...
git@github.com: Permission denied (publickey).
fatal: Could not read from remote repository.

Please make sure you have the correct access rights
and the repository exists.

Kindly recommend solution.
Thanks!
",SuchismitaSahu1993,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/470,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NDQ4MTE0MTM=,"[cudamapper] Default parameters should be hardened against many datasets / GPUs, match those of minimap2",CLOSED,2020-06-24T18:07:33Z,2020-07-13T16:23:58Z,2020-07-13T16:23:58Z,"Cudamapper is supposed to be a drop-in replacement for minimap2. Our default parameters, however, differ from those of minimap2. In addition, they seem to be unstable on many GPUs, causing crashes.

This is a major barrier to entry for users - they want the program to run to completion, even at the expense of performance.

Minimap2 defaults:
- [x] Minimizer kmer size: 15
- [x]  Minimizer window size: 10
- [x] Minimum number of minimizers in a chain: 3
- [x] Max distance between minimizers before chain is terminated: 5000
- [x] Minimum overlap size: <500
- [x] Minibatch size: 500M

Most of these can be addressed by either a single cudamapper parameter or a combination of multiple parameters. 

In the case of minibatch size, it's not so much about matching the number as it is about providing a stable CLI. I find I'm often having to tweak the `-I, -i, -q, -Q, -c, -C, -m` parameters to balance memory usage (e.g. to prevent out-of-memory errors) and performance. I think we should establish safe defaults for long reads on 8GB, 16GB and 32GB memory GPUs. Even though we programatically check for max preallocated memory we often seem to OOM due to index size parameterizations. My vote would be to prioritize stability and provide a one-pager on tuning for max performance (acknowledging the limits of each GPU considering maximum read size).
",edawson,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/471,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NDY5ODU1Mzg=,[pygw] reference to stream getting lost in CudaAlignerBatch object,OPEN,2020-06-28T19:01:58Z,2020-06-28T19:01:58Z,,"The reference to the stream object is getting lost somehow in CudaAlignerBatch object, because of which stream and batch are sometimes getting destroyed out of order. Explicit ref increment/decrement resolves the issue, but this should be handled by the automatic mechanism in python. This issue is to investigate why that's not working.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/476,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTAxOTgxMzA=,[cudapoa] cudapoa binary input options,CLOSED,2020-07-02T20:53:28Z,2020-11-30T16:56:00Z,2020-11-30T16:56:00Z,"deciding whether to keep option `-M` which currently defines number of POA groups, as it is, or change it to represent maximum number of reads? or simply get rid of it all together.
On the same note, there is possibly another set of options required to modify default `BatchSize` constructor values.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/483,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTI2NTYzMzE=,[CI] Add build Slack notifications,CLOSED,2020-07-07T21:21:38Z,2020-09-22T13:48:34Z,2020-09-22T13:48:34Z,Integrate GenomeWorks branch builds with `nvgenomics-ci` slack channel,ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/487,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTM1NDc5MTY=,[cudamapper] Skip pairs of indices which cause out of memory errors,CLOSED,2020-07-08T19:40:48Z,2020-07-14T14:32:15Z,2020-07-14T14:32:15Z,"Depending on read characteristics some pairs of indices can cause OOM errors.
Skip such pairs of indices and print a message to the user.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/489,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTM2MDA4MTY=,[cudamapper] Process skipped pairs of indices separately,OPEN,2020-07-08T21:12:57Z,2020-07-08T21:12:57Z,,Keep a list of pairs of indices which were skipped due to an OOM error (Issue #489). Once all other pairs of indices have been processed go over skipped ones and process them one by one without keeping any other indices on device in order to maximize the amount of available device memory.,mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/490,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTM2MDQwNzI=,[cudamapper] Split index pairs which cause OOM into multiple pairs of indices,OPEN,2020-07-08T21:19:17Z,2020-07-08T21:19:17Z,,"If a pair of indices causes OOM error even when no other indices are kept on device (Issue #490, also see #489) split indices into several smaller indices and find overlaps.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/491,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTQ3NTE4MzI=,[cudapoa] customizable number of cells per thread in NW kernels,CLOSED,2020-07-10T12:38:23Z,2020-12-02T15:42:38Z,2020-12-02T15:42:38Z,"In the current implementation, different variations of Needleman-Wunch kernels process score matrix row by row. Each thread processes a fixed number of cells per row at a time, `CELLS_PER_THREAD = 4`. To make this number variable allows adjusting parallelism granularity (e.g. right now, minimum band-width length = `CELLS_PER_THREAD*WARP_SIZE`) and potentially improving performance.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/494,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTYxOTg2NzQ=,[cudapoa][cudaaligner] adding support for different types of gap penalty,OPEN,2020-07-13T22:49:01Z,2020-07-13T22:56:54Z,,"The current implementation supports constant gap penalty. This issue suggests adding linear, affine and convex types as well.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/496,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTY4NzMyMTI=,[cudapoa] add tests for banded and adaptive alignment,CLOSED,2020-07-14T20:18:33Z,2020-11-30T22:42:35Z,2020-11-30T22:42:35Z,Add some tests to verify banded-alignment as well as adaptive-alignment. Tests can compare consensus output against full-alignment.,r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/502,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTY4OTAwNzE=,[cudamapper] Overlaps at the same position in an index are dropped even when query and target files are not the same.,CLOSED,2020-07-14T20:49:11Z,2020-07-23T15:10:06Z,2020-07-23T15:10:06Z,"When using two different FASTA files, reads at index i in the query index and index j in the target index are not overlapped when i == j. This is because of a check that was introduced in https://github.com/clara-parabricks/GenomeWorks/blob/0702c2ffd672fa04887f3b4e82bfd18d1d213218/cudamapper/src/overlapper.cpp#L25, and is valid for all-to-all but not sequence-to-reference overlapping.

The filtering condition should be ignored when not running in all-to-all mode.",edawson,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/503,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTY4OTc3ODU=,[cudamapper] Filtering parameters are too stringent for very small read sets,CLOSED,2020-07-14T21:03:49Z,2020-07-31T00:51:26Z,2020-07-31T00:51:26Z,"While testing cases related to #503 , it became apparent that for very small readsets (e..g, two reads) the default filtering parameter `-F` is too stringent. Values of `-F` smaller than approximately 0.001 produce no overlaps.

The right way to fix this is to properly handle repetitive minimizers. We could do this with a fixed mask, a weighting function like that used in WinnowMap, or by rearchitecting the sketch handling in cudamapper to function like MashMap. As a temporary fix, it might make sense to use a filtering parameter value scaled by the number of reads in the input data (probably growing 1 / (number of reads)^2, with a minimum of 2e-4). ",edawson,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/504,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTczODMyODA=,[cudaaligner] Tests should load data from file,OPEN,2020-07-15T14:12:38Z,2020-07-15T14:12:38Z,,"cudaaligner's tests use hard coded test data. This data should be loaded from data file(s) instead (like cudamapper).


cudaaligner's hard coded data: https://github.com/clara-parabricks/GenomeWorks/blob/dev-v0.5.0/cudaaligner/tests/cudaaligner_test_cases.cpp

cudamapper's data and tests: https://github.com/clara-parabricks/GenomeWorks/tree/dev-v0.5.0/cudamapper/data and https://github.com/clara-parabricks/GenomeWorks/tree/dev-v0.5.0/cudamapper/tests",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/505,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NjE5NTI4ODY=,[cudamapper] Create public interface for overlapper,CLOSED,2020-07-20T15:27:22Z,2020-07-21T21:58:19Z,2020-07-21T21:58:19Z,"Similarly to other classes in public interface `Overlapper` should also have a `create_overlapper()` function.

For example see https://github.com/clara-parabricks/GenomeWorks/blob/dbf5b61e0bf11124d8de366e6a4292a36f7b6038/cudamapper/include/claraparabricks/genomeworks/cudamapper/matcher.hpp#L51",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/509,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NjQ4MzY1OTU=,[cudamapper] Create public interface for IndexDescriptor,CLOSED,2020-07-24T00:03:32Z,2020-07-24T18:57:21Z,2020-07-24T18:57:21Z,"As discussed in #508, the read grouping functionality of the IndexDescriptors is useful for creating batches for cudamapper. It should have an entry point to use in the public interface ",nvvishanthi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/514,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NjUxMzg4OTg=,[cudamapper] Expose print_paf() in public interface,CLOSED,2020-07-24T12:35:25Z,2020-08-03T19:22:57Z,2020-08-03T19:22:57Z,As discussed in #508 `print_paf()` should be moved from `cudamapper/src/cudamapper_utils.hpp` into a new file in `cudamapper/include/claraparabricks/genomeworks/cudamapper`,mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/516,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NjUxNDE0MTI=,[cudamapper] Expose IndexDescriptor in public interface,CLOSED,2020-07-24T12:40:11Z,2020-09-03T23:11:19Z,2020-09-03T23:11:19Z,"`IndexDescriptor` is currently not part of public interface. During implementation of cudamapper sample (#508. #340) it turned out that `IndexDescriptor` would be useful in other implementations of cudamapper as well.

Expose `IndexDescriptor` in public interface, probably in the same way e.g. `Matcher` is exposed.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/517,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2Njg5MTU0Nzk=,[cudapoa] unifying closely related numerous parameters related to POA graph length,CLOSED,2020-07-30T16:07:49Z,2020-07-31T15:53:02Z,2020-07-31T15:53:02Z,"Currently there are different variables that are closely related to graph length, such as `max_nodes_per_window`, `max_matrix_graph_dimension`, and their banded versions. It makes life much easier to deal with only one parameter instead.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/521,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2Njk5NTk5MDY=,[cudapoa] unify CUDA kernels in banded and adaptive NW ,CLOSED,2020-07-31T15:56:12Z,2020-11-05T03:22:26Z,2020-11-05T03:22:26Z,"there are multiple kernels in `cudapoa_nw_banded.cuh` and `cudapoa_nw_adaptive_banded.cuh` which are similar and with some effort can be unified and combined together. Merge them and have them in a separate file, such as `banded_nw_utils.cuh`",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/522,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NzE3NTk1NDU=,[cudamaper] Use events to sync generation and communication streams,OPEN,2020-08-03T03:00:32Z,2020-09-01T13:51:21Z,,"When creating indices in IndexCache synchronize generation and communication streams using events, not `cudaStreamSynchronize()`

Continuation of #318 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/524,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NzE3NjAxMzQ=,[cudamapper] Use stream callback functions to update Index state,OPEN,2020-08-03T03:02:32Z,2020-08-03T03:02:32Z,,"When copying indices from host to device use stream callback functions to update the state indices upon copy completion.

Continuation of #318 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/525,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NzE3NjA3NjM=,[cudamapper] Throw custom exception when Index not found,CLOSED,2020-08-03T03:04:56Z,2020-10-22T14:37:46Z,2020-10-22T14:37:45Z,"Throw custom exceptions when indices are not found in `IndexCache`.
Continuation of #318 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/526,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NzI4Njg5MDY=,[cudapoa] add description to error codes,CLOSED,2020-08-04T15:11:20Z,2020-12-04T02:56:05Z,2020-12-04T02:56:05Z,"currently we only print out the error code. It helps to have a description added. We can even for some cases, add hints about which corresponding parameters in `BatchConfig` object can be modified to fix the error.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/527,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NzMxNDMzNzc=,[cudapoa] consolidate macros for banded alignment in single header,OPEN,2020-08-04T23:21:41Z,2020-08-04T23:21:41Z,,"Right now the macros for banded alignment like CUDAPOA_BANDED_MATRIX_RIGHT_PADDING are not shared between the kernel code and other sources that determine sizes for bands (such as in batch.cu). For now they're hard coded to specific numbers, but this is error prone. This needs to be fixed to the macros are shared between files.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/528,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NzMzODYzNTU=,[cudamapper] Do not do self-mapping of reads,OPEN,2020-08-05T09:14:37Z,2020-08-05T09:14:54Z,,"When doing all-vs-all do not look for anchors of reads with the same `read_id`. Currently we are doing this for the sake of code simplicity, but this introduces additional overlaps which probably affect accuracy and definitely affect performance by creating additional anchors which take up more space and require time to be processed.

There are two options:
1) Make `Matcher` not look for anchors with the same `read_id`
2) If `1)` turns out to be too complicated simply skip matching same indices. This would lead to all read pairs from those indices to be skipped, so option `1)` is preferred",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/531,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2ODE5NjU3NTg=,[cudamapper] Index should accept IndexDescriptor,CLOSED,2020-08-19T16:10:15Z,2020-09-15T00:27:03Z,2020-09-15T00:27:03Z,"Currently `Index`'s constructor accepts `first_read` and `number_of_reads` explicitly. Having it accept `IndexDescriptor` would be more elegant.

See discussion in #536 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/539,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2ODU0ODk5OTg=,[common] Rename device_copy_n to reflect non-blocking behavior,CLOSED,2020-08-25T13:32:52Z,2021-01-26T14:22:33Z,2021-01-26T14:22:33Z,"The version of `device_copy_n` which takes a CUDA stream argument
https://github.com/clara-parabricks/GenomeWorks/blob/74e6424c156a7ee15b4137d4788a4257ee6482c4/common/base/include/claraparabricks/genomeworks/utils/cudautils.hpp#L138
should be renamed to `device_copy_n_async` to make the non-blocking behavior more obvious.


The blocking three-argument version of `device_copy_n` should remain as is.",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/541,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2ODc5NjY2MTc=,[cudamapper] Small improvements to IndexGPU,CLOSED,2020-08-28T10:11:28Z,2020-08-28T15:45:35Z,2020-08-28T15:45:35Z,"While reviewing a PR I noticed
a) `cudaStreamSynchronize()` is missing a `GW_CU_CHECK_ERR` in
https://github.com/clara-parabricks/GenomeWorks/blob/d715ab18b9a704726350613b6bb248a741b0d9f3/cudamapper/src/index_gpu.cuh#L781

b) I think the block around the mentioned `cudaStreamSynchronize()`:
```
    cudautils::device_copy_n(merged_basepairs_h.data(), ...,  cuda_stream_); // H2D

    cudaStreamSynchronize(cuda_stream_);
    merged_basepairs_h.clear();
    merged_basepairs_h.shrink_to_fit();

    // sketch elements get generated here
    auto sketch_elements = SketchElementImpl::generate_sketch_elements(..., cuda_stream_);
```
could be changed to
```
    cudautils::device_copy_n(merged_basepairs_h.data(), ...,  cuda_stream_); // H2D

    // sketch elements get generated here
    auto sketch_elements = SketchElementImpl::generate_sketch_elements(..., cuda_stream_);

    cudaStreamSynchronize(cuda_stream_);
    merged_basepairs_h.clear();
    merged_basepairs_h.shrink_to_fit();
```
which could potentially allow for a bit more overlapping. @mimaric ?",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/543,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2ODkyNDU0ODc=,[cudapoa] reduce register count in cudapoa kernels,CLOSED,2020-08-31T14:19:42Z,2020-09-14T09:05:11Z,2020-09-14T09:05:11Z,The recent changes to banded and adaptive banded have increased the register count in cuda kernels and hence limited occupancy of the kernels. Investigate steps to keep the register count in check.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/547,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2OTY1MjUxMTQ=,GenomeWorks compiling error,CLOSED,2020-09-09T07:27:34Z,2020-10-08T10:43:57Z,2020-10-08T10:43:57Z,"Hi!
I am working around two days trying to compile GenomeWorks which included into racon genome assembler.
GCC = 9.3.0
cmake = 3.18.20200908-g1d74a64
make = 4.3
nvcc = 11.0
cuDNN = 8.0.2
nvidia driver = 450.51.06

CMakeCache.txt was manually edited with including `CMAKE_CXX_FLAGS:STRING=-DFMT_USE_USER_DEFINED_LITERALS=0` string
the error occured whyle the most of work was done: 
`
[ 81%] Linking CXX static library ../../lib/libcudaaligner.a
Reaping winning child 0x55c2e3d8eaf0 PID 14870 
Live child 0x55c2e3d8eaf0 (lib/libcudaaligner.a) PID 14872 
Reaping winning child 0x55c2e3d8eaf0 PID 14872 
Live child 0x55c2e3d8eaf0 (lib/libcudaaligner.a) PID 14874 
Reaping winning child 0x55c2e3d8eaf0 PID 14874 
Removing child 0x55c2e3d8eaf0 PID 14874 from chain.
Considering target file 'GenomeWorks/cudaaligner/CMakeFiles/cudaaligner.dir/build'.
 File 'GenomeWorks/cudaaligner/CMakeFiles/cudaaligner.dir/build' does not exist.
  Considering target file 'lib/libcudaaligner.a'.
  File 'lib/libcudaaligner.a' was considered already.
 Finished prerequisites of target file 'GenomeWorks/cudaaligner/CMakeFiles/cudaaligner.dir/build'.
Must remake target 'GenomeWorks/cudaaligner/CMakeFiles/cudaaligner.dir/build'.
Successfully remade target file 'GenomeWorks/cudaaligner/CMakeFiles/cudaaligner.dir/build'.
Reaping winning child 0x558a0914daf0 PID 14802 
Live child 0x558a0914daf0 (GenomeWorks/cudaaligner/CMakeFiles/cudaaligner.dir/all) PID 14879 
[ 81%] Built target cudaaligner
Reaping winning child 0x558a0914daf0 PID 14879 
Removing child 0x558a0914daf0 PID 14879 from chain.
Reaping losing child 0x560a19aabcb0 PID 14245 
make: *** [Makefile:171: all] Error 2
Removing child 0x560a19aabcb0 PID 14245 from chain.
`

I updated cmake and make, but compilation still aborting.
I have no a great experience on C-like languages and compilation. May be I don't understand some configs or I have to change something in cmake-generated files?

I hope you can help me to find answers.
Thanks.",asan-emirsaleh,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/554,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDIxNzM3NDE=,[pygenomeworks] Support reading compressed PAF as input,OPEN,2020-09-15T18:55:39Z,2020-09-15T18:55:39Z,,"Currently, the evaluate_paf script in pygenomeworks (and the backing readers) require input to be raw text. However, we often use gzip-compressed PAF to save space, and miniasm natively supports reading it. It would be nice to modify our PAF reader to natively support gzipped PAF.",edawson,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/559,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDIxNzY0NTE=,[pygenomeworks] evalute_paf does not properly report the number of incorrect starts/ends,CLOSED,2020-09-15T18:59:57Z,2020-09-23T17:10:21Z,2020-09-23T17:10:21Z,"The evaluate_paf script in pygenomeworks/bin reports a number of correct query/target starts and ends. However, the numbers reported currently are not accurate, as each searched interval increments these variables:
https://github.com/clara-parabricks/GenomeWorks/blob/88dcc74b17a659e1baf21139920a41d9e0cac7f6/pygenomeworks/bin/evaluate_paf#L195-L198

The proper behavior should instead be to only report the correctness of starts/ends only for the best match.",edawson,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/560,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDY0MDU4ODE=,[cudapoa/cudaaligner] fix compute version to 60,CLOSED,2020-09-22T13:53:26Z,2020-12-03T20:38:12Z,2020-12-03T20:38:12Z,"Because of the perf issue observed in cudapoa and cudaaligner, the max compute version that gives best numbers is compute 60. Update the nvcc flags for cudapoa and cudaaligner to compile to compute 60 only. Accordingly, update GW readme to only support architectures beyond Pascal.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/566,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDY0MTMzNzQ=,[cudaextender] Add new cuadextender module to GW,CLOSED,2020-09-22T14:02:19Z,2020-10-01T22:19:28Z,2020-10-01T22:19:28Z,"This is a blanket issue for the following tasks

1. create a new API for cuda accelerated extension algorithms
2. port CUDA x drop algorithm by @gsneha26 and @yatisht into GenomeWorks
3. add tests and samples for the API and implementation",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/567,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDcxNjc4MDA=,[sdk] Update the way we fetch CUB,CLOSED,2020-09-23T08:41:43Z,2020-12-07T10:42:16Z,2020-12-07T10:42:16Z,"CUDA 11 ships with CUB, so there is no need to download it separately into `3rdparty` (unless for some reason we need another version)

For pre-CUDA 11, CUB has been moved under Nvidia organization on GitHub: https://github.com/NVIDIA/cub/. Old link still works, but we should update it for consistency.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/570,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDc1NTI2MjE=,[pygenomeworks] evaluate_paf script is too slow to be practical for very large PAF files,OPEN,2020-09-23T17:34:33Z,2020-09-23T17:34:44Z,,"Despite updating the evaluate_paf script to handle queries better, the performance of the script is inadequate for large-scale CI jobs. 

One solution to this is to ditch the interval tree data structure and instead rely on sorted PAF input. For large PAF files, this may still take a significant amount of time, though it should significantly reduce the memory usage (requiring only two PAF records to be kept in memory at a time; currently, all truth set records are maintained in memory).

Another option would be to provide random access to bgzipped PAF files, either through TABIX or some other API.",edawson,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/571,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDgyOTA5Mzk=,[cmake] move version file configuration into base,OPEN,2020-09-24T15:58:13Z,2020-09-24T15:58:13Z,,"The `version.cpp.in` file should be configured once as part of the base module, and all the modules should simply call into the `version.hpp` header. currently that file is being separately configured as part of cudapoa/cudamapper/etc. ",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/572,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTI5ODE2Mzg=,[cudaextender] Replace cudaextender's hardcoded encoding scheme with cudasequence,OPEN,2020-10-01T16:06:10Z,2020-10-01T19:30:20Z,,`cudaextender/src/ungapped_xdrop.cu` currently uses a hardcoded encoding scheme with fixed scoring matrices and a fixed alphabet. Replace that scheme with the generalized scheme that cudasequence will propose. ,atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/574,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTI5ODY1MTM=,[cudaextender] Check if entropy calculation can be done using a float.,OPEN,2020-10-01T16:12:38Z,2020-10-01T19:30:02Z,,Currently cudaextender uses doubles for entropy calculation during ungapped extension. Check the accuracy implications of moving the calculation to a float. ,atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/575,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTI5OTMyMTI=,[cudaextender] Calculate memory limits based on datastructures used.,OPEN,2020-10-01T16:21:36Z,2020-10-01T19:29:47Z,,"Currently element and memory limits are artifacts of hardcoded global memory limits in SegAlign. To be replaced with actual calculation of memory requirements with sizes of  datastructures taken into consideration. Also currently the max limit is based on total global memory, which should be replaced with memory available from the passed in allocator.",atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/576,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTI5OTc1NTg=,[cudaextender] Explore configurability of kernel launch parameters.,OPEN,2020-10-01T16:27:34Z,2020-10-01T19:29:33Z,,Currently cudaextender has hardcoded block and grid dimensions. Explore configurability of these based on size of workload. Also explore if these need to be exposed to the user for config. ,atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/577,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTMwMDE2MjQ=,[cudaextender] Make output compression async,OPEN,2020-10-01T16:33:04Z,2020-10-01T19:29:21Z,,Currently cudaextender's output compression is synchronous. Explore dynamic parallelism or kernel replacement for Thrust's stable sort for making the tail end of cudaextender truly async.,atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/578,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTMwNjI4MTY=,[cudaextender] Kernel optimizations,OPEN,2020-10-01T17:54:53Z,2020-10-01T18:00:40Z,,"Investigate kernel optimizations with:
-  code reuse 
-  hardcoded limit removal
-  removal of unnecessary operations like memset",atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/579,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTMxMjQ0OTE=,[cudaextender] Performance analysis,OPEN,2020-10-01T19:28:45Z,2020-10-01T19:29:07Z,,Investigate performance difference between native SegAlign implementation and cudaextender implementation of ungapped extension.,atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/580,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTMyMjk2NjQ=,[cudaextender] Update readme with cudaextender info,CLOSED,2020-10-01T22:40:08Z,2020-10-20T15:15:33Z,2020-10-20T15:15:33Z,Add cudaextender details to the main project's readme. ,atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/582,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTU4NjE4NjY=,[Documentation] Add code blocks instructions for dependencies setup,OPEN,2020-10-06T17:01:38Z,2020-10-06T17:01:53Z,,"Adding code blocks instructions to the README file for GenomeWorks setup steps to include both:
- Installing all dependencies through Anaconda.
- Installing all dependencies from source or the system package manager.",ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/583,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTY1ODg4MjA=,[cudapoa] add tests for different band modes,CLOSED,2020-10-07T14:36:19Z,2020-12-02T16:57:10Z,2020-12-02T16:57:10Z,"there are different variations of NW algorithm (full-band, static-band, adaptive-band, traceback static and traceback adaptive bands). We need to add some tests for each case.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/584,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTc3MzgyMDM=,[docs] rework documentation for modules in GW,CLOSED,2020-10-08T23:33:11Z,2020-12-03T23:22:57Z,2020-12-03T23:22:57Z,"Move the documentation per module into respective module folders. i.e. add a new `README.md` file under each module such as `cudapoa` or `cudaextender` and add more detailed documentation regarding algorithm, features, limitations, etc in there.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/586,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MjI1ODM5Mzc=,[cudapoa] overlapping vertical/diagonal update of score matrix with horizontal update,OPEN,2020-10-15T18:52:10Z,2020-10-15T18:52:10Z,,investigate overlapping vertical/diagonal update of score matrix in NW with horizontal update. A crude measurement on a short-read set indicated  up to 40% of the time can be spent on vertical/diagonal update.,r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/587,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MjU2OTczODA=,[cudamapper] bug in extracting kmers,CLOSED,2020-10-20T15:14:05Z,2020-12-03T19:05:46Z,2020-12-03T19:05:46Z,"[here](https://github.com/clara-parabricks/GenomeWorks/blob/dev-v0.6.0/cudamapper/src/cudamapper_utils.cpp#L49), the second argument of `std::substr` is length of the substring, not the end position. Should be changed from `i + kmer_size` to `kmer_size`",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/591,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MzE1NzU3OTY=,How to install GenomeWorks on local machine?,OPEN,2020-10-28T15:58:44Z,2021-02-09T07:02:42Z,,"Hello everyone,
I am a research scholar, and I need to test GenomeWorks  on sample data. Could anyone please explain how to install and run on my system?
System details:
UBUNTU 18.0
6GB CUDA -enabled NVIDIA GTX 1660Ti
Intel core-i7 9th Gen
16GB RAM

Thanks in advance.",kountaydwivedi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/593,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3NDM5NzE2MDU=,"[common] DevicePreallocatedAllocator should allocate exactly the amount of memory requested, not more",CLOSED,2020-11-16T16:22:45Z,2020-11-30T17:55:03Z,2020-11-30T17:55:03Z,"`DevicePreallocatedAllocator` currently rounds up allocations to the next size divisible by 256. This comes from the property of `cudaMalloc()` that all its allocations are 256B-aligned (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses).
As a consequence of this if the last block in memory has e.g. 300 free bytes and 300B are requested those 300 requested bytes will be rounded up to 512B and the allocation will fail due to insufficient memory (for details see PR #598).
The property of aligning allocations to 256B should be kept, but their sizes should not be rounded up. The allocator should internally be aware that the remaining `((requested_size - 1) / 256 + 1) * 256 - requested_size` bytes are ""junk"".",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/600,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3NTEzNDc4MjE=,terminate called after throwing an instance of 'std::runtime_error',OPEN,2020-11-26T07:14:35Z,2021-01-21T11:54:35Z,,"```
root@lt5h8:~/dataset/hg38-1# cudamapper -a 2 hg38-1.mut hg38.fa
-C / --target-indices-in-host-memory not set, using -Q / --query-indices-in-host-memory value: 10
-c / --target-indices-in-device-memory not set, using -q / --query-indices-in-device-memory value: 5
Query file: hg38-1.mut, number of reads: 25
Target file: hg38.fa, number of reads: 25
Programmatically looking for max cached memory
Using device memory cache of 16376457462 bytes
Device 0 took batch 1 out of 9 batches in total
Aligning 0 overlaps (0x0) with batch size 0
terminate called after throwing an instance of 'std::runtime_error'
  what():  Max alignments must be at least 1.
Aborted (core dumped)
```

What causes this problem and how to fix it??",bellstwohearted,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/603,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3NTE4NjE2MDE=,[cudapoa] throw an error in case all weights are zero,CLOSED,2020-11-26T23:15:16Z,2020-12-07T17:22:16Z,2020-12-07T17:22:16Z,"heavy-bundle algorithm in POA to generate consensus assumes non-zero base weights. We should check and throw an error in case this assumption is not satisfied, otherwise cudaPOA will potentially generate some incorrect consensus output (since all the paths have the same weight of 0).",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/604,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3NTM4NjQzNTg=,[cudapoa] make maximum number of edges per node configurable,OPEN,2020-11-30T22:58:37Z,2020-11-30T22:58:37Z,,"`CUDAPOA_MAX_NODE_EDGES` and `CUDAPOA_MAX_NODE_ALIGNMENTS` with default value of 50 defined in `cudapoa_structs.cuh` have a big impact on memory usage per POA. Consequently maximum number of POAs residing on GPU can increase by using smaller values for these two parameters. Changing these macros to template parameters allows achieving higher parallelism, particularly for processing long reads. 
As a rule of thumb, the value for these parameters should not exceed maximum number of reads per window. ",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/607,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3NjEzNDI5ODk=,[logging] reduce logging overhead,OPEN,2020-12-10T15:33:22Z,2020-12-11T15:10:55Z,,"Suggestions from @ahehn-nv -

1.
```
You could avoid the construction of the std::string by directly operating on the stream:

std::ostream& operator << (std::ostream& os, LogLevel level)
{
    switch(level)
    {
       case critical: os << ""CRITICAL""; break;
       ...
    }
    return os;
}
or, if you dislike overloading operators, a similar function void add_prefix(std::ostream& os, LogLevel level).
```
 
2.
```
We could actually base the whole logger on overloading << instead of macros and std::strings, providing a syntax like:

 log(LogLevel::debug) << ""here's some debug integer: "" << some_integer << std::endl;
Advantages:

common C++ syntax.
messages become almost no-ops if a higher logging level is selected.
Disadvantage:

more templates -> Slightly higher compilation times.
```",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/616,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3OTAzMzQ5MDY=,Can GenomeWorks work without CUDA? Can it work parallelize through MPI?,CLOSED,2021-01-20T21:24:56Z,2021-01-21T09:02:56Z,2021-01-21T09:02:56Z,,yurivict,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/619,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU4MDk1NDczNTg=,[cudaaligner] Disabled caching device-allocator may trigger OOM in cudaaligner,OPEN,2021-02-16T18:25:58Z,2021-02-16T18:25:58Z,,"AlignerGlobalMyersBanded's `reset_max_bandwidth(...)` runs out of device memory when the caching device-allocator is disabled at compilation. (This allocator is enabled by default.)
It is unclear if cudaaligner respects the `max_device_memory` setting passed at construction at all in this case.",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/630,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU4MTU0MDE4NDE=,format.h is broken and breaks CUDA compile,OPEN,2021-02-24T11:46:21Z,2021-02-25T14:39:10Z,,"There's a misplaced set of quotes in format.h file that prevents CUDA integration into RAVEN (error2 build fail).:

This showed up when I was trying to compile RAVEN for CUDA in </raven/build/_deps/genomeworks-src/3rdparty/spdlog/include/spdlog/fmt/bundled/format.h>

Pulled solution from here: https://www.gitmemory.com/issue/yuzu-emu/yuzu/2597/507715224

Changed Line 3475 from:
FMT_CONSTEXPR internal::udl_formatter<Char, CHARS...> operator""""_format() {

To (remove quotes):
FMT_CONSTEXPR internal::udl_formatter<Char, CHARS...> operator_format() {",cement-head,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/637,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU4ODExMDk5Nzg=,[pygenomeworks] pinned dependencies.,CLOSED,2021-05-08T17:51:16Z,2021-05-13T11:36:13Z,2021-05-13T11:36:13Z,"Hey all,

I'm looking to depend on `genomeworks-cuda-10-2` in `bonito` but the current set of pinned dependencies are too restrictive.

Specifically, the troubles are with the requirement on `numpy==1.16.3` and the use of [h5py](https://github.com/h5py/h5py/blob/3.1.0/setup.py#L28) and [cupy](https://github.com/cupy/cupy/blob/master/setup.py#L34).

",iiSeymour,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/647,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU4ODExNjY5NzA=,[pygenomeworks] logger chatter.,OPEN,2021-05-08T18:44:58Z,2021-05-18T12:47:08Z,,"When creating a `CudaPoaBatch` object a default logger is initialized and outputs to `stderr`.

```python
>>> from genomeworks.cudapoa import CudaPoaBatch
>>> CudaPoaBatch(1000, 1000, 3724032)
GenomeWorks logger not initialized yet. Initializing default logger now.
Initialized GenomeWorks logger with log level ERROR
```

Can the logger be initialized from Python with a stream to avoid this output?  
",iiSeymour,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/648,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU5MzEyODU2ODM=,How to fix cudaErrorInvalidDeviceFunction exception for cudamapper,CLOSED,2021-06-28T08:00:08Z,2021-07-09T08:36:24Z,2021-07-09T08:36:24Z,"Hi, 

When I ran ""cudamapper 1.fasta 2.fasta"", I met with an error ""cudaErrorInvalidDeviceFunction"". The screen shows below:
> Initialized GenomeWorks logger with log level ERROR
> -C / --target-indices-in-host-memory not set, using -Q / --query-indices-in-host-memory value: 10
> -c / --target-indices-in-device-memory not set, using -q / --query-indices-in-device-memory value: 5
> Query file: 1.fasta, number of reads: 1
> Target file: 2.fasta, number of reads: 1
> Programmatically looking for max cached memory
> Using device memory cache of 12493416039 bytes
> Device 0 took batch 1 out of 1 batches in total
> terminate called after throwing an instance of 'thrust::system::system_error'
>   what():  scan failed on 2nd step: cudaErrorInvalidDeviceFunction: invalid device function
> Aborted (core dumped)


Also, I tried to run the test cases for cudamapper, 19 tests failed with the below exception:

> ...
> [----------] 5 tests from TestCudamapperIndexCaching
> [ RUN      ] TestCudamapperIndexCaching.test_index_cache_same_query_and_target
> unknown file: Failure
> C++ exception with description ""scan failed on 2nd step: cudaErrorInvalidDeviceFunction: invalid device function"" thrown in the test body.
> [  FAILED  ] TestCudamapperIndexCaching.test_index_cache_same_query_and_target (20 ms)
> ...

My linux system is Ubuntu 21.04.
My GenomeWorks program is the lastest dev version (9fd8232). My cuda version is 11.3.  
My GPU is GTX 1080ti and arch flag for compilation is 6.1.
What should I do to fix the problem described above?",wzboy1984,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/655,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU5MzczNzUzNDU=,cudamapper error using bam output,OPEN,2021-07-05T21:33:13Z,2021-07-06T00:57:58Z,,"Hi folks,
I'm trying cudamapper with this command:
`/opt/GenomeWorks-2021.02.2/bin/cudamapper PAG33026_pass_concat.fastq.gz ../hg19a.fa -B > cudamapper_2021_02_02_GM24385.bam`

which outputs quite a lot of output to stdout/stderr, from which I have reported the unique lines below:
```
Initialized GenomeWorks logger with log level ERROR
-C / --target-indices-in-host-memory not set, using -Q / --query-indices-in-host-memory value: 10
-c / --target-indices-in-device-memory not set, using -q / --query-indices-in-device-memory value: 5
 Query file: PAG33026_pass_concat.fastq.gz, number of reads: 9983679
Target file: ../hg19a.fa, number of reads: 84
Programmatically looking for max cached memory
Using device memory cache of 24899308094 bytes
Device 0 took batch 1 out of 1790 batches in total
[E::sam_hrecs_update_hashes] Duplicate entry ""5"" in sam header
print_sam: could not add header value
[E::sam_hrecs_update_hashes] Duplicate entry ""5"" in sam header
print_sam: could not add header value
[E::sam_hrecs_update_hashes] Duplicate entry ""5"" in sam header
print_sam: could not add header value
...
[E::sam_hrecs_update_hashes] Duplicate entry ""19"" in sam header
print_sam: could not add header value
[E::sam_hrecs_update_hashes] Duplicate entry ""22"" in sam header
print_sam: could not add header value
[E::sam_hrecs_update_hashes] Duplicate entry ""5"" in sam header
print_sam: could not add header value
[E::bgzf_flush] File write failed (wrong size)
terminate called after throwing an instance of 'std::runtime_error'
  what():  ERROR, print_sam: could not write alignment
Aborted (core dumped)
```
In practise I think I get the ""Duplicate entry ""N"" "" error for each read that is processed.",RichardCorbett,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/656,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU5NzAyNzQ2MzQ=,Buils fails with gcc 9.3,CLOSED,2021-08-13T10:29:04Z,2021-08-17T08:17:08Z,2021-08-13T13:12:30Z,"Hi,

I tried to build racon and as part of it genomeworks is built. Per default I had gcc9.3 installed and the build of GenomeWorks failed. When I tried to build it separately from racon I had the same problem. I was able to install it nicely when switching back to gcc8. 

I got this error message:
09:55:56  [ 36%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/cudaaligner.cpp.o
09:55:56  [ 36%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/aligner_global_ukkonen.cpp.o
09:55:56  [ 38%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/aligner.cpp.o
09:55:56  [ 38%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/aligner_global.cpp.o
09:55:56  [ 38%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/alignment.cpp.o
09:55:56  [ 39%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/alignment_impl.cpp.o
09:55:56  [ 39%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/aligner_global_myers.cpp.o
09:55:56  [ 40%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/ukkonen_cpu.cpp.o
09:55:56  [ 40%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/aligner_global_myers_banded.cpp.o
09:55:56  [ 40%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/aligner_global_hirschberg_myers.cpp.o
09:55:56  [ 42%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/needleman_wunsch_cpu.cpp.o
09:56:00  [ 43%] Linking CXX static library libcudaaligner.a
09:56:00  [ 43%] Built target cudaaligner
09:56:39  Scanning dependencies of target cudapoa
09:56:39  [ 45%] Building CXX object cudapoa/CMakeFiles/cudapoa.dir/src/cudapoa.cpp.o
09:56:39  [ 45%] Building CXX object cudapoa/CMakeFiles/cudapoa.dir/version.cpp.o
09:56:39  [ 45%] Linking CXX static library libcudapoa.a
09:56:39  [ 45%] Built target cudapoa
09:56:39  Makefile:162: recipe for target 'all' failed
09:56:39  make: *** [all] Error 2

Unfortunately, I cannot easily extract the Makefile for these builds as I am building singularity images in a build pipeline. 

Dominik",dominik-handler,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/660,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU5OTIzMTU2MTE=,Floating Point Exception in Racon,OPEN,2021-09-09T14:46:13Z,2021-09-09T14:46:13Z,,"Hi,

Thanks for great software. Running latest version of racon (commit b591b12c22539948782704446989893bde826a29) and hitting a floating point exception on GPU, but CPU works. The racon authors [directed me here](https://github.com/lbcb-sci/racon/issues/58#issuecomment-915875871). Thanks for your help!

I'm attaching what I hope is a reproducible example. [racon_debug.zip](https://github.com/lbcb-sci/racon/files/7117517/racon_debug.zip)

```
root@a5698f05c7c3:/data/racon_trouble# racon -m 8 -x -6 -g -8 -w 500 --include-unpolished -t 4 --cudapoa-batches 1 --cudaaligner-batches 4 --cuda-banded-alignment filtered.fastq output.paf polished-input.fa
Using 1 GPU(s) to perform polishing
Initialize device 0
[CUDAPolisher] Constructed.
[racon::Polisher::initialize] loaded target sequences 0.000033 s
[racon::Polisher::initialize] loaded sequences 0.006921 s
[racon::Polisher::initialize] loaded overlaps 0.001669 s
GPU 0: Aligning with band width 68
[racon::CUDAPolisher::initialize] allocated memory on GPUs for alignment 0.989071 s
Alignment skipped by GPU: 415 / 921
[racon::Polisher::initialize] aligning overlaps [====================] 0.035475 s
[racon::Polisher::initialize] transformed data into windows 0.001138 s
[racon::CUDAPolisher::polish] allocated memory on GPUs for polishing 1.352416 s
Floating point exception (core dumped)
```
",schorlton,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/662,NVIDIA-Genomics-Research++GenomeWorks.csv
I_kwDOC02oTc47gU4g,Build fails with gcc 7 and 8,CLOSED,2021-09-16T15:11:32Z,2021-09-17T12:18:50Z,2021-09-17T12:18:50Z,"Hi!
I am attempting to build GenomeWorks but it crashes with the following errors.

After `make -j install`:

[ 44%] Built target cudapoa
Makefile:162: recipe for target 'all' failed
make: *** [all] Error 2

Then, I try just `make` and see this one (I also see ith with `make -j` but further up.

/home/dennistpw/packages/GenomeWorks/3rdparty/spoa/src/simd_alignment_engine.cpp:12:14: fatal error: immintrin.h: No such file or directory
     #include <immintrin.h> // AVX2 and lower
              ^~~~~~~~~~~~~
compilation terminated.
3rdparty/spoa/CMakeFiles/spoa.dir/build.make:110: recipe for target '3rdparty/spoa/CMakeFiles/spoa.dir/src/simd_alignment_engine.cpp.o' failed
make[2]: *** [3rdparty/spoa/CMakeFiles/spoa.dir/src/simd_alignment_engine.cpp.o] Error 1
CMakeFiles/Makefile2:413: recipe for target '3rdparty/spoa/CMakeFiles/spoa.dir/all' failed
make[1]: *** [3rdparty/spoa/CMakeFiles/spoa.dir/all] Error 2
Makefile:162: recipe for target 'all' failed
make: *** [all] Error 2

I saw on another issue that it may be compiler issue so I switch between gcc/g++ 7 and 8, and no luck.

I ran `make VERBOSE=1 2>&1 | tee verbose_build.log` and have attached the logs below if that would be more useful!

Versions:
- `Ubuntu 18.04.5 LTS (GNU/Linux 4.9.253-tegra aarch64)`
- `Python 3.6.9`
- `CUDA Version 10.2.300`
- `cmake version 3.10.2`
- GPU generation Volta
- autoconf and automake both installed

Any help would be greatly appreciated, thank you! :)

[verbose_build.log](https://github.com/clara-parabricks/GenomeWorks/files/7178957/verbose_build.log)
",tristanpwdennis,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/663,NVIDIA-Genomics-Research++GenomeWorks.csv
I_kwDOC02oTc47puM2,cudamapper terminates while doing an all-vs-all mapping,OPEN,2021-09-20T10:13:14Z,2021-09-20T10:13:14Z,,"I'm trying to do an all-vs-all mapping with cudamapper (dev branch, git-baab5668) and it terminates with an exception:

```console
$ cudamapper SRR.unmapped.choped.fastq.gz SRR.unmapped.choped.fastq.gz
Initialized GenomeWorks logger with log level ERROR
-C / --target-indices-in-host-memory not set, using -Q / --query-indices-in-host-memory value: 10
-c / --target-indices-in-device-memory not set, using -q / --query-indices-in-device-memory value: 5
NOTE - Since query and target files are same, activating all_to_all mode. Query index size used for both files.
Query file: SRR.unmapped.choped.fastq.gz, number of reads: 249455
Target file: SRR.unmapped.choped.fastq.gz, number of reads: 249455
Programmatically looking for max cached memory
Using device memory cache of 33390691615 bytes
Device 0 took batch 1 out of 1 batches in total
terminate called without an active exception
Aborted
```

Environment is CentOS 7 with an NVIDIA Tesla V100-PCIE-32GB. Thank you!",alanorth,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/664,NVIDIA-Genomics-Research++GenomeWorks.csv
I_kwDOC02oTc475z5D,[cudamapper] compared to minimap2,OPEN,2021-09-23T04:44:12Z,2021-09-23T04:44:12Z,,"Hi,

I've tried doing alignment by cudamapper over 3 datasets, and compared to that by minimap2. 
The time costs don't reduce much when compared to minimap2. In some cases, the running speeds of cudamapper are slower than minimap2, as shown in the below table.

 | Name | wall time(s) | mem peak(G) | note
-- | -- | -- | -- | --
data 1 | cudamapper | 650.63 | 10.87 | v100, 16G
 | minimap2_v2.20 | 1687.86 | 31.53 | -t 32 -k 17 -w 17 -x ava-ont
data 2 | cudamapper | 11193 | 39.76 | v100, 16G
 | minimap2_v2.20 | 4491 | 19.21 | -t 32 -k 17 -w 17 -x ava-ont
data 3 | cudamapper | 5958 | 27.4 | NVIDIA TITAN xp, 12G
 | minimap2_v2.20 | 4590 | 54.02 | -t 32-x ava-ont

Also, the sensitivity of the cudamapper alignments is lower than that of minimap2, which leads to the poorer assembly results based on cudamapper alignments of the 3 above datasets. The algorithm of cudamapper might need to be modified to get alignment results similar to minimap2. 
",wzboy1984,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/665,NVIDIA-Genomics-Research++GenomeWorks.csv
I_kwDOC02oTc5EohQj,[cudapoa] Kernel error,OPEN,2022-02-26T08:32:32Z,2022-02-26T08:32:32Z,,"Hello,
I tried updating GenomeWorks inside Racon from v0.5.3 to v2021.02.2 (and even v2021.02.0), and get kernel errors while using `BandMode::full_band` (only cudapoa is enabled, without bands):

`_deps/genomeworks-src/cudapoa/src/cudapoa_batch.cuh:451] Kernel Error: Traceback in Needleman-Wunsch algorithm failed. in batch 8
Suggestion  : You may retry with a different banding mode.`

Got any suggestions what could be causing this? I have two tests with the same data, one [with](https://github.com/lbcb-sci/racon/blob/master/test/racon_test.cpp#L454-L470) QV the other [without](https://github.com/lbcb-sci/racon/blob/master/test/racon_test.cpp#L472-L488), and the first one finishes successfully while the other yields the error above and the process hangs.

Thank you and best regards,
Robert",rvaser,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/666,NVIDIA-Genomics-Research++GenomeWorks.csv
I_kwDOC02oTc5vsAXA,GenomeWorks fails to compile with CUDA 12,OPEN,2023-08-30T14:30:06Z,2024-09-23T18:50:15Z,,"I'm trying to compile GenomeWorks using the lastest CUDA version, and there seem to be some breaking changes in thrust that generates some compilation errors, here are the errors reported when doing `make -j install`:

```
In file included from /home/qaguado/GenomeWorks/cudaaligner/src/batched_device_matrices.cuh:25,                                                                                                            
                 from /home/qaguado/GenomeWorks/cudaaligner/src/ukkonen_gpu.cu:18:                                                                                                                         
/home/qaguado/GenomeWorks/common/base/include/claraparabricks/genomeworks/utils/pinned_host_vector.hpp:23:10: fatal error: thrust/system/cuda/experimental/pinned_allocator.h: No such file or directory   
   23 | #include <thrust/system/cuda/experimental/pinned_allocator.h>                                                                                                                                      
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                      
compilation terminated.                                                                                                                                                                                    
In file included from /home/qaguado/GenomeWorks/cudaaligner/src/batched_device_matrices.cuh:25,                                                                                                            
                 from /home/qaguado/GenomeWorks/cudaaligner/src/hirschberg_myers_gpu.cuh:20,                                                                                                               
                 from /home/qaguado/GenomeWorks/cudaaligner/src/hirschberg_myers_gpu.cu:17:                                                                                                                
/home/qaguado/GenomeWorks/common/base/include/claraparabricks/genomeworks/utils/pinned_host_vector.hpp:23:10: fatal error: thrust/system/cuda/experimental/pinned_allocator.h: No such file or directory   
   23 | #include <thrust/system/cuda/experimental/pinned_allocator.h>                                                                                                                                      
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                      
compilation terminated.                                                                                                                                                                                    
CMake Error at cudaaligner_generated_ukkonen_gpu.cu.o.Release.cmake:220 (message):                                                                                                                         
  Error generating                                                                                                                                                                                         
  /home/qaguado/GenomeWorks/build/cudaaligner/CMakeFiles/cudaaligner.dir/src/./cudaaligner_generated_ukkonen_gpu.cu.o
```

I tried to fix the error by doing the following changes in `/common/base/include/claraparabricks/genomeworks/utils/pinned_host_vector.hpp` (from [this NVIDIA forum answer](https://forums.developer.nvidia.com/t/thrust-pinned-memory-in-cuda-12-0/242093/3)):

``` c++
// ...

//#include <thrust/system/cuda/experimental/pinned_allocator.h>
#include <thrust/system/cuda/memory_resource.h>
#include <thrust/mr/allocator.h>
#include <thrust/system/cpp/memory.h>

// ...

//using pinned_host_vector = std::vector<T, thrust::system::cuda::experimental::pinned_allocator<T>>;
template <typename T>
using pinned_host_vector = std::vector<T, thrust::mr::stateless_resource_allocator<T, thrust::cuda::universal_host_pinned_memory_resource>>;
```

But it still fails with the following error:

```
/usr/include/c++/9/bits/alloc_traits.h:556:25: error: no matching function for call to __do_alloc_on_move(thrust::mr::stateless_resource_allocator<claraparabricks::genomeworks::cudaaligner::batched_devi
ce_matrices<unsigned int>::device_interface, thrust::system::cuda::detail::cuda_memory_resource<cudaMallocHost, cudaFreeHost, thrust::pointer<void, thrust::cuda_cub::tag, void, thrust::use_default> > >&, thrust::mr::stateless_resource_allocator<claraparabricks::genomeworks::cudaaligner::batched_device_matrices<unsigned int>::device_interface, thrust::system::cuda::detail::cuda_memory_resource<cudaMallocHost, cudaFreeHost, thrust::pointer<void, thrust::cuda_cub::tag, void, thrust::use_default> > >&, __pocma)
```

Are there any plans to make GenomeWorks compatible with CUDA 12?

Thanks",quim0,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/668,NVIDIA-Genomics-Research++GenomeWorks.csv
I_kwDOC02oTc6N-AqD,"#include ""seqio.h"" //TODO add this to 3rdparty",OPEN,2024-06-29T16:25:33Z,2024-06-29T16:25:33Z,,"<img width=""185"" alt=""image"" src=""https://github.com/NVIDIA-Genomics-Research/GenomeWorks/assets/66343484/e897beb4-eb1c-4065-9f7b-3d422ce481c2"">

What does TODO mean? When I compile, it shows that there is no seqio.h file. How can I solve this problem?",CTForGitHub,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/670,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU5MzI1ODk3Mzc=,input for extract_genome_stats.py?,CLOSED,2021-06-29T12:24:21Z,2022-11-29T02:07:03Z,2022-11-29T02:07:03Z,"I am trying to understand the arguments for extract_genome_stats.py. 
The first is the csv created by convert2csv.py. But what is the accession_filename ?
Looking forward to trying this script!",EmelineFavreau,https://github.com/pbfrandsen/insect_genome_assemblies/issues/1,pbfrandsen++insect_genome_assemblies.csv
MDU6SXNzdWUzNjUxNzg1MTg=,Confirm that use of BLAST's `-max_target_seqs` is intentional,CLOSED,2018-09-30T00:29:43Z,2018-10-01T07:51:15Z,2018-10-01T07:51:15Z,"Hi there,

This is a semi-automated message from a fellow bioinformatician. Through a GitHub search, I found that the following source files make use of BLAST's `-max_target_seqs` parameter: 

- [R.padi_contaimination_filtering/clc_assembly.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/R.padi_contaimination_filtering/clc_assembly.sh)
- [R.padi_contaimination_filtering/clc_assembly_v5.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/R.padi_contaimination_filtering/clc_assembly_v5.sh)
- [RNAseq_analysis/Annotating_transcriptome/Rp_annotate.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/RNAseq_analysis/Annotating_transcriptome/Rp_annotate.sh)
- [R.padi_contaimination_filtering/clc_assembly_v2.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/R.padi_contaimination_filtering/clc_assembly_v2.sh)
- [R.padi_contaimination_filtering/clc_assembly_v3.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/R.padi_contaimination_filtering/clc_assembly_v3.sh)
- [R.padi_contaimination_filtering/clc_assembly_v4.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/R.padi_contaimination_filtering/clc_assembly_v4.sh)
- [R.padi_contaimination_filtering/clc_mapper.sh](https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/blob/c6cb771afaf40f5def47e33ff11cd8867ec528e0/R.padi_contaimination_filtering/clc_mapper.sh)

Based on the recently published report, [Misunderstood parameter of NCBI BLAST impacts the correctness of bioinformatics workflows](https://academic.oup.com/bioinformatics/advance-article-abstract/doi/10.1093/bioinformatics/bty833/5106166?redirectedFrom=fulltext), there is a strong chance that this parameter is misused in your repository.

If the use of this parameter was intentional, please feel free to ignore and close this issue but I would highly recommend to add a comment to your source code to notify others about this use case. If this is a duplicate issue, please accept my apologies for the redundancy as this simple automation is not smart enough to identify such issues.

Thank you!
-- Arman ([armish/blast-patrol](https://github.com/armish/blast-patrol))",armish,https://github.com/peterthorpe5/Methods_M.cerasi_R.padi_genome_assembly/issues/1,peterthorpe5++Methods_M.cerasi_R.padi_genome_assembly.csv
I_kwDOLi82ts6Ojcos,About publication information ,OPEN,2024-07-05T02:27:35Z,2024-07-06T01:49:07Z,,"Hi, this is a well-organized pipeline that will facilitate readers in practicing within their projects. However, I cannot find the detailed information regarding the corresponding literature, which poses a challenge for me to fully understand the process. Could you please provide a DOI or other publication information if the article is published?",changchuanjun,https://github.com/Phantom-Aria/Ap_genome_assembly/issues/1,Phantom-Aria++Ap_genome_assembly.csv
I_kwDOFbFZ4s6CQk7O,Can you provide some examples with the piple,OPEN,2024-03-14T04:16:29Z,2024-03-14T04:16:29Z,,"Hi, 
I finished the bash pl_getcg.sh step, now I am trying bash pl_treegen.sh but seems the file/path i am providing is not right....is possible to provide one example and also the command line so that I can try.",manik-123,https://github.com/PriyaLakr/coreGenomePhylogeny/issues/1,PriyaLakr++coreGenomePhylogeny.csv
MDU6SXNzdWUxMzM2OTgyMDU=,have spades respect cpu and memory constraints,CLOSED,2016-02-15T12:15:07Z,2016-03-24T18:13:04Z,2016-03-24T18:13:04Z,,pveber,https://github.com/pveber/genome-assembly-benchmark/issues/1,pveber++genome-assembly-benchmark.csv
MDU6SXNzdWUxNDIyMDE1NTc=,Include CGAL,OPEN,2016-03-20T20:29:02Z,2016-03-20T20:29:02Z,,,pveber,https://github.com/pveber/genome-assembly-benchmark/issues/2,pveber++genome-assembly-benchmark.csv
MDU6SXNzdWUxNDIyMDE1Njk=,Include ALE,OPEN,2016-03-20T20:29:10Z,2016-03-20T20:29:10Z,,,pveber,https://github.com/pveber/genome-assembly-benchmark/issues/3,pveber++genome-assembly-benchmark.csv
MDU6SXNzdWUxNDIyMDE1OTg=,Include FRCbam,OPEN,2016-03-20T20:29:41Z,2016-03-20T20:29:41Z,,,pveber,https://github.com/pveber/genome-assembly-benchmark/issues/4,pveber++genome-assembly-benchmark.csv
I_kwDOG73WaM5UDuiy,FEAT: Support genes annotations correction after fixing potential frameshifts,OPEN,2022-10-15T19:05:30Z,2022-10-15T20:34:26Z,,"At the moment, the tool is capable of detecting potential indels that may be causing ORF interruption(s) due frameshift(s) and then output a VCF with modifications to possible fix it. The next step, involving applying the VCF variants to the reference in order to get the corrected genomic sequence, is done by external tools such as `bcftools consensus`. After that, a new annotation file (i.e. gff and/or tbl) have to be generated by running external genome annotation tools. However, as far as i'm concern, we don't have to reannotate the corrected genome sequence.

A way to overcome this is by fixing the original genome annotation in those annotation features where frameshifts were located. Furthermore, literature shows that some indels leading to stop-codons within an ORF may be caused by true variants, particularly in fewer prokaryotes species [1]. This bacterial evolutionary event is known as ORF pseudogenisation. My proposals are (1) correct original annotations by lifting over annotation features positions from reference (initial genome sequence) to new genome sequence (i.e. after applying VCF variants), (2) if corrected gene annotation still leads to truncated protein annotate it with pseudogene tag and (3) output GFF3 following NCBI genbank genome submission guidelines [2].

[1] http://www.opiniomics.org/a-simple-test-for-uncorrected-insertions-and-deletions-indels-in-bacterial-genomes/

[2] https://www.ncbi.nlm.nih.gov/genbank/genomes_gff/

",rodtheo,https://github.com/rodtheo/rs-genomesub/issues/2,rodtheo++rs-genomesub.csv
I_kwDOLJHOOM6MY49K,Allow input reads to be in gzipped format,OPEN,2024-06-15T23:57:17Z,2024-06-15T23:57:17Z,,"Hi Roland,
It would be great if GenomeTailor would accept reads in gzipped format.
Thanks a lot in advance!",jflot,https://github.com/RolandFaure/GenomeTailor/issues/1,RolandFaure++GenomeTailor.csv
I_kwDOFeaGwM5S2fI0,TODO List,OPEN,2022-09-28T22:31:04Z,2023-02-14T05:29:36Z,,"- [x] Examine if the raw data can be downloaded directly from google drive to Ceres
- [x] Download and keep the raw data in Ceres. Google drive is preventing too many API downloads
- [x] Rearrange the files and folders in this repository
- [x] Create appropriate Dockerfiles and CWL tool scripts for reproducibility
    - [x] Create CWL tool script for the following general software: 
        - [x] gdrive
        - [x] samtools
        - [x] STAR
        - [x] bowtie2
        - [x] FGMP
    - [x] Genome assemblers
        - [x] masurca (http://www.genome.umd.edu/masurca.html)
        - [x] Megahit
        - [x] SOAPdenovo2
        - [x] ABySS 2.0 (https://genome.cshlp.org/content/27/5/768)
    - [x] Scaffolders
        - [x] Rascaf (file:///Users/gsfuerst/Downloads/tpg-9-3-plantgenome2016.03.0027.pdf) [Uses RNA-Seq reads]
        - [x] P_RNA_scaffolder (https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864.-018-4567-3?optIn=false)
        - [x] Create a wrapper for Rascaf to process from the tar.gz generated by ABySS
        - [x] Create a wrapper for P_RNA_scaffolder to process from the .tar.gz generated by ABySS
        - [x] Verify each scaffolder with dummy data
- [ ] Create the following workflows
  - [ ] Assemble reads into a draft assembly using multiple assemblers
  - [ ] Write CWL script for scaffolding the assembled reads
  - [ ] Merge assemblies, scaffolds, verification with FGMP and STAR alignments
- [x] Check the output generated by each assembler and name them properly to reflect the correct assembler and the parameters used to generate those. Repeat the same for scaffolders as well
- [x] Write a python script to read the outputs generated by STAR mapping and FGMP. Compile it into a single report
- [x] Write up a script to map denovo transcripts to corresponding genomic references. Also, use the stringtie transcriptome to detect genes/transcripts that could be elongated in this way.
- [ ] Add localizer, effectorP, signalP & BLASTp for functional analysis


",sagnikbanerjee15,https://github.com/sagnikbanerjee15/fungal_genome_assemblies_and_annotation/issues/1,sagnikbanerjee15++fungal_genome_assemblies_and_annotation.csv
MDU6SXNzdWU2ODQ0MjQ2MjE=,Week1,OPEN,2020-08-24T07:08:55Z,2020-08-24T07:09:05Z,,"
",Sakthi-Govindaraju,https://github.com/Sakthi-Govindaraju/Genome-Assembly-Programming-Challenge/issues/1,Sakthi-Govindaraju++Genome-Assembly-Programming-Challenge.csv
I_kwDOHptrP8590lfj,genomeassembly usage,CLOSED,2024-01-31T20:45:21Z,2024-02-01T12:24:07Z,2024-02-01T12:24:07Z,"Hi There,
I'm so happy that this pipeline has been released, I was looking forward to using it.
But while trying it on my data, I realized that the HiC dataset needs to be in .CRAM but I have it as paired .FASTQ (F and R). ",abdo3a,https://github.com/sanger-tol/genomeassembly/issues/34,sanger-tol++genomeassembly.csv
I_kwDOHptrP86DHF32,purge_dups and hifiasm?,OPEN,2024-03-21T09:46:36Z,2024-03-22T11:31:25Z,,"### Description of the bug

Hifiasm has built-in purging of haplotigs and seem to claim that purge_dups is too aggressive in purging (https://github.com/chhylp123/hifiasm/issues/162).  Have you done comparisons of the purging done by hifiasm and purge_dups? Would it make sense to allow users to disable the purge_dups purging or allow users to set the hifiasm purging parameters?

### Command used and terminal output

_No response_

### Relevant files

_No response_

### System information

_No response_",nikostr,https://github.com/sanger-tol/genomeassembly/issues/35,sanger-tol++genomeassembly.csv
I_kwDOHptrP86Egu4w,Input & help files,OPEN,2024-04-03T15:00:02Z,2024-06-10T17:09:39Z,,"### Description of feature

@muffato @gq1 @ksenia-krasheninnikova Hi, I want to run the pipeline with some insect genomes, I was wondering if there is any input or help files I can start with. Thanks",cintiaoi,https://github.com/sanger-tol/genomeassembly/issues/36,sanger-tol++genomeassembly.csv
I_kwDOHptrP86IIKsi,Multiple BUSCO lineages?,OPEN,2024-05-07T17:05:04Z,2024-06-04T12:08:05Z,,"Hi!

I was wondering if it's possible to specify more than one lineage and download path for BUSCO in the .yaml file.

Thanks for the help!",malvaradol,https://github.com/sanger-tol/genomeassembly/issues/43,sanger-tol++genomeassembly.csv
I_kwDOHptrP86RGXVf,Broken singularity longranger image + help with organelles workflow,CLOSED,2024-07-29T03:22:49Z,2024-08-16T09:35:28Z,2024-08-16T09:35:28Z,"### Description of the bug

Hi there!

I'm currently using the pipeline to assembly some data, and I find myself having issues with the polishing step. According to the error message, the longranger singularity image seems to be broken or no longer exists. I include here the .log file of the run. 

On the other hand, I had to run the pipeline without the organelles workflow as I have not figured out how to get it running, so I take advantage of the Longranger bug to make a few questions. Is the API key of the singularity secret provided by the HPC admin or is it something that I can find on my HPC home directory? Do i need to run the workflow with internet connection? This last question is because everything has to be run on an offline node, but pulling everything with nf-core tools was doing the work so far. I also include the .log of the organelles workflow.

Thanks in advance for all the help with the bug and the questions. Looking forward to your response.

### Command used and terminal output

```console
Longranger: nextflow run 0_10_0/main.nf --input tdimi_genome.yaml -profile singularity --outdir output_tdimi --organelles_on false --hifiasm_hic_on true --polishing_on true --max_cpus 32 --max_memory 640.GB

Organelles: nextflow run 0_10_0/main.nf --input tdimi_genome.yaml -profile singularity --outdir test_data --hifiasm_hic_on true --polishing_on true --organelles_on true --max_cpus 32 --max_memory 640.GB
```


### Relevant files

[nextflow_longranger.log](https://github.com/user-attachments/files/16407046/nextflow_longranger.log)
[nextflow_organelles.log](https://github.com/user-attachments/files/16407047/nextflow_organelles.log)


### System information

NF version: 24.04.3
Hardware: HPC
Executor: LSF
Container: Singularity
OS: CentOS
genomeassembly version: 0_10_0",malvaradol,https://github.com/sanger-tol/genomeassembly/issues/48,sanger-tol++genomeassembly.csv
I_kwDOHptrP86TNIbx,Version the mitohifi container,OPEN,2024-08-16T07:34:48Z,2024-08-16T07:34:48Z,,"### Description of feature

The current `dev` branch uses the container `ghcr.io/marcelauliano/mitohifi:master`.
I happened to have an old version of that container, from before Oct 2023, which made the pipeline fail when testing it.

To prevent that, the containers should be versioned and the module should be using the version.",muffato,https://github.com/sanger-tol/genomeassembly/issues/52,sanger-tol++genomeassembly.csv
I_kwDOHptrP86XV5Ka,Latest minimap2 version reduces peak memory,OPEN,2024-09-20T15:28:36Z,2024-09-20T15:28:36Z,,"### Description of the bug

The [latest version of minimap2](https://github.com/lh3/minimap2/releases/tag/v2.28) changes a default setting (`--cap-kalloc`) to reduce peak memory consumption. I keep running into memory issues, with the `MINIMAP2_ALIGN_ASSEMBLY` step requiring more than 100GB of RAM - would it make sense to update the version of minimap2 used in this pipeline?

### Command used and terminal output

_No response_

### Relevant files

_No response_

### System information

_No response_",nikostr,https://github.com/sanger-tol/genomeassembly/issues/54,sanger-tol++genomeassembly.csv
I_kwDOHptrP86Xqww3,"BUSCO bug, solved in latest BUSCO version",OPEN,2024-09-24T07:22:12Z,2024-10-15T09:30:16Z,,"### Description of the bug

I run into this bug https://gitlab.com/ezlab/busco/-/issues/721 when `SANGERTOL_GENOMEASSEMBLY:GENOMEASSEMBLY:GENOME_STATISTICS_PURGED:BUSCO` is being executed. This seems to be resolved in the latest version of BUSCO. 

### Command used and terminal output

```
nextflow run sanger-tol/genomeassembly \
        -resume \
        -c custom.config \
        -profile singularity,pdc_kth \
        --input assets/dataset.yaml \
        --outdir output-dir \
        -r 0.10.0 \
        --project <project-id>
```

### Relevant files

_No response_

### System information

_No response_",nikostr,https://github.com/sanger-tol/genomeassembly/issues/56,sanger-tol++genomeassembly.csv
I_kwDOHptrP86Yg_av,MitoHiFi -a parameter,OPEN,2024-10-01T10:11:05Z,2024-10-01T14:49:56Z,,"### Description of the bug

When attempting to run MitoHiFi it crashes with the following error message:
```
  'parsed_blast.txt' and 'parsed_blast_all.txt' files are empty.
  The pipeline has stopped !! You need to run further scripts to check if you have mito reads pulled to a large NUMT!
```
In https://github.com/marcelauliano/MitoHiFi/issues/58 the MitoHiFi author suggests that this may have to do with the `-a` parameter being incorrectly set. Would it make sense to allow users to pass this parameter as a part of the config?

### Command used and terminal output

_No response_

### Relevant files

_No response_

### System information

_No response_",nikostr,https://github.com/sanger-tol/genomeassembly/issues/57,sanger-tol++genomeassembly.csv
I_kwDOHN-IIM5IxQ4x,Nf-core module: bamtools/bamtobed,CLOSED,2022-04-29T13:50:05Z,2024-06-18T13:19:06Z,2022-06-22T11:56:52Z,"### Description of feature

Software/tool: bedtools/bamtobed

Function: Convert Aligned BAM to BED

",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/1,sanger-tol++genomenote.csv
I_kwDOHN-IIM5IxR6G,Nf-core module: samtools/view,CLOSED,2022-04-29T13:51:58Z,2024-06-18T13:19:06Z,2022-06-22T11:54:47Z,"### Description of feature

Software/tool: samtools/view

Function: Convert aligned CRAM file to BAM with flag `-F0x400`",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/2,sanger-tol++genomenote.csv
I_kwDOHN-IIM5IyA6L,Local module: bed_filter,CLOSED,2022-04-29T15:20:02Z,2024-06-18T13:19:07Z,2022-06-30T10:37:35Z,"### Description of feature

Software tool: `sort, paste, sed, awk, tr, sort`

Function: Filter the bed file

Current commands:
```
$$self{bamToBed} | sort -k4 --parallel=8 -S50G > $outfile.part])

cmd(qq[paste -d '\\t' - - < $bed | sed 's/-/_/g' | awk 'BEGIN {FS=""\\t""; OFS=""\\t""} {if (\$1 > \$7) {print substr(\$4,1,length(\$4)-2),\$12,\$7,\$8,""16"",\$6,\$1,\$2,""8"",\$11,\$5} else { print substr(\$4,1,length(\$4)-2),\$6,\$1,\$2,""8"",\$12,\$7,\$8,""16"",\$5,\$11} }' | tr '\\-+' '01'  | sort --parallel=8 -S10G -k3,3d -k7,7d > $outfile.part])
```",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/3,sanger-tol++genomenote.csv
I_kwDOHN-IIM5IyDMF,Local module: genome_filter,CLOSED,2022-04-29T15:24:21Z,2024-06-18T13:19:08Z,2022-10-05T17:11:51Z,"### Description of feature

Software/tool: `cut, sed`

Function: Filter the genome index file 

Current command:
```
cmd(qq[cut -f1,2 $ref_index | sed 's/-/_/g'|sort -k2,2 -nr > $$self{outdir}/$$self{hname}.genome])
```",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/4,sanger-tol++genomenote.csv
I_kwDOHN-IIM5IyFPe,Nf-core module: samtools/faidx,CLOSED,2022-04-29T15:28:30Z,2024-06-18T13:19:09Z,2022-06-22T11:55:28Z,"### Description of feature

Software/tool: samtools/faidx

Function: Index the genome fasta",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/5,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I2ktR,Nf-core module: cooler/zoomify,CLOSED,2022-05-01T19:46:57Z,2024-06-18T13:19:10Z,2022-10-05T17:11:37Z,"### Description of feature

Software/tool: cooler/zoomify

Function: create `mcool` from `cool` file",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/6,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I2k4t,Local module: cooler/cload_pairs,CLOSED,2022-05-01T19:50:46Z,2024-06-18T13:19:10Z,2022-07-01T06:35:27Z,"### Description of feature

Software/tool: cooler/cload_pairs

Function: Create the `.cool` file from filtered genome index and BED files",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/7,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I2leG,Local module: pretext,CLOSED,2022-05-01T20:01:13Z,2024-06-18T13:19:11Z,2022-05-09T14:27:29Z,"### Description of feature

Software/tool: pretext

Function: Create `pretext` contact maps from BAM",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/8,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I2swG,Subworkflow: contact_maps,CLOSED,2022-05-01T21:48:12Z,2024-06-18T13:19:12Z,2022-10-05T17:12:12Z,"### Description of feature

This subworkflow takes aligned CRAM files and creates contact maps using `cooler` and `pretext`.

**Step 1.**
Index the genome #5
Convert from BAM to BED #1

**Step 2.**
Filter the genome #4 
Filter the BED #3

**Step 3.**
Create `.cool` #7
Create pretext contact map #8 

**Step 4.**
Create cooler contact map #6

**Output**
`.pretext`
`.cool`
`.mcool`",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/9,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I2tvc,NG50,CLOSED,2022-05-01T22:03:12Z,2024-06-18T13:19:13Z,2022-10-05T17:10:32Z,"### Description of feature

For NG50, the details are in [Supplementary Note 4: Assessing overall assembly quality](https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-021-03451-0/MediaObjects/41586_2021_3451_MOESM1_ESM.pdf) but there is not enough information that I can calculate on my own.

This needs to be calculated for both contig and scaffold.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/10,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I2y5Y,Base pair QV,CLOSED,2022-05-01T23:14:00Z,2024-06-18T13:19:14Z,2022-10-05T17:10:39Z,"### Description of feature

For Base QV, the information is under [Base pair accuracy (QV) estimate](https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-021-03451-0/MediaObjects/41586_2021_3451_MOESM1_ESM.pdf). There are two methods: mapping based using longranger and kmer based using Merqury. As long as we have the [meryl](https://quay.io/repository/biocontainers/merqury) database, the kmer method is straight forward. There are also instructions to create meryl dbs: https://github.com/marbl/merqury/wiki/1.-Prepare-meryl-dbs",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/11,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I2zU8,Kmer completeness,CLOSED,2022-05-01T23:19:05Z,2024-06-18T13:19:14Z,2022-10-05T17:10:48Z,"### Description of feature

They did Kmer completeness with Merqury as well, details under [Quantifying false duplications with k-mers](https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-021-03451-0/MediaObjects/41586_2021_3451_MOESM1_ESM.pdf). We can use FastK if needed.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/12,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I4wjT,Transcript mappability,OPEN,2022-05-02T12:40:01Z,2024-10-01T10:55:39Z,,"### Description of feature

This is ideally done with RNA-seq data. It is equal to percentage of reads mapped to the genome.
Possible software: [WGSIM](https://github.com/lh3/wgsim)

 ",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/13,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5Mmw,Small test dataset,CLOSED,2022-05-02T14:22:59Z,2024-06-18T13:19:15Z,2022-06-22T10:19:06Z,"### Description of feature

Create a small test dataset for unit testing.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/14,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5N6g,Small test ,CLOSED,2022-05-02T14:27:45Z,2024-06-18T13:18:04Z,2023-05-18T23:13:22Z,"### Description of feature

Organism: Chicken of the woods, Laetiporus sulphureus (gfLaeSulp1)

",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/15,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5OVl,Small test,CLOSED,2022-05-02T14:29:18Z,2024-06-18T13:18:05Z,2023-12-08T13:55:50Z,"### Description of feature

Organism: Chicken of the woods, Laetiporus sulphureus (gfLaeSulp1)",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/16,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5PXD,Medium test,CLOSED,2022-05-02T14:32:59Z,2024-06-18T13:18:05Z,2023-05-18T23:23:57Z,"### Description of feature

Organism: Mottled umber, Erannis defoliaria (ilEraDefo1)",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/17,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5Pyn,Medium test,CLOSED,2022-05-02T14:34:30Z,2024-06-18T13:18:06Z,2023-12-08T13:55:56Z,"### Description of feature

Organism: Mottled umber, Erannis defoliaria (ilEraDefo1)",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/18,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5QMw,Large test,CLOSED,2022-05-02T14:35:52Z,2024-06-18T13:18:07Z,2023-05-18T23:35:58Z,"### Description of feature

Organism: Red deer, Cervus elaphus (mCerEla1)",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/19,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5Qek,Large test,CLOSED,2022-05-02T14:36:54Z,2024-06-18T13:18:07Z,2023-12-08T13:56:01Z,"### Description of feature

Organism: Red deer, Cervus elaphus (mCerEla1)",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/20,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5VVk,Local module: input_check,CLOSED,2022-05-02T14:54:56Z,2022-10-05T17:11:00Z,2022-10-05T17:10:59Z,"### Description of feature

For the first milestone, the module checks the CRAM and genome file paths. If the file exists, it passes them downstream.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/21,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5VfQ,Subworkflow: check_input,CLOSED,2022-05-02T14:55:31Z,2022-10-05T17:11:14Z,2022-10-05T17:11:14Z,"### Description of feature

This subworkflow takes the aligned CRAM file location and estimates the location of all the other required files. If not ToL file structure, than the input file is needed.

For the first milestone, it requires the genome and CRAM aligned file, which can both be provided as params. 

**Step 1.**
Check file paths #21",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/22,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5gAm,Genome mappability,OPEN,2022-05-02T15:34:48Z,2024-09-09T13:55:39Z,,"### Description of feature

It is equal to percentage of reads mapped to the genome.
Possible software: [WGSIM](https://github.com/lh3/wgsim)",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/23,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5isJ,Sex chromosomes,OPEN,2022-05-02T15:45:38Z,2024-06-02T09:18:19Z,,"### Description of feature

Are sex chromosomes localised homologous pairs?",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/24,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5jaZ,Organelles,CLOSED,2022-05-02T15:48:14Z,2024-06-18T13:17:35Z,2022-11-30T16:58:31Z,"### Description of feature

Should be one complete allele?",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/25,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5kdx,BUSCO,CLOSED,2022-05-02T15:52:54Z,2024-06-18T13:17:24Z,2022-10-05T17:09:53Z,"### Description of feature

Calculate BUSCO scores from the genome",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/26,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5mAe,Subworkflow: table_statistics,CLOSED,2022-05-02T15:59:55Z,2024-06-18T13:17:19Z,2022-11-30T16:58:32Z,"### Description of feature

This needs to be further defined.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/27,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5p2a,README,CLOSED,2022-05-02T16:14:35Z,2023-05-18T13:21:29Z,2023-05-18T13:21:28Z,"### Description of feature

1. Introduction
2. Pipeline Summary
3. Quick Start
4. Documentation
5. Credits
6. Contributions and Support
7. Citations",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/28,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5qO0,docs/README,CLOSED,2022-05-02T16:16:03Z,2023-05-18T13:21:30Z,2023-05-18T13:21:29Z,"### Description of feature

Details of pipeline documentation.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/29,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5qbj,docs/usage,CLOSED,2022-05-02T16:16:48Z,2023-05-18T13:21:30Z,2023-05-18T13:21:30Z,"### Description of feature

An overview of how the pipeline works, how to run it and a description of all of the different command-line flags.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/30,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5qwR,docs/output,CLOSED,2022-05-02T16:18:04Z,2023-05-18T13:21:31Z,2023-05-18T13:21:31Z,"### Description of feature

An overview of the different results produced by the pipeline and how to interpret them.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/31,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5q-k,docs/parameter,CLOSED,2022-05-02T16:18:54Z,2023-05-18T13:21:32Z,2023-05-18T13:21:31Z,"### Description of feature

An overview of the different parameters used by the pipeline and how to interpret them.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/32,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5v8A,CITATIONS,CLOSED,2022-05-02T16:38:20Z,2024-06-18T13:16:57Z,2023-05-18T13:21:32Z,"### Description of feature

An extensive list of references for the tools used by the pipeline.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/33,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5wQ6,JSON files,CLOSED,2022-05-02T16:39:48Z,2024-06-18T13:16:58Z,2023-05-18T13:21:33Z,"### Description of feature

Update the following 3 files:
1. `modules.json`
2. `modules_local.json`
3. `subworkflows_local.json`",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/34,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5xJl,CHANGELOG,CLOSED,2022-05-02T16:44:06Z,2024-06-18T13:16:58Z,2023-05-18T13:21:33Z,"### Description of feature

All notable changes added and fixed. Also all dependencies and the deprecated features.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/35,sanger-tol++genomenote.csv
I_kwDOHN-IIM5I5zDt,Update documentation,CLOSED,2022-05-02T16:52:40Z,2023-05-18T13:21:34Z,2023-05-18T13:21:34Z,"### Description of feature

1. README - Pipeline summary
2. docs/usage - Samplesheet input
3. docs/parameters
4. docs/output
5. CITATIONS
6. JSON files
7. CHANGELOG",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/36,sanger-tol++genomenote.csv
I_kwDOHN-IIM5TfZ5x,Unnecessary sort,CLOSED,2022-10-07T07:25:06Z,2022-11-30T16:58:33Z,2022-11-30T16:58:33Z,"### Description of the bug

Found whilst reviewing #44 

In the contact_maps subworkflow, bedtools/bamtobed already sorts the bed file, cf https://github.com/sanger-tol/nf-core-modules/blob/main/modules/bedtools/bamtobed/main.nf#L28
There is no need to sort it again at https://github.com/sanger-tol/genomenote/blob/dev/subworkflows/local/contact_maps.nf#L41

(noticed that because bedtools/bamtobed takes a ton of memory)


### Command used and terminal output

_No response_

### Relevant files

_No response_

### System information

_No response_",muffato,https://github.com/sanger-tol/genomenote/issues/45,sanger-tol++genomenote.csv
I_kwDOHN-IIM5Vvfs6,Update bed_filter,CLOSED,2022-11-07T15:04:42Z,2024-06-18T13:16:19Z,2022-11-30T16:58:33Z,"### Description of the bug

The current version of the `bed_filter.sh` does not filter out truncated rows, so I want to add that functionality, with an additional pipe: ` | awk 'NF==11'` ",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/47,sanger-tol++genomenote.csv
I_kwDOHN-IIM5VvhZL,update `bedtools_bamtobed` config settings,CLOSED,2022-11-07T15:08:09Z,2022-11-30T16:58:33Z,2022-11-30T16:58:33Z,"### Description of the bug

For `bedtools_bamtobed` update config settings to start with the following settings
```
    withName: ""BEDTOOLS_BAMTOBED"" {
        cpus   = { 2                    }
        memory = { 48.GB * task.attempt }
        time   = { 4.h   * task.attempt }
    }
```
",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/48,sanger-tol++genomenote.csv
I_kwDOHN-IIM5VvklV,N50 from GoaT not always available,CLOSED,2022-11-07T15:16:27Z,2022-11-30T16:58:34Z,2022-11-30T16:58:34Z,"### Description of the bug

N50 values from GoaT are not always available, this means either that statistic calculation is skipped or it might be useful to implement this functionality using a stand alone tool. Examples: `Malus domestica` genomes `GCA_916050505.1` and `GCA_916615275.2`.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/49,sanger-tol++genomenote.csv
I_kwDOHN-IIM5VvmlS,Update `create_table` to deal with optional inputs,CLOSED,2022-11-07T15:22:10Z,2022-11-30T16:58:34Z,2022-11-30T16:58:34Z,"### Description of the bug

It is not possible to always run `merquryfk` for genome notes. Currently, this means that `create_table` is not run as well, as all inputs are required. The module needs update to accommodate optional inputs. Alternatively, the other results files can be published and processed separately.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/50,sanger-tol++genomenote.csv
I_kwDOHN-IIM5Vv5qp,Remove `bedtools_sort`,CLOSED,2022-11-07T16:14:14Z,2022-11-30T16:58:35Z,2022-11-30T16:58:35Z,"### Description of the bug

Currently the `bedtools_bamtobed` module includes `bedtools_sort`, which consumes a lot of memory. Considering removing the `sort` step and implementing with the basic linux `sort`
[Bedtools](https://bedtools.readthedocs.io/en/latest/content/tools/sort.html) recommends `sort -k 1,1 -k2,2n a.bed` 
Currently the `bed_sort` step after `bedtools_bamtobed` run `sort -k4`, so these need to be combined, before filtering.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/51,sanger-tol++genomenote.csv
I_kwDOHN-IIM5XoPoU,Headers created without content,CLOSED,2022-11-30T20:14:38Z,2022-12-03T23:50:03Z,2022-12-03T23:50:03Z,"### Description of the bug

In the `create_table.py` script, even when certain data is missing, headers may be created. See `Organelle` in example:
```
##Assembly_Information
Accession,GCA_943735745.1
Organism_Name,Anopheles bellator
ToL_ID,idAnoBell3
Taxon_ID,139047
Assembly_Name,idAnoBellAS_SP24_06
Assembly_Level,Chromosome
Life_Stage,adult
Tissue,WHOLE ORGANISM
Sex,NOT PROVIDED
##Assembly_Statistics
Total_Sequence,169575294
Chromosomes,3
Scaffolds,2985
Scaffold_N50,85293694
Contigs,5058
Contig_N50,196687
GC_Percent,48.5
##Chromosome,Length,GC_Percent
1,85293694,48.5
2,60404489,49
X,12334942,48
##Organelle,Length,GC_Percent
##BUSCO
Lineage,diptera_odb10
Summary,""C:97.2%[S:96.3%,D:0.9%],F:0.6%,M:2.2%,n:3285""
```

### Command used and terminal output

_No response_

### Relevant files

_No response_

### System information

_No response_",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/52,sanger-tol++genomenote.csv
I_kwDOHN-IIM5Xqc7z,Get HiC Mapping result in summary table,CLOSED,2022-12-01T06:14:42Z,2022-12-03T23:49:51Z,2022-12-03T23:49:51Z,"### Description of feature

`create_table` should take `hic.flagstat` file and add the `primary mapped` statistic to the summary table.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/53,sanger-tol++genomenote.csv
I_kwDOHN-IIM5XsH39,FastK optional module,CLOSED,2022-12-01T11:57:04Z,2024-06-18T13:16:08Z,2023-02-24T09:02:04Z,"### Description of feature

Add the fastk module but make it optional, only run if read files are provided instead of the kmer database.",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/54,sanger-tol++genomenote.csv
I_kwDOHN-IIM5XtZ61,Add support for multiple PacBio kmer databases,CLOSED,2022-12-01T15:32:08Z,2023-05-18T13:21:35Z,2023-05-18T13:21:35Z,"### Description of the bug

Currently if multiple kmer databases are provided, only one is run and does not always get copied to create table accurately. Feature with multiple kmer databases and how it will be integrated into the final table needs work.

### Command used and terminal output

_No response_

### Relevant files

_No response_

### System information

_No response_",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/55,sanger-tol++genomenote.csv
I_kwDOHN-IIM5X6lNb,Make chromosomes optional,CLOSED,2022-12-04T16:35:48Z,2022-12-04T23:55:39Z,2022-12-04T23:55:39Z,"### Description of the bug

Not also assemblies are chromosome level, for these assemblies the current script throws an error as it is missing field `total_number_of_chromosomes`.
1. Make `Chromosomes` optional
2. Move the `chromosome` header inside loop similar to `organelle`",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/58,sanger-tol++genomenote.csv
I_kwDOHN-IIM5p8tCJ,Genome metadata,CLOSED,2023-06-27T18:29:20Z,2024-04-27T19:55:19Z,2024-04-27T19:55:19Z,"### Description of feature

Improve genome metadata fetching and processing",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/71,sanger-tol++genomenote.csv
I_kwDOHN-IIM5p9Xwx,Optional readmapping subworkflow,OPEN,2023-06-27T20:21:54Z,2024-06-17T12:58:14Z,,"### Description of feature
Create optional subworkflow to map HiC reads before creating contact maps",priyanka-surana,https://github.com/sanger-tol/genomenote/issues/72,sanger-tol++genomenote.csv
I_kwDOHN-IIM5u7cQ9,meta.id confusion,CLOSED,2023-08-22T09:46:47Z,2024-10-11T15:02:28Z,2024-10-11T15:02:28Z,"### Description of the bug

On the public_dev branch, the input fasta is called `GCA_946965045.1.fasta.gz` and the Hi-C CRAM file `GCA_946965045.1.unmasked.hic.uoEpiScrs1.subsampled.cram`, but the assembly parameter is set to `GCA_946965045.2`. After a run of the `test` profile, 1) I get these two files in the `genome_note/` directory:
- `GCA_946965045.1.csv`
- `GCA_946965045.2.docx`

2), `GCA_946965045.1.csv` contains:
```csv
Accession,GCA_946965045.1
```
3), and many more intermediate files are also named `GCA_946965045.1.*`, indicating that the pipeline is confused about what is `meta.id`.

The input file names can be different from the accession number etc, but I'd expect the outputs of the pipeline to be consistently named.


### Command used and terminal output

```console
nextflow run sanger-tol/genomenote/ -profile test,singularity -r public_dev
```


### Relevant files

_No response_

### System information

Nextflow 23.04.1-5866 from our central installation",muffato,https://github.com/sanger-tol/genomenote/issues/79,sanger-tol++genomenote.csv
I_kwDOHN-IIM5u7pGh,Inconsistent variable names in the DOCX template,CLOSED,2023-08-22T10:09:48Z,2024-06-13T15:37:47Z,2024-06-13T15:37:47Z,"### Description of the bug

The `genome_note_template.docx` provided in the pipeline has inconsistent naming of some variables. For instance, the scaffold N50 is indicated with both `SCAFF_N50` (in the text) and `scaffold_N50` (in the table). The pipeline uses `SCAFF_N50` as the variable, leaving the field in the table empty.
The contig N50 is indicated as `contig_N50` in the table but the pipeline provides `CONTIG_N50` so the table is still empty.
The title of the table 2 refers to a variable named `species` but `SPECIES_GENUS` is defined by the pipeline so it remains empty.
There are probably more examples like this.

Something to pass on to Karen ?

### Command used and terminal output

_No response_

### Relevant files

_No response_

### System information

_No response_",muffato,https://github.com/sanger-tol/genomenote/issues/80,sanger-tol++genomenote.csv
I_kwDOHN-IIM51B5tg,ERROR ~ toIndex = 2 -- Check script 'genomenote/./workflows/genomenote.nf' at line: 98,CLOSED,2023-10-26T12:17:16Z,2024-10-03T13:21:29Z,2024-10-03T13:21:29Z,"### Description of the bug

Hi. I'm interested in trying this pipeline, but running into issues. The main one is the error immediately after running:
```{bash}
ERROR ~ toIndex = 2

 -- Check script 'genomenote/./workflows/genomenote.nf' at line: 98 or see '.nextflow.log' file for more details
```
My commands and the sample sheet are below. Thanks!


### Command used and terminal output

```console
DIRIN=/mount/home/user/data/WorkData/proj1/2023-08.HiC_test
INPUT=${DIRIN}/samplesheet_genomenote.csv
DIROUT=${DIRIN}/OUT_genomenote
GENOME=/mount/home/user/data/ExtData/UCSC/hg38/hg38.fa
nextflow run sanger-tol/genomenote --input ${INPUT} \
  --outdir ${DIROUT} \
  --fasta ${GENOME} \
  -profile singularity
```


### Relevant files

sample,datatype,datafile
sample1,hic,/mount/home/user/data/WorkData/proj1/2023-08.HiC_test/sample1/data/aligned/merged_dedup.bam
sample2,hic,/mount/home/user/data/WorkData/proj1/2023-08.HiC_test/sample2/data/aligned/merged_dedup.bam

### System information

Nextflow version 23.04.3 build 5875
HPC
local
singularity
CentOS
latest cloned sanger-tol/genomenote",mdozmorov,https://github.com/sanger-tol/genomenote/issues/87,sanger-tol++genomenote.csv
I_kwDOHN-IIM51Yn3q,Order the contact map like the karyotype,CLOSED,2023-10-30T23:38:37Z,2024-05-01T21:15:24Z,2024-05-01T21:15:24Z,"### Description of feature

Currently, the pipeline orders the sequences in the contact map by decreasing size (`FILTER_GENOME` process). Whilst it is reasonable for many species, there are cases where it's not the best choice:

- Some species have chromosome names that predate genome sequencing and don't follow the sizes in base-pairs. This is the case of many primates, starting with human, chimpanzee, gibbon, etc.
- Traditionally, sex chromosomes are placed after the autosomes.
- Very large genomes like [Meconema thalassinum](https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_946902985.2/) have sequences too large to be in INSDC as one piece (the limit is 2^31-1 bp) and are split into chromosome 1_1, chromsome 1_2, etc. On the map, the fragments have to be put right next to each other in the right order.

To overcome this, I propose reading the sequence report from NCBI datasets, which is already pulled by the pipeline and is ordered correctly, and copy the order into the contact map.",muffato,https://github.com/sanger-tol/genomenote/issues/88,sanger-tol++genomenote.csv
I_kwDOHN-IIM51Yoyc,Deprecate generating the `.genome` file,CLOSED,2023-10-30T23:43:06Z,2023-11-20T16:19:29Z,2023-11-20T16:19:29Z,"### Description of feature

We found out today that the `.genome` file is superfluous. HiGlass has an option to draw the chromosome grid from the cool file directly.

We can therefore consider not generating the file at all in this pipeline, which makes things a bit simpler.",muffato,https://github.com/sanger-tol/genomenote/issues/89,sanger-tol++genomenote.csv
I_kwDOHN-IIM52_uUI,Leftover files in /tmp from the `sort` commands,CLOSED,2023-11-16T09:18:57Z,2023-12-08T13:58:30Z,2023-12-08T13:58:30Z,"### Description of the bug

We've been regularly hit issues in production: no more space in `/var/tmp` and then farm nodes closed.

The problems come from the `sort` commands leaving files in their `/tmp`.

First, the biocontainer isn't mounting `/tmp` properly and instead uses `/var/tmp`, which only has 40 GB. Our workaround is to explicitly mount `/tmp`.

The second issue comes from LSF killing the `sort` commands because of MEMLIMIT.

### Command used and terminal output

_No response_

### Relevant files

_No response_

### System information

_No response_",muffato,https://github.com/sanger-tol/genomenote/issues/91,sanger-tol++genomenote.csv
I_kwDOHN-IIM55KN4G,Agree on which Busco lineage to use for which species,OPEN,2023-12-08T14:07:51Z,2024-06-17T20:16:02Z,,"### Description of feature

We use Busco to assess the completeness & fragmentation of an assembly. The main parameter is a lineage name, that needs to be phylogenetically relevant to the species being tested. Our implementations are inconsistent:

- BlobToolKit computes Busco against all lineages that are parent of the species, and Rich provides the closest one to Karen.
- Here, @muffato suggested that _all_ mammals should be evaluated against `eutheria_odb10` rather than the more specific ones (rodents, primates, etc): https://github.com/sanger-tol/genomenote/blob/1.0.0/bin/get_odb.py#L35-L36
- When assessing an assembly, ToLA follow these rules: https://github.com/sanger-tol/tol-workflows/blob/360c14086a5eab3804a5c35bedff0aa47fd6c7f1/wr/wr-asm-analysis#L31-L58

We need to agree on one rule and use it throughout all pipelines.",muffato,https://github.com/sanger-tol/genomenote/issues/100,sanger-tol++genomenote.csv
I_kwDOHN-IIM56J7LZ,Report all samples in the statistics CSV,CLOSED,2023-12-19T20:57:08Z,2024-06-18T13:15:35Z,2024-05-01T21:15:24Z,"### Description of feature

Currently, the statistics CSV file is generated from the first PacBio specimen and the first Hi-C specimen that reach its module. If there is more than one specimen, the other ones are computed/analysed but _not_ included in the CSV.
",muffato,https://github.com/sanger-tol/genomenote/issues/104,sanger-tol++genomenote.csv
I_kwDOHN-IIM6BESX8,Error executing process GENOME_STATISTICS:SUMMARYSEQUENCE with invalid assembly accession,CLOSED,2024-03-03T14:27:24Z,2024-10-11T15:01:53Z,2024-10-11T15:01:53Z,"### Description of the bug

I encountered an error while executing the SANGERTOL_GENOMENOTE:GENOMENOTE:GENOME_STATISTICS:SUMMARYSEQUENCE process in the sanger-tol/genomenote pipeline. The process fails with an ""invalid or unsupported assembly accession"" error message when attempting to generate a sequence summary JSON file using the datasets command. This issue arises despite following the pipeline's usage instructions and providing valid input parameters.

```console
-[sanger-tol/genomenote] Pipeline completed with errors-
[0b/de2c7e] Submitted process > SANGERTOL_GENOMENOTE:GENOMENOTE:GENOME_STATISTICS:SUMMARYSEQUENCE (genome.1)
[f9/348360] Submitted process > SANGERTOL_GENOMENOTE:GENOMENOTE:INPUT_CHECK:SAMPLESHEET_CHECK (samplesheet.csv)
[81/f56f5d] Submitted process > SANGERTOL_GENOMENOTE:GENOMENOTE:GENOME_STATISTICS:SUMMARYGENOME (genome.1)
[9e/883111] Submitted process > SANGERTOL_GENOMENOTE:GENOMENOTE:CONTACT_MAPS:SAMTOOLS_FAIDX (genome.1.fasta)
ERROR ~ Error executing process > 'SANGERTOL_GENOMENOTE:GENOMENOTE:GENOME_STATISTICS:SUMMARYSEQUENCE (genome.1)'

Caused by:
  Process `SANGERTOL_GENOMENOTE:GENOMENOTE:GENOME_STATISTICS:SUMMARYSEQUENCE (genome.1)` terminated with an error exit status (1)

Command executed:

  datasets \
      summary \
      genome \
      accession \
      genome.1 \
      --report sequence \
      > genome.1_sequence.json
  
  validate_datasets_json.py genome.1_sequence.json
  
  cat <<-END_VERSIONS > versions.yml
  ""SANGERTOL_GENOMENOTE:GENOMENOTE:GENOME_STATISTICS:SUMMARYSEQUENCE"":
      ncbi-datasets-cli: $(datasets --version | sed 's/^.*datasets version: //')
  END_VERSIONS

Command exit status:
  1

Command output:
  (empty)

Command error:
  Error: invalid or unsupported assembly accession: genome.1
  
  Use datasets summary genome accession <command> --help for detailed help about a command.

Work dir:
  /media/la_nube/tools/genomenotes/work/0b/de2c7e9f02030233c72ca802f6d05c

Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`

 -- Check '.nextflow.log' file for details
```

### Command used and terminal output

```console
nextflow run sanger-tol/genomenote \
   -profile docker \
   -r 1.1.1 \
   --input samplesheet.csv \
   --fasta genome.1.fasta \
   --outdir genomenote_results \
   --max_cpus 20 \
   --max_memory 200GB \
   --max_time '999h' \
   -resume
```


### Relevant files

_No response_

### System information

Pipeline Version: 1.1.1
Nextflow Version: 23.10.1
Execution Environment: Docker
Hardware: Workstation
OS: Linux Ubuntu
Executor: Local 
Container engine: Docker, Singularity",mtammami,https://github.com/sanger-tol/genomenote/issues/109,sanger-tol++genomenote.csv
I_kwDOHN-IIM6MII_Q,Allow running of metatdata subworkflow on multiple specimen IDs,CLOSED,2024-06-13T11:51:21Z,2024-07-30T10:51:27Z,2024-07-30T10:51:27Z,"### Description of feature

A genome note provides meta data related to the specimen used to produce the genome assembly, the specimen used to generate HiC data and the specimen used to produce RNA-Seq data. These may all be different specimens. The genome note pipeline should be able to take in each of these IDs and run the metadata subworkflow on each, recording the relevant data for use in the publication    ",BethYates,https://github.com/sanger-tol/genomenote/issues/114,sanger-tol++genomenote.csv
I_kwDOHN-IIM6MJAuV,Add COPO to the metadata sources,CLOSED,2024-06-13T13:32:54Z,2024-09-26T16:05:56Z,2024-09-26T16:05:56Z,"### Description of feature

Add COPO to the set of sources queried by the genome metadata subworkflow",BethYates,https://github.com/sanger-tol/genomenote/issues/115,sanger-tol++genomenote.csv
I_kwDOHN-IIM6MJEWk,Add GFA stats ,OPEN,2024-06-13T13:38:56Z,2024-08-12T15:31:20Z,,"### Description of feature

Add GFA stats https://github.com/vgl-hub/gfastats to the genome statistics subworkflow
",BethYates,https://github.com/sanger-tol/genomenote/issues/116,sanger-tol++genomenote.csv
I_kwDOHN-IIM6MKP2I,Merqury and Meryl,OPEN,2024-06-13T15:50:37Z,2024-08-12T15:31:17Z,,"### Description of feature

Allow running of Merqury and Meryl as an alternative to Merqury.FK? As used by CBP and Nor-BP",BethYates,https://github.com/sanger-tol/genomenote/issues/117,sanger-tol++genomenote.csv
I_kwDOHN-IIM6MKVDB,Set Higlass config default values,CLOSED,2024-06-13T16:00:46Z,2024-10-11T15:02:59Z,2024-10-11T15:02:59Z,"### Description of feature

Evaluate HiC maps of multiple species to try and set some suitable default values to set in the config when uploading HiC data to Higlass",BethYates,https://github.com/sanger-tol/genomenote/issues/118,sanger-tol++genomenote.csv
I_kwDOHN-IIM6MKpFB,Refine input params,CLOSED,2024-06-13T16:43:46Z,2024-10-11T15:02:13Z,2024-10-11T15:02:13Z,"### Description of feature

Refine input parameters and samplesheet checking ahead of release 2.0",BethYates,https://github.com/sanger-tol/genomenote/issues/119,sanger-tol++genomenote.csv
I_kwDOHN-IIM6MjHcU,Make BUSCO annotations an optional input,OPEN,2024-06-17T18:47:16Z,2024-09-06T13:45:23Z,,,muffato,https://github.com/sanger-tol/genomenote/issues/120,sanger-tol++genomenote.csv
I_kwDOHN-IIM6M7Z7c,Sub-workflow for gene statistics,OPEN,2024-06-20T12:57:52Z,2024-08-16T15:22:34Z,,"We want to be able to include some standard basic statistics on the gene/protein annotation set for an assembly in a genome note. This sub workflow should accept an annotation set and calculate some statistics, (exact values still to be determined but will most likely be things like the number of protein coding genes, number of non-coding genes, exons per transcript etc as well as BUSCO scores).

This could be a standalone pipeline or could be added to either the genomenote pipeline or to the ensemblgenedownload pipeline, although it may not always be Ensembl that provides the annotations.


- Exon count
- Exon length
- Intron length
- DNA strand bias

",BethYates,https://github.com/sanger-tol/genomenote/issues/121,sanger-tol++genomenote.csv
I_kwDOHN-IIM6M7aaS,Flagger,OPEN,2024-06-20T12:58:33Z,2024-06-20T13:00:07Z,,Investigate adding Flagger to the genomenote pipeline to evaluate diploid assemblies,BethYates,https://github.com/sanger-tol/genomenote/issues/122,sanger-tol++genomenote.csv
I_kwDOHN-IIM6M7ac_,GenomeScope,OPEN,2024-06-20T12:58:38Z,2024-06-20T13:00:20Z,,Include GenomeScope profile in genome note?,BethYates,https://github.com/sanger-tol/genomenote/issues/123,sanger-tol++genomenote.csv
I_kwDOHN-IIM6M7ang,MUMmer,OPEN,2024-06-20T12:58:57Z,2024-06-20T13:00:26Z,,MUMmer used by Nor-BP to evaluate differences between assembly haplotypes. Is this something we want to add as an option to the genomenote pipeline?,BethYates,https://github.com/sanger-tol/genomenote/issues/124,sanger-tol++genomenote.csv
I_kwDOHN-IIM6NQgD9,Add GBIF to the metadata sources,CLOSED,2024-06-24T10:50:48Z,2024-10-03T16:25:09Z,2024-10-03T16:25:08Z,"### Description of feature

Add GBIF to the set of sources queried by the genome metadata subworkflow
",BethYates,https://github.com/sanger-tol/genomenote/issues/125,sanger-tol++genomenote.csv
I_kwDOHN-IIM6Ol9ng,ERROR pipeline failure when fields missing from NCBI genome report [v1.2.0],CLOSED,2024-07-05T10:21:18Z,2024-08-01T13:03:03Z,2024-08-01T13:03:03Z,"### Description of the bug

Key error from `create_table.py`: 
```
Command error:
  Traceback (most recent call last):
    File ""/lustre/scratch123/tol/teams/tolit/users/tolpipe/registered_workflows/prod/sanger-tol/genomenote-1.2.0/workflow/bin/create_table.py"", line 182, in <module>
      sys.exit(main())
    File ""/lustre/scratch123/tol/teams/tolit/users/tolpipe/registered_workflows/prod/sanger-tol/genomenote-1.2.0/workflow/bin/create_table.py"", line 171, in main
      ncbi_stats(args.genome, args.sequence, writer)
    File ""/lustre/scratch123/tol/teams/tolit/users/tolpipe/registered_workflows/prod/sanger-tol/genomenote-1.2.0/workflow/bin/create_table.py"", line 81, in ncbi_stats
      writer.writerow([""Scaffolds"", stats[""number_of_scaffolds""]])
  KeyError: 'number_of_scaffolds'
```

Failure is on assembly `GCA_963966575.1` which lacks several expected fields in assembly stats: 
```
  ""assemblyStats"": {
    ""contigL50"": 32,
    ""contigN50"": 24519,
    ""gcCount"": ""788905"",
    ""gcPercent"": 38.0,
    ""genomeCoverage"": ""46.0x"",
    ""numberOfComponentSequences"": 87,
    ""numberOfContigs"": 87,
    ""totalSequenceLength"": ""2065980"",
    ""totalUngappedLength"": ""2065980""
  },
  ```

### Command used and terminal output

_No response_

### Relevant files

_No response_

### System information

_No response_",tkchafin,https://github.com/sanger-tol/genomenote/issues/126,sanger-tol++genomenote.csv
I_kwDOHN-IIM6W4ot9,Add BUSCO to the annotation_statistics subworkflow,CLOSED,2024-09-17T15:12:14Z,2024-11-19T09:28:59Z,2024-11-19T09:28:58Z,,BethYates,https://github.com/sanger-tol/genomenote/issues/141,sanger-tol++genomenote.csv
I_kwDOHN-IIM6aF0JT,Allow inclusion of multiple species in a single genome note,OPEN,2024-10-14T08:25:59Z,2024-10-14T08:26:25Z,,"### Description of feature

A question following the BGA genomenote session:

Stephania Sandoval: I had to leave the session a bit early today but I wanted to ask if the pipeline can be used for more than one species at a time. For example, if you have several species from the same genus and want to put them all in one genome note instead of individual notes, can that be incorporated into this pipeline? thank you!
",BethYates,https://github.com/sanger-tol/genomenote/issues/148,sanger-tol++genomenote.csv
MDU6SXNzdWU1NzIyNDg5NjI=,about pan-genome analysis,OPEN,2020-02-27T17:47:46Z,2020-08-31T07:25:26Z,,"Hello,
Much appreciated for your excellent work.
I try to run your code in my project with pangenome command. 
I met a error as following:
Starting ======   2020-02-27 12:40:48   ======
Traceback (most recent call last):
  File ""/isilon/saskatoon-rdc/users/fuf/comDIR/AMPRIL-genomes/pangenome/wga.pangenome.py"", line 236, in <module>
    main(sys.argv[1:])
  File ""/isilon/saskatoon-rdc/users/fuf/comDIR/AMPRIL-genomes/pangenome/wga.pangenome.py"", line 52, in main
    result = runJob(arr, num, chrBeds, accs, wgadir, outdir)
  File ""/isilon/saskatoon-rdc/users/fuf/comDIR/AMPRIL-genomes/pangenome/wga.pangenome.py"", line 91, in runJob
    t = getLen(chrBeds[accs[j]])
  File ""/isilon/saskatoon-rdc/users/fuf/comDIR/AMPRIL-genomes/pangenome/wga.pangenome.py"", line 217, in getLen
    fi = open(inFile,""r"")
IOError: [Errno 2] No such file or directory: './chrsize/C24.leng.txt'
###########################################################################
So can I use your code in my project? Because I check the command and find you have difined the accs as following:
 accs = [""An-1"",""C24"",""Col"",""Cvi"",""Eri"",""Kyo"",""Ler"",""Sha""].
I think this is only for your project.
Thanks,
Fuyou",sunnycqcn,https://github.com/schneebergerlab/AMPRIL-genomes/issues/1,schneebergerlab++AMPRIL-genomes.csv
MDU6SXNzdWU2ODg1MjMxODY=,annotation.config,OPEN,2020-08-29T12:19:44Z,2020-08-31T07:47:29Z,,"I guess that before I run evm.pasa.integrate.pipeline.py, I should create a config file named annotation.config. but can you show me the format and content of the config file ? thanks",liufy11,https://github.com/schneebergerlab/AMPRIL-genomes/issues/2,schneebergerlab++AMPRIL-genomes.csv
MDU6SXNzdWU2ODg5OTQ3NzI=,output of genome,CLOSED,2020-08-31T07:43:01Z,2020-08-31T07:53:13Z,2020-08-31T07:53:13Z,"Hello! I get the result of pangenome. but I don't know the meaning of the file. like pan-genome.wga.conensus.statspan-genome.wga.core.stats  pan-genome.wga.newseq.stats and files in tmp. like An-1.com-2.wga.bed,  tmp.An-1.C24.bed and so on . ",liufy11,https://github.com/schneebergerlab/AMPRIL-genomes/issues/3,schneebergerlab++AMPRIL-genomes.csv
MDU6SXNzdWU2ODkwMDEwNzk=,output of pangenome,OPEN,2020-08-31T07:53:43Z,2020-08-31T09:09:49Z,,"Hello! I get the result of pangenome. but I don't know the meaning of the file. like pan-genome.wga.conensus.statspan-genome.wga.core.stats pan-genome.wga.newseq.stats and files in tmp. like An-1.com-2.wga.bed, tmp.An-1.C24.bed and so on .",liufy11,https://github.com/schneebergerlab/AMPRIL-genomes/issues/4,schneebergerlab++AMPRIL-genomes.csv
MDU6SXNzdWU3MDQzODI4MDM=,Synteny diversity calculation,OPEN,2020-09-18T13:33:18Z,2020-09-18T13:33:18Z,,"Hello wen-biao,
I'm trying to compare the degree of genomic rearrangements among a reference genome P and several related query genomes C1-C3. I don't fully understand the files used in step1 (pairwise whole genome alignment and synteny identification) you've described. Are these files included in the folder pairwiseWGA the delta files generated by MUMmer4? or some other files?
Also, I just want to make comparisons between the genoem P and each query genome C, escaping the pairwise comparisons within query genomes, so is it OK to use your scripts? Or, do I need to modify some command lines in the scripts?
Looking forward for your reply!

Best wishes,
Chengyu",Li-Chengyu,https://github.com/schneebergerlab/AMPRIL-genomes/issues/5,schneebergerlab++AMPRIL-genomes.csv
MDU6SXNzdWU3MjczMjc2NjY=,pangenome file prepare,OPEN,2020-10-22T12:06:33Z,2020-10-22T12:06:33Z,,"Hello,
This is a very great work that make me learned a lot. Thank you very much for sharing.
Here I have a question on pangenome, that is how to prepare the bed formated file ""xx.del.bed"" and ""xx.ins.bed"", because it is not very clear in the tutorial, is this file available in the sv.txt file generated by Syri? 
Hope to get your reply and help, thank you very much!",lin-jiahao,https://github.com/schneebergerlab/AMPRIL-genomes/issues/6,schneebergerlab++AMPRIL-genomes.csv
MDU6SXNzdWU4OTUwODU3ODg=,annotated protein coding genes,CLOSED,2021-05-19T07:22:34Z,2021-05-19T07:28:57Z,2021-05-19T07:28:57Z,"Hello,

Thanks for excellent software and scripts.

I am interested to know how you generated the gene rearrangement figure ( figure 3d) in your manuscript ""Chromosome-level assemblies of multiple Arabidopsis genomes reveal hotspots of rearrangements with altered evolutionary dynamics"".

Thanks and regards

sandip",sandipmkale,https://github.com/schneebergerlab/AMPRIL-genomes/issues/7,schneebergerlab++AMPRIL-genomes.csv
MDU6SXNzdWU4OTUxMDE5OTg=,ImportError: No module named util.util,CLOSED,2021-05-19T07:37:56Z,2021-05-28T12:00:12Z,2021-05-28T12:00:12Z,"Hello,

I got above error while running ""evm.pasa.integrate.pipeline.py""
 can you please help.

With best regards

Sandip",sandipmkale,https://github.com/schneebergerlab/AMPRIL-genomes/issues/8,schneebergerlab++AMPRIL-genomes.csv
MDU6SXNzdWU5MDA4MjA3OTg=,pan-genome.plot.r ,OPEN,2021-05-25T13:34:12Z,2021-05-25T13:34:12Z,,"Hi,
I've tried to create the pan-genome saturation plot with Arbidopsis dataset that you provided.  I get the below error when I run the fit of decay. Can you pls give some suggestions to fix this ? 


> model_1 <- nls(yvalues ~ A*exp(B*xvalues)+C,start=list(A=800,B=-0.3,C=24000))
Error in numericDeriv(form[[3L]], names(ind), env) :
  Missing value or an infinity produced when evaluating the model

Regards,
Muru

",Murukarthick,https://github.com/schneebergerlab/AMPRIL-genomes/issues/9,schneebergerlab++AMPRIL-genomes.csv
I_kwDODBV7Ws5Bex0v,Synteny diversity calculation?,OPEN,2022-01-11T02:40:28Z,2022-01-11T06:48:34Z,,"Hi Wen-Biao,

Thanks for providing the code for your recent publication. Good work on this.

I just have a query about the calculation of synteny diversity.

In the publication, it is defined as:
![image](https://user-images.githubusercontent.com/13409610/148715410-1079d1ed-ccf7-4c69-85e6-a38ab9b64603.png)

It looks like the script 'calculate.syn.diversity.pl' takes all pairwise comparisons and sums the number of times a site is non-synonymous then divides this sum by the total number of comparisons. Is this correct?

If i and j from the equation refer to all pairwise comparisons and pi_ij is either a 1 or a 0, or  the fraction of 1s over all possible pairwise comparisons, this is not quite the same as what the script actually does. 

For example, working with 11 genomes, we would have 55 pairwise comparisons. Let's say 20/55 comparisons evaluate to 1 as the sites are syntenic. The fraction of syntenic comparisons would be 20/55. This seems to be the number that 'calculate.syn.diversity.pl' gives us. However, this is not what one would get using the algebra in the equation.

For example:
`Pi=0`
`for(i in 1:10){for(j in (i+1):11){Pi=Pi+1/11*(1/11)*(20/55)}}`

Would set Pi to about 0.17, whereas 20/55 is actually 0.36. If you keep 20/55 as the fraction of non-syntenic sites among all pairwise comparisons then perform the same analysis for all isolates including self-comparisons, for example:

`Pi=0`
`for(i in 1:11){for(j in 1:11){Pi=Pi+1/11*(1/11)*(20/55)}}`

Then Pi will be set to 0.36, which is the same as just outputting 20/55. Is this what the equation is describing? If so, one could omit the summation of x_ij and just say that this statistic is the fraction of non-syntenic sites among all pairwise comparisons. It would be a lot simpler.

Please can you provide a few more details on synteny diversity and how calculate.syn.diversity.pl works? Is my interpretation of this script correct?

Best wishes,
Mark",markcharder,https://github.com/schneebergerlab/AMPRIL-genomes/issues/10,schneebergerlab++AMPRIL-genomes.csv
I_kwDODBV7Ws5KAZuP,Step2:get the coordinates of syntenic regions in all genomes,OPEN,2022-05-19T11:18:27Z,2022-05-19T11:18:27Z,,"Hello, 
I try to get the coordinates of syntenic regions in 3 genomes. When I run the get.all.syn.coord.pl, I get the wrong output, just like this, There is no value but NA, may be it was caused by the code, could you please tell me how to modify the code in line 86 and 98. Or other possible problems? Thank you very much!
<img width=""304"" alt=""image"" src=""https://user-images.githubusercontent.com/72898813/169280917-882c483a-448d-4ffd-8b7b-b107dd24f6c9.png"">
",HongboTang,https://github.com/schneebergerlab/AMPRIL-genomes/issues/11,schneebergerlab++AMPRIL-genomes.csv
I_kwDODBV7Ws5rUjtx,A new method for rapidly calculating the synteny diversity can be accessed in the new GitHub repository: https://github.com/JiaoLab2021/SynDiv,OPEN,2023-07-12T09:21:47Z,2023-07-12T09:21:47Z,,A new method for rapidly calculating the synteny diversity can be accessed in the new GitHub repository: https://github.com/JiaoLab2021/SynDiv,wen-biao,https://github.com/schneebergerlab/AMPRIL-genomes/issues/12,schneebergerlab++AMPRIL-genomes.csv
MDU6SXNzdWUzMTI4MzI0Mg==,Add util functions to get component level statistics,CLOSED,2014-04-10T21:25:18Z,2014-05-12T20:48:16Z,2014-05-12T20:48:16Z,"nof components
nof gaps
avg, std dev
% covered by components and gaps
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/1,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWUzMzM0NTAwMA==,Add gap/seq length stats to summarize.pl,CLOSED,2014-05-12T20:44:03Z,2015-03-02T01:52:23Z,2015-03-02T01:52:23Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/2,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWUzMzQxNDY3NQ==,summarize.pl - globbing and tabular reports,OPEN,2014-05-13T16:23:52Z,2015-03-06T21:36:02Z,,"Should be able to read in set of AGP/TPF files and produce tabular report
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/3,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWUzMzgwMjE1Mg==,Make GFF3 module mx-runnable,OPEN,2014-05-19T14:03:48Z,2015-03-06T21:36:56Z,,"See Jeremy's controller code
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/4,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1NTM4OTA1MA==,print component/scaffold level gap filling data,CLOSED,2015-01-24T23:31:47Z,2015-02-09T23:43:56Z,2015-02-09T23:43:56Z,"add #,length of gaps covered for components/contigs and scaffolds to groupcoords report
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/5,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1Nzg1NjYyOA==,filter_delta script,CLOSED,2015-02-16T22:05:37Z,2015-03-02T01:50:26Z,2015-03-02T01:50:26Z,"Print filtered delta output file without the BACs that are aligned out of order.
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/6,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1Nzg1Njk0Nw==,Output fasta from group_coords.pl,OPEN,2015-02-16T22:08:55Z,2015-03-06T21:36:56Z,,"Print fasta of query seqs that did not align
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/7,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1ODk3MjM3Ng==,Print coords and names for BACs that have mixed alignments (group_coords.pl),CLOSED,2015-02-25T21:24:59Z,2015-02-25T23:07:52Z,2015-02-25T23:07:52Z,"query BAC aligns to both + and - strand of ref chr
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/8,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1ODk3Mjc0MQ==,Print coords and names for BACs that have non co-linear alignments. Also remove from output  (group_coords.pl),CLOSED,2015-02-25T21:27:36Z,2015-03-02T01:50:26Z,2015-03-02T01:50:26Z,"Add methods AlignmentCoordsGroup.pm. Removing BAC alignments that align in non co-linear order to ref chr.
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/9,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1OTI1OTI4OQ==,Add mixed orientation BACs to test data (group_coords.pl),CLOSED,2015-02-27T16:32:00Z,2015-03-02T01:12:48Z,2015-03-02T01:12:48Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/10,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1OTI2MjM1OQ==,Create test GFF with SL2.50 components from TPF and BAC sequences. ,CLOSED,2015-02-27T16:53:39Z,2015-04-24T02:47:51Z,2015-04-24T02:47:51Z,"Should include switch over cases. For testing GFF -> TPF pipeline for bld 3.0
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/11,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1OTI4MjM4MA==,How many filled gaps are within genes? How many genes still contain gaps within them? (group_coords.pl),CLOSED,2015-02-27T19:29:25Z,2015-03-04T21:32:52Z,2015-03-04T21:32:52Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/12,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1OTI4MjQ2OA==,Create test annotation GFF for testing gap filling stats (group_coords.pl),CLOSED,2015-02-27T19:30:05Z,2015-03-04T21:31:46Z,2015-03-04T21:31:46Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/13,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1OTI4Njk1NQ==,Add non co-linearly aligned BACs to test data (group_coords.pl),CLOSED,2015-02-27T20:06:12Z,2015-03-02T01:50:26Z,2015-03-02T01:50:26Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/14,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1OTg2NjU1Mw==,Add stript to align BAC ends to SL2.50 and compute coverage stats,CLOSED,2015-03-04T21:40:48Z,2015-03-18T16:02:32Z,2015-03-18T16:02:32Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/15,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1OTg3MDE4OQ==,Create test set for align_BACends_group_coords.pl,CLOSED,2015-03-04T22:07:31Z,2015-03-18T16:01:05Z,2015-03-18T16:01:05Z," -r  Fasta file of reference (required)
 -q  Fasta file of query (assembled and singleton BACs, required)
 -c  Contig or component AGP file for reference (includes scaffold gaps)
 -s  Chromosome AGP file for reference (with only scaffolds and gaps) 
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/16,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2MDE2MjE2OQ==,Check if BACend fasta contains the correct sequences (align_BACends_group_coords.pl),CLOSED,2015-03-06T21:35:54Z,2015-03-18T16:01:59Z,2015-03-18T16:01:59Z,"File: query_bacends.fasta
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/17,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2MDI0MTQ4Ng==,Remove mixed and outoforder output files and stats (align_BACends_group_coords.pl),OPEN,2015-03-08T04:59:38Z,2015-03-18T04:28:42Z,,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/18,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2MjU4NjU4Nw==,Clean up BAC right end logic (align_BACends_group_coords.pl),CLOSED,2015-03-18T04:29:13Z,2015-03-23T21:33:54Z,2015-03-23T21:33:54Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/19,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2MjU4NjcyNw==,Check for BAC ends that are align too close on ref chr  (align_BACends_group_coords.pl),OPEN,2015-03-18T04:29:58Z,2015-05-11T14:12:39Z,,"Is it required???
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/20,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2MjczNzM1Mw==,"Output Fasta of valid, mixed, outoforder and both_errors from align_BACends_group_coords.pl",OPEN,2015-03-18T16:38:43Z,2015-03-18T16:38:43Z,,"uniq in mixed, outoforder 
common in both_errors
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/21,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2Mjk4ODE4NA==,Add mixed orientation and out of order cases to test data (align_BACends_group_coords.pl),OPEN,2015-03-19T13:33:46Z,2015-03-19T13:33:46Z,,"Use 500 1 convention of nucmer
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/22,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2MzgxMzg2OQ==,Check why mixed alignment cases are not flagged as error ,CLOSED,2015-03-23T19:39:25Z,2015-03-27T19:25:18Z,2015-03-27T19:25:18Z,"Check AlignCoordGroup.pm

sample nucmer output

> 18361542   18377740    1   16206   16199   16206   99.94   70787664    203766  0.02    7.95    1   1   SL2.50ch03  Contig90  
> 53614018   53614614    17944   17348   597 597 99.66   70787664    203766  0.00    0.29    1   -1  SL2.50ch03  Contig90

500bp.mixedoutoforder.agp.group_coords.stdout

> Contig90   SL2.50ch03  18361542    18564072    202530  1   203766  203766  154944  1   1   0   Contains    0   0   48822   0   596 SL2.50ch03:597:53614018:53614614    
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/23,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2MzgzNTQ0Mw==,Add capability to handle multiple references to Bio::GenomeUpdate::AGP,CLOSED,2015-03-23T21:20:38Z,2015-03-27T21:27:12Z,2015-03-27T21:27:12Z,"Needed for BAC alignments to all chrs.
Fix get_gap_overlap()
Then remove err msg from align_BACends_group_coords.pl and test
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/24,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2NDgzOTQwNQ==,Need script to identify BACs with source chromosomes that align to other chrs,OPEN,2015-03-27T19:50:16Z,2015-03-27T20:10:02Z,,"Align BACs to all chrs and validate if they align to only the chr they belong to. If not, add them to the no_chr set.
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/25,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2NTc2MTY3Nw==,Generate switch point curation files for TPF in NCBI GRC format,CLOSED,2015-04-01T19:32:08Z,2015-10-07T01:34:13Z,2015-10-07T01:34:13Z,"Columns for switch point curation file:
- Taxid (value (Solanum lycopersicum)=4081)
- AssmGrp (value=TGP)
- AssmUnit (value=Primary)
- Chr (values=1-12, Un)
- TPFType (values=chromosome, contig (latter used for unlocalized or unplaced scaffolds, see TPF spec))
- Acc.ver1
- Acc.ver2
- Orient1 (orientation of acc.ver1 in AGP)
- Orient2 (orientation of acc.ver2 in AGP)
- Point1 (1-based, last base of acc.ver1 to be used in AGP)
- Point2 (1-based, first base of acc.ver2 to be used in AGP)
- Comment (reqd, min 25 char)
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/26,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2NTc3MTQyMQ==,Create test set for place_bacs.pl,CLOSED,2015-04-01T20:21:58Z,2015-04-02T18:44:57Z,2015-04-02T18:44:57Z,"-t <TPF_file>                         Original TPF file (mandatory)
-s <scaffold AGP_file>           scaffold AGP file (mandatory)
-c <chromosome AGP_file>  chromosome AGP file (mandatory)
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/27,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2NzQ2NDcxOQ==,Add method to insert BACs and substitute both seq and gap lines,CLOSED,2015-04-09T22:31:40Z,2015-04-14T18:58:30Z,2015-04-14T18:58:30Z,"get_tpf_with_bacs_inserted
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/28,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2ODQ3MzU1Ng==,Upgrade Bio::GenomeUpdate::TPF to TPF v1.8,OPEN,2015-04-14T19:20:34Z,2015-05-11T15:27:39Z,,"TPF spec v1.8 added biological feature in a non-sequence line (centromere or heterochromatin).
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/29,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2OTY2MzgyMw==,Remove from the TPF - old WGS contigs that are now covered by the BACs (contained in BACs) (place_bacs.pl),CLOSED,2015-04-20T19:35:34Z,2015-04-24T02:52:52Z,2015-04-24T02:52:52Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/30,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU2OTY2NDEyMQ==,Read phrap ACE and deduce the TPF line for each contig with member BAC accession numbers (place_bacs.pl),CLOSED,2015-04-20T19:37:28Z,2015-05-06T03:25:06Z,2015-05-06T03:25:06Z,"Will be substituted in for ""ContigX"" placeholder from the group_coords sdtout.
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/31,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3MDU3MTA5MA==,place_bacs.pl does not account for BAC regions that start or end within gaps when resizing gaps.,CLOSED,2015-04-24T03:08:50Z,2015-04-24T21:42:25Z,2015-04-24T21:42:25Z,"The problem is that mummer does not report alignments to N's so BAC regions that extend beyond the WGS contig are not considered. Need to compute ""overhangs"" from BAC length and seq_in_clusters.
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/32,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3MDU3NTkzNg==,BAC orientation in TPF from place_bacs.pl may be incorrect as direction in group_coords stdout is not considered.,CLOSED,2015-04-24T03:36:27Z,2015-07-10T23:33:30Z,2015-07-10T23:33:30Z,"Check using GRC tpf_solo pipeline.
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/33,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3MDgxMDI0Mg==,Create test ACE file for place_bacs.pl contig_to_components,CLOSED,2015-04-24T22:28:16Z,2015-05-06T03:25:05Z,2015-05-06T03:25:05Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/34,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3MTY5ODUwNA==,Create /shell_scripts dir and move Bryans and other scripts into it,CLOSED,2015-04-28T20:47:28Z,2016-05-04T13:16:10Z,2016-05-04T13:16:10Z,"Maybe move .PL /scripts into scripts dir. Only if history is preserved.
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/35,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3MTk0MTI0MQ==,Add function to sort remapped VCFs by coordinate,CLOSED,2015-04-29T17:48:45Z,2015-05-01T18:48:50Z,2015-05-01T18:48:50Z,"Modify copy_updated_coordinates_to_vcf to sort -V its output file so that features end up in correct order and are ready for compression and display in jbrowse.  
",bellerbrock,https://github.com/solgenomics/Bio-GenomeUpdate/issues/36,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3MTk0NDUwMQ==,Solve external dependency problems,CLOSED,2015-04-29T18:00:55Z,2015-05-01T18:48:50Z,2015-05-01T18:48:50Z,"find way to include paths of lib modules in scripts that call them without hardcoding them. 
",bellerbrock,https://github.com/solgenomics/Bio-GenomeUpdate/issues/37,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3MzcxODMwNg==,Remove contained clause for BACs that were contained in WGS contigs but those contigs were subsequently removed,CLOSED,2015-05-06T19:47:32Z,2015-05-07T15:24:05Z,2015-05-07T15:24:05Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/39,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3MzczMzM0Mg==,Add contained clause for individual BACs in an assembled BAC contig before adding to TPF (place_bacs.pl),CLOSED,2015-05-06T20:48:53Z,2015-05-07T15:24:05Z,2015-05-07T15:24:05Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/40,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3NDA3MTYxNw==,Write a LOG file with Contig name and accessions of member BACs (process_bac_assembly.pl),OPEN,2015-05-07T17:49:33Z,2015-05-07T17:49:33Z,,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/41,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3NDA3MTkxOQ==,Fix contig_mismatch() to work with ACE files from phrap. (process_bac_assembly.pl),OPEN,2015-05-07T17:50:32Z,2015-05-07T17:50:32Z,,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/42,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3NDA3MjA1Mw==,Fix add_contig_to_scaffold() to work with test ACE object (wrong aligned coordinates reported) and ACE files from phrap.  (process_bac_assembly.pl),OPEN,2015-05-07T17:51:02Z,2015-05-07T17:51:02Z,,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/43,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3NDA3MjIyMQ==,Add test routine that processes a test ACE file from phrap  (process_bac_assembly.pl),OPEN,2015-05-07T17:51:29Z,2015-05-07T17:51:44Z,,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/44,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3NTI0MDg4Mw==,Generate trim files for TPF in NCBI GRC format,OPEN,2015-05-11T14:26:51Z,2015-05-11T14:51:04Z,,"Columns for Trim curation file:
- Taxid (value (Solanum lycopersicum)=4081)
- AssmGrp (value=TGP)
- AssmUnit (value=Primary)
- Chr (values=1-12, Un)
- TPFType (values=chromosome, contig)
- Acc.ver
- TrimPos (1-based; first or last base used in AGP)
- FromEnd (values = L, H; L: trim bases with values lt TrimPos; H: trim bases with values gt TrimPos)
- Comment

Create new classes
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/45,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3NjgzMjUzMw==,The order of BACs written to TPF for an assembled BAC contig is reversed,CLOSED,2015-05-15T19:34:40Z,2015-07-10T23:33:30Z,2015-07-10T23:33:30Z,"AEKE02023669    ?   SL2.50sc05925   MINUS
AC244870    ?   SL2.50sc05925   PLUS
AC244937    ?   SL2.50sc05925   MINUS   contig469
AC244803    ?   SL2.50sc05925   PLUS    contig469
AC244944    ?   SL2.50sc05925   PLUS    contig469
AC254768    ?   SL2.50sc05925   MINUS   contig469
AEKE02023661    ?   SL2.50sc05925   MINUS

Contig469_right_1000 aligns to -ive AEKE02023661.1
Contig469_right_1000 aligns to -ive end of AC244937
Contig469_left_1000 aligns to -ive end of AC254768
Contig469_left_1000 aligns to middle of AC244870

Correct order 
AEKE02023669    ?   SL2.50sc05925   MINUS
AC244870    ?   SL2.50sc05925   PLUS
AC254768    ?   SL2.50sc05925   MINUS   contig469
AC244944    ?   SL2.50sc05925   PLUS    contig469
AC244803    ?   SL2.50sc05925   PLUS    contig469
AC244937    ?   SL2.50sc05925   MINUS   contig469
AEKE02023661    ?   SL2.50sc05925   MINUS

68kb 99% identical alignment between AC244870 and AC254768
9.2kb 99% identical alignment between AC244937 and AEKE02023661
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/46,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU3NjgzMzcyNw==,How to handle BACs that are identical within a assembled BAC? Leave one out???,CLOSED,2015-05-15T19:38:20Z,2015-09-02T21:40:06Z,2015-09-02T21:40:06Z,"![selection_001_screenshot](https://cloud.githubusercontent.com/assets/1084749/7660514/bc8529b8-fb18-11e4-9e60-08f2a7f4d110.png)

Contig 469 for Chr 10 represented by the following TPF lines
AC244937    ?   SL2.50sc05925   MINUS
AC244803    ?   SL2.50sc05925   PLUS
AC244944    ?   SL2.50sc05925   PLUS
AC254768    ?   SL2.50sc05925   MINUS

Can be
AC244937    ?   SL2.50sc05925   MINUS
AC244944    ?   SL2.50sc05925   PLUS
AC254768    ?   SL2.50sc05925   MINUS
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/47,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU4NDc3NTYyNA==,Handle cases where inserted BAC/BAC contig is flush with either end of WGS,CLOSED,2015-06-03T21:20:06Z,2015-06-07T03:55:47Z,2015-06-07T03:55:47Z,"Attribute (accession_prefix_last_base) does not pass the type constraint because: The string, -1, was not a positive coordinate at /usr/local/lib/x86_64-linux-gnu/perl/5.20.2/Moose/Object.pm line 24
    Moose::Object::new('Bio::GenomeUpdate::SP::SPLine', 'chromosome', 10, 'accession_prefix', 'AEKE02007654', 'accession_suffix', 'AC239654', 'accession_prefix_orientation', '-', 'accession_suffix_orientation', '+', 'accession_prefix_last_base', -1, 'accession_suffix_first_base', 1, 'comment', 'BAC AC239654 is contained within WGS contig AEKE02007654 from previous version. Designates switch point from WGS contig to BAC.') called at /home/surya/work/Eclipse/Bio-GenomeUpdate/lib/Bio/GenomeUpdate/TPF.pm line 1628
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/48,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU4NTg1MDc3MA==,Change Contig names in TPF line to first or last BAC in the contig in switch points file,CLOSED,2015-06-07T04:00:14Z,2015-10-04T16:50:14Z,2015-10-04T16:50:14Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/49,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU4NjIwNzQyNg==,BACs and Contigs are inserted in the wrong location for a TPF line after the first insertion,CLOSED,2015-06-08T14:50:25Z,2015-06-22T16:38:19Z,2015-06-22T16:38:19Z,"The location is relative to the original TPF line but multiple insertions are done with respect to the original line number, not the new location. Need to maintain a separate offset counter for 'before' and 'after' insertions for each original TPF line.
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/50,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU4NjY3NTAxMQ==,update_coordinates_gff.pl generates error when mapping RF_007 (tomato 150 vcf) to SL2.50,CLOSED,2015-06-09T17:34:51Z,2015-06-09T18:08:26Z,2015-06-09T18:01:03Z,"![screenshot from 2015-06-09 13 34 19](https://cloud.githubusercontent.com/assets/11297346/8064964/48a12518-0eac-11e5-8fd5-9cbe0f05db0a.png)
",bellerbrock,https://github.com/solgenomics/Bio-GenomeUpdate/issues/51,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU5MDIxMzg1MQ==,Remove overlapping BACs/Contig BACs from group_coords output,CLOSED,2015-06-22T21:14:16Z,2015-07-10T23:33:30Z,2015-07-10T23:33:30Z,"Some BACs and BAC contigs cover the same region on the reference. Keep only one BAC or Contig BAC for a reference region. Should also sort by ref location as group_coords does not do that.

Also add warning message to place_bacs
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/52,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU5NDQxNDQ4OA==,Singleton BACs should be inserted in the order of occurence in the filtered group_coords file,OPEN,2015-07-10T23:46:23Z,2015-07-11T00:53:02Z,,"**group_coords file**
gi|290775087|gb|AC240216.2| SL2.50ch10  4289172 4387688 98516   1   98517   98517   1000    1   1   0   Contains    0   0   97517   0   0  
gi|81295483|gb|AC171731.1|  SL2.50ch10  4385074 4458461 73387   1   73387   73387   1000    1   1   0   Contains    0   0   72387   0   0  
gi|339639709|gb|AC244887.2| SL2.50ch10  4478239 4578469 100230  1   100588  100588  1000    -1  1   0   Contains    0   0   99588   0   0       

**shows up as**
AEKE02023497    ?   SL2.50sc05925   MINUS
AC244887    ?   SL2.50sc05925   MINUS
AC171731    ?   SL2.50sc05925   CONTAINED   AEKE02023497    ?
AC240216    ?   SL2.50sc05925   CONTAINED   AEKE02023497    ?`
AEKE02023493    ?   SL2.50sc05925   MINUS

**should be**
AEKE02023497    ?   SL2.50sc05925   MINUS
AC240216    ?   SL2.50sc05925   CONTAINED   AEKE02023497    ?
AC171731    ?   SL2.50sc05925   CONTAINED   AEKE02023497    ?
AC244887    ?   SL2.50sc05925   MINUS
AEKE02023493    ?   SL2.50sc05925   MINUS
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/53,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU5NTQ0Mjc2Mg==,Solo BAC end alignments are not handled correctly in get_tpf_sp_tp_with_bacs_inserted_in_sequences_and_gaps,OPEN,2015-07-16T14:15:47Z,2015-10-07T12:51:33Z,,"Not using the Contains or Partial keyword in `align_BACends_group_coords.pl` so we get warnings and critical messages from tpf_solo
`Warning: Segment too short. AEKE02023641.1 length 1 : 0..0 is under 10`

Where it is assigning just one base from a WGS contig to the AGP.
`SL2.50SC05925  1631525 1677570 65  W   AEKE02023641.1  16935   62980   -`
`SL2.50SC05925  1677571 1694497 66  F   AC244568.2  1   16927   +`
`SL2.50SC05925  1694498 1694498 67  W   AEKE02023641.1  1   1   -`

Should not assign 'CONTAINED' for partial alignments. Manually removing for now. Adding a default TYPE-2 gap between the end-aligned solo BAC and the next sequence if there is no overlap.

TODO: Do this in `get_tpf_sp_tp_with_bacs_inserted_in_sequences_and_gaps`
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/54,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU5OTgyOTQzMA==,Refactor ACE file code out of place_bacs.pl into separate pre-processing script,OPEN,2015-08-08T19:27:44Z,2015-08-08T19:27:59Z,,"Suggested by @lukasmueller 
Input: ACE file
Output: pseudo TPF file for each assembled contig and a TPF with list of singletons
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/55,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWUxMTEyMTkwNzg=,Cannot handle BACs from non-genbank sources,CLOSED,2015-10-13T16:34:31Z,2015-10-13T16:40:50Z,2015-10-13T16:40:50Z,,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/56,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWUxMTUzNjAxMjM=,process_bac_assembly.pl writes BACs to disk in wrong orientation,CLOSED,2015-11-05T19:49:41Z,2015-11-10T23:26:14Z,2015-11-10T23:26:14Z,"BACs in negative orientation in a contig should be reverse complemented before writing to disk. This creates problems downstream in place_bacs.pl because it presumes the BAC sequence read from disk to be in positive orientation and writes the wrong orientation in the final updated TPF file.
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/57,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWUxMzQwODc2MTM=,Some reference and alt alleles are incorrect in vcfs mapped to build 2.50,CLOSED,2016-02-16T20:23:27Z,2016-03-10T18:39:47Z,2016-03-10T18:39:46Z,"From a user:

Dear SGN,

I am parsing the data from 360 genomes project. I've seen so far that some SNPs in the VCF files of SL2.50 have a wrong reference allele. For example, having the following list:

SL2.50ch01      39138511        G       C
SL2.50ch01      39141120        T       A
SL2.50ch01      39144494        G       C
SL2.50ch01      39162103        G       C
SL2.50ch01      39175764        G       C
SL2.50ch01      39177173        G       C
SL2.50ch01      39186267        G       C
SL2.50ch01      39192822        G       C
SL2.50ch01      39207130        G       C
SL2.50ch01      39207130        G       C

the first column is the chromosome name, the second column contains the position in the reference genome SL2.50, the third column is the reference allele in your VCF files, and the 4th column is actually the reference allele in SL2.50.

It does not happen in all SNPs, only in some of them. Why do I see so many transversions? Why did you choose different strands at the time of reporting your variants?
",bellerbrock,https://github.com/solgenomics/Bio-GenomeUpdate/issues/58,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWUxMzQzMjcwMTk=,Scafold/Contig specific GFF for chr00 Scafold/Contig ,CLOSED,2016-02-17T16:19:36Z,2016-05-03T21:13:46Z,2016-05-03T21:13:46Z,"Needed for loading ITAG2.4 genes on chr00 into NCBI 
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/59,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWUxOTkyMTcyMTI=,ITAG gene naming for novel genes,CLOSED,2017-01-06T15:19:21Z,2017-02-09T21:57:54Z,2017-02-09T21:57:54Z,"Naming ITAG genes with Solyc ID convention. 
In ITAG3.0 there are several novel genes compared to ITAG2.40 which needs Solyc ID. In general, the ID should reflect chromosome number and genomic position.  

Conditions
-conflict with any previous Solyc ID",phosmani,https://github.com/solgenomics/Bio-GenomeUpdate/issues/60,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWUxOTkyMzg3Nzk=,Assigning Solyc from ITAG2.40 to ITAG2.90,CLOSED,2017-01-06T16:54:24Z,2017-02-09T21:56:51Z,2017-02-09T21:56:51Z,"In two steps
1. Assign Solyc ID from maker updated ITAG2.43 annotation set based on blastp output.
            -- check if the blastp match SolycID is in order as per ITAG2.40.
2. Replace maker generated names with Solyc ID from Name field within gff attributes column.

GFF file with MAKER names and ITAG names.
/export/projects/SL3.0/ITAG3.0/ITAG2.90/ITAG2.90_standard.gff

TAB delimited file for ID conversion.
 /export/projects/SL3.0/ITAG3.0/ITAG2.90/ITAG_pass_standard.id.map

",phosmani,https://github.com/solgenomics/Bio-GenomeUpdate/issues/61,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWUyMDQwNjA4NjU=,Update ver # and add fields to attributes column of Maker_ITAG GFF,CLOSED,2017-01-30T16:35:12Z,2017-02-09T21:58:51Z,2017-02-09T21:58:50Z,"Match Solyc id to new information

```
Solyc00g005000.2.1    Solyc00g005000.3.1    Note=LOW QUALITY:Aspartic proteinase nepenthesin I (AHRD V3.* **-- A9ZMF9_NEPAL) contains Interpro domain(s) IPR001461 Peptidase A1;Dbxref=InterPro:IPR032799,InterPro:IPR032861,Pfam:PF14541,Pfam:PF14543;Ontology_term=GO
```

",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/62,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWUyMDcwODg1Mjk=,script to parse SL3.0 chrs using SL2.93 TPF files and extract contigs,OPEN,2017-02-12T22:49:16Z,2017-02-12T22:49:30Z,,"Compare list of gap sizes from SL2.93 TPF file to stretches of N's in chr to identify start/stop coordinates. 

Account for contamination fixes
* chloroplast contamination https://github.com/solgenomics/data/issues/60
* arabidopsis contamination https://github.com/solgenomics/data/issues/22

**Output**
* Fasta of contigs
* TPF with temp contig names and correct gap sizes
",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/63,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1MTA2NTM3Njc=,Reimplement fasta parsers with Bioperl,OPEN,2019-10-22T13:24:28Z,2019-10-22T13:24:28Z,,"update_maker_names_fasta.pl
update_maker_names_fasta_chrlocs.pl",suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/64,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU1MTA2NjM2MDU=,Use mummer instead of nucmer for dot plots,CLOSED,2019-10-22T13:39:40Z,2019-10-24T12:31:56Z,2019-10-24T12:31:56Z,https://github.com/mummer4/mummer/issues/51,suryasaha,https://github.com/solgenomics/Bio-GenomeUpdate/issues/65,solgenomics++Bio-GenomeUpdate.csv
MDU6SXNzdWU4MjMwOTA0NDk=,how to assemble genomes with four fasta files?,CLOSED,2021-03-05T13:33:11Z,2021-03-05T19:44:37Z,2021-03-05T19:44:37Z,"HI @StephenFordham 
Very nice toolbox. Could I ask one question about the input for the genome assembly? Here, for one strain, we have four fasta files? Could we still use your nice toolbox?

<img width=""383"" alt=""Screenshot 2021-03-05 at 14 30 07"" src=""https://user-images.githubusercontent.com/31989005/110122110-7def6a80-7dbf-11eb-85e6-b765b6744db6.png"">

Thanks a lot!

Best regards,
Hongzhong",hongzhonglu,https://github.com/StephenFordham/BacGenomePipeline/issues/1,StephenFordham++BacGenomePipeline.csv
I_kwDOJ_k_qM5uXBKo,add option for sorted or random selection of genomes,OPEN,2023-08-15T14:20:23Z,2023-08-15T14:20:23Z,,Make an option to choose if one wants to download random genomes or have it sorted by some quality criteria,strejcem,https://github.com/strejcem/download_gtdb_genomes/issues/5,strejcem++download_gtdb_genomes.csv
I_kwDOJ_k_qM5uXB3A,Add option for dplyr type of metadata filtering,OPEN,2023-08-15T14:22:13Z,2023-08-15T14:22:13Z,,"Swtich to customable dplyr filter syntax instead of individual filter arguments like `--mimag`, `--representative`, etc. ",strejcem,https://github.com/strejcem/download_gtdb_genomes/issues/6,strejcem++download_gtdb_genomes.csv
I_kwDOJ_k_qM5uX0WA,Unified output directory,OPEN,2023-08-15T16:12:07Z,2023-08-15T16:12:07Z,,"Make output everything into a single directory, including log file and make `--out_tax` and `--contig2genome` into flag arguments?",strejcem,https://github.com/strejcem/download_gtdb_genomes/issues/7,strejcem++download_gtdb_genomes.csv
I_kwDOEEKPJM5ZGz5u,Fix broken CI,CLOSED,2022-12-13T18:51:19Z,2023-03-27T17:27:35Z,2023-03-27T17:27:35Z,,Ulthran,https://github.com/sunbeam-labs/sbx_genome_assembly/issues/2,sunbeam-labs++sbx_genome_assembly.csv
I_kwDOEEKPJM5gGTXR,Fix conventions,CLOSED,2023-03-06T21:55:30Z,2023-10-31T15:26:03Z,2023-10-31T15:26:03Z,"e.g. stop using str() casting around snakemake Paths, use subprocess instead of os.system",Ulthran,https://github.com/sunbeam-labs/sbx_genome_assembly/issues/4,sunbeam-labs++sbx_genome_assembly.csv
I_kwDOEEKPJM51duPn,Add config options,CLOSED,2023-10-31T15:27:23Z,2023-12-07T20:12:14Z,2023-12-07T20:12:14Z,Especially for SPAdes,Ulthran,https://github.com/sunbeam-labs/sbx_genome_assembly/issues/6,sunbeam-labs++sbx_genome_assembly.csv
I_kwDOEEKPJM55ZUqP,add CheckM extension argument,OPEN,2023-12-11T23:02:29Z,2023-12-11T23:02:29Z,,"checkm_tree rule fails with ""ERROR: No bins found. Check the extension (-x) used to identify bins."" When I add `-x fasta` to the command and run it from the command prompt, it works like a charm.

It's also giving me grief about the CheckM.yml input where I have 'Staphylococcus aureus' repeated for every sample name. Not sure what the fix for that is yet.

log file (paths editted for anonymization):

[2023-12-11 17:45:27] INFO: CheckM v1.2.2
[2023-12-11 17:45:27] INFO: checkm taxonomy_wf -t 8 species 'Staphylococcus aureus' /path/to/sunbeam/project/sunbeam4_komplexity_issues/sunbeam_output/assembly/spades_bins/SAMPLEX /path/to/sunbeam/project/sunbeam_output/assembly/checkm_output/tree_output/SAMPLEX
[2023-12-11 17:45:27] INFO: CheckM data: ~/packages/sunbeam/.snakemake/0f2c769a31c1c9a6c339474387bfeb7f_/checkm_data
[2023-12-11 17:45:27] INFO: [CheckM - taxon_set] Generate taxonomic-specific marker set.
[2023-12-11 17:45:30] ERROR: Unrecognized taxon: 'Staphylococcus aureus' (in rank species):
[2023-12-11 17:45:30] INFO: { Current stage: 0:00:02.827 || Total: 0:00:02.827 }
[2023-12-11 17:45:30] INFO: [CheckM - analyze] Identifying marker genes in bins.
[2023-12-11 17:45:30] ERROR: No bins found. Check the extension (-x) used to identify bins.

  Controlled exit resulting from an unrecoverable error or warning.",naomiwilson,https://github.com/sunbeam-labs/sbx_genome_assembly/issues/8,sunbeam-labs++sbx_genome_assembly.csv
I_kwDOEEKPJM5_wtA1,Move to sunbeam-labs org,OPEN,2024-02-20T03:30:43Z,2024-02-20T03:30:43Z,,,Ulthran,https://github.com/sunbeam-labs/sbx_genome_assembly/issues/10,sunbeam-labs++sbx_genome_assembly.csv
MDU6SXNzdWU2NzM2MTU4NDg=,DNA read generator,OPEN,2020-08-05T15:11:08Z,2020-08-05T15:11:46Z,,Current dna read generator is broken (since offset value can be repeated probabilistically). Utilize a bag selection based system for read generator,thsubaku9,https://github.com/thsubaku9/Kukulkan_Genome_assembly/issues/1,thsubaku9++Kukulkan_Genome_assembly.csv
MDU6SXNzdWU2NzM2MTc3Mjg=,Verbose logical verification,OPEN,2020-08-05T15:13:28Z,2020-08-05T15:19:31Z,,The overlap graph sequence utilizes a nice turnaround price technique to prevent tips and bubbles from being created. Need to check how well this works,thsubaku9,https://github.com/thsubaku9/Kukulkan_Genome_assembly/issues/2,thsubaku9++Kukulkan_Genome_assembly.csv
MDU6SXNzdWU2NzM2MTkwNTQ=,Circulation Problem solver,OPEN,2020-08-05T15:15:02Z,2020-08-05T15:19:13Z,,At times the reads may be faulty or we might have insufficient info for our dna recreator. The answer to this is to utilize a circulation solver to find flow rate in our graph while accounting for surplus/deficits.,thsubaku9,https://github.com/thsubaku9/Kukulkan_Genome_assembly/issues/3,thsubaku9++Kukulkan_Genome_assembly.csv
MDU6SXNzdWU4MDE4NjE1Njk=,How to get 4d sites from progressive cactus maf file ?,OPEN,2021-02-05T05:35:16Z,2021-02-05T05:35:16Z,,"Hello, Sir:
I have a simple question just as the title.",biozhangzhou,https://github.com/tsackton/ratite-genomics/issues/1,tsackton++ratite-genomics.csv
MDU6SXNzdWU5Mjk5NzAyMzk=,File don't exist,CLOSED,2021-06-25T08:45:14Z,2024-08-02T14:16:23Z,2021-06-28T06:24:59Z,"Hi.
I am trying to follow your pipline with the ratite-genomics, but i found a script don't exist in the folder.

in  `ratite-genomics/04_wga/02_ce_id/run_phast.sh` line 183, you write:

> ./keep_ref_only.pl $MAF &

but i can not find this `keep_ref_only.pl`.

Could please upload this script?

Thanks!!",Rusfell,https://github.com/tsackton/ratite-genomics/issues/2,tsackton++ratite-genomics.csv
MDU6SXNzdWU0MTM3OTk4NTE=,Binning ,CLOSED,2019-02-24T09:06:38Z,2019-03-29T10:58:02Z,2019-03-29T10:58:02Z,"binning.c 
1. Right now , it is hashing reads , not k-mers. 
2. We have to store the no. of times a particular k-mer is appearing in a bin also. ",harshitagoyal311,https://github.com/twitu/genome-assembly/issues/1,twitu++genome-assembly.csv
MDU6SXNzdWU0MjY5MzE5NTQ=,Possible character leakage,CLOSED,2019-03-29T11:01:00Z,2019-04-08T15:52:31Z,2019-04-08T15:52:31Z,"new kmer key after key sometimes does terminate with `\0` instead presents a single unicode point. This result varies on different runs, the last character switching between 3 possibilities.",twitu,https://github.com/twitu/genome-assembly/issues/2,twitu++genome-assembly.csv
MDU6SXNzdWUyMTIwNTU0OA==,Fix the stop condition of scaffolding,CLOSED,2013-10-18T08:06:37Z,2013-12-08T01:41:38Z,2013-12-08T01:41:38Z,"Instead of running until no more paths are valid (which will take many iterations), we can aggregate a boolean and then read it from all the active path nodes.  A boolean should be cheap to access and perhaps we could even put it in the distributed cache, essentially pushing it out to all the machines.
",anbangx,https://github.com/uci-cbcl/genomix/issues/1,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTIzNjM4Ng==,test issue,CLOSED,2013-10-18T18:25:07Z,2013-10-19T02:27:48Z,2013-10-19T02:27:48Z,"anbang, did you get this?
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/3,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTIzNjQwMA==,test issue 2,CLOSED,2013-10-18T18:25:24Z,2013-10-19T02:27:48Z,2013-10-19T02:27:48Z,"@anbangx I'm mentioning you now
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/4,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTI1MjAxOA==,Automate genomix-hadoop/hyracks test compare code.,CLOSED,2013-10-18T23:55:37Z,2013-10-31T19:48:59Z,2013-10-22T22:26:50Z,"The hyracks automate test code is done. 
The hadoop automate test code is half done. The comparison between two is run under genomix-hadoop.

This task is to move the test code of comparison into genomix-driver. And make the it automatically. 
",JavierJia,https://github.com/uci-cbcl/genomix/issues/6,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTI1NjQ4Mg==,Vertex size spill problem,OPEN,2013-10-19T04:44:58Z,2013-10-21T18:22:47Z,,"The Hyracks frame size should be smaller that 128K, otherwise it will have some  unknown problem. 

Our EdgeSet will grow bigger and bigger in path merge phase. If we use 100K to store the EdgeSet, it can only contains 12800 readid. 

The first plan is to store the sorted id set into the HDFS, and only store the filename inside the node. And the sorted order will also benefit the union/intersect operation afterward.
",JavierJia,https://github.com/uci-cbcl/genomix/issues/7,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTI2ODk0NQ==,Write-space optimization for pregelix messages and genomix-data structures.,CLOSED,2013-10-19T21:06:43Z,2013-12-08T01:41:12Z,2013-12-08T01:41:12Z,"@anbangx 

The messages we send are pretty big and sometimes they are larger than they need to be.  For example, KILL_SELF messages don't need to carry an entire node with them, nor a srcVertexId. Same goes for our Node class-- we often write len=0 for edges that don't exist.

One solution is to use either boolean values or a flag representing what data values are present in the stream.  We write the header to the stream.  When we read, we only call the readFields functions on the values that are actually present.
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/10,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTI2ODk1Nw==,BUILD_HYRACKS still failing?,CLOSED,2013-10-19T21:07:51Z,2013-11-05T04:08:13Z,2013-10-21T18:00:04Z,"Hi @Nan-Zhang @JavierJia 

It seems the graphbuild using hyracks is still failing after our recent refactor? There is no output data when I run from the cmdline.
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/11,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTM0NDMzMg==,Graphbuild could use optimized representation,OPEN,2013-10-21T21:06:30Z,2013-10-31T22:42:04Z,,"@JavierJia @Nan-Zhang 
Currently, graphbuild uses and outputs VKmer keys and VKmer edges.  They could instead use Kmer keys and a single letter for each neighbor.
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/16,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTM1Mjg3MQ==,get travis to complete all test successfully,CLOSED,2013-10-21T23:52:14Z,2013-11-05T04:08:13Z,2013-10-22T18:34:25Z,,Nan-Zhang,https://github.com/uci-cbcl/genomix/issues/17,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTM1MjkxNQ==,Generate simulated data,OPEN,2013-10-21T23:53:23Z,2013-10-26T21:33:31Z,,"- [x] Maybe chr19 or 1/10th of it?  100x coverage
- [ ] generate statistics for our pipleline
",Nan-Zhang,https://github.com/uci-cbcl/genomix/issues/18,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTM1Mjk0Mw==,rerun with lower hadoop max tasks,CLOSED,2013-10-21T23:54:07Z,2013-11-05T04:08:13Z,2013-10-31T22:18:27Z,"- [ ] update hadoop job conf's to use the driver-set values (should be equal to the length of IO_DIRS in the conf)
- [x] rerun hadoop graphbuild to use this many map tasks.
",Nan-Zhang,https://github.com/uci-cbcl/genomix/issues/19,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTM1MzAyMw==,Profile patterns,OPEN,2013-10-21T23:56:01Z,2013-11-12T19:48:48Z,,"- [ ] Hadoop graphbuild
- [x] hyracks graphbuild
- [x] pathmerge
- [ ] bubble merge
- [ ] scaffolding

@anbangx to help.
",Nan-Zhang,https://github.com/uci-cbcl/genomix/issues/20,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTM1MzA3Mw==,Fix bubblemerge,CLOSED,2013-10-21T23:57:20Z,2013-11-05T04:08:13Z,2013-10-29T18:14:10Z,"Bubble merge doesn't seem to affect the graph... Is it doing anything or are we too strict in our filtering?
",Nan-Zhang,https://github.com/uci-cbcl/genomix/issues/21,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTM1MzExNA==,Fix remove low coverage,CLOSED,2013-10-21T23:58:35Z,2013-11-05T04:08:13Z,2013-10-29T18:13:24Z,"Jake has details.
",Nan-Zhang,https://github.com/uci-cbcl/genomix/issues/22,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTM1MzE4Ng==,Fix split repeats,CLOSED,2013-10-22T00:00:40Z,2013-11-05T04:08:13Z,2013-10-23T20:56:38Z,"failing on large data on the first iteration (trying to remove an edge that doesn't exist).
",Nan-Zhang,https://github.com/uci-cbcl/genomix/issues/23,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTM1MzMyOA==,Implement Ray's scaffolding,OPEN,2013-10-22T00:05:02Z,2013-11-04T23:38:10Z,,"@jakebiesinger 
- [ ] Talk about how exactly
- [ ] meet with others and explain 
- [ ] write up test cases
- [ ] implement
",Nan-Zhang,https://github.com/uci-cbcl/genomix/issues/24,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTM1NTI2Mg==,optimize genomix-data to use only start- and end- letters,OPEN,2013-10-22T01:03:30Z,2013-10-22T01:04:02Z,,"@anbangx @JavierJia @Nan-Zhang @Elmira88 

A while back, Nan pointed out that we actually don't need to store most of the kmer within a node-- we need only the last/first letter(s).  That would be substantial space savings for us (hundreds of MB out of a few GB of data).
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/25,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTQwMTExMA==,Use script to run graphviz and text file generator instead of automatically generating files under source control,CLOSED,2013-10-22T17:35:41Z,2013-11-05T04:08:13Z,2013-10-28T18:31:20Z,"you shouldn't include automatically generated files under source control (rather, use a We shouldn't include automatically generated files under source control (rather,script to generate them). Since these aren't really needed as input or as expected, maybe we want to remove them?

Then again, they do kind of help with debugging-- we can see what the output should be by having a graphical representation of the input.But I think they should be removed from source control and we should just add a little script that generates the graphs from the binary files.

Same goes for text files, actually. Binary files are fine-- they just show up on github as ""binary files not shown"". But both text and binary can be generated using a script and would help us keep these code reviews clean.
",anbangx,https://github.com/uci-cbcl/genomix/issues/27,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTQzNDQ5OQ==,`getip.sh` isn't reliable enough,OPEN,2013-10-23T05:33:22Z,2013-10-23T06:33:30Z,,"@JavierJia @Nan-Zhang 

We've seen from #29 and #26 that java returns a different value than `getip.sh`.  `getip.sh` is just a hack that reads out the IP address from `ifconfig` for `eth0`.

In other words, it's a hack.  Users may not have their setup on `eth0`-- I imagine that's the error you saw, @JavierJia ? your laptop is probably connecting over wifi and therefore doesn't use eth0? We're seeing this on travis, where some machines [aren't connected on eth0](https://travis-ci.org/uci-cbcl/genomix/jobs/12915715) and others are...

I think the solution is probably a very small java program that uses the java API rather than parsing from eth0.

Any volunteers to implement such a program?
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/31,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTQzNTYyNg==,Think about how to do split repeat on tandem repeat,OPEN,2013-10-23T06:22:08Z,2013-10-24T20:09:31Z,,"The current bug of split repeat is caused by trying to split tandem repeat node. 

 I leave them off for now. 

But let's think a better way to solve it.
",anbangx,https://github.com/uci-cbcl/genomix/issues/32,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTQ5MjU0Ng==,Improve the usage message,OPEN,2013-10-23T23:42:25Z,2013-10-24T20:09:32Z,,"The genomix driver prints a usage message... We'll want to hide some of those options, provide defaults in the usage string, and provide a high-level description of the program.
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/37,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTQ5NTgyMw==,Change name of start and end readids,CLOSED,2013-10-24T01:21:47Z,2013-11-05T04:08:14Z,2013-10-31T22:15:16Z,"Let's name them unflippedReadIds and flippedReadIds.
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/39,uci-cbcl++genomix.csv
MDU6SXNzdWUyMTcyODYyMA==,We need a comparison with existing methods,OPEN,2013-10-28T23:32:28Z,2013-12-10T05:12:57Z,,"Take a small, synthetic genome with single-end reads and compare our results with:
- [ ] velvet
- [ ] contrail
- [ ] ray
",anbangx,https://github.com/uci-cbcl/genomix/issues/43,uci-cbcl++genomix.csv
MDU6SXNzdWUyMjEwNjk3MQ==,`-runLocal` doesn't shut down properly,CLOSED,2013-11-05T09:06:08Z,2013-11-18T23:49:37Z,2013-11-18T23:49:37Z,"It seems that since we started to use the miniMR or miniDFS clusters, you have to interrupt any `-runLocal` runs yourself via `ctrl+c`.  As a result, our builds have started timing out (see https://travis-ci.org/uci-cbcl/genomix/jobs/13513861 for an example).
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/54,uci-cbcl++genomix.csv
MDU6SXNzdWUyMzA5MDExMw==,Handling `N`'s in the input files,OPEN,2013-11-21T19:18:38Z,2013-11-22T19:25:45Z,,"There are going to be `N` characters in the input file.  I think the proper way to handle these would be NOT to include any kmers containing `N`.  As it is now, we throw away the entire _read_ if any of the characters are `N`.

When we store the read, we could store the entire sequence, N and all, but that would mess up our 4-letter, 2-bit representation.  For simplicity, I guess we could throw those reads away from the the ReadHead.  But I still think the other non-`N` kmers should be included in the graph.
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/69,uci-cbcl++genomix.csv
MDU6SXNzdWUyMzg3ODQ3Mg==,Support for variable length reads and variable insert sizes,OPEN,2013-12-06T19:11:31Z,2013-12-06T20:14:23Z,,"For the scaffolding steps, we need to know how long each read is and its ""outer distance"", that is, the total distance between the two outside tips of the fragment.  We currently don't have any mechanism for recording this.

Reads belong to different ""libraries"", all of whose reads will have the same length and that will have the same insert size.  We currently don't have any way of indicating the library of a given read.

We need to record the _library-id_ in each read and then have _lookup tables_ that map library-id to read length and library-id to outer-distance.
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/88,uci-cbcl++genomix.csv
MDU6SXNzdWUyMzkxNTY1NA==,Travis has been failing for a while,OPEN,2013-12-08T00:18:15Z,2013-12-08T00:18:18Z,,"We need to regenerate the expected outputs and fix the step names
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/93,uci-cbcl++genomix.csv
MDU6SXNzdWUyMzkxNjU1Ng==,Need to standardize Counters usage in pregelix,OPEN,2013-12-08T01:36:03Z,2013-12-18T02:32:15Z,,"Only a few jobs use Counters right now but it would be awesome to report them between jobs.
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/95,uci-cbcl++genomix.csv
MDU6SXNzdWUyMzk5MDM5OA==,Determine parameters automatically,OPEN,2013-12-09T20:24:51Z,2013-12-09T20:24:51Z,,"It would be slick if we could build the coverage graph automatically and determine optimal parameters if they're not given on the cmdline.
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/98,uci-cbcl++genomix.csv
MDU6SXNzdWUyNDAwMDAxOQ==,Hyracks Graph build exceptions aren't propagated to the Driver,OPEN,2013-12-09T22:57:45Z,2013-12-09T23:11:35Z,,"See https://s3.amazonaws.com/archive.travis-ci.org/jobs/15107105/log.txt at the end.  BUILD_HYRACKS failed and threw an exception but it isn't being passed up to the Hyracks Driver (or we're catching it somewhere?).

@Nan-Zhang do you want to look into it?
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/99,uci-cbcl++genomix.csv
MDU6SXNzdWUyNDIyMDU1Mw==,Need read length for each library,OPEN,2013-12-13T00:55:18Z,2013-12-13T00:55:18Z,,"We could detect this automatically, either when converting the fasta file or when running graph build, but it will need to be specified on the command-line if we aren't running those steps.
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/104,uci-cbcl++genomix.csv
MDU6SXNzdWUyNDQ3MzYxMg==,concatenated jobs save state,OPEN,2013-12-18T07:20:20Z,2013-12-18T18:36:38Z,,"@anbangx @Elmira88 @JavierJia @Nan-Zhang 

Elmira found a pretty major problem when running without `-saveIntermediateResults` recently:  the vertex value is unchanged between iterations.  I had thought that the entire dataset would be scrubbed by going through the Input/OutputFormat adapters between jobs (Node -> P4VertexValue -> Node -> RayVertexValue -> Node -> ...).  

Turns out that's false and the only reason we haven't noticed before is because of a bug in pregelix by which concatenated jobs all use the generic base class `VertexValue`.  I've submitted the bug report to @sigmod and there's a temporary solution: we manually scrub the data on the first iteration.

In the meantime, I recommend using `-saveIntermediateResults` to make sure that the state gets wiped between jobs. Specifying this flag will force an HDFS write and therefore a trip through the Input/OutputFormat adapters.
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/110,uci-cbcl++genomix.csv
MDU6SXNzdWUyNDUwNzkxMw==,scaffolding ideas,OPEN,2013-12-18T18:12:35Z,2013-12-18T18:12:35Z,,"@anbangx @Elmira88 @JavierJia @Nan-Zhang 

I was thinking about scaffolding last night.  I mentioned in #101 some ideas and future optimizations but thought I'd do a brain dump here as well.

Here's an idea for a ""SplitRepeat"" job:  take the current framework but for each walk node that has 2+ back- or incoming-edges, we can request the candidate's score according to the read sequences in those back edges.  When two candidates seem to have nearly equal scores, we can turn turn to the backedge scores to try to split the repeated frontier node (or some portion of the walk).

In ascii art:

```
         b1
           \  ----c1
w1--w2--w3--f<
              ----c2
```

in the simple version of this algorithm, we request scores of the subkmers `f--c1` and `f--c2` from b1 which aggregates the score to `f`, just like the walk nodes `w1`-`w3` do.  If we get a ""strong"" signal from b1 about one of the paths (say, `b1--f--c1`) and it's not the same as the path that's strong in the walk (say, `w1--w2--w3--f--c2`), then we could assume that `f` is a repeat node, shared by the two different paths.  We could the split `f` into `f1` and `f2`, resulting in the paths `b1--f1--c1` and `w1--w2--w3--f--c2`.
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/112,uci-cbcl++genomix.csv
MDU6SXNzdWUyNDcyNjg4OQ==,hadoop /user/tmp is cleared automatically; the readid list disappears!,CLOSED,2013-12-23T22:24:47Z,2014-01-07T00:09:31Z,2014-01-07T00:09:31Z,"Hey @JavierJia we just tried to rerun some previous results on ipubmed2 and had a glaring realization... the filemanager dumps the readidset to disk under /user/tmp which (apparently) gets cleaned out automatically.  We tried to run some pipeline steps using data that was dumped on Thursday as input... there are many missing directories (though some are still intact).

With your #108, we gain the option to store the node in the local fs.  I think what we now need is a way to store the full set in the write() and read() calls.  Pregelix uses an adapter to dump from the vertex to an HDFS-based `Node`. I think in our output format,
we can explicitly set the readheadset to be dumped inside the node.  You should be able to add it somewhere aroung https://github.com/uci-cbcl/genomix/blob/genomix/fullstack_genomix/genomix/genomix-pregelix/src/main/java/edu/uci/ics/genomix/pregelix/base/GenericVertexToNodeOutputFormat.java#L34

I think this needs to be fixed ASAP...

cc @anbangx 
",jakebiesinger,https://github.com/uci-cbcl/genomix/issues/117,uci-cbcl++genomix.csv
MDU6SXNzdWUyNTE0MTYxOA==,Recover genomix-pregelix test cases.,OPEN,2014-01-07T01:00:09Z,2014-01-07T01:00:09Z,,,JavierJia,https://github.com/uci-cbcl/genomix/issues/122,uci-cbcl++genomix.csv
MDU6SXNzdWUyNTE0MTYyMw==,create Ray scaffolding test cases ,OPEN,2014-01-07T01:00:32Z,2014-01-07T01:00:32Z,,,JavierJia,https://github.com/uci-cbcl/genomix/issues/123,uci-cbcl++genomix.csv
MDU6SXNzdWUyNTE0MTYzMg==,recover ,CLOSED,2014-01-07T01:00:39Z,2014-01-07T05:07:42Z,2014-01-07T05:07:42Z,,JavierJia,https://github.com/uci-cbcl/genomix/issues/124,uci-cbcl++genomix.csv
MDU6SXNzdWUyNTE0MTY2MA==,Recover genomix-driver test cases,OPEN,2014-01-07T01:01:25Z,2014-01-07T01:01:25Z,,,JavierJia,https://github.com/uci-cbcl/genomix/issues/125,uci-cbcl++genomix.csv
MDU6SXNzdWUxODU4MDEyNTY=,Failed to map REF block,CLOSED,2016-10-27T23:01:08Z,2018-08-21T19:21:55Z,2018-08-21T19:21:55Z,"Trying to convert this hg19 VCF to hg38:
https://storage.cloud.google.com/genomics-public-data/platinum-genomes/vcf/NA12880_S1.genome.vcf

Using the chain file from the README and a query BED file that covers all passing reference positions, the processing stops with the following error:

```
Exception in thread ""main"" java.lang.IllegalArgumentException: Different reference for query variant and reference in query_range {
  reference_name: ""chr1""
  start: 1584759
  end: 1584798
}
target_range {
  reference_name: ""chr1""
  start: 1653313
  end: 1653352
}
target_strand: POSITIVE_STRAND
region_type: MISMATCHED_BASES

        at com.google.common.base.Preconditions.checkArgument(Preconditions.java:146)
        at com.verily.genomewarp.TransformationUnit.getTargetAssemblyVariantsFromDualSNVs(TransformationUnit.java:244)
        at com.verily.genomewarp.TransformationUnit.getTargetAssemblyVariants(TransformationUnit.java:163)
        at com.verily.genomewarp.TransformVariantsInRange.getTargetVariantsForAllTransformationUnitsInRange(TransformVariantsInRange.java:332)
        at com.verily.genomewarp.TransformVariantsInRange.transform(TransformVariantsInRange.java:162)
        at com.verily.genomewarp.TransformVariantsInRange.transformQueryToTargetVariants(TransformVariantsInRange.java:85)
        at com.verily.genomewarp.GenomeWarpSerial.main(GenomeWarpSerial.java:833)
```

Query entry causing the issue:
`chr1    1584760 .       C       .       .       PASS    END=1584798;BLOCKAVG_min30p3a   GT:DP:GQX:MQ    0/0:38:99:49`

HG19 (query_range sequence)

```
>chr1:1584760-1584798
caccc*g*gctttatttttatttttttcagatagaatctcg
```

HG38 (target_range sequence)

```
>chr1:1653314-1653352
CACCC*A*GCTTTATTTTTATTTTTTTCAGATAGAATCTCG
```

This part of the code performs a comparison of the first position of the query REF block (`C`) with the 6th position in the target REF block (`G`):
`https://github.com/verilylifesciences/genomewarp/blob/15a9a2a22c609dbe7f8bc1fe7818c8a8323cf165/src/main/java/com/verily/genomewarp/TransformationUnit.java#L245`

Line 245: `referenceGenomeDifference().queryDna().equals(variant.getReferenceBases()),`

Values compared by `.equals()`:
`referenceGenomeDifference()` = `{queryPosition=1584764, queryDna=G, targetDna=A}`
`variant.getReferenceBases()` = `C`

The query reference base for REF blocks will always be a single base and should not be compared to the n-th base with the difference in the target sequence.
",robertschmieder,https://github.com/verilylifesciences/genomewarp/issues/2,verilylifesciences++genomewarp.csv
MDU6SXNzdWUyODYwODEwNjU=,Variants doubled with a subset bed file for the same vcf file,CLOSED,2018-01-04T18:57:15Z,2018-09-19T20:29:53Z,2018-09-19T20:29:53Z,"Dear all,
I use the same vcf file from hg37 run two times with a bed and its subset.
However, I get double variants with the subset bed, the number of which even more reasonable for normal sense.
Could you help me figure out what happened behind this result

#####brief points for two run####
INPUT1: VCF1, BED1, Hg37.fa, hg19to38.chain.file, hg38
OUTPUT1: VCF1_output1, BED1_output;

INPUT2: VCF1, BED2, Hg37.fa, hg19to38.chain.file, hg38
OUTPUT2: VCF1_output2, BED2_output

Initial variants in VCF1: 4875314
Initial bases in BED1: 2806545357
Initial bases in BED2: 2728614045
**Relationship between BED1 and BED2: BED2 is a totally subset of BED1**
Variants in VCF1_output1: **2102101**
Variants in VCF1_output2: **3983104**
bases in BED1_output: 1143768646
bases in BED2_output: 2628402283
 
#######file used for two run##############
VCF1: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/NISTv3.3.2/GRCh37/supplementaryFiles/inputvcfsandbeds/HG001_GRCh37_CHROM1-MT_novoalign_Ilmn150bp300X_FB.vcf.gz

BED1: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/NISTv3.3.2/GRCh37/supplementaryFiles/inputvcfsandbeds/HG001_GRCh37_CHROM1-MT_novoalign_Ilmn150bp300X_callableloci.bed
note: keep ""callable"" position only according the lable information in column 4

BEDg: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/NISTv3.3.2/GRCh37/supplementaryFiles/inputvcfsandbeds/HG001_GRCh37_CHROM1-X_novoalign_Ilmn150bp300X_GATKHC_gvcf_callable.bed
BED2: Intersect region of BED1 and BEDg by ""bedtools-intersect"" command

hg37.fa: ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz
hg38,fa: ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna.gz
chainfile:
http://hgdownload.cse.ucsc.edu/goldenpath/hg19/liftOver/hg19ToHg38.over.chain.gz

Thanks for your time




",justwalking2017,https://github.com/verilylifesciences/genomewarp/issues/4,verilylifesciences++genomewarp.csv
MDU6SXNzdWUzOTg5OTkwMTY=,Support or fail when query input BED contains overlapping records,CLOSED,2019-01-14T17:39:58Z,2019-04-08T15:53:07Z,2019-04-08T15:53:07Z,"GenomeWarp requires that the query input BED contain no overlapping records.
When the input BED does contain overlapping records, the result can be that GenomeWarp drops variants in the liftover.

At the very least it would be great if GenomeWarp detected this situation and aborted with a helpful error message.",mbookman,https://github.com/verilylifesciences/genomewarp/issues/6,verilylifesciences++genomewarp.csv
I_kwDOA_TuC85nvr94,Failed to build ,CLOSED,2023-06-04T19:51:34Z,2023-07-05T13:31:05Z,2023-07-05T13:31:05Z,"Hello,
I've followed the steps to build the .jar file, but I ran into this issue (after running mvn package):

> [ERROR] Failed to execute goal org.xolstice.maven.plugins:protobuf-maven-plugin:0.5.0:compile (default) on project verilylifesciences-genomewarp: Missing:
> [ERROR] ----------
> [ERROR] 1) com.google.protobuf:protoc:exe:osx-aarch_64:3.0.0-beta-2
> [ERROR] 
> [ERROR]   Try downloading the file manually from the project website.
> [ERROR] 
> [ERROR]   Then, install it using the command: 
> [ERROR]       mvn install:install-file -DgroupId=com.google.protobuf -DartifactId=protoc -Dversion=3.0.0-beta-2 -Dclassifier=osx-aarch_64 -Dpackaging=exe -Dfile=/path/to/file
> [ERROR] 
> [ERROR]   Alternatively, if you host your own repository you can deploy the file there: 
> [ERROR]       mvn deploy:deploy-file -DgroupId=com.google.protobuf -DartifactId=protoc -Dversion=3.0.0-beta-2 -Dclassifier=osx-aarch_64 -Dpackaging=exe -Dfile=/path/to/file -Durl=[url] -DrepositoryId=[id]
> [ERROR] 
> [ERROR]   Path to dependency: 
> [ERROR]   	1) com.verily.genomewarp:verilylifesciences-genomewarp:jar:1.2.1
> [ERROR]   	2) com.google.protobuf:protoc:exe:osx-aarch_64:3.0.0-beta-2
> [ERROR] 
> [ERROR] ----------
> [ERROR] 1 required artifact is missing.
> [ERROR] 
> [ERROR] for artifact: 
> [ERROR]   com.verily.genomewarp:verilylifesciences-genomewarp:jar:1.2.1
> [ERROR] 
> [ERROR] from the specified remote repositories:
> [ERROR]   central (https://repo.maven.apache.org/maven2, releases=true, snapshots=false)

I also tried building manually, again using Gradle, and of course also following the steps in the error message to fix the issue. However, this hasn't worked. Would it be possible to provide the already built .jar file itself? Or am I missing something obvious here?

Thanks!",scpv,https://github.com/verilylifesciences/genomewarp/issues/14,verilylifesciences++genomewarp.csv
I_kwDOIJbMPc59zLuV,Using chrR ref genome with STAR,OPEN,2024-01-31T17:06:06Z,2024-11-16T22:24:43Z,,"Hi,
Thank you for putting these reference genomes together! They've been very helpful for my work.

I'd like to use hg38-rDNA_v1.0.fa to map an RNAseq dataset using STAR. How should the annotation file, hg38-rDNA_v1.0.bed, be adapted for compatibility with STAR's .gtf format?

Best",LucasMcNU,https://github.com/vikramparalkar/rDNA-Mapping-Genomes/issues/1,vikramparalkar++rDNA-Mapping-Genomes.csv
I_kwDOIJbMPc6WRDY_,Some rRNA not mapped to the reference genome,OPEN,2024-09-12T00:21:02Z,2024-09-26T00:51:29Z,,"Dear team;
Thanks for providing those wonderful reference genome. It helps me a lot in my research. I met a problem that many of my reads could mapped to rrna region but was classified to not aligned when using bowtie2 alignment. Here is the details:
I used  `bowtie2     -x rRNA_mm10_reference_genome/bowtie2_index/rRNA     -U ../clean_Sample_1_R1.fastq.gz   -S rRNA_trash.sam   --un mrna_sample1.fastq` And I assume unmapped as normal mrna. 
 For the next step, I put the unmapped reads to STARaligner, and got the mapped mrna reads. 
```
STAR --genomeDir reference_genome/mm10_Gencode_STAR \
	--runThreadN 40 \
	--readFilesIn mrna_sample1.fastq \
	--outFileNamePrefix sample1_mRNA_R1 \
	--outSAMtype BAM SortedByCoordinate
```
Later, I used feature count to get the count matrix `featureCounts -a gencode.vM10.annotation.gtf -g gene_name -o count_sample1_R1_ds sample1_mRNA_R1Aligned.sortedByCoord.out.bam` And I found there are huge numbers of Rn18s-rs5 gene, which is a typical 18s rRNA. But it show up in the mrna files (All rRNA should be filter out) that should not contain any rRNA. I double check those reads  in the genome browser(IGV) and majority of them does not have splice sites. Could you help me check this issue? Thanks a lot.
Yuchen",Xuyuch,https://github.com/vikramparalkar/rDNA-Mapping-Genomes/issues/2,vikramparalkar++rDNA-Mapping-Genomes.csv
I_kwDOED2S9s6ArklP,ruby: No such file or directory -- solid_pairs.rb (LoadError),OPEN,2024-02-28T12:53:42Z,2024-02-28T12:53:42Z,,"Hi,

Thank you for making this tool available to the community.

I am running `compare-genome-qualities` using the following command:

```
nohup docker run --volume=`pwd`:/mnt:rw wurmlab/compare-genome-qualities \
	--genome-size 7000000 \
	--busco-lineage burkholderiales_odb10.2024-01-08.tar.gz \
	--illumina-R1 Cmet/NA4_R1.fastq.gz \
	--illumina-R2 Cmet/NA4_R2.fastq.gz \
	--num-cpus 8 \
	Cmet/assemblies/original_files/NA4.unicycler.fasta \
	Cmet/assemblies/original_files/NA4.try.polish.fasta \
	Cmet/assemblies/original_files/NA4.raven.fasta \
	Cmet/assemblies/original_files/NA4.miniasm.fasta \
	Cmet/assemblies/original_files/NA4.flye.fasta \
	Cmet/assemblies/original_files/NA4.canu.trim.fasta \
    > nohup-nextflow.out \
    2> nohup-nextflow.err
```

And I am getting the following error:

```
--2024-02-28 12:24:16--  https://busco-data.ezlab.org/v5/data/lineages/burkholderiales_odb10.2024-01-08.tar.gz
Resolving busco-data.ezlab.org (busco-data.ezlab.org)... 129.194.190.40
Connecting to busco-data.ezlab.org (busco-data.ezlab.org)|129.194.190.40|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 17750318 (17M) [application/octet-stream]
Saving to: compare-genome-qualities-2024-02-28-122415/burkholderiales_odb10.2024-01-08.tar.gz

     0K .......... .......... .......... .......... ..........  0% 2.94M 6s
    50K .......... .......... .......... .......... ..........  0% 3.01M 6s
   100K .......... .......... .......... .......... ..........  0% 75.4M 4s
   ...
 17150K .......... .......... .......... .......... .......... 99% 79.6M 0s
 17200K .......... .......... .......... .......... .......... 99%  110M 0s
 17250K .......... .......... .......... .......... .......... 99%  107M 0s
 17300K .......... .......... .......... ....                 100%  141M=0.2s

2024-02-28 12:24:17 (68.6 MB/s) - compare-genome-qualities-2024-02-28-122415/burkholderiales_odb10.2024-01-08.tar.gz saved [17750318/17750318]

/cmg/quast.sh -g 7000000 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.unicycler.fasta)/quast Cmet/assemblies/original_files/NA4.unicycler.fasta
/cmg/quast.sh -g 7000000 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.try.polish.fasta)/quast Cmet/assemblies/original_files/NA4.try.polish.fasta
/cmg/quast.sh -g 7000000 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.raven.fasta)/quast Cmet/assemblies/original_files/NA4.raven.fasta
/cmg/quast.sh -g 7000000 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.miniasm.fasta)/quast Cmet/assemblies/original_files/NA4.miniasm.fasta
/cmg/quast.sh -g 7000000 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.flye.fasta)/quast Cmet/assemblies/original_files/NA4.flye.fasta
/cmg/quast.sh -g 7000000 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.canu.trim.fasta)/quast Cmet/assemblies/original_files/NA4.canu.trim.fasta
/cmg/busco.sh -b compare-genome-qualities-2024-02-28-122415/burkholderiales_odb10 -n 8 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.unicycler.fasta)/busco Cmet/assemblies/original_files/NA4.unicycler.fasta
/cmg/busco.sh -b compare-genome-qualities-2024-02-28-122415/burkholderiales_odb10 -n 8 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.try.polish.fasta)/busco Cmet/assemblies/original_files/NA4.try.polish.fasta
/cmg/busco.sh -b compare-genome-qualities-2024-02-28-122415/burkholderiales_odb10 -n 8 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.raven.fasta)/busco Cmet/assemblies/original_files/NA4.raven.fasta
/cmg/busco.sh -b compare-genome-qualities-2024-02-28-122415/burkholderiales_odb10 -n 8 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.miniasm.fasta)/busco Cmet/assemblies/original_files/NA4.miniasm.fasta
/cmg/busco.sh -b compare-genome-qualities-2024-02-28-122415/burkholderiales_odb10 -n 8 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.flye.fasta)/busco Cmet/assemblies/original_files/NA4.flye.fasta
/cmg/busco.sh -b compare-genome-qualities-2024-02-28-122415/burkholderiales_odb10 -n 8 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.canu.trim.fasta)/busco Cmet/assemblies/original_files/NA4.canu.trim.fasta
/cmg/map_illumina.sh -n 8 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.unicycler.fasta)/illumina Cmet/assemblies/original_files/NA4.unicycler.fasta Cmet/NA4_R1.fastq.gz Cmet/NA4_R2.fastq.gz
/cmg/map_illumina.sh -n 8 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.try.polish.fasta)/illumina Cmet/assemblies/original_files/NA4.try.polish.fasta Cmet/NA4_R1.fastq.gz Cmet/NA4_R2.fastq.gz
/cmg/map_illumina.sh -n 8 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.raven.fasta)/illumina Cmet/assemblies/original_files/NA4.raven.fasta Cmet/NA4_R1.fastq.gz Cmet/NA4_R2.fastq.gz
/cmg/map_illumina.sh -n 8 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.miniasm.fasta)/illumina Cmet/assemblies/original_files/NA4.miniasm.fasta Cmet/NA4_R1.fastq.gz Cmet/NA4_R2.fastq.gz
/cmg/map_illumina.sh -n 8 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.flye.fasta)/illumina Cmet/assemblies/original_files/NA4.flye.fasta Cmet/NA4_R1.fastq.gz Cmet/NA4_R2.fastq.gz
/cmg/map_illumina.sh -n 8 -o compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.canu.trim.fasta)/illumina Cmet/assemblies/original_files/NA4.canu.trim.fasta Cmet/NA4_R1.fastq.gz Cmet/NA4_R2.fastq.gz
[bwa_index] Pack FASTA... 0.09 sec
[bwa_index] Construct BWT for the packed sequence...
[bwa_index] 2.91 seconds elapse.
[bwa_index] Update BWT... 0.08 sec
[bwa_index] Pack forward-only FASTA... 0.05 sec
[bwa_index] Construct SA from BWT and Occ... 1.06 sec
[main] Version: 0.7.17-r1188
[main] CMD: bwa index compare-genome-qualities-2024-02-28-122415/NA4.raven.fasta/illumina/NA4.raven.fasta
[main] Real time: 4.458 sec; CPU: 4.193 sec
[bam_sort_core] merging from 0 files and 8 in-memory blocks...
[bwa_index] Pack FASTA... 0.09 sec
[bwa_index] Construct BWT for the packed sequence...
[bwa_index] 3.13 seconds elapse.
[bwa_index] Update BWT... 0.07 sec
[bwa_index] Pack forward-only FASTA... 0.06 sec
[bwa_index] Construct SA from BWT and Occ... 1.05 sec
[main] Version: 0.7.17-r1188
[main] CMD: bwa index compare-genome-qualities-2024-02-28-122415/NA4.try.polish.fasta/illumina/NA4.try.polish.fasta
[main] Real time: 4.697 sec; CPU: 4.408 sec
[bam_sort_core] merging from 0 files and 8 in-memory blocks...
[bwa_index] Pack FASTA... 0.06 sec
[bwa_index] Construct BWT for the packed sequence...
[bwa_index] 3.00 seconds elapse.
[bwa_index] Update BWT... 0.08 sec
[bwa_index] Pack forward-only FASTA... 0.06 sec
[bwa_index] Construct SA from BWT and Occ... 1.05 sec
[main] Version: 0.7.17-r1188
[main] CMD: bwa index compare-genome-qualities-2024-02-28-122415/NA4.miniasm.fasta/illumina/NA4.miniasm.fasta
[main] Real time: 4.709 sec; CPU: 4.262 sec
[bam_sort_core] merging from 0 files and 8 in-memory blocks...
[bwa_index] Pack FASTA... 0.10 sec
[bwa_index] Construct BWT for the packed sequence...
[bwa_index] 2.86 seconds elapse.
[bwa_index] Update BWT... 0.08 sec
[bwa_index] Pack forward-only FASTA... 0.06 sec
[bwa_index] Construct SA from BWT and Occ... 1.06 sec
[main] Version: 0.7.17-r1188
[main] CMD: bwa index compare-genome-qualities-2024-02-28-122415/NA4.unicycler.fasta/illumina/NA4.unicycler.fasta
[main] Real time: 4.515 sec; CPU: 4.158 sec
[bam_sort_core] merging from 0 files and 8 in-memory blocks...
[bwa_index] Pack FASTA... 0.06 sec
[bwa_index] Construct BWT for the packed sequence...
[bwa_index] 2.89 seconds elapse.
[bwa_index] Update BWT... 0.06 sec
[bwa_index] Pack forward-only FASTA... 0.06 sec
[bwa_index] Construct SA from BWT and Occ... 1.11 sec
[main] Version: 0.7.17-r1188
[main] CMD: bwa index compare-genome-qualities-2024-02-28-122415/NA4.canu.trim.fasta/illumina/NA4.canu.trim.fasta
[main] Real time: 4.545 sec; CPU: 4.180 sec
[bam_sort_core] merging from 0 files and 8 in-memory blocks...
[bwa_index] Pack FASTA... 0.09 sec
[bwa_index] Construct BWT for the packed sequence...
[bwa_index] 2.46 seconds elapse.
[bwa_index] Update BWT... 0.07 sec
[bwa_index] Pack forward-only FASTA... 0.06 sec
[bwa_index] Construct SA from BWT and Occ... 1.11 sec
[main] Version: 0.7.17-r1188
[main] CMD: bwa index compare-genome-qualities-2024-02-28-122415/NA4.flye.fasta/illumina/NA4.flye.fasta
[main] Real time: 4.050 sec; CPU: 3.795 sec
[bam_sort_core] merging from 0 files and 8 in-memory blocks...
/cmg/solid_pairs.sh compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.unicycler.fasta)/illumina/bwa_mem_default.bam
/cmg/solid_pairs.sh compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.try.polish.fasta)/illumina/bwa_mem_default.bam
/cmg/solid_pairs.sh compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.raven.fasta)/illumina/bwa_mem_default.bam
/cmg/solid_pairs.sh compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.miniasm.fasta)/illumina/bwa_mem_default.bam
/cmg/solid_pairs.sh compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.flye.fasta)/illumina/bwa_mem_default.bam
/cmg/solid_pairs.sh compare-genome-qualities-2024-02-28-122415/$(basename Cmet/assemblies/original_files/NA4.canu.trim.fasta)/illumina/bwa_mem_default.bam
ruby: No such file or directory -- solid_pairs.rb (LoadError)
ruby: No such file or directory -- solid_pairs.rb (LoadError)
ruby: No such file or directory -- solid_pairs.rb (LoadError)
ruby: No such file or directory -- solid_pairs.rb (LoadError)
ruby: No such file or directory -- solid_pairs.rb (LoadError)
```

Would you have any suggestions to overcome this?
",etlioglu,https://github.com/wurmlab/CompareGenomeQualities/issues/1,wurmlab++CompareGenomeQualities.csv
MDU6SXNzdWU3OTI0NTUyNTY=,a question about the #TE annotation,OPEN,2021-01-23T06:37:20Z,2021-01-23T08:25:08Z,,"hello, I would like to ask a question about your TE annotated script.
###
RepeatMasker -pa 24 -div 22 -cutoff 250 -gff -lib barthiiSpecificTelib.fa -nolow -norna -xsmall barthii.fa

 Where is the lib file barthiiSpecificTelib.fa  or how did you get it?",yilinZhang-bio,https://github.com/xma82/rice_genome_assembly/issues/1,xma82++rice_genome_assembly.csv
I_kwDOMSca8s6V1JTn,SOAPdenovo_array.sh error,OPEN,2024-09-09T11:48:02Z,2024-09-11T07:46:42Z,,"We tried running the SOAPdenovo_array.sh script using 30 .fq files of total size 557GB as input and a reference genome with a total size of approximately 17GB.
The SOAPdenovo_array.sh script requires a cluster with 22 computing nodes and 200GB RAM.
Our cluster contains 16 computing nodes, with 48 CPUs and 120GB RAM each, thus we changed the SOAPdenovo_array.sh script SLURM parameters to cater to our system specs.

However, when we run the script using sbatch, it didn't produce any output. After checking the .err files, we get the following message at the file end:

slurmstepd: error: Detected 2 oom_kill events in StepId=3851.0. Some of the step tasks have been OOM Killed.
srun: error: comp16: task 9: Out Of Memory
slurmstepd: error: Detected 4 oom_kill events in StepId=3851.0. Some of the step tasks have been OOM Killed.
--- 100000000th reads.
--- 100000000th reads.
--- 200000000th reads.
--- 200000000th reads.

We wonder what modifications we should try in order to run SOAPdenovo_array.sh successfully. ",AlkistisZach,https://github.com/YannBourgeois/Scripts_Genome_assembly_Tgraeca/issues/1,YannBourgeois++Scripts_Genome_assembly_Tgraeca.csv
MDU6SXNzdWU5NTYzNTE4NTA=,Genome annotation resources,OPEN,2021-07-30T02:47:45Z,2021-07-30T02:47:45Z,,"Dear Zachary,
I am looking for the genome annotation resources of Acropora millepora in your project, but seems it is not available in NCBI.
Would you kindly provide the gene model annoation files, including the transcript and protein sequence file and gff file?
Thank you very much!

Best,
Yichun",xieyichun50,https://github.com/zfuller5280/CoralGenomes/issues/1,zfuller5280++CoralGenomes.csv
I_kwDOH0oqe85P9Ilq,Figures: STgenome assembly,OPEN,2022-08-17T09:07:21Z,2022-08-19T11:42:16Z,,"Fig1: Bandage
![Screen Shot 2022-08-17 at 09 59 08](https://user-images.githubusercontent.com/12142475/185080381-697dfc3c-6a39-45a9-86e8-d190193b0f9d.png)

Fig2: Bandage with size labels
![Screen Shot 2022-08-17 at 09 58 53](https://user-images.githubusercontent.com/12142475/185080389-a8de0e71-0f42-4344-80f0-67582701d815.png)

Fig3: purge_dups histogram prior to purging in Round1
<img width=""822"" alt=""Screen Shot 2022-08-17 at 16 23 47"" src=""https://user-images.githubusercontent.com/12142475/185180801-73e17a67-d461-4088-b941-1bc4aad4b978.png"">

Fig4: purge_dups histogram after purging in Round1
![Screen Shot 2022-08-19 at 12 41 46](https://user-images.githubusercontent.com/12142475/185611037-916efc02-9404-4497-bfff-69db92424ae7.png)



",alexjvr1,https://github.com/alexjvr1/T.dalmanni_Genomics_of_meiotic_drive/issues/1,alexjvr1++T.dalmanni_Genomics_of_meiotic_drive.csv
I_kwDOH0oqe85XG96E,Figures for diagnostic primers,OPEN,2022-11-23T10:10:31Z,2022-11-23T10:10:31Z,,"![Screen Shot 2022-11-23 at 12 07 33](https://user-images.githubusercontent.com/12142475/203520468-fe1b13ed-8b0c-4627-9c93-98bc79f71d0c.png)

![Screen Shot 2022-11-23 at 10 17 48](https://user-images.githubusercontent.com/12142475/203520479-9b87143c-2615-4e0d-86d7-39d4e584a8db.png)
",alexjvr1,https://github.com/alexjvr1/T.dalmanni_Genomics_of_meiotic_drive/issues/2,alexjvr1++T.dalmanni_Genomics_of_meiotic_drive.csv
I_kwDOH0oqe85YIeEo,Figures: PCA,OPEN,2022-12-06T09:11:52Z,2022-12-06T09:11:52Z,,"![Screen Shot 2022-12-06 at 11 07 33](https://user-images.githubusercontent.com/12142475/205868236-ab2477e5-e044-4ec7-a782-755657eabe14.png)

![Screen Shot 2022-12-06 at 11 11 26](https://user-images.githubusercontent.com/12142475/205869103-178d6637-21ed-4e3f-b0f0-72ac2cf6b7f0.png)

",alexjvr1,https://github.com/alexjvr1/T.dalmanni_Genomics_of_meiotic_drive/issues/3,alexjvr1++T.dalmanni_Genomics_of_meiotic_drive.csv
I_kwDOHnk0is5Xp1_G,"Is there any relationship between false positives and ""rescue mapping""?",CLOSED,2022-12-01T03:02:35Z,2023-01-19T09:02:31Z,2023-01-19T09:02:30Z,"Very interesting work, and some nice results in terms of performance and sensitivity! However, the false positive rate is pretty startling--I suspect it is unacceptably high for many applications.

In section 3.6.3 I noticed this concept of ""rescue mapping"" when there is no hit above the user-provided threshold. I was curious: do you see any enrichment for false positives among these rescued reads? You mention that it improves sensitivity, but I am curious what the cost is.",jamestwebber,https://github.com/CMU-SAFARI/Genome-on-Diet/issues/1,CMU-SAFARI++Genome-on-Diet.csv
I_kwDOLDyf8859Os17,Fix event update loop,OPEN,2024-01-25T19:10:22Z,2024-01-25T19:28:01Z,,Create a custom event loop to handle UI updates efficiently.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/1,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859OtPy,Fix cancelling preprocessing terminates app,CLOSED,2024-01-25T19:11:39Z,2024-01-27T00:38:59Z,2024-01-27T00:38:59Z,"""os.kill(self.preprocessing_process.pid, signal.CTRL_C_EVENT)"" terminates the whole program.",mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/2,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859OuzQ,Reserve preproccessing progress bar space,CLOSED,2024-01-25T19:16:37Z,2024-02-04T01:11:54Z,2024-02-04T01:11:53Z,"The progress bar moves too much when multiple files are being downloaded quickly.

Keep only one instance of the progress bar and clear it when downloading.",mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/3,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859O4A2,Add console output to prepoccessing tab,OPEN,2024-01-25T19:42:09Z,2024-01-26T02:56:06Z,,To track downloads and errors.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/4,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QfQa,Make console output log file,OPEN,2024-01-26T02:29:46Z,2024-01-26T03:04:00Z,,Add logging capability to allow for extensive tracking.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/5,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qfdv,Add all Ray parameters to UI,OPEN,2024-01-26T02:31:01Z,2024-01-26T02:34:19Z,,Give more control to the user.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/6,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qfji,Add all DSK parameters to UI,OPEN,2024-01-26T02:31:32Z,2024-01-26T02:34:26Z,,Give more control to the user.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/7,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qfl5,Add all Kover parameters to UI,CLOSED,2024-01-26T02:31:47Z,2024-01-31T14:29:59Z,2024-01-31T14:29:58Z,Give more control to the user.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/8,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QfxT,Fix resizing issues,CLOSED,2024-01-26T02:32:49Z,2024-02-04T00:40:55Z,2024-02-04T00:40:54Z,Allow frames to be scrollable when the window size is too small.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/9,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QgNG,Add download speed meter,OPEN,2024-01-26T02:35:29Z,2024-01-26T03:04:14Z,,Quality of life improvement.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/10,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qgjf,Add Express tab,OPEN,2024-01-26T02:37:30Z,2024-01-26T02:38:02Z,,Add a tab to automate the workflow of the application.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/11,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qg9x,"Improve ""latest metadata for AMR"" tab UI",CLOSED,2024-01-26T02:39:57Z,2024-02-04T00:40:56Z,2024-02-04T00:40:55Z,Remove redundant action requirements to use the tab and improve its robustness.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/12,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QhNl,Rearrange Genomes tab UI,OPEN,2024-01-26T02:41:19Z,2024-01-26T03:04:37Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/13,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QhX0,Implement Dataset creation functionility,CLOSED,2024-01-26T02:42:15Z,2024-01-27T13:43:35Z,2024-01-27T13:43:34Z,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/14,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qhd1,Implement Dataset split functionility,CLOSED,2024-01-26T02:42:48Z,2024-01-29T12:08:23Z,2024-01-29T12:08:23Z,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/15,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QhhB,Implement Kover learn functionility,CLOSED,2024-01-26T02:43:06Z,2024-01-31T07:53:01Z,2024-01-31T07:53:00Z,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/16,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qhlz,Create Dataset split UI,CLOSED,2024-01-26T02:43:30Z,2024-01-28T23:40:58Z,2024-01-28T23:40:58Z,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/17,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qhr2,Create Kover learn UI,CLOSED,2024-01-26T02:44:00Z,2024-01-31T07:53:01Z,2024-01-31T07:53:01Z,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/18,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qhwu,Fix light mode,OPEN,2024-01-26T02:44:26Z,2024-01-26T03:08:08Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/19,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QiCE,Add Analysis tab,OPEN,2024-01-26T02:45:59Z,2024-01-26T03:05:34Z,,Add the Analysis tab that is responsible for studying the results of the Kover learn step.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/20,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QiLb,Allow for parallel downloading,CLOSED,2024-01-26T02:46:43Z,2024-04-21T16:48:54Z,2024-04-21T16:48:54Z,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/21,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QiRd,Write code comments,OPEN,2024-01-26T02:47:11Z,2024-01-26T03:05:41Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/22,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QiZK,Add readme file,OPEN,2024-01-26T02:47:57Z,2024-01-26T02:48:15Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/23,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qid7,Add license,OPEN,2024-01-26T02:48:25Z,2024-01-26T02:48:50Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/24,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qijf,Read license of third party dependencies,OPEN,2024-01-26T02:49:02Z,2024-01-26T02:49:15Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/25,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qio_,Credit third party dependencies,OPEN,2024-01-26T02:49:33Z,2024-01-26T02:49:42Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/26,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qive,Dockerize project,OPEN,2024-01-26T02:50:08Z,2024-01-26T03:05:56Z,,Dockerize project for ease of use.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/27,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qi0C,Add description to the project,OPEN,2024-01-26T02:50:35Z,2024-01-26T02:50:48Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/28,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qi6l,Add build workflows,OPEN,2024-01-26T02:51:14Z,2024-01-26T03:06:08Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/29,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QjEs,Add versions,OPEN,2024-01-26T02:52:12Z,2024-01-26T03:06:19Z,,Add versions to improve development tracking.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/30,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QjNW,Add website,OPEN,2024-01-26T02:53:03Z,2024-01-26T03:06:25Z,,Add a website for documentation purposes.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/31,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859QjR_,Add tests,OPEN,2024-01-26T02:53:31Z,2024-01-26T02:53:59Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/32,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qjl4,Add copy funcationaliy to tables,OPEN,2024-01-26T02:55:19Z,2024-01-26T02:55:40Z,,Allow the user to copy data from tables by CTRL+C or right-clicking.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/33,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Qu-g,Fix dirty buffer error in Ray,OPEN,2024-01-26T03:34:16Z,2024-01-26T03:34:34Z,,Fix the Ray dirty buffer loop that happens randomly when the count of .fna files is large.,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/34,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Td0I,Fix select directory on latest commit when downloading metadata files,CLOSED,2024-01-26T13:54:15Z,2024-01-26T21:28:33Z,2024-01-26T21:28:32Z,,editnori,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/35,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859UVPW,Move independent functions outside of gui.py,OPEN,2024-01-26T16:16:33Z,2024-01-26T16:17:47Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/36,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859UV0J,"Change ""Pick Dataset"" depending on selected method",OPEN,2024-01-26T16:18:04Z,2024-01-26T16:18:23Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/37,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859UflO,Make filedialogs more descriptive,OPEN,2024-01-26T16:44:19Z,2024-01-26T16:44:34Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/38,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859VDyq,Make run.ps1 automatically install venv if it does not exist,OPEN,2024-01-26T18:13:25Z,2024-01-26T18:13:42Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/39,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859VieB,Add load from reads in dataset creation,OPEN,2024-01-26T19:45:23Z,2024-01-26T19:45:52Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/40,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Wp_4,Cleanup after process termination,OPEN,2024-01-27T00:23:08Z,2024-01-27T00:23:34Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/41,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859WqIj,Put temp files in .temp/,CLOSED,2024-01-27T00:24:10Z,2024-02-05T03:59:26Z,2024-02-05T03:59:26Z,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/42,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Yfkj,Make cmd output buffered,CLOSED,2024-01-27T12:43:03Z,2024-01-31T14:35:13Z,2024-01-31T14:35:13Z,Allow for line changes using \r in the cmd output,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/43,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859YkMi,Clean kover,OPEN,2024-01-27T13:39:38Z,2024-01-27T13:39:52Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/44,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859Ykya,Fix application not fully closing,OPEN,2024-01-27T13:47:06Z,2024-01-27T13:47:30Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/45,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859aFfF,Change K-mer select in preprocessing to spinbox,OPEN,2024-01-28T06:13:38Z,2024-01-28T06:13:54Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/46,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859a1OU,Auto check if a kover dataset has folds disable CV if not,CLOSED,2024-01-28T14:21:13Z,2024-02-03T21:18:58Z,2024-02-03T21:18:58Z,"Add function when selecting Split IDs from `self.kover_learn_frame_control_panel_hp_selector` that changes `self.hp_choices` to remove `kover.HpChoice.CV` if `folds_count == 0`

```
match = re.search(r""(Folds: )(\d+)"", ""<result string>"")

folds_count = int(match.group(2))
```
",mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/47,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859bXr4,Add more Hover tips,OPEN,2024-01-28T20:04:50Z,2024-01-28T20:05:10Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/48,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859bqNs,Change dataset creation entry to spinbox,OPEN,2024-01-28T23:41:45Z,2024-01-28T23:41:58Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/49,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859bqQC,Add labels and move hovertips to the labels,OPEN,2024-01-28T23:42:10Z,2024-01-28T23:42:22Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/50,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859bwFX,Fix data creation grid,CLOSED,2024-01-29T00:31:05Z,2024-02-04T00:40:55Z,2024-02-04T00:40:55Z,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/51,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859fBqH,Add option to make train/test IDs for dataset split,OPEN,2024-01-29T11:32:50Z,2024-01-29T13:57:59Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/52,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859q3fQ,Have one wsl processing running and pipe all commands to it,OPEN,2024-01-30T17:25:59Z,2024-01-30T17:26:17Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/53,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf8859ysf1,Fix bug with paths cotaining spaces,OPEN,2024-01-31T16:04:03Z,2024-02-01T16:46:56Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/54,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf885-BBH4,Hide ctk.CTkScrollableFrame scrollbar when not needed,CLOSED,2024-02-02T06:34:52Z,2024-02-03T07:44:03Z,2024-02-03T07:44:03Z,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/55,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf885-BBaJ,Disable MouseScroll binding of ctk.CTkScrollableFrame when child with MouseScroll binding is entered,CLOSED,2024-02-02T06:35:36Z,2024-02-02T07:12:33Z,2024-02-02T07:12:32Z,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/56,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf885-KIgc,Add ability to resize for all widgets,OPEN,2024-02-03T16:46:21Z,2024-02-03T16:46:39Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/57,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf885-Ku-l,Fix infinite recursion in scrollableframe when its height is less than the size of elements,OPEN,2024-02-04T00:04:13Z,2024-02-04T00:09:33Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/58,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf886Gsz0e,Add Kover learn queueing,OPEN,2024-04-23T22:40:54Z,2024-04-23T23:13:33Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/59,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf886Gsz1e,Add Kover learning repeating,OPEN,2024-04-23T22:40:59Z,2024-04-23T23:14:39Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/60,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf886Gsz2h,"Name the project ""Genomic Resistance Mapping"" (GRM)",CLOSED,2024-04-23T22:41:04Z,2024-04-25T13:31:28Z,2024-04-25T13:31:28Z,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/61,editnori++Genomic-Resistance-Mapping-GRM-.csv
I_kwDOLDyf886G7Ju4,Add settings tab,OPEN,2024-04-25T13:52:46Z,2024-04-25T13:53:05Z,,,mhdeeb,https://github.com/editnori/Genomic-Resistance-Mapping-GRM-/issues/62,editnori++Genomic-Resistance-Mapping-GRM-.csv
MDU6SXNzdWUxNjM1MTAyNjc=,GFF and PTT parsers confused,OPEN,2016-07-02T09:23:03Z,2016-07-02T09:23:03Z,,"The enclosed GFF file is confused by the parser detection as PTT rather than GFF.

The cause is the double dot in the identifier of the contig.

[reproduce.zip](https://github.com/AbeelLab/genomeview/files/344475/reproduce.zip)
",thomasabeel,https://github.com/GenomeView/genomeview/issues/1,GenomeView++genomeview.csv
MDU6SXNzdWUzNTU1MjMxNjc=,All features from a BED file show as 'CDS' after tabbix indexing,OPEN,2018-08-30T10:28:49Z,2018-09-03T08:36:56Z,,"Compressed BED file with `bgzip `   
Indexing:   
```
tabbix -S 1 -p bed bed_file.gzip
```
All features will now be labeled as ""CDS"" instead of with the trackname or filename.

Uncompressed BED files will be shown correctly.",thpar,https://github.com/GenomeView/genomeview/issues/4,GenomeView++genomeview.csv
I_kwDOAxda1c5VOHDI,maf genome position ,OPEN,2022-10-31T12:25:38Z,2022-11-11T08:14:14Z,,"Hi, thanks for providing this useful tool.
It seems a small bug in genome position of maf
```
##maf version=1 
a score=262.0
s Xenopus_tropicalis.chr5           29721 13 + 164033575 CCCCCCGTTTGTT
s Ambystoma_mexicana.chr8q      150634379 13 + 886375962 TAATTCCTTTCTC
s Andrias_davidianus.ptg000471l   1972369 13 +   2026336 CCTTCTGCTTTCC
s Hynobius_yiwuensis.Contig128   31709499 13 -  45235456 CTTTTTAATTTCC
```
The corresponding result is 
![image](https://user-images.githubusercontent.com/38097726/199006968-e9815bf0-b549-4dca-9a1d-d5fd4fc192dd.png)

For example, the genomic position of Xenopus tropicalis should be 29722~29734 (13 bp).
",AlisaGU,https://github.com/GenomeView/genomeview/issues/6,GenomeView++genomeview.csv
I_kwDOFeq_N85Npei-,Truncated File Issue After Generating Flanking Seqs Step,CLOSED,2022-07-12T23:25:22Z,2022-07-14T14:46:02Z,2022-07-14T14:46:02Z,"Any clue why this might be happening?  I'm running VCF_2_Fasta_v1.1.py with no reported errors.  But the mapping step keeps kicking out this ""truncated file"" error.  Like this:  

[M::mem_process_seqs] Processed 49752 reads in 10.999 CPU sec, 10.926 real sec
[M::process] read 49752 sequences (10000152 bp)...
[M::mem_process_seqs] Processed 49752 reads in 11.168 CPU sec, 11.104 real sec
[E::sam_parse1] query name too long
[W::sam_read1_sam] Parse error at line 987047
samtools sort: truncated file. Aborting",kellybarr,https://github.com/KrisChristensen/MapVCF2NewGenome/issues/1,KrisChristensen++MapVCF2NewGenome.csv
I_kwDOFeq_N854Mwgx,error while running the CheckMappingVCF.v1.0.py,CLOSED,2023-11-29T13:35:06Z,2023-11-29T14:54:57Z,2023-11-29T14:54:57Z,"Hi, I am having problems generating the old2new.positions_filtered.txt

Everything ran correctly until step 5 (below), but then I got this error regarding the location of a key ""KeyError: 'CAE02294'"", but old2new.positions.txt contains the mentioned key. Any idea of what it can be?

Is it possible to add some dummy data so that I can test the different steps?
I have tried with other data sets without success either.

I am attaching the files here too. 
[Test.zip](https://github.com/KrisChristensen/MapVCF2NewGenome/files/13501024/Test.zip)

Thanks for your help.


python CheckMappingVCF.v1.0.py -map old2new.positions.txt -fasta1 flankingSeqs.fasta -fai1 flankingSeqs.fasta.fai -fasta2 newGenome.fasta -fai2 newGenome.fasta.fai -flanking 20 -output most > old2new.positions.filtered.txt


Running CheckMappingVCF version: 1.0 with the following parameters:
        -map: old2new.positions.txt
        -fasta1: flankingSeqs.fasta
        -fasta2: newGenome.fasta
        -fai1: flankingSeqs.fasta.fai
        -fai2: newGenome.fasta.fai
        -flanking: 20
        -output: most
        -verbose: NA

Opened index of fasta file (fai1): flankingSeqs.fasta.fai
        Finished reading scaffold fasta fai file: Found 37 sequence(s)
        Total Nucleotide(s): 7437

Opened index of fasta file (fai2): newGenome.fasta.fai
        Finished reading scaffold fasta fai file: Found 1115 sequence(s)
        Total Nucleotide(s): 1863494

Opened map file: old2new.positions.txt
Traceback (most recent call last):
  File ""/env/export/cns_n02_proj/proj21/q_seq_lab/Angelina/M2/SOIL/Genetic_Variability/VCF/MapVCF2NewGenome-main/Test/CheckMappingVCF.v1.0.py"", line 202, in <module>
    open_map = OpenFile(args.map, ""map"", ""1"")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/env/export/cns_n02_proj/proj21/q_seq_lab/Angelina/M2/SOIL/Genetic_Variability/VCF/MapVCF2NewGenome-main/Test/CheckMappingVCF.v1.0.py"", line 38, in __init__
    self.readLinesMap(self.file)
  File ""/env/export/cns_n02_proj/proj21/q_seq_lab/Angelina/M2/SOIL/Genetic_Variability/VCF/MapVCF2NewGenome-main/Test/CheckMappingVCF.v1.0.py"", line 72, in readLinesMap
    if ((int(self.start1) > 0 and int(Variables.sequences1[self.contig1]) >= int(self.end1)) and
                                      ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
KeyError: 'CAE02294'
",angi-bvg,https://github.com/KrisChristensen/MapVCF2NewGenome/issues/2,KrisChristensen++MapVCF2NewGenome.csv
I_kwDOFeq_N854dSQi,Empty old2new.positions.txt file. ,OPEN,2023-12-01T14:03:12Z,2023-12-01T14:45:19Z,,"Hi, I get an empty file during certain runs. Do you have an explanation?

I don't understand why the ""old2new.positions.txt"" file is empty (bad_run), when all the previous steps produce no errors.
I know that the codes are working, because I get results on one of my data (good_run).

I am attaching the files here.
[good_run.zip](https://github.com/KrisChristensen/MapVCF2NewGenome/files/13527406/good_run.zip)
[bad_run.zip](https://github.com/KrisChristensen/MapVCF2NewGenome/files/13527408/bad_run.zip)

Thanks for your help.
",angi-bvg,https://github.com/KrisChristensen/MapVCF2NewGenome/issues/3,KrisChristensen++MapVCF2NewGenome.csv
MDU6SXNzdWU3MDY5NjkzNw==,Core Data documentation,CLOSED,2015-04-24T13:54:20Z,2015-10-24T03:22:10Z,2015-09-28T22:20:41Z,"Hi guys, your framework look promising and very clear! I would like to ask extend Core data support documentation. Especially what I'm interesting in is: how to get some keys from JSON in init section to link with existing objects in CD and not to create new one?  
",SPopenko,https://github.com/loganwright/Genome/issues/2,loganwright++Genome.csv
MDU6SXNzdWUxMDgzNzM3MjA=,Simple Customizable Logging,CLOSED,2015-09-25T17:35:44Z,2015-09-25T18:19:54Z,2015-09-25T18:19:54Z,"Possibilities

```
var logOutput: ((ErrorType) -> Void)? = print
```

Or, an array:

```
var logOutput: [(ErrorType) -> Void)] = [print]
```
",loganwright,https://github.com/loganwright/Genome/issues/6,loganwright++Genome.csv
MDU6SXNzdWUxMDg0ODk3NTQ=,Logging Documentation,CLOSED,2015-09-26T19:39:48Z,2015-09-26T23:15:43Z,2015-09-26T23:15:43Z,"Show quick demo how to hook into loggers.
",loganwright,https://github.com/loganwright/Genome/issues/8,loganwright++Genome.csv
MDU6SXNzdWUxMDg1NzQ3Nzg=,Genome and Realm can be used together ?,CLOSED,2015-09-28T01:40:47Z,2015-09-28T22:21:26Z,2015-09-28T22:21:26Z,"Genome and Realm can be used together ?
",arden,https://github.com/loganwright/Genome/issues/10,loganwright++Genome.csv
MDU6SXNzdWUxMDg1NzUxMzA=,source directory is missing.,CLOSED,2015-09-28T01:42:59Z,2015-09-28T01:56:41Z,2015-09-28T01:55:39Z,"source directory is missing.
",arden,https://github.com/loganwright/Genome/issues/11,loganwright++Genome.csv
MDU6SXNzdWUxMTAzMzc5MjU=,tvOS support,CLOSED,2015-10-07T23:14:00Z,2015-10-23T13:21:43Z,2015-10-23T13:21:43Z,"`import Genome` currently results in the following build error on Xcode 7.1 beta 3:

```
module file was created for incompatible target x86_64-apple-ios8.0: [...]/Carthage/Build/iOS/Genome.framework/Modules/Genome.swiftmodule/x86_64.swiftmodule
```

It would be great to see this project support tvOS like Alamofire and Decodable have!
",iliaskarim,https://github.com/loganwright/Genome/issues/15,loganwright++Genome.csv
MDU6SXNzdWUxMTE5MTIyNjI=,Map.swift:53:26: Use of undeclared type 'NSNull',CLOSED,2015-10-16T21:12:45Z,2015-10-19T05:34:51Z,2015-10-18T22:51:38Z,"I opened the playground folder in Xcode 7.0.1 and got the following error:
Genome/Genome.playground/Sources/Map.swift:53:26: Use of undeclared type NSNull'
",jplasser,https://github.com/loganwright/Genome/issues/20,loganwright++Genome.csv
MDU6SXNzdWUxMTc4Nzg3MDU=,Int64 unexpected value mapping error,CLOSED,2015-11-19T18:38:03Z,2016-02-15T10:48:57Z,2016-01-16T17:18:18Z,"Could you describe how to use Genome with Int64 type? I'm getting error while trying to map:

> ""UnexpectedValue(""Found: 42 ofType: __NSCFNumber Expected: Int64 KeyPath: id TargetType: Int64"")\n""

Here is sample:

``` swift
let string = ""{ \""id\"": 42 }""
let data = string.dataUsingEncoding(NSUTF8StringEncoding)
let json = try? NSJSONSerialization.JSONObjectWithData(data!, options: .AllowFragments)

struct Sample: BasicMappable {
    private(set) var id: Int64 = 0
    mutating func sequence(map: Map) throws {
        try id <~> map[""id""]
    }
}

do {
    let sample = try Sample.mappedInstance(json as! JSON)
    print(sample.id)
} catch {
    print(error)
}
```
",max-potapov,https://github.com/loganwright/Genome/issues/25,loganwright++Genome.csv
MDU6SXNzdWUxMjI2NDg2Njk=,Ambiguous reference to member 'transformFromJson' when using Optional property,CLOSED,2015-12-17T02:42:08Z,2015-12-17T20:24:09Z,2015-12-17T20:24:09Z,"I have an optional property that I'm trying to transform

```
init(map: Map) throws {
    try logo = <~?map[""logo""].transformFromJson(urlFromString)
}
```

It works great with non-optional properties, I'm guessing it can't decide which version of the generic transformFromJson method to use.
",NinoScript,https://github.com/loganwright/Genome/issues/28,loganwright++Genome.csv
MDU6SXNzdWUxMjUyOTU5ODY=,Swift Package Manager,CLOSED,2016-01-07T00:33:48Z,2016-09-13T16:33:36Z,2016-09-13T16:33:36Z,"Support for Swift Package Manager stripping Foundation Requirements
",loganwright,https://github.com/loganwright/Genome/issues/30,loganwright++Genome.csv
MDU6SXNzdWUxMjY3NTI1Njk=,null value under KeyPath,CLOSED,2016-01-14T21:31:59Z,2016-01-19T03:43:20Z,2016-01-19T03:42:49Z,"Hi,
Awesome library! I'm trying to figure out how to handle a case when a given field may contain null value. Right now I receive

``` swift
UnexpectedInputType(""Unexpectedly found nil input.  KeyPath: .KeyPath(Date2) Expected: String"")
```

which is quite understandable given it contains `null` value.
How should I approach it?
",kamil-tomaszewski,https://github.com/loganwright/Genome/issues/33,loganwright++Genome.csv
MDU6SXNzdWUxMjcyNTk0MjQ=,transformToJson to NSNull,CLOSED,2016-01-18T16:15:42Z,2016-01-19T16:09:58Z,2016-01-19T16:09:58Z,"``` Swift
// Genome 1.0
try self.note ~> map[""note""]
  .transformToJson {
    $0 ?? NSNull()
  }
```

``` Swift
// Genome 2.0
try self.note ~> map[""note""]
  .transformToJson { (value: String?) -> String in
    if let text = value {
      return text
    }
    return ""\(NSNull())""
  }
```

In Genome 1.0, I can `transformToJson` from nil to NSNull by first code block
but In Genome 2.0, I have to change the transform code to second block which does not actually return NSNull as I want but a String

does there have some way to do the function like before?
",wanewang,https://github.com/loganwright/Genome/issues/36,loganwright++Genome.csv
MDU6SXNzdWUxMjgyMTU0Nzc=,jsonRepresentation can not cast to AnyObject,CLOSED,2016-01-22T18:31:39Z,2016-09-13T16:31:51Z,2016-09-13T16:31:51Z,"In v1.0.8
I can do this directly(obj is a class object confirm to BasicMappable)

``` Swift
  var basic = [String: AnyObject]()
  basic[""obj""] = obj.jsonRepresentation()
```

But in v2, it won't work and I can't even cast to AnyObject

``` Swift
if let dict = try obj.jsonRepresentation() as? AnyObject {
  basic[""obj""] = dict
}
```

I'm using Alamofire to do a POST which take Dictionary<String, AnyObject> as parameter and assemble to string automatically, does there a way to do things like before?
",wanewang,https://github.com/loganwright/Genome/issues/39,loganwright++Genome.csv
MDU6SXNzdWUxMjk5Njg2NjM=,Core Data example in readme,CLOSED,2016-01-30T10:05:51Z,2016-01-30T15:04:08Z,2016-01-30T15:04:08Z,"I've tried to play with Genome 2.0 and CoreData example and faced with complier error:

> error: declarations from extensions cannot be overridden yet

Here is example without CoreData stack to reduce code size.

```
public class NSManagedObjectContextStub {}
public class NSManagedObjectObjectStub {}

extension NSManagedObjectContextStub: Context {}

extension NSManagedObjectObjectStub: MappableBase {
    public class var entityName: String {
        return ""\(self)""
    }

    public func sequence(map: Map) throws {
        fatalError(""Sequence must be overwritten"")
    }

    public class func newInstance(json: Json, context: Context) throws -> Self {
        return try newInstance(json, context: context, type: self)
    }

    public class func newInstance<T: NSManagedObjectObjectStub>(json: Json, context: Context, type: T.Type) throws -> T {
        let context = context as! NSManagedObjectContextStub
        let new = NSManagedObjectObjectStub() as! T
        let map = Map(json: json, context: context)
        try new.sequence(map)
        return new
    }
}

class Person: NSManagedObjectObjectStub {
    override func sequence(map: Map) throws {
        // error: declarations from extensions cannot be overridden yet
    }
}
```
",max-potapov,https://github.com/loganwright/Genome/issues/41,loganwright++Genome.csv
MDU6SXNzdWUxMzI1NDY3Mzk=,Create a method for converting null strings to empty strings on map.,OPEN,2016-02-09T21:52:19Z,2016-02-09T21:53:38Z,,"Instead of doing something like

```
extension String {
    static func fromJson(json: Json) -> String {
        return json.stringValue ?? """"
    }
}
func sequence(map: Map) throws {
    try someValue <~ map[""someValue""].transformFromJson(String.fromJson)
}
```

Add a method like: `<~ map[""someValue""].emptyStringTransform()`
",Benuuu,https://github.com/loganwright/Genome/issues/44,loganwright++Genome.csv
MDU6SXNzdWUxMzI3Njk5MDg=,Problems running playground,CLOSED,2016-02-10T17:46:12Z,2016-02-11T12:03:48Z,2016-02-11T12:02:30Z,"Hi,

I'm having some troubles trying to run playground. I need to drag `Genome.xcodeproj` inside of _Genome.playground > Sources_ folder because if I don't do it, it has problems finding `MappableObject` and other requirements in playground.

Do you know if I'm doing something wrong? I usually don't use playgrounds, so maybe it's a problem of mine...
",patoroco,https://github.com/loganwright/Genome/issues/50,loganwright++Genome.csv
MDU6SXNzdWUxNTM4NzA0NTM=,Swift-3 branch indefinite dictionary initializer,CLOSED,2016-05-09T21:08:33Z,2016-05-10T06:17:04Z,2016-05-10T06:17:04Z,"https://github.com/LoganWright/Genome/blob/lw/swift-3/Sources/GenomeJson/Genome%2BJson.swift#L51
",loganwright,https://github.com/loganwright/Genome/issues/59,loganwright++Genome.csv
MDU6SXNzdWUxNTM5NDQ2MzE=,Can't build with Carthage,CLOSED,2016-05-10T07:54:53Z,2016-09-13T16:33:52Z,2016-09-13T16:33:52Z,"I tried building Genome 3.0.0 with Carthage, but I couldn't build with error 'Dependency ""Genome"" has no shared framework schemes for any of the platforms: iOS'.
",rizumita,https://github.com/loganwright/Genome/issues/60,loganwright++Genome.csv
MDU6SXNzdWUxNTU0MDAzMjM=,Error: method 'newInstance(_:context:)' in non-final class 'ChecklistItem' must return `Self` to conform to protocol 'JsonConvertibleType',CLOSED,2016-05-18T01:49:46Z,2016-08-22T19:38:23Z,2016-08-22T19:38:23Z,"I'm getting this error using Carthage install: github ""LoganWright/Genome"" ""2.0.4""

Here is the source code

```
class ChecklistItem: MappableObject {

    var title: String
    var checked: Bool

    init(title: String, checked: Bool) {
        self.title = title
        self.checked = checked
    }

    convenience init(title: String) {
        self.init(title: title, checked: false)
    }

    required init(map: Map) throws {
        self.title = try map.extract(""title"")
        self.checked = try map.extract(""checked"")
    }

    func sequence(map: Map) throws {
        try title ~> map[""title""];
        try checked ~> map[""checked""];
    }

}

extension ChecklistItem: Equatable { }
func == (lhs: ChecklistItem, rhs: ChecklistItem) -> Bool {
    return lhs.checked == rhs.checked && lhs.title == rhs.title
}
```
",jefferythomas,https://github.com/loganwright/Genome/issues/62,loganwright++Genome.csv
MDU6SXNzdWUxNjQxMTAxNTk=,'String' is not convertible to 'KeyType',CLOSED,2016-07-06T15:52:35Z,2016-07-07T07:22:41Z,2016-07-07T07:22:41Z,"Hello,

first of all: great library. I just moved from another lib to Genome, and I find it much more transparent and efficient.

My problem: I want to save a `UIImage`, using this code in the `sequence` function:

```
        try image <~> map[""image""]
            .transformFromJson {
                let stringData = $0
                let image = UIImage.fromBase64(stringData)
                return UIImage(data: imageData)
        }
            .transformToJson {
                let image: UIImage = $0
                let stringData = image.toBase64()
                return stringData
        }
```

However, this does not compile, as the error ""'String' is not convertible to 'KeyType'"" is thrown. What goes wrong, and how to fix it?

Thank a lot in advance!
- Hardy
",,https://github.com/loganwright/Genome/issues/63,loganwright++Genome.csv
MDU6SXNzdWUxNjQyNTAzMjQ=,Problem with restoring data,CLOSED,2016-07-07T07:55:46Z,2016-09-13T16:31:17Z,2016-09-13T16:31:17Z,"I have a custom data structure, with DM_ModelRoot as root item. Writing to a JSON string is working fine:

```
let map = Map()
var settableRoot: DM_ModelRoot? = self.modelRoot

try settableRoot ~> map[""modelRoot""]

print(settableRoot)

var jsonString = map.toJson.serialize()
```

However, when trying to restore the JSON string, there is an error `UnableToMap(.KeyPath(modelRoot), Genome.SequenceError.FoundNil(""Key: .KeyPath(identifier) TargetType: String""))`:

```
var settableRoot: DM_ModelRoot?

let json = try Json.deserialize(jsonString)

let map = Map(json: json)

try settableRoot <~ map[""modelRoot""]
```

What am I doing wrong? 

Note: DM_ModelRoot is setup with init(...) and sequence(...) properly, the JSON string is created correctly.

BTW: It would be helpful to have examples for correctly reading and writing JSON from and into custom objects on the documentation page ;-)
",,https://github.com/loganwright/Genome/issues/64,loganwright++Genome.csv
MDU6SXNzdWUxNzU5Nzc4NDI=,Swift 3 / Xcode 8 / Carthage: usable version available soon?,CLOSED,2016-09-09T10:28:33Z,2016-09-14T07:51:43Z,2016-09-14T01:34:50Z,"Are there plans to have a working version of this very nice project soon that can be used with Swift 3 and be checkout out via Carthage?

I had a look at #58 but current state doesn't even contain a Xcode project. The Swift 3 branch over at [PureJsonSerializer](https://github.com/gfx/Swift-PureJsonSerializer/pull/17) also seems very outdated.

Would be cool to have and working Swift 3 version soon. It's the one thing holding me back from upgrading to Xcode 8.
",t-unit,https://github.com/loganwright/Genome/issues/65,loganwright++Genome.csv
MDU6SXNzdWUxNzg5OTI5MTU=,Node alternative to Json.deserialize(string) and Json.serialize(style)?,CLOSED,2016-09-23T23:19:01Z,2016-09-28T23:20:28Z,2016-09-26T19:56:41Z,"Hi!
Yesterday I serialized and deserialized strings to and from JSON directly with PureJsonSerializer like this:

`Json.deserialize(rawString)`
and 
`Json.serialize(aStyle)`

but know I'm a little but confused as to how to do it with Node. Could you give us some insight on this please? 

Thanks!
",diegomontoyas,https://github.com/loganwright/Genome/issues/71,loganwright++Genome.csv
MDU6SXNzdWUxODE0MTYxMzc=,Swift 3: Date unconditionallyBridgeFromObjectiveC exception,CLOSED,2016-10-06T13:34:00Z,2021-04-10T11:24:09Z,2016-11-07T23:40:20Z,"I am using Genome to parse server response to CoreData entity. Exception is thrown when non-optional Date field is parsed:
 **libswiftFoundation.dylib`static Foundation.Date._unconditionallyBridgeFromObjectiveC (Swift.Optional<__ObjC.NSDate>) -> Foundation.Date:**

```
extension BaseNote {
    @NSManaged var date: Date
    @NSManaged var text: String?
}

override func sequence(_ map: Map) throws {
//...
    try date <~> map[""date""]
        .transformFromNode {
            return Date(timeIntervalSince1970: $0)
        }
        .transformToNode { return $0.timeIntervalSince1970 }
}
```

Note that the problem disappears if I use NSDate in NSManagedObject subclass or make the field optional (Date?). It worked fine before migration to Swift 3.

Please correct me if I'm doing it wrong.
",alexburtnik,https://github.com/loganwright/Genome/issues/72,loganwright++Genome.csv
MDU6SXNzdWUxODU2MDYzOTE=,version 3.1.0 not work in Carthage,CLOSED,2016-10-27T08:39:29Z,2016-11-10T07:05:23Z,2016-11-09T20:36:34Z,"I'm trying Genome with Carthage, but when running `carthage update` it won't download `Packages`  folder content. Node, PathIndexable and Polymorphic is missing in project, which caused built failed.

I'm now running with specific version
`github ""LoganWright/Genome"" == 3.0.3`
It worked.

might be submodule issue?
",wanewang,https://github.com/loganwright/Genome/issues/75,loganwright++Genome.csv
MDU6SXNzdWUxODU3NTM4MzM=,Missing sections in README.md,OPEN,2016-10-27T19:05:46Z,2017-04-03T15:49:41Z,,"The README has a **Table Of Contents** with links to two sections that don't exist.

One is about Alamofire:
https://github.com/LoganWright/Genome#alamofire

And the other about Logging:
https://github.com/LoganWright/Genome#logging
",NinoScript,https://github.com/loganwright/Genome/issues/76,loganwright++Genome.csv
MDU6SXNzdWUxODg4OTk1MjY=,Dealing with optional variables (basic types and enum),OPEN,2016-11-12T08:05:13Z,2016-11-14T15:50:31Z,,"I am learning how to use Genome, and so far I am impressed with the flexibility offered by Genome.   

1.  Is it possible to declare optional variables (both basic type and enum) that will not be mapped to JSON at all if they are nil? 
2. An extension to this question is how do I specify the transformToNode and transformFromNode functions for these optional variables?
3. I am trying to extend Date class, making it NodeRepresentable and NodeConvertible. (See code below). Would this implementation be able to handle when _date_ is nil during serialization (my intention is to skip saving _date_ data if _date_ is nil) and when the JSON data is absent during deserialization (my intention is to leave the _date_ variable uninitialized)?

```swift
extension Date: NodeRepresentable {
    public func makeNode(context: Context = EmptyNode) throws -> Node {
        return .string(self.ISO8601String())
    }
}

extension Date: NodeConvertible {
    public init(node: Node, in context: Context) throws {
        guard let string = node.string else {
            throw NodeError.unableToConvert(node: node, expected: ""\(String.self)"")
        }
        guard let date = Date.dateFromISO8601String(string: string) else {
            throw NodeError.unableToConvert(node: node, expected: ""Date is stored in ISO8601 format"")
        }
        self = date
    }
}
```

Example class definition:
```swift
enum FooType: Int8 {
    case typeA
    case typeB
}

class Bar: BasicMappable {
    var foo: FooType?
    var date: Date?
    var name: String?
    
    required init() {
    }
    
    func sequence(map: Map) throws {
        try foo <~> map[""foo""]
        try date <~> map[""date""]
        try name <~> map[""name""]
    }
}
```
",jimmyti,https://github.com/loganwright/Genome/issues/81,loganwright++Genome.csv
MDU6SXNzdWUxOTY4OTg4NDI=,Include map key in error message,OPEN,2016-12-21T10:34:59Z,2017-01-04T23:03:05Z,,"I remember that 2.0 has key information in error message right?
like if `let id:String = map[""id""]`, but `map[""id""]` is nil, 
the message will have the key `id` in it.
It would be better for debugging with the key information.
",wanewang,https://github.com/loganwright/Genome/issues/82,loganwright++Genome.csv
MDU6SXNzdWUyMTM4MDE4Njc=,Update Podspec,OPEN,2017-03-13T15:24:25Z,2017-03-13T15:24:25Z,,"Latest version when adding with cocoapods is Installing Genome (3.0.2). Not latest (3.1.1)
",waltermvp,https://github.com/loganwright/Genome/issues/83,loganwright++Genome.csv
MDU6SXNzdWUyMTQ4OTMzOTQ=,Updated CoreData Example,OPEN,2017-03-17T02:47:36Z,2017-03-17T03:01:05Z,,"I'm not sure exactly how to use Genome with core Data. Am I missing something here? How do they get initialized?

How do I fetch or init it?

```swift
public class Todo: ManagedObject {
    
    init(map: Map, context: Context) throws {
        try checked ~> map[""checked""]
        try id ~> map[""id""]
        try text ~> map[""text""]
    }

    public override func sequence(_ map: Map) throws {
        try checked ~> map[""checked""]
        try id ~> map[""id""]
        try text ~> map[""text""]
    }
       
}
```",waltermvp,https://github.com/loganwright/Genome/issues/84,loganwright++Genome.csv
MDU6SXNzdWUyMTgyMTc4MTE=,Core Data initialization,OPEN,2017-03-30T14:32:59Z,2017-04-03T16:46:41Z,,"Can you provide us how to use Genome for core data?
Which protocol/class we have to use? 

According to your Readme: NSMappableManagedObject is not avaiable.

",lumo2707,https://github.com/loganwright/Genome/issues/86,loganwright++Genome.csv
MDU6SXNzdWUyMjA3NTM4MjQ=,Add copyright,OPEN,2017-04-10T20:00:51Z,2017-04-10T20:00:51Z,,"Hi,
Could you please add a copyright statement to the license?
Thank you!",sakma,https://github.com/loganwright/Genome/issues/87,loganwright++Genome.csv
MDU6SXNzdWUyMjc3MjE4NjA=,sub-map node not change when mapping,OPEN,2017-05-10T15:35:08Z,2017-05-10T15:35:08Z,,"I would like to have a sub-map when mapping so I don't have to type the path repeatedly
e.x. json is
```
[
    ""test"": ""abc"",
    ""sub"": [
        ""int"": 9,
        ""string"": ""8""
    ]
]
```
and my mapping function is
```
try mainString <~> map[""test""]
let subMap = map[""sub""]
try subInt <~> subMap[""int""]
try subString <~> subMap[""string""]
```
but when I do `let subMap = map[""sub""]`
the subMap.node is still original node since subscript only change result
```
// file Map.swift line 102
public subscript(keys: [PathIndex]) -> Map {
    lastPath = keys
    result = node[keys]
    return self
}
```
should it also change `node` to `node[keys]`?",wanewang,https://github.com/loganwright/Genome/issues/93,loganwright++Genome.csv
MDU6SXNzdWUyNTk1NjMxOTI=,Swift 4 ,OPEN,2017-09-21T16:50:41Z,2017-10-01T01:40:06Z,,"Yes, we have a new way to work with JSON in swift-4, but project which use Genome could really make use of an update. Do you plan to update it? 
Seems easy: https://www.dropbox.com/s/l2gmoepbxvhfku7/Screenshot%202017-09-21%2019.51.12.png?dl=0
P.S: I see the updates brunch, but it seems like it's abandoned :) ",lonkly,https://github.com/loganwright/Genome/issues/98,loganwright++Genome.csv
MDU6SXNzdWUyNjI5ODUzODE=,User Defaults,CLOSED,2017-10-05T02:16:10Z,2017-10-05T15:49:10Z,2017-10-05T15:49:10Z,"I am attempting to set a Genome.Node.array value to user defaults. Is this even possible via Genome? I have looked into extending Genome and Node to conform to NSCoding but have not found a unsuccessful as they are not classes. 

Suggestions? Thank you.",cnbecom,https://github.com/loganwright/Genome/issues/99,loganwright++Genome.csv
MDU6SXNzdWUyODU3ODA5NTU=,Abandoned Repo,OPEN,2018-01-03T19:11:38Z,2018-01-03T19:11:38Z,,,btelintelo,https://github.com/loganwright/Genome/issues/100,loganwright++Genome.csv
MDU6SXNzdWU0MTM5NjA5NTE=,How to use Genome in Swift 4.2,OPEN,2019-02-25T07:02:24Z,2019-02-25T07:02:50Z,,,RajAggrawal0507,https://github.com/loganwright/Genome/issues/102,loganwright++Genome.csv
I_kwDOHCIM185GFBsQ,Research data: collection,CLOSED,2022-03-21T17:36:50Z,2022-04-22T10:07:25Z,2022-04-22T10:07:25Z,"Assess OpenAlex. Some questions to consider:
  * What is its coverage?
  * What is its timeliness?
  * How will we collect it?
  * How will we store it?
  * How will we find AI / genomics papers in it?",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/2,nestauk++ai_genomics.csv
I_kwDOHCIM185GFCcB,Research data: institutions,CLOSED,2022-03-21T17:39:45Z,2022-04-22T10:07:25Z,2022-04-22T10:07:25Z,"Assess options to enrich OpenAlex data with institutional / geographical information from GRID
* This will involve fuzzy matching OpenAlex institutions with e.g. GRID institutions",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/3,nestauk++ai_genomics.csv
I_kwDOHCIM185GFC9J,Research data: knowledge flow,CLOSED,2022-03-21T17:41:38Z,2022-04-22T10:07:17Z,2022-04-22T10:07:17Z,"Explore options to enrich OpenAlex with semantic scholar data including:
* Citations
* High impact citations
* Fields of study
As part of this, request access to free + fast API (it takes some time for them to confirm access)

JMG will be working on this w/c 4 April",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/4,nestauk++ai_genomics.csv
I_kwDOHCIM185GFDt-,Research data: Influence / impact / controversy,CLOSED,2022-03-21T17:44:28Z,2022-10-03T09:12:20Z,2022-10-03T09:12:20Z,"Assess options to enrich publication data with information about influence / impact / controversy
* Citation data already addressed in #4
* Assess options to enrich publication data with information about social media debates from Crossref Event data:
  * What information is available directly from CRED API?
* Assess how controversial a paper is using scite.ai
  * This will involve some costs. Estimate costs under different scenarios

JMG will be working on this w/c 28 March",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/5,nestauk++ai_genomics.csv
I_kwDOHCIM185GFEPZ,Research data: open source,CLOSED,2022-03-21T17:46:32Z,2022-04-22T10:07:06Z,2022-04-22T10:07:06Z,"* Find AI + genomics papers in Papers with Code
* Get their GitHub repos
* Are there any benchmark data related to AI + genomics?",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/6,nestauk++ai_genomics.csv
I_kwDOHCIM185GHr9g,Funding data: sources,CLOSED,2022-03-22T08:14:00Z,2022-10-03T09:12:34Z,2022-10-03T09:12:34Z,"Options include:
* Gateway to Research
* NIH
* EU (through Cordis)
* Wellcome Trust",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/7,nestauk++ai_genomics.csv
I_kwDOHCIM185GHsyy,Patents: Sources,CLOSED,2022-03-22T08:17:27Z,2022-04-22T10:06:57Z,2022-04-22T10:06:57Z,"Some options:
* Patent lens
* Global Patent Index
* USPTO using the open AI patent dataset (https://www.uspto.gov/ip-policy/economic-research/research-datasets/artificial-intelligence-patent-dataset)
* Google Patent dataset @Big query
* Check with Karlis / Discovery Hub about their plans to analyse patent data",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/8,nestauk++ai_genomics.csv
I_kwDOHCIM185GHtBg,CrunchBase: assess,OPEN,2022-03-22T08:18:26Z,2022-03-31T12:12:39Z,,"* Assess CrunchBase dataset: 
  * What are the right crunchbase tags
  * How long are the descriptions of CB companies
  * ...",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/9,nestauk++ai_genomics.csv
I_kwDOHCIM185GHtVE,Research data: MeSH terms,CLOSED,2022-03-22T08:19:46Z,2022-04-22T10:13:50Z,2022-04-22T10:13:50Z,"* Check pipeline to enrich abstract data with MeSH terms: what is required to run this, how long does it take?",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/10,nestauk++ai_genomics.csv
I_kwDOHCIM185GHtpS,Research data: analysis,CLOSED,2022-03-22T08:21:06Z,2022-08-22T05:43:38Z,2022-08-22T05:43:38Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/11,nestauk++ai_genomics.csv
I_kwDOHCIM185GHt_T,Patents: analysis,CLOSED,2022-03-22T08:22:22Z,2022-04-22T10:06:58Z,2022-04-22T10:06:58Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/12,nestauk++ai_genomics.csv
I_kwDOHCIM185GHuCP,Funding data: Analysis,OPEN,2022-03-22T08:22:32Z,2022-03-22T08:22:32Z,,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/13,nestauk++ai_genomics.csv
I_kwDOHCIM185GHuFS,CrunchBase: analysis,CLOSED,2022-03-22T08:22:44Z,2022-08-03T08:43:07Z,2022-08-03T08:43:07Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/14,nestauk++ai_genomics.csv
I_kwDOHCIM185GYYBE,Template,CLOSED,2022-03-25T13:27:27Z,2022-04-12T13:42:25Z,2022-04-12T13:42:25Z,Create template,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/15,nestauk++ai_genomics.csv
I_kwDOHCIM185IQAss,Write technical spec,CLOSED,2022-04-22T10:16:31Z,2022-06-28T11:05:34Z,2022-06-28T11:05:34Z,"Structure:

1. Context
  * Project goals
  * Research questions
3. Methodology
  * High level methodological narrative
  * Data sources: collection and enrichment
  * Analysis
4. Outputs
5. Timelines and budget",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/22,nestauk++ai_genomics.csv
I_kwDOHCIM185LpoZW,Start work on getting full collection of OpenAlex,CLOSED,2022-06-13T10:05:33Z,2022-08-05T09:05:17Z,2022-08-05T09:05:16Z,,india-kerle,https://github.com/nestauk/ai_genomics/issues/23,nestauk++ai_genomics.csv
I_kwDOHCIM185Lpoj8,Read material related to AI and genomics,OPEN,2022-06-13T10:06:05Z,2022-08-12T08:44:27Z,,"Per our kick off call on 13-06, Ada folks to send over literature reviews for our review.

We currently have access to Conor Griffin's [Biotechnology & AI review paper](https://docs.google.com/document/d/1f4xbwmXYlm-VyNfG87FNTfTBLFOedtPZdZBDGIvDINo/edit) ",india-kerle,https://github.com/nestauk/ai_genomics/issues/24,nestauk++ai_genomics.csv
I_kwDOHCIM185Lpp9D,Identify data collection tasks that can be ongoing between 06/20 - 07/01,CLOSED,2022-06-13T10:10:43Z,2022-08-05T08:43:29Z,2022-08-05T08:43:28Z,as @Jack-Vines and I will be on OJO. ,india-kerle,https://github.com/nestauk/ai_genomics/issues/25,nestauk++ai_genomics.csv
I_kwDOHCIM185LpqgP,Have conversation with Luca and Sam on the AI map,CLOSED,2022-06-13T10:12:34Z,2022-08-05T08:39:27Z,2022-08-05T08:39:27Z,second convo - spotlight tool on thursday morning,india-kerle,https://github.com/nestauk/ai_genomics/issues/26,nestauk++ai_genomics.csv
I_kwDOHCIM185Lp-D-,Update crunchbase data,CLOSED,2022-06-13T11:23:38Z,2022-07-18T16:13:37Z,2022-07-18T16:13:37Z,,india-kerle,https://github.com/nestauk/ai_genomics/issues/27,nestauk++ai_genomics.csv
I_kwDOHCIM185Lp-XB,prototype patent data pipeline,CLOSED,2022-06-13T11:24:40Z,2022-08-05T08:44:32Z,2022-08-05T08:44:32Z,can we do one for like 5 patents? filter patent ids in genomics - precondition for issue #25 ,india-kerle,https://github.com/nestauk/ai_genomics/issues/28,nestauk++ai_genomics.csv
I_kwDOHCIM185Lp-uB,Look for categories that map against AI genomics,CLOSED,2022-06-13T11:25:59Z,2022-07-18T16:10:02Z,2022-07-18T16:10:01Z,"in patent, openalex, crunchbase taxonomies ",india-kerle,https://github.com/nestauk/ai_genomics/issues/29,nestauk++ai_genomics.csv
I_kwDOHCIM185Lp_JZ,outstanding admin from call this morning,CLOSED,2022-06-13T11:27:36Z,2022-08-05T08:46:58Z,2022-08-05T08:46:58Z,"- [x] Get lit reviews
- [x] Get timelines for other project streams
- [ ] Get lists of terms they are using to define AI / Genomics
- [ ] Get research questions / assumptions
- [ ] Schedule dates for epic meetings
- [x] Create project slack and invite them (do we want to do this? :-))
- [ ] Agree if there is an advisory board / its composition / how we engage with it
- [ ] Decide comm strategy: where does the report live and how do we share it with others",india-kerle,https://github.com/nestauk/ai_genomics/issues/30,nestauk++ai_genomics.csv
I_kwDOHCIM185LqBAk,Go over AI map codebase,CLOSED,2022-06-13T11:34:25Z,2022-08-05T08:39:40Z,2022-08-05T08:39:40Z,,india-kerle,https://github.com/nestauk/ai_genomics/issues/31,nestauk++ai_genomics.csv
I_kwDOHCIM185LqYQi,Epic 1 Goals,CLOSED,2022-06-13T12:58:51Z,2022-08-09T14:47:55Z,2022-08-09T14:47:55Z,"- [x] Collect data relevant across research data, patent data, business data and funding data
- [x] Conduct EDA and DQA across the relevant datasets
- [ ] Improve collective domain knowledge and subject expertise of AI and genomics
- [ ] Solidify agile ways of working
- [x] Define whether this data collection work should sit within this project repo or beyond it",india-kerle,https://github.com/nestauk/ai_genomics/issues/32,nestauk++ai_genomics.csv
I_kwDOHCIM185LrBTB,Have a conversation with Liz about how she found AI companies for the AI map project,CLOSED,2022-06-13T14:55:20Z,2022-08-05T08:39:34Z,2022-08-05T08:39:34Z,,india-kerle,https://github.com/nestauk/ai_genomics/issues/33,nestauk++ai_genomics.csv
I_kwDOHCIM185L_Eme,Explore impact of definitions on OpenAlex results,CLOSED,2022-06-17T09:51:55Z,2022-07-12T07:42:45Z,2022-07-12T07:42:45Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/34,nestauk++ai_genomics.csv
I_kwDOHCIM185L_EvI,Develop algorithm to re-create OpenAlex abstracts from inverted indices,CLOSED,2022-06-17T09:52:28Z,2022-07-12T07:42:44Z,2022-07-12T07:42:44Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/35,nestauk++ai_genomics.csv
I_kwDOHCIM185L_E1r,Get Semantic Scholar API key,CLOSED,2022-06-17T09:52:52Z,2022-08-10T09:07:21Z,2022-08-10T09:07:21Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/36,nestauk++ai_genomics.csv
I_kwDOHCIM185L_FCz,Prototype strategy to enrich OpenAlex data with institutional information from Global Research Identifier (GRID),CLOSED,2022-06-17T09:53:42Z,2022-07-18T16:12:52Z,2022-07-18T16:12:51Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/37,nestauk++ai_genomics.csv
I_kwDOHCIM185NEahT,Develop strategy to get genomics classification codes,CLOSED,2022-07-04T10:58:46Z,2022-08-05T08:47:34Z,2022-08-05T08:47:34Z,,india-kerle,https://github.com/nestauk/ai_genomics/issues/39,nestauk++ai_genomics.csv
I_kwDOHCIM185NhuKs,sample ai genomics patent abstracts,CLOSED,2022-07-11T13:06:14Z,2022-08-05T08:40:05Z,2022-08-05T08:40:05Z,"based off of ai genomics patent ids, develop methodology to sample abstracts, subject to google bigquery limits.",india-kerle,https://github.com/nestauk/ai_genomics/issues/41,nestauk++ai_genomics.csv
I_kwDOHCIM185NhuYX,evaluate ai genomics patent ids,CLOSED,2022-07-11T13:06:57Z,2022-08-05T08:40:54Z,2022-08-05T08:40:54Z,"Sanity check patent ids that should be ai and genomics.

- [x] pick N .csvs and check patent ids are relevant to ai AND genomics (perhaps pulling a sample of titles to review or even searching patent ids in Google's front end: https://patents.google.com/ for more complete info) 
- [x] Investigate distribution of cpc/ipc codes in ""golden-shine-355915.genomics.*"" - are all codes represented to at least some extent? ",india-kerle,https://github.com/nestauk/ai_genomics/issues/42,nestauk++ai_genomics.csv
I_kwDOHCIM185Nhvjl,identify and pull relevant fields for ai genomics patent ids,CLOSED,2022-07-11T13:10:52Z,2022-08-05T08:41:32Z,2022-08-05T08:41:32Z,"Using ai genomics patent ids, query BigQuery for additional fields that will be relevant for analysis.

- [x] interrogate patent data schema to identify fields most relevant for analysis
- [ ] interrogate how complete those fields are on a sample of ai genomics patent ids",india-kerle,https://github.com/nestauk/ai_genomics/issues/43,nestauk++ai_genomics.csv
I_kwDOHCIM185Nlf65,EDA of OpenAlex data,CLOSED,2022-07-12T07:46:50Z,2022-08-25T04:38:09Z,2022-08-25T04:38:09Z,"* Update getters to fetch data from S3 without storing locally
* Generate summary by year including
  * Number of papers
  * Top institutions
  * Top countries
  * Top concepts
* Update getters to fetch data and query for specific concepts, store locally (necessary for genomics)
* Explore impact of different definitions on corpus
  * E.g. number of papers in intersection of AI and genomics
  * Coverage of papers in literature review",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/44,nestauk++ai_genomics.csv
I_kwDOHCIM185N6JP5,"Check reliability of results under different ""AI thresholds""",CLOSED,2022-07-17T12:46:09Z,2022-10-03T09:13:17Z,2022-10-03T09:13:17Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/47,nestauk++ai_genomics.csv
I_kwDOHCIM185Pea2p,Chat with Luca and Sam about wikipedia topics,CLOSED,2022-08-09T14:49:06Z,2022-09-26T05:07:24Z,2022-09-26T05:07:24Z,from Luca: yesterday I forgot that Sam is on leave until Friday so I guess we could discuss wikipedia topics for this project next week (15-08),india-kerle,https://github.com/nestauk/ai_genomics/issues/53,nestauk++ai_genomics.csv
I_kwDOHCIM185PebSw,Dataset joining based on entity matching,OPEN,2022-08-09T14:50:25Z,2022-08-30T10:16:28Z,,"As part of the project deliverable, we are also interested in joining datasets to analyse. We would then need to:

- [ ] Identify common entities across all the datasets we've collected so far i.e. a company name
- [ ] We will need to identify a strategy to join datasets based on an entities i.e. use jacchammer? Are there other entity matching algorithms we want to explore? What preprocessing will we need to do to join? 
- [ ] Justify why we need joins - is this to help with analysis? Which analysis? Is this to expand data collection?
- [ ] Develop an evaluation strategy for joining i.e. develop a ground truth dataset of the same entity across different datasets - report on how many entities do we in/correctly join etc.? How do these metrics change subject to different entity matching algorithms and preprocessing methods?     

[from @Juan-Mateos] Potential joins:
- orgs from patent data w/ crunchbase
- expanding list of crunchbase companies based on patent join

Other ideas:
- join named patent inventors w/ OpenAlex's publisher or display_name",india-kerle,https://github.com/nestauk/ai_genomics/issues/54,nestauk++ai_genomics.csv
I_kwDOHCIM185PecFX,Clean up repo,CLOSED,2022-08-09T14:52:45Z,2022-08-10T09:03:26Z,2022-08-10T09:03:26Z,"- [x] close issues that have been completed
- [x] delete remote branches that have been merged",india-kerle,https://github.com/nestauk/ai_genomics/issues/55,nestauk++ai_genomics.csv
I_kwDOHCIM185PiRHe,Establish collaborative report writing process,CLOSED,2022-08-10T10:04:16Z,2022-09-26T05:08:00Z,2022-09-26T05:07:49Z,"Based on feedback from the first epic, we need to clarify a collaborative report writing process. We will also need to schedule an onboarding call to make sure everyone knows how we will be collaborating.

- [ ] Establish report writing process
- [ ] Set up call with team to onboard us
- [ ] implement process ",india-kerle,https://github.com/nestauk/ai_genomics/issues/56,nestauk++ai_genomics.csv
I_kwDOHCIM185Pi9DG,Current snapshot (present and past two years) of the funding and research environment ,OPEN,2022-08-10T12:38:27Z,2022-08-30T10:16:20Z,,,india-kerle,https://github.com/nestauk/ai_genomics/issues/57,nestauk++ai_genomics.csv
I_kwDOHCIM185Pi9EZ,Identify topics industry is becoming more interested in and abandoning,OPEN,2022-08-10T12:38:32Z,2022-08-30T10:16:14Z,,,india-kerle,https://github.com/nestauk/ai_genomics/issues/58,nestauk++ai_genomics.csv
I_kwDOHCIM185Pi9GD,Identify topics academics are becoming more interested in and abandoning,OPEN,2022-08-10T12:38:37Z,2022-08-30T10:16:05Z,,,india-kerle,https://github.com/nestauk/ai_genomics/issues/59,nestauk++ai_genomics.csv
I_kwDOHCIM185PscuG,Identify topics strategy,OPEN,2022-08-12T10:50:30Z,2022-08-30T10:15:56Z,,"start simple:
- simplest approach: just use crunchbase topics or openalex topics 

Think about approaches:
- what about using pygram? n-grams in abstracts and look at trends -- what's emerging? (second simplest)
- spectar (sp?) embeddings of documents (just pull vectors based on DOI from semantic scholar) and just cluster those guys  (stretch-ish goal)
- topic modelling
- some ""minimum"" threshold of topics - can we at least find these types of categories from the literature review?

crunchbase --> do we do this in a qualitative way? 
 ",india-kerle,https://github.com/nestauk/ai_genomics/issues/60,nestauk++ai_genomics.csv
I_kwDOHCIM185Psf03,entity extraction: DBPedia vs. OpenAlex Tagger,CLOSED,2022-08-12T11:03:00Z,2022-09-26T05:19:14Z,2022-09-26T05:19:14Z,,india-kerle,https://github.com/nestauk/ai_genomics/issues/61,nestauk++ai_genomics.csv
I_kwDOHCIM185PsgHj,Update openalex pipeline to work with extra data,OPEN,2022-08-12T11:04:22Z,2022-08-12T13:01:05Z,,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/62,nestauk++ai_genomics.csv
I_kwDOHCIM185PsgH4,Mop up data collection,CLOSED,2022-08-12T11:04:24Z,2022-08-25T04:38:09Z,2022-08-25T04:38:09Z,- OpenAlex EDA PR,india-kerle,https://github.com/nestauk/ai_genomics/issues/63,nestauk++ai_genomics.csv
I_kwDOHCIM185PsgVq,Expert engagement strategy,CLOSED,2022-08-12T11:05:19Z,2022-09-01T13:54:07Z,2022-09-01T13:54:07Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/64,nestauk++ai_genomics.csv
I_kwDOHCIM185Psgk4,baseline metrics,CLOSED,2022-08-12T11:06:25Z,2022-10-03T09:10:47Z,2022-10-03T09:10:47Z,"As a baseline, we could use the same metrics karlis used in innovation sweet spots - we could also use his code from the repo to calculate i.e.: 

- #of orgs founded per topic (pending topic definition: i.e. crunchbase category, cluster etc.)
- #of funding rounds per topic per topic (pending topic definition: i.e. crunchbase category, cluster etc.)
- Overall funding per topic

We could also join on patent assignees and look at the number of patents per topic. 

After that, we could also calculate more complex indicators around emergence metrics, look into [novelpy](https://novelpy.readthedocs.io/en/latest/)  ",india-kerle,https://github.com/nestauk/ai_genomics/issues/65,nestauk++ai_genomics.csv
I_kwDOHCIM185QOVXB,GtR definitions file does not run,CLOSED,2022-08-22T07:16:45Z,2022-08-31T02:16:12Z,2022-08-31T02:16:12Z,"The format of the `/inputs/gtr/gtr_projects-projects.json` file on S3 has changed, meaning `gtr_definintions.py` does not run ",Jack-0-0,https://github.com/nestauk/ai_genomics/issues/68,nestauk++ai_genomics.csv
I_kwDOHCIM185QOeJx,Getters for the processed AI and Genomics data,CLOSED,2022-08-22T07:49:19Z,2022-08-31T06:12:10Z,2022-08-31T06:12:10Z,"The project is missing getters for the processed crunchbase, gtr, openalex, patent data.",Jack-0-0,https://github.com/nestauk/ai_genomics/issues/70,nestauk++ai_genomics.csv
I_kwDOHCIM185QU9-0,Add informative root README,OPEN,2022-08-23T10:03:32Z,2022-08-23T10:03:32Z,,"Things to add:

- [ ] Project name
- [ ] Description of project
- [ ] A nice picture
- [ ] Outline of the components of the project
- [ ] Guide for where to find parts of the pipeline and analysis
- [ ] Link to other resource (e.g. slide deck of results)
- [ ] Installation instructions
- [ ] Who to reach out to with questions",georgerichardson,https://github.com/nestauk/ai_genomics/issues/72,nestauk++ai_genomics.csv
I_kwDOHCIM185QU_Lf,Write expert definition validation and engagement proposal,CLOSED,2022-08-23T10:07:15Z,2022-10-03T08:34:04Z,2022-10-03T08:33:52Z,"Write to Harry with proposal. Should include:

- Plan for initial briefing
- Outline of definition validation exercise and how it will be completed
- Plan for follow up discussion meeting
- Invitation for further engagement",georgerichardson,https://github.com/nestauk/ai_genomics/issues/73,nestauk++ai_genomics.csv
I_kwDOHCIM185QWCok,Identify influential researchers,CLOSED,2022-08-23T13:23:32Z,2022-08-26T05:25:51Z,2022-08-26T05:25:51Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/74,nestauk++ai_genomics.csv
I_kwDOHCIM185QZi-Y,There are some patents with titles in languages other than english,CLOSED,2022-08-24T05:12:37Z,2022-09-26T05:06:54Z,2022-09-26T05:06:54Z,"e.g 
3270,EP-3622524-A1,Variantenklassierer auf der basis von tiefen neuronalen netzen
2868,KR-20160057792-A,SiNG-PCRseq       
8397,RU-2746477-C2,       ,""FIELD: biotechnology. ",Jack-0-0,https://github.com/nestauk/ai_genomics/issues/75,nestauk++ai_genomics.csv
I_kwDOHCIM185QZkHs,Generate text samples from each of the datasets for tagging,CLOSED,2022-08-24T05:19:48Z,2022-09-01T09:12:36Z,2022-09-01T09:12:36Z,"Generate text samples from patents, openalex, gtr and crunchbase for tagging",Jack-0-0,https://github.com/nestauk/ai_genomics/issues/76,nestauk++ai_genomics.csv
I_kwDOHCIM185QbRNs,Add full list of CPC/IPC codes per patent publication_number,CLOSED,2022-08-24T11:57:09Z,2022-09-26T05:02:37Z,2022-09-26T05:02:37Z,"Should be able to fetch full list of CPC/IPC codes per patent publication number with this query:

`with ai_genomics_ids as (select distinct publication_number from golden-shine-355915.genomics.ai_genomics) select publication_number, cpc, ipc from patents-public-data.patents.publications`

Will need to then concatenate to current patents dataset in s3. 

From George: Can we roll this into a current PR?
",india-kerle,https://github.com/nestauk/ai_genomics/issues/77,nestauk++ai_genomics.csv
I_kwDOHCIM185QkZw1,Identify AI Genomics people/organisations,CLOSED,2022-08-26T04:11:51Z,2022-08-31T11:17:39Z,2022-08-31T11:17:39Z,"Produce a list of AI Genomics people/organisations. From Harry's email:

We are looking for a mixture of people, but especially those who:

* Understand and work on genomic science, and particularly the application of AI to genomics;
* Understand and have insight into the larger trends in private and public funding for genomics research and R&D; or
* Understand and have insight into the larger trends in terms of how government, industry and other actors are thinking about researching and deploying genomic science.
 

I was wondering if it would be possible to use the data so far generated by the scientometric analysis to help identify relevant figures.

Specifically, is it possible to look through the data

* To identify people who match or look likely to match the above criteria; and/or
* to identify companies, research centres and other entities that may be home of people worth including on the longlist?",Jack-0-0,https://github.com/nestauk/ai_genomics/issues/80,nestauk++ai_genomics.csv
I_kwDOHCIM185QzCoK,Identify tags in patent data,CLOSED,2022-08-30T10:42:15Z,2022-09-26T04:57:40Z,2022-09-26T04:57:40Z,related to #60,india-kerle,https://github.com/nestauk/ai_genomics/issues/81,nestauk++ai_genomics.csv
I_kwDOHCIM185Q3M5J,GtR data: gtr_definitions.py searches for terms inside a string,OPEN,2022-08-31T02:13:05Z,2022-09-01T13:38:14Z,,"`gtr_definitions.py` searches for terms inside a string. This could cause issues by matching partial words.
Can be fixed by searching for matches against a list of terms within the string instead.",Jack-0-0,https://github.com/nestauk/ai_genomics/issues/83,nestauk++ai_genomics.csv
I_kwDOHCIM185Q5SAZ,GtR data: check pipeline as to why bird song related projects are being included,OPEN,2022-08-31T11:24:00Z,2022-09-01T13:38:20Z,,"In the GtR data, I noticed the person with the most publications works on using machine learning on bird/animal sounds (I used to work with him!), not AI and genomics.",Jack-0-0,https://github.com/nestauk/ai_genomics/issues/85,nestauk++ai_genomics.csv
I_kwDOHCIM185Q-BOa,Analyse OpenAlex concept trends,OPEN,2022-09-01T08:10:43Z,2022-10-04T12:16:00Z,,"- [ ] Bar chart of most frequent topics in last 2 years
- [ ] Investigate increase and decrease in topic popularity by calculating absolute change in topic frequency and looking at highest positive and negative growth areas between last complete year and 5 years previous. Could also look at line chart plotting rise and fall of those topics.",georgerichardson,https://github.com/nestauk/ai_genomics/issues/86,nestauk++ai_genomics.csv
I_kwDOHCIM185Q_imX,Investigate use of a different language detection model,OPEN,2022-09-01T13:15:31Z,2022-09-01T13:15:31Z,,Currently download a fasttext model using `wget`. Perhaps there are alternatives from e.g. huggingface?,georgerichardson,https://github.com/nestauk/ai_genomics/issues/87,nestauk++ai_genomics.csv
I_kwDOHCIM185Q_99u,Qualitative topic trend analysis of Crunchbase data,OPEN,2022-09-01T14:30:56Z,2022-09-26T04:57:13Z,,"There are relatively few companies from CB. We will do a qualitative analysis of what has become popular/declined and what the current state is.

This could include some manual grouping and basic quantitative analysis.",georgerichardson,https://github.com/nestauk/ai_genomics/issues/89,nestauk++ai_genomics.csv
I_kwDOHCIM185RANb-,Generate samples for expert validation,OPEN,2022-09-01T15:11:34Z,2022-09-26T07:35:43Z,,"- [x] Generate samples of abstracts
  - [x] >50 abstracts from publications and patents
  - [x] CPC patent codes used in definition augmentated with descriptions and taxonomy context
  - [x] IPC patent codes used in definition augmented with descriptions and taxonomy context
  - [x] OpenAlex concepts used in definition augmented with descriptions and taxonomy context
- [x] Create a method for splitting the samples according to the number of contributors
- [x] Analyse highest frequency codes to further filter if there are fewer contributors",georgerichardson,https://github.com/nestauk/ai_genomics/issues/90,nestauk++ai_genomics.csv
I_kwDOHCIM185RANuU,GtR DBpedia - current status and trends,OPEN,2022-09-01T15:12:14Z,2022-10-03T08:22:23Z,,"Analysis of GtR trends using DBpedia tags:
- [ ] Analysis of top topics in most recent 2 full years
- [ ] Analysis of changes in top, bottom and emerging topics over last 5 years

This issue is for producing a pipeline to create the aggregate data and functions for plotting. This will later be combined with the equivalent charts from the other datasets.",georgerichardson,https://github.com/nestauk/ai_genomics/issues/91,nestauk++ai_genomics.csv
I_kwDOHCIM185RFf52,Modify current script to generate relevant IPC/CPC codes WITH descriptions ,CLOSED,2022-09-02T16:22:41Z,2022-09-26T04:55:37Z,2022-09-26T04:55:37Z,Modify current script (`ai_genomics/pipeline/patent_data/get_ai_genomics_patents.py`) to get ai/genomics related cpc/ipc codes AND their respective descriptions. Useful for identifying bad codes and for generating our expert validation dataset. ,india-kerle,https://github.com/nestauk/ai_genomics/issues/92,nestauk++ai_genomics.csv
I_kwDOHCIM185RPe_D,Generate openalex sample tables,OPEN,2022-09-06T09:48:14Z,2022-09-26T04:49:40Z,,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/94,nestauk++ai_genomics.csv
I_kwDOHCIM185RUE3i,Generate baseline data,CLOSED,2022-09-07T07:26:56Z,2022-09-26T04:50:17Z,2022-09-26T04:50:17Z,get a sample of AI patents and a sample of Genomics patents to create datasets we can compare i.e. relative growth in etc. ,india-kerle,https://github.com/nestauk/ai_genomics/issues/95,nestauk++ai_genomics.csv
I_kwDOHCIM185RhJgz,Update CrunchBase getters including baseline data,CLOSED,2022-09-09T10:43:32Z,2022-09-23T09:40:52Z,2022-09-23T09:13:22Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/96,nestauk++ai_genomics.csv
I_kwDOHCIM185RhJlC,Update GtR getters including baseline data,CLOSED,2022-09-09T10:43:49Z,2022-09-23T09:40:57Z,2022-09-23T09:13:09Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/97,nestauk++ai_genomics.csv
I_kwDOHCIM185Rv_ex,add post processing functions to bad entities from DBpedia,CLOSED,2022-09-13T14:18:20Z,2022-10-03T09:10:29Z,2022-10-03T09:10:29Z,as some entities do not have classes associated to them. We will need to also post process bad entities,india-kerle,https://github.com/nestauk/ai_genomics/issues/102,nestauk++ai_genomics.csv
I_kwDOHCIM185Rv_hZ,generate look ups from data to be tagged with DBpedia,CLOSED,2022-09-13T14:18:26Z,2022-10-03T09:10:16Z,2022-10-03T09:10:16Z,"where look ups for entity extraction should be in the form:

{id: text}

in s3",india-kerle,https://github.com/nestauk/ai_genomics/issues/103,nestauk++ai_genomics.csv
I_kwDOHCIM185SSXXB,Diversity and concentration of topics within communities or institutions,OPEN,2022-09-21T08:33:51Z,2022-10-04T12:09:56Z,,from ada: Low priority,india-kerle,https://github.com/nestauk/ai_genomics/issues/106,nestauk++ai_genomics.csv
I_kwDOHCIM185SSXZN,Level of interdisciplinarity of papers and patents,OPEN,2022-09-21T08:33:58Z,2022-10-04T12:09:50Z,,from ada: Low priority,india-kerle,https://github.com/nestauk/ai_genomics/issues/107,nestauk++ai_genomics.csv
I_kwDOHCIM185SSXeh,Comparing trends across sectors/datasets with DBpedia tags,OPEN,2022-09-21T08:34:13Z,2022-10-04T12:09:43Z,,from ada: Medium priority,india-kerle,https://github.com/nestauk/ai_genomics/issues/108,nestauk++ai_genomics.csv
I_kwDOHCIM185SSXiV,discernible changes in the kinds of actors involved in genomics practice,OPEN,2022-09-21T08:34:25Z,2022-10-04T12:09:33Z,,from ada: Medium priority,india-kerle,https://github.com/nestauk/ai_genomics/issues/109,nestauk++ai_genomics.csv
I_kwDOHCIM185SSXko,where funding is becoming available and drying up,OPEN,2022-09-21T08:34:32Z,2022-10-04T12:09:27Z,,from ada: Medium priority,india-kerle,https://github.com/nestauk/ai_genomics/issues/110,nestauk++ai_genomics.csv
I_kwDOHCIM185SSXoH,Discernible changes in the kinds of actors and entities involved in funding genomics,OPEN,2022-09-21T08:34:43Z,2022-10-04T12:09:22Z,,from ada: Medium/high priority,india-kerle,https://github.com/nestauk/ai_genomics/issues/111,nestauk++ai_genomics.csv
I_kwDOHCIM185SSXst,Novelty of topic combinations that are brought together in new research,OPEN,2022-09-21T08:34:56Z,2022-10-04T12:08:49Z,,from ada: High priority,india-kerle,https://github.com/nestauk/ai_genomics/issues/112,nestauk++ai_genomics.csv
I_kwDOHCIM185SdQX9,Evolution of topics in GtR research,CLOSED,2022-09-23T07:27:19Z,2022-10-04T11:22:21Z,2022-10-04T11:22:21Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/113,nestauk++ai_genomics.csv
I_kwDOHCIM185SlIFR,OpenAlex DBpedia - current status and trends,OPEN,2022-09-26T05:52:35Z,2022-10-03T08:22:43Z,,"Analysis of OpenAlex trends using DBpedia tags:
- [ ] Analysis of top topics in most recent 2 full years
- [ ] Analysis of changes in top, bottom and emerging topics over last 5 years

This issue is for producing a pipeline to create the aggregate data and functions for plotting. This will later be combined with the equivalent charts from the other datasets.",georgerichardson,https://github.com/nestauk/ai_genomics/issues/115,nestauk++ai_genomics.csv
I_kwDOHCIM185SlIit,Patent DBpedia - current status and trends,OPEN,2022-09-26T05:54:52Z,2022-10-04T12:08:35Z,,"Analysis of patent trends using DBpedia tags:
- [ ] Analysis of top topics in most recent 2 full years
- [ ] Analysis of changes in top, bottom and emerging topics over last 5 years

This issue is for producing a pipeline to create the aggregate data and functions for plotting. This will later be combined with the equivalent charts from the other datasets.",georgerichardson,https://github.com/nestauk/ai_genomics/issues/116,nestauk++ai_genomics.csv
I_kwDOHCIM185SsSxK,Postprocessing pipeline for DBpedia tags,CLOSED,2022-09-27T08:28:45Z,2022-09-28T13:31:56Z,2022-09-28T13:31:55Z,"Create a post-processing pipeline for the DBpedia tags extracted from the four datasets:

- [ ] Remove place names, people etc. using NER
- [ ] Output data in a useable format",georgerichardson,https://github.com/nestauk/ai_genomics/issues/117,nestauk++ai_genomics.csv
I_kwDOHCIM185Ss5Gp,Add domain-expert generated concepts to OpenAlex pipeline,OPEN,2022-09-27T10:18:25Z,2022-09-27T10:18:26Z,,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/118,nestauk++ai_genomics.csv
I_kwDOHCIM185Ss5Qk,Add domain-expert generated keywords to semantic search pipelines,OPEN,2022-09-27T10:18:57Z,2022-09-27T10:18:57Z,,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/119,nestauk++ai_genomics.csv
I_kwDOHCIM185THBNu,Agree consistent chart style,CLOSED,2022-10-03T08:31:34Z,2022-10-27T11:33:41Z,2022-10-27T11:33:41Z,"- [ ] Font
- [ ] Palette
- [ ] Sizing
- [ ] Other style elements",georgerichardson,https://github.com/nestauk/ai_genomics/issues/122,nestauk++ai_genomics.csv
I_kwDOHCIM185THBnZ,Prepare round 2 expert validation documents,OPEN,2022-10-03T08:32:56Z,2022-10-03T08:33:01Z,,,georgerichardson,https://github.com/nestauk/ai_genomics/issues/123,nestauk++ai_genomics.csv
I_kwDOHCIM185THuJo,Geographic analysis of trends using DBpedia tags,OPEN,2022-10-03T10:56:00Z,2022-10-03T10:56:00Z,,"- [ ] Specialisation
- [ ] Composition of top fields by country",georgerichardson,https://github.com/nestauk/ai_genomics/issues/124,nestauk++ai_genomics.csv
I_kwDOHCIM185TN9An,Influence analysis using topic modelling,CLOSED,2022-10-04T12:07:07Z,2022-10-11T10:43:17Z,2022-10-11T10:43:17Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/126,nestauk++ai_genomics.csv
I_kwDOHCIM185TN-go,evolution analysis of DBpedia tag clusters ,OPEN,2022-10-04T12:12:03Z,2022-10-04T12:14:23Z,,for firebreak week: Apply PEC-like libraries approach to track the growth and decline of DBpedia tag clusters across datasets. ,india-kerle,https://github.com/nestauk/ai_genomics/issues/127,nestauk++ai_genomics.csv
I_kwDOHCIM185TtbIM,Refactor code for influence analysis so it works outside OpenAlex,CLOSED,2022-10-11T10:42:30Z,2022-10-18T10:55:02Z,2022-10-18T10:55:02Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/129,nestauk++ai_genomics.csv
I_kwDOHCIM185TvC4I,Triage novelty metrics,OPEN,2022-10-11T15:28:46Z,2022-10-11T15:28:46Z,,"Potential strategies
- [ ] Measure topic entropy ( a proxy for interdisciplinarity)
- [ ] Cluster docs yearly and calculate individual doc eccentricity in relation to clusters e.g. how difficult is it to classify in one of them
- [ ] Use measures in [pysciscy](https://github.com/SciSciCollective/pyscisci)
- [ ] Use [novelpy](https://novelpy.readthedocs.io/)",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/131,nestauk++ai_genomics.csv
I_kwDOHCIM185TzDS2,filter openalex entities look up,OPEN,2022-10-12T09:36:14Z,2022-10-12T15:48:29Z,,it takes too long to filter the look up in scripts - write a script to sample and filter ai genomics and save outputs to s3,india-kerle,https://github.com/nestauk/ai_genomics/issues/133,nestauk++ai_genomics.csv
I_kwDOHCIM185TzQ1_,Update data collection working product with updated numbers/figures and expert validation exercise,OPEN,2022-10-12T10:15:33Z,2022-10-12T10:15:40Z,,"Updated data collection part of the [hackmd working product](https://hackmd.io/cBINz49-SRGRzHQHx9YxUw) with new numbers/figures after a final rerun of the pipeline given updates from the expert validation exercise. 

Also add expert validation section to data collection part of the working product. ",india-kerle,https://github.com/nestauk/ai_genomics/issues/134,nestauk++ai_genomics.csv
I_kwDOHCIM185T1JvT,extract entities from both the title and the abstracts ,OPEN,2022-10-12T15:48:55Z,2022-10-12T15:49:29Z,,,india-kerle,https://github.com/nestauk/ai_genomics/issues/135,nestauk++ai_genomics.csv
I_kwDOHCIM185UNIA0,Utility functions/pipeline to embed and cluster DBpedia tags,CLOSED,2022-10-18T07:40:57Z,2022-10-22T15:06:41Z,2022-10-22T15:06:41Z,,georgerichardson,https://github.com/nestauk/ai_genomics/issues/137,nestauk++ai_genomics.csv
I_kwDOHCIM185UPtkG,Integrated emergence analysis,CLOSED,2022-10-18T15:11:58Z,2022-11-06T12:30:21Z,2022-11-06T12:30:21Z,"* Read entities
* Count doc activity by entity
* Calculate recency / significance by data source (papers, patents, grants)
* Cluster entities based on their document summaries
* Analyse their evolution of activity",Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/139,nestauk++ai_genomics.csv
I_kwDOHCIM185UclmS,Fix broken patent entity getter,CLOSED,2022-10-20T14:56:25Z,2022-10-22T08:29:42Z,2022-10-22T08:29:42Z,,georgerichardson,https://github.com/nestauk/ai_genomics/issues/140,nestauk++ai_genomics.csv
I_kwDOHCIM185U9ZHq,Script for embedding descriptions with SPECTER,CLOSED,2022-10-27T10:08:22Z,2022-10-28T11:29:38Z,2022-10-28T11:29:38Z,,georgerichardson,https://github.com/nestauk/ai_genomics/issues/144,nestauk++ai_genomics.csv
I_kwDOHCIM185VEc2W,Update GtR definition,OPEN,2022-10-28T12:59:50Z,2022-10-28T12:59:50Z,,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/150,nestauk++ai_genomics.csv
I_kwDOHCIM185VKqsY,Document SPECTER clusters,CLOSED,2022-10-30T15:30:30Z,2022-11-02T21:41:17Z,2022-11-02T21:41:17Z,,georgerichardson,https://github.com/nestauk/ai_genomics/issues/151,nestauk++ai_genomics.csv
I_kwDOHCIM185VT3Dt,Break down entity lookups for OpenAlex,CLOSED,2022-11-01T11:19:13Z,2022-11-02T08:43:38Z,2022-11-02T08:43:38Z,,georgerichardson,https://github.com/nestauk/ai_genomics/issues/154,nestauk++ai_genomics.csv
I_kwDOHCIM185VVJmA,Update influence analysis,CLOSED,2022-11-01T15:18:00Z,2023-01-03T15:24:43Z,2023-01-03T15:24:43Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/156,nestauk++ai_genomics.csv
I_kwDOHCIM185VZYln,Update entity clusters,OPEN,2022-11-02T08:39:04Z,2022-11-02T08:39:04Z,,- [ ] Run entity clustering pipeline on updated ai and genomics entities,georgerichardson,https://github.com/nestauk/ai_genomics/issues/158,nestauk++ai_genomics.csv
I_kwDOHCIM185VdpkT,Descriptive analysis charts,OPEN,2022-11-02T21:56:29Z,2022-11-02T21:56:29Z,,"Create charts for high level descriptive analysis:

- [ ] Number of AI, genomics and AI + genomics items by country in last 2 years
- [ ] Number of AI + genomics items over time
- [ ] Top publishers institutions in AI + genomics in the last 2 years 
- [ ] Top entities in AI + genomics and over time
- [ ] Tracking AI entities over time",georgerichardson,https://github.com/nestauk/ai_genomics/issues/161,nestauk++ai_genomics.csv
I_kwDOHCIM185VfStx,Entity distribution over clusters,CLOSED,2022-11-03T08:14:07Z,2022-11-03T16:41:47Z,2022-11-03T16:41:47Z,,georgerichardson,https://github.com/nestauk/ai_genomics/issues/162,nestauk++ai_genomics.csv
I_kwDOHCIM185VpnEI,Cluster analysis,OPEN,2022-11-05T10:58:50Z,2022-11-05T10:58:50Z,,"- [ ] Specialisation of institution types by cluster (publications)
- [ ] Specialisation of top institutions by cluster (publications)
- [ ] Specialisation of top institutions by cluster (patents)
- [ ] Specialisation of top clusters by country (patents + publications)",georgerichardson,https://github.com/nestauk/ai_genomics/issues/164,nestauk++ai_genomics.csv
I_kwDOHCIM185VrNKq,Updated emergence analysis,CLOSED,2022-11-06T12:31:58Z,2023-01-03T15:25:38Z,2023-01-03T15:25:38Z,,Juan-Mateos,https://github.com/nestauk/ai_genomics/issues/165,nestauk++ai_genomics.csv
I_kwDOHCIM185ajUat,Consolidate and filter topics,OPEN,2023-01-04T15:55:36Z,2023-01-04T15:55:36Z,,"- [ ] Remove Animals and Agriculture
- [ ] Collapse duplicate topics",georgerichardson,https://github.com/nestauk/ai_genomics/issues/169,nestauk++ai_genomics.csv
I_kwDOHCIM185ajkM2,Update doc cluster graphs,OPEN,2023-01-04T16:37:50Z,2023-01-04T16:37:50Z,,Update graphs to use new consolidated document clusters,georgerichardson,https://github.com/nestauk/ai_genomics/issues/171,nestauk++ai_genomics.csv
MDU6SXNzdWU0NjcwODY3NTA=,document missing,CLOSED,2019-07-11T20:17:42Z,2020-12-04T16:12:48Z,2020-12-04T16:12:48Z,"I get GitHub 404 for this link 
https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/master/docs/annotated.html
from this page 
https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/master/docs/README-SDK.md

I guess the generated HTML is not checked in?
",cschin,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/33,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0Njk3Mjc0NTU=,Path Missing CMakeLists.txt,CLOSED,2019-07-18T11:54:20Z,2020-03-27T07:51:36Z,2019-07-19T11:38:35Z,"I tried to install Claragenomics in ubuntu 18.04 using command cmake .. -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=install,but I'm getting this error
The source directory /home/vaibhavcurl/ClaraGenomicsAnalysis-master/3rdparty/bioparser
does not contain a CMakeLists.txt file.
The source directory

    /home/vaibhavcurl/ClaraGenomicsAnalysis-master/3rdparty/spdlog

  does not contain a CMakeLists.txt file.

",vaibhaw1994kumar,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/40,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0NzA0ODg3NDE=,Hitting graph size larger than allowed GPU limits,CLOSED,2019-07-19T18:55:00Z,2019-07-22T14:18:52Z,2019-07-22T14:18:52Z,Observed a graph overflowing the max edges count during a run. Reported in #44 by @SamStudio8,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/45,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0NzA3NjY5ODU=,Kernel Error:: Node count exceeded maximum nodes per window,CLOSED,2019-07-21T10:36:27Z,2019-08-06T10:56:15Z,2019-08-06T10:56:14Z,"Observed this error on my `stderr` while running `racon-gpu`, not sure if related to #45? It's [raised by the code here](https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/master/cudapoa/src/cudapoa_batch.cpp#L204).",SamStudio8,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/47,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0NzM4NzM3MjI=,Unable to clone,CLOSED,2019-07-29T06:32:09Z,2019-07-29T08:42:46Z,2019-07-29T08:31:31Z,"Hi, 
The clone command fails with access right error.
```
$ git clone --recursive git@github.com:clara-genomics/ClaraGenomicsAnalysis.git
Cloning into 'ClaraGenomicsAnalysis'...
The authenticity of host 'github.com (140.82.114.3)' can't be established.
RSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'github.com,140.82.114.3' (RSA) to the list of known hosts.
git@github.com: Permission denied (publickey).
fatal: Could not read from remote repository.

Please make sure you have the correct access rights
and the repository exists.
```
Any thought?",mahmoodn,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/53,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0NzM5MjY0NTI=,About singlebatch ,CLOSED,2019-07-29T08:46:01Z,2019-07-30T12:14:08Z,2019-07-30T12:14:08Z,"I went to `build/install/benchmarks/cudapoa/` and when I run `singlebatch`, I get the following output

```
$ ./singlebatch
2019-07-29 13:14:25
Running ./singlebatch
Run on (16 X 3600 MHz CPU s)
CPU Caches:
  L1 Data 32K (x8)
  L1 Instruction 64K (x8)
  L2 Unified 512K (x8)
  L3 Unified 8192K (x2)
Load Average: 0.33, 0.15, 0.16
***WARNING*** CPU scaling is enabled, the benchmark real time measurements may be noisy and will incur extra overhead.
------------------------------------------------------------------
Benchmark                        Time             CPU   Iterations
------------------------------------------------------------------
BM_SingleBatchTest/1          1594 ms         1593 ms            1
BM_SingleBatchTest/4          2429 ms         2427 ms            1
BM_SingleBatchTest/16         2687 ms         2685 ms            1
BM_SingleBatchTest/64         3231 ms         3228 ms            1
BM_SingleBatchTest/256        8233 ms         8225 ms            1
terminate called after throwing an instance of 'std::runtime_error'
  what():  GPU Error:: out of memory /home/mahmood/cactus/cl/ClaraGenomicsAnalysis/cudapoa/src/allocate_block.cpp 46
Aborted (core dumped)
```

I would like to test a specific batch size and not variable sizes. It seems that singlebatch is a binary file. Any idea for that?",mahmoodn,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/54,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0NzQ1NjkzODc=,Still about single batch,CLOSED,2019-07-30T12:57:07Z,2019-08-29T14:59:35Z,2019-08-29T14:59:35Z,"For my GPU analyses, I tried running single-batch with nv profiler. It seems that there are two kernels only where the dominant one is `generatePOAKernel`.  The other is `generateConsensusKernel` which is not important. So, this benchmark is not going to solve the problem and is only good for generating the graph. Am I right? I am not expert in this field and want to analyze some GPU things. I don't know if that graph generation is a big problem. 

A single run of batch=256, takes 
  Time = 8094 ms
  CPU = 8092 ms
  Iterations = 1
So, where is GPU in the results? ",mahmoodn,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/57,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODcwMTE2NzY=,`IndexGenerator` and `Matcher` unable to allocate memory on GPU when number of reads too large,CLOSED,2019-08-29T14:58:21Z,2019-09-19T20:41:37Z,2019-09-19T20:41:37Z,"When running overlaps with a FASTA/FASTQ that is too large (e.g >500MB) the following error is encountered:

```
terminate called after throwing an instance of 'claragenomics::device_memory_allocation_exception'
  what():  Could not allocate device memory!
```

This happens because on-device memory requirements of `IndexGenerator` and `Matcher` scale with size of the input reads.

The solution is to implement a ""chunked"" version of `IndexGenerator` and `Matcher`.",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/94,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODcwNDIwMjE=,create conda builds for C++ libraries and python modules,OPEN,2019-08-29T15:49:42Z,2020-04-09T15:31:46Z,,"1. Create conda recipes for C++ libs
2. Create conda recipes for pyclaragenomics
3. Host releases in conda channel",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/95,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODcxNTY0NTA=,revert CGA_CU_CHECK_ERR to abort on error,CLOSED,2019-08-29T20:17:39Z,2019-09-05T14:29:06Z,2019-09-05T14:29:06Z,"Revert the CGA_CU_CHECK_ERR functionality to abort on error for Release builds, and `assert(false)` and then abort for Debug builds.

Potentially add cudaDeviceSynchronize in debug builds to catch errors when they occur",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/96,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODczNTkzNDE=,`IndexGenerator` needs chunked implementation,CLOSED,2019-08-30T08:34:50Z,2019-08-30T23:28:00Z,2019-08-30T23:27:16Z,As solving part of #94 a low-memory (chunked) implementation of `InexGenerator` is required.,vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/98,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODc0NjE0NjY=,Add build dependencies to Conda for GPUCI builds,CLOSED,2019-08-30T12:38:14Z,2019-08-30T17:16:53Z,2019-08-30T17:16:53Z,"Some recent GPUCI failures have revealed that (eg [this one](https://gpuci.gpuopenanalytics.com/blue/organizations/jenkins/gpuCI-private%2Fclara-genomics-analysis%2Fprb%2Fclara-genomics-analysis-cpu-build/detail/clara-genomics-analysis-cpu-build/1457/pipeline)) have revealed that we are sensitive to what packages are installed on GPUCI VM/docker instances we are running.

Conda should be used as much as possible to allow our tests to run on a clean CI instance. This includes at a minimum:

1. Cmake
2. Flake",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/101,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODc3MDI4NzY=,Solve performance regression caused by chunked Index Generator,CLOSED,2019-08-30T23:31:01Z,2019-09-18T09:47:56Z,2019-09-18T09:47:56Z,#100 allows indexing of an arbitarily-large set of sequences but introduces a performance regression. This is caused because several sorted lists of SketchElements now need to be merged together. The merging is not being performed in an optimal way and can be improved by multithreading to run in ~log(N) time. There is also the possibility of performing this on GPU.,vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/103,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODc3MDMyMjk=,`Matcher` needs chunked implementation,CLOSED,2019-08-30T23:33:28Z,2019-10-29T16:49:00Z,2019-10-29T16:49:00Z,As solving part of #94 a low-memory (chunked) implementation of `Matcher` is required.,vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/104,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2ODQyOTQ=,Sample app for cuda aligner,CLOSED,2019-09-03T15:46:13Z,2019-10-28T12:59:11Z,2019-10-28T12:59:11Z,Write a sample application for cuda aligner,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/106,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2ODU5MTQ=,cuda aligner API to take in max available memory and max ref/query sizes,OPEN,2019-09-03T15:49:04Z,2021-01-26T16:52:25Z,,"1. each aligner batch to take in max memory and max ref/query sizes and determine how many how alignments can be performed in the batch.
2. provide api to check max alignments possible
3. actual max alignments may me larger based on inputs processed so far, and actual max can be determined by continually adding and checking return value of add alignment api call
 ",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/107,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTA3ODU=,Add python API for cuda aligner,CLOSED,2019-09-03T15:58:01Z,2019-10-28T13:10:33Z,2019-10-28T13:10:33Z,,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/108,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTE0NTQ=,Enable style check for cudamapper,CLOSED,2019-09-03T15:59:18Z,2019-10-28T12:57:36Z,2019-10-28T12:57:35Z,Would just require the CMakeLists.txt in cudamapper folder to have one more line as specified here https://gitlab-master.nvidia.com/genomics/GenomeWorks/blob/master/cudapoa/CMakeLists.txt#L67,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/109,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTIxMDA=,Acceleration improvements for Hirschberg,CLOSED,2019-09-03T16:00:30Z,2019-10-29T16:50:39Z,2019-10-29T16:50:39Z,,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/110,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTMwNDc=,Evaluate nvBowTie import into CGA,OPEN,2019-09-03T16:02:19Z,2019-09-03T16:02:19Z,,Import nvBowTie into ClaraGenomicsAnalysis SDK from NVBio repo,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/111,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTYzNjY=,Increase cudaaligner singlealignment sweep to 1 Mb,OPEN,2019-09-03T16:09:02Z,2019-09-10T21:01:06Z,,Update Myers + Hirschberg benchmark sweep to end at 1 Mb,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/112,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTcxNTg=,"Make SDK functions ""current device""-neutral",CLOSED,2019-09-03T16:10:33Z,2019-09-11T14:34:26Z,2019-09-11T14:34:26Z,"If we assume our users use CUDA also outside of our library, we should also ensure that our methods are ""current device""-neutral, i.e. that we reset the device (cudaSetDevice) at the end of each method to the value it had when it entered the method.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/113,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTc4ODg=,clang-format: fix member initializer formatting,CLOSED,2019-09-03T16:12:08Z,2019-10-29T11:58:52Z,2019-10-29T11:58:52Z,"clang-format formats the member initializer of a constructor as a single long line regardless of the length of this line.
For long lines clang-format should introduce line breaks in some sensible way.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/114,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODg2OTg2NDc=,Improve README for different various parts of the SDK,CLOSED,2019-09-03T16:13:42Z,2020-12-04T16:13:52Z,2020-12-04T16:13:52Z,"Currently READMEs are not setup in an easy to use manner. The following needs to be done - 
Proper README for each section (main, benchmarks, samples, APIs, tests)
Link all READMEs from main one to provide connected information from single location",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/115,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODkyMjk0MDY=,pycga setup.py should run from any folder,CLOSED,2019-09-04T15:20:45Z,2019-09-05T10:39:55Z,2019-09-05T10:39:55Z,Right now `setup.py` only runs from the `pyclaragenomics` folder. This should be runnable from any directory,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/118,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0ODk2NjQ5MTY=,Index should accept SketchElement implementation as tempalte parameter,CLOSED,2019-09-05T10:24:44Z,2019-09-13T14:57:42Z,2019-09-13T14:57:42Z,"Currently `Index` works with pointers to `SketchElement`, meaning we have to use `std::vector<std::unique_ptr<SketchElement>>` which is bad for performance and makes it hard to use that data on the GPU.
Change the implementation so that `Index` (or it's constructor) accepts one implementation of `SketchElement` and then work with `std::vector<SketchElementImpl>`",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/122,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTAyOTQ0NTU=,Shared objects not being detected by python when importing `claragenomics.bindings`,CLOSED,2019-09-06T12:14:01Z,2019-09-09T13:17:11Z,2019-09-09T13:17:11Z,"When installing pyclaragenomics with venv, the following error is happening when running samples/tests:


```
Traceback (most recent call last):
  File ""./sample_cudapoa"", line 18, in <module>
    from claragenomics.bindings import cudapoa
ImportError: liblogging.so: cannot open shared object file: No such file or directory
```


it seems that if `ClaraGenomicsAnalysis/pyclaragenomics/cga_build/install/lib/` is added to `LD_LIBRARY_PATH` this problem is resolved.

This error does not seem to occur when running in a Conda environment, but does in a venv (as reported by @mimaric ).",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/127,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTAzNDMxNjk=,genome_simulator slow on large genomes,OPEN,2019-09-06T13:58:33Z,2019-09-06T13:58:50Z,,"After `genome_simulator` prints out

```Simulating genome:
100%|| 120/120 [05:41<00:00,  1.76s/it]
Simulating reads:
100%|| 120/120 [06:54<00:00,  3.46s/it]
```

If running with a large genome (e.g 100MB @ 30x) there is a very long period where a single CPU is at 100% utilisation. This can probably be sped up through multiprocessing and/or other means.",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/128,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTMzMzIzMTU=,After PR #131 results of cudamapper are different,CLOSED,2019-09-13T13:41:28Z,2019-09-25T17:20:15Z,2019-09-25T17:20:15Z,"For a 10 megabases 30x coverage input cudamapper returns different results than before the merge of #131 
Please investigate and unittest to cover that case.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/133,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTMzNjM1NDE=,Do final steps of index generation in IndexGPU on GPU,CLOSED,2019-09-13T14:41:54Z,2019-12-04T15:13:28Z,2019-12-04T15:13:28Z,"As specified in PR #134 last part of building index in `IndexGPU`  (done in `details::index_gpu::build_index()`) is still done on the CPU and takes about half of the total time execution time of `IndexGPU` generation.

Look for a way to move it to the GPU",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/135,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTMzNjk0MTk=,SketchElementImpl::ReadidPositionDirection became new SketchElement,OPEN,2019-09-13T14:53:14Z,2019-12-09T09:19:29Z,,"`SketchElement`/`Minimizer` objects are not used anymore. `IndexGPU` internally relies on `SketchElementImpl::ReadidPositionDirection`. Its output consists of the content of `SketchElementImpl::ReadidPositionDirection` split into three separate arrays.

Look into ways to:
1) Change the interface of `Index` so that `SketchElementImpl::ReadidPositionDirection` does not have to be split into three arrays
2) Refactor the code to reflect the current state of not using `SketchElement` objects",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/136,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTMzNzA5ODE=,Improve exception handling in python bindings,OPEN,2019-09-13T14:56:08Z,2020-04-28T14:59:43Z,,"Currently error codes are simply converted to python RuntimeErrors, whereas it might be more appropriate to throw some of them as ValueErrors based on the type of error status",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/138,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTMzODQ2NTU=,Create Error class for python bindings,OPEN,2019-09-13T15:22:42Z,2020-05-04T22:03:22Z,,Wrap the C++ error enums into an error class that has a to `__str__` function and can be thrown from within the binding classes,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/139,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTM0MjMwNzc=,Move enums back to enum classes in C++ CGA,OPEN,2019-09-13T16:49:34Z,2019-09-13T16:49:34Z,,"Because of cython limitations, C++ enum classes had to be converted to enums for compatibility. However, there seem to be some workarounds in cython land to make up for that limitation. Worth investigating those WARs to avoid violating good C++ coding guidelines",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/140,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTQxMjgyODQ=,[cudaaligner] FormattedAlignment should include `|` and `x` symbols,CLOSED,2019-09-16T15:39:01Z,2019-12-02T13:27:52Z,2019-12-02T13:27:52Z,"`FormattedAlignment` in cudaaligner returns aligned strings in the following format:

```
ACCGTCA
ACGC--A
```

This would be preferable:

```
ACCGTCA
||xx  |
ACGC--A
```",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/141,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTQxNjM3NzU=,[cudaaligner] Add character set check to API,OPEN,2019-09-16T16:50:24Z,2021-01-26T16:53:20Z,,"The cudaaligner API only supports `ATCG` alphabet, but the API doesn't check for this in input strings right now, leading to undefined behavior.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/142,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTU4ODc1Mzc=,[cudapoa] combine benchmarks into single application,CLOSED,2019-09-19T15:52:50Z,2019-10-31T13:44:04Z,2019-10-31T13:44:04Z,Combine cudapoa benchmarks into a single application instead of two. google benchmarks provides a way to select which benchmarks to run based on filters,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/147,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTU4ODc4NTQ=,[cudaaligner] combine benchmarks into single application,CLOSED,2019-09-19T15:53:29Z,2019-11-04T19:04:16Z,2019-11-04T19:04:16Z,Use google bench filters instead to choose which set of benchmarks to run,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/148,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTYwMTUzNzQ=,Add CIGAR alignments to cudamapper using cudaaligner,CLOSED,2019-09-19T20:39:50Z,2020-03-06T23:46:07Z,2020-03-06T23:46:07Z,"* Add optional `cigar` attribute to `Overlap` objects.
* Add `-a` flag to cudamapper for the option of computing alignments
* Once overlapping is complete, alignments can be completed in batches using cudaaligner.
* If alignments are computed, they should be added to the `PAF` file (the relevant modification needs to be performed in the `print_paf` function).",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/150,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTY0ODA3NDg=,[tests] test_wrappers.py test fails without minimap2 and racon in env,CLOSED,2019-09-20T18:06:39Z,2020-12-04T16:14:45Z,2020-12-04T16:14:45Z,"the test_wrappers.py script always fails if minimap2 and racon are not present in the environment, and our documentation currently doesn't require those to be installed. we need to update documentation to take care of that.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/152,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTcyMDY3Njc=,Use pip to install pyclaragenomics instead of setup.py,CLOSED,2019-09-23T16:37:29Z,2019-11-11T14:14:22Z,2019-11-11T14:14:22Z,There are several benefits to using `pip` to install custom packages instead of running `setup.py` directly. A good summary can be found here - https://stackoverflow.com/questions/15724093/difference-between-python-setup-py-install-and-pip-install/15731459,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/153,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTg5NTY3MzE=,Graph representation in python and serialization methods,CLOSED,2019-09-26T15:22:52Z,2020-01-13T19:58:11Z,2020-01-13T19:58:11Z,"The python bindings are very helpful to perform alignments and consensus calls, but there currently isn't a good way to work with the resulting graph structures in python.  The structures are available in C++, but there are some nuances to them.  It would be nice if there were some examples (with documentation) of working with the resulting graphs in C++ and some bindings (or a new interface) to work with them in python as well.

It would also be helpful if there were a method that can be called after performing an alignment or consensus call that would serialize the graph (in DOT or some similar format) so it can be easily inspected / visualized after creation. ",jonn-smith,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/157,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU0OTk0NTgzNTM=,improve alignment error handling in kernel,OPEN,2019-09-27T13:50:12Z,2019-09-27T13:50:12Z,,"In CUDA aligner, some times valid inputs can lead to errors in processing e.g. when the hirschberg processing stack is full. We should have an error handling mechanism which reports when certain alignments could not be processed correctly so they can be reported back to the caller.


Specific case - cudaaligner/src/hirschberg_myers_gpu.cu has a `printf(ERROR: Stack full)` case.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/159,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MDA3NDI2NDk=,python build fails when Doxygen not present,CLOSED,2019-10-01T08:29:47Z,2019-10-01T14:56:57Z,2019-10-01T14:56:56Z,"When setup.py first runs `cmake` it is noted that:

```-- Could NOT find Doxygen (missing: DOXYGEN_EXECUTABLE)
-- Doxygen not found. Doc gen disabled.
```

but the subsequent `cmake --build ... docs install` call fails.",cjw85,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/162,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MDI1MDQxNjU=,[cudapoa]  Lost lines in MSA output,CLOSED,2019-10-04T08:33:17Z,2019-11-01T00:39:04Z,2019-11-01T00:39:04Z,"In the example `pyclaragenomics/samples/sample_cudapoa`, the maximum sequences per poa is specified as 100, though the outputs are only 99 long. Changing the maximum sequences to 50, results in outputs of length 49. In appears that it is the final input sequence that is lost.",cjw85,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/169,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MDI1MTE0MTA=,[cudapoa] Expose compile-time constants as parameters,CLOSED,2019-10-04T08:49:21Z,2020-04-10T21:03:10Z,2020-04-10T21:03:10Z,There are several constants defined in `cudapoa_kernels.cuh` which control various maximum sizes of graph properties. It would be useful to vary these at runtime.,cjw85,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/170,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MDI1MTQ4MzI=,[cudapoa] CudaPoaBatch.get_msa() incorrectly reports success on failure with large inputs,CLOSED,2019-10-04T08:56:26Z,2019-11-05T16:20:15Z,2019-11-05T16:20:15Z,"The results of at least the python binding can be unexpected when the maximum MSA width is surpassed (default 1024 from `cudapoa_kernels.cuh`). Ive observed the status be reported as 0 but the results be slightly mangled.

For example Ive input 70 sequences of ~660bases, the status is 0, and the lengths of the strings returned for the MSA are not equal (often the first being longer than the rest). Taking a one/a few bases away from the inputs gives MSA lines uniformly of length 1023.",cjw85,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/171,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MDI1MzkwMTE=,[cudamapper] Number of overlaps generated has dependency on `index_size`,OPEN,2019-10-04T09:47:18Z,2019-10-04T09:47:18Z,,"A regression appears to have been introduced whereby whatever `index_size` variable is set to affects the number of overlaps comptued. This results in very small differences between the number of overlaps detected prior and after read-level chunking. Example:

```wc -l res_*
   899904 res_new.out
   899973 res_old.out```
```

This is likely to be an off-by-one error at some point in the read-level chunking",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/172,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MDI5NTkzNDI=,Setting the cuda toolkit location with PyClaraGenomics,CLOSED,2019-10-05T12:49:13Z,2019-10-06T20:58:33Z,2019-10-06T20:58:33Z,"It would be useful to override the `CUDA_TOOLKIT_ROOT_DIR` when building the Python bindings. The patch below passes the environment variable `CUDA_TOOLKIT_ROOT_DIR` to CMake if it is set, let me know if you want a P.R for this.

```diff
--- a/pyclaragenomics/setup.py
+++ b/pyclaragenomics/setup.py
@@ -35,6 +35,7 @@ class CMakeWrapper():
         self.cmake_root_dir = os.path.abspath(cmake_root_dir)
         self.cmake_install_dir = os.path.join(self.build_path, ""install"")
         self.cmake_extra_args = cmake_extra_args
+        self.cuda_toolkit_root_dir = os.environ.get(""CUDA_TOOLKIT_ROOT_DIR"")
 
     def run_cmake_cmd(self):
         cmake_args = ['-DCMAKE_INSTALL_PREFIX=' + self.cmake_install_dir,
@@ -42,6 +43,9 @@ class CMakeWrapper():
                       '-DCMAKE_INSTALL_RPATH=' + os.path.join(self.cmake_install_dir, ""lib"")]
         cmake_args += [self.cmake_extra_args]
 
+        if self.cuda_toolkit_root_dir:
+            cmake_args += [""-DCUDA_TOOLKIT_ROOT_DIR=%s"" % self.cuda_toolkit_root_dir]
+
         if not os.path.exists(self.build_path):
             os.makedirs(self.build_path)
```
",iiSeymour,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/175,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MTAxNTU4ODM=,Remove Ubuntu dependency,CLOSED,2019-10-21T17:45:45Z,2019-10-28T12:54:55Z,2019-10-28T12:54:55Z,"On Linux distributions which aren't Ubuntu or CentOS, building the source code fails with the 'unrecognized distro' fatal error. This error occurs in Packaging, which is not relevant to building the rest of the code to use on a given machine and should not block this.",kellyrowland,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/193,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MTA4MjM2NzA=,[common] fasta file I/O performance,OPEN,2019-10-22T18:14:05Z,2019-10-22T18:14:05Z,,"Look into other libraries to improve fasta file I/O performance.
Eric suggested https://github.com/cartoonist/kseqpp",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/195,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MTc2NzI2Njg=,[common] Option to disable doc build,CLOSED,2019-11-05T10:08:38Z,2019-11-13T00:28:34Z,2019-11-13T00:28:34Z,"Please add an option `cga_build_documentation` (or similar) to the cmake options, such that you can opt-out of building the documentation.

Right now the documentation is built if cmake finds doxygen and I'm not aware of any way to turn it off.",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/205,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MTgwODE0MzI=,[CI] Add support for executing gpuCI tests locally through nvidia-docker,CLOSED,2019-11-05T22:13:10Z,2019-11-13T15:39:05Z,2019-11-13T15:39:05Z,Follow https://github.com/rapidsai/cudf/tree/branch-0.11/ci/local,ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/206,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjMwMzI4MDE=,[cudapoa] Add alignment checks to cudapoa host allocation,OPEN,2019-11-14T18:34:37Z,2019-11-14T18:34:37Z,,Right now cudapoa host allocations don't take into account alignment of datatype like uint16_t. This can lead to problems if the offset becomes odd at any point (till now avoided because sizes are all even),tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/215,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjQ1NzE0NzU=,[cudamapper] cub cmake setup,CLOSED,2019-11-18T19:29:54Z,2020-05-07T15:02:42Z,2020-05-07T15:02:41Z,The usage of `cub` in CMake can be improved by making the `cub` folder an interface target (similar to what we have to the `utils` folder).,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/218,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjQ5MjYwMjQ=,[cudaaligner] Mismatch in formatted alignment when running sample,CLOSED,2019-11-19T10:45:12Z,2019-12-07T21:04:37Z,2019-12-07T21:04:36Z,"Steps to reproduce:
- Fetch pull request #219 changes. 
- Build CGA and run 'sample_cudaaligner -p'
- The pairing string does not correspond to the query & target strings.

@tijyojwad reported that when setting query length to 50 and target length to 60 in the sample, then alignments come out fine. But when increasing those to 100 and 110 respectively, then the issue arises.",ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/220,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjUxNDQ2NTY=,[cudamapper] re-architected indexer and matcher,CLOSED,2019-11-19T17:08:47Z,2019-11-27T19:05:16Z,2019-11-27T19:05:16Z,Indexer and matcher re-architected to be a shared component to remove a GPU -> CPU -> GPU copy between the two stages.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/221,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjUxNDYwNzY=,[cudamapper] optimize overlapper,CLOSED,2019-11-19T17:11:25Z,2019-12-23T23:27:55Z,2019-12-23T23:27:55Z,Optimize the overlapper in cudamapper to keep anchors generated from matcher in GPU memory when finding overlaps. Also port the overlap detection algorithm to GPU completely.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/222,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjUxNDcyMzc=,[cudamapper] add better hash function for minimizer,CLOSED,2019-11-19T17:13:33Z,2019-11-19T17:14:04Z,2019-11-19T17:14:04Z,Add a better hashing function for the minimizers so that minimizers within a window are better distributed.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/223,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjUxNTQxNzk=,"[CI] PR tests are marked as pass, even if unit tests fails",CLOSED,2019-11-19T17:26:20Z,2019-11-20T14:19:54Z,2019-11-20T14:19:54Z,"It was observed in https://github.com/clara-genomics/ClaraGenomicsAnalysis/pull/216.

If we take a look at the details of gpuCI/clara-genomics-analysis/gpu-test/ubuntu18.04-cuda10.1:
https://gpuci.gpuopenanalytics.com/blue/organizations/jenkins/clara-genomics%2Fgpuci%2Fclara-genomics-analysis%2Fprb%2Fclara-genomics-analysis-gpu-build/detail/clara-genomics-analysis-gpu-build/342/pipeline
We can see that some of the unit tests fail.
",ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/224,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MjcyMDc3NzQ=,[pyclaragenomics] libcudapoa.so not found after sucessful build,CLOSED,2019-11-22T13:53:10Z,2019-11-22T18:38:18Z,2019-11-22T18:38:18Z,"After building `pyclaragenomics` and running `sample_cudapoa` the following error is thrown.

> ImportError: libcudapoa.so: cannot open shared object file: No such file or directory

Build log -

```bash
$ python setup_pyclaragenomics.py --build_output_folder build/
-- Building ClaraGenomicsAnalysis libraries as shared objects
-- Using CUDA 10.1 from /usr/local/cuda-10.1
-- Build type: Release
-- Package generator - DEB
-- Using CUDA 10.1 from /usr/local/cuda-10.1
-- Enabling Doxygen documentation generation
-- Could NOT find Doxygen (missing: DOXYGEN_EXECUTABLE) 
-- Doxygen not found. Doc gen disabled.
-- clang-format not found. Auto-formatting disabled.
-- Configuring done
-- Generating done
-- Build files have been written to: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build
[  9%] Built target cudamapper_utils
[  9%] Built target cgaio
[ 13%] Built target logging
[ 15%] Linking CXX static library libminimizer.a
[ 17%] Linking CXX shared library libcudapoa.so
[ 19%] Linking CXX shared library libcudaaligner.so
[ 21%] Linking CXX static library libmatcher_gpu.a
[ 23%] Linking CXX static library libmatcher.a
[ 25%] Linking CXX static library liboverlapper_triggerred.a
[ 26%] Built target minimizer
[ 28%] Built target matcher_gpu
[ 30%] Built target matcher
[ 32%] Built target overlapper_triggerred
[ 34%] Linking CXX static library libindex_gpu.a
[ 36%] Linking CXX static library libindex_gpu_two_indices.a
[ 42%] Built target index_gpu
[ 51%] Built target cudapoa
[ 59%] Built target index_gpu_two_indices
[ 61%] Linking CXX executable sample_cudapoa
[ 82%] Built target cudaaligner
[ 84%] Linking CXX executable sample_cudaaligner
[ 86%] Linking CXX executable cudamapper
[ 88%] Built target sample_cudapoa
[ 90%] Built target sample_cudaaligner
[100%] Built target cudamapper
Install the project...
Install the project...
-- Install configuration: ""Release""
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/lib/liblogging.so
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/logging
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/logging/logging.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/logging.cmake
-- Installing: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/logging-release.cmake
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/device_buffer.cuh
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/cudautils.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/stringutils.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/genomeutils.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/graph.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/mathutils.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/cudaversions.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/limits.cuh
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/utils/signed_integer_utils.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/utils.cmake
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/lib/libcgaio.so
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/io
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/io/fasta_parser.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cgaio.cmake
-- Installing: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cgaio-release.cmake
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/lib/libcudapoa.so
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudapoa
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudapoa/cudapoa.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudapoa/batch.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cudapoa.cmake
-- Installing: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cudapoa-release.cmake
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/benchmarks/cudapoa/README.md
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/samples/sample_cudapoa
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/bin/cudamapper
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cudamapper.cmake
-- Installing: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cudamapper-release.cmake
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/lib/libcudaaligner.so
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudaaligner
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudaaligner/alignment.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudaaligner/cudaaligner.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/include/claragenomics/cudaaligner/aligner.hpp
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cudaaligner.cmake
-- Installing: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/cmake/cudaaligner-release.cmake
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/benchmarks/cudaaligner/README.md
-- Up-to-date: /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics/build/install/samples/sample_cudaaligner
Processing /home/cseymour/Code/github/ClaraGenomicsAnalysis/pyclaragenomics
Building wheels for collected packages: pyclaragenomics
  Building wheel for pyclaragenomics (setup.py) ... done
  Created wheel for pyclaragenomics: filename=pyclaragenomics-0.3.0-cp36-cp36m-linux_x86_64.whl size=494354 sha256=42b9d0e80d2cea78ab6f539771d3f2e2ec9043b5f4a742c3151224f2856c54da
  Stored in directory: /tmp/pip-ephem-wheel-cache-mcsgz45e/wheels/f2/90/27/0a912d86c66c3b8fc0e1b1bb30b233fe9bff7063c960a64c1f
Successfully built pyclaragenomics
Installing collected packages: pyclaragenomics
  Found existing installation: pyclaragenomics 0.3.0
    Uninstalling pyclaragenomics-0.3.0:
      Successfully uninstalled pyclaragenomics-0.3.0
Successfully installed pyclaragenomics-0.3.0
pyclaragenomics was successfully setup in installation mode!
```

Putting `build/install/lib` on the `LD_LIBRARY_PATH` results in `sample_cudapoa` running successfully. 

```bash
$ python samples/sample_cudapoa
Traceback (most recent call last):
  File ""samples/sample_cudapoa"", line 17, in <module>
    from claragenomics.bindings import cuda
ImportError: libcudapoa.so: cannot open shared object file: No such file or directory
$ LD_LIBRARY_PATH=./build/install/lib/ python samples/sample_cudapoa 
Processed group 0 - 999
```

Extra Info -

os - Ubuntu 16.04
branch - dev-v0.4.0
commit - 226834941d9ff7b3f0219ec17a1acdde1fe0fb29",iiSeymour,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/230,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1Mjc2ODYyMjk=,[pyclaragenomics] Generate a Python wheel for pyclaragenomics,CLOSED,2019-11-24T11:45:48Z,2019-11-27T23:18:55Z,2019-11-27T23:18:55Z,,ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/237,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1Mjg4NTM5MDE=,[pyclaragenomics] Improve setup script support for generating wheel package,CLOSED,2019-11-26T16:57:20Z,2019-11-27T23:18:56Z,2019-11-27T23:18:56Z,"As discussed in PR #238 comments:
1. Use data_files instead of package_data.
2. Copy the shared libraries in setup.py and not in setup_pyclaragenomics.py
3.  generate a wheel using pip command",ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/240,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MzAxMDk2ODI=,[pyclaragenomics] Python 3.5 wheels not on PyPi,CLOSED,2019-11-29T00:47:13Z,2019-11-29T22:01:23Z,2019-11-29T22:01:23Z,"Hey Guys, Thank you for sorting out wheels, it's a huge help. I can successfully install the 3.6 wheels with pip but I don't think the 3.5 wheels are on PyPi.

```bash
(venv3.5) $ python --version
Python 3.5.2
(venv3.5)  $ pip show pyclaragenomics-cuda10-1
WARNING: Package(s) not found: pyclaragenomics-cuda10-0
(venv3.6) $ python --version
Python 3.6.8
(venv3.6) pip show pyclaragenomics-cuda10-1
Name: pyclaragenomics-cuda10-1
Version: 0.4.0
Summary: NVIDIA genomics python libraries and utiliites
Home-page: https://github.com/clara-genomics/ClaraGenomicsAnalysis
Author: NVIDIA Corporation
Author-email: None
License: Apache License 2.0
Location: .../venv3.6/lib/python3.6/site-packages
Requires: quast, numpy, flake8, networkx, matplotlib, pytest, tqdm, Cython, sortedcollections
Required-by: 
```",iiSeymour,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/247,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MzI3NTE3MTA=,[cudamapper] Filter out most common representations,CLOSED,2019-12-04T15:17:28Z,2019-12-11T09:19:06Z,2019-12-11T09:19:06Z,Implement a functionality which lets the user pass a `filtering_parameter` and then in each index remove all sketch elements with representations such that `number_of_sketch_elements_with_that_representation_in_that_index/total_number_of_sketch_elements_in_that_index >= filtering_parameter`,mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/254,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1MzQ0NTIxNjg=,[sdk] add htslib as submodule,CLOSED,2019-12-07T21:00:03Z,2020-04-10T20:32:02Z,2020-04-10T20:32:01Z,add htslib as submodule to tie to specific version for stability,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/261,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NDA1NTU3MTU=,[cudamapper] Optimize sorting in overlapper,CLOSED,2019-12-19T20:46:29Z,2020-02-17T15:04:05Z,2020-02-17T15:04:05Z,"cudamapper spends most of its execution time doing sorting at the beginning of the `Overlapper`. This is because `Matcher` groups anchors by representation and `Overlapper` needs them to be grouped by pairs of query and target read_ids

Think of a way to avoid this sort and harmonize the interface between `Matcher` and `Overlapper`.

Alternatively look for ways to reduce the sorting time.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/265,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NDYxOTcyMDM=,[cudamapper] data race in cudamapper,CLOSED,2020-01-07T10:14:42Z,2020-01-08T12:25:54Z,2020-01-08T11:01:13Z,"There is a data race in cudamapper's main.cu, which may result in an out-of-bound read

When the atomic variable `ranges_idx` is `query_target_ranges.size()-1`, two (or more) threads may enter the loop
https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/67ff96c80bc7fcce589c2af83d93e73bfc7015f4/cudamapper/src/main.cu#L306
before one of the threads increments `ranges_idx` in next line:
https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/67ff96c80bc7fcce589c2af83d93e73bfc7015f4/cudamapper/src/main.cu#L308
For the other thread(s) entering the loop, this will result in a `range_idx` value >= `query_target_ranges.size()` and result in an out-of-bound memory access in line
https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/67ff96c80bc7fcce589c2af83d93e73bfc7015f4/cudamapper/src/main.cu#L312",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/272,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NDkxNDcyMzA=,[pyclaragenomics] add native namespace packaging to cga,CLOSED,2020-01-13T19:55:43Z,2020-04-10T20:36:03Z,2020-04-10T20:36:03Z,"Update pcga to use native namespace packaging to allow multiple clara genomics repos to share the same namespace

https://packaging.python.org/guides/packaging-namespace-packages/#native-namespace-packages",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/275,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NDkxNDc4MDE=,[cudaaligner] add banding to Myers global alignment,CLOSED,2020-01-13T19:56:57Z,2020-04-17T15:26:19Z,2020-04-17T15:26:19Z,Add banding support to myers bit vector global alignment implementation,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/276,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NDkxNDkyMTE=,[sdk] add cached CUDA allocator,CLOSED,2020-01-13T19:59:57Z,2020-02-10T22:39:39Z,2020-02-10T22:39:39Z,Cached CUDA allocated in CGA to optimize device allocations,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/277,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NTAzODgwNzE=,[CI][pyclaragenomics] Build artifacts distribution,CLOSED,2020-01-15T19:37:39Z,2020-05-04T22:02:25Z,2020-05-04T22:02:25Z,"1. As part of adding a nightly build job, we would like the artifacts(wheel/conda packages) created in that job to be uploaded to PyPI directly. An issue was raised for the rapids ops team to support this:
https://github.com/rapidsai/ops/issues/618
1.1 Once this job is up and running, we will need our PyPI credentials to be configured as environment variables and add the upload commands to the build script. 

2. We would like the tests to be focused on the GPU, the modified test cases should be  as described in https://github.com/rapidsai/ops/issues/617 & https://github.com/rapidsai/ops/issues/618#issuecomment-573852496

",ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/278,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NTcwNjM2ODQ=,[cudamapper] gaps between GPU kernels in cudamapper,CLOSED,2020-01-29T19:20:03Z,2020-02-26T14:50:06Z,2020-02-26T14:50:06Z,profiling cudamapper indicates some gaps between GPU kernels caused by CPU blocking calls. The causes of these gaps need to be identified and resolved where applicable. ,r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/286,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NjE0NDcyMTY=,About BM_SingleBatchAlignment,CLOSED,2020-02-07T06:28:51Z,2020-03-28T05:27:49Z,2020-03-28T05:27:49Z,May I know more information about `BM_SingleBatchAlignment<AlignerGlobalUkkonen>/256/4096`? What are those 2 numbers?,mahmoodn,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/289,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NjMwNjA4NjA=,[cga] Centralize compilation flags,CLOSED,2020-02-11T09:05:10Z,2021-02-12T23:00:34Z,2021-02-12T23:00:34Z,"Currently every module defines its own compilation flags. In some cases this is the wanted behavior, but in others (C++ standard, warning level..) it causes confusion.

Think about which flags should be set for the whole SDK.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/291,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NjUzNzU5Njc=,[cga] Adapt custom allocator and buffer to be more in line with STL,CLOSED,2020-02-14T14:54:32Z,2020-02-25T08:23:08Z,2020-02-25T08:23:08Z,"DeviceAllocator should have `T* DeviceAllocator<T>::allocate()` instead of `void* DeviceAllocator::allocate()`. This is required in order to use DeviceAllocator for internal temporary arrays in Thrust's algorithms.
Doing so will enable us to allocate more memory for caching allocator and also reduce time Thrust spends allocating temporary arrays.

This requires substantial changes to design and adaptation of existing usages of `device_buffer` in cudamapper",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/292,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzA3MzI4MTQ=,[pyclaragenomics] Increase the maximum sequence length limit,CLOSED,2020-02-25T17:43:15Z,2020-07-01T14:37:19Z,2020-07-01T14:37:19Z,"The 1,000 base limit with POA interface makes it quite restrictive for long-read applications and I've only been able to use it for proof of concept ideas. It would great to see this limit removed.",iiSeymour,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/299,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzQ2NTY4NTE=,[cudamapper] Implement multi-layered cache,CLOSED,2020-03-03T13:09:44Z,2020-03-03T17:41:09Z,2020-03-03T17:41:09Z,Host cache currently starts filling at the same time as device cache. therefore if cudamapper is run with the arguments `-c 10 -C 10` host RAM is used but host cache is not used. If cudamapper is run with the arguments `-c 10 -C 15` effective host cache is 5 indices since for the first 10 indices device cache is always used for reads. Host cache should only be invoked when device cache is full.,vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/302,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzQ2OTc2Mjc=,[cudamapper] segfault when running with multi GPU,CLOSED,2020-03-03T14:14:13Z,2020-06-09T19:57:23Z,2020-06-09T19:57:23Z,"Running with multi-GPU on any sizeable dataset (e.g 20k human ONT reads) is resulting in a segfault:

```
time /home/mike/dev/ClaraGenomicsAnalysis/cmake-build-release/cudamapper/cudamapper /data/20k_reads_shuffled-chrX.fasta /data/20k_reads_shuffled-chrX.fasta -i 30 -w 5 -k 15 -c 30 -F 1e-5 -d 2 > out 

NOTE - Since query and target files are same, activating all_to_all mode. Query index size used for both files.
Query /data/20k_reads_shuffled-chrX.fasta index 20000
Target /data/20k_reads_shuffled-chrX.fasta index 20000
Processing query range: (0 - 1116)
Processing query range: (1117 - 2230)
Processing query range: (2231 - 3257)
Processing query range: (3258 - 4370)
Processing query range: (4371 - 5444)
Processing query range: (5445 - 6539)
Processing query range: (6540 - 7597)
Processing query range: (7598 - 8664)
Processing query range: (8665 - 9710)
[2]    5992 segmentation fault (core dumped)  /home/mike/dev/ClaraGenomicsAnalysis/cmake-build-release/cudamapper/cudamappe
/home/mike/dev/ClaraGenomicsAnalysis/cmake-build-release/cudamapper/cudamappe  36.29s user 4.13s system 531% cpu 7.611 total
```",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/304,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzQ3ODY1OTI=,[cudamapper] `CachingDeviceAllocator` causing segfault when running with multi-GPU and cache eviction.,CLOSED,2020-03-03T16:25:28Z,2020-03-05T15:00:59Z,2020-03-05T15:00:59Z,"When running with multiple GPUs, a segfault is resulting if CGA is compiled with the flag `-Dcga_enable_allocator=ON`

Command I am running with: `cudamapper /data/20k_reads_shuffled-chrX.fasta /data/20k_reads_shuffled-chrX.fasta -i 30 -w 5 -k 15 -c 30 -F 1e-5 -d 2 >out`

Interestingly, if [device-side cache eviction](https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/dev-v0.5.0/cudamapper/src/main.cu#L351) is disabled, the segfault disappears.

When compiling with  `-Dcga_enable_allocator=OFF` there is no segfault.

Stderr:

```
 time /home/mike/dev/ClaraGenomicsAnalysis/cmake-build-release/cudamapper/cudamapper /data/20k_reads_shuffled-chrX.fasta /data/20k_reads_shuffled-chrX.fasta -i 30 -w 5 -k 15 -c 30 -F 1e-5 -d 2 > out
NOTE - Since query and target files are same, activating all_to_all mode. Query index size used for both files.
Query /data/20k_reads_shuffled-chrX.fasta index 20000
Target /data/20k_reads_shuffled-chrX.fasta index 20000
Processing query range: (0 - 1116)
Processing query range: (1117 - 2230)
Processing query range: (2231 - 3257)
Processing query range: (3258 - 4370)
Processing query range: (4371 - 5444)
[2]    28589 segmentation fault (core dumped)  /home/mike/dev/ClaraGenomicsAnalysis/cmake-build-release/cudamapper/cudamappe
/home/mike/dev/ClaraGenomicsAnalysis/cmake-build-release/cudamapper/cudamappe  21.83s user 2.21s system 353% cpu 6.806 total
```",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/306,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzUwOTExNzc=,[cudamapper] remove self-mapped reads,CLOSED,2020-03-04T02:28:19Z,2020-03-06T23:46:07Z,2020-03-06T23:46:07Z,Self-mapped reads should be filtered out by GPU filtering.,vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/308,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzUwOTIxODg=,[cudamapper] no useful error message when cudamapper pointed to non-existent file.,CLOSED,2020-03-04T02:29:47Z,2020-04-01T15:42:25Z,2020-04-01T15:42:25Z,"A useful error is needed. Right now application does not crash but ends with:

```
Processing query range (0 - -1)
```",vellamike,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/309,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzUzNTU3MzU=,[cudamapper] code clean-up related to fuse_overlaps,CLOSED,2020-03-04T12:17:06Z,2020-06-25T18:50:32Z,2020-06-25T18:50:32Z,"there are some files and tests associated with deprecated `fuse_overlaps` function. Assuming `fuse_overlaps` is no longer used, they can be removed.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/311,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzU1MTMwNTA=,[cudapoa] make max sequence and graph size configurable,CLOSED,2020-03-04T15:39:44Z,2020-04-08T01:56:08Z,2020-04-08T01:56:08Z,currently the max sizes for sequence and graph are all hard coded based on empirical observations while running racon. these should instead of parameters passed during construction of the cudapoa batch object.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/312,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzY0MDgzNDk=,[cga] Implement preallocating device allocator,CLOSED,2020-03-05T17:14:36Z,2020-03-09T15:57:34Z,2020-03-09T15:57:34Z,"(De)allocating device memory is expensive. We are currently using `cub::CachingDeviceAllocator` which caches smaller array (see #277), but large arrays (> 500MB) are still being constantly allocated and deallocated.

Implement an allocator which allocates a big chunk of device memory in the beginning and then assigns parts of it, meaning it only has to allocate device memory once in the beginning and deallocate it once at the end",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/315,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzY0MjQwOTM=,[cudamapper] Have all work for one iteration in one stream,CLOSED,2020-03-05T17:42:09Z,2020-03-12T09:51:10Z,2020-03-12T09:51:10Z,"Currently different kernels of one query - target read pair (iteration) use different streams without a specific need for that.

Make all kernels of one iteration use the same stream. This will
- prevent possible bugs due to incorrectly synchronized streams
- enable us to to use stream sync deallocations in caching allocators
- make it easier to overlap fetching indices from host cache with matcher-overlapper calculations
- make the profiles cleaner",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/317,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzY0MjY2NjM=,[cudamapper] Overlap fetching indices from host memory with matcher+overlapper,CLOSED,2020-03-05T17:46:54Z,2020-10-22T14:37:45Z,2020-10-22T14:37:45Z,"Fetch new target index from host cache while matcher+overlapper work on current target index.

On current benchmarks fetching index from device cache takes approximately the same amount of time as doing mathcer + overlapper for it, so it makes sense to overlap those two activities.

Work on this issue can start after issue #317 has been done",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/318,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzY0MzA0OTk=,[cga] Implement host pool allocator,OPEN,2020-03-05T17:53:53Z,2020-03-05T17:53:53Z,,"Allocating/resizing some host arrays (e.g. when creating host copies of indices) takes a significant amount of time.

Implement host pool allocator.
Also evaluate the possibility of using implementations from Thrust 1.9.4 or C++17. Currently those do not look like viable options due minimally system requirements on CGA's side.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/319,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1NzgwNDQ0MTE=,[cudamapper] CIGAR integration,CLOSED,2020-03-09T16:46:39Z,2020-04-22T15:11:29Z,2020-04-22T15:11:29Z,"CIGAR part uses a custom stream and does not use `device_buffer`/preallocating allocator.

Revisit that implementation, identify necessary changes and implement them

See:
#307 
#313 
#316 
#318 
#320 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/321,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1Nzk0NTM3MjU=,[cudamapper] debug accuracy issues for drosophila,CLOSED,2020-03-11T18:12:15Z,2020-04-07T14:29:27Z,2020-04-07T14:29:27Z,,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/322,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1Nzk0NjEwOTc=,[cudamapper] add end2end binary run test,OPEN,2020-03-11T18:26:01Z,2020-05-06T15:41:33Z,,"Currently we only have unit tests for cudamapper, but nothing that runs the bianry on a dataset end to end. This should be added to gpuCI runs as well, for both single and multi GPU configurations",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/323,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1Nzk5NTg0NDc=,cudamapper does not fail with invalid input path,CLOSED,2020-03-12T13:58:49Z,2020-03-13T00:53:00Z,2020-03-13T00:53:00Z,"If you pass an invalid path as fasta input, cudamapper does not report any error.
(Instead it creates an empty index.)",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/324,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1ODM5NTA4ODE=,[cga] Automatically determine compute capability,CLOSED,2020-03-18T19:22:07Z,2020-03-23T19:53:53Z,2020-03-23T19:53:53Z,"Currently we are compiling for default compute capability (I believe sm_35).

For cudamapper one can specify higher compute capability by adding it to `CMakeLists.txt` (https://github.com/clara-genomics/ClaraGenomicsAnalysis/blob/317bce9591cc72285785e8bfc937ac149c44515c/cudamapper/CMakeLists.txt#L22), for example for Volta `-arch=compute_70 -code=sm_70`, but this is not a flexible solution. Setting the value manually brings significant improvements to cudamapper's performance.

Goal: Use `CUDA_SELECT_NVCC_ARCH_FLAGS` (https://cmake.org/cmake/help/v3.10/module/FindCUDA.html) to set this value per default. Ideally have it set on SDK level, but for now just cudammaper would work. I would suggest using `Auto` option, although I'm not sure how this works when using a machine without a GPU or building and packaging it.

Also see issue #291 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/326,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1ODgwMDQ2OTU=,[cudamapper] output overlaps in BAM,CLOSED,2020-03-25T21:33:32Z,2020-10-16T23:24:07Z,2020-10-16T23:24:07Z,Support output the overlaps in both PAF and BAM format. Similar to the `-a` option in `minimap2` (described in https://github.com/lh3/minimap2#general-usage),tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/335,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1ODkwNTM1Nzg=,Can not find cudaaligner executable after compiling,CLOSED,2020-03-27T11:01:58Z,2020-04-01T15:14:41Z,2020-04-01T15:14:41Z,"Hello,

I want to run `cudaaligner` but after compiling successfully I am unable to find the executable.
For instance, the `cudamapper` tool is found in the `../ClaraGenomicsAnalysis/build/install/bin` folder. However I have ran `find ../ClaraGenomicsAnalysis -name ""cudaaligner"" -executable -type f` and nothing shows. Can you please help? Thank you.
BTW: I am not running as sudo as I have no permissions",estebanpw,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/339,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1ODk1MzU2NTU=,[cudamapper] example API usage,CLOSED,2020-03-28T08:45:46Z,2020-07-24T17:48:41Z,2020-07-24T17:48:41Z,"Hi!

I really appreciated the example API usage for cudapoa and would like to ask for something similar for cudamapper.

Thanks!
Armin",armintoepfer,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/340,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1ODk4ODA3NDE=,performance drop-down related to CUDA_NVCC_FLAGS,CLOSED,2020-03-29T20:40:36Z,2020-07-08T17:53:12Z,2020-07-08T17:53:12Z,"cudapoa_benchmark seems to be ~10% slower which this line is added to `cmake/CUDA.cmake`:
`set(CUDA_NVCC_FLAGS ""${CUDA_NVCC_FLAGS} ${ARCH_FLAGS}"")`   ([link here](https://github.com/r-mafi/ClaraGenomicsAnalysis/commit/2b5d632fa66f5471b7ac3c27106af721bf4530a1#diff-d77f46a67237a37b9c4eae17e6a1b741R27))

![image](https://user-images.githubusercontent.com/59714522/77860190-c8459000-71db-11ea-919d-fe9b20d54557.png)

",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/341,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTEyMTM5ODU=,[cudaaligner] add cudaaligner binary for pairwise global alignment,OPEN,2020-03-31T15:42:54Z,2020-03-31T15:43:23Z,,"A binary to compute pairwise alignment for a set of inputs

Example - Emboss needle app

Raised by @estebanpw in #339 ",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/345,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTE5MzQ3NTk=,unexpected behavior in cudautils::align,CLOSED,2020-04-01T13:53:12Z,2020-04-14T05:57:10Z,2020-04-14T05:57:10Z,"`cudautils::align<int32_t, 4>` function makes any input a divisible by 4, if it is already divisible by 4, it still adds 4, e.g. `align<int32_t, 4>(1023) = 1024`, `align<int32_t, 4>(1024) = 1028` or `align<int32_t, 4>(0) = 4`. This seems a bit unexpected, we probably do not need to change an input which is already divisible by 4 in this example.

Note: if this behavior changes, `claragenomics::cudapoa::BatchSize` constructors needs to get modified as well, since it is defined based on this current behavior.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/346,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTE5OTI3MTM=,[cudamapper] read to reference mapping capability,CLOSED,2020-04-01T15:12:06Z,2021-01-26T16:56:06Z,2021-01-26T16:56:06Z,Add support for read to reference mapping to `cudamapper`. Initially assigning to @vellamike ,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/349,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTY3MDA5NzE=,[cudamapper] package cudamapper components into libcudamapper,CLOSED,2020-04-08T16:20:27Z,2020-04-20T13:28:59Z,2020-04-20T13:28:59Z,"Current cmake structure create separate private libs for indexer, matcher and overlapper. Would be good to combine all of them into a single `libcudamapper` object that the `cudamapper` application links against.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/352,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTc0OTg0Mzc=,[cudaaligner] use device_copy_n,OPEN,2020-04-09T19:18:58Z,2020-04-09T19:18:58Z,,"cudaaligner uses many `cudaMemcpy`, many (if not all) can be replaced with `device_copy_n`.",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/355,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTc2NTQ3NTM=,[cudapoa] expose configurable cudapoa sizes to python API,CLOSED,2020-04-10T02:14:17Z,2020-04-29T15:13:31Z,2020-04-29T15:13:31Z,Update cudapoa python API to expose variable sizes for sequences and graphs ,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/356,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU1OTgwNzIzMTY=,[cudapoa] Remove `exceeded_batch_size` error,CLOSED,2020-04-10T20:14:43Z,2020-05-04T18:10:06Z,2020-05-04T18:10:06Z,"There's a redundancy in error codes in `cudapoa` when it comes to max POAs. POAs can be limited either by the heuristic calculation that accounts for max possible POAs, and also by how much space is left for the scoring matrices. These two currently return different error codes if surpassed, whereas semantically they're the same (i.e. limit how many POAs can be processed in a batch), so they should return the same error.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/358,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDA0MTk4MzE=,[cga] Move cgalogging and cgaconfig to libcgabase,CLOSED,2020-04-15T16:14:03Z,2020-04-20T13:25:27Z,2020-04-20T13:25:27Z,PR #359 introduces `libcgabase`. `cgalogging` and `cgaconfig` should also be part of it.,mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/369,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDQ4NTU1OTc=,[cudaaligner] reduce memory footprint of banded myers implementation,CLOSED,2020-04-22T15:36:49Z,2020-08-04T14:24:25Z,2020-08-04T14:24:25Z,Reduce the memory requirements for banded Myers implementation to fit more alignments per batch,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/380,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDQ4NjQ0ODY=,[pyclaragenomics] Add python API for cudamapper components ,OPEN,2020-04-22T15:49:00Z,2020-04-22T15:49:00Z,,"Add python bindings for `cudamapper` components - `indexer`, `matcher` and `overlapper`",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/381,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDQ4NjUxNzc=,[cudamapper] generate shared library for cudamapper,OPEN,2020-04-22T15:50:00Z,2020-04-22T15:50:00Z,,Currently only a static `cudamapper` library is generated. Add support for shared library generation as well. A prerequisite for #381 ,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/382,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUwMTQxNTA=,[README] PyPI pycga link broken in README,CLOSED,2020-04-22T19:37:11Z,2020-04-22T22:52:18Z,2020-04-22T22:52:18Z,The link on the `pyclaragenomics` readme that points to the PyPI packages is broken. This needs to be merged to master,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/385,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUwMTcwMDY=,[pyclaragenomics] upload pyclaragenomics API documentation,CLOSED,2020-04-22T19:41:49Z,2020-08-31T14:14:38Z,2020-08-31T14:14:38Z,publish pyclaragenomics API documentation to public location,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/386,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUwOTg2NDI=,[cudapoa] Automatic selection for max_sequence_size and max_sequences_per_poa,CLOSED,2020-04-22T21:52:54Z,2020-12-02T15:59:15Z,2020-12-02T15:59:15Z,"Currently cudapoa requires user input to define maximum sequence size as well as maximum number of sequences per POA. In other words, considering a window of reads, its width and height should be defined by the user. A conservative choice of these parameters can result in sub-optimal memory usage, and potentially reducing GPU occupancy. An optimal value for these parameters can be extracted based on input data.

The initial motivation for the current implementation was to reuse allocated buffers between multiple iterations. But using pre-allocated buffers, we should be able to compute batch size dynamically and more optimally.

This is a suggestion to allow automatic selection of  `max_sequence_size` and `max_sequences_per_poa` after integrating pre-allocated buffers in cudapoa.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/390,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUxMzIxMTI=,[cudapoa] Reconcile cudapoa BatchSize API between C++ and Python,OPEN,2020-04-22T23:16:40Z,2020-04-22T23:16:40Z,,"Python API takes in several params as optional, but C++ API only exposes 2 constructors. That means if only some optional args are provided in python API, the rest need to heuristically calculated on the python side. However, heuristics are already implemented on the C++ side and they may diverge over time. Feature request is to update C++ API so it's most seamless compatible with needs of the python API",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/391,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUxMzMzMjQ=,[pyclaragenomics] increase cudapoa test coverage,OPEN,2020-04-22T23:19:48Z,2020-04-22T23:23:10Z,,"Add more tests covering the following in pycga cudapoa - 

1. use of different output types
2. use of different values for alignment
3. use of custom sizes for sequence and graph sizes

and other parts of the API that are untested",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/392,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUxMzQyODg=,[common] Wrapping CUDA stream in another class to catch stream destruction,CLOSED,2020-04-22T23:22:24Z,2020-08-27T14:05:37Z,2020-08-27T14:05:37Z,,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/393,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDUxMzUyMTg=,[cudamapper] investigate output minimap2 index from cudamapper,CLOSED,2020-04-22T23:24:56Z,2021-01-26T16:57:09Z,2021-01-26T16:57:08Z,minimap2 provides an `index` interface through the `minimap2 index` data structure. investigate if the data structure can be generated through cudamapper so it can plug into the minimap2 flow seamlessly.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/394,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDc2ODQ4MzA=,[cudapoa] keep member type and allocation size in sync,CLOSED,2020-04-27T16:29:39Z,2020-06-08T14:43:06Z,2020-06-08T14:43:06Z,"The way cudapoa allocates buffers right now is by calculating the size based on type of the struct elements. However, the sizing calculation uses the type explicitly instead of drawing it from the member element directly. This means the type has to be specified in two places, and more importantly updated in two places concurrently, which is the source of many problems.

It would be a good idea to use something like http://www.cplusplus.com/reference/typeinfo/type_info/name/ to keep the types in sync so they only need to be updated in one place.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/396,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDkxMDQ0MDY=,[cudapoa] Error code 8 on some cases of Bonito sample,CLOSED,2020-04-29T14:30:20Z,2020-05-11T15:26:59Z,2020-05-11T15:26:59Z,"In bonito sample dataset, for about 7 cases, generate consensus in `cudapoa` fails to run successfully. It exits with Error code 8. Would be helpful to investigate why it fails, whether it's a bug or not, and how to fix.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/398,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDkxMDY4MjE=,[common] remove CUB caching allocator,CLOSED,2020-04-29T14:33:38Z,2020-05-01T16:43:32Z,2020-05-01T16:43:32Z,"Since CUB caching allocator is not being actively used in the SDK and there are semantic differences in how the CUB and preallocator allocator APIs behave, we decided to remove the CUB allocator for now. If need be, it can be brought back from git history.

For some insight into CUB semantics issue, please see https://github.com/clara-genomics/ClaraGenomicsAnalysis/pull/379",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/399,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MDkxNjM4NzM=,[gpuCI] enable CGA nightly tests,CLOSED,2020-04-29T15:48:30Z,2020-06-05T10:19:11Z,2020-06-05T10:19:11Z,Enable nightly tests for `master` and default `dev-vX.Y.Z` branch in CGA repo.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/402,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTA3OTk0MDU=,[cudapoa] add and use an error code for add_alignment,CLOSED,2020-05-01T15:09:22Z,2020-12-02T16:06:23Z,2020-12-02T16:06:23Z,"`addAlignmentToGraph` in `cudapoa_add_alignment.cu` returns an error code, but this error code is not used and not passed along to the caller functions.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/405,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTA3OTk4OTQ=,[cudapoa] add and use error code in addAlignmentKernel,CLOSED,2020-05-01T15:10:23Z,2020-05-01T15:11:30Z,2020-05-01T15:11:30Z,"`addAlignmentToGraph` in `cudapoa_add_alignment.cu` returns an error code, but this error code is not used and not passed along to the caller functions.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/406,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTE5MzYwNzc=,[cudapoa] Replace the usage of `void*` with templated args,CLOSED,2020-05-04T14:51:22Z,2020-06-15T03:52:04Z,2020-06-15T03:52:04Z,"https://github.com/clara-genomics/ClaraGenomicsAnalysis/pull/397 introduces functions that take in `void *` arguments in the kernel host wrappers. A restructuring of the source files in cudapoa can potentially remove this requirement as this is requiring duplication of logic in some files (i.e. heuristics to choose between different sizer types).

example attempt in https://github.com/tijyojwad/ClaraGenomicsAnalysis/tree/jdaw/template-structure-changes",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/407,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTIwOTA0Njc=,[cudamapper] Improve PAF generation,CLOSED,2020-05-04T18:49:53Z,2020-05-13T15:54:02Z,2020-05-13T15:54:02Z,"New implementation of index caching (#318) is bottlenecked by generation of strings for PAF files (not writing to files themselves). We currently copy read names and lengths into `Overlap` objects using `Overlapper::update_read_names()` and then use `Overlapper::print_paf()`.

Remove read name and length from `Overlap` object and parallelize `Overlapper::print_paf()` for better performance.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/410,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTI3NTI5NDM=,[cga] Support multiple streams in device_buffer and DevicePreallocatedAllocator,CLOSED,2020-05-05T16:57:36Z,2020-06-26T20:10:57Z,2020-06-26T20:10:57Z,"`DevicePreallocatedAllocator::DeviceAllocate()` currently accept `cudaStream_t`. `DevicePreallocatedAllocator::DeviceFree()` waits on that stream before actually deallocating memory in order to prevent the memory from being deallocated before all work that uses it is done.
In cases when the same buffer is used by two or more streams it is not possible to wait on all of them and the user has to make sure that all other streams have finished.

The goal it to support associating one allocation with multiple streams.

This should also be supported by `device_buffer`/`buffer`.

Consider using variadic template to pass one or more streams, store them in a `vector` internally and loop over them in `DevicePreallocatedAllocator::DeviceFree()`

This issue is part of issue #318 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/414,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTM0MjI3MTM=,[cudapoa] analyze accuracy of cudaPOA on long read data,CLOSED,2020-05-06T15:46:14Z,2020-05-19T02:56:32Z,2020-05-19T02:56:32Z,Need to evaluate the accuracy of cudaPOA consensus with long reads against CPU equivalent using Pomoxis metrics.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/416,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTQwODQ1Mzc=,[pycga] enable doc generation test for pyclaragenomics,OPEN,2020-05-07T14:04:27Z,2020-05-07T14:10:38Z,,Python doc generation only happens successfully when the bindings have been built. However the current sphinx command doesn't fail when bindings aren't built. This issue is to investigate the right way to build sphinx based documentation and enable it in the tests so doc generation is validated on every PR.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/419,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTU0MTgzNTI=,[SDK] rename SDK to GenomeWorks,CLOSED,2020-05-10T15:42:31Z,2020-06-26T17:34:48Z,2020-06-26T17:34:48Z,Description to be updated once final name of repo is decided,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/424,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTYwMDI3MDc=,[cudapoa] Re mixed usage of local and global index in banded NW,OPEN,2020-05-11T16:08:29Z,2020-05-11T16:08:29Z,,"In Banded NW in cudaPOA, there are some kernels such as `get_score()` or `set_score()` that accept column index both as local-index (cases such as [here](https://github.com/clara-parabricks/ClaraGenomicsAnalysis/blob/dev-v0.5.0/cudapoa/src/cudapoa_nw_banded.cu#L238), where 0 is passed for column index) or global-index.
It helps to avoid possible bugs and better maintenance of the code if we make a clear distinction between local and global indices, or simply unify the usage to one case.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/425,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTY3MDg4ODU=,[cudamapper] Move overlaps post-processing to GPU,OPEN,2020-05-12T14:36:37Z,2020-06-25T18:43:50Z,,"Currently `Overlapper::post_process_overlaps()` and new functionality to be added in PR #422 run on CPU. They should be moved to GPU.

There are two reason for that:
a) One matcher + overlapper iteration on our benchmark currently takes around 115ms (that number will likely be cut at least in half in the future) and generate 220k overlaps. If done on CPU those overlaps should ideally be post-processed during next matcher + overlapper iteration, giving around 0.5us to process each overlap. Even if we use multiple threads this will still not give us more than 3 - 5us per overlap.
b) Output generation is likely to move to GPU and for that we would need the overlaps to remain on device. Also, if we decide to pass the data directly to the next application in the pipeline we would also like to avoid having to copy the data back to host just to copy it back to device",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/428,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTczMjAyNzQ=,[common] Use int32_t for position_in_read_t and number_of_basepairs_t.,OPEN,2020-05-13T10:09:04Z,2020-05-13T10:09:04Z,,"In order to avoid mixing signed and unsigned arithmetic, we should make change the type of `position_in_read_t` and `number_of_basepairs_t` from `uint32_t` to `int32_t`.
This should not lead to any problems, as we don't expect reads larger than 2x10^9.",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/429,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MTg1MTE2NzE=,[cudapoa] add cudapoa binary for generating msa or consensus,CLOSED,2020-05-14T20:22:08Z,2020-06-30T00:08:47Z,2020-06-30T00:08:47Z,"a binary that takes one or multiple fasta/text files as input and outputs consensus  or MSA or both.
Improving single-window performance is probably a prerequisite.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/431,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjA0OTc5MTI=,[CI] Support different image combinations for pull request branch and master/dev branch,OPEN,2020-05-18T20:50:34Z,2020-05-18T20:50:34Z,,,ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/433,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjA2NjYyNTQ=,[bindings] replace cython with SWIG for python bindings,CLOSED,2020-05-19T04:23:30Z,2020-12-04T16:25:02Z,2020-12-04T16:25:02Z,"Replace cython based python bindings generation with SWIG. 

Based on analysis by @rilango , SWIG provides more generic language extension framework and support multiple target languages such as python, Java, etc. Helpful in scaling CGA bindings to multiple languages through a single frameworks.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/435,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjE4NzY1NjY=,[cudapoa] increase bandwidth in banded cudapoa,CLOSED,2020-05-20T15:56:54Z,2020-05-27T20:14:48Z,2020-05-27T20:14:48Z,Current implementation of cudapoa banded uses a fixed band width of 128 elements. Investigate ways to increase the fixed band width.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/440,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjIxMjIwNTQ=,[cudapoa] adding PO-PO alignment,CLOSED,2020-05-20T22:26:00Z,2020-11-30T17:05:19Z,2020-11-30T17:05:19Z,"the current cudaPOA is mainly based on original POA algorithm [[POA 2002](https://doi.org/10.1093/bioinformatics/18.3.452)]. Same author in  another paper [[POA 2004](https://doi.org/10.1093/bioinformatics/bth126)] proposes an extension of the algorithm that allows aligning POA graphs to each other.
This extension is useful for polishing and MSA applications. It can increase cudaPOA parallelism and help to improve performance of MSA/consensus problems for a single window with large number of sequences.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/441,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjIxMjQyMDg=,[cudapoa] improve estimation of maximum graph length,CLOSED,2020-05-20T22:31:35Z,2020-12-02T16:25:38Z,2020-12-02T16:25:37Z,"POA graph length depends on the differences between multiple sequences in a window. As this difference can potentially grow by increasing the number of sequences in a window, we can modify heuristics to estimate the maximum graph length in `BatchSize` constructor to take this parameter into account. Using a fixed formula for maximum graph length can be wasteful in some cases and insufficient for some others.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/442,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjI0ODgzNjk=,[pycga] Pass arguments to setup.py from setup_pyclaragenomics.py directly,OPEN,2020-05-21T13:09:28Z,2020-05-21T14:28:51Z,,"Currently, we are passing these parameters as environment variables to the subprocess, they should be passed directly through pip. (see https://stackoverflow.com/a/49609956)",ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/443,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjU4MDE1MzY=,[cudapoa] error types in cudaPOA,CLOSED,2020-05-27T15:35:22Z,2020-12-04T00:55:54Z,2020-12-04T00:55:54Z,"There is no use of `StatusType::seq_len_exceeded_maximum_nodes_per_window` and can be removed.

On the same note, there is a subtle difference between maximum number of nodes per window and maximum graph dimension. The latter needs to be multiple of 4. We can remove `max_nodes_per_window` in `BatchSize` and only use `max_matrix_graph_dimension`. Same applies for banded version of the variables.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/446,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MjY5MTIyNzM=,Install from source needed for dev functionality,CLOSED,2020-05-29T00:15:47Z,2020-08-05T14:58:48Z,2020-08-05T14:58:48Z,"In order to be able to run cudapoa, it is necessary to install the pyclaragenomics package from source. TODO: Updated documentation on this. ",rahulmohan,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/447,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MzAxNDQ0ODU=,[cudapoa] investigate adaptive banding in cudapoa,CLOSED,2020-06-03T16:29:07Z,2020-08-05T00:14:41Z,2020-08-05T00:14:41Z,design algorithm for adaptive banding suitable for cudapoa implementation.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/448,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MzE1OTY1NDA=,[cudamapper] Perform range-check on program arguments.,OPEN,2020-06-05T13:38:58Z,2020-06-05T13:38:58Z,,"cudamapper takes a series of program arguments parsed with `getopt_long`. For many arguments the program checks if the argument is within valid range, but not for all. Especially checks for negative values, which are invalid for most arguments, are missing.
We need to go through the arguments and make similar range checks for all arguments.
",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/451,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MzU4NDcyOTY=,[cudapoa] graph output in cudaPOA,CLOSED,2020-06-10T00:49:02Z,2020-12-02T15:44:42Z,2020-12-02T15:44:42Z,adding `.png` format to export POA graph for a given POA group can be useful. That is a convenient way to visualize pretty large graphs.,r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/454,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2Mzg0NjM5OTM=,[logging] remove spdlog as logger dependency,CLOSED,2020-06-15T00:29:27Z,2020-12-14T15:15:33Z,2020-12-14T15:15:33Z,"We have added a lot of hacks to support the logging library for CUDA < 10.0 because `spdlog` uses uninitialized constructors which doesn't play well with old `nvcc`. `spdlog` is also heavily based on templates, which means the library headers spill into the install folder of GenomeWorks, and hence requires `spdlog` to also be shipped in the `install` folder.

Best thing would be to remove `spdlog` as a logger library and instead use a simpler one for now which resolves all of these issues.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/459,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2Mzg0NjQyNDI=,[sdk] add CI for CUDA 11 and validate support,CLOSED,2020-06-15T00:30:49Z,2020-10-07T19:46:10Z,2020-10-07T19:46:10Z,Add a CUDA 11 Ubuntu 18.04 test to gpuCI for GenomeWorks,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/460,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2Mzg0NjQ0NjA=,[sdk] remove cuda 9.x support,CLOSED,2020-06-15T00:31:54Z,2020-12-04T21:44:05Z,2020-12-04T21:44:05Z,"After CUDA 11 support (issue #460) is officially added, remove explicit CUDA 9 support from SDK.
",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/461,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2MzkyNTE3Mzk=,[cudapoa] toward DRY code by merging estimate_max_poas() and calculate_space_per_poa(),OPEN,2020-06-15T23:26:56Z,2020-06-15T23:26:56Z,,"`estimate_max_poas()` and `calculate_space_per_poa()` in `BatchBlock` class, share some similar logic and with some effort, they can be unified.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/466,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NDA1OTAxOTU=,[tests] upgrade CI harness scripts to be more robust,OPEN,2020-06-17T16:44:09Z,2020-06-17T16:44:09Z,,"Our CI scripts currently written in `bash`, and use a lot of env vars and positional arguments. But this setup is ripe for bugs and errors. It's important to upgrade the scripts to be more robust so our testing system itself doesn't silently break.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/469,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NDE1NzkzMjg=,Permission denied (publickey). fatal: Could not read from remote repository.,CLOSED,2020-06-18T22:11:16Z,2020-06-22T12:45:55Z,2020-06-22T12:45:55Z,"Error on executing the following command:
$ git clone --recursive git@github.com:clara-genomics/ClaraGenomicsAnalysis.git
Cloning into 'ClaraGenomicsAnalysis'...
git@github.com: Permission denied (publickey).
fatal: Could not read from remote repository.

Please make sure you have the correct access rights
and the repository exists.

Kindly recommend solution.
Thanks!
",SuchismitaSahu1993,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/470,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NDQ4MTE0MTM=,"[cudamapper] Default parameters should be hardened against many datasets / GPUs, match those of minimap2",CLOSED,2020-06-24T18:07:33Z,2020-07-13T16:23:58Z,2020-07-13T16:23:58Z,"Cudamapper is supposed to be a drop-in replacement for minimap2. Our default parameters, however, differ from those of minimap2. In addition, they seem to be unstable on many GPUs, causing crashes.

This is a major barrier to entry for users - they want the program to run to completion, even at the expense of performance.

Minimap2 defaults:
- [x] Minimizer kmer size: 15
- [x]  Minimizer window size: 10
- [x] Minimum number of minimizers in a chain: 3
- [x] Max distance between minimizers before chain is terminated: 5000
- [x] Minimum overlap size: <500
- [x] Minibatch size: 500M

Most of these can be addressed by either a single cudamapper parameter or a combination of multiple parameters. 

In the case of minibatch size, it's not so much about matching the number as it is about providing a stable CLI. I find I'm often having to tweak the `-I, -i, -q, -Q, -c, -C, -m` parameters to balance memory usage (e.g. to prevent out-of-memory errors) and performance. I think we should establish safe defaults for long reads on 8GB, 16GB and 32GB memory GPUs. Even though we programatically check for max preallocated memory we often seem to OOM due to index size parameterizations. My vote would be to prioritize stability and provide a one-pager on tuning for max performance (acknowledging the limits of each GPU considering maximum read size).
",edawson,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/471,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NDY5ODU1Mzg=,[pygw] reference to stream getting lost in CudaAlignerBatch object,OPEN,2020-06-28T19:01:58Z,2020-06-28T19:01:58Z,,"The reference to the stream object is getting lost somehow in CudaAlignerBatch object, because of which stream and batch are sometimes getting destroyed out of order. Explicit ref increment/decrement resolves the issue, but this should be handled by the automatic mechanism in python. This issue is to investigate why that's not working.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/476,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTAxOTgxMzA=,[cudapoa] cudapoa binary input options,CLOSED,2020-07-02T20:53:28Z,2020-11-30T16:56:00Z,2020-11-30T16:56:00Z,"deciding whether to keep option `-M` which currently defines number of POA groups, as it is, or change it to represent maximum number of reads? or simply get rid of it all together.
On the same note, there is possibly another set of options required to modify default `BatchSize` constructor values.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/483,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTI2NTYzMzE=,[CI] Add build Slack notifications,CLOSED,2020-07-07T21:21:38Z,2020-09-22T13:48:34Z,2020-09-22T13:48:34Z,Integrate GenomeWorks branch builds with `nvgenomics-ci` slack channel,ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/487,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTM1NDc5MTY=,[cudamapper] Skip pairs of indices which cause out of memory errors,CLOSED,2020-07-08T19:40:48Z,2020-07-14T14:32:15Z,2020-07-14T14:32:15Z,"Depending on read characteristics some pairs of indices can cause OOM errors.
Skip such pairs of indices and print a message to the user.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/489,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTM2MDA4MTY=,[cudamapper] Process skipped pairs of indices separately,OPEN,2020-07-08T21:12:57Z,2020-07-08T21:12:57Z,,Keep a list of pairs of indices which were skipped due to an OOM error (Issue #489). Once all other pairs of indices have been processed go over skipped ones and process them one by one without keeping any other indices on device in order to maximize the amount of available device memory.,mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/490,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTM2MDQwNzI=,[cudamapper] Split index pairs which cause OOM into multiple pairs of indices,OPEN,2020-07-08T21:19:17Z,2020-07-08T21:19:17Z,,"If a pair of indices causes OOM error even when no other indices are kept on device (Issue #490, also see #489) split indices into several smaller indices and find overlaps.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/491,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTQ3NTE4MzI=,[cudapoa] customizable number of cells per thread in NW kernels,CLOSED,2020-07-10T12:38:23Z,2020-12-02T15:42:38Z,2020-12-02T15:42:38Z,"In the current implementation, different variations of Needleman-Wunch kernels process score matrix row by row. Each thread processes a fixed number of cells per row at a time, `CELLS_PER_THREAD = 4`. To make this number variable allows adjusting parallelism granularity (e.g. right now, minimum band-width length = `CELLS_PER_THREAD*WARP_SIZE`) and potentially improving performance.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/494,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTYxOTg2NzQ=,[cudapoa][cudaaligner] adding support for different types of gap penalty,OPEN,2020-07-13T22:49:01Z,2020-07-13T22:56:54Z,,"The current implementation supports constant gap penalty. This issue suggests adding linear, affine and convex types as well.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/496,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTY4NzMyMTI=,[cudapoa] add tests for banded and adaptive alignment,CLOSED,2020-07-14T20:18:33Z,2020-11-30T22:42:35Z,2020-11-30T22:42:35Z,Add some tests to verify banded-alignment as well as adaptive-alignment. Tests can compare consensus output against full-alignment.,r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/502,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTY4OTAwNzE=,[cudamapper] Overlaps at the same position in an index are dropped even when query and target files are not the same.,CLOSED,2020-07-14T20:49:11Z,2020-07-23T15:10:06Z,2020-07-23T15:10:06Z,"When using two different FASTA files, reads at index i in the query index and index j in the target index are not overlapped when i == j. This is because of a check that was introduced in https://github.com/clara-parabricks/GenomeWorks/blob/0702c2ffd672fa04887f3b4e82bfd18d1d213218/cudamapper/src/overlapper.cpp#L25, and is valid for all-to-all but not sequence-to-reference overlapping.

The filtering condition should be ignored when not running in all-to-all mode.",edawson,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/503,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTY4OTc3ODU=,[cudamapper] Filtering parameters are too stringent for very small read sets,CLOSED,2020-07-14T21:03:49Z,2020-07-31T00:51:26Z,2020-07-31T00:51:26Z,"While testing cases related to #503 , it became apparent that for very small readsets (e..g, two reads) the default filtering parameter `-F` is too stringent. Values of `-F` smaller than approximately 0.001 produce no overlaps.

The right way to fix this is to properly handle repetitive minimizers. We could do this with a fixed mask, a weighting function like that used in WinnowMap, or by rearchitecting the sketch handling in cudamapper to function like MashMap. As a temporary fix, it might make sense to use a filtering parameter value scaled by the number of reads in the input data (probably growing 1 / (number of reads)^2, with a minimum of 2e-4). ",edawson,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/504,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NTczODMyODA=,[cudaaligner] Tests should load data from file,OPEN,2020-07-15T14:12:38Z,2020-07-15T14:12:38Z,,"cudaaligner's tests use hard coded test data. This data should be loaded from data file(s) instead (like cudamapper).


cudaaligner's hard coded data: https://github.com/clara-parabricks/GenomeWorks/blob/dev-v0.5.0/cudaaligner/tests/cudaaligner_test_cases.cpp

cudamapper's data and tests: https://github.com/clara-parabricks/GenomeWorks/tree/dev-v0.5.0/cudamapper/data and https://github.com/clara-parabricks/GenomeWorks/tree/dev-v0.5.0/cudamapper/tests",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/505,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NjE5NTI4ODY=,[cudamapper] Create public interface for overlapper,CLOSED,2020-07-20T15:27:22Z,2020-07-21T21:58:19Z,2020-07-21T21:58:19Z,"Similarly to other classes in public interface `Overlapper` should also have a `create_overlapper()` function.

For example see https://github.com/clara-parabricks/GenomeWorks/blob/dbf5b61e0bf11124d8de366e6a4292a36f7b6038/cudamapper/include/claraparabricks/genomeworks/cudamapper/matcher.hpp#L51",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/509,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NjQ4MzY1OTU=,[cudamapper] Create public interface for IndexDescriptor,CLOSED,2020-07-24T00:03:32Z,2020-07-24T18:57:21Z,2020-07-24T18:57:21Z,"As discussed in #508, the read grouping functionality of the IndexDescriptors is useful for creating batches for cudamapper. It should have an entry point to use in the public interface ",nvvishanthi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/514,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NjUxMzg4OTg=,[cudamapper] Expose print_paf() in public interface,CLOSED,2020-07-24T12:35:25Z,2020-08-03T19:22:57Z,2020-08-03T19:22:57Z,As discussed in #508 `print_paf()` should be moved from `cudamapper/src/cudamapper_utils.hpp` into a new file in `cudamapper/include/claraparabricks/genomeworks/cudamapper`,mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/516,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NjUxNDE0MTI=,[cudamapper] Expose IndexDescriptor in public interface,CLOSED,2020-07-24T12:40:11Z,2020-09-03T23:11:19Z,2020-09-03T23:11:19Z,"`IndexDescriptor` is currently not part of public interface. During implementation of cudamapper sample (#508. #340) it turned out that `IndexDescriptor` would be useful in other implementations of cudamapper as well.

Expose `IndexDescriptor` in public interface, probably in the same way e.g. `Matcher` is exposed.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/517,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2Njg5MTU0Nzk=,[cudapoa] unifying closely related numerous parameters related to POA graph length,CLOSED,2020-07-30T16:07:49Z,2020-07-31T15:53:02Z,2020-07-31T15:53:02Z,"Currently there are different variables that are closely related to graph length, such as `max_nodes_per_window`, `max_matrix_graph_dimension`, and their banded versions. It makes life much easier to deal with only one parameter instead.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/521,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2Njk5NTk5MDY=,[cudapoa] unify CUDA kernels in banded and adaptive NW ,CLOSED,2020-07-31T15:56:12Z,2020-11-05T03:22:26Z,2020-11-05T03:22:26Z,"there are multiple kernels in `cudapoa_nw_banded.cuh` and `cudapoa_nw_adaptive_banded.cuh` which are similar and with some effort can be unified and combined together. Merge them and have them in a separate file, such as `banded_nw_utils.cuh`",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/522,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NzE3NTk1NDU=,[cudamaper] Use events to sync generation and communication streams,OPEN,2020-08-03T03:00:32Z,2020-09-01T13:51:21Z,,"When creating indices in IndexCache synchronize generation and communication streams using events, not `cudaStreamSynchronize()`

Continuation of #318 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/524,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NzE3NjAxMzQ=,[cudamapper] Use stream callback functions to update Index state,OPEN,2020-08-03T03:02:32Z,2020-08-03T03:02:32Z,,"When copying indices from host to device use stream callback functions to update the state indices upon copy completion.

Continuation of #318 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/525,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NzE3NjA3NjM=,[cudamapper] Throw custom exception when Index not found,CLOSED,2020-08-03T03:04:56Z,2020-10-22T14:37:46Z,2020-10-22T14:37:45Z,"Throw custom exceptions when indices are not found in `IndexCache`.
Continuation of #318 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/526,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NzI4Njg5MDY=,[cudapoa] add description to error codes,CLOSED,2020-08-04T15:11:20Z,2020-12-04T02:56:05Z,2020-12-04T02:56:05Z,"currently we only print out the error code. It helps to have a description added. We can even for some cases, add hints about which corresponding parameters in `BatchConfig` object can be modified to fix the error.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/527,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NzMxNDMzNzc=,[cudapoa] consolidate macros for banded alignment in single header,OPEN,2020-08-04T23:21:41Z,2020-08-04T23:21:41Z,,"Right now the macros for banded alignment like CUDAPOA_BANDED_MATRIX_RIGHT_PADDING are not shared between the kernel code and other sources that determine sizes for bands (such as in batch.cu). For now they're hard coded to specific numbers, but this is error prone. This needs to be fixed to the macros are shared between files.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/528,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2NzMzODYzNTU=,[cudamapper] Do not do self-mapping of reads,OPEN,2020-08-05T09:14:37Z,2020-08-05T09:14:54Z,,"When doing all-vs-all do not look for anchors of reads with the same `read_id`. Currently we are doing this for the sake of code simplicity, but this introduces additional overlaps which probably affect accuracy and definitely affect performance by creating additional anchors which take up more space and require time to be processed.

There are two options:
1) Make `Matcher` not look for anchors with the same `read_id`
2) If `1)` turns out to be too complicated simply skip matching same indices. This would lead to all read pairs from those indices to be skipped, so option `1)` is preferred",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/531,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2ODE5NjU3NTg=,[cudamapper] Index should accept IndexDescriptor,CLOSED,2020-08-19T16:10:15Z,2020-09-15T00:27:03Z,2020-09-15T00:27:03Z,"Currently `Index`'s constructor accepts `first_read` and `number_of_reads` explicitly. Having it accept `IndexDescriptor` would be more elegant.

See discussion in #536 ",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/539,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2ODU0ODk5OTg=,[common] Rename device_copy_n to reflect non-blocking behavior,CLOSED,2020-08-25T13:32:52Z,2021-01-26T14:22:33Z,2021-01-26T14:22:33Z,"The version of `device_copy_n` which takes a CUDA stream argument
https://github.com/clara-parabricks/GenomeWorks/blob/74e6424c156a7ee15b4137d4788a4257ee6482c4/common/base/include/claraparabricks/genomeworks/utils/cudautils.hpp#L138
should be renamed to `device_copy_n_async` to make the non-blocking behavior more obvious.


The blocking three-argument version of `device_copy_n` should remain as is.",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/541,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2ODc5NjY2MTc=,[cudamapper] Small improvements to IndexGPU,CLOSED,2020-08-28T10:11:28Z,2020-08-28T15:45:35Z,2020-08-28T15:45:35Z,"While reviewing a PR I noticed
a) `cudaStreamSynchronize()` is missing a `GW_CU_CHECK_ERR` in
https://github.com/clara-parabricks/GenomeWorks/blob/d715ab18b9a704726350613b6bb248a741b0d9f3/cudamapper/src/index_gpu.cuh#L781

b) I think the block around the mentioned `cudaStreamSynchronize()`:
```
    cudautils::device_copy_n(merged_basepairs_h.data(), ...,  cuda_stream_); // H2D

    cudaStreamSynchronize(cuda_stream_);
    merged_basepairs_h.clear();
    merged_basepairs_h.shrink_to_fit();

    // sketch elements get generated here
    auto sketch_elements = SketchElementImpl::generate_sketch_elements(..., cuda_stream_);
```
could be changed to
```
    cudautils::device_copy_n(merged_basepairs_h.data(), ...,  cuda_stream_); // H2D

    // sketch elements get generated here
    auto sketch_elements = SketchElementImpl::generate_sketch_elements(..., cuda_stream_);

    cudaStreamSynchronize(cuda_stream_);
    merged_basepairs_h.clear();
    merged_basepairs_h.shrink_to_fit();
```
which could potentially allow for a bit more overlapping. @mimaric ?",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/543,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2ODkyNDU0ODc=,[cudapoa] reduce register count in cudapoa kernels,CLOSED,2020-08-31T14:19:42Z,2020-09-14T09:05:11Z,2020-09-14T09:05:11Z,The recent changes to banded and adaptive banded have increased the register count in cuda kernels and hence limited occupancy of the kernels. Investigate steps to keep the register count in check.,tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/547,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU2OTY1MjUxMTQ=,GenomeWorks compiling error,CLOSED,2020-09-09T07:27:34Z,2020-10-08T10:43:57Z,2020-10-08T10:43:57Z,"Hi!
I am working around two days trying to compile GenomeWorks which included into racon genome assembler.
GCC = 9.3.0
cmake = 3.18.20200908-g1d74a64
make = 4.3
nvcc = 11.0
cuDNN = 8.0.2
nvidia driver = 450.51.06

CMakeCache.txt was manually edited with including `CMAKE_CXX_FLAGS:STRING=-DFMT_USE_USER_DEFINED_LITERALS=0` string
the error occured whyle the most of work was done: 
`
[ 81%] Linking CXX static library ../../lib/libcudaaligner.a
Reaping winning child 0x55c2e3d8eaf0 PID 14870 
Live child 0x55c2e3d8eaf0 (lib/libcudaaligner.a) PID 14872 
Reaping winning child 0x55c2e3d8eaf0 PID 14872 
Live child 0x55c2e3d8eaf0 (lib/libcudaaligner.a) PID 14874 
Reaping winning child 0x55c2e3d8eaf0 PID 14874 
Removing child 0x55c2e3d8eaf0 PID 14874 from chain.
Considering target file 'GenomeWorks/cudaaligner/CMakeFiles/cudaaligner.dir/build'.
 File 'GenomeWorks/cudaaligner/CMakeFiles/cudaaligner.dir/build' does not exist.
  Considering target file 'lib/libcudaaligner.a'.
  File 'lib/libcudaaligner.a' was considered already.
 Finished prerequisites of target file 'GenomeWorks/cudaaligner/CMakeFiles/cudaaligner.dir/build'.
Must remake target 'GenomeWorks/cudaaligner/CMakeFiles/cudaaligner.dir/build'.
Successfully remade target file 'GenomeWorks/cudaaligner/CMakeFiles/cudaaligner.dir/build'.
Reaping winning child 0x558a0914daf0 PID 14802 
Live child 0x558a0914daf0 (GenomeWorks/cudaaligner/CMakeFiles/cudaaligner.dir/all) PID 14879 
[ 81%] Built target cudaaligner
Reaping winning child 0x558a0914daf0 PID 14879 
Removing child 0x558a0914daf0 PID 14879 from chain.
Reaping losing child 0x560a19aabcb0 PID 14245 
make: *** [Makefile:171: all] Error 2
Removing child 0x560a19aabcb0 PID 14245 from chain.
`

I updated cmake and make, but compilation still aborting.
I have no a great experience on C-like languages and compilation. May be I don't understand some configs or I have to change something in cmake-generated files?

I hope you can help me to find answers.
Thanks.",asan-emirsaleh,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/554,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDIxNzM3NDE=,[pygenomeworks] Support reading compressed PAF as input,OPEN,2020-09-15T18:55:39Z,2020-09-15T18:55:39Z,,"Currently, the evaluate_paf script in pygenomeworks (and the backing readers) require input to be raw text. However, we often use gzip-compressed PAF to save space, and miniasm natively supports reading it. It would be nice to modify our PAF reader to natively support gzipped PAF.",edawson,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/559,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDIxNzY0NTE=,[pygenomeworks] evalute_paf does not properly report the number of incorrect starts/ends,CLOSED,2020-09-15T18:59:57Z,2020-09-23T17:10:21Z,2020-09-23T17:10:21Z,"The evaluate_paf script in pygenomeworks/bin reports a number of correct query/target starts and ends. However, the numbers reported currently are not accurate, as each searched interval increments these variables:
https://github.com/clara-parabricks/GenomeWorks/blob/88dcc74b17a659e1baf21139920a41d9e0cac7f6/pygenomeworks/bin/evaluate_paf#L195-L198

The proper behavior should instead be to only report the correctness of starts/ends only for the best match.",edawson,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/560,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDY0MDU4ODE=,[cudapoa/cudaaligner] fix compute version to 60,CLOSED,2020-09-22T13:53:26Z,2020-12-03T20:38:12Z,2020-12-03T20:38:12Z,"Because of the perf issue observed in cudapoa and cudaaligner, the max compute version that gives best numbers is compute 60. Update the nvcc flags for cudapoa and cudaaligner to compile to compute 60 only. Accordingly, update GW readme to only support architectures beyond Pascal.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/566,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDY0MTMzNzQ=,[cudaextender] Add new cuadextender module to GW,CLOSED,2020-09-22T14:02:19Z,2020-10-01T22:19:28Z,2020-10-01T22:19:28Z,"This is a blanket issue for the following tasks

1. create a new API for cuda accelerated extension algorithms
2. port CUDA x drop algorithm by @gsneha26 and @yatisht into GenomeWorks
3. add tests and samples for the API and implementation",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/567,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDcxNjc4MDA=,[sdk] Update the way we fetch CUB,CLOSED,2020-09-23T08:41:43Z,2020-12-07T10:42:16Z,2020-12-07T10:42:16Z,"CUDA 11 ships with CUB, so there is no need to download it separately into `3rdparty` (unless for some reason we need another version)

For pre-CUDA 11, CUB has been moved under Nvidia organization on GitHub: https://github.com/NVIDIA/cub/. Old link still works, but we should update it for consistency.",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/570,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDc1NTI2MjE=,[pygenomeworks] evaluate_paf script is too slow to be practical for very large PAF files,OPEN,2020-09-23T17:34:33Z,2020-09-23T17:34:44Z,,"Despite updating the evaluate_paf script to handle queries better, the performance of the script is inadequate for large-scale CI jobs. 

One solution to this is to ditch the interval tree data structure and instead rely on sorted PAF input. For large PAF files, this may still take a significant amount of time, though it should significantly reduce the memory usage (requiring only two PAF records to be kept in memory at a time; currently, all truth set records are maintained in memory).

Another option would be to provide random access to bgzipped PAF files, either through TABIX or some other API.",edawson,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/571,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MDgyOTA5Mzk=,[cmake] move version file configuration into base,OPEN,2020-09-24T15:58:13Z,2020-09-24T15:58:13Z,,"The `version.cpp.in` file should be configured once as part of the base module, and all the modules should simply call into the `version.hpp` header. currently that file is being separately configured as part of cudapoa/cudamapper/etc. ",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/572,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTI5ODE2Mzg=,[cudaextender] Replace cudaextender's hardcoded encoding scheme with cudasequence,OPEN,2020-10-01T16:06:10Z,2020-10-01T19:30:20Z,,`cudaextender/src/ungapped_xdrop.cu` currently uses a hardcoded encoding scheme with fixed scoring matrices and a fixed alphabet. Replace that scheme with the generalized scheme that cudasequence will propose. ,atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/574,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTI5ODY1MTM=,[cudaextender] Check if entropy calculation can be done using a float.,OPEN,2020-10-01T16:12:38Z,2020-10-01T19:30:02Z,,Currently cudaextender uses doubles for entropy calculation during ungapped extension. Check the accuracy implications of moving the calculation to a float. ,atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/575,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTI5OTMyMTI=,[cudaextender] Calculate memory limits based on datastructures used.,OPEN,2020-10-01T16:21:36Z,2020-10-01T19:29:47Z,,"Currently element and memory limits are artifacts of hardcoded global memory limits in SegAlign. To be replaced with actual calculation of memory requirements with sizes of  datastructures taken into consideration. Also currently the max limit is based on total global memory, which should be replaced with memory available from the passed in allocator.",atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/576,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTI5OTc1NTg=,[cudaextender] Explore configurability of kernel launch parameters.,OPEN,2020-10-01T16:27:34Z,2020-10-01T19:29:33Z,,Currently cudaextender has hardcoded block and grid dimensions. Explore configurability of these based on size of workload. Also explore if these need to be exposed to the user for config. ,atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/577,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTMwMDE2MjQ=,[cudaextender] Make output compression async,OPEN,2020-10-01T16:33:04Z,2020-10-01T19:29:21Z,,Currently cudaextender's output compression is synchronous. Explore dynamic parallelism or kernel replacement for Thrust's stable sort for making the tail end of cudaextender truly async.,atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/578,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTMwNjI4MTY=,[cudaextender] Kernel optimizations,OPEN,2020-10-01T17:54:53Z,2020-10-01T18:00:40Z,,"Investigate kernel optimizations with:
-  code reuse 
-  hardcoded limit removal
-  removal of unnecessary operations like memset",atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/579,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTMxMjQ0OTE=,[cudaextender] Performance analysis,OPEN,2020-10-01T19:28:45Z,2020-10-01T19:29:07Z,,Investigate performance difference between native SegAlign implementation and cudaextender implementation of ungapped extension.,atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/580,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTMyMjk2NjQ=,[cudaextender] Update readme with cudaextender info,CLOSED,2020-10-01T22:40:08Z,2020-10-20T15:15:33Z,2020-10-20T15:15:33Z,Add cudaextender details to the main project's readme. ,atadkase,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/582,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTU4NjE4NjY=,[Documentation] Add code blocks instructions for dependencies setup,OPEN,2020-10-06T17:01:38Z,2020-10-06T17:01:53Z,,"Adding code blocks instructions to the README file for GenomeWorks setup steps to include both:
- Installing all dependencies through Anaconda.
- Installing all dependencies from source or the system package manager.",ohadmo,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/583,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTY1ODg4MjA=,[cudapoa] add tests for different band modes,CLOSED,2020-10-07T14:36:19Z,2020-12-02T16:57:10Z,2020-12-02T16:57:10Z,"there are different variations of NW algorithm (full-band, static-band, adaptive-band, traceback static and traceback adaptive bands). We need to add some tests for each case.",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/584,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MTc3MzgyMDM=,[docs] rework documentation for modules in GW,CLOSED,2020-10-08T23:33:11Z,2020-12-03T23:22:57Z,2020-12-03T23:22:57Z,"Move the documentation per module into respective module folders. i.e. add a new `README.md` file under each module such as `cudapoa` or `cudaextender` and add more detailed documentation regarding algorithm, features, limitations, etc in there.",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/586,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MjI1ODM5Mzc=,[cudapoa] overlapping vertical/diagonal update of score matrix with horizontal update,OPEN,2020-10-15T18:52:10Z,2020-10-15T18:52:10Z,,investigate overlapping vertical/diagonal update of score matrix in NW with horizontal update. A crude measurement on a short-read set indicated  up to 40% of the time can be spent on vertical/diagonal update.,r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/587,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MjU2OTczODA=,[cudamapper] bug in extracting kmers,CLOSED,2020-10-20T15:14:05Z,2020-12-03T19:05:46Z,2020-12-03T19:05:46Z,"[here](https://github.com/clara-parabricks/GenomeWorks/blob/dev-v0.6.0/cudamapper/src/cudamapper_utils.cpp#L49), the second argument of `std::substr` is length of the substring, not the end position. Should be changed from `i + kmer_size` to `kmer_size`",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/591,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3MzE1NzU3OTY=,How to install GenomeWorks on local machine?,OPEN,2020-10-28T15:58:44Z,2021-02-09T07:02:42Z,,"Hello everyone,
I am a research scholar, and I need to test GenomeWorks  on sample data. Could anyone please explain how to install and run on my system?
System details:
UBUNTU 18.0
6GB CUDA -enabled NVIDIA GTX 1660Ti
Intel core-i7 9th Gen
16GB RAM

Thanks in advance.",kountaydwivedi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/593,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3NDM5NzE2MDU=,"[common] DevicePreallocatedAllocator should allocate exactly the amount of memory requested, not more",CLOSED,2020-11-16T16:22:45Z,2020-11-30T17:55:03Z,2020-11-30T17:55:03Z,"`DevicePreallocatedAllocator` currently rounds up allocations to the next size divisible by 256. This comes from the property of `cudaMalloc()` that all its allocations are 256B-aligned (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses).
As a consequence of this if the last block in memory has e.g. 300 free bytes and 300B are requested those 300 requested bytes will be rounded up to 512B and the allocation will fail due to insufficient memory (for details see PR #598).
The property of aligning allocations to 256B should be kept, but their sizes should not be rounded up. The allocator should internally be aware that the remaining `((requested_size - 1) / 256 + 1) * 256 - requested_size` bytes are ""junk"".",mimaric,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/600,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3NTEzNDc4MjE=,terminate called after throwing an instance of 'std::runtime_error',OPEN,2020-11-26T07:14:35Z,2021-01-21T11:54:35Z,,"```
root@lt5h8:~/dataset/hg38-1# cudamapper -a 2 hg38-1.mut hg38.fa
-C / --target-indices-in-host-memory not set, using -Q / --query-indices-in-host-memory value: 10
-c / --target-indices-in-device-memory not set, using -q / --query-indices-in-device-memory value: 5
Query file: hg38-1.mut, number of reads: 25
Target file: hg38.fa, number of reads: 25
Programmatically looking for max cached memory
Using device memory cache of 16376457462 bytes
Device 0 took batch 1 out of 9 batches in total
Aligning 0 overlaps (0x0) with batch size 0
terminate called after throwing an instance of 'std::runtime_error'
  what():  Max alignments must be at least 1.
Aborted (core dumped)
```

What causes this problem and how to fix it??",bellstwohearted,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/603,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3NTE4NjE2MDE=,[cudapoa] throw an error in case all weights are zero,CLOSED,2020-11-26T23:15:16Z,2020-12-07T17:22:16Z,2020-12-07T17:22:16Z,"heavy-bundle algorithm in POA to generate consensus assumes non-zero base weights. We should check and throw an error in case this assumption is not satisfied, otherwise cudaPOA will potentially generate some incorrect consensus output (since all the paths have the same weight of 0).",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/604,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3NTM4NjQzNTg=,[cudapoa] make maximum number of edges per node configurable,OPEN,2020-11-30T22:58:37Z,2020-11-30T22:58:37Z,,"`CUDAPOA_MAX_NODE_EDGES` and `CUDAPOA_MAX_NODE_ALIGNMENTS` with default value of 50 defined in `cudapoa_structs.cuh` have a big impact on memory usage per POA. Consequently maximum number of POAs residing on GPU can increase by using smaller values for these two parameters. Changing these macros to template parameters allows achieving higher parallelism, particularly for processing long reads. 
As a rule of thumb, the value for these parameters should not exceed maximum number of reads per window. ",r-mafi,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/607,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3NjEzNDI5ODk=,[logging] reduce logging overhead,OPEN,2020-12-10T15:33:22Z,2020-12-11T15:10:55Z,,"Suggestions from @ahehn-nv -

1.
```
You could avoid the construction of the std::string by directly operating on the stream:

std::ostream& operator << (std::ostream& os, LogLevel level)
{
    switch(level)
    {
       case critical: os << ""CRITICAL""; break;
       ...
    }
    return os;
}
or, if you dislike overloading operators, a similar function void add_prefix(std::ostream& os, LogLevel level).
```
 
2.
```
We could actually base the whole logger on overloading << instead of macros and std::strings, providing a syntax like:

 log(LogLevel::debug) << ""here's some debug integer: "" << some_integer << std::endl;
Advantages:

common C++ syntax.
messages become almost no-ops if a higher logging level is selected.
Disadvantage:

more templates -> Slightly higher compilation times.
```",tijyojwad,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/616,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU3OTAzMzQ5MDY=,Can GenomeWorks work without CUDA? Can it work parallelize through MPI?,CLOSED,2021-01-20T21:24:56Z,2021-01-21T09:02:56Z,2021-01-21T09:02:56Z,,yurivict,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/619,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU4MDk1NDczNTg=,[cudaaligner] Disabled caching device-allocator may trigger OOM in cudaaligner,OPEN,2021-02-16T18:25:58Z,2021-02-16T18:25:58Z,,"AlignerGlobalMyersBanded's `reset_max_bandwidth(...)` runs out of device memory when the caching device-allocator is disabled at compilation. (This allocator is enabled by default.)
It is unclear if cudaaligner respects the `max_device_memory` setting passed at construction at all in this case.",ahehn-nv,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/630,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU4MTU0MDE4NDE=,format.h is broken and breaks CUDA compile,OPEN,2021-02-24T11:46:21Z,2021-02-25T14:39:10Z,,"There's a misplaced set of quotes in format.h file that prevents CUDA integration into RAVEN (error2 build fail).:

This showed up when I was trying to compile RAVEN for CUDA in </raven/build/_deps/genomeworks-src/3rdparty/spdlog/include/spdlog/fmt/bundled/format.h>

Pulled solution from here: https://www.gitmemory.com/issue/yuzu-emu/yuzu/2597/507715224

Changed Line 3475 from:
FMT_CONSTEXPR internal::udl_formatter<Char, CHARS...> operator""""_format() {

To (remove quotes):
FMT_CONSTEXPR internal::udl_formatter<Char, CHARS...> operator_format() {",cement-head,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/637,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU4ODExMDk5Nzg=,[pygenomeworks] pinned dependencies.,CLOSED,2021-05-08T17:51:16Z,2021-05-13T11:36:13Z,2021-05-13T11:36:13Z,"Hey all,

I'm looking to depend on `genomeworks-cuda-10-2` in `bonito` but the current set of pinned dependencies are too restrictive.

Specifically, the troubles are with the requirement on `numpy==1.16.3` and the use of [h5py](https://github.com/h5py/h5py/blob/3.1.0/setup.py#L28) and [cupy](https://github.com/cupy/cupy/blob/master/setup.py#L34).

",iiSeymour,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/647,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU4ODExNjY5NzA=,[pygenomeworks] logger chatter.,OPEN,2021-05-08T18:44:58Z,2021-05-18T12:47:08Z,,"When creating a `CudaPoaBatch` object a default logger is initialized and outputs to `stderr`.

```python
>>> from genomeworks.cudapoa import CudaPoaBatch
>>> CudaPoaBatch(1000, 1000, 3724032)
GenomeWorks logger not initialized yet. Initializing default logger now.
Initialized GenomeWorks logger with log level ERROR
```

Can the logger be initialized from Python with a stream to avoid this output?  
",iiSeymour,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/648,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU5MzEyODU2ODM=,How to fix cudaErrorInvalidDeviceFunction exception for cudamapper,CLOSED,2021-06-28T08:00:08Z,2021-07-09T08:36:24Z,2021-07-09T08:36:24Z,"Hi, 

When I ran ""cudamapper 1.fasta 2.fasta"", I met with an error ""cudaErrorInvalidDeviceFunction"". The screen shows below:
> Initialized GenomeWorks logger with log level ERROR
> -C / --target-indices-in-host-memory not set, using -Q / --query-indices-in-host-memory value: 10
> -c / --target-indices-in-device-memory not set, using -q / --query-indices-in-device-memory value: 5
> Query file: 1.fasta, number of reads: 1
> Target file: 2.fasta, number of reads: 1
> Programmatically looking for max cached memory
> Using device memory cache of 12493416039 bytes
> Device 0 took batch 1 out of 1 batches in total
> terminate called after throwing an instance of 'thrust::system::system_error'
>   what():  scan failed on 2nd step: cudaErrorInvalidDeviceFunction: invalid device function
> Aborted (core dumped)


Also, I tried to run the test cases for cudamapper, 19 tests failed with the below exception:

> ...
> [----------] 5 tests from TestCudamapperIndexCaching
> [ RUN      ] TestCudamapperIndexCaching.test_index_cache_same_query_and_target
> unknown file: Failure
> C++ exception with description ""scan failed on 2nd step: cudaErrorInvalidDeviceFunction: invalid device function"" thrown in the test body.
> [  FAILED  ] TestCudamapperIndexCaching.test_index_cache_same_query_and_target (20 ms)
> ...

My linux system is Ubuntu 21.04.
My GenomeWorks program is the lastest dev version (9fd8232). My cuda version is 11.3.  
My GPU is GTX 1080ti and arch flag for compilation is 6.1.
What should I do to fix the problem described above?",wzboy1984,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/655,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU5MzczNzUzNDU=,cudamapper error using bam output,OPEN,2021-07-05T21:33:13Z,2021-07-06T00:57:58Z,,"Hi folks,
I'm trying cudamapper with this command:
`/opt/GenomeWorks-2021.02.2/bin/cudamapper PAG33026_pass_concat.fastq.gz ../hg19a.fa -B > cudamapper_2021_02_02_GM24385.bam`

which outputs quite a lot of output to stdout/stderr, from which I have reported the unique lines below:
```
Initialized GenomeWorks logger with log level ERROR
-C / --target-indices-in-host-memory not set, using -Q / --query-indices-in-host-memory value: 10
-c / --target-indices-in-device-memory not set, using -q / --query-indices-in-device-memory value: 5
 Query file: PAG33026_pass_concat.fastq.gz, number of reads: 9983679
Target file: ../hg19a.fa, number of reads: 84
Programmatically looking for max cached memory
Using device memory cache of 24899308094 bytes
Device 0 took batch 1 out of 1790 batches in total
[E::sam_hrecs_update_hashes] Duplicate entry ""5"" in sam header
print_sam: could not add header value
[E::sam_hrecs_update_hashes] Duplicate entry ""5"" in sam header
print_sam: could not add header value
[E::sam_hrecs_update_hashes] Duplicate entry ""5"" in sam header
print_sam: could not add header value
...
[E::sam_hrecs_update_hashes] Duplicate entry ""19"" in sam header
print_sam: could not add header value
[E::sam_hrecs_update_hashes] Duplicate entry ""22"" in sam header
print_sam: could not add header value
[E::sam_hrecs_update_hashes] Duplicate entry ""5"" in sam header
print_sam: could not add header value
[E::bgzf_flush] File write failed (wrong size)
terminate called after throwing an instance of 'std::runtime_error'
  what():  ERROR, print_sam: could not write alignment
Aborted (core dumped)
```
In practise I think I get the ""Duplicate entry ""N"" "" error for each read that is processed.",RichardCorbett,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/656,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU5NzAyNzQ2MzQ=,Buils fails with gcc 9.3,CLOSED,2021-08-13T10:29:04Z,2021-08-17T08:17:08Z,2021-08-13T13:12:30Z,"Hi,

I tried to build racon and as part of it genomeworks is built. Per default I had gcc9.3 installed and the build of GenomeWorks failed. When I tried to build it separately from racon I had the same problem. I was able to install it nicely when switching back to gcc8. 

I got this error message:
09:55:56  [ 36%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/cudaaligner.cpp.o
09:55:56  [ 36%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/aligner_global_ukkonen.cpp.o
09:55:56  [ 38%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/aligner.cpp.o
09:55:56  [ 38%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/aligner_global.cpp.o
09:55:56  [ 38%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/alignment.cpp.o
09:55:56  [ 39%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/alignment_impl.cpp.o
09:55:56  [ 39%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/aligner_global_myers.cpp.o
09:55:56  [ 40%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/ukkonen_cpu.cpp.o
09:55:56  [ 40%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/aligner_global_myers_banded.cpp.o
09:55:56  [ 40%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/aligner_global_hirschberg_myers.cpp.o
09:55:56  [ 42%] Building CXX object cudaaligner/CMakeFiles/cudaaligner.dir/src/needleman_wunsch_cpu.cpp.o
09:56:00  [ 43%] Linking CXX static library libcudaaligner.a
09:56:00  [ 43%] Built target cudaaligner
09:56:39  Scanning dependencies of target cudapoa
09:56:39  [ 45%] Building CXX object cudapoa/CMakeFiles/cudapoa.dir/src/cudapoa.cpp.o
09:56:39  [ 45%] Building CXX object cudapoa/CMakeFiles/cudapoa.dir/version.cpp.o
09:56:39  [ 45%] Linking CXX static library libcudapoa.a
09:56:39  [ 45%] Built target cudapoa
09:56:39  Makefile:162: recipe for target 'all' failed
09:56:39  make: *** [all] Error 2

Unfortunately, I cannot easily extract the Makefile for these builds as I am building singularity images in a build pipeline. 

Dominik",dominik-handler,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/660,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU5OTIzMTU2MTE=,Floating Point Exception in Racon,OPEN,2021-09-09T14:46:13Z,2021-09-09T14:46:13Z,,"Hi,

Thanks for great software. Running latest version of racon (commit b591b12c22539948782704446989893bde826a29) and hitting a floating point exception on GPU, but CPU works. The racon authors [directed me here](https://github.com/lbcb-sci/racon/issues/58#issuecomment-915875871). Thanks for your help!

I'm attaching what I hope is a reproducible example. [racon_debug.zip](https://github.com/lbcb-sci/racon/files/7117517/racon_debug.zip)

```
root@a5698f05c7c3:/data/racon_trouble# racon -m 8 -x -6 -g -8 -w 500 --include-unpolished -t 4 --cudapoa-batches 1 --cudaaligner-batches 4 --cuda-banded-alignment filtered.fastq output.paf polished-input.fa
Using 1 GPU(s) to perform polishing
Initialize device 0
[CUDAPolisher] Constructed.
[racon::Polisher::initialize] loaded target sequences 0.000033 s
[racon::Polisher::initialize] loaded sequences 0.006921 s
[racon::Polisher::initialize] loaded overlaps 0.001669 s
GPU 0: Aligning with band width 68
[racon::CUDAPolisher::initialize] allocated memory on GPUs for alignment 0.989071 s
Alignment skipped by GPU: 415 / 921
[racon::Polisher::initialize] aligning overlaps [====================] 0.035475 s
[racon::Polisher::initialize] transformed data into windows 0.001138 s
[racon::CUDAPolisher::polish] allocated memory on GPUs for polishing 1.352416 s
Floating point exception (core dumped)
```
",schorlton,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/662,NVIDIA-Genomics-Research++GenomeWorks.csv
I_kwDOC02oTc47gU4g,Build fails with gcc 7 and 8,CLOSED,2021-09-16T15:11:32Z,2021-09-17T12:18:50Z,2021-09-17T12:18:50Z,"Hi!
I am attempting to build GenomeWorks but it crashes with the following errors.

After `make -j install`:

[ 44%] Built target cudapoa
Makefile:162: recipe for target 'all' failed
make: *** [all] Error 2

Then, I try just `make` and see this one (I also see ith with `make -j` but further up.

/home/dennistpw/packages/GenomeWorks/3rdparty/spoa/src/simd_alignment_engine.cpp:12:14: fatal error: immintrin.h: No such file or directory
     #include <immintrin.h> // AVX2 and lower
              ^~~~~~~~~~~~~
compilation terminated.
3rdparty/spoa/CMakeFiles/spoa.dir/build.make:110: recipe for target '3rdparty/spoa/CMakeFiles/spoa.dir/src/simd_alignment_engine.cpp.o' failed
make[2]: *** [3rdparty/spoa/CMakeFiles/spoa.dir/src/simd_alignment_engine.cpp.o] Error 1
CMakeFiles/Makefile2:413: recipe for target '3rdparty/spoa/CMakeFiles/spoa.dir/all' failed
make[1]: *** [3rdparty/spoa/CMakeFiles/spoa.dir/all] Error 2
Makefile:162: recipe for target 'all' failed
make: *** [all] Error 2

I saw on another issue that it may be compiler issue so I switch between gcc/g++ 7 and 8, and no luck.

I ran `make VERBOSE=1 2>&1 | tee verbose_build.log` and have attached the logs below if that would be more useful!

Versions:
- `Ubuntu 18.04.5 LTS (GNU/Linux 4.9.253-tegra aarch64)`
- `Python 3.6.9`
- `CUDA Version 10.2.300`
- `cmake version 3.10.2`
- GPU generation Volta
- autoconf and automake both installed

Any help would be greatly appreciated, thank you! :)

[verbose_build.log](https://github.com/clara-parabricks/GenomeWorks/files/7178957/verbose_build.log)
",tristanpwdennis,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/663,NVIDIA-Genomics-Research++GenomeWorks.csv
I_kwDOC02oTc47puM2,cudamapper terminates while doing an all-vs-all mapping,OPEN,2021-09-20T10:13:14Z,2021-09-20T10:13:14Z,,"I'm trying to do an all-vs-all mapping with cudamapper (dev branch, git-baab5668) and it terminates with an exception:

```console
$ cudamapper SRR.unmapped.choped.fastq.gz SRR.unmapped.choped.fastq.gz
Initialized GenomeWorks logger with log level ERROR
-C / --target-indices-in-host-memory not set, using -Q / --query-indices-in-host-memory value: 10
-c / --target-indices-in-device-memory not set, using -q / --query-indices-in-device-memory value: 5
NOTE - Since query and target files are same, activating all_to_all mode. Query index size used for both files.
Query file: SRR.unmapped.choped.fastq.gz, number of reads: 249455
Target file: SRR.unmapped.choped.fastq.gz, number of reads: 249455
Programmatically looking for max cached memory
Using device memory cache of 33390691615 bytes
Device 0 took batch 1 out of 1 batches in total
terminate called without an active exception
Aborted
```

Environment is CentOS 7 with an NVIDIA Tesla V100-PCIE-32GB. Thank you!",alanorth,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/664,NVIDIA-Genomics-Research++GenomeWorks.csv
I_kwDOC02oTc475z5D,[cudamapper] compared to minimap2,OPEN,2021-09-23T04:44:12Z,2021-09-23T04:44:12Z,,"Hi,

I've tried doing alignment by cudamapper over 3 datasets, and compared to that by minimap2. 
The time costs don't reduce much when compared to minimap2. In some cases, the running speeds of cudamapper are slower than minimap2, as shown in the below table.

 | Name | wall time(s) | mem peak(G) | note
-- | -- | -- | -- | --
data 1 | cudamapper | 650.63 | 10.87 | v100, 16G
 | minimap2_v2.20 | 1687.86 | 31.53 | -t 32 -k 17 -w 17 -x ava-ont
data 2 | cudamapper | 11193 | 39.76 | v100, 16G
 | minimap2_v2.20 | 4491 | 19.21 | -t 32 -k 17 -w 17 -x ava-ont
data 3 | cudamapper | 5958 | 27.4 | NVIDIA TITAN xp, 12G
 | minimap2_v2.20 | 4590 | 54.02 | -t 32-x ava-ont

Also, the sensitivity of the cudamapper alignments is lower than that of minimap2, which leads to the poorer assembly results based on cudamapper alignments of the 3 above datasets. The algorithm of cudamapper might need to be modified to get alignment results similar to minimap2. 
",wzboy1984,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/665,NVIDIA-Genomics-Research++GenomeWorks.csv
I_kwDOC02oTc5EohQj,[cudapoa] Kernel error,OPEN,2022-02-26T08:32:32Z,2022-02-26T08:32:32Z,,"Hello,
I tried updating GenomeWorks inside Racon from v0.5.3 to v2021.02.2 (and even v2021.02.0), and get kernel errors while using `BandMode::full_band` (only cudapoa is enabled, without bands):

`_deps/genomeworks-src/cudapoa/src/cudapoa_batch.cuh:451] Kernel Error: Traceback in Needleman-Wunsch algorithm failed. in batch 8
Suggestion  : You may retry with a different banding mode.`

Got any suggestions what could be causing this? I have two tests with the same data, one [with](https://github.com/lbcb-sci/racon/blob/master/test/racon_test.cpp#L454-L470) QV the other [without](https://github.com/lbcb-sci/racon/blob/master/test/racon_test.cpp#L472-L488), and the first one finishes successfully while the other yields the error above and the process hangs.

Thank you and best regards,
Robert",rvaser,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/666,NVIDIA-Genomics-Research++GenomeWorks.csv
I_kwDOC02oTc5vsAXA,GenomeWorks fails to compile with CUDA 12,OPEN,2023-08-30T14:30:06Z,2024-09-23T18:50:15Z,,"I'm trying to compile GenomeWorks using the lastest CUDA version, and there seem to be some breaking changes in thrust that generates some compilation errors, here are the errors reported when doing `make -j install`:

```
In file included from /home/qaguado/GenomeWorks/cudaaligner/src/batched_device_matrices.cuh:25,                                                                                                            
                 from /home/qaguado/GenomeWorks/cudaaligner/src/ukkonen_gpu.cu:18:                                                                                                                         
/home/qaguado/GenomeWorks/common/base/include/claraparabricks/genomeworks/utils/pinned_host_vector.hpp:23:10: fatal error: thrust/system/cuda/experimental/pinned_allocator.h: No such file or directory   
   23 | #include <thrust/system/cuda/experimental/pinned_allocator.h>                                                                                                                                      
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                      
compilation terminated.                                                                                                                                                                                    
In file included from /home/qaguado/GenomeWorks/cudaaligner/src/batched_device_matrices.cuh:25,                                                                                                            
                 from /home/qaguado/GenomeWorks/cudaaligner/src/hirschberg_myers_gpu.cuh:20,                                                                                                               
                 from /home/qaguado/GenomeWorks/cudaaligner/src/hirschberg_myers_gpu.cu:17:                                                                                                                
/home/qaguado/GenomeWorks/common/base/include/claraparabricks/genomeworks/utils/pinned_host_vector.hpp:23:10: fatal error: thrust/system/cuda/experimental/pinned_allocator.h: No such file or directory   
   23 | #include <thrust/system/cuda/experimental/pinned_allocator.h>                                                                                                                                      
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                      
compilation terminated.                                                                                                                                                                                    
CMake Error at cudaaligner_generated_ukkonen_gpu.cu.o.Release.cmake:220 (message):                                                                                                                         
  Error generating                                                                                                                                                                                         
  /home/qaguado/GenomeWorks/build/cudaaligner/CMakeFiles/cudaaligner.dir/src/./cudaaligner_generated_ukkonen_gpu.cu.o
```

I tried to fix the error by doing the following changes in `/common/base/include/claraparabricks/genomeworks/utils/pinned_host_vector.hpp` (from [this NVIDIA forum answer](https://forums.developer.nvidia.com/t/thrust-pinned-memory-in-cuda-12-0/242093/3)):

``` c++
// ...

//#include <thrust/system/cuda/experimental/pinned_allocator.h>
#include <thrust/system/cuda/memory_resource.h>
#include <thrust/mr/allocator.h>
#include <thrust/system/cpp/memory.h>

// ...

//using pinned_host_vector = std::vector<T, thrust::system::cuda::experimental::pinned_allocator<T>>;
template <typename T>
using pinned_host_vector = std::vector<T, thrust::mr::stateless_resource_allocator<T, thrust::cuda::universal_host_pinned_memory_resource>>;
```

But it still fails with the following error:

```
/usr/include/c++/9/bits/alloc_traits.h:556:25: error: no matching function for call to __do_alloc_on_move(thrust::mr::stateless_resource_allocator<claraparabricks::genomeworks::cudaaligner::batched_devi
ce_matrices<unsigned int>::device_interface, thrust::system::cuda::detail::cuda_memory_resource<cudaMallocHost, cudaFreeHost, thrust::pointer<void, thrust::cuda_cub::tag, void, thrust::use_default> > >&, thrust::mr::stateless_resource_allocator<claraparabricks::genomeworks::cudaaligner::batched_device_matrices<unsigned int>::device_interface, thrust::system::cuda::detail::cuda_memory_resource<cudaMallocHost, cudaFreeHost, thrust::pointer<void, thrust::cuda_cub::tag, void, thrust::use_default> > >&, __pocma)
```

Are there any plans to make GenomeWorks compatible with CUDA 12?

Thanks",quim0,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/668,NVIDIA-Genomics-Research++GenomeWorks.csv
I_kwDOC02oTc6N-AqD,"#include ""seqio.h"" //TODO add this to 3rdparty",OPEN,2024-06-29T16:25:33Z,2024-06-29T16:25:33Z,,"<img width=""185"" alt=""image"" src=""https://github.com/NVIDIA-Genomics-Research/GenomeWorks/assets/66343484/e897beb4-eb1c-4065-9f7b-3d422ce481c2"">

What does TODO mean? When I compile, it shows that there is no seqio.h file. How can I solve this problem?",CTForGitHub,https://github.com/NVIDIA-Genomics-Research/GenomeWorks/issues/670,NVIDIA-Genomics-Research++GenomeWorks.csv
MDU6SXNzdWU5MjQ1NDc0MTU=,Typo in binder/start script,CLOSED,2021-06-18T05:10:00Z,2022-01-10T08:04:59Z,2022-01-10T08:04:59Z,"export SPAKR_DRIVER_MAXRESULTSIZE=4G

This should be:
export SPARK_DRIVER_MAXRESULTSIZE=4G",pwrose,https://github.com/sbl-sdsc/mmtf-genomics/issues/29,sbl-sdsc++mmtf-genomics.csv
I_kwDOIJbMPc59zLuV,Using chrR ref genome with STAR,OPEN,2024-01-31T17:06:06Z,2024-11-16T22:24:43Z,,"Hi,
Thank you for putting these reference genomes together! They've been very helpful for my work.

I'd like to use hg38-rDNA_v1.0.fa to map an RNAseq dataset using STAR. How should the annotation file, hg38-rDNA_v1.0.bed, be adapted for compatibility with STAR's .gtf format?

Best",LucasMcNU,https://github.com/vikramparalkar/rDNA-Mapping-Genomes/issues/1,vikramparalkar++rDNA-Mapping-Genomes.csv
I_kwDOIJbMPc6WRDY_,Some rRNA not mapped to the reference genome,OPEN,2024-09-12T00:21:02Z,2024-09-26T00:51:29Z,,"Dear team;
Thanks for providing those wonderful reference genome. It helps me a lot in my research. I met a problem that many of my reads could mapped to rrna region but was classified to not aligned when using bowtie2 alignment. Here is the details:
I used  `bowtie2     -x rRNA_mm10_reference_genome/bowtie2_index/rRNA     -U ../clean_Sample_1_R1.fastq.gz   -S rRNA_trash.sam   --un mrna_sample1.fastq` And I assume unmapped as normal mrna. 
 For the next step, I put the unmapped reads to STARaligner, and got the mapped mrna reads. 
```
STAR --genomeDir reference_genome/mm10_Gencode_STAR \
	--runThreadN 40 \
	--readFilesIn mrna_sample1.fastq \
	--outFileNamePrefix sample1_mRNA_R1 \
	--outSAMtype BAM SortedByCoordinate
```
Later, I used feature count to get the count matrix `featureCounts -a gencode.vM10.annotation.gtf -g gene_name -o count_sample1_R1_ds sample1_mRNA_R1Aligned.sortedByCoord.out.bam` And I found there are huge numbers of Rn18s-rs5 gene, which is a typical 18s rRNA. But it show up in the mrna files (All rRNA should be filter out) that should not contain any rRNA. I double check those reads  in the genome browser(IGV) and majority of them does not have splice sites. Could you help me check this issue? Thanks a lot.
Yuchen",Xuyuch,https://github.com/vikramparalkar/rDNA-Mapping-Genomes/issues/2,vikramparalkar++rDNA-Mapping-Genomes.csv
MDU6SXNzdWU0MzU5NjIxNzI=,implement snp,OPEN,2019-04-23T01:54:15Z,2019-04-23T01:54:15Z,,,darlliu,https://github.com/darlliu/genomestore/issues/1,darlliu++genomestore.csv
MDU6SXNzdWU0MzU5NjIxOTA=,implement gene,OPEN,2019-04-23T01:54:20Z,2019-04-23T01:54:20Z,,,darlliu,https://github.com/darlliu/genomestore/issues/2,darlliu++genomestore.csv
MDU6SXNzdWU0MzU5NjIyNzQ=,refactor the code to be more data driven,OPEN,2019-04-23T01:54:46Z,2019-04-23T01:54:46Z,,,darlliu,https://github.com/darlliu/genomestore/issues/3,darlliu++genomestore.csv
MDU6SXNzdWU0MzU5NjIzNDQ=,write more test cases,OPEN,2019-04-23T01:55:10Z,2019-04-23T01:59:43Z,,,darlliu,https://github.com/darlliu/genomestore/issues/4,darlliu++genomestore.csv
MDU6SXNzdWU0MzU5NjI0NTE=,add loader for refGene and clinicVar (python layer),OPEN,2019-04-23T01:55:48Z,2019-04-23T01:55:48Z,,,darlliu,https://github.com/darlliu/genomestore/issues/5,darlliu++genomestore.csv
MDU6SXNzdWU0MzU5NjI2MzU=,scope out the basic functionalities of the library,OPEN,2019-04-23T01:56:55Z,2019-04-23T01:56:55Z,,"1. retrieval
2. matching snp profile
3. basic statistics 
4. some ML related stuff
5. viz",darlliu,https://github.com/darlliu/genomestore/issues/6,darlliu++genomestore.csv
MDU6SXNzdWUxNjM1MTAyNjc=,GFF and PTT parsers confused,OPEN,2016-07-02T09:23:03Z,2016-07-02T09:23:03Z,,"The enclosed GFF file is confused by the parser detection as PTT rather than GFF.

The cause is the double dot in the identifier of the contig.

[reproduce.zip](https://github.com/AbeelLab/genomeview/files/344475/reproduce.zip)
",thomasabeel,https://github.com/GenomeView/genomeview/issues/1,GenomeView++genomeview.csv
MDU6SXNzdWUzNTU1MjMxNjc=,All features from a BED file show as 'CDS' after tabbix indexing,OPEN,2018-08-30T10:28:49Z,2018-09-03T08:36:56Z,,"Compressed BED file with `bgzip `   
Indexing:   
```
tabbix -S 1 -p bed bed_file.gzip
```
All features will now be labeled as ""CDS"" instead of with the trackname or filename.

Uncompressed BED files will be shown correctly.",thpar,https://github.com/GenomeView/genomeview/issues/4,GenomeView++genomeview.csv
I_kwDOAxda1c5VOHDI,maf genome position ,OPEN,2022-10-31T12:25:38Z,2022-11-11T08:14:14Z,,"Hi, thanks for providing this useful tool.
It seems a small bug in genome position of maf
```
##maf version=1 
a score=262.0
s Xenopus_tropicalis.chr5           29721 13 + 164033575 CCCCCCGTTTGTT
s Ambystoma_mexicana.chr8q      150634379 13 + 886375962 TAATTCCTTTCTC
s Andrias_davidianus.ptg000471l   1972369 13 +   2026336 CCTTCTGCTTTCC
s Hynobius_yiwuensis.Contig128   31709499 13 -  45235456 CTTTTTAATTTCC
```
The corresponding result is 
![image](https://user-images.githubusercontent.com/38097726/199006968-e9815bf0-b549-4dca-9a1d-d5fd4fc192dd.png)

For example, the genomic position of Xenopus tropicalis should be 29722~29734 (13 bp).
",AlisaGU,https://github.com/GenomeView/genomeview/issues/6,GenomeView++genomeview.csv
I_kwDOD5u-Rs5HvKk5,Temp folder need to specify,OPEN,2022-04-13T16:45:47Z,2022-04-13T16:45:47Z,,"When using parallel to users need to specify a temp folder in there user directories and export the temp file.
Otherwise there will be error whenever the default temp is full and cannot write.

```
mkdir -p ${HOME}/temp
export TMPDIR=""${HOME}/temp""
```

above need to be specify in the 01_fasterq_dump.sh and the following in everyother script with uses parallel
`export TMPDIR=""${HOME}/temp""`",golden75,https://github.com/CBC-UCONN/RNA-seq-with-reference-genome-and-annotation/issues/1,CBC-UCONN++RNA-seq-with-reference-genome-and-annotation.csv
I_kwDOD5u-Rs5ICRV0,SRAtools intialize,OPEN,2022-04-19T15:54:06Z,2022-04-19T15:54:06Z,," before using sratoolkit/2.11.3, need to set up the configuration for the temp folder",golden75,https://github.com/CBC-UCONN/RNA-seq-with-reference-genome-and-annotation/issues/2,CBC-UCONN++RNA-seq-with-reference-genome-and-annotation.csv
I_kwDOD5u-Rs5P7B7C,add cityscape stuff,OPEN,2022-08-16T20:58:13Z,2022-08-16T20:58:13Z,,"per jill, add genemania and stringdb?",nreid,https://github.com/CBC-UCONN/RNA-seq-with-reference-genome-and-annotation/issues/3,CBC-UCONN++RNA-seq-with-reference-genome-and-annotation.csv
I_kwDOD5u-Rs5QSsFa,easy teaching purpose for align.sh ,OPEN,2022-08-22T22:38:17Z,2022-08-22T22:38:17Z,,"Change the SLURM header from
#SBATCH --array=[0-18]%5
to 
#SBATCH --array=[1-19]%5.  Per learning purpose.

So NUM=$(expr ${SLURM_ARRAY_TASK_ID} + 1)

will be just
NUM=${SLURM_ARRAY_TASK_ID} 

",golden75,https://github.com/CBC-UCONN/RNA-seq-with-reference-genome-and-annotation/issues/4,CBC-UCONN++RNA-seq-with-reference-genome-and-annotation.csv
I_kwDOD5u-Rs5YNeRH,Module updates,OPEN,2022-12-06T19:04:53Z,2022-12-15T15:27:38Z,,- update sratoolkit to sratoolkit/3.0.1  - newer version avoids running program for configuration,mianahom,https://github.com/CBC-UCONN/RNA-seq-with-reference-genome-and-annotation/issues/5,CBC-UCONN++RNA-seq-with-reference-genome-and-annotation.csv
MDU6SXNzdWU4MTEzMjcyMzM=,Images,CLOSED,2021-02-18T17:51:23Z,2021-02-18T17:54:11Z,2021-02-18T17:54:11Z,"![Pipeline_Scheme](https://user-images.githubusercontent.com/7016350/108399339-9cf6d580-71df-11eb-97ad-cf0366fddd02.jpg)
",cfarkas,https://github.com/cfarkas/annotate_my_genomes/issues/2,cfarkas++annotate_my_genomes.csv
I_kwDODMnPJc4-1KPR,dyld: Library not loaded: @rpath/libcrypto.1.0.0.dylib,OPEN,2021-11-15T21:37:29Z,2021-11-15T21:40:55Z,,"The following error appear when I used genome-download-macOSX:

dyld: Library not loaded: @rpath/libcrypto.1.0.0.dylib
  Referenced from: /opt/miniconda3/envs/annotate_my_genomes/bin/samtools
  Reason: image not found
./genome-download-macOSX: line 70:  9356 Abort trap: 6           samtools faidx ${genome}.fa

please help
Amella

",andymella,https://github.com/cfarkas/annotate_my_genomes/issues/3,cfarkas++annotate_my_genomes.csv
I_kwDODMnPJc6HqD0C,"Error: Too many positional arguments (1), the offending value: -",OPEN,2024-05-02T16:23:03Z,2024-05-02T16:23:03Z,,"Hello,

I try to annotate my transcripts with annotated genome. I think your workflow is perfect for my purpose. However, I ran into the following error during the `process > feelnc_annotation`.

`
Error: Too many positional arguments (1), the offending value: -
Error:  (CArgException::eSynopsis) Too many positional arguments (1), the offending value: -
`
Can you guide me where to find the `blastx` script to fix `-`

![Screenshot 2024-05-02 at 12 21 11PM](https://github.com/cfarkas/annotate_my_genomes/assets/42744112/52322b1a-5c3d-4728-bc0a-0fca2e2d808f)
![Screenshot 2024-05-02 at 12 20 13PM
](https://github.com/cfarkas/annotate_my_genomes/assets/42744112/2d7eb1dc-73b0-45dd-bcd0-bebe9f332f12)
",chenyanniii,https://github.com/cfarkas/annotate_my_genomes/issues/5,cfarkas++annotate_my_genomes.csv
MDU6SXNzdWUyMDc0MjM5MzE=,Error messages at Step1Preprocess.R,OPEN,2017-02-14T05:45:21Z,2017-02-14T05:45:21Z,,"At line 192, I received the error message indicating ""in correct number of subscripts on matrix"" (see attached screenshot). Could you please help fix this problem? Thanks! -James

![untitled](https://cloud.githubusercontent.com/assets/3751222/22916793/6f15bd6a-f246-11e6-9c93-91f477e5e8da.png)
",jamesjcai,https://github.com/dhglab/Genome-wide-changes-in-lncRNA-alternative-splicing-and-cortical-patterning-in-autism/issues/1,dhglab++Genome-wide-changes-in-lncRNA-alternative-splicing-and-cortical-patterning-in-autism.csv
MDU6SXNzdWU0MDYxODQyODk=,RData files,CLOSED,2019-02-04T05:12:47Z,2019-02-04T05:33:16Z,2019-02-04T05:33:16Z,The Rdata files ASD_RNAseq_ExpressionData are not found in the /data folder. Can you pl upload them ?,akatav,https://github.com/dhglab/Genome-wide-changes-in-lncRNA-alternative-splicing-and-cortical-patterning-in-autism/issues/2,dhglab++Genome-wide-changes-in-lncRNA-alternative-splicing-and-cortical-patterning-in-autism.csv
I_kwDOBEfBx86C53-X,"Error message with ""GC18unionAnno.Rdata"" file",OPEN,2024-03-19T23:08:33Z,2024-03-19T23:08:33Z,,"Hello! I got an error message when trying to load this RData file: ""GC18unionAnno.Rdata"" in the Pre Processing R code and indeed the file is really small (5kB)... I guess this old file was removed . Where could I find an alternative one for the replication of the analysis?  Thank you very much! ",dubucalma,https://github.com/dhglab/Genome-wide-changes-in-lncRNA-alternative-splicing-and-cortical-patterning-in-autism/issues/3,dhglab++Genome-wide-changes-in-lncRNA-alternative-splicing-and-cortical-patterning-in-autism.csv
I_kwDOGiQZ6s5ir0yy,5 mouse genes cause errors referencing very large genes on the same chromosome,OPEN,2023-04-05T13:47:32Z,2023-07-27T15:04:54Z,,"used mouse genome 12-column BED file: 
mm10 from UCSC as gzip https://genome.ucsc.edu/cgi-bin/hgTables assembly:mm10 -> track:NCBI RefSeq -> table:refFlat; output format: BED

error genes

- Ccl19 -> chr4:42,754,525-42,756,543 2,019 bp
- Ccl21a -> chr4:42,772,860-42,773,993 1,134 bp
- Ccl21c -> chr4:42,612,123-42,613,253 1,131 bp
- Il11ra2 -> chr4:42,656,001-42,665,763 9,763 bp
- Rarres2 -> chr6:48,546,630-48,549,721 3,092 bp

Mdn1 pops up in all Chr4 error messages:
chr4:32,657,119-32,775,217
118,099 bp

Sspo pops up in Rarres2 (on Chr6) error message
chr6:48,425,163-48,478,169
53,007 bp

Ccl19 (error)
chr4:42,754,525-42,756,543
2,019 bp

Cxcl17 not correctly displayed! no gene not correct coordinates
chr7:25,099,478-25,112,311
12,834 bp

Ccl17 completely fine
chr8:95,537,081-95,538,664
1,584 bp

[https://www.informatics.jax.org/marker/MGI:109123](https://www.informatics.jax.org/marker/MGI:109123)

[https://genome.ucsc.edu/cgi-bin/hgTracks?db=mm39&lastVirtModeType=default&lastVirtModeExtraState=&virtModeType=default&virtMode=0&nonVirtPosition=&position=chr6%3A48425163-48478169&hgsid=1597741285_OPZS1OsEmzcw5yAStALoyZTLcBbj](https://genome.ucsc.edu/cgi-bin/hgTracks?db=mm39&lastVirtModeType=default&lastVirtModeExtraState=&virtModeType=default&virtMode=0&nonVirtPosition=&position=chr6%3A48425163%2D48478169&hgsid=1597741285_OPZS1OsEmzcw5yAStALoyZTLcBbj)",sreichl,https://github.com/epigen/genome_tracks/issues/1,epigen++genome_tracks.csv
I_kwDOGiQZ6s5swLUe,consider switching to ggcoverage package,CLOSED,2023-07-27T15:01:28Z,2024-03-13T14:04:56Z,2024-03-13T14:04:55Z,"- https://cran.r-project.org/web/packages/ggcoverage/index.html
- https://cran.r-project.org/web/packages/ggcoverage/vignettes/ggcoverage.html#3_RNA-seq_data",sreichl,https://github.com/epigen/genome_tracks/issues/2,epigen++genome_tracks.csv
I_kwDOGiQZ6s5swLi7,consider adding IGV-Reports (self-contained HTML) Snakemake wrapper,CLOSED,2023-07-27T15:01:59Z,2024-03-14T18:04:48Z,2024-03-14T18:04:48Z,"- https://snakemake-wrappers.readthedocs.io/en/stable/wrappers/igv-reports.html
- https://github.com/igvteam/igv-reports
- If I understand correctly you can create one report summarizing all samples, which would be great
- [x] try it manually on one test example, if easy -> implement.
  - in bioconda: https://bioconda.github.io/recipes/igv-reports/README.html",sreichl,https://github.com/epigen/genome_tracks/issues/3,epigen++genome_tracks.csv
I_kwDOGiQZ6s5swMYB,change input to CSV instead of txt file,CLOSED,2023-07-27T15:03:52Z,2024-03-13T17:04:47Z,2024-03-13T17:04:47Z,"- consider gene/region input as csv
- first column gene/region
- second column ymax/"" (then remove from config)  then its at least configurable on a gene/region level  can be extracted like DEA parameters in dea_limma workflow
- ymax parameter: have in addition to ""==auto also ""max which determines the max value across all to be plotted and uses that as ymax  not possible, because that is not known before",sreichl,https://github.com/epigen/genome_tracks/issues/4,epigen++genome_tracks.csv
I_kwDOGiQZ6s5xPOjE,make output format configurable,CLOSED,2023-09-17T15:16:35Z,2023-09-19T13:09:10Z,2023-09-19T13:09:10Z,"from the docs: The file type of the plot will be determined by the output file extension.

currently hard coded: .svg
extend to: .png and .pdf",sreichl,https://github.com/epigen/genome_tracks/issues/5,epigen++genome_tracks.csv
I_kwDOGiQZ6s5-hjHZ,check & provide instructions for single cell modalities,CLOSED,2024-02-07T10:43:04Z,2024-03-18T16:46:27Z,2024-03-18T16:46:27Z,"should also work for scRNA-seq and scATAC-seq data/samples that gets grouped and merged by metadata

- [x] works in principle, need to find a way to differentiate between normal and single cell bams in rule `sc_bams`
- [x] I have to turn the order for single cell around
  - [x] First split per sample into sample/group.bam
  - [x] Then merge the same groups together and put into merged_band and take from there as before. 
  - [x] So, when single cell. Then preprocessing step with sinto. 
  - [x] Why? Because of potential barcode duplicates across samples (can happen by chance)",sreichl,https://github.com/epigen/genome_tracks/issues/6,epigen++genome_tracks.csv
I_kwDOGiQZ6s6CLORf,generate UCSC genome browser track hub (see ATAC-seq pipeline),CLOSED,2024-03-13T13:07:03Z,2024-03-14T10:48:49Z,2024-03-14T10:48:49Z,,sreichl,https://github.com/epigen/genome_tracks/issues/7,epigen++genome_tracks.csv
I_kwDOGiQZ6s6CLnG8,make MR.PARETO module,CLOSED,2024-03-13T13:54:53Z,2024-03-20T15:07:10Z,2024-03-20T15:07:10Z,"- [x] #11 
- [x] update and extend docs
  - [x] config.yaml
  - [x] config/README: how configure single cell data; important that single-cell metadata.tsv is sample specific as by chance different samples could have the same cell barcodes...
  - [x] README
    - [x] remove ALL feature -> always all
    - [x] add new features: ymax per gene/region; color per group; UCSC genome browser hub; IGV-Report, single-cell bam file support,...
    - [x] move all genome browser track related docs/instructions from ATAC-seq pipeline to genome_tracks
    - [x] performance
      - 78 ATAC-seq samples in 31 groups took 22 minutes with max 4 cores and 4GB memory
      - 64 RNA-seq samples in 31 groups took 16 minutes with max 4 cores and 4GB memory
      - 2 10x genomics 5' scRNA-seq reactions each ~10k cells split in 2 small subset groups took 31 minutes with max 4 cores and 8GB memory
- [x] go through MRP checklist",sreichl,https://github.com/epigen/genome_tracks/issues/8,epigen++genome_tracks.csv
I_kwDOGiQZ6s6CMkQ1,check and implement parameters,CLOSED,2024-03-13T15:43:27Z,2024-03-14T14:43:40Z,2024-03-14T14:43:40Z,"- [x] check normalization methods in deeptools::bamCoverage (e.g., RPKM vs RPGC) -> configurable?
- [x] check if scaling is necessary in deeptools::bamCoverage ie as a dependency to the number of samples merged? or during merging with samtools? -> no, samtools merge literally only merges.
  - no scaling is necessary as it is done by all normalization methods. In case of [RPGC*](https://groups.google.com/g/deeptools/c/th96gaftAXQ) it not only takes the total number of reads into consideration, but also the effective genome size, making it even more robust.
- [x] check if the parameters work with tracks (they are from pyGenomeTracks): `--dpi 300 --fontSize 12`
  - nope 

from ATAC-seq pipeline
```shell
bamCoverage --bam {input.bam} \
            -p max --binSize 10  --normalizeUsing RPGC \
            --effectiveGenomeSize {params.genome_size} --extendReads 175 \
            -o ""{output.bigWig}"" > ""{output.bigWig_log}"" 2>&1;
```

*RPGC, on the other hand, does not only take the total number of reads into consideration, it also needs the effective genome size (which will differ from the ""real"" genome size because for mapping reads those regions of the genome where the sequence is either not determined or too repetitive to be covered should not be taken into consideration for calculating the coverage. Note that the exact effective genome size might be bigger than the values we indicate in the help texts if you have very long sequencing reads. For the example above, RPGC would work as follows:
sequencing depth = (total number of mapped reads * fragment length) / effective genome size = 50 x 10^6 * 200/ 2.15057 x 10^9 = 4.65
RPGC scaling factor = 1/sequencing depth = 1/4.65 = 0.22
RPGC(bin1) = 0.22 * 10 = 2.2
RPGC(bin2) = 0.22 * 12 = 2.64",sreichl,https://github.com/epigen/genome_tracks/issues/9,epigen++genome_tracks.csv
I_kwDOGiQZ6s6CNAJJ,customize coloring,CLOSED,2024-03-13T16:37:51Z,2024-03-14T15:51:06Z,2024-03-14T15:51:06Z,"[Changing the color palette](https://gitlab.com/salk-tm/gtracks#changing-the-color-palette)
probably requires gtracks update -> gtracks 1.12.6",sreichl,https://github.com/epigen/genome_tracks/issues/10,epigen++genome_tracks.csv
I_kwDOGiQZ6s6Cd9aS,test & clean everything,CLOSED,2024-03-15T15:38:19Z,2024-03-19T17:48:26Z,2024-03-19T17:48:26Z,"- [x] clean code and comments
- [x] add reporting for IGV-report
- [x] macroStim RNA-seq
- [x] macroStim ATACseq
- [x] macroStim PT141 for NT, Csf1r subsets (check KO)
",sreichl,https://github.com/epigen/genome_tracks/issues/11,epigen++genome_tracks.csv
I_kwDOGiQZ6s6Dv0zH,Consider seqNdisplayR package,CLOSED,2024-03-27T09:59:13Z,2024-03-27T09:59:42Z,2024-03-27T09:59:42Z,"Protocol for generating customizable and reproducible plots of sequencing coverage data using the seqNdisplayR package.
https://www.sciencedirect.com/science/article/pii/S2666166724001254
",sreichl,https://github.com/epigen/genome_tracks/issues/12,epigen++genome_tracks.csv
I_kwDOGiQZ6s6V-yOz,add docs about IGV SSL problems,OPEN,2024-09-10T12:09:56Z,2024-09-13T14:28:03Z,,"IGV report: OSError: error when opening file `https://igv-genepattern-org.s3.amazonaws.com/genomes/seq/hg38/hg38.fa`
-> their https ie SSL certificate is outdated

or pin this issue?",sreichl,https://github.com/epigen/genome_tracks/issues/13,epigen++genome_tracks.csv
MDU6SXNzdWUxOTg1NjUzODE=,Are FPKMs calculated this way actually comparable?,OPEN,2017-01-03T20:49:24Z,2017-01-03T20:49:24Z,,"I have noticed that in this program, the FPKM for a gene is defined as the FPKM for the transcript where [read count]/[length] is the largest. My experience is that, as a result, the gene length used for the same symbol can be very different for different individuals, despite using the same exon.bed. Would this make the FPKMs calculated this way any less comparable?",JohnMCMa,https://github.com/Genomon-Project/GenomonExpression/issues/1,Genomon-Project++GenomonExpression.csv
I_kwDOHAd7ks5F6LPp,Curious about X,CLOSED,2022-03-17T20:27:11Z,2022-03-17T21:01:13Z,2022-03-17T21:01:13Z,XYZ here are my thoughts,DaSLZapier,https://github.com/jhudsl/GDSCN_Book_Statistics_for_Genomics_RNA-seq/issues/3,jhudsl++GDSCN_Book_Statistics_for_Genomics_RNA-seq.csv
I_kwDOHAd7ks5F6YBe,Add edit pencil button,CLOSED,2022-03-17T21:19:51Z,2022-03-17T21:20:12Z,2022-03-17T21:20:12Z,https://github.com/jhudsl/AnVIL_Book_Getting_Started/pull/109,avahoffman,https://github.com/jhudsl/GDSCN_Book_Statistics_for_Genomics_RNA-seq/issues/4,jhudsl++GDSCN_Book_Statistics_for_Genomics_RNA-seq.csv
I_kwDOHDtReM5JFTaa,Rename book,CLOSED,2022-05-05T01:57:25Z,2022-05-10T13:28:43Z,2022-05-10T13:28:43Z,Change the name of the book in the link to scRNA-seq,ehumph,https://github.com/jhudsl/GDSCN_Book_Statistics_for_Genomics_scRNA-seq/issues/6,jhudsl++GDSCN_Book_Statistics_for_Genomics_scRNA-seq.csv
I_kwDOFEf9is5Cd1M1,How to download Insect virus,OPEN,2022-01-26T14:58:31Z,2022-01-26T14:58:31Z,,"I didn't see the download-all button for the insect virus. Could you help me with that? Or can you please send me a list of accession or taxonomy id of these viruses? Thank you!

",JY-97,https://github.com/meiyang12/Genome-annotation-pipeline/issues/1,meiyang12++Genome-annotation-pipeline.csv
I_kwDOFEf9is5H-vrr,Can not get homolog_change_gff3.pl in this pipeline,OPEN,2022-04-19T02:12:49Z,2022-04-19T02:12:49Z,,"Dear Dr. Yang:
I can't find the scripts of ""homolog_change_gff3.pl"" in this pipeline, can you share this script here? Thx !",cccsnd,https://github.com/meiyang12/Genome-annotation-pipeline/issues/2,meiyang12++Genome-annotation-pipeline.csv
I_kwDOFEf9is5KQ2XU,How different methods on RepeatMasker running can lead to different results,OPEN,2022-05-24T03:28:39Z,2022-05-24T03:28:39Z,,"Hi! Thank you for providing this pipline to annotate a new assembling genome!

I run RepeatMasker on different libraries ( one is build by RepeatModeler, another is 'species' contained in the RepBase ) according to your command, but I add the parameter `-xsmall [returns repetitive regions in lowercase (rest capitals) rather than masked]` because I notice it is recommended that the braker runs on genomic sequences that have been softmasked for Repeats. And also the option `--softmasking` is suitable for softmasked genomes. The command looks like this:
```
RepeatMasker -pa 20 -lib 01_repeatModeler-denovo-repeat.lib/RM_*/consensi.fa.classified -html -gff -xsmall -dir 02_delete-denovo-lib-result genome.fa &>RepeatMasker_run.log1
RepeatMasker -pa 20 -species ""Lepidoptera"" -html -gff -xsmall -dir 03_delete-repeatmasker-lib-result 02_delete-denovo-lib-result/genome.fa.masked &>RepeatMasker_run.log2
RepeatMasker -pa 20 -species ""Lepidoptera"" -html -gff -xsmall -noint -dir 04_delete-repeamasker-noint-result 03_delete-repeatmasker-lib-result/genome.fa.masked.masked &>RepeatMasker_run.log3
```
I have compared the two masked genome generated by run 1 & 2, I see some sequences that is masked in the first run (with `-lib`) is unmasked in the second run (with `-species`). I think this case is caused by the option `-xsmall`, so I run again above commands but delete the option `-xsmall` and this problem is solved.

It is confusing that this pipeline use the genome.fa.masked.masked in `03_delete-repeatmasker-lib-result/genome.fa.masked.masked` directory rather than the genome.fa.masked.masked.masked in `04_delete-repeamasker-noint-result/genome.fa.masked.masked.masked` directory to run BRAKER. 

So what the meaning of run 3 ( with `-noint` ) ? If we run RepeatMasker in hardmasking model, I think the `braker.pl` shouldn't add the option `--softmasking`. If we run RepeatMasker in softmasking model, does the better way is to combine the libraries into one library as mentioned by jebrosen https://github.com/Dfam-consortium/TETools/issues/20#issuecomment-983927917 and then feed the genome.fa.masked ( soft-masking ) to BRAKER with `--softmasking` ?",yshcai,https://github.com/meiyang12/Genome-annotation-pipeline/issues/3,meiyang12++Genome-annotation-pipeline.csv
MDU6SXNzdWU1MzU0MzQ3MTk=,Submit to F1000 Bioconductor channel,CLOSED,2019-12-10T01:26:13Z,2019-12-21T09:17:24Z,2019-12-21T09:17:23Z,"Tasks remaining:

## coding

- [x] clean up example from lines 585 - 624, this could be done in a simpler way without the need for `summarise_at` or creating a list of functions
- [ ] answer the remaining questions:
    - [ ] We specified a fixed-size window for computing overlaps.  How could we have looked at 
       various settings of this distance parameter?  A: repeat the anchor_center code section for
       various widths using the map + bind_ranges strategy. 
   - [ ]  How would you adapt the code to also consider variations on the thresholds applied to 
      the DE genes (FDR 1%, testing against a null region of |LFC| < 1), and to the FDR cutoff (1%)
      for the DA peaks? A: here you could create a grouping variable using the same strategy as the  example using `summarise_at`
   - [x] Due to the one-to-many mappings of DE genes to peaks, we don't know if we have the same number of DE genes participating or less, as we increase the threshold on the peak LFC. A: group by gene_id before counting. It also occurs to me that we could be using `reduce_ranges()` instead of summarise to avoid grouping by everything. 
 - [x] set a seed for the resampling


## writing and formatting 

- [x] mention how tximeta can be used without an internet connection
- [x] switch over to f1000 template using BiocWorkflowTools
- [ ] incorporate feedback from Michael Lawrence
- [x] incorporate feedback from Di




Does the workflow package need to be on Bioconductor before its submitted to f1000?
@mikelove is there anything else?",sa-lee,https://github.com/sa-lee/fluentGenomics/issues/1,sa-lee++fluentGenomics.csv
MDU6SXNzdWU1NDAwMjU2MTM=,rewrite abstract,CLOSED,2019-12-19T01:51:48Z,2019-12-20T00:37:33Z,2019-12-20T00:37:33Z,I think we can provide maybe the bigger ideas of what the workflow looks like - what are the core principles behind the analysis etc. ,sa-lee,https://github.com/sa-lee/fluentGenomics/issues/2,sa-lee++fluentGenomics.csv
MDU6SXNzdWU1NDAwMjU3MTA=,add a diagram showing the big picture of the steps in the workflow,CLOSED,2019-12-19T01:52:15Z,2020-01-15T03:40:44Z,2020-01-15T03:40:44Z,,sa-lee,https://github.com/sa-lee/fluentGenomics/issues/3,sa-lee++fluentGenomics.csv
MDU6SXNzdWU1NDAwNjYxOTI=,add diagram illustrating idea behind overlap joins and reduce,OPEN,2019-12-19T04:19:31Z,2019-12-19T04:19:31Z,,,sa-lee,https://github.com/sa-lee/fluentGenomics/issues/4,sa-lee++fluentGenomics.csv
MDU6SXNzdWU1NDA2ODY2OTg=,better variable naming,CLOSED,2019-12-20T01:34:54Z,2019-12-23T05:00:03Z,2019-12-23T05:00:03Z,"From Mike 

>  I think you've shown how to compute lots of things that people want to compute, but maybe we can do better at naming variables. An example: ""any_peaks"" is made from ""overlap_genes"" and consists of genes. I know we don't want names to be too long, but maybe we can come up with a variable naming convention for the enrichment section. To create ""enrichments"" involves a lot of steps and intermediate objects. Again, the final plot is exactly what we want, but maybe if we had a convention for naming the intermediates it may help.

I agree, maybe something like when doing summarise or reduce_ranges:

If its still a granges object use suffix gr, otherwise use df. 

If its been grouped and then summarized we name it as  group_name + last result. So any_peaks would be gene_peak_lfc_gr, and overlap tab would be origin_peak_lfc_df and so on. Now that I think of the variable any should really be changed to peak_count. Does that clear things up? Naming things is hard!",sa-lee,https://github.com/sa-lee/fluentGenomics/issues/5,sa-lee++fluentGenomics.csv
MDU6SXNzdWU1NDA2ODY5MzI=,add diagram showing GRanges and SE abstraction,OPEN,2019-12-20T01:35:27Z,2019-12-20T01:35:27Z,,,sa-lee,https://github.com/sa-lee/fluentGenomics/issues/6,sa-lee++fluentGenomics.csv
MDU6SXNzdWU1NDEzMDU1NDE=,extension: window sizes,OPEN,2019-12-21T09:20:34Z,2019-12-21T09:20:34Z,," We specified a fixed-size window for computing overlaps. How could we have looked at
various settings of this distance parameter? 

A: repeat the anchor_center code section for various widths using the map + bind_ranges strategy.
",sa-lee,https://github.com/sa-lee/fluentGenomics/issues/7,sa-lee++fluentGenomics.csv
MDU6SXNzdWU1NDEzMDU1ODA=,extension: FDR thresholds,OPEN,2019-12-21T09:21:08Z,2019-12-21T09:21:08Z,,"How would you adapt the code to also consider variations on the thresholds applied to
the DE genes (FDR 1%, testing against a null region of |LFC| < 1), and to the FDR cutoff (1%)
for the DA peaks? 

A: here you could create a grouping variable using the same strategy as the example using summarise_at",sa-lee,https://github.com/sa-lee/fluentGenomics/issues/8,sa-lee++fluentGenomics.csv
MDU6SXNzdWUzNjMxNDUzOTY=,htseq-count,OPEN,2018-09-24T13:25:55Z,2018-09-24T13:25:55Z,,"  File ""/u/home/s/serghei/project/anaconda2/bin/htseq-count"", line 3, in <module>
    import HTSeq.scripts.count
  File ""/u/home/s/serghei/.local/lib/python2.7/site-packages/HTSeq/__init__.py"", line 9, in <module>
    from _HTSeq import *
ImportError: /u/home/s/serghei/.local/lib/python2.7/site-packages/HTSeq/_HTSeq.so: undefined symbol: PyUnicodeUCS2_Tailmatch",smangul1,https://github.com/smangul1/genomics.hoffman2/issues/1,smangul1++genomics.hoffman2.csv
I_kwDOFIO7Dc5CXcLo,Medaka Model,CLOSED,2022-01-25T05:24:06Z,2023-07-07T15:03:57Z,2023-07-07T15:03:57Z,"Hi

May I know what are the `medaka models` that being supported in this pipeline?

Thank you!",llk578496,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/1,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5Ny7jr,"SyntaxWarning: ""is"" with a literal. Did you mean ""==""?",CLOSED,2022-07-14T19:23:37Z,2023-08-18T11:16:45Z,2023-08-18T11:16:45Z,"Hi,
I just wanted to bring up an issue that I have run into when using the wf-bacterial-genomes workflow. I am getting this error on the medakaNetwork process when I run the workflow on a directory of fastqs from one barcode. However, if I pre concatenate the barcode fastqs I do not run into this issue. For the time being is pre concatenating a suitable fix, would it harm the final output of the analysis?

Thank you.

`
Error executing process > 'calling_pipeline:medakaNetwork (2)'

Caused by:
  Process `calling_pipeline:medakaNetwork (2)` terminated with an error exit status (137)

Command executed:

  medaka consensus 00-480.reads2ref.bam 00-480.2.consensus_probs.hdf --threads 2 --model r941_prom_variant_g360 --region ""contig_2:0-1000000
  ""

Command exit status:
  137

Command output:
  (empty)

Command error:
  /home/epi2melabs/conda/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py:285: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?
    minval_is_zero = minval is 0  # pylint: disable=literal-comparison
  /home/epi2melabs/conda/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py:286: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?
    maxval_is_one = maxval is 1  # pylint: disable=literal-comparison
  /home/epi2melabs/conda/lib/python3.8/site-packages/tensorflow/python/ops/ragged/ragged_batch_gather_with_default_op.py:84: SyntaxWarning: ""is not"" with a literal. Did you mean ""!=""?
    if (default_value.shape.ndims is not 0
  /home/epi2melabs/conda/lib/python3.8/site-packages/tensorflow/python/ops/ragged/ragged_batch_gather_with_default_op.py:85: SyntaxWarning: ""is not"" with a literal. Did you mean ""!=""?
    and default_value.shape.ndims is not 1):
  [17:13:51 - Predict] Setting tensorflow inter/intra-op threads to 2/1.
  [17:13:51 - Predict] Processing region(s): contig_2:0-1000000
  [17:13:51 - Predict] Using model: /home/epi2melabs/conda/lib/python3.8/site-packages/medaka/data/r941_prom_variant_g360_model.hdf5.
  [17:13:51 - Predict] Processing 1 long region(s) with batching.
  [17:13:51 - MdlStore] filepath /home/epi2melabs/conda/lib/python3.8/site-packages/medaka/data/r941_prom_variant_g360_model.hdf5
  [17:13:52 - Sampler] Initializing sampler for consensus of region contig_2:0-1000000.
  [17:13:52 - PWorker] Running inference for 1.0M draft bases.
  [17:14:00 - Feature] Processed contig_2:0.0-999999.2 (median depth 173.0)
  [17:14:00 - Sampler] Took 8.76s to make features.
  [17:14:22 - PWorker] Batches in cache: 3.
  [17:14:22 - PWorker] 34.1% Done (0.3/1.0 Mbases) in 30.8s
  .command.sh: line 3:    29 Killed                  medaka consensus 00-480.reads2ref.bam 00-480.2.consensus_probs.hdf --threads 2 --model r941_prom_variant_g360 --region ""contig_2:0-1000000
  ""
`",awh082834,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/2,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5UauGT,demo Workflow has terminated but no outputs are available,CLOSED,2022-10-20T09:33:21Z,2023-08-18T11:16:34Z,2023-08-18T11:16:34Z,"### What happened?

demo Workflow has terminated but no outputs are available

### Operating System

Windows 10

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

3.1.5  env 1.2.5

### Workflow Execution - Execution Profile

Docker

### Workflow Version

0.2.5

### Relevant log output

```shell
N E X T F L O W ~ version 21.10.6

Launching `epi2me-labs/wf-bacterial-genomes` [trusting_hopper] - revision: 24db269e21 [v0.2.5]

NOTE: Your local project version looks outdated - a different revision is available in the remote repository [9b59bc5d52]

Core Nextflow options

revision : v0.2.5

runName : trusting_hopper

containerEngine: docker

launchDir : /mnt/c/Users/alessiosoggiu/epi2melabs-data/nextflow

workDir : /mnt/c/Users/alessiosoggiu/epi2melabs-data/nextflow/instances/2022-10-20-11-32_wf-bacterial-genomes_LV36YMTkYBavTzSe4b6eLV/work

projectDir : /root/.nextflow/assets/epi2me-labs/wf-bacterial-genomes

userName : root

profile : standard

configFiles : /root/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config

Input/output options

fastq : /root/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/test_data/fastq

out_dir : /mnt/c/Users/alessiosoggiu/epi2melabs-data/nextflow/instances/2022-10-20-11-32_wf-bacterial-genomes_LV36YMTkYBavTzSe4b6eLV/output

Reference genome options

reference : /root/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/test_data/ref

!! Only displaying parameters that differ from the pipeline defaults !!

------------------------------------------------------

If you use epi2me-labs/wf-template for your analysis please cite:

* The nf-core framework

https://doi.org/10.1038/s41587-020-0439-x

Checking fastq input.

Barcoded directories detected.

[28/5a5158] Submitted process > calling_pipeline:getVersions

[cc/76fc24] Submitted process > calling_pipeline:getParams

[4d/bac24c] Submitted process > calling_pipeline:concatFastq (1)

[ba/5bf686] Submitted process > calling_pipeline:concatFastq (2)

[cf/39ffea] Submitted process > calling_pipeline:alignReads (1)

[25/26eca3] Submitted process > calling_pipeline:alignReads (2)

Error executing process > 'calling_pipeline:alignReads (1)'

Caused by:

Process `calling_pipeline:alignReads (1)` terminated with an error exit status (1)

Command executed:

mini_align -i barcode02.reads.fastq -r ref -p barcode02.reads2ref -t 1 -m

Command exit status:

1

Command output:

(empty)

Command error:

Constructing minimap index.

[E::fai_build3_core] Failed to open the file ref

[faidx] Could not build fai index ref.fai

Work dir:

/mnt/c/Users/alessiosoggiu/epi2melabs-data/nextflow/instances/2022-10-20-11-32_wf-bacterial-genomes_LV36YMTkYBavTzSe4b6eLV/work/cf/39ffea222a7cca01477cc1eb288a01

Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`

WARN: Killing pending tasks (2)
```
",asogg,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/3,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5gwuXf,[Bug]: Report not taking top hit of 16s quast blast ,CLOSED,2023-03-14T12:31:53Z,2023-08-18T11:16:07Z,2023-08-18T11:16:07Z,"### What happened?

Hi, 

Report appears to be showing 3rd top hit of blast results from metaquast against SILVA 16s database. 

Example metaquast blast result:

```
# BLASTN 2.13.0+
# Query: NZ_CP027798.1
# Database: /home/epi2melabs/conda/lib/python3.8/site-packages/quast_libs/silva/silva.138.1.db
# Fields: query acc.ver, subject acc.ver, % identity, alignment length, mismatches, gap opens, q. start, q. end, s. start, s. end, evalue, bit score
# 4000 hits found
NZ_CP027798.1	CP012639.1795630.1797181_Bacteria;Proteobacteria;Gammaproteobacteria;Enterobacterales;Yersiniaceae;Serratia;Serratia_marcescens	100.000	1552	0	0	3730374	3731925	1552	1	0.0	2867
NZ_CP027798.1	CP012639.1795630.1797181_Bacteria;Proteobacteria;Gammaproteobacteria;Enterobacterales;Yersiniaceae;Serratia;Serratia_marcescens	99.936	1552	0	1	652578	654128	1	1552	0.0	2859
NZ_CP027798.1	CP012639.1795630.1797181_Bacteria;Proteobacteria;Gammaproteobacteria;Enterobacterales;Yersiniaceae;Serratia;Serratia_marcescens	99.807	1552	2	1	5036064
```
Report shows %identity of 99.807 (image attached)
![quast_error_AM90](https://user-images.githubusercontent.com/38727026/225002270-b40a7d88-3c68-4d1d-b2a6-05071e943753.png)


Appears to be the run_species_stats function in report.py where species_data df has top hit as header, and top_hit takes 2nd row (i.e 3rd row of quast blast output). 
```
def run_species_stats(species_stats_path, sample_names):    
    """"""Analysis of metaquast data.""""""
    results = []
    for indexs, sample_name in enumerate(sample_names):
        species_data_path = os.path.join(
            species_stats_path, ""blast.res_""+sample_name+""-medaka"")
        species_data = pd.read_csv(species_data_path, sep='\t', comment=""#"")
        top_hit = species_data.iloc[1, :]
        species_split = re.split(""\\."", top_hit[1])[2].split("";"")
        species = species_split[len(species_split)-1]
        species = re.sub(""_"", "" "", species)
        results.append(
            {'Sample': sample_name,
             'Species': species,
             'Perc_identity': top_hit[2]})
    results_df = pd.DataFrame(results, index=sample_names).iloc[:, 1:3]
    results_df.columns = ['Species ID', 'Identity (%)']
    return results_df
```

Possible fix:
```
def run_species_stats(species_stats_path, sample_names):    
    """"""Analysis of metaquast data.""""""
    results = []
    for indexs, sample_name in enumerate(sample_names):
        species_data_path = os.path.join(
            species_stats_path, ""blast.res_""+sample_name+""-medaka"")
        species_data = pd.read_csv(species_data_path, sep='\t', comment=""#"", header=None)
        top_hit = species_data.iloc[0, :]
        species_split = re.split(""\\."", top_hit[1])[2].split("";"")
        species = species_split[len(species_split)-1]
        species = re.sub(""_"", "" "", species)
        results.append(
            {'Sample': sample_name,
             'Species': species,
             'Perc_identity': top_hit[2]})
    results_df = pd.DataFrame(results, index=sample_names).iloc[:, 1:3]
    results_df.columns = ['Species ID', 'Identity (%)']
    return results_df
```




### Operating System

ubuntu 20.04

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

None

### Workflow Version

0.2.12

### Relevant log output

```shell
N/A
```
",cjalder,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/4,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5g8JpH,workflow fails with demo data,CLOSED,2023-03-15T22:38:49Z,2023-03-22T07:16:46Z,2023-03-21T20:46:55Z,"### What happened?

Hi,

I have been trying to get this workflow to run for awhile with no success. When attempting to run the workflow on demo data it rapidly fails and produces a ""stops with error"" outcome. 

The log shows that there is an error when calling prokka:
Command error:
touch: cannot touch '.command.trace': Permission denied

I have tried altering permissions to the directory to be the most permissive with no success. 

Would you be able to help?

Thanks,
Charlie

### Operating System

Ubuntu 20.04

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

V4.1.3

### Workflow Execution - CLI Execution Profile

None

### Workflow Version

v0.2.12

### Relevant log output

```shell
NOTE: Nextflow is not tested with Java 1.8.0_362 -- It's recommended the use of version 11 up to 18
N E X T F L O W  ~  version 22.04.5
Launching `/home/nanopore-catalyst/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/main.nf` [goofy_kalam] DSL2 - revision: f4f74b71cb
||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.2.12
--------------------------------------------------------------------------------
Core Nextflow options
  runName             : goofy_kalam
  containerEngine     : docker
  launchDir           : /home/nanopore-catalyst/epi2melabs/instances/wf-bacterial-genomes_07513228-afc6-44a5-b9f8-494da672e466
  workDir             : /home/nanopore-catalyst/epi2melabs/instances/wf-bacterial-genomes_07513228-afc6-44a5-b9f8-494da672e466/work
  projectDir          : /home/nanopore-catalyst/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes
  userName            : nanopore-catalyst
  profile             : standard
  configFiles         : /home/nanopore-catalyst/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/nextflow.config, /home/nanopore-catalyst/epi2melabs/instances/wf-bacterial-genomes_07513228-afc6-44a5-b9f8-494da672e466/demo.config
Input Options
  fastq               : /home/nanopore-catalyst/epi2melabs/demo/epi2me-labs/wf-bacterial-genomes/wf-bacterial-genomes-demo/fastq
  summarise_assemblies: true
Output Options
  out_dir             : /home/nanopore-catalyst/epi2melabs/instances/wf-bacterial-genomes_07513228-afc6-44a5-b9f8-494da672e466/output
!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:
* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x
--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v0.2.12.
--------------------------------------------------------------------------------
Checking fastq input.
Barcoded directories detected.
Running Denovo assembly.
[1a/dc8277] Submitted process > calling_pipeline:prokkaVersion
[41/fbfb49] Submitted process > calling_pipeline:concatFastq (1)
[d5/485863] Submitted process > calling_pipeline:concatFastq (2)
[0e/d5e754] Submitted process > calling_pipeline:getParams
[29/445c44] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
Error executing process > 'calling_pipeline:prokkaVersion'
Caused by:
  Process `calling_pipeline:prokkaVersion` terminated with an error exit status (1)
Command executed:
  prokka --version | sed 's/ /,/' >> ""prokka_version.txt""
Command exit status:
  1
Command output:
  (empty)
Command error:
  touch: cannot touch '.command.trace': Permission denied
Work dir:
  /home/nanopore-catalyst/epi2melabs/instances/wf-bacterial-genomes_07513228-afc6-44a5-b9f8-494da672e466/work/1a/dc827712d6c17f9700b49dcaa836ba
Tip: when you have fixed the problem you can continue the execution adding the option `-resume` to the run command line
WARN: Killing running tasks (4)
```
",baynec2,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/5,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5jwrWR,[Bug]: No VCF file output? ,CLOSED,2023-04-18T19:21:44Z,2023-07-07T15:01:00Z,2023-07-07T15:01:00Z,"### What happened?

Hello, 
I am using the command-line version of the wf-bacterial-genomes workflow. 
It successfully finished and provided me the FASTA file, genbank file, and html report, but no VCF file was found.
Is there a setting I may be missing?
Here is my command:
`nextflow run epi2me-labs/wf-bacterial-genomes -profile standard --fastq ../Lab_Z6X_2_AK029-A.fastq --reference ../avinelandiidj_genome.fasta --threads 4`

### Operating System

ubuntu 20.04

### Workflow Execution

Command line

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

Docker

### Workflow Version

v0.2.12-g8ded2f0

### Relevant log output

```shell
N E X T F L O W  ~  version 22.10.6
Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [fervent_aryabhata] DSL2 - revision: 8ded2f04e8 [master]

||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.2.12-g8ded2f0
--------------------------------------------------------------------------------
Core Nextflow options
  revision            : master
  runName             : fervent_aryabhata
  containerEngine     : docker
  launchDir           : /home/msobol/test
  workDir             : /home/msobol/test/work
  projectDir          : /home/msobol/.nextflow/assets/epi2me-labs/wf-bacterial-genomes
  userName            : msobol
  profile             : standard
  configFiles         : /home/msobol/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config

Input Options
  fastq               : ../Lab_Z6X_2_AK029-A.fastq
  reference           : ../avinelandiidj_genome.fasta
  summarise_assemblies: true

Advanced Options
  threads             : 4

!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:

* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x


--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v0.2.12-g8ded2f0.
--------------------------------------------------------------------------------
Checking fastq input.
Single file input detected.
WARN: Access to undefined parameter `process_label` -- Initialise it to a default value eg. `params.process_label = some_value`
executor >  local (26)
[d6/c83249] process > isolateSingleFile (1)                              [100%] 1 of 1 
[cd/e197b6] process > calling_pipeline:concatFastq (1)                   [100%] 1 of 1 
[e8/38fa6c] process > calling_pipeline:deNovo (1)                        [100%] 1 of 1 
[bf/fa8d4b] process > calling_pipeline:alignReads (1)                    [100%] 1 of 1 
[a5/a3288f] process > calling_pipeline:readStats (1)                     [100%] 1 of 1 
[e7/4ab1f9] process > calling_pipeline:coverStats (1)                    [100%] 1 of 1 
[c3/b7bb3e] process > calling_pipeline:splitRegions (1)                  [100%] 1 of 1 
[80/11003a] process > calling_pipeline:lookup_medaka_consensus_model (1) [100%] 1 of 1 
[3b/6f7688] process > calling_pipeline:lookup_medaka_variant_model (1)   [100%] 1 of 1 
[f5/1eaada] process > calling_pipeline:medakaNetwork (5)                 [100%] 6 of 6 
[26/51465e] process > calling_pipeline:medakaConsensus (1)               [100%] 1 of 1 
[1b/70978d] process > calling_pipeline:assemblyStats                     [100%] 1 of 1 
[8c/ed8b7e] process > calling_pipeline:runProkka (1)                     [100%] 1 of 1 
[18/cccd7a] process > calling_pipeline:prokkaVersion                     [100%] 1 of 1 
[68/f6f220] process > calling_pipeline:medakaVersion                     [100%] 1 of 1 
[a8/c32d1b] process > calling_pipeline:getVersions                       [100%] 1 of 1 
[96/03fc69] process > calling_pipeline:getParams                         [100%] 1 of 1 
[75/806f5d] process > calling_pipeline:makeReport                        [100%] 1 of 1 
[69/3a2ebd] process > output (2)                                         [100%] 3 of 3 
Completed at: 18-Apr-2023 14:02:30
Duration    : 31m 38s
CPU hours   : 1.7
Succeeded   : 26
```
",morgansobol,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/6,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5kj-LW,[Bug]: program doesn't run,CLOSED,2023-04-27T16:06:14Z,2023-07-07T15:01:20Z,2023-07-07T15:01:20Z,"### What happened?

First off thank you for this great program <3

The program unfortunately does not run. I have attached the screenshot of my termainal to show the error message that I am getting. It says this:
No such variable: Exception evaluating property 'out' for nextflow.script.ChannelOut, Reason: groovy.lang.MissingPropertyException: No such property: out for class: groovyx.gpars.dataflow.DataflowBroadcast


Thank you for the help!

![Screenshot from 2023-04-27 09-01-50](https://user-images.githubusercontent.com/81880944/234920542-eac6b603-e1e4-4547-b68e-72140c6e26d5.png)


### Operating System

ubuntu 20.04

### Workflow Execution

Command line

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

None

### Workflow Version

0.2.5

### Relevant log output

```shell
There is no log output in my output directory.
```
",matteo1313,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/7,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5lDQFW,[Bug]: Problem with Metaquast-part of report,CLOSED,2023-05-04T06:40:05Z,2023-08-18T11:15:48Z,2023-08-18T11:15:47Z,"### What happened?

Hi Team,

When running the workflow, it stops (either when using reference-based assembly or de novo assembly) with an error because the report cannot be compiled. This might be due to missing reference files for metaquast (see log output). I am using a proxy server for internet connection.
Is there any workaround for this? I did not find the folder mentioned in the error message to manually provide the reference file.

Thank you very much in advance!

### Operating System

ubuntu 20.04

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

4.1.4

### Workflow Execution - CLI Execution Profile

Docker

### Workflow Version

v0.2.12

### Relevant log output

```shell
Workflow execution completed unsuccessfully!

The exit status of the task that caused the workflow execution to fail was: 1.

The full error message was:

Error executing process > 'calling_pipeline:makeReport'

Caused by:
  Process `calling_pipeline:makeReport` terminated with an error exit status (1)

Command executed:

  workflow-glue report     --prokka      --versions versions     --params params.json     --output wf-bacterial-genomes-report.html     --sample_ids 2639127-28052-01

Command exit status:
  1

Command output:
  (empty)

Command error:
  /home/epi2melabs/conda/lib/python3.8/site-packages/pkg_resources/__init__.py:2804: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)
  /home/epi2melabs/conda/lib/python3.8/site-packages/pkg_resources/__init__.py:2804: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('repoze')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)
  /home/epi2melabs/conda/lib/python3.8/site-packages/pkg_resources/__init__.py:2804: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)
  /home/epi2melabs/conda/lib/python3.8/site-packages/pkg_resources/__init__.py:2804: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)
  /home/epi2melabs/conda/lib/python3.8/site-packages/BCBio/GFF/GFFParser.py:66: DeprecationWarning: invalid escape sequence \w
    gff3_kw_pat = re.compile(""\w+="")
  [09:08:04 - workflow_glue] Starting entrypoint.
  Traceback (most recent call last):
    File ""/home/nanopore/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/bin/workflow-glue"", line 7, in 
      cli()
    File ""/home/nanopore/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/bin/workflow_glue/__init__.py"", line 62, in cli
      args.func(args)
    File ""/home/nanopore/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/bin/workflow_glue/report.py"", line 275, in main
      species_stats = run_species_stats(
    File ""/home/nanopore/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/bin/workflow_glue/report.py"", line 146, in run_species_stats
      species_data = pd.read_csv(species_data_path, sep='\t', comment=""#"")
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/util/_decorators.py"", line 211, in wrapper
      return func(*args, **kwargs)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/util/_decorators.py"", line 331, in wrapper
      return func(*args, **kwargs)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 950, in read_csv
      return _read(filepath_or_buffer, kwds)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 605, in _read
      parser = TextFileReader(filepath_or_buffer, **kwds)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 1442, in __init__
      self._engine = self._make_engine(f, self.engine)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 1735, in _make_engine
      self.handles = get_handle(
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/common.py"", line 856, in get_handle
      handle = open(
  FileNotFoundError: [Errno 2] No such file or directory: 'quast_stats/quast_downloaded_references/blast.res_2639127-28052-01-medaka'

Work dir:
  /home/nanopore/epi2melabs/instances/wf-bacterial-genomes_278008ab-61d9-4c96-8600-5e4e4c7d1453/work/d7/31ebbb6a71721aa9651db0b7fb89e2

Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`


And also Metaquast.log:

/home/epi2melabs/conda/bin/metaquast.py -o quast_output -t 1 2639127-28052-01.medaka.fasta.gz

Version: 5.2.0

System information:
  OS: Linux-5.15.0-71-generic-x86_64-with-glibc2.10 (linux_64)
  Python version: 3.8.15
  CPUs number: 48

Started: 2023-05-03 08:59:05

Logging to /home/nanopore/epi2melabs/instances/wf-bacterial-genomes_278008ab-61d9-4c96-8600-5e4e4c7d1453/work/06/ae06638763ae742c301cf76dd9e858/quast_output/metaquast.log

Contigs:
  Pre-processing...
  2639127-28052-01.medaka.fasta.gz ==> 2639127-28052-01.medaka

No references are provided, starting to search for reference genomes in SILVA 16S rRNA database and to download them from NCBI...

2023-05-03 08:59:08

Downloading SILVA 16S ribosomal RNA gene database (version 138.1)...

ERROR! Failed downloading SILVA 16S rRNA gene database (http://www.arb-silva.de/fileadmin/silva_databases/release_138.1/Exports/SILVA_138.1_SSURef_NR99_tax_silva.fasta.gz)! The search for reference genomes cannot be performed. Try to download it manually, put under /home/epi2melabs/conda/lib/python3.8/site-packages/quast_libs/silva/ and restart your command.
Reference genomes are not found.

NOTICE: No references are provided, starting regular QUAST with MetaGeneMark gene finder
```
",lknegendorf,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/8,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5ln7fl,[Bug]: Error in checking FASTQ and Script,CLOSED,2023-05-11T02:56:53Z,2023-07-07T15:06:06Z,2023-07-07T15:06:06Z,"### What happened?

Hi, I got an error while running wf-bacterial-genomes using demo data. However, I successfully executed the others such as wf-transcriptomes and wf-metagenomics without any issues. I also attempted to resolve the issue by deleting and re-installingl the workflow, but it still doesn't work. 

nextflow.log
https://drive.google.com/file/d/1U9TybH7EfQaYLwebU-Y7O3UKQVSF29X_/view?usp=share_link

Could you please help me with this?

### Operating System

Windows 11

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

4.1.3

### Workflow Execution - CLI Execution Profile

Docker

### Workflow Version

0.2.13

### Relevant log output

```shell
N E X T F L O W  ~  version 22.04.5
Launching `/mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/workflows/epi2me-labs/wf-bacterial-genomes/main.nf` [blissful_aryabhata] DSL2 - revision: 85754a734d
||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.2.13
--------------------------------------------------------------------------------
Core Nextflow options
  runName        : blissful_aryabhata
  containerEngine: docker
  launchDir      : /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/instances/wf-bacterial-genomes_082be453-ed96-4e18-8f7f-7c0fe5725e46
  workDir        : /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/instances/wf-bacterial-genomes_082be453-ed96-4e18-8f7f-7c0fe5725e46/work
  projectDir     : /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/workflows/epi2me-labs/wf-bacterial-genomes
  userName       : jump
  profile        : standard
  configFiles    : /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/workflows/epi2me-labs/wf-bacterial-genomes/nextflow.config, /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/instances/wf-bacterial-genomes_082be453-ed96-4e18-8f7f-7c0fe5725e46/demo.config
Input Options
  fastq          : /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/demo/epi2me-labs/wf-bacterial-genomes/wf-bacterial-genomes-demo/fastq
Output Options
  out_dir        : /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/instances/wf-bacterial-genomes_082be453-ed96-4e18-8f7f-7c0fe5725e46/output
!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:
* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x
--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v0.2.13.
--------------------------------------------------------------------------------
Checking fastq input.
Input directory '/mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/demo/epi2me-labs/wf-bacterial-genomes/wf-bacterial-genomes-demo/fastq' cannot contain FASTQ files and sub-directories with FASTQ files.
 -- Check script '/mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/workflows/epi2me-labs/wf-bacterial-genomes/./lib/fastqingress.nf' at line: 293 or see '/mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/instances/wf-bacterial-genomes_082be453-ed96-4e18-8f7f-7c0fe5725e46/nextflow.log' file for more details
```
",phongphak,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/9,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5nFGBE,[Bug]: Failed to build prokka singularity image,CLOSED,2023-05-28T10:45:15Z,2023-05-31T15:54:53Z,2023-05-31T15:54:53Z,"### What happened?

```
Error executing process > 'calling_pipeline:prokkaVersion'

Caused by:
  Failed to pull singularity image
  command: singularity pull  --name ontresearch-prokka-sha08669655982fbef7c750c7895e97e100196c4967.img.pulling.1685270451064 docker://ontresearch/prokka:sha08669655982fbef7c750c7895e97e100196c4967 > /dev/null
  status : 255
  message:
    INFO:    Converting OCI blobs to SIF format
    INFO:    Starting build...
    Getting image source signatures
    Copying blob sha256:0d9e0007c6ce71ae58e9bc7f851c00164171d6f0692e16461df735bf76533804
    Copying blob sha256:3b65ec22a9e96affe680712973e88355927506aa3f792ff03330f3a3eb601a98
    Copying blob sha256:841971ce0eda383b58744bb8ddbd52b52f4a97756fd995ff31d24276df207477
    Copying blob sha256:5d642c3b6198dd371ea8a09ba12867f66c5e127febcbeb1791446af033ae97a4
    Copying blob sha256:d96d7215a062c674c82c408836f9c89cf3728322ee56a49010c396ca679a0b1c
    Copying blob sha256:27a9f84bae05e2575847f4e95ac0955fb4f5cdb87faf7410c44905eaeae20040
    Copying blob sha256:b3bf890f25149ff8980e2f9f3b484ad6ab8cdd75fef4e6cb8b268fce944c308f
    Copying blob sha256:b3bf890f25149ff8980e2f9f3b484ad6ab8cdd75fef4e6cb8b268fce944c308f
    Copying config sha256:36b6725b02a33e75bd952fd7e0f56c3d8ddaccd52a91ad5cac5533bf41cd034a
    Writing manifest to image destination
    Storing signatures
    FATAL:   While making image from oci registry: error fetching image to cache: while building SIF from layers: conveyor failed to get: no descriptor found for reference ""sha256.e9a0243edee458b0ba7af7426107908ae91d9a17f813e628f872c3ee23560cea""

```

**singularity version 3.10**

### Operating System

ubuntu 20.04

### Workflow Execution

Command line

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

Singularity

### Workflow Version

wf-bacterial-genomes v0.2.9-g4d009af

### Relevant log output

```shell
Posted in ""What happened?""
```
",thanhleviet,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/10,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5nbGwQ,Medaka model for dna_r10.4.1_e8.2_260bps_sup ??,CLOSED,2023-05-31T23:08:30Z,2023-08-18T11:20:43Z,2023-08-18T11:20:42Z,"### What happened?

Hello,

There is no medaka model for the R10.4.1, 260bps, super accurate basecalling. What should I do? 

### Operating System

Windows 10

### Workflow Execution

Command line

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

None

### Workflow Version

0.2.12

### Relevant log output

```shell
ERROR: Validation pipeline of parameters failed!

*--basecaller_cfg: dna_r10.4.1_e8.2_260bps_sup is not a valid enum value (dna_r10.4.1_e8.2_260bps_sup)
```
",lagphase,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/11,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5pENwk,[Bug]: Pipeline terminates with error when specifying more than 4 --threads ,CLOSED,2023-06-19T04:35:35Z,2023-07-28T13:58:11Z,2023-07-28T13:58:11Z,"### What happened?

The pipeline is terminating with an error when running the command with --threads specified higher than 4
I am running it on a 16 CPU VM on our cluster, and would like to take advantage of that for de novo assembly

However, the following error is generated and the pipeline exits when specifying --threads 8 for example

`ERROR ~ Error executing process > 'calling_pipeline:deNovo (1)'

Caused by:
  Process requirement exceeds available CPUs -- req: 8; avail: 4

Command executed:

  LOW_COV_FAIL=0
  FLYE_EXIT_CODE=0
  flye --nano-raw reads.fastq.gz --out-dir output --threads ""8"" ||     FLYE_EXIT_CODE=$?
  
  if [[ $FLYE_EXIT_CODE -eq 0 ]]; then
      mv output/assembly.fasta ""./sa19_filtered.draft_assembly.fasta""
      mv output/assembly_info.txt ""./sa19_filtered_flye_stats.tsv""
      bgzip ""sa19_filtered.draft_assembly.fasta""
  else
      # flye failed --> check the log to see if low coverage caused the failure
      edge_cov=$(grep -oP 'Mean edge coverage: \K\d+' output/flye.log)
      ovlp_cov=$(grep -oP 'Overlap-based coverage: \K\d+' output/flye.log)
      if [[
          $edge_cov -lt 5 ||
          $ovlp_cov -lt 5
      ]]; then
          echo -n ""Caught Flye failure due to low coverage (either mean edge cov. or ""
          echo ""overlap-based cov. were below 5)"".
          LOW_COV_FAIL=1
      else
          # exit a subshell with error so that the process fails
          ( exit $FLYE_EXIT_CODE )
      fi
  fi

Command exit status:
  -

Command output:
  (empty)`

### Operating System

ubuntu 20.04

### Workflow Execution

Command line

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

Docker

### Workflow Version

v0.3.0-g0d2379f

### Relevant log output

```shell
Jun-19 02:15:25.721 [main] DEBUG nextflow.cli.Launcher - $> nextflow run epi2me-labs/wf-bacterial-genomes --fastq sa19_filtered.fastq.gz --threads 8 --out_dir wf-bac-genome
Jun-19 02:15:25.795 [main] INFO  nextflow.cli.CmdRun - N E X T F L O W  ~  version 23.04.1
Jun-19 02:15:25.811 [main] DEBUG nextflow.plugin.PluginsFacade - Setting up plugin manager > mode=prod; embedded=false; plugins-dir=/home/ubuntu/.nextflow/plugins; core-plugins: nf-amazon@1.16.2,nf-azure@1.0.1,nf-codecommit@0.1.4,nf-console@1.0.5,nf-ga4gh@1.0.5,nf-google@1.7.3,nf-tower@1.5.12,nf-wave@0.8.2
Jun-19 02:15:25.820 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Enabled plugins: []
Jun-19 02:15:25.821 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Disabled plugins: []
Jun-19 02:15:25.824 [main] INFO  org.pf4j.DefaultPluginManager - PF4J version 3.4.1 in 'deployment' mode
Jun-19 02:15:25.832 [main] INFO  org.pf4j.AbstractPluginManager - No plugins
Jun-19 02:15:25.844 [main] DEBUG nextflow.scm.ProviderConfig - Using SCM config path: /home/ubuntu/.nextflow/scm
Jun-19 02:15:26.611 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/.git/config; branch: master; remote: origin; url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Jun-19 02:15:26.628 [main] DEBUG nextflow.scm.RepositoryFactory - Found Git repository result: [RepositoryFactory]
Jun-19 02:15:26.635 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/.git/config; branch: master; remote: origin; url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Jun-19 02:15:27.903 [main] DEBUG nextflow.config.ConfigBuilder - Found config base: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Jun-19 02:15:27.904 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Jun-19 02:15:27.916 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Jun-19 02:15:28.055 [main] DEBUG nextflow.cli.CmdRun - Applied DSL=2 from script declararion
Jun-19 02:15:28.056 [main] INFO  nextflow.cli.CmdRun - Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [suspicious_mendel] DSL2 - revision: 0d2379f52b [master]
Jun-19 02:15:28.056 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins default=[]
Jun-19 02:15:28.056 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins resolved requirement=[]
Jun-19 02:15:28.060 [main] DEBUG nextflow.secret.LocalSecretsProvider - Secrets store: /home/ubuntu/.nextflow/secrets/store.json
Jun-19 02:15:28.062 [main] DEBUG nextflow.secret.SecretsLoader - Discovered secrets providers: [nextflow.secret.LocalSecretsProvider@7e5efcab] - activable => nextflow.secret.LocalSecretsProvider@7e5efcab
Jun-19 02:15:28.107 [main] DEBUG nextflow.Session - Session UUID: 8602c007-fc97-495e-a8b8-e2bcb6dffea8
Jun-19 02:15:28.108 [main] DEBUG nextflow.Session - Run name: suspicious_mendel
Jun-19 02:15:28.108 [main] DEBUG nextflow.Session - Executor pool size: 16
Jun-19 02:15:28.118 [main] DEBUG nextflow.util.ThreadPoolBuilder - Creating thread pool 'FileTransfer' minSize=10; maxSize=48; workQueue=LinkedBlockingQueue[10000]; allowCoreThreadTimeout=false
Jun-19 02:15:28.135 [main] DEBUG nextflow.cli.CmdRun - 
  Version: 23.04.1 build 5866
  Created: 15-04-2023 06:51 UTC 
  System: Linux 5.15.0-67-generic
  Runtime: Groovy 3.0.16 on OpenJDK 64-Bit Server VM 20-internal-adhoc..src
  Encoding: UTF-8 (UTF-8)
  Process: 2467608@rnaseq [127.0.1.1]
  CPUs: 16 - Mem: 62.8 GB (8.6 GB) - Swap: 0 (0)
Jun-19 02:15:28.149 [main] DEBUG nextflow.Session - Work-dir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work [ext2/ext3]
Jun-19 02:15:28.166 [main] DEBUG nextflow.executor.ExecutorFactory - Extension executors providers=[]
Jun-19 02:15:28.175 [main] DEBUG nextflow.Session - Observer factory: DefaultObserverFactory
Jun-19 02:15:28.245 [main] DEBUG nextflow.cache.CacheFactory - Using Nextflow cache factory: nextflow.cache.DefaultCacheFactory
Jun-19 02:15:28.255 [main] DEBUG nextflow.util.CustomThreadPool - Creating default thread pool > poolSize: 17; maxThreads: 1000
Jun-19 02:15:28.610 [main] DEBUG nextflow.Session - Session start
Jun-19 02:15:28.622 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow started -- trace file: /home/ubuntu/scratch/raw_data/nanopore/sa19/wf-bac-genome/execution/trace.txt
Jun-19 02:15:28.629 [main] DEBUG nextflow.Session - Using default localLib path: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Jun-19 02:15:28.633 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Jun-19 02:15:28.634 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib/nfcore_external_java_deps.jar
Jun-19 02:15:30.611 [main] DEBUG nextflow.script.ScriptRunner - > Launching execution
Jun-19 02:15:31.341 [main] INFO  nextflow.Nextflow - 
[0;92m||||||||||   [0m[2m_____ ____ ___ ____  __  __ _____      _       _
[0;92m||||||||||  [0m[2m| ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
[0;33m|||||       [0m[2m|  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
[0;33m|||||       [0m[2m| |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
[0;94m||||||||||  [0m[2m|_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
[0;94m||||||||||  [0m[1mwf-bacterial-genomes v0.3.0-g0d2379f[0m
[2m--------------------------------------------------------------------------------[0m
[1mCore Nextflow options[0m
  [0;34mrevision       : [0;32mmaster[0m
  [0;34mrunName        : [0;32msuspicious_mendel[0m
  [0;34mcontainerEngine: [0;32mdocker[0m
  [0;34mlaunchDir      : [0;32m/home/ubuntu/scratch/raw_data/nanopore/sa19[0m
  [0;34mworkDir        : [0;32m/home/ubuntu/scratch/raw_data/nanopore/sa19/work[0m
  [0;34mprojectDir     : [0;32m/home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes[0m
  [0;34muserName       : [0;32mubuntu[0m
  [0;34mprofile        : [0;32mstandard[0m
  [0;34mconfigFiles    : [0;32m/home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config[0m

[1mInput Options[0m
  [0;34mfastq          : [0;32msa19_filtered.fastq.gz[0m

[1mOutput Options[0m
  [0;34mout_dir        : [0;32mwf-bac-genome[0m

[1mAdvanced Options[0m
  [0;34mthreads        : [0;32m8[0m

[1mOther parameters[0m
  [0;34mprocess_label  : [0;32mwfbacterialgenomes[0m

!! Only displaying parameters that differ from the pipeline defaults !!
[2m--------------------------------------------------------------------------------[0m
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:

* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x


[2m--------------------------------------------------------------------------------[0m
This is epi2me-labs/wf-bacterial-genomes v0.3.0-g0d2379f.
[2m--------------------------------------------------------------------------------[0m
Jun-19 02:15:32.535 [main] INFO  nextflow.Nextflow - Checking fastq input.
Jun-19 02:15:32.917 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name fastcat
Jun-19 02:15:32.922 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:32.922 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:33.173 [main] DEBUG nextflow.executor.Executor - [warm up] executor > local
Jun-19 02:15:33.179 [main] DEBUG n.processor.LocalPollingMonitor - Creating local task monitor for executor 'local' > cpus=4; memory=8 GB; capacity=16; pollInterval=100ms; dumpInterval=5m
Jun-19 02:15:34.444 [main] INFO  nextflow.Nextflow - Running Denovo assembly.
Jun-19 02:15:34.603 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:deNovo
Jun-19 02:15:34.604 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.604 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.615 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:alignReads
Jun-19 02:15:34.615 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.615 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.618 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:readStats
Jun-19 02:15:34.618 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.618 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.621 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:coverStats
Jun-19 02:15:34.621 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.621 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.625 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:splitRegions
Jun-19 02:15:34.625 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.625 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.638 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:lookup_medaka_consensus_model
Jun-19 02:15:34.638 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.639 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.641 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:lookup_medaka_variant_model
Jun-19 02:15:34.642 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.642 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.653 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaNetwork
Jun-19 02:15:34.654 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.654 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.661 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaConsensus
Jun-19 02:15:34.661 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.661 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.665 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:prokka` matches labels `prokka` for process with name calling_pipeline:runProkka
Jun-19 02:15:34.665 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.665 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.668 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:prokka` matches labels `prokka` for process with name calling_pipeline:prokkaVersion
Jun-19 02:15:34.668 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.668 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.670 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaVersion
Jun-19 02:15:34.670 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.670 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.672 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:mlst` matches labels `mlst` for process with name calling_pipeline:mlstVersion
Jun-19 02:15:34.672 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.672 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.674 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:getVersions
Jun-19 02:15:34.674 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.674 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.676 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:getParams
Jun-19 02:15:34.676 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.676 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.693 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:makeReport
Jun-19 02:15:34.694 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.694 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.698 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:collectFastqIngressResultsInDir
Jun-19 02:15:34.698 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.698 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.708 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name output
Jun-19 02:15:34.708 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.708 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.710 [main] DEBUG nextflow.Session - Workflow process names [dsl2]: resfinder, calling_pipeline:alignReads, deNovo, medakaConsensus, calling_pipeline:getParams, validate_sample_sheet, calling_pipeline:mlstVersion, calling_pipeline:lookup_medaka_variant_model, calling_pipeline:medakaVersion, medakaVersion, alignReads, readStats, output, medakaVariant, runProkka, medakaNetwork, collectFastqIngressResultsInDir, makeReport, calling_pipeline:deNovo, calling_pipeline:collectFastqIngressResultsInDir, lookup_medaka_variant_model, getVersions, calling_pipeline:coverStats, medakaVariantConsensus, calling_pipeline:readStats, prokkaVersion, calling_pipeline:medakaConsensus, lookup_medaka_consensus_model, calling_pipeline:medakaNetwork, splitRegions, getPointfinderSpecies, calling_pipeline:getVersions, coverStats, calling_pipeline:runProkka, calling_pipeline:makeReport, calling_pipeline:splitRegions, calling_pipeline:lookup_medaka_consensus_model, move_or_compress, processResfinder, mlstSearch, fastcat, mlstVersion, getParams, makePerSampleReports, calling_pipeline:prokkaVersion
Jun-19 02:15:34.712 [main] DEBUG nextflow.Session - Igniting dataflow network (28)
Jun-19 02:15:34.713 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > fastcat
Jun-19 02:15:34.713 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:deNovo
Jun-19 02:15:34.713 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:alignReads
Jun-19 02:15:34.713 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:readStats
Jun-19 02:15:34.713 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:coverStats
Jun-19 02:15:34.713 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:splitRegions
Jun-19 02:15:34.718 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:lookup_medaka_consensus_model
Jun-19 02:15:34.718 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:lookup_medaka_variant_model
Jun-19 02:15:34.718 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaNetwork
Jun-19 02:15:34.718 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaConsensus
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:runProkka
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:prokkaVersion
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaVersion
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:mlstVersion
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:getVersions
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:getParams
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:makeReport
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:collectFastqIngressResultsInDir
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > output
Jun-19 02:15:34.719 [main] DEBUG nextflow.script.ScriptRunner - > Awaiting termination 
Jun-19 02:15:34.719 [main] DEBUG nextflow.Session - Session await
Jun-19 02:15:35.021 [Actor Thread 4] DEBUG nextflow.util.CacheHelper - Hash asset file sha-256: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/data/medaka_models.tsv
Jun-19 02:15:35.063 [Actor Thread 6] DEBUG nextflow.util.CacheHelper - Hash asset file sha-256: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/bin/workflow-glue
Jun-19 02:15:35.099 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 02:15:35.118 [Task submitter] INFO  nextflow.Session - [54/b76301] Submitted process > calling_pipeline:prokkaVersion
Jun-19 02:15:35.125 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 02:15:35.125 [Task submitter] INFO  nextflow.Session - [53/101949] Submitted process > calling_pipeline:getParams
Jun-19 02:15:35.130 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 02:15:35.131 [Task submitter] INFO  nextflow.Session - [b9/ba8311] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
Jun-19 02:15:35.134 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 02:15:35.134 [Task submitter] INFO  nextflow.Session - [f7/19f9fe] Submitted process > calling_pipeline:lookup_medaka_consensus_model (1)
Jun-19 02:16:54.311 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 2; name: calling_pipeline:prokkaVersion; status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/54/b76301075d0155a45631eaec504c88]
Jun-19 02:16:55.316 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 02:16:55.316 [Task submitter] INFO  nextflow.Session - [95/1556bc] Submitted process > calling_pipeline:medakaVersion
Jun-19 02:17:10.826 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 4; name: calling_pipeline:getParams; status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/53/10194967aa1d0c93fe54b9406c5bb9]
Jun-19 02:17:22.256 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 1; name: calling_pipeline:lookup_medaka_variant_model (1); status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/b9/ba8311b4462575ea21affcbef22efd]
Jun-19 02:17:23.610 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 3; name: calling_pipeline:lookup_medaka_consensus_model (1); status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/f7/19f9fec5a75d56031ed0d421470710]
Jun-19 02:17:23.614 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 02:17:23.615 [Task submitter] INFO  nextflow.Session - [2c/4fb84a] Submitted process > fastcat (1)
Jun-19 02:17:46.457 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 5; name: fastcat (1); status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/2c/4fb84a5c2ee3454d3468d3f06b8e08]
Jun-19 02:17:46.470 [Task submitter] DEBUG nextflow.processor.TaskProcessor - Handling unexpected condition for
  task: name=calling_pipeline:deNovo (1); work-dir=/home/ubuntu/scratch/raw_data/nanopore/sa19/work/6a/62ce6616158344cec75d3cc8d1e421
  error [nextflow.exception.ProcessUnrecoverableException]: Process requirement exceeds available CPUs -- req: 8; avail: 4
Jun-19 02:17:46.542 [Task submitter] DEBUG nextflow.processor.TaskRun - Unable to dump error of process 'null' -- Cause: java.nio.file.NoSuchFileException: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/6a/62ce6616158344cec75d3cc8d1e421/.command.log
Jun-19 02:17:46.543 [Task submitter] ERROR nextflow.processor.TaskProcessor - Error executing process > 'calling_pipeline:deNovo (1)'

Caused by:
  Process requirement exceeds available CPUs -- req: 8; avail: 4

Command executed:

  LOW_COV_FAIL=0
  FLYE_EXIT_CODE=0
  flye --nano-raw reads.fastq.gz --out-dir output --threads ""8"" ||     FLYE_EXIT_CODE=$?
  
  if [[ $FLYE_EXIT_CODE -eq 0 ]]; then
      mv output/assembly.fasta ""./sa19_filtered.draft_assembly.fasta""
      mv output/assembly_info.txt ""./sa19_filtered_flye_stats.tsv""
      bgzip ""sa19_filtered.draft_assembly.fasta""
  else
      # flye failed --> check the log to see if low coverage caused the failure
      edge_cov=$(grep -oP 'Mean edge coverage: \K\d+' output/flye.log)
      ovlp_cov=$(grep -oP 'Overlap-based coverage: \K\d+' output/flye.log)
      if [[
          $edge_cov -lt 5 ||
          $ovlp_cov -lt 5
      ]]; then
          echo -n ""Caught Flye failure due to low coverage (either mean edge cov. or ""
          echo ""overlap-based cov. were below 5)"".
          LOW_COV_FAIL=1
      else
          # exit a subshell with error so that the process fails
          ( exit $FLYE_EXIT_CODE )
      fi
  fi

Command exit status:
  -

Command output:
  (empty)

Work dir:
  /home/ubuntu/scratch/raw_data/nanopore/sa19/work/6a/62ce6616158344cec75d3cc8d1e421

Tip: when you have fixed the problem you can continue the execution adding the option `-resume` to the run command line
Jun-19 02:17:46.545 [Task submitter] DEBUG nextflow.Session - Session aborted -- Cause: Process requirement exceeds available CPUs -- req: 8; avail: 4
Jun-19 02:17:46.558 [Task submitter] DEBUG nextflow.Session - The following nodes are still active:
[process] calling_pipeline:alignReads
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:readStats
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:coverStats
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:splitRegions
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:medakaNetwork
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:medakaConsensus
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:runProkka
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:mlstVersion
  status=ACTIVE
  port 0: (value) OPEN  ; channel: input_version.txt
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:getVersions
  status=ACTIVE
  port 0: (value) OPEN  ; channel: input_versions.txt
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:makeReport
  status=ACTIVE
  port 0: (value) OPEN  ; channel: versions/*
  port 1: (value) bound ; channel: params.json
  port 2: (value) bound ; channel: variants/*
  port 3: (value) bound ; channel: sample_ids
  port 4: (value) OPEN  ; channel: prokka/*
  port 5: (queue) OPEN  ; channel: per_read_stats
  port 6: (value) OPEN  ; channel: fwd/*
  port 7: (value) OPEN  ; channel: rev/*
  port 8: (value) OPEN  ; channel: total_depth/*
  port 9: (value) OPEN  ; channel: flye_stats/*
  port 10: (value) bound ; channel: resfinder/*
  port 11: (value) bound ; channel: mlst/*
  port 12: (cntrl) -     ; channel: $

[process] output
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: fname
  port 1: (cntrl) -     ; channel: $

Jun-19 02:17:47.509 [main] DEBUG nextflow.Session - Session await > all processes finished
Jun-19 02:17:47.510 [main] DEBUG nextflow.Session - Session await > all barriers passed
Jun-19 02:17:47.743 [main] WARN  n.processor.TaskPollingMonitor - Killing running tasks (1)
Jun-19 02:17:47.820 [Actor Thread 11] ERROR nextflow.extension.DataflowHelper - @unknown
java.nio.channels.ClosedByInterruptException: null
	at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:199)
	at java.base/sun.nio.ch.FileChannelImpl.endBlocking(FileChannelImpl.java:171)
	at java.base/sun.nio.ch.FileChannelImpl.mapInternal(FileChannelImpl.java:1349)
	at java.base/sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:1188)
	at org.iq80.leveldb.impl.MMapLogWriter.<init>(MMapLogWriter.java:66)
	at org.iq80.leveldb.impl.Logs.createLogWriter(Logs.java:36)
	at org.iq80.leveldb.impl.VersionSet.initializeIfNeeded(VersionSet.java:107)
	at org.iq80.leveldb.impl.VersionSet.<init>(VersionSet.java:92)
	at org.iq80.leveldb.impl.DbImpl.<init>(DbImpl.java:180)
	at org.iq80.leveldb.impl.Iq80DBFactory.open(Iq80DBFactory.java:83)
	at nextflow.sort.LevelDbSort.create(LevelDbSort.java:48)
	at nextflow.file.SortFileCollector.createStoreAndIndex(SortFileCollector.groovy:174)
	at nextflow.file.SortFileCollector.add(SortFileCollector.groovy:204)
	at nextflow.file.SortFileCollector$add.call(Unknown Source)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:148)
	at nextflow.extension.CollectFileOp.processItem(CollectFileOp.groovy:162)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
	at java.base/java.lang.reflect.Method.invoke(Method.java:578)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:107)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:323)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1258)
	at groovy.lang.MetaClassImpl.invokeMethodClosure(MetaClassImpl.java:1047)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1132)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1035)
	at groovy.lang.Closure.call(Closure.java:412)
	at groovy.lang.Closure.call(Closure.java:428)
	at groovy.lang.Closure$call.call(Unknown Source)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:53)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:139)
	at nextflow.extension.DataflowHelper$_subscribeImpl_closure2.doCall(DataflowHelper.groovy:284)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
	at java.base/java.lang.reflect.Method.invoke(Method.java:578)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:107)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:323)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:274)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1035)
	at groovy.lang.Closure.call(Closure.java:412)
	at groovyx.gpars.dataflow.operator.DataflowOperatorActor.startTask(DataflowOperatorActor.java:120)
	at groovyx.gpars.dataflow.operator.DataflowOperatorActor.onMessage(DataflowOperatorActor.java:108)
	at groovyx.gpars.actor.impl.SDAClosure$1.call(SDAClosure.java:43)
	at groovyx.gpars.actor.AbstractLoopingActor.runEnhancedWithoutRepliesOnMessages(AbstractLoopingActor.java:293)
	at groovyx.gpars.actor.AbstractLoopingActor.access$400(AbstractLoopingActor.java:30)
	at groovyx.gpars.actor.AbstractLoopingActor$1.handleMessage(AbstractLoopingActor.java:93)
	at groovyx.gpars.util.AsyncMessagingCore.run(AsyncMessagingCore.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1623)
Jun-19 02:17:47.821 [main] DEBUG nextflow.trace.WorkflowStatsObserver - Workflow completed > WorkflowStats[succeededCount=5; failedCount=1; ignoredCount=0; cachedCount=0; pendingCount=2; submittedCount=0; runningCount=-1; retriesCount=0; abortedCount=1; succeedDuration=1m 48s; failedDuration=0ms; cachedDuration=0ms;loadCpus=-8; loadMemory=0; peakRunning=4; peakCpus=4; peakMemory=0; ]
Jun-19 02:17:47.823 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow completed -- saving trace file
Jun-19 02:17:47.824 [main] DEBUG nextflow.trace.ReportObserver - Workflow completed -- rendering execution report
Jun-19 02:17:47.865 [main] DEBUG nextflow.trace.ReportObserver - Execution report summary data:
  [{""cpuUsage"":{""mean"":15.2,""min"":15.2,""q1"":15.2,""q2"":15.2,""q3"":15.2,""max"":15.2,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""process"":""prokkaVersion"",""mem"":{""mean"":12091392,""min"":12091392,""q1"":12091392,""q2"":12091392,""q3"":12091392,""max"":12091392,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":22552576,""min"":22552576,""q1"":22552576,""q2"":22552576,""q3"":22552576,""max"":22552576,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""reads"":{""mean"":1554117,""min"":1554117,""q1"":1554117,""q2"":1554117,""q3"":1554117,""max"":1554117,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""cpu"":{""mean"":15.2,""min"":15.2,""q1"":15.2,""q2"":15.2,""q3"":15.2,""max"":15.2,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""time"":{""mean"":440,""min"":440,""q1"":440,""q2"":440,""q3"":440,""max"":440,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""writes"":{""mean"":252,""min"":252,""q1"":252,""q2"":252,""q3"":252,""max"":252,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""}},{""cpuUsage"":{""mean"":123.1,""min"":123.1,""q1"":123.1,""q2"":123.1,""q3"":123.1,""max"":123.1,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""process"":""getParams"",""mem"":null,""memUsage"":null,""timeUsage"":null,""vmem"":null,""reads"":{""mean"":58942,""min"":58942,""q1"":58942,""q2"":58942,""q3"":58942,""max"":58942,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""cpu"":{""mean"":123.1,""min"":123.1,""q1"":123.1,""q2"":123.1,""q3"":123.1,""max"":123.1,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""time"":{""mean"":2,""min"":2,""q1"":2,""q2"":2,""q3"":2,""max"":2,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""writes"":{""mean"":1646,""min"":1646,""q1"":1646,""q2"":1646,""q3"":1646,""max"":1646,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""}},{""cpuUsage"":{""mean"":42.1,""min"":42.1,""q1"":42.1,""q2"":42.1,""q3"":42.1,""max"":42.1,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""process"":""lookup_medaka_variant_model"",""mem"":{""mean"":414617600,""min"":414617600,""q1"":414617600,""q2"":414617600,""q3"":414617600,""max"":414617600,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":2538094592,""min"":2538094592,""q1"":2538094592,""q2"":2538094592,""q3"":2538094592,""max"":2538094592,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""reads"":{""mean"":52719589,""min"":52719589,""q1"":52719589,""q2"":52719589,""q3"":52719589,""max"":52719589,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""cpu"":{""mean"":42.1,""min"":42.1,""q1"":42.1,""q2"":42.1,""q3"":42.1,""max"":42.1,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""time"":{""mean"":34747,""min"":34747,""q1"":34747,""q2"":34747,""q3"":34747,""max"":34747,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""writes"":{""mean"":26566109,""min"":26566109,""q1"":26566109,""q2"":26566109,""q3"":26566109,""max"":26566109,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""}},{""cpuUsage"":{""mean"":40.8,""min"":40.8,""q1"":40.8,""q2"":40.8,""q3"":40.8,""max"":40.8,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""process"":""lookup_medaka_consensus_model"",""mem"":{""mean"":414904320,""min"":414904320,""q1"":414904320,""q2"":414904320,""q3"":414904320,""max"":414904320,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":2553286656,""min"":2553286656,""q1"":2553286656,""q2"":2553286656,""q3"":2553286656,""max"":2553286656,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""reads"":{""mean"":52719602,""min"":52719602,""q1"":52719602,""q2"":52719602,""q3"":52719602,""max"":52719602,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""cpu"":{""mean"":40.8,""min"":40.8,""q1"":40.8,""q2"":40.8,""q3"":40.8,""max"":40.8,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""time"":{""mean"":41009,""min"":41009,""q1"":41009,""q2"":41009,""q3"":41009,""max"":41009,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""writes"":{""mean"":26566108,""min"":26566108,""q1"":26566108,""q2"":26566108,""q3"":26566108,""max"":26566108,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""}},{""cpuUsage"":{""mean"":48.1,""min"":48.1,""q1"":48.1,""q2"":48.1,""q3"":48.1,""max"":48.1,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""process"":""fastcat"",""mem"":{""mean"":10878976,""min"":10878976,""q1"":10878976,""q2"":10878976,""q3"":10878976,""max"":10878976,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":385417216,""min"":385417216,""q1"":385417216,""q2"":385417216,""q3"":385417216,""max"":385417216,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""reads"":{""mean"":670543345,""min"":670543345,""q1"":670543345,""q2"":670543345,""q3"":670543345,""max"":670543345,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""cpu"":{""mean"":144.3,""min"":144.3,""q1"":144.3,""q2"":144.3,""q3"":144.3,""max"":144.3,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""time"":{""mean"":10678,""min"":10678,""q1"":10678,""q2"":10678,""q3"":10678,""max"":10678,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""writes"":{""mean"":678402356,""min"":678402356,""q1"":678402356,""q2"":678402356,""q3"":678402356,""max"":678402356,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""}},{""cpuUsage"":null,""process"":""deNovo"",""mem"":null,""memUsage"":null,""timeUsage"":null,""vmem"":null,""reads"":null,""cpu"":null,""time"":null,""writes"":null},{""cpuUsage"":null,""process"":""medakaVersion"",""mem"":null,""memUsage"":null,""timeUsage"":null,""vmem"":null,""reads"":null,""cpu"":null,""time"":null,""writes"":null}]
Jun-19 02:17:48.971 [main] DEBUG nextflow.trace.TimelineObserver - Workflow completed -- rendering execution timeline
Jun-19 02:17:49.032 [main] DEBUG nextflow.cache.CacheDB - Closing CacheDB done
Jun-19 02:17:49.107 [main] DEBUG nextflow.file.FileCollector - Deleting file collector temp dir: /tmp/nxf-12209019396811809986
Jun-19 02:17:49.109 [main] DEBUG nextflow.file.SortFileCollector - FileCollector temp dir not removed: null
Jun-19 02:17:49.109 [main] DEBUG nextflow.script.ScriptRunner - > Execution complete -- Goodbye
```
",samuelmontgomery,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/12,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5pERe1,[Bug]: error executing process 'calling_pipeline:run_isolates:processResfinder',CLOSED,2023-06-19T04:57:17Z,2023-08-18T11:18:01Z,2023-08-18T11:18:00Z,"### What happened?

Hi, 
I am getting a consisent error when including --isolate true in my pipeline
It appears the pipeline isn't writing the results of PointFinder to the work directory, as the pipeline is unable to find it to run 'calling_pipeline:run_isolates:processResfinder'

When navigating to the work directory, I can see that the file ""PointFinder_results.txt"" file does not exists, but the ResFinder results are there

### Operating System

Windows 10

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

None

### Workflow Version

v0.3

### Relevant log output

```shell
Jun-19 04:49:42.954 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 04:49:42.954 [Task submitter] INFO  nextflow.Session - [a4/411820] Submitted process > calling_pipeline:run_isolates:resfinder (1)
Jun-19 04:50:41.769 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 23; name: calling_pipeline:run_isolates:resfinder (1); status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/a4/4118209cff8e009ecdd2f27175e9c1]
Jun-19 04:50:41.780 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 04:50:41.780 [Task submitter] INFO  nextflow.Session - [19/c71662] Submitted process > calling_pipeline:run_isolates:processResfinder (1)
Jun-19 04:50:41.800 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 04:50:41.800 [Task submitter] INFO  nextflow.Session - [45/602b1a] Submitted process > calling_pipeline:makePerSampleReports (1)
Jun-19 04:51:06.198 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 25; name: calling_pipeline:makePerSampleReports (1); status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/45/602b1a068f4d425447a8511e7acb53]
Jun-19 04:51:07.416 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 24; name: calling_pipeline:run_isolates:processResfinder (1); status: COMPLETED; exit: 1; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/19/c71662a3a4cdbd3afaaed301540476]
Jun-19 04:51:07.419 [Task monitor] DEBUG nextflow.processor.TaskProcessor - Handling unexpected condition for
  task: name=calling_pipeline:run_isolates:processResfinder (1); work-dir=/home/ubuntu/scratch/raw_data/nanopore/sa19/work/19/c71662a3a4cdbd3afaaed301540476
  error [nextflow.exception.ProcessFailedException]: Process `calling_pipeline:run_isolates:processResfinder (1)` terminated with an error exit status (1)
Jun-19 04:51:07.427 [Task monitor] ERROR nextflow.processor.TaskProcessor - Error executing process > 'calling_pipeline:run_isolates:processResfinder (1)'

Caused by:
  Process `calling_pipeline:run_isolates:processResfinder (1)` terminated with an error exit status (1)

Command executed:

  workflow-glue process_resfinder             --resfinder_file sa19_filtered_resfinder_results/ResFinder_results_tab.txt             --pointfinder_file sa19_filtered_resfinder_results/PointFinder_results.txt             --output sa19_filtered.resfinder_results.txt             --database_location sa19_filtered_resfinder_results/pointfinder_blast/tmp/

Command exit status:
  1

Command output:
  (empty)

Command error:
  [04:50:58 - workflow_glue] Starting entrypoint.
  Traceback (most recent call last):
    File ""/home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/bin/workflow-glue"", line 7, in <module>
      cli()
    File ""/home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/bin/workflow_glue/__init__.py"", line 62, in cli
      args.func(args)
    File ""/home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/bin/workflow_glue/process_resfinder.py"", line 161, in main
      pointfinder_data = pd.read_csv(args.pointfinder_file, sep=""\t"")
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 912, in read_csv
      return _read(filepath_or_buffer, kwds)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 577, in _read
      parser = TextFileReader(filepath_or_buffer, **kwds)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 1407, in __init__
      self._engine = self._make_engine(f, self.engine)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 1661, in _make_engine
      self.handles = get_handle(
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/common.py"", line 859, in get_handle
      handle = open(
  FileNotFoundError: [Errno 2] No such file or directory: 'sa19_filtered_resfinder_results/PointFinder_results.txt'

Work dir:
  /home/ubuntu/scratch/raw_data/nanopore/sa19/work/19/c71662a3a4cdbd3afaaed301540476

Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`
Jun-19 04:51:07.429 [Task monitor] DEBUG nextflow.Session - Session aborted -- Cause: Process `calling_pipeline:run_isolates:processResfinder (1)` terminated with an error exit status (1)
Jun-19 04:51:07.442 [Task monitor] DEBUG nextflow.Session - The following nodes are still active:
[process] calling_pipeline:makeReport
  status=ACTIVE
  port 0: (value) bound ; channel: versions/*
  port 1: (value) bound ; channel: params.json
  port 2: (value) bound ; channel: variants/*
  port 3: (value) bound ; channel: sample_ids
  port 4: (value) bound ; channel: prokka/*
  port 5: (queue) closed; channel: per_read_stats
  port 6: (value) bound ; channel: fwd/*
  port 7: (value) bound ; channel: rev/*
  port 8: (value) bound ; channel: total_depth/*
  port 9: (value) bound ; channel: flye_stats/*
  port 10: (value) bound ; channel: resfinder/*
  port 11: (value) bound ; channel: mlst/*
  port 12: (cntrl) -     ; channel: $

[process] output
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: fname
  port 1: (cntrl) -     ; channel: $

Jun-19 04:51:07.454 [Actor Thread 13] DEBUG nextflow.util.CacheHelper - Hash asset file sha-256: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/data/OPTIONAL_FILE
Jun-19 04:51:07.457 [Task submitter] DEBUG n.processor.TaskPollingMonitor - %% executor local > tasks in the submission queue: 1 -- tasks to be submitted are shown below
~> TaskHandler[id: 26; name: calling_pipeline:makeReport (1); status: NEW; exit: -; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/0e/1029af066443477807ff5d62f0630e]
Jun-19 04:51:08.400 [main] DEBUG nextflow.Session - Session await > all processes finished
Jun-19 04:51:08.400 [main] DEBUG nextflow.Session - Session await > all barriers passed
Jun-19 04:51:08.637 [main] DEBUG nextflow.trace.WorkflowStatsObserver - Workflow completed > WorkflowStats[succeededCount=24; failedCount=1; ignoredCount=0; cachedCount=0; pendingCount=1; submittedCount=0; runningCount=0; retriesCount=0; abortedCount=0; succeedDuration=55m 13s; failedDuration=25.5s; cachedDuration=0ms;loadCpus=0; loadMemory=0; peakRunning=4; peakCpus=4; peakMemory=0; ]
Jun-19 04:51:08.637 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow completed -- saving trace file
Jun-19 04:51:08.638 [main] DEBUG nextflow.trace.ReportObserver - Workflow completed -- rendering execution report
```
",samuelmontgomery,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/13,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5pS4af,[Question]: no gbk output files for the newest version?,CLOSED,2023-06-21T02:22:28Z,2023-07-28T13:54:47Z,2023-07-28T13:54:47Z,"### What happened?

Hi, 
The newest version generates gff output file but not gbk file anymore (which is not really helpful). Is there an option for gbk output file? Thanks.

### Operating System

Windows 10

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

None

### Workflow Version

0.3.0

### Relevant log output

```shell
||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.3.0-g0d2379f
```
",lagphase,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/14,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5sqcWm,r1041_e82_400bps_sup_v4.2.0 missing from basecaller options,CLOSED,2023-07-26T19:51:40Z,2023-08-18T10:58:35Z,2023-08-18T10:58:35Z,"### Is your feature related to a problem?

I use the bacterial genome workflow with data from Plasmidsaurus, a commercial plasmid/genome sequencing service based on Nanopore sequencing tech. They use the r1041_e82_400bps_sup_v4.2.0 basecalling option, which seems to be absent from the current Medeka models. 

### Describe the solution you'd like

Train the Medeka model on r1041_e82_400bps_sup_v4.2.0 and include it as an option. 

### Describe alternatives you've considered

What would be the closest, currently available basecalling model?

### Additional context

_No response_",WolfgangSchmied,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/15,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5tD3Zl,Use `-profile docker` instead of `-profile standard` when using Docker,CLOSED,2023-07-31T17:43:02Z,2023-08-18T10:54:18Z,2023-08-18T10:54:17Z,"### Is your feature related to a problem?

At the moment, for using _Docker_, one needs to run the workflow with `-profile standard`. 
It might be more intuitive for users to use `-profile docker` to do this instead, which is the standard used by `nf-core` pipelines. 

### Describe the solution you'd like

I believe this could be done by changing the [current config file](https://github.com/epi2me-labs/wf-bacterial-genomes/blob/e223e1b85bd301fd73cac520048ac2d1fbd5f82a/nextflow.config#L102) to use something closer to what nf-core pipelines use ([example here](https://github.com/nf-core/rnaseq/blob/3bec2331cac2b5ff88a1dc71a21fab6529b57a0f/nextflow.config#L145)).

### Describe alternatives you've considered

Adding clearer documentation about the default behaviour to the README (and possibly the `--help` page) could be an alternative. At the moment this has to be inferred from the config source. 

### Additional context

(and thank you for all the work in developing these pipelines!)",tavareshugo,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/16,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5teEPI,"Got ""No disjointigs were assembled"" error when running denovo",CLOSED,2023-08-04T11:42:59Z,2023-08-18T11:19:39Z,2023-08-18T11:19:39Z,"I have tried to run the pipeline with single ONT sample on WSL2 with singularity profile _denovo_ i.e. running with flye assembler. The sample appears to have high coverage. It is from bacteria with 4mb genome size.  Further investigation in the .nexflow.log file indicated it is a flye related error which seemed to be the case as reported [here](https://github.com/fenderglass/Flye/issues/128).

 I manually configured the flye command in the 'main.nf' file by adding the `--asm-coverage` and `--genome-size` options which didn't throw that error anymore only threw a memory error.

Would it be convenient to add in the advanced options additional parameters in the pipeline for running flye like it is recommended [here](https://github.com/fenderglass/Flye/issues/128#issuecomment-506509828) in a similar way you hva done for running prokka or medaka which are available in the pipeline usage help (`nextflow run epi2me-labs/wf-bacterial-genomes --help`)?

Note:
The solution given in the flye issue above require to add additional paramter `--genome-size <value>` as shoen in the current flye usage [doc](https://github.com/fenderglass/Flye/blob/flye/docs/USAGE.md#-quick-usage).

Thank you!",bsalehe,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/17,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5vBCvb,Different result from flye 2.9.2,CLOSED,2023-08-23T04:26:14Z,2023-08-25T15:15:54Z,2023-08-25T15:15:54Z,"### Ask away!

I've assemble a circular bacterial genome from fastq data using flye CLI 2.9.2-b1794
I used an options: --nano=hq only.

and i tried to use this workflow to assemble same bacterial genome as well.
but i found the result fasta file of wf-bacterial-genomes is different from flye's 

I've check the flye version in the workflow and it was 2.9.2 -b1786 - same as mine
I assume the flye option that this workflow uses maybe different from my flye configuration.

How could i see the flye option that wf-bacterial-genomes uses?

and one more thing, Is there any way that i could change flye option in the EPI2ME Labs?",Yoon90,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/18,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5yZffM,Workflow execution completed unsuccessfully! Error executing process > 'calling_pipeline:medakaNetwork (2)',CLOSED,2023-09-29T13:34:34Z,2023-09-29T13:38:24Z,2023-09-29T13:38:24Z,"### Ask away!

Hello Epi2me labs team,

We tried to run the workflow 'bacterial genome' within an oracle VM with Ubuntu 22.04.3 LTS 64-bit in the Epi2me labs desktop application.
To check if it works, we tried 'Use Demo Data'

We had this report :

Workflow execution completed unsuccessfully!
The exit status of the task that caused the workflow execution to fail was: 134.

The full error message was:

Error executing process > 'calling_pipeline:medakaNetwork (2)'

Caused by:
  Process `calling_pipeline:medakaNetwork (2)` terminated with an error exit status (134)

Command executed:

  medaka --version
      echo r1041_e82_400bps_sup_v4.2.0
  
      echo r1041_e82_400bps_sup_v4.2.0
  
      medaka consensus align.bam ""test1.consensus_probs.hdf""         --threads 2 --regions ""NC_000962.3:999000-1999000
  "" --model r1041_e82_400bps_sup_v4.2.0

Command exit status:
  134

Command output:
  medaka 1.9.1
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0

Command error:
  Cannot import pyabpoa, some features may not be available.
  medaka 1.9.1
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0
  The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.
  .command.sh: line 8:    90 Aborted                 (core dumped) medaka consensus align.bam ""test1.consensus_probs.hdf"" --threads 2 --regions ""NC_000962.3:999000-1999000
  "" --model r1041_e82_400bps_sup_v4.2.0

Work dir:
  /home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/work/72/fb42aff10d6ba33fdc644968b2c3ff

Tip: you can replicate the issue by changing to the process work dir and entering the command `bash .command.run`




I tried this : https://github.com/tensorflow/tensorflow/issues/24548
(mehdirezaie commented on Mar 27, 2020)

But we still have the same error.
What could we do to solve this ?",Lenfera,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/19,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5yZjqV,Workflow execution completed unsuccessfully! Error executing process > 'calling_pipeline:medakaNetwork (2)',CLOSED,2023-09-29T13:45:12Z,2024-05-10T13:00:03Z,2024-05-10T13:00:03Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

v0.4.0

### Workflow Execution

EPI2ME Desktop application

### EPI2ME Version

v5.1.2

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

Hello Epi2me labs team,

We tried to run the workflow 'bacterial genome' within an oracle VM with Ubuntu 22.04.3 LTS 64-bit in the Epi2me labs desktop application.
To check if it works, we tried 'Use Demo Data'

We had this report :

Workflow execution completed unsuccessfully!
The exit status of the task that caused the workflow execution to fail was: 134.

The full error message was:

Error executing process > 'calling_pipeline:medakaNetwork (2)'

Caused by:
Process calling_pipeline:medakaNetwork (2) terminated with an error exit status (134)

Command executed:

medaka --version
echo r1041_e82_400bps_sup_v4.2.0

  echo r1041_e82_400bps_sup_v4.2.0

  medaka consensus align.bam ""test1.consensus_probs.hdf""         --threads 2 --regions ""NC_000962.3:999000-1999000

"" --model r1041_e82_400bps_sup_v4.2.0

Command exit status:
134

Command output:
medaka 1.9.1
r1041_e82_400bps_sup_v4.2.0
r1041_e82_400bps_sup_v4.2.0

Command error:
Cannot import pyabpoa, some features may not be available.
medaka 1.9.1
r1041_e82_400bps_sup_v4.2.0
r1041_e82_400bps_sup_v4.2.0
The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.
.command.sh: line 8: 90 Aborted (core dumped) medaka consensus align.bam ""test1.consensus_probs.hdf"" --threads 2 --regions ""NC_000962.3:999000-1999000
"" --model r1041_e82_400bps_sup_v4.2.0

Work dir:
/home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/work/72/fb42aff10d6ba33fdc644968b2c3ff

Tip: you can replicate the issue by changing to the process work dir and entering the command bash .command.run

I tried this : https://github.com/tensorflow/tensorflow/issues/24548
(mehdirezaie commented on Mar 27, 2020)

But we still have the same error.
What could we do to solve this ?

### Relevant log output

```shell
N E X T F L O W  ~  version 23.04.2
Launching `/home/sprzto/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/main.nf` [wizardly_rosalind] DSL2 - revision: 3d3482183d
||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.4.0
--------------------------------------------------------------------------------
Core Nextflow options
  runName                 : wizardly_rosalind
  containerEngine         : docker
  launchDir               : /home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK
  workDir                 : /home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/work
  projectDir              : /home/sprzto/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes
  userName                : sprzto
  profile                 : standard
  configFiles             : /home/sprzto/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/nextflow.config, /home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/demo.config
Input Options
  fastq                   : /home/sprzto/epi2melabs/demo/epi2me-labs/wf-bacterial-genomes/v0.4.0/wf-bacterial-genomes-demo/isolates_fastq
  reference_based_assembly: true
  reference               : /home/sprzto/epi2melabs/demo/epi2me-labs/wf-bacterial-genomes/v0.4.0/wf-bacterial-genomes-demo/ref/ref.fasta.gz
Sample Options
  sample_sheet            : /home/sprzto/epi2melabs/demo/epi2me-labs/wf-bacterial-genomes/v0.4.0/wf-bacterial-genomes-demo/isolates_sample_sheet.csv
Output Options
  out_dir                 : /home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/output
Isolate options
  isolates                : true
Advanced Options
  threads                 : 3
!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:
* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x
--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v0.4.0.
--------------------------------------------------------------------------------
Checking fastq input.
Reference based assembly selected.
[43/4d29ed] Submitted process > calling_pipeline:getParams
[07/745d32] Submitted process > calling_pipeline:lookup_medaka_consensus_model (1)
[81/f490ce] Submitted process > calling_pipeline:prokkaVersion
[f7/f99deb] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
[f0/d397d2] Submitted process > validate_sample_sheet
[7e/199664] Submitted process > calling_pipeline:medakaVersion
[4d/6d385d] Submitted process > calling_pipeline:mlstVersion
[5b/d1a558] Submitted process > calling_pipeline:getVersions
[b5/a842fb] Submitted process > fastcat (1)
[57/e3b0f0] Submitted process > fastcat (2)
[60/d2ab0f] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (1)
[4b/2f1d69] Submitted process > calling_pipeline:alignReads (1)
[cb/50852a] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (2)
[16/ac5817] Submitted process > calling_pipeline:alignReads (2)
[02/076eb3] Submitted process > calling_pipeline:readStats (1)
[e2/641ec3] Submitted process > calling_pipeline:splitRegions (1)
[12/82ae58] Submitted process > calling_pipeline:coverStats (1)
[ec/986fa7] Submitted process > calling_pipeline:splitRegions (2)
[df/f0eb5c] Submitted process > calling_pipeline:readStats (2)
[85/5daa57] Submitted process > calling_pipeline:coverStats (2)
[72/fb42af] Submitted process > calling_pipeline:medakaNetwork (2)
[33/178ff6] Submitted process > calling_pipeline:medakaNetwork (3)
[8f/6feb25] Submitted process > calling_pipeline:medakaVariantHdf (4)
ERROR ~ Error executing process > 'calling_pipeline:medakaNetwork (2)'
Caused by:
  Process `calling_pipeline:medakaNetwork (2)` terminated with an error exit status (134)
Command executed:
  medaka --version
      echo r1041_e82_400bps_sup_v4.2.0
  
      echo r1041_e82_400bps_sup_v4.2.0
  
      medaka consensus align.bam ""test1.consensus_probs.hdf""         --threads 2 --regions ""NC_000962.3:999000-1999000
  "" --model r1041_e82_400bps_sup_v4.2.0
Command exit status:
  134
Command output:
  medaka 1.9.1
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0
Command error:
  Cannot import pyabpoa, some features may not be available.
  medaka 1.9.1
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0
  The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.
  .command.sh: line 8:    90 Aborted                 (core dumped) medaka consensus align.bam ""test1.consensus_probs.hdf"" --threads 2 --regions ""NC_000962.3:999000-1999000
  "" --model r1041_e82_400bps_sup_v4.2.0
Work dir:
  /home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/work/72/fb42aff10d6ba33fdc644968b2c3ff
Tip: you can replicate the issue by changing to the process work dir and entering the command `bash .command.run`
 -- Check '/home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/nextflow.log' file for details
WARN: Killing running tasks (2)
```


### Application activity log entry

_No response_",Lenfera,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/20,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc51JrEw,failing the test_data run,CLOSED,2023-10-27T12:53:55Z,2023-10-27T13:50:37Z,2023-10-27T13:25:54Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

v0.4.0 70714be

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

# running in the repo folder

nextflow run epi2me-labs/wf-bacterial-genomes --fastq ./test_data/fastq --isolates --reference_based_assembly --reference ./test_data/ref/reference.subseq.fa.gz --sample_sheet ./test_data/isolates_sample_sheet.csv --out_dir test_run



### Workflow Execution - CLI Execution Profile

standard (default)

### What happened?

N E X T F L O W  ~  version 23.04.3
NOTE: Your local project version looks outdated - a different revision is available in the remote repository [70714be9ef]
Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [amazing_carson] DSL2 - revision: d3fdcc0dd3 [master]

ERROR ~ ERROR: Validation of pipeline parameters failed!

 -- Check '.nextflow.log' file for details
ERROR ~ * --basecaller_cfg: dna_r10.4.1_e8.2_400bps_sup@v4.2.0 is not a valid enum value (dna_r10.4.1_e8.2_400bps_sup@v4.2.0)

 -- Check '.nextflow.log' file for details


WARN: Found unexpected parameters:
* --mlst_version: 2.23.0
* --flye_opts: null
* --process_label: wfbacterialgenomes
- Ignore this warning: params.schema_ignore_params = ""mlst_version,flye_opts,process_label"" 


### Relevant log output

```shell
Oct-27 14:51:07.248 [main] DEBUG nextflow.cli.Launcher - $> nextflow run epi2me-labs/wf-bacterial-genomes --fastq ./test_data/fastq --isolates --reference_based_assembly --reference ./test_data/ref/reference.subseq.fa.gz --sample_sheet ./test_data/isolates_sample_sheet.csv --out_dir test_run
Oct-27 14:51:07.326 [main] INFO  nextflow.cli.CmdRun - N E X T F L O W  ~  version 23.04.3
Oct-27 14:51:07.346 [main] DEBUG nextflow.plugin.PluginsFacade - Setting up plugin manager > mode=prod; embedded=false; plugins-dir=/home/luna.kuleuven.be/u0002316/.nextflow/plugins; core-plugins: nf-amazon@1.16.2,nf-azure@1.0.1,nf-codecommit@0.1.4,nf-console@1.0.5,nf-ga4gh@1.0.5,nf-google@1.7.3,nf-tower@1.5.12,nf-wave@0.8.4
Oct-27 14:51:07.357 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Enabled plugins: []
Oct-27 14:51:07.358 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Disabled plugins: []
Oct-27 14:51:07.361 [main] INFO  org.pf4j.DefaultPluginManager - PF4J version 3.4.1 in 'deployment' mode
Oct-27 14:51:07.372 [main] INFO  org.pf4j.AbstractPluginManager - No plugins
Oct-27 14:51:07.387 [main] DEBUG nextflow.scm.ProviderConfig - Using SCM config path: /home/luna.kuleuven.be/u0002316/.nextflow/scm
Oct-27 14:51:08.272 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/.git/config; branch: master; remote: origin; url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Oct-27 14:51:08.301 [main] DEBUG nextflow.scm.RepositoryFactory - Found Git repository result: [RepositoryFactory]
Oct-27 14:51:08.310 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/.git/config; branch: master; remote: origin; url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Oct-27 14:51:09.089 [main] INFO  nextflow.scm.AssetManager - NOTE: Your local project version looks outdated - a different revision is available in the remote repository [70714be9ef]
Oct-27 14:51:09.101 [main] DEBUG nextflow.config.ConfigBuilder - Found config base: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Oct-27 14:51:09.101 [main] DEBUG nextflow.config.ConfigBuilder - Found config local: /opt/biotools/wf-bacterial-genomes/nextflow.config
Oct-27 14:51:09.102 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Oct-27 14:51:09.102 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /opt/biotools/wf-bacterial-genomes/nextflow.config
Oct-27 14:51:09.112 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Oct-27 14:51:09.246 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Oct-27 14:51:09.452 [main] DEBUG nextflow.cli.CmdRun - Applied DSL=2 from script declararion
Oct-27 14:51:09.454 [main] INFO  nextflow.cli.CmdRun - Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [amazing_carson] DSL2 - revision: d3fdcc0dd3 [master]
Oct-27 14:51:09.455 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins default=[]
Oct-27 14:51:09.455 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins resolved requirement=[]
Oct-27 14:51:09.459 [main] DEBUG nextflow.secret.LocalSecretsProvider - Secrets store: /home/luna.kuleuven.be/u0002316/.nextflow/secrets/store.json
Oct-27 14:51:09.461 [main] DEBUG nextflow.secret.SecretsLoader - Discovered secrets providers: [nextflow.secret.LocalSecretsProvider@7b18658a] - activable => nextflow.secret.LocalSecretsProvider@7b18658a
Oct-27 14:51:09.519 [main] DEBUG nextflow.Session - Session UUID: 2ae9cbec-7d65-46a6-be31-81f97206f53d
Oct-27 14:51:09.519 [main] DEBUG nextflow.Session - Run name: amazing_carson
Oct-27 14:51:09.519 [main] DEBUG nextflow.Session - Executor pool size: 88
Oct-27 14:51:09.530 [main] DEBUG nextflow.util.ThreadPoolBuilder - Creating thread pool 'FileTransfer' minSize=10; maxSize=264; workQueue=LinkedBlockingQueue[10000]; allowCoreThreadTimeout=false
Oct-27 14:51:09.557 [main] DEBUG nextflow.cli.CmdRun - 
  Version: 23.04.3 build 5875
  Created: 11-08-2023 18:37 UTC (20:37 CEST)
  System: Linux 5.4.0-165-generic
  Runtime: Groovy 3.0.16 on OpenJDK 64-Bit Server VM 17.0.8.1+1-Ubuntu-0ubuntu120.04
  Encoding: UTF-8 (UTF-8)
  Process: 283897@gbw-s-pacbio01 [10.118.132.7]
  CPUs: 88 - Mem: 503.8 GB (2.9 GB) - Swap: 0 (0)
Oct-27 14:51:09.572 [main] DEBUG nextflow.Session - Work-dir: /opt/biotools/wf-bacterial-genomes/work [ext2/ext3]
Oct-27 14:51:09.585 [main] DEBUG nextflow.executor.ExecutorFactory - Extension executors providers=[]
Oct-27 14:51:09.593 [main] DEBUG nextflow.Session - Observer factory: DefaultObserverFactory
Oct-27 14:51:09.659 [main] DEBUG nextflow.cache.CacheFactory - Using Nextflow cache factory: nextflow.cache.DefaultCacheFactory
Oct-27 14:51:09.668 [main] DEBUG nextflow.util.CustomThreadPool - Creating default thread pool > poolSize: 89; maxThreads: 1000
Oct-27 14:51:09.724 [main] DEBUG nextflow.Session - Session start
Oct-27 14:51:09.727 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow started -- trace file: /opt/biotools/wf-bacterial-genomes/test_run/execution/trace.txt
Oct-27 14:51:09.734 [main] DEBUG nextflow.Session - Using default localLib path: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Oct-27 14:51:09.736 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Oct-27 14:51:09.737 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib/nfcore_external_java_deps.jar
Oct-27 14:51:11.702 [main] DEBUG nextflow.script.ScriptRunner - > Launching execution
Oct-27 14:51:12.396 [main] ERROR nextflow.Nextflow - ERROR: Validation of pipeline parameters failed!
Oct-27 14:51:12.408 [main] ERROR nextflow.Nextflow - * --basecaller_cfg: dna_r10.4.1_e8.2_400bps_sup@v4.2.0 is not a valid enum value (dna_r10.4.1_e8.2_400bps_sup@v4.2.0)
Oct-27 14:51:12.412 [main] WARN  nextflow.Nextflow - Found unexpected parameters:
* --mlst_version: 2.23.0
* --flye_opts: null
* --process_label: wfbacterialgenomes
Oct-27 14:51:12.413 [main] INFO  nextflow.Nextflow - - Ignore this warning: params.schema_ignore_params = ""mlst_version,flye_opts,process_label""
```


### Application activity log entry

_No response_",splaisan,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/21,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc51KHA1,failing to run test_data,CLOSED,2023-10-27T13:53:38Z,2023-10-27T14:11:32Z,2023-10-27T14:05:52Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

 v0.4.0-g70714be

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

nextflow run epi2me-labs/wf-bacterial-genomes --fastq ./test_data/fastq --isolates --reference_based_assembly --reference ./test_data/ref/reference.subseq.fa.gz --sample_sheet ./test_data/isolates_sample_sheet.csv --out_dir test_run


### Workflow Execution - CLI Execution Profile

None

### What happened?

```
N E X T F L O W  ~  version 23.04.3
Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [loving_pasteur] DSL2 - revision: 70714be9ef [master]

||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.4.0-g70714be
--------------------------------------------------------------------------------
Core Nextflow options
  revision                : master
  runName                 : loving_pasteur
  containerEngine         : docker
  launchDir               : /opt/biotools/wf-bacterial-genomes
  workDir                 : /opt/biotools/wf-bacterial-genomes/work
  projectDir              : /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes
  userName                : u0002316
  profile                 : standard
  configFiles             : /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config, /opt/biotools/wf-bacterial-genomes/nextflow.config

Input Options
  fastq                   : ./test_data/fastq
  reference_based_assembly: true
  reference               : ./test_data/ref/reference.subseq.fa.gz

Sample Options
  sample_sheet            : ./test_data/isolates_sample_sheet.csv

Output Options
  out_dir                 : test_run

Isolate options
  isolates                : true

Advanced Options
  threads                 : 3

!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:

* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x


--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v0.4.0-g70714be.
--------------------------------------------------------------------------------
Checking fastq input.
executor >  local (12)
executor >  local (12)
[5d/540bd7] process > validate_sample_sheet                                [100%] 1 of 1 
[2c/b38300] process > fastcat (2)                                          [100%] 2 of 2 
[15/a5e619] process > calling_pipeline:alignReads (1)                      [  0%] 0 of 1
[-        ] process > calling_pipeline:readStats                           -
[-        ] process > calling_pipeline:coverStats                          -
[-        ] process > calling_pipeline:splitRegions                        -
[31/2f8008] process > calling_pipeline:lookup_medaka_consensus_model (1)   [100%] 1 of 1 
[a2/68e1ce] process > calling_pipeline:lookup_medaka_variant_model (1)     [100%] 1 of 1 
[-        ] process > calling_pipeline:medakaNetwork                       -
[-        ] process > calling_pipeline:medakaConsensus                     -
[-        ] process > calling_pipeline:medakaVariantHdf                    -
[-        ] process > calling_pipeline:medakaVariant                       -
[-        ] process > calling_pipeline:runProkka                           -
[-        ] process > calling_pipeline:run_isolates:mlstSearch             -
[-        ] process > calling_pipeline:run_isolates:getPointfinderSpecies  -
[-        ] process > calling_pipeline:run_isolates:resfinder              -
[-        ] process > calling_pipeline:run_isolates:processResfinder       -
[0a/1f72d5] process > calling_pipeline:prokkaVersion                       [100%] 1 of 1 
[0e/870bc7] process > calling_pipeline:medakaVersion                       [100%] 1 of 1 
[6d/253928] process > calling_pipeline:mlstVersion                         [100%] 1 of 1 
[23/bd2054] process > calling_pipeline:getVersions                         [100%] 1 of 1 
[ab/321412] process > calling_pipeline:getParams                           [100%] 1 of 1 
[-        ] process > calling_pipeline:makeReport                          -
[-        ] process > calling_pipeline:makePerSampleReports                -
[92/60cdb1] process > calling_pipeline:collectFastqIngressResultsInDir (1) [  0%] 0 of 3
[-        ] process > output                                               -
Reference based assembly selected.
ERROR ~ Cannot invoke method resolve() on null object

 -- Check script '/home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf' at line: 586 or see '.nextflow.log' file for more details
ERROR ~ Error executing process > 'calling_pipeline:alignReads (3)'

Caused by:
  Not a valid path value type: org.codehaus.groovy.runtime.NullObject (null)


Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`

 -- Check '.nextflow.log' file for details
```

### Relevant log output

```shell
Oct-27 15:51:09.716 [main] DEBUG nextflow.cli.Launcher - $> nextflow run epi2me-labs/wf-bacterial-genomes --fastq ./test_data/fastq --isolates --reference_based_assembly --reference ./test_data/ref/reference.subseq.fa.gz --sample_sheet ./test_data/isolates_sample_sheet.csv --out_dir test_run
Oct-27 15:51:09.782 [main] INFO  nextflow.cli.CmdRun - N E X T F L O W  ~  version 23.04.3
Oct-27 15:51:09.807 [main] DEBUG nextflow.plugin.PluginsFacade - Setting up plugin manager > mode=prod; embedded=false; plugins-dir=/home/luna.kuleuven.be/u0002316/.nextflow/plugins; core-plugins: nf-amazon@1.16.2,nf-azure@1.0.1,nf-codecommit@0.1.4,nf-console@1.0.5,nf-ga4gh@1.0.5,nf-google@1.7.3,nf-tower@1.5.12,nf-wave@0.8.4
Oct-27 15:51:09.817 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Enabled plugins: []
Oct-27 15:51:09.818 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Disabled plugins: []
Oct-27 15:51:09.821 [main] INFO  org.pf4j.DefaultPluginManager - PF4J version 3.4.1 in 'deployment' mode
Oct-27 15:51:09.831 [main] INFO  org.pf4j.AbstractPluginManager - No plugins
Oct-27 15:51:09.845 [main] DEBUG nextflow.scm.ProviderConfig - Using SCM config path: /home/luna.kuleuven.be/u0002316/.nextflow/scm
Oct-27 15:51:10.824 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/.git/config; branch: master; remote: origin; url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Oct-27 15:51:10.850 [main] DEBUG nextflow.scm.RepositoryFactory - Found Git repository result: [RepositoryFactory]
Oct-27 15:51:10.859 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/.git/config; branch: master; remote: origin; url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Oct-27 15:51:11.654 [main] DEBUG nextflow.config.ConfigBuilder - Found config base: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Oct-27 15:51:11.654 [main] DEBUG nextflow.config.ConfigBuilder - Found config local: /opt/biotools/wf-bacterial-genomes/nextflow.config
Oct-27 15:51:11.655 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Oct-27 15:51:11.655 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /opt/biotools/wf-bacterial-genomes/nextflow.config
Oct-27 15:51:11.666 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Oct-27 15:51:11.833 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Oct-27 15:51:11.867 [main] DEBUG nextflow.cli.CmdRun - Applied DSL=2 from script declararion
Oct-27 15:51:11.867 [main] INFO  nextflow.cli.CmdRun - Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [loving_pasteur] DSL2 - revision: 70714be9ef [master]
Oct-27 15:51:11.867 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins default=[]
Oct-27 15:51:11.868 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins resolved requirement=[]
Oct-27 15:51:11.870 [main] DEBUG nextflow.secret.LocalSecretsProvider - Secrets store: /home/luna.kuleuven.be/u0002316/.nextflow/secrets/store.json
Oct-27 15:51:11.874 [main] DEBUG nextflow.secret.SecretsLoader - Discovered secrets providers: [nextflow.secret.LocalSecretsProvider@6df4af5] - activable => nextflow.secret.LocalSecretsProvider@6df4af5
Oct-27 15:51:11.934 [main] DEBUG nextflow.Session - Session UUID: c5808332-0855-466a-aced-f2c7f191bfab
Oct-27 15:51:11.934 [main] DEBUG nextflow.Session - Run name: loving_pasteur
Oct-27 15:51:11.934 [main] DEBUG nextflow.Session - Executor pool size: 88
Oct-27 15:51:11.946 [main] DEBUG nextflow.util.ThreadPoolBuilder - Creating thread pool 'FileTransfer' minSize=10; maxSize=264; workQueue=LinkedBlockingQueue[10000]; allowCoreThreadTimeout=false
Oct-27 15:51:11.971 [main] DEBUG nextflow.cli.CmdRun - 
  Version: 23.04.3 build 5875
  Created: 11-08-2023 18:37 UTC (20:37 CEST)
  System: Linux 5.4.0-165-generic
  Runtime: Groovy 3.0.16 on OpenJDK 64-Bit Server VM 17.0.8.1+1-Ubuntu-0ubuntu120.04
  Encoding: UTF-8 (UTF-8)
  Process: 343660@gbw-s-pacbio01 [10.118.132.7]
  CPUs: 88 - Mem: 503.8 GB (3.6 GB) - Swap: 0 (0)
Oct-27 15:51:11.990 [main] DEBUG nextflow.Session - Work-dir: /opt/biotools/wf-bacterial-genomes/work [ext2/ext3]
Oct-27 15:51:12.004 [main] DEBUG nextflow.executor.ExecutorFactory - Extension executors providers=[]
Oct-27 15:51:12.014 [main] DEBUG nextflow.Session - Observer factory: DefaultObserverFactory
Oct-27 15:51:12.116 [main] DEBUG nextflow.cache.CacheFactory - Using Nextflow cache factory: nextflow.cache.DefaultCacheFactory
Oct-27 15:51:12.131 [main] DEBUG nextflow.util.CustomThreadPool - Creating default thread pool > poolSize: 89; maxThreads: 1000
Oct-27 15:51:12.201 [main] DEBUG nextflow.Session - Session start
Oct-27 15:51:12.206 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow started -- trace file: /opt/biotools/wf-bacterial-genomes/test_run/execution/trace.txt
Oct-27 15:51:12.214 [main] DEBUG nextflow.Session - Using default localLib path: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Oct-27 15:51:12.217 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Oct-27 15:51:12.218 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib/nfcore_external_java_deps.jar
Oct-27 15:51:14.386 [main] DEBUG nextflow.script.ScriptRunner - > Launching execution
Oct-27 15:51:14.970 [main] INFO  nextflow.Nextflow - 
||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.4.0-g70714be
--------------------------------------------------------------------------------
Core Nextflow options
  revision                : master
  runName                 : loving_pasteur
  containerEngine         : docker
  launchDir               : /opt/biotools/wf-bacterial-genomes
  workDir                 : /opt/biotools/wf-bacterial-genomes/work
  projectDir              : /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes
  userName                : u0002316
  profile                 : standard
  configFiles             : /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config, /opt/biotools/wf-bacterial-genomes/nextflow.config

Input Options
  fastq                   : ./test_data/fastq
  reference_based_assembly: true
  reference               : ./test_data/ref/reference.subseq.fa.gz

Sample Options
  sample_sheet            : ./test_data/isolates_sample_sheet.csv

Output Options
  out_dir                 : test_run

Isolate options
  isolates                : true

Advanced Options
  threads                 : 3

!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:

* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x


--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v0.4.0-g70714be.
--------------------------------------------------------------------------------
Oct-27 15:51:15.219 [main] INFO  nextflow.Nextflow - Checking fastq input.
Oct-27 15:51:15.274 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wf_common` matches labels `fastq_ingress,wf_common` for process with name validate_sample_sheet
Oct-27 15:51:15.292 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.292 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.299 [main] DEBUG nextflow.executor.Executor - [warm up] executor > local
Oct-27 15:51:15.305 [main] DEBUG n.processor.LocalPollingMonitor - Creating local task monitor for executor 'local' > cpus=4; memory=8 GB; capacity=88; pollInterval=100ms; dumpInterval=5m
Oct-27 15:51:15.481 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wf_common` matches labels `fastq_ingress,wf_common` for process with name fastcat
Oct-27 15:51:15.483 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.483 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.517 [main] INFO  nextflow.Nextflow - Reference based assembly selected.
Oct-27 15:51:15.534 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:alignReads
Oct-27 15:51:15.535 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.535 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.541 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:readStats
Oct-27 15:51:15.542 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.542 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.548 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:coverStats
Oct-27 15:51:15.549 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.550 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.554 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:splitRegions
Oct-27 15:51:15.554 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.554 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.563 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:lookup_medaka_consensus_model
Oct-27 15:51:15.564 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.565 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.570 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:lookup_medaka_variant_model
Oct-27 15:51:15.571 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.571 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.583 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaNetwork
Oct-27 15:51:15.584 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.584 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.596 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaConsensus
Oct-27 15:51:15.597 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.597 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.602 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaVariantHdf
Oct-27 15:51:15.602 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.602 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.611 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaVariant
Oct-27 15:51:15.611 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.611 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.617 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:prokka` matches labels `prokka` for process with name calling_pipeline:runProkka
Oct-27 15:51:15.618 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.618 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.622 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:mlst` matches labels `mlst` for process with name calling_pipeline:run_isolates:mlstSearch
Oct-27 15:51:15.623 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.623 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.629 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:run_isolates:getPointfinderSpecies
Oct-27 15:51:15.630 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.630 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.640 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:amr` matches labels `amr` for process with name calling_pipeline:run_isolates:resfinder
Oct-27 15:51:15.641 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.641 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.648 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:run_isolates:processResfinder
Oct-27 15:51:15.649 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.649 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.654 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:prokka` matches labels `prokka` for process with name calling_pipeline:prokkaVersion
Oct-27 15:51:15.655 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.655 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.657 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaVersion
Oct-27 15:51:15.658 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.658 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.660 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:mlst` matches labels `mlst` for process with name calling_pipeline:mlstVersion
Oct-27 15:51:15.661 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.661 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.663 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:getVersions
Oct-27 15:51:15.664 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.664 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.666 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:getParams
Oct-27 15:51:15.667 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.667 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.696 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:makeReport
Oct-27 15:51:15.697 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.697 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.717 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:makePerSampleReports
Oct-27 15:51:15.718 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.718 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.722 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:collectFastqIngressResultsInDir
Oct-27 15:51:15.723 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.723 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.732 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name output
Oct-27 15:51:15.733 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.733 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.735 [main] DEBUG nextflow.Session - Workflow process names [dsl2]: resfinder, deNovo, calling_pipeline:getParams, calling_pipeline:mlstVersion, medakaVersion, alignReads, output, medakaVariant, medakaNetwork, collectFastqIngressResultsInDir, makeReport, calling_pipeline:collectFastqIngressResultsInDir, getVersions, calling_pipeline:coverStats, calling_pipeline:readStats, calling_pipeline:run_isolates:processResfinder, calling_pipeline:medakaConsensus, getPointfinderSpecies, calling_pipeline:getVersions, coverStats, calling_pipeline:runProkka, fastcat, mlstVersion, calling_pipeline:medakaVariantHdf, getParams, calling_pipeline:prokkaVersion, calling_pipeline:alignReads, medakaConsensus, validate_sample_sheet, medakaVariantHdf, calling_pipeline:run_isolates:resfinder, calling_pipeline:lookup_medaka_variant_model, calling_pipeline:medakaVersion, calling_pipeline:run_isolates:mlstSearch, readStats, runProkka, calling_pipeline:run_isolates:getPointfinderSpecies, lookup_medaka_variant_model, prokkaVersion, calling_pipeline:makePerSampleReports, lookup_medaka_consensus_model, calling_pipeline:medakaNetwork, splitRegions, calling_pipeline:makeReport, calling_pipeline:splitRegions, calling_pipeline:lookup_medaka_consensus_model, move_or_compress, processResfinder, mlstSearch, calling_pipeline:medakaVariant, makePerSampleReports
Oct-27 15:51:15.738 [main] DEBUG nextflow.Session - Igniting dataflow network (32)
Oct-27 15:51:15.738 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > validate_sample_sheet
Oct-27 15:51:15.744 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > fastcat
Oct-27 15:51:15.745 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:alignReads
Oct-27 15:51:15.745 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:readStats
Oct-27 15:51:15.746 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:coverStats
Oct-27 15:51:15.746 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:splitRegions
Oct-27 15:51:15.746 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:lookup_medaka_consensus_model
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:lookup_medaka_variant_model
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaNetwork
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaConsensus
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaVariantHdf
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaVariant
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:runProkka
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:run_isolates:mlstSearch
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:run_isolates:getPointfinderSpecies
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:run_isolates:resfinder
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:run_isolates:processResfinder
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:prokkaVersion
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaVersion
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:mlstVersion
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:getVersions
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:getParams
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:makeReport
Oct-27 15:51:15.749 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:makePerSampleReports
Oct-27 15:51:15.749 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:collectFastqIngressResultsInDir
Oct-27 15:51:15.749 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > output
Oct-27 15:51:15.749 [main] DEBUG nextflow.script.ScriptRunner - > Awaiting termination 
Oct-27 15:51:15.749 [main] DEBUG nextflow.Session - Session await
Oct-27 15:51:15.819 [Actor Thread 79] DEBUG nextflow.util.CacheHelper - Hash asset file sha-256: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/bin/workflow-glue
Oct-27 15:51:15.842 [Actor Thread 83] DEBUG nextflow.util.CacheHelper - Hash asset file sha-256: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/data/medaka_models.tsv
Oct-27 15:51:15.888 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:15.890 [Task submitter] INFO  nextflow.Session - [ab/321412] Submitted process > calling_pipeline:getParams
Oct-27 15:51:15.897 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:15.897 [Task submitter] INFO  nextflow.Session - [0a/1f72d5] Submitted process > calling_pipeline:prokkaVersion
Oct-27 15:51:15.903 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:15.903 [Task submitter] INFO  nextflow.Session - [5d/540bd7] Submitted process > validate_sample_sheet
Oct-27 15:51:15.908 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:15.909 [Task submitter] INFO  nextflow.Session - [a2/68e1ce] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
Oct-27 15:51:17.007 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 4; name: calling_pipeline:getParams; status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/ab/321412e265e6dfb37d01304470c290]
Oct-27 15:51:17.024 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:17.025 [Task submitter] INFO  nextflow.Session - [31/2f8008] Submitted process > calling_pipeline:lookup_medaka_consensus_model (1)
Oct-27 15:51:17.202 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 3; name: calling_pipeline:prokkaVersion; status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/0a/1f72d5cc3ca0a225bf2f31177070a2]
Oct-27 15:51:17.215 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:17.216 [Task submitter] INFO  nextflow.Session - [0e/870bc7] Submitted process > calling_pipeline:medakaVersion
Oct-27 15:51:18.675 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 6; name: calling_pipeline:medakaVersion; status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/0e/870bc758a3f3d7274743e8c5b0b5b6]
Oct-27 15:51:18.696 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:18.697 [Task submitter] INFO  nextflow.Session - [6d/253928] Submitted process > calling_pipeline:mlstVersion
Oct-27 15:51:28.452 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 7; name: calling_pipeline:mlstVersion; status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/6d/253928b88a84420488faf94a90eb04]
Oct-27 15:51:28.467 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:28.468 [Task submitter] INFO  nextflow.Session - [23/bd2054] Submitted process > calling_pipeline:getVersions
Oct-27 15:51:29.872 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 8; name: calling_pipeline:getVersions; status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/23/bd20541e8f1e6cd8dc2b2692f735fb]
Oct-27 15:51:37.325 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 2; name: calling_pipeline:lookup_medaka_variant_model (1); status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/a2/68e1ce0dce4d13116f48a9767b7922]
Oct-27 15:51:37.414 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 1; name: validate_sample_sheet; status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/5d/540bd7d4b8ae2fcbbe11d0ba96e070]
Oct-27 15:51:37.449 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:37.450 [Task submitter] INFO  nextflow.Session - [20/335c74] Submitted process > fastcat (1)
Oct-27 15:51:38.045 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 5; name: calling_pipeline:lookup_medaka_consensus_model (1); status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/31/2f80086f6d1e7368581b0ce3c0450b]
Oct-27 15:51:38.584 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 9; name: fastcat (1); status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/20/335c74a6db68e30f7fb05dc84d8bbd]
Oct-27 15:51:38.592 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:38.593 [Task submitter] INFO  nextflow.Session - [2c/b38300] Submitted process > fastcat (2)
Oct-27 15:51:39.553 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 10; name: fastcat (2); status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/2c/b38300b76f95b72dd8b5351ace4841]
Oct-27 15:51:39.561 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:39.562 [Task submitter] INFO  nextflow.Session - [15/a5e619] Submitted process > calling_pipeline:alignReads (1)
Oct-27 15:51:39.561 [Actor Thread 84] ERROR nextflow.extension.OperatorImpl - @unknown
java.lang.NullPointerException: Cannot invoke method resolve() on null object
	at org.codehaus.groovy.runtime.NullObject.invokeMethod(NullObject.java:91)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:44)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)
	at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:34)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)
	at org.codehaus.groovy.runtime.callsite.PojoMetaClassSite.call(PojoMetaClassSite.java:49)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:139)
	at Script_96e8d947$_runScript_closure22$_closure54$_closure74.doCall(Script_96e8d947:586)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:107)
	at org.codehaus.groovy.runtime.metaclass.TransformMetaMethod.invoke(TransformMetaMethod.java:55)
	at groovy.lang.MetaClassImpl$2.invoke(MetaClassImpl.java:1298)
	at org.codehaus.groovy.runtime.metaclass.TransformMetaMethod.doMethodInvoke(TransformMetaMethod.java:62)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:274)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1035)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:38)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:53)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:139)
	at nextflow.extension.MapOp$_apply_closure1.doCall(MapOp.groovy:56)
	at jdk.internal.reflect.GeneratedMethodAccessor226.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:107)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:323)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:274)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1035)
	at groovy.lang.Closure.call(Closure.java:412)
	at groovyx.gpars.dataflow.operator.DataflowOperatorActor.startTask(DataflowOperatorActor.java:120)
	at groovyx.gpars.dataflow.operator.DataflowOperatorActor.onMessage(DataflowOperatorActor.java:108)
	at groovyx.gpars.actor.impl.SDAClosure$1.call(SDAClosure.java:43)
	at groovyx.gpars.actor.AbstractLoopingActor.runEnhancedWithoutRepliesOnMessages(AbstractLoopingActor.java:293)
	at groovyx.gpars.actor.AbstractLoopingActor.access$400(AbstractLoopingActor.java:30)
	at groovyx.gpars.actor.AbstractLoopingActor$1.handleMessage(AbstractLoopingActor.java:93)
	at groovyx.gpars.util.AsyncMessagingCore.run(AsyncMessagingCore.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Oct-27 15:51:39.565 [Actor Thread 81] DEBUG nextflow.processor.TaskProcessor - Handling unexpected condition for
  task: name=calling_pipeline:alignReads (3); work-dir=null
  error [nextflow.exception.ProcessUnrecoverableException]: Not a valid path value type: org.codehaus.groovy.runtime.NullObject (null)
Oct-27 15:51:39.566 [Actor Thread 85] DEBUG nextflow.util.CacheHelper - Hash asset file sha-256: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/data/OPTIONAL_FILE
Oct-27 15:51:39.567 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:39.571 [Task submitter] INFO  nextflow.Session - [92/60cdb1] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (1)
Oct-27 15:51:39.572 [Actor Thread 84] DEBUG nextflow.Session - Session aborted -- Cause: Cannot invoke method resolve() on null object
Oct-27 15:51:39.576 [Actor Thread 81] ERROR nextflow.processor.TaskProcessor - Error executing process > 'calling_pipeline:alignReads (3)'

Caused by:
  Not a valid path value type: org.codehaus.groovy.runtime.NullObject (null)


Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`
Oct-27 15:51:39.578 [Actor Thread 87] DEBUG nextflow.processor.TaskProcessor - Handling unexpected condition for
  task: name=calling_pipeline:alignReads (4); work-dir=null
  error [nextflow.exception.ProcessUnrecoverableException]: Not a valid path value type: org.codehaus.groovy.runtime.NullObject (null)
Oct-27 15:51:39.580 [Actor Thread 79] DEBUG nextflow.processor.TaskProcessor - Handling unexpected condition for
  task: name=calling_pipeline:alignReads; work-dir=null
  error [java.lang.InterruptedException]: java.lang.InterruptedException
Oct-27 15:51:39.588 [Actor Thread 89] DEBUG nextflow.sort.BigSort - Sort completed -- entries: 2; slices: 1; internal sort time: 0.021 s; external sort time: 0.001 s; total time: 0.022 s
Oct-27 15:51:39.600 [Actor Thread 84] DEBUG nextflow.Session - The following nodes are still active:
[process] calling_pipeline:readStats
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:coverStats
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:splitRegions
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:medakaNetwork
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:medakaConsensus
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:medakaVariantHdf
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:medakaVariant
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:runProkka
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:run_isolates:mlstSearch
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:run_isolates:getPointfinderSpecies
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:run_isolates:resfinder
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (value) bound ; channel: resfinder_threshold
  port 2: (value) bound ; channel: resfinder_coverage
  port 3: (cntrl) -     ; channel: $

[process] calling_pipeline:run_isolates:processResfinder
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:makeReport
  status=ACTIVE
  port 0: (value) bound ; channel: versions/*
  port 1: (value) bound ; channel: params.json
  port 2: (value) OPEN  ; channel: variants/*
  port 3: (value) bound ; channel: sample_ids
  port 4: (value) OPEN  ; channel: prokka/*
  port 5: (queue) OPEN  ; channel: per_read_stats
  port 6: (value) OPEN  ; channel: fwd/*
  port 7: (value) OPEN  ; channel: rev/*
  port 8: (value) OPEN  ; channel: total_depth/*
  port 9: (value) bound ; channel: flye_stats/*
  port 10: (value) OPEN  ; channel: resfinder/*
  port 11: (value) OPEN  ; channel: mlst/*
  port 12: (cntrl) -     ; channel: $

[process] calling_pipeline:makePerSampleReports
  status=ACTIVE
  port 0: (value) bound ; channel: versions.txt
  port 1: (value) bound ; channel: params.json
  port 2: (queue) OPEN  ; channel: -
  port 3: (cntrl) -     ; channel: $

[process] output
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: fname
  port 1: (cntrl) -     ; channel: $

Oct-27 15:51:39.609 [Actor Thread 89] DEBUG nextflow.file.FileCollector - Saved collect-files list to: /opt/biotools/wf-bacterial-genomes/work/collect-file/d35a16d66436dbbd20902f201ee6075d
Oct-27 15:51:39.617 [Actor Thread 89] DEBUG nextflow.file.FileCollector - Deleting file collector temp dir: /tmp/nxf-662444189237774055
Oct-27 15:51:39.686 [main] DEBUG nextflow.Session - Session await > all processes finished
Oct-27 15:51:39.686 [main] DEBUG nextflow.Session - Session await > all barriers passed
Oct-27 15:51:39.727 [main] WARN  n.processor.TaskPollingMonitor - Killing running tasks (2)
Oct-27 15:51:39.744 [main] DEBUG nextflow.trace.WorkflowStatsObserver - Workflow completed > WorkflowStats[succeededCount=10; failedCount=0; ignoredCount=0; cachedCount=0; pendingCount=4; submittedCount=2; runningCount=-2; retriesCount=0; abortedCount=2; succeedDuration=1m 4s; failedDuration=0ms; cachedDuration=0ms;loadCpus=-4; loadMemory=0; peakRunning=4; peakCpus=4; peakMemory=0; ]
Oct-27 15:51:39.745 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow completed -- saving trace file
Oct-27 15:51:39.747 [main] DEBUG nextflow.trace.ReportObserver - Workflow completed -- rendering execution report
Oct-27 15:51:39.825 [main] DEBUG nextflow.trace.ReportObserver - Execution report summary data:
  [{""cpuUsage"":{""mean"":38.4,""min"":38.4,""q1"":38.4,""q2"":38.4,""q3"":38.4,""max"":38.4,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""process"":""getParams"",""mem"":null,""memUsage"":null,""timeUsage"":null,""vmem"":null,""reads"":{""mean"":65567,""min"":65567,""q1"":65567,""q2"":65567,""q3"":65567,""max"":65567,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""cpu"":{""mean"":38.4,""min"":38.4,""q1"":38.4,""q2"":38.4,""q3"":38.4,""max"":38.4,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""time"":{""mean"":6,""min"":6,""q1"":6,""q2"":6,""q3"":6,""max"":6,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""writes"":{""mean"":1902,""min"":1902,""q1"":1902,""q2"":1902,""q3"":1902,""max"":1902,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""}},{""cpuUsage"":{""mean"":85.2,""min"":85.2,""q1"":85.2,""q2"":85.2,""q3"":85.2,""max"":85.2,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""process"":""prokkaVersion"",""mem"":{""mean"":14585856,""min"":14585856,""q1"":14585856,""q2"":14585856,""q3"":14585856,""max"":14585856,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":25321472,""min"":25321472,""q1"":25321472,""q2"":25321472,""q3"":25321472,""max"":25321472,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""reads"":{""mean"":1560531,""min"":1560531,""q1"":1560531,""q2"":1560531,""q3"":1560531,""max"":1560531,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""cpu"":{""mean"":85.2,""min"":85.2,""q1"":85.2,""q2"":85.2,""q3"":85.2,""max"":85.2,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""time"":{""mean"":165,""min"":165,""q1"":165,""q2"":165,""q3"":165,""max"":165,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""writes"":{""mean"":239,""min"":239,""q1"":239,""q2"":239,""q3"":239,""max"":239,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""}},{""cpuUsage"":{""mean"":909.9,""min"":909.9,""q1"":909.9,""q2"":909.9,""q3"":909.9,""max"":909.9,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""},""process"":""medakaVersion"",""mem"":{""mean"":13774848,""min"":13774848,""q1"":13774848,""q2"":13774848,""q3"":13774848,""max"":13774848,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":20627456,""min"":20627456,""q1"":20627456,""q2"":20627456,""q3"":20627456,""max"":20627456,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""},""reads"":{""mean"":8475669,""min"":8475669,""q1"":8475669,""q2"":8475669,""q3"":8475669,""max"":8475669,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""},""cpu"":{""mean"":909.9,""min"":909.9,""q1"":909.9,""q2"":909.9,""q3"":909.9,""max"":909.9,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""},""time"":{""mean"":629,""min"":629,""q1"":629,""q2"":629,""q3"":629,""max"":629,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""},""writes"":{""mean"":304,""min"":304,""q1"":304,""q2"":304,""q3"":304,""max"":304,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""}},{""cpuUsage"":{""mean"":61.1,""min"":61.1,""q1"":61.1,""q2"":61.1,""q3"":61.1,""max"":61.1,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""},""process"":""mlstVersion"",""mem"":{""mean"":15085568,""min"":15085568,""q1"":15085568,""q2"":15085568,""q3"":15085568,""max"":15085568,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":26316800,""min"":26316800,""q1"":26316800,""q2"":26316800,""q3"":26316800,""max"":26316800,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""},""reads"":{""mean"":872236,""min"":872236,""q1"":872236,""q2"":872236,""q3"":872236,""max"":872236,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""},""cpu"":{""mean"":61.1,""min"":61.1,""q1"":61.1,""q2"":61.1,""q3"":61.1,""max"":61.1,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""},""time"":{""mean"":166,""min"":166,""q1"":166,""q2"":166,""q3"":166,""max"":166,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""},""writes"":{""mean"":265,""min"":265,""q1"":265,""q2"":265,""q3"":265,""max"":265,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""}},{""cpuUsage"":{""mean"":87.7,""min"":87.7,""q1"":87.7,""q2"":87.7,""q3"":87.7,""max"":87.7,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""},""process"":""getVersions"",""mem"":{""mean"":2834432,""min"":2834432,""q1"":2834432,""q2"":2834432,""q3"":2834432,""max"":2834432,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":3989504,""min"":3989504,""q1"":3989504,""q2"":3989504,""q3"":3989504,""max"":3989504,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""},""reads"":{""mean"":3791217,""min"":3791217,""q1"":3791217,""q2"":3791217,""q3"":3791217,""max"":3791217,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""},""cpu"":{""mean"":87.7,""min"":87.7,""q1"":87.7,""q2"":87.7,""q3"":87.7,""max"":87.7,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""},""time"":{""mean"":621,""min"":621,""q1"":621,""q2"":621,""q3"":621,""max"":621,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""},""writes"":{""mean"":1644274,""min"":1644274,""q1"":1644274,""q2"":1644274,""q3"":1644274,""max"":1644274,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""}},{""cpuUsage"":{""mean"":121.6,""min"":121.6,""q1"":121.6,""q2"":121.6,""q3"":121.6,""max"":121.6,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""process"":""lookup_medaka_variant_model"",""mem"":{""mean"":439128064,""min"":439128064,""q1"":439128064,""q2"":439128064,""q3"":439128064,""max"":439128064,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":12535533568,""min"":12535533568,""q1"":12535533568,""q2"":12535533568,""q3"":12535533568,""max"":12535533568,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""reads"":{""mean"":49275441,""min"":49275441,""q1"":49275441,""q2"":49275441,""q3"":49275441,""max"":49275441,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""cpu"":{""mean"":121.6,""min"":121.6,""q1"":121.6,""q2"":121.6,""q3"":121.6,""max"":121.6,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""time"":{""mean"":20162,""min"":20162,""q1"":20162,""q2"":20162,""q3"":20162,""max"":20162,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""writes"":{""mean"":28213285,""min"":28213285,""q1"":28213285,""q2"":28213285,""q3"":28213285,""max"":28213285,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""}},{""cpuUsage"":{""mean"":128.6,""min"":128.6,""q1"":128.6,""q2"":128.6,""q3"":128.6,""max"":128.6,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""},""process"":""validate_sample_sheet"",""mem"":{""mean"":441389056,""min"":441389056,""q1"":441389056,""q2"":441389056,""q3"":441389056,""max"":441389056,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":12534493184,""min"":12534493184,""q1"":12534493184,""q2"":12534493184,""q3"":12534493184,""max"":12534493184,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""},""reads"":{""mean"":49458298,""min"":49458298,""q1"":49458298,""q2"":49458298,""q3"":49458298,""max"":49458298,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""},""cpu"":{""mean"":128.6,""min"":128.6,""q1"":128.6,""q2"":128.6,""q3"":128.6,""max"":128.6,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""},""time"":{""mean"":20346,""min"":20346,""q1"":20346,""q2"":20346,""q3"":20346,""max"":20346,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""},""writes"":{""mean"":28295652,""min"":28295652,""q1"":28295652,""q2"":28295652,""q3"":28295652,""max"":28295652,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""}},{""cpuUsage"":{""mean"":126.4,""min"":126.4,""q1"":126.4,""q2"":126.4,""q3"":126.4,""max"":126.4,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""process"":""lookup_medaka_consensus_model"",""mem"":{""mean"":439443456,""min"":439443456,""q1"":439443456,""q2"":439443456,""q3"":439443456,""max"":439443456,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":12535533568,""min"":12535533568,""q1"":12535533568,""q2"":12535533568,""q3"":12535533568,""max"":12535533568,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""reads"":{""mean"":49275435,""min"":49275435,""q1"":49275435,""q2"":49275435,""q3"":49275435,""max"":49275435,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""cpu"":{""mean"":126.4,""min"":126.4,""q1"":126.4,""q2"":126.4,""q3"":126.4,""max"":126.4,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""time"":{""mean"":20099,""min"":20099,""q1"":20099,""q2"":20099,""q3"":20099,""max"":20099,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""writes"":{""mean"":28213269,""min"":28213269,""q1"":28213269,""q2"":28213269,""q3"":28213269,""max"":28213269,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""}},{""cpuUsage"":{""mean"":88.55,""min"":74.6,""q1"":81.58,""q2"":88.55,""q3"":95.53,""max"":102.5,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (2)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""process"":""fastcat"",""mem"":{""mean"":6760448,""min"":3182592,""q1"":4971520,""q2"":6760448,""q3"":8549376,""max"":10338304,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (2)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":196689920,""min"":7979008,""q1"":102334464,""q2"":196689920,""q3"":291045376,""max"":385400832,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (2)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""reads"":{""mean"":13098218.5,""min"":10982098,""q1"":12040158.25,""q2"":13098218.5,""q3"":14156278.75,""max"":15214339,""minLabel"":""fastcat (2)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (2)"",""q2Label"":""fastcat (2)"",""q3Label"":""fastcat (2)""},""cpu"":{""mean"":265.65,""min"":223.8,""q1"":244.73,""q2"":265.65,""q3"":286.58,""max"":307.5,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (2)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""time"":{""mean"":265,""min"":193,""q1"":229,""q2"":265,""q3"":301,""max"":337,""minLabel"":""fastcat (2)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (2)"",""q2Label"":""fastcat (2)"",""q3Label"":""fastcat (2)""},""writes"":{""mean"":12937781,""min"":10824139,""q1"":11880960,""q2"":12937781,""q3"":13994602,""max"":15051423,""minLabel"":""fastcat (2)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (2)"",""q2Label"":""fastcat (2)"",""q3Label"":""fastcat (2)""}},{""cpuUsage"":null,""process"":""alignReads"",""mem"":null,""memUsage"":null,""timeUsage"":null,""vmem"":null,""reads"":null,""cpu"":null,""time"":null,""writes"":null},{""cpuUsage"":null,""process"":""collectFastqIngressResultsInDir"",""mem"":null,""memUsage"":null,""timeUsage"":null,""vmem"":null,""reads"":null,""cpu"":null,""time"":null,""writes"":null}]
Oct-27 15:51:40.370 [main] DEBUG nextflow.trace.TimelineObserver - Workflow completed -- rendering execution timeline
Oct-27 15:51:40.432 [main] DEBUG nextflow.cache.CacheDB - Closing CacheDB done
Oct-27 15:51:40.452 [main] DEBUG nextflow.script.ScriptRunner - > Execution complete -- Goodbye
```


### Application activity log entry

_No response_",splaisan,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/22,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc51KSnL,bakta instead of prokka,CLOSED,2023-10-27T14:17:33Z,2024-05-30T10:52:51Z,2024-05-30T10:52:51Z,"### Is your feature related to a problem?

I recently [read from the Prokka author himself Torsten Seemann](https://twitter.com/torstenseemann/status/1565471892840259585) that [Bakta](https://github.com/oschwengers/bakta) would now be a better option to annotate bacterial genome as it is better maintained.


### Describe the solution you'd like

Would it be possible to add bakta to the pipeline and make this an option for those who want to stick to prokka?


### Describe alternatives you've considered

none for bacterial genomes but for bacterio-phages there is also [pharokka](https://github.com/gbouras13/pharokka) which makes an incredible good job.

### Additional context

thanks in advance for considering this (these)",splaisan,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/23,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc58wTps,--profile standard should have one dash,CLOSED,2024-01-22T04:14:55Z,2024-05-30T11:11:51Z,2024-05-30T11:11:50Z,"### Ask away!

I think in the test example the argument should be -profile instead of --profile",osilander,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/24,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5_22rG,Dorado models v4.3.0,CLOSED,2024-02-20T19:07:49Z,2024-07-30T13:04:47Z,2024-07-30T13:04:46Z,"### Ask away!

Hi,

Could you update the workflow to integrate the new Medaka configuration for Dorado basecalling dna_r10.4.1_e8.2_400bps@v4.3.0 ?

Thank you.",lagphase,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/25,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc5_9pyO,Does the pipeline have internal error correction?,CLOSED,2024-02-21T14:17:26Z,2024-03-11T17:10:45Z,2024-03-11T17:10:44Z,"Does the pipeline have internal error correction prior to assembly? If not, what error correction method/pipeline is recommended? Thanks.",weishwu,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/26,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6BqDQi,Information about circular contigs,CLOSED,2024-03-08T05:00:33Z,2024-11-14T05:40:15Z,2024-11-14T05:40:15Z,"### Is your feature related to a problem?

The wf-bacterial-genomes workflow enables the reconstruction of circular genomes and plasmids. In the report, the number of circular contigs is indicated. However, it is difficult to determine which contigs are circular and which are linear. It seems that this information is not provided in the report, nor in the .gbk or fasta.gz files. It is necessary to delve into the 'work' directory and locate the flye_stats.tsv file to determine whether a contig is circular or not. 

### Describe the solution you'd like

Would it be possible to indicate in the report which contigs are circular? 

### Describe alternatives you've considered

Furthermore, could this information be included in the .gbk file? Currently, all circular contigs are identified as linear in the GBK file.

Thank you in advance for your help.

Sincerly

Etienne

",frumencelab,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/27,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6Br4pl,Demo data Error: [E::fai_build3_core] Failed to open the file ref.fasta.gz,OPEN,2024-03-08T10:44:58Z,2024-03-08T12:50:45Z,,"### Ask away!

Hi,

I tried running demo data as given in your ReadMe but got below error
`[E::fai_build3_core] Failed to open the file ref.fasta.gz`",kiranpatil222,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/28,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6B1fSA,Error with Demo data,OPEN,2024-03-11T05:48:56Z,2024-03-12T05:34:07Z,,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

v1.2.0

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

```
nextflow run epi2me-labs/wf-bacterial-genomes \
    --fastq wf-bacterial-genomes-demo/isolates_fastq \
    --isolates \
    --sample_sheet wf-bacterial-genomes-demo/isolates_sample_sheet.csv \
    -profile standard
```

### Workflow Execution - CLI Execution Profile

standard (default)

### What happened?

```
ERROR ~ Error executing process > 'calling_pipeline:deNovo (2)'

Caused by:
  Process `calling_pipeline:deNovo (2)` terminated with an error exit status (1)

Command executed:

  COV_FAIL=0
  FLYE_EXIT_CODE=0
  flye    --nano-hq reads.fastq.gz --out-dir output --threads ""3"" ||     FLYE_EXIT_CODE=$?

  if [[ $FLYE_EXIT_CODE -eq 0 ]]; then
      mv output/assembly.fasta ""./test1.draft_assembly.fasta""
      mv output/assembly_info.txt ""./test1_flye_stats.tsv""
      bgzip ""test1.draft_assembly.fasta""
  else
      # flye failed --> check the log to check why
      edge_cov=$(
          grep -oP 'Mean edge coverage: \K\d+' output/flye.log             || echo 5
      )
      ovlp_cov=$(
          grep -oP 'Overlap-based coverage: \K\d+' output/flye.log             || echo 5
      )
      if [[
          $edge_cov -lt 5 ||
          $ovlp_cov -lt 5
      ]]; then
          echo -n ""Caught Flye failure due to low coverage (either mean edge cov. or ""
          echo ""overlap-based cov. were below 5)"".
          COV_FAIL=1
      elif grep -q ""No disjointigs were assembled"" output/flye.log; then
          echo -n ""Caught Flye failure due to disjointig assembly.""
          COV_FAIL=2
      else
          # exit a subshell with error so that the process fails
          ( exit $FLYE_EXIT_CODE )
      fi
  fi

Command exit status:
  1

Command output:
  (empty)

Command error:
  [2024-03-08 11:32:29] INFO: Extending reads
  [2024-03-08 11:33:26] INFO: Overlap-based coverage: 32
  [2024-03-08 11:33:26] INFO: Median overlap divergence: 0.0971861
  0% 80% 90% 100%
  [2024-03-08 11:34:32] INFO: Assembled 2 disjointigs
  [2024-03-08 11:34:32] INFO: Generating sequence
  0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
  [2024-03-08 11:34:35] INFO: Filtering contained disjointigs
  0% 50% 100%
  [2024-03-08 11:34:37] INFO: Contained seqs: 0
  [2024-03-08 11:34:37] INFO: >>>STAGE: consensus
  [2024-03-08 11:34:37] INFO: Running Minimap2
  [2024-03-08 11:35:11] INFO: Computing consensus
  Process SyncManager-1:
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap
      self.run()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/process.py"", line 108, in run
      self._target(*self._args, **self._kwargs)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 608, in _run_server
      server = cls._Server(registry, address, authkey, serializer)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 154, in __init__
      self.listener = Listener(address=address, backlog=16)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 448, in __init__
      self._listener = SocketListener(address, family, backlog)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 591, in __init__
      self._socket.bind(address)
  OSError: AF_UNIX path too long
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/bin/flye"", line 33, in <module>
      sys.exit(load_entry_point('flye==2.9.3', 'console_scripts', 'flye')())
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/main.py"", line 756, in main
      _run(args)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/main.py"", line 493, in _run
      jobs[i].run()
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/main.py"", line 284, in run
      consensus_fasta = cons.get_consensus(out_alignment, self.in_contigs,
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/polishing/consensus.py"", line 71, in get_consensus
      mp_manager = multiprocessing.Manager()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/context.py"", line 57, in Manager
      m.start()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 583, in start
      self._address = reader.recv()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 250, in recv
      buf = self._recv_bytes()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 414, in _recv_bytes
      buf = self._recv(4)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 383, in _recv
      raise EOFError
  EOFError
```

### Relevant log output

```shell
ERROR ~ Error executing process > 'calling_pipeline:deNovo (2)'

Caused by:
  Process `calling_pipeline:deNovo (2)` terminated with an error exit status (1)

Command executed:

  COV_FAIL=0
  FLYE_EXIT_CODE=0
  flye    --nano-hq reads.fastq.gz --out-dir output --threads ""3"" ||     FLYE_EXIT_CODE=$?

  if [[ $FLYE_EXIT_CODE -eq 0 ]]; then
      mv output/assembly.fasta ""./test1.draft_assembly.fasta""
      mv output/assembly_info.txt ""./test1_flye_stats.tsv""
      bgzip ""test1.draft_assembly.fasta""
  else
      # flye failed --> check the log to check why
      edge_cov=$(
          grep -oP 'Mean edge coverage: \K\d+' output/flye.log             || echo 5
      )
      ovlp_cov=$(
          grep -oP 'Overlap-based coverage: \K\d+' output/flye.log             || echo 5
      )
      if [[
          $edge_cov -lt 5 ||
          $ovlp_cov -lt 5
      ]]; then
          echo -n ""Caught Flye failure due to low coverage (either mean edge cov. or ""
          echo ""overlap-based cov. were below 5)"".
          COV_FAIL=1
      elif grep -q ""No disjointigs were assembled"" output/flye.log; then
          echo -n ""Caught Flye failure due to disjointig assembly.""
          COV_FAIL=2
      else
          # exit a subshell with error so that the process fails
          ( exit $FLYE_EXIT_CODE )
      fi
  fi

Command exit status:
  1

Command output:
  (empty)

Command error:
  [2024-03-08 11:32:29] INFO: Extending reads
  [2024-03-08 11:33:26] INFO: Overlap-based coverage: 32
  [2024-03-08 11:33:26] INFO: Median overlap divergence: 0.0971861
  0% 80% 90% 100%
  [2024-03-08 11:34:32] INFO: Assembled 2 disjointigs
  [2024-03-08 11:34:32] INFO: Generating sequence
  0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
  [2024-03-08 11:34:35] INFO: Filtering contained disjointigs
  0% 50% 100%
  [2024-03-08 11:34:37] INFO: Contained seqs: 0
  [2024-03-08 11:34:37] INFO: >>>STAGE: consensus
  [2024-03-08 11:34:37] INFO: Running Minimap2
  [2024-03-08 11:35:11] INFO: Computing consensus
  Process SyncManager-1:
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap
      self.run()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/process.py"", line 108, in run
      self._target(*self._args, **self._kwargs)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 608, in _run_server
      server = cls._Server(registry, address, authkey, serializer)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 154, in __init__
      self.listener = Listener(address=address, backlog=16)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 448, in __init__
      self._listener = SocketListener(address, family, backlog)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 591, in __init__
      self._socket.bind(address)
  OSError: AF_UNIX path too long
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/bin/flye"", line 33, in <module>
      sys.exit(load_entry_point('flye==2.9.3', 'console_scripts', 'flye')())
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/main.py"", line 756, in main
      _run(args)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/main.py"", line 493, in _run
      jobs[i].run()
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/main.py"", line 284, in run
      consensus_fasta = cons.get_consensus(out_alignment, self.in_contigs,
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/polishing/consensus.py"", line 71, in get_consensus
      mp_manager = multiprocessing.Manager()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/context.py"", line 57, in Manager
      m.start()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 583, in start
      self._address = reader.recv()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 250, in recv
      buf = self._recv_bytes()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 414, in _recv_bytes
      buf = self._recv(4)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 383, in _recv
      raise EOFError
  EOFError
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

no

### Other demo data information

_No response_",kiranpatil222,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/29,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6CJLF-,Add option for bandage plots in report,OPEN,2024-03-13T08:54:56Z,2024-05-21T08:35:16Z,,"### Is your feature related to a problem?

Not related to a problem

### Describe the solution you'd like

An option (or default) to output the gfa file and a Bandage plot of the gfa file for a quick visual summary of the assemblies (perhaps in the full summary report). Alternatively, just the Bandage plot.

### Describe alternatives you've considered

I've tried copying and renaming the assembly_graph.gfa output files from flye into the output dir, as it's possible to then make the Bandage plot. The .gfa files in the work directory aren't named by barcode so it's not possible to take them from there.

### Additional context

_No response_",osilander,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/30,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6EYFki,Sample name not included in consensus fasta file,OPEN,2024-04-02T16:10:16Z,2024-04-03T09:36:06Z,,"### Operating System

Other Linux (please specify below)

### Other Linux

Redhat

### Workflow Version

v1.1.1

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

nextflow run epi2me-labs/wf-bacterial-genomes --fastq data/fastq_pass/ --reference_based_assembly --reference GCF_900205735.1_N16961_v2_genomic.fna --sample_sheet samplesheet_epi2me.csv -profile singularity -c cambridge.config -resume

### Workflow Execution - CLI Execution Profile

singularity

### What happened?

The pipeline ran successfully but the consensus fasta files created by the pipeline have the reference name and basecaller model in the fasta header instead of the sample id. This is not particularly helpful for building alignments to create phylogenetic trees.

### Relevant log output

```shell
grep "">"" CTMA_1402.medaka.fasta

>NZ_LT906615.1 basecall_model=dna_r10.4.1_e8.2_400bps_sup@v4.2.0
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

other (please describe below)

### Other demo data information

```shell
Not tested
```
",avantonder,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/31,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6EYWBz,Output  improvements,CLOSED,2024-04-02T16:42:11Z,2024-04-02T18:05:03Z,2024-04-02T18:05:03Z,"### Is your feature related to a problem?

Show more options for workflow rather than run in nextflow command line. At the moment you can only select input and reference file

Output is limited in Report

Zoom buttons do not work correctly in report charts

### Describe the solution you'd like

It would be useful to see an output of the lengths of each contig from Flye assemblies

MLST output - it would be useful to obtain an output if MLST analysis was successful or failed as no output is not very informative

### Describe alternatives you've considered

Run Brakta instead of Prokka

### Additional context

_No response_",fraser-combe,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/32,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6G6whR,Failed to pull singularity iamge,OPEN,2024-04-25T13:10:29Z,2024-04-26T09:10:14Z,,"### Operating System

Other Linux (please specify below)

### Other Linux

RedHat Enterprise 8.3

### Workflow Version

Latest

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

ERROR ~ Error executing process > 'calling_pipeline:getParams'

Caused by:
  Failed to pull singularity image
  command: singularity pull  --name ontresearch-wf-bacterial-genomes-shaa4cda1aeeda01242c54f4af03419e9623397dc0c.img.pulling.1714050463708 docker://ontresearch/wf-bacterial-genomes:shaa4cda1aeeda01242c54f4af03419e9623397dc0c > /dev/null
  status : 255
  message:
    WARNING: SINGULARITY_CACHEDIR and APPTAINER_CACHEDIR have different values, using the latter
    INFO:    Converting OCI blobs to SIF format
    INFO:    Starting build...
    Getting image source signatures
    Copying blob sha256:f9432144bf11a2ae3ffb7360b4e32f7b18c75c7c8c125274ec3cf49d0de28e24
    Copying blob sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445c2e325ea448f8f68
    Copying blob sha256:e8b63ef4ca0ca489bb848ecf9f4db232528d222a2c0bb2a599b312ce6b5b551a
    Copying blob sha256:88397e6fd840152eca6643094559385065a6ab98a1c3c7e75eb676b9d97aad97
    Copying blob sha256:0456c71d8011447360dd461b49b6a1a4cb36edf8f7250817e99ceeb0d353f06b
    Copying blob sha256:38cad909cfed9fb07cc2c6612612435d52302b48ebcf94a2a4b77e02b8414142
    Copying blob sha256:cd889bc730171a0013130be60f28f869d7e7cc4d923396628660de9b67f7eec8
    Copying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1
    Copying blob sha256:2042b0824681af825bf6a3c7d48cf91a218427db24a26198aaa7a2e92145081d
    Copying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1
    Copying blob sha256:973691ee7cdac427dd9005f99675e8e77fb7feda0e94e11626a95e46e5d2973e
    Copying blob sha256:4a9d7e589e1778374b42cbdb32d978af00de957133897cdc1171659808fb6f7f
    Copying blob sha256:3fc3949421420f916ca77ede3295a7f762d493b84b0bc2e4a2212f8573b76e3c
    Copying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1
    Copying blob sha256:6de220563c5cae03fae0f6b66c78c7e1091b6d2a91b0d199ec712fd216399bc6
    Copying blob sha256:7f4c1460c3a6a5c0a29dd740394343f9e4dc867062c299febc85015eb3cf8606
    Copying blob sha256:8e13bd657a727a4c167b0e27b05aa3ee5dab63fda01f8b2643400f4c10053dd8
    Copying blob sha256:d8af254b567f3b0a15ba645cf6dee25e3223b4a610fe237a3ad31a4dedf679fc
    Copying blob sha256:786231868c62c95197f37ffa3046b4f0ccffc11bd49a4f206a032c700eb18ef6
    Copying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1
    Copying config sha256:755ac014996a07c3bf534514c4b2e0f7c0b97a0985a8be3111b8d76f22d8c30c
    Writing manifest to image destination
    FATAL:   While making image from oci registry: error fetching image to cache: while building SIF from layers: conveyor failed to get: while getting config: no descriptor found for reference ""0afe778952f0d96b21c5b5e679d0e4e7fa471a27de53375f550c47e3cfc5996f""

### Relevant log output

```shell
As above
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

no

### Other demo data information

_No response_",adbeggs,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/33,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6JUHD_,Basecalling options not included in basecaller.cfg.,CLOSED,2024-05-18T01:34:12Z,2024-07-30T12:55:49Z,2024-07-30T12:55:49Z,"### Ask away!

The latest version uses dna_r10.4.1_e8.2_400bps_sup@v4.3.0 for basecalling with MinKNOW. 
However, there are currently no available options to select. The latest version available is v4.2.0. What should be done in this case?
![image](https://github.com/epi2me-labs/wf-bacterial-genomes/assets/128474904/43941096-928d-4270-bbfe-b075e1e6c7bc)
",YoungMunLEE,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/34,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6LV5mR,Collapse contig coverage graphs,OPEN,2024-06-06T09:19:00Z,2024-06-06T09:47:08Z,,"### Is your feature related to a problem?

No problem, but if you are doing shotgun metagenomics for e.g. human stool samples, there are a lot of contigs!!

### Describe the solution you'd like

 The ability to collapse them or have the output on a separate page or chooseable like the Pavian sample level output would be very useful

### Describe alternatives you've considered

Doing my own pipeline

### Additional context

_No response_",adbeggs,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/35,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6M4vpZ,wf-bacterial-genomes stopped with error,CLOSED,2024-06-20T07:04:26Z,2024-08-23T14:45:15Z,2024-08-23T14:45:14Z,"### Operating System

Windows 10

### Other Linux

-

### Workflow Version

v1.2.0

### Workflow Execution

EPI2ME Desktop application

### EPI2ME Version

_No response_

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

[EPI2ME_issue_export.tar.gz](https://github.com/user-attachments/files/15910056/EPI2ME_issue_export.tar.gz)
The wf-bacterial-genomes stopped with error. The attached file is generated after clicking ""report issue"" in the desktop application.

### Relevant log output

```shell
N E X T F L O W  ~  version 23.04.2
Launching `/mnt/c/Users/lisun/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/main.nf` [Cheese-iso-001-genome] DSL2 - revision: 67ff77f941
WARN: NEXTFLOW RECURSION IS A PREVIEW FEATURE - SYNTAX AND FUNCTIONALITY CAN CHANGE IN FUTURE RELEASES

[0;92m||||||||||   [0m[2m_____ ____ ___ ____  __  __ _____      _       _
[0;92m||||||||||  [0m[2m| ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
[0;33m|||||       [0m[2m|  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
[0;33m|||||       [0m[2m| |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
[0;94m||||||||||  [0m[2m|_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
[0;94m||||||||||  [0m[1mwf-bacterial-genomes v1.2.0[0m
[2m--------------------------------------------------------------------------------[0m
[1mCore Nextflow options[0m
  [0;34mrunName          : [0;32mCheese-iso-001-genome[0m
  [0;34mcontainerEngine  : [0;32mdocker[0m
  [0;34mlaunchDir        : [0;32m/mnt/c/Users/lisun/epi2melabs/instances/wf-bacterial-genomes_01J0R9CF7AR99GSCPVW644T2EQ[0m
  [0;34mworkDir          : [0;32m/mnt/c/Users/lisun/epi2melabs/instances/wf-bacterial-genomes_01J0R9CF7AR99GSCPVW644T2EQ/work[0m
  [0;34mprojectDir       : [0;32m/mnt/c/Users/lisun/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes[0m
  [0;34muserName         : [0;32mepi2mewsl[0m
  [0;34mprofile          : [0;32mstandard[0m
  [0;34mconfigFiles      : [0;32m/mnt/c/Users/lisun/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/nextflow.config, /mnt/c/Users/lisun/epi2melabs/instances/wf-bacterial-genomes_01J0R9CF7AR99GSCPVW644T2EQ/local.config[0m

[1mInput Options[0m
  [0;34mfastq            : [0;32m/mnt/g/Cheese-pure-iso/Cheese-iso-001/20240612_2005_MN46760_FAY51710_ba62f739/fastq_pass[0m

[1mAdvanced Options[0m
  [0;34mflye_genome_size : [0;32m2800000[0m
  [0;34mflye_asm_coverage: [0;32m50[0m

[1mOutput Options[0m
  [0;34mout_dir          : [0;32m/mnt/c/Users/lisun/epi2melabs/instances/wf-bacterial-genomes_01J0R9CF7AR99GSCPVW644T2EQ/output[0m

[1mMiscellaneous Options[0m
  [0;34mthreads          : [0;32m6[0m

!! Only displaying parameters that differ from the pipeline defaults !!
[2m--------------------------------------------------------------------------------[0m
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:

* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x


[2m--------------------------------------------------------------------------------[0m
This is epi2me-labs/wf-bacterial-genomes v1.2.0.
[2m--------------------------------------------------------------------------------[0m
Searching input for [.fastq, .fastq.gz, .fq, .fq.gz] files.
Running Denovo assembly.
[45/a56415] Submitted process > calling_pipeline:prokkaVersion
[78/5fd76c] Submitted process > calling_pipeline:getParams
[ef/9f32b8] Submitted process > calling_pipeline:lookup_medaka_consensus_model (1)
[ad/e27640] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
[16/8541a5] Submitted process > fastcat (1)
[57/26ae79] Submitted process > calling_pipeline:medakaVersion
[bd/12b42c] Submitted process > calling_pipeline:mlstVersion
[fe/01ff37] Submitted process > calling_pipeline:getVersions
[13/ef9e13] Submitted process > calling_pipeline:amrCheckpoint (1)
[0c/555ea9] Submitted process > calling_pipeline:ingressCheckpoint (1)
[dc/ba2aed] Submitted process > calling_pipeline:perSampleReportingCheckpoint (1)
[c1/2100a1] Submitted process > calling_pipeline:variantCheckpoint (1)
[32/6ae7a1] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (1)
[cf/f0af7b] Submitted process > calling_pipeline:accumulateCheckpoints (1)
[ed/037feb] Submitted process > calling_pipeline:deNovo (1)
[08/905ab1] Submitted process > calling_pipeline:accumulateCheckpoints (2)
ERROR ~ Error executing process > 'calling_pipeline:deNovo (1)'

Caused by:
  Process `calling_pipeline:deNovo (1)` terminated with an error exit status (1)

Command executed:

  COV_FAIL=0
  FLYE_EXIT_CODE=0
  flye  --genome-size 2800000 --asm-coverage 50 --nano-hq reads.fastq.gz --out-dir output --threads ""6"" ||     FLYE_EXIT_CODE=$?
  
  if [[ $FLYE_EXIT_CODE -eq 0 ]]; then
      mv output/assembly.fasta ""./fastq_pass.draft_assembly.fasta""
      mv output/assembly_info.txt ""./fastq_pass_flye_stats.tsv""
      bgzip ""fastq_pass.draft_assembly.fasta""
  else
      # flye failed --> check the log to check why
      edge_cov=$(
          grep -oP 'Mean edge coverage: \K\d+' output/flye.log             || echo 5
      )
      ovlp_cov=$(
          grep -oP 'Overlap-based coverage: \K\d+' output/flye.log             || echo 5
      )
      if [[
          $edge_cov -lt 5 ||
          $ovlp_cov -lt 5
      ]]; then
          echo -n ""Caught Flye failure due to low coverage (either mean edge cov. or ""
          echo ""overlap-based cov. were below 5)"".
          COV_FAIL=1
      elif grep -q ""No disjointigs were assembled"" output/flye.log; then
          echo -n ""Caught Flye failure due to disjointig assembly.""
          COV_FAIL=2
      else
          # exit a subshell with error so that the process fails
          ( exit $FLYE_EXIT_CODE )
      fi
  fi

Command exit status:
  1

Command output:
  (empty)

Command error:
      ref_seq = aln_reader.get_region_sequence(ctg_region.ctg_id, ctg_region.start,
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/utils/sam_parser.py"", line 206, in get_region_sequence
      contig_str = self.ref_fasta[parsed_contig]
    File ""<string>"", line 2, in __getitem__
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 834, in _callmethod
      conn.send((self._id, methodname, args, kwds))
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 206, in send
      self._send_bytes(_ForkingPickler.dumps(obj))
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 411, in _send_bytes
      self._send(header + buf)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 368, in _send
      n = write(self._handle, buf)
  BrokenPipeError: [Errno 32] Broken pipe
  
  Process Process-11:
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/polishing/bubbles.py"", line 71, in _thread_worker
      ref_seq = aln_reader.get_region_sequence(ctg_region.ctg_id, ctg_region.start,
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/utils/sam_parser.py"", line 206, in get_region_sequence
      contig_str = self.ref_fasta[parsed_contig]
    File ""<string>"", line 2, in __getitem__
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 834, in _callmethod
      conn.send((self._id, methodname, args, kwds))
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 206, in send
      self._send_bytes(_ForkingPickler.dumps(obj))
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 411, in _send_bytes
      self._send(header + buf)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 368, in _send
      n = write(self._handle, buf)
  BrokenPipeError: [Errno 32] Broken pipe
  
  During handling of the above exception, another exception occurred:
  
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap
      self.run()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/process.py"", line 108, in run
      self._target(*self._args, **self._kwargs)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/polishing/bubbles.py"", line 108, in _thread_worker
      error_queue.put(e)
    File ""<string>"", line 2, in put
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 834, in _callmethod
      conn.send((self._id, methodname, args, kwds))
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 206, in send
      self._send_bytes(_ForkingPickler.dumps(obj))
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 411, in _send_bytes
      self._send(header + buf)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 368, in _send
      n = write(self._handle, buf)
  BrokenPipeError: [Errno 32] Broken pipe

Work dir:
  /mnt/c/Users/lisun/epi2melabs/instances/wf-bacterial-genomes_01J0R9CF7AR99GSCPVW644T2EQ/work/ed/037feb94e83e8046138460d4139d33

Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`

 -- Check '/mnt/c/Users/lisun/epi2melabs/instances/wf-bacterial-genomes_01J0R9CF7AR99GSCPVW644T2EQ/nextflow.log' file for details
WARN: Killing running tasks (1)
```


### Application activity log entry

```shell
No
```


### Were you able to successfully run the latest version of the workflow with the demo data?

yes

### Other demo data information

_No response_",liatslu,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/36,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6NdJLb,Flye circular prediction,CLOSED,2024-06-25T17:19:40Z,2024-11-14T05:39:21Z,2024-11-14T05:39:21Z,"### Is your feature related to a problem?

no

### Describe the solution you'd like

Can either the flye_stats.tsv file be saved in the output file, or the contigs be reported as circular/linear in the HTML file output.

### Describe alternatives you've considered

Manually copying file out of intermediate subdirectories.

### Additional context

_No response_",VICTO160,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/37,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6Nkz09,Script compilation error on test dataset,CLOSED,2024-06-26T12:42:31Z,2024-06-26T13:30:55Z,2024-06-26T13:30:55Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

v1.2.0

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

nextflow run epi2me-labs/wf-bacterial-genomes \
    --fastq wf-bacterial-genomes-demo/isolates_fastq \
    --isolates \
    --sample_sheet wf-bacterial-genomes-demo/isolates_sample_sheet.csv \
    -profile standard


### Workflow Execution - CLI Execution Profile

None

### What happened?

Hello, 
I tried running the test dataset before using my own data and I get the following error: 
```
 N E X T F L O W   ~  version 24.04.2

Pulling epi2me-labs/wf-bacterial-genomes ...
 downloaded from https://github.com/epi2me-labs/wf-bacterial-genomes.git
Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [hopeful_wiles] DSL2 - revision: 6af54574c3 [master]

ERROR ~ Script compilation error
- file : /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf
- cause: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^

1 error
```

I tried other workflows (like wf-metagenomes) and they work, so it does not seem related to the Nextflow installation. I also tried removing the wf with `nextflow drop` and downloading it again but the issue persists. Even trying to get the help message by running `nextflow run epi2me-labs/wf-bacterial-genomes --help` results on the same Script compilation error from above. Do you guys have any idea of what might be causing the issue? Thanks a lot for your time!
Best, 
Juan. 

### Relevant log output

```shell
Jun-26 14:26:54.503 [main] DEBUG nextflow.cli.Launcher - $> nextflow run epi2me-labs/wf-bacterial-genomes --fastq wf-bacterial-genomes-demo/isolates_fastq --isolates --sample_sheet wf-bacterial-genomes-demo
/isolates_sample_sheet.csv -profile standard
Jun-26 14:26:54.611 [main] DEBUG nextflow.cli.CmdRun - N E X T F L O W  ~  version 24.04.2
Jun-26 14:26:54.638 [main] DEBUG nextflow.plugin.PluginsFacade - Setting up plugin manager > mode=prod; embedded=false; plugins-dir=/home/bioinfoserver/.nextflow/plugins; core-plugins: nf-amazon@2.5.2,nf-az
ure@1.6.0,nf-cloudcache@0.4.1,nf-codecommit@0.2.0,nf-console@1.1.3,nf-ga4gh@1.3.0,nf-google@1.13.2,nf-tower@1.9.1,nf-wave@1.4.2
Jun-26 14:26:54.652 [main] INFO  o.pf4j.DefaultPluginStatusProvider - Enabled plugins: []
Jun-26 14:26:54.653 [main] INFO  o.pf4j.DefaultPluginStatusProvider - Disabled plugins: []
Jun-26 14:26:54.656 [main] INFO  org.pf4j.DefaultPluginManager - PF4J version 3.10.0 in 'deployment' mode
Jun-26 14:26:54.671 [main] INFO  org.pf4j.AbstractPluginManager - No plugins
Jun-26 14:26:54.688 [main] DEBUG nextflow.scm.ProviderConfig - Using SCM config path: /home/bioinfoserver/.nextflow/scm
Jun-26 14:26:54.724 [main] DEBUG nextflow.scm.RepositoryFactory - Found Git repository result: [RepositoryFactory]
Jun-26 14:26:54.736 [main] INFO  nextflow.cli.CmdRun - Pulling epi2me-labs/wf-bacterial-genomes ...
Jun-26 14:26:54.741 [main] DEBUG nextflow.scm.RepositoryProvider - Request [credentials -:-] -> https://api.github.com/repos/epi2me-labs/wf-bacterial-genomes/contents/nextflow.config
Jun-26 14:26:56.419 [main] DEBUG nextflow.scm.RepositoryProvider - Request [credentials -:-] -> https://api.github.com/repos/epi2me-labs/wf-bacterial-genomes/contents/main.nf
Jun-26 14:26:56.734 [main] DEBUG nextflow.scm.RepositoryProvider - Request [credentials -:-] -> https://api.github.com/repos/epi2me-labs/wf-bacterial-genomes
Jun-26 14:26:56.931 [main] DEBUG nextflow.scm.AssetManager - Pulling epi2me-labs/wf-bacterial-genomes -- Using remote clone url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Jun-26 14:27:06.109 [main] INFO  nextflow.cli.CmdRun -  downloaded from https://github.com/epi2me-labs/wf-bacterial-genomes.git
Jun-26 14:27:06.143 [main] DEBUG nextflow.config.ConfigBuilder - Found config base: /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Jun-26 14:27:06.145 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Jun-26 14:27:06.152 [main] DEBUG n.secret.LocalSecretsProvider - Secrets store: /home/bioinfoserver/.nextflow/secrets/store.json
Jun-26 14:27:06.156 [main] DEBUG nextflow.secret.SecretsLoader - Discovered secrets providers: [nextflow.secret.LocalSecretsProvider@578a5ce8] - activable => nextflow.secret.LocalSecretsProvider@578a5ce8
Jun-26 14:27:06.168 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Jun-26 14:27:06.404 [main] DEBUG nextflow.cli.CmdRun - Applied DSL=2 from script declaration
Jun-26 14:27:06.405 [main] DEBUG nextflow.cli.CmdRun - Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [hopeful_wiles] DSL2 - revision: 6af54574c3 [master]
Jun-26 14:27:06.407 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins default=[]
Jun-26 14:27:06.407 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins resolved requirement=[]
Jun-26 14:27:06.477 [main] DEBUG nextflow.Session - Session UUID: cb1ae23f-847d-4221-90d7-8f22e4fd2928
Jun-26 14:27:06.477 [main] DEBUG nextflow.Session - Run name: hopeful_wiles
Jun-26 14:27:06.478 [main] DEBUG nextflow.Session - Executor pool size: 28
Jun-26 14:27:06.490 [main] DEBUG nextflow.file.FilePorter - File porter settings maxRetries=3; maxTransfers=50; pollTimeout=null
Jun-26 14:27:06.518 [main] DEBUG nextflow.cli.CmdRun -
  Version: 24.04.2 build 5914
  Created: 29-05-2024 06:19 UTC (08:19 CEST)
  System: Linux 4.15.0-213-generic
  Runtime: Groovy 4.0.21 on OpenJDK 64-Bit Server VM 21-internal-adhoc.conda.src
  Encoding: UTF-8 (UTF-8)
  Process: 28691@bioinfoserver [127.0.1.1]
  CPUs: 28 - Mem: 251.4 GB (192.9 GB) - Swap: 976 MB (975 MB) - Virtual threads ON
Jun-26 14:27:06.552 [main] DEBUG nextflow.Session - Work-dir: /home/bioinfoserver/projects/juan/bet/miboc/epi2me/work [ext2/ext3]
Jun-26 14:27:06.588 [main] DEBUG nextflow.executor.ExecutorFactory - Extension executors providers=[]
Jun-26 14:27:06.603 [main] DEBUG nextflow.Session - Observer factory: DefaultObserverFactory
Jun-26 14:27:06.682 [main] DEBUG nextflow.cache.CacheFactory - Using Nextflow cache factory: nextflow.cache.DefaultCacheFactory
Jun-26 14:27:06.691 [main] DEBUG nextflow.util.CustomPoolFactory - Creating virtual thread pool
Jun-26 14:27:06.761 [main] DEBUG nextflow.Session - Session start
Jun-26 14:27:06.765 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow started -- trace file: /home/bioinfoserver/projects/juan/bet/miboc/epi2me/output/execution/trace.txt
Jun-26 14:27:06.770 [main] DEBUG nextflow.Session - Using default localLib path: /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Jun-26 14:27:06.774 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Jun-26 14:27:06.774 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib/nfcore_external_java_deps.jar
Jun-26 14:27:07.996 [main] DEBUG nextflow.script.ScriptRunner - Parsed script files:
Jun-26 14:27:08.004 [main] ERROR nextflow.cli.Launcher - Script compilation error
- file : /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf
- cause: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^

1 error

nextflow.exception.ScriptCompilationException: Script compilation error
- file : /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf
- cause: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^

1 error

        at nextflow.script.ScriptParser.parse0(ScriptParser.groovy:196)
        at nextflow.script.ScriptParser.parse(ScriptParser.groovy:206)
        at nextflow.script.ScriptRunner.parseScript(ScriptRunner.groovy:229)
        at nextflow.script.ScriptRunner.execute(ScriptRunner.groovy:136)
        at nextflow.cli.CmdRun.run(CmdRun.groovy:372)
        at nextflow.cli.Launcher.run(Launcher.groovy:503)
        at nextflow.cli.Launcher.main(Launcher.groovy:657)
Caused by: org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed:
Script_e5c63c8040c5e648: 862: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^

1 error

        at org.codehaus.groovy.control.ErrorCollector.failIfErrors(ErrorCollector.java:292)
        at org.codehaus.groovy.control.CompilationUnit$IPrimaryClassNodeOperation.doPhaseOperation(CompilationUnit.java:980)
        at org.codehaus.groovy.control.CompilationUnit.processPhaseOperations(CompilationUnit.java:692)
        at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:666)
        at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:373)
        at groovy.lang.GroovyClassLoader.lambda$parseClass$2(GroovyClassLoader.java:316)
        at org.codehaus.groovy.runtime.memoize.StampedCommonCache.compute(StampedCommonCache.java:163)
        at org.codehaus.groovy.runtime.memoize.StampedCommonCache.getAndPut(StampedCommonCache.java:154)
        at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:314)
        at groovy.lang.GroovyShell.parseClass(GroovyShell.java:572)
        at groovy.lang.GroovyShell.parse(GroovyShell.java:585)
        at groovy.lang.GroovyShell.parse(GroovyShell.java:639)
        at groovy.lang.GroovyShell.parse(GroovyShell.java:643)
        at nextflow.script.ScriptParser.parse0(ScriptParser.groovy:175)
        ... 6 common frames omitted
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

no

### Other demo data information

_No response_",jdiazsupsi,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/38,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6OZckF,Help? Error running nextflow run epi2me-labs/wf-bacterial-genomes -help,CLOSED,2024-07-03T16:31:22Z,2024-07-04T10:07:45Z,2024-07-04T10:07:45Z,"### Ask away!

While trying to assist a user to run wf-bacterial-genomes on a Linux Cluster, I installed nextflow. After installation,

i tried wf-bacterial-genomes --help and got an error:


./nextflow run epi2me-labs/wf-bacterial-genomes -help

 N E X T F L O W   ~  version 24.04.2

Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [focused_marconi] DSL2 - revision: 6af54574c3 [master]

ERROR ~ Script compilation error
- file : /home/xxxx/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf
- cause: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^

1 error


on .nextflow.log i got a mention to the same error


Jul-03 17:28:33.365 [main] DEBUG nextflow.script.ScriptRunner - Parsed script files:
Jul-03 17:28:33.374 [main] ERROR nextflow.cli.Launcher - Script compilation error
- file : /home/xxxx/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf
- cause: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^

1 error


Could you please provide some help on solving this?
Thanks!

",greytear,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/39,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6QutiS,Error executing process > 'calling_pipeline:medakaNetwork (1)',OPEN,2024-07-24T17:55:45Z,2024-07-31T20:45:35Z,,"### Operating System

macOS

### Other Linux

_No response_

### Workflow Version

v1.2.0

### Workflow Execution

EPI2ME Desktop application

### EPI2ME Version

v5.1.14

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

standard (default)

### What happened?

Hi!!!
We are running the workflow using the desktop version (however we are also having the same error using the command line). We have several samples (files) but some of them we cannot run using the workflow. It means that with some samples (files) the workflow ran perfectly but with other samples (files) appeared the following error: 



Error executing process > 'calling_pipeline:medakaNetwork (1)'

Caused by:
  Process `calling_pipeline:medakaNetwork (1)` terminated with an error exit status (137)

Command executed:

  medaka --version
      echo r1041_e82_400bps_sup_v4.2.0
  
      echo r1041_e82_400bps_sup_v4.2.0
  
      medaka consensus align.bam ""barcode06.consensus_probs.hdf""         --threads 2 --regions ""contig_1:0-1000000
  "" --model r1041_e82_400bps_sup_v4.2.0

Command exit status:
  137

Command output:
  medaka 1.11.3
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0

Command error:
  medaka 1.11.3
  Cannot import pyabpoa, some features may not be available.
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0
  Cannot import pyabpoa, some features may not be available.
  [14:24:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.
  [14:24:04 - Predict] Processing region(s): contig_1:0-1000000
  [14:24:04 - Predict] Using model: /home/epi2melabs/conda/lib/python3.8/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.
  [14:24:04 - BAMFile] Creating pool of 16 BAM file sets.
  [14:24:04 - Predict] Processing 1 long region(s) with batching.
  [14:24:04 - MdlStrTF] Model 
  [14:24:04 - MdlStrTF] loading weights from /tmp/tmpluc93g_q/model/variables/variables (using expect partial)
  [14:24:04 - Sampler] Initializing sampler for consensus of region contig_1:0-1000000.
  [14:24:04 - PWorker] Running inference for 1.0M draft bases.
  [14:24:06 - Feature] Pileup counts do not span requested region, requested contig_1:0-1000000, received 3-999999.
  [14:24:06 - Feature] Processed contig_1:3.0-999999.0 (median depth 112.0)
  [14:24:06 - Sampler] Took 2.10s to make features.
  2024-07-24 14:24:09.796869: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:24:09.803240: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:24:09.872491: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:24:09.885988: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:24:10.262625: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  .command.sh: line 8:    98 Killed                  medaka consensus align.bam ""barcode06.consensus_probs.hdf"" --threads 2 --regions ""contig_1:0-1000000
  "" --model r1041_e82_400bps_sup_v4.2.0

Work dir:
  /Users/industria/epi2melabs/instances/wf-bacterial-genomes_01J3JHG4VTBFPSAMNT30EHY8ZZ/work/c0/d8d6038c8162f13021214ed41e53d7

Tip: you can replicate the issue by changing to the process work dir and entering the command `bash .command.run`

### Relevant log output

```shell
N E X T F L O W  ~  version 23.04.2
Launching `/Users/industria/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/main.nf` [zen_rich] DSL2 - revision: 67ff77f941
WARN: NEXTFLOW RECURSION IS A PREVIEW FEATURE - SYNTAX AND FUNCTIONALITY CAN CHANGE IN FUTURE RELEASES
||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v1.2.0
--------------------------------------------------------------------------------
Core Nextflow options
  runName        : zen_rich
  containerEngine: docker
  launchDir      : /Users/industria/epi2melabs/instances/wf-bacterial-genomes_01J3JJMARPQ4M98X7Y0P13A40J
  workDir        : /Users/industria/epi2melabs/instances/wf-bacterial-genomes_01J3JJMARPQ4M98X7Y0P13A40J/work
  projectDir     : /Users/industria/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes
  userName       : industria
  profile        : standard
  configFiles    : /Users/industria/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/nextflow.config
Input Options
  fastq          : /Library/MinKNOW/data/WGS_Microbiolo_icmt_ces/Ensayo1_18062024/20240618_1535_MN44954_FAY44725_fd76f707/fastq_pass/barcode04
Output Options
  out_dir        : /Users/industria/epi2melabs/instances/wf-bacterial-genomes_01J3JJMARPQ4M98X7Y0P13A40J/output
!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:
* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x
--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v1.2.0.
--------------------------------------------------------------------------------
Searching input for [.fastq, .fastq.gz, .fq, .fq.gz] files.
Running Denovo assembly.
[11/4c3180] Submitted process > calling_pipeline:getParams
[aa/29977b] Submitted process > fastcat (1)
[0f/04bf97] Submitted process > calling_pipeline:prokkaVersion
[0b/dc71a8] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
[48/c46955] Submitted process > calling_pipeline:lookup_medaka_consensus_model (1)
[18/0fbf57] Submitted process > calling_pipeline:medakaVersion
[31/400630] Submitted process > calling_pipeline:mlstVersion
[d3/53ab8a] Submitted process > calling_pipeline:getVersions
[b3/5b0465] Submitted process > calling_pipeline:variantCheckpoint (1)
[8c/5133b1] Submitted process > calling_pipeline:perSampleReportingCheckpoint (1)
[2c/b95220] Submitted process > calling_pipeline:amrCheckpoint (1)
[ec/359d81] Submitted process > calling_pipeline:ingressCheckpoint (1)
[08/891809] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (1)
[3c/0d5a8e] Submitted process > calling_pipeline:deNovo (1)
[8a/fff31d] Submitted process > calling_pipeline:accumulateCheckpoints (1)
[d8/76aca0] Submitted process > calling_pipeline:accumulateCheckpoints (2)
[60/c2b2ae] Submitted process > calling_pipeline:accumulateCheckpoints (3)
[c3/815b7c] Submitted process > calling_pipeline:accumulateCheckpoints (4)
[6a/ea00bd] Submitted process > calling_pipeline:alignReads (1)
[ea/d63bb4] Submitted process > calling_pipeline:alignmentCheckpoint (1)
[cc/bdaf14] Submitted process > calling_pipeline:coverStats (1)
[85/f50ed1] Submitted process > calling_pipeline:readStats (1)
[96/4bc10b] Submitted process > calling_pipeline:splitRegions (1)
[b9/cf29f9] Submitted process > calling_pipeline:accumulateCheckpoints (5)
[d8/675260] Submitted process > calling_pipeline:medakaNetwork (2)
[0b/7a1570] Submitted process > calling_pipeline:medakaNetwork (3)
[1b/9d1a96] Submitted process > calling_pipeline:medakaNetwork (4)
[2f/97e54d] Submitted process > calling_pipeline:medakaNetwork (1)
[0b/7a1570] NOTE: Process `calling_pipeline:medakaNetwork (3)` terminated with an error exit status (137) -- Execution is retried (1)
[af/f72104] Re-submitted process > calling_pipeline:medakaNetwork (3)
[2f/97e54d] NOTE: Process `calling_pipeline:medakaNetwork (1)` terminated with an error exit status (137) -- Execution is retried (1)
[d8/675260] NOTE: Process `calling_pipeline:medakaNetwork (2)` terminated with an error exit status (137) -- Execution is retried (1)
[af/42ff0c] Re-submitted process > calling_pipeline:medakaNetwork (1)
[9f/40d55b] Re-submitted process > calling_pipeline:medakaNetwork (2)
ERROR ~ Error executing process > 'calling_pipeline:medakaNetwork (3)'
Caused by:
  Process `calling_pipeline:medakaNetwork (3)` terminated with an error exit status (137)
Command executed:
  medaka --version
      echo r1041_e82_400bps_sup_v4.2.0
  
      echo r1041_e82_400bps_sup_v4.2.0
  
      medaka consensus align.bam ""barcode04.consensus_probs.hdf""         --threads 2 --regions ""contig_1:1998000-2772987
  "" --model r1041_e82_400bps_sup_v4.2.0
Command exit status:
  137
Command output:
  medaka 1.11.3
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0
Command error:
  medaka 1.11.3
  Cannot import pyabpoa, some features may not be available.
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0
  Cannot import pyabpoa, some features may not be available.
  [14:44:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.
  [14:44:47 - Predict] Processing region(s): contig_1:1998000-2772987
  [14:44:47 - Predict] Using model: /home/epi2melabs/conda/lib/python3.8/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.
  [14:44:47 - BAMFile] Creating pool of 16 BAM file sets.
  [14:44:47 - Predict] Processing 1 long region(s) with batching.
  [14:44:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0xffff349e4c10>
  [14:44:48 - MdlStrTF] loading weights from /tmp/tmp48_v3ah3/model/variables/variables (using expect partial)
  [14:44:48 - Sampler] Initializing sampler for consensus of region contig_1:1998000-2772987.
  [14:44:48 - PWorker] Running inference for 0.8M draft bases.
  [14:44:49 - Feature] Processed contig_1:1998000.0-2772986.0 (median depth 119.0)
  [14:44:49 - Sampler] Took 1.26s to make features.
  2024-07-24 14:44:52.874826: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:44:52.882347: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:44:53.237184: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:44:53.294152: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:44:53.897555: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  [14:45:00 - PWorker] Batches in cache: 2.
  [14:45:00 - PWorker] 79.7% Done (0.6/0.8 Mbases) in 12.0s
  .command.sh: line 8:    98 Killed                  medaka consensus align.bam ""barcode04.consensus_probs.hdf"" --threads 2 --regions ""contig_1:1998000-2772987
  "" --model r1041_e82_400bps_sup_v4.2.0
Work dir:
  /Users/industria/epi2melabs/instances/wf-bacterial-genomes_01J3JJMARPQ4M98X7Y0P13A40J/work/af/f72104527b947fbc7a372545e9aaed
Tip: you can replicate the issue by changing to the process work dir and entering the command `bash .command.run`
 -- Check '/Users/industria/epi2melabs/instances/wf-bacterial-genomes_01J3JJMARPQ4M98X7Y0P13A40J/nextflow.log' file for details
WARN: Killing running tasks (2)
Invocation logs
2024-07-24T14:34Z  Initialising
2024-07-24T14:34Z  Reading launch data
2024-07-24T14:34Z  Acquiring database record
2024-07-24T14:34Z  Starting workflow invocation
2024-07-24T14:34Z  Connecting to app via IPC
2024-07-24T14:34Z  Awaiting weblog via HTTP on 53071
2024-07-24T14:34Z  Launching nextflow subprocess
2024-07-24T14:34Z  Uplink established to app
2024-07-24T14:45Z  Subprocess closed
2024-07-24T14:45Z  Exiting
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

yes

### Other demo data information

_No response_",ycuesta,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/40,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6Q9nEv,wf-bacterial-genomes  workflow not working,CLOSED,2024-07-26T11:51:52Z,2024-07-30T12:25:30Z,2024-07-30T12:25:30Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

 N E X T F L O W   ~  version 24.04.3

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

nextflow run epi2me-labs/wf-bacterial-genomes -help

### Workflow Execution - CLI Execution Profile

standard (default)

### What happened?

I have been using wf-bacterial-genomes workflow for last 2 years. It worked fine till date. However, now it started showing following erros 

""ERROR ~ Script compilation error
- file : /home/hmn/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf
- cause: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^
I checked main.nf file fow syntax error but it is perfectly fine. Still I downloaded new file from source ""https://github.com/epi2me-labs/wf-bacterial-genomes/blob/master/main.nf""

Upgraded nextflow for latest version too.
Still not working for me. Need suggestions to troubleshoot.

### Relevant log output

```shell
na
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

yes

### Other demo data information

_No response_",bunnu27,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/41,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6ToESx,From basecalling to error correction (Fastq to Fasta) as input to wf-bacterial genome,OPEN,2024-08-21T00:29:07Z,2024-08-21T00:29:07Z,,"### Ask away!

Hi 
I want to ask that downstream from base calling we do error-correction using dorrado , the step which convert fastq to fasta. However in wf-bacterial workflow we directly use fastq. Which fastq is it - uncorrected. And can we use fasta as input.
Many thanks ",jibrantahir,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/42,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6ToFBw,"Can unclassified bams from basecalling which could not be demultplexed, be of some use in reference based assembly",OPEN,2024-08-21T00:33:07Z,2024-08-21T00:33:07Z,,"### Ask away!

Hi
When we basecall and demultiplex our pod5 reads, there are some unclassified bam piled up in one file. It still has reads but could not be demultiplexed. Is there a way to still utilize them- for example in a reference based assembly scenario, can we use them?
Thank you",jibrantahir,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/43,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6Vlz4R,can only analyse one barcode at a time,CLOSED,2024-09-06T07:24:21Z,2024-09-12T20:05:34Z,2024-09-12T20:05:33Z,"### Ask away!

The workflow fails or the laptop freezes when i try to run more than one sample at a time. our laptop has Inspiron G15 5530: 13th Gen Intel Core i9-13900HX (24MB Cache, up to 4.9 GHz, 12 cores),15.6"" FHD (1920x1080) ComfortViewPlus,16GB (2x8GB) DDR5 4800MHz, 1TB SSD PCIe M.2, NVIDIA GeForce RTX 4060 8GB GDDR6.

we are not even annotating with Prokka.
is there anything we can do so that we can analyse 24 barcodes? they do not need to be analysed in parallel but just a batch upload",nrt94,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/44,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6WWKz8,"Pipeline failure from process 'calling_pipeline:makeReport""",CLOSED,2024-09-12T13:24:33Z,2024-11-22T14:55:25Z,2024-11-17T19:07:05Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

1.3.0

### Workflow Execution

Command line (Cluster)

### Other workflow execution

In Conda environment

### EPI2ME Version

_No response_

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

This is an issue that seems to occur during a handful of different executions; however, today it occurred after attempting to execute the following:

nextflow run main.nf -profile singularity --bam /lab_data/daniels_lab/tysh/nanopore_seq/calls.bam  --out_dir /lab_data/des/ --reference_based_assembly --reference ../references/mycobacteria/NZ_HG964481.1.fasta --override_basecaller_cfg dna_r9.4.1_e8_hac@v3.3

### Relevant log output

```shell
Caused by:
  Process `calling_pipeline:makeReport` terminated with an error exit status (1)


Command executed:

  workflow-glue report     --stats per_read_stats/*          --prokka               --versions versions     --params params.json     --output wf-bacterial-genomes-report.html     --sample_ids calls

Command exit status:
  1

Command output:
  (empty)

Command error:
  [07:13:01 - workflow_glue] Bootstrapping CLI.
  [07:13:12 - matplotlib] Matplotlib created a temporary cache directory at /tmp/matplotlib-18dbyb0q because the default path (/home/tsherman/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
  [07:13:13 - matplotlib.font_manager] generated new fontManager
  [07:13:13 - workflow_glue] Starting entrypoint.
  Traceback (most recent call last):
    File ""/home/tsherman/wf-bacterial-genomes/bin/workflow-glue"", line 7, in <module>
      cli()
    File ""/home/tsherman/wf-bacterial-genomes/bin/workflow_glue/__init__.py"", line 82, in cli
      args.func(args)
    File ""/home/tsherman/wf-bacterial-genomes/bin/workflow_glue/report.py"", line 594, in main
      report = create_report(args, logger)
    File ""/home/tsherman/wf-bacterial-genomes/bin/workflow_glue/report.py"", line 290, in create_report
      zip(args.sample_ids_with_stats, args.stats), key=lambda x: x[0]
  TypeError: 'NoneType' object is not iterable
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

yes

### Other demo data information

_No response_",forty2wallabyway,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/45,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6bbiwg,"Bacterial genome wf ""Stopped with error""",OPEN,2024-10-23T08:13:02Z,2024-11-14T05:42:48Z,,"### Operating System

Windows 11

### Other Linux

_No response_

### Workflow Version

v1.2.0

### Workflow Execution

EPI2ME Desktop (Local)

### Other workflow execution

_No response_

### EPI2ME Version

v5.2.1

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

Uploaded fastq files (92 files), it runs for about 30 mins and then shows a ""stopped with error"". Tried it a few times. I then troubleshooted with the demo-data and the workflow works.
Opted to then run the files in batches of 10 and it works.

### Relevant log output

```shell
N E X T F L O W ~ version 23.04.2
Launching `/mnt/c/Users/Sequencing/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/main.nf` [competent_rosalind] DSL2 - revision: 67ff77f941
WARN: NEXTFLOW RECURSION IS A PREVIEW FEATURE - SYNTAX AND FUNCTIONALITY CAN CHANGE IN FUTURE RELEASES
|||||||||| _____ ____ ___ ____ __ __ _____ _ _
|||||||||| | ____| _ \_ _|___ \| \/ | ____| | | __ _| |__ ___
||||| | _| | |_) | | __) | |\/| | _| _____| |/ _` | '_ \/ __|
||||| | |___| __/| | / __/| | | | |__|_____| | (_| | |_) \__ \
|||||||||| |_____|_| |___|_____|_| |_|_____| |_|\__,_|_.__/|___/
|||||||||| wf-bacterial-genomes v1.2.0
--------------------------------------------------------------------------------
Core Nextflow options
runName : competent_rosalind
containerEngine: docker
launchDir : /mnt/c/Users/Sequencing/epi2melabs/instances/wf-bacterial-genomes_01JACZ50KNN6EF71EKC6551GPZ
workDir : /mnt/c/Users/Sequencing/epi2melabs/instances/wf-bacterial-genomes_01JACZ50KNN6EF71EKC6551GPZ/work
projectDir : /mnt/c/Users/Sequencing/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes
userName : epi2mewsl
profile : standard
configFiles : /mnt/c/Users/Sequencing/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/nextflow.config
Input Options
fastq : /mnt/c/data/Anjali_colistin_16Oct2024/no_sample/20241016_1356_MN44856_FAZ04752_0602dabf/fastq_pass
Output Options
out_dir : /mnt/c/Users/Sequencing/epi2melabs/instances/wf-bacterial-genomes_01JACZ50KNN6EF71EKC6551GPZ/output
!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:
* The nf-core framework
https://doi.org/10.1038/s41587-020-0439-x
--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v1.2.0.
--------------------------------------------------------------------------------
Searching input for [.fastq, .fastq.gz, .fq, .fq.gz] files.
Running Denovo assembly.
[47/7a7159] Submitted process > calling_pipeline:getParams
[5c/66f392] Submitted process > fastcat (2)
[19/fa4991] Submitted process > calling_pipeline:prokkaVersion
[14/4caee5] Submitted process > fastcat (1)
[e0/e89f79] Submitted process > fastcat (4)
[3b/f22c3d] Submitted process > fastcat (5)
[5b/a90141] Submitted process > fastcat (3)
[65/168365] Submitted process > fastcat (6)
[73/79fe56] Submitted process > calling_pipeline:lookup_medaka_consensus_model (1)
[1e/31f082] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
[ff/d1dcef] Submitted process > fastcat (7)
[b7/0c158b] Submitted process > fastcat (8)
[68/58af70] Submitted process > calling_pipeline:ingressCheckpoint (1)
[2a/e36ff6] Submitted process > fastcat (9)
[67/fb2c0f] Submitted process > fastcat (10)
[8d/06776a] Submitted process > fastcat (11)
[b9/28ca64] Submitted process > fastcat (12)
[28/4aadae] Submitted process > calling_pipeline:amrCheckpoint (1)
[27/bea04c] Submitted process > fastcat (13)
[b3/71e431] Submitted process > fastcat (14)
[69/878478] Submitted process > fastcat (15)
[15/36982e] Submitted process > fastcat (16)
[26/595280] Submitted process > calling_pipeline:variantCheckpoint (1)
[06/70d0da] Submitted process > fastcat (17)
[79/09e595] Submitted process > fastcat (18)
[7f/0ed4ef] Submitted process > fastcat (19)
[d1/3e946c] Submitted process > fastcat (20)
[3d/6085c3] Submitted process > calling_pipeline:perSampleReportingCheckpoint (1)
[8e/642502] Submitted process > fastcat (21)
[8a/36fd47] Submitted process > fastcat (22)
[a2/264c9f] Submitted process > fastcat (23)
[e8/c302db] Submitted process > calling_pipeline:perSampleReportingCheckpoint (2)
[6f/6534cb] Submitted process > fastcat (24)
[09/c152b1] Submitted process > fastcat (25)
[78/92ea46] Submitted process > calling_pipeline:ingressCheckpoint (2)
[8a/9b01d1] Submitted process > fastcat (26)
[95/7ea4f4] Submitted process > fastcat (27)
[f5/7e6e39] Submitted process > fastcat (28)
[68/44bb6f] Submitted process > calling_pipeline:amrCheckpoint (2)
[db/9afc43] Submitted process > fastcat (29)
[6a/9468b9] Submitted process > fastcat (30)
[08/628731] Submitted process > fastcat (31)
[3f/b019f2] Submitted process > fastcat (32)
[a6/bff595] Submitted process > calling_pipeline:medakaVersion
[68/d3d255] Submitted process > fastcat (33)
[98/c04318] Submitted process > calling_pipeline:variantCheckpoint (2)
[c2/f80915] Submitted process > fastcat (34)
[78/fd0edb] Submitted process > fastcat (35)
[2d/0b158a] Submitted process > fastcat (36)
[9c/635764] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (1)
[94/684993] Submitted process > fastcat (37)
[40/5e0d38] Submitted process > calling_pipeline:variantCheckpoint (3)
[86/7da59d] Submitted process > fastcat (38)
[25/ba0989] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (2)
[68/c51154] Submitted process > fastcat (39)
[a2/37e6a8] Submitted process > fastcat (40)
[27/81f971] Submitted process > fastcat (41)
[f5/417729] Submitted process > calling_pipeline:amrCheckpoint (3)
[93/c76c70] Submitted process > calling_pipeline:perSampleReportingCheckpoint (3)
[4f/2d46d0] Submitted process > calling_pipeline:ingressCheckpoint (3)
[ba/b8bbf2] Submitted process > fastcat (42)
[4a/9bffb4] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (3)
[5f/f83e85] Submitted process > fastcat (43)
[95/dbbbd7] Submitted process > calling_pipeline:ingressCheckpoint (4)
[4f/371b43] Submitted process > calling_pipeline:perSampleReportingCheckpoint (4)
[e9/066d59] Submitted process > calling_pipeline:amrCheckpoint (4)
[d0/a7f4e5] Submitted process > calling_pipeline:variantCheckpoint (4)
[55/d186c8] Submitted process > calling_pipeline:variantCheckpoint (5)
[d1/e9cb0b] Submitted process > calling_pipeline:amrCheckpoint (5)
[77/2ece43] Submitted process > calling_pipeline:ingressCheckpoint (5)
[f2/0a17d8] Submitted process > fastcat (44)
[c8/02461f] Submitted process > calling_pipeline:perSampleReportingCheckpoint (5)
[a6/65bef4] Submitted process > calling_pipeline:variantCheckpoint (6)
[18/dff1ba] Submitted process > calling_pipeline:amrCheckpoint (6)
[eb/c63ebf] Submitted process > calling_pipeline:perSampleReportingCheckpoint (6)
[7b/241d8a] Submitted process > calling_pipeline:ingressCheckpoint (6)
[18/5a008b] Submitted process > calling_pipeline:amrCheckpoint (7)
[1f/e05817] Submitted process > calling_pipeline:ingressCheckpoint (7)
[fc/73777c] Submitted process > fastcat (45)
[83/2733b1] Submitted process > fastcat (46)
[31/0f5026] Submitted process > calling_pipeline:perSampleReportingCheckpoint (7)
[62/856fce] Submitted process > calling_pipeline:variantCheckpoint (7)
[9c/1a9e44] Submitted process > calling_pipeline:variantCheckpoint (8)
[e7/278b56] Submitted process > calling_pipeline:amrCheckpoint (8)
[c0/3cb23f] Submitted process > calling_pipeline:perSampleReportingCheckpoint (8)
[7a/9a5994] Submitted process > fastcat (47)
[35/d96e68] Submitted process > fastcat (48)
[ab/335f73] Submitted process > calling_pipeline:ingressCheckpoint (8)
[eb/d9bed6] Submitted process > fastcat (49)
[8d/2fe611] Submitted process > calling_pipeline:variantCheckpoint (9)
[ac/2ea39a] Submitted process > calling_pipeline:ingressCheckpoint (9)
[f9/329882] Submitted process > calling_pipeline:amrCheckpoint (9)
[07/e4fda7] Submitted process > calling_pipeline:perSampleReportingCheckpoint (9)
[1d/ef1b47] Submitted process > fastcat (50)
[5e/337b7e] Submitted process > calling_pipeline:ingressCheckpoint (10)
[55/c381e6] Submitted process > fastcat (51)
[9e/2803c2] Submitted process > calling_pipeline:amrCheckpoint (10)
[41/a4b2d8] Submitted process > calling_pipeline:variantCheckpoint (10)
[26/1ab26c] Submitted process > calling_pipeline:perSampleReportingCheckpoint (10)
[89/cfdfd3] Submitted process > calling_pipeline:ingressCheckpoint (11)
[d7/19ce8a] Submitted process > calling_pipeline:variantCheckpoint (11)
[a7/91bb8d] Submitted process > calling_pipeline:amrCheckpoint (11)
[b3/d5b059] Submitted process > fastcat (52)
[46/c8ccd8] Submitted process > calling_pipeline:perSampleReportingCheckpoint (11)
[95/da2941] Submitted process > calling_pipeline:perSampleReportingCheckpoint (12)
[93/3946ad] Submitted process > fastcat (53)
[9d/f90e6b] Submitted process > calling_pipeline:variantCheckpoint (12)
[f6/623157] Submitted process > calling_pipeline:amrCheckpoint (12)
[0c/e747e4] Submitted process > calling_pipeline:ingressCheckpoint (12)
[f2/c9bf73] Submitted process > calling_pipeline:ingressCheckpoint (13)
[39/864f51] Submitted process > calling_pipeline:amrCheckpoint (13)
[e0/b1c1eb] Submitted process > fastcat (54)
[b1/1fb810] Submitted process > calling_pipeline:perSampleReportingCheckpoint (13)
[de/536bcb] Submitted process > fastcat (55)
[e1/5d2f43] Submitted process > calling_pipeline:variantCheckpoint (13)
[c3/90326a] Submitted process > fastcat (56)
[15/ada4ca] Submitted process > calling_pipeline:ingressCheckpoint (14)
[f2/fb495f] Submitted process > calling_pipeline:amrCheckpoint (14)
[98/2f8d84] Submitted process > calling_pipeline:variantCheckpoint (14)
[46/c9adc0] Submitted process > calling_pipeline:perSampleReportingCheckpoint (14)
[5e/3377be] Submitted process > calling_pipeline:ingressCheckpoint (15)
[23/b43659] Submitted process > calling_pipeline:variantCheckpoint (15)
[e4/05d3be] Submitted process > calling_pipeline:perSampleReportingCheckpoint (15)
[f2/a22fa1] Submitted process > fastcat (57)
[33/dfba67] Submitted process > calling_pipeline:amrCheckpoint (15)
[f2/0e6687] Submitted process > calling_pipeline:variantCheckpoint (16)
[b3/48c02e] Submitted process > fastcat (58)
[d2/d310a6] Submitted process > fastcat (59)
[e4/8c391e] Submitted process > calling_pipeline:ingressCheckpoint (16)
[ca/a6d3d7] Submitted process > calling_pipeline:amrCheckpoint (16)
[54/3fd85f] Submitted process > calling_pipeline:perSampleReportingCheckpoint (16)
[0d/fc3c70] Submitted process > calling_pipeline:amrCheckpoint (17)
[a1/7de0bb] Submitted process > calling_pipeline:ingressCheckpoint (17)
[da/4c73e7] Submitted process > fastcat (60)
[38/5fc209] Submitted process > calling_pipeline:variantCheckpoint (17)
[91/022ae5] Submitted process > fastcat (61)
[0d/a8104b] Submitted process > calling_pipeline:perSampleReportingCheckpoint (17)
[07/32a717] Submitted process > calling_pipeline:amrCheckpoint (18)
[8b/80df0b] Submitted process > calling_pipeline:ingressCheckpoint (18)
[76/8b4b6f] Submitted process > calling_pipeline:variantCheckpoint (18)
[cc/6e801b] Submitted process > calling_pipeline:perSampleReportingCheckpoint (18)
[15/7bbc79] Submitted process > calling_pipeline:amrCheckpoint (19)
[0c/f788e5] Submitted process > calling_pipeline:ingressCheckpoint (19)
[82/2bb48f] Submitted process > fastcat (62)
[a7/b380c2] Submitted process > calling_pipeline:variantCheckpoint (19)
[68/b27c25] Submitted process > calling_pipeline:perSampleReportingCheckpoint (19)
[31/f2f44b] Submitted process > calling_pipeline:perSampleReportingCheckpoint (20)
[05/1f8d0b] Submitted process > fastcat (63)
[b6/2ab54f] Submitted process > fastcat (64)
[88/b64547] Submitted process > calling_pipeline:variantCheckpoint (20)
[ff/9b12ed] Submitted process > calling_pipeline:ingressCheckpoint (20)
[3f/113604] Submitted process > calling_pipeline:amrCheckpoint (20)
[25/d532f3] Submitted process > calling_pipeline:perSampleReportingCheckpoint (21)
[f8/eb34a5] Submitted process > calling_pipeline:variantCheckpoint (21)
[0e/ef4490] Submitted process > fastcat (65)
[d8/a6ead8] Submitted process > calling_pipeline:ingressCheckpoint (21)
[95/03c016] Submitted process > calling_pipeline:amrCheckpoint (21)
[28/a268dd] Submitted process > fastcat (66)
[e9/1034b8] Submitted process > calling_pipeline:amrCheckpoint (22)
[55/d4a83c] Submitted process > calling_pipeline:ingressCheckpoint (22)
[1b/9a1017] Submitted process > fastcat (67)
[dd/eefc1b] Submitted process > calling_pipeline:perSampleReportingCheckpoint (22)
[5e/4a0431] Submitted process > calling_pipeline:variantCheckpoint (22)
[5f/25abec] Submitted process > calling_pipeline:amrCheckpoint (23)
[4d/c0d61f] Submitted process > calling_pipeline:variantCheckpoint (23)
[9e/782fe9] Submitted process > fastcat (68)
[cf/e9afd8] Submitted process > calling_pipeline:perSampleReportingCheckpoint (23)
[21/43c40c] Submitted process > fastcat (69)
[c3/036f0f] Submitted process > calling_pipeline:ingressCheckpoint (23)
[a7/8eea1d] Submitted process > calling_pipeline:ingressCheckpoint (24)
[52/7d48e7] Submitted process > calling_pipeline:variantCheckpoint (24)
[35/980b57] Submitted process > calling_pipeline:amrCheckpoint (24)
[ff/d8a3e8] Submitted process > fastcat (70)
[14/3dab15] Submitted process > calling_pipeline:perSampleReportingCheckpoint (24)
[01/aca2dc] Submitted process > fastcat (71)
[a2/70ff7c] Submitted process > calling_pipeline:perSampleReportingCheckpoint (25)
[0c/fefbe1] Submitted process > calling_pipeline:amrCheckpoint (25)
[80/b4b13c] Submitted process > calling_pipeline:ingressCheckpoint (25)
[75/f31eae] Submitted process > calling_pipeline:variantCheckpoint (25)
[8a/c21f57] Submitted process > fastcat (72)
[f5/6328a8] Submitted process > calling_pipeline:ingressCheckpoint (26)
[ed/5d7c22] Submitted process > calling_pipeline:amrCheckpoint (26)
[55/0170ee] Submitted process > calling_pipeline:variantCheckpoint (26)
[aa/abe157] Submitted process > calling_pipeline:perSampleReportingCheckpoint (26)
[92/4af525] Submitted process > fastcat (73)
[f2/e0409b] Submitted process > calling_pipeline:variantCheckpoint (27)
[4f/b05a77] Submitted process > fastcat (74)
[26/6a0b80] Submitted process > calling_pipeline:ingressCheckpoint (27)
[ce/eecd21] Submitted process > calling_pipeline:amrCheckpoint (27)
[8f/acacce] Submitted process > calling_pipeline:perSampleReportingCheckpoint (27)
[d4/0e9115] Submitted process > fastcat (75)
[d2/c973a9] Submitted process > calling_pipeline:ingressCheckpoint (28)
[52/fb164f] Submitted process > calling_pipeline:amrCheckpoint (28)
[bf/525d20] Submitted process > calling_pipeline:perSampleReportingCheckpoint (28)
[66/221f6e] Submitted process > calling_pipeline:variantCheckpoint (28)
[12/91abbb] Submitted process > calling_pipeline:variantCheckpoint (29)
[4c/13acb1] Submitted process > calling_pipeline:perSampleReportingCheckpoint (29)
[7e/398520] Submitted process > fastcat (76)
[fa/77144e] Submitted process > fastcat (77)
[37/8484c7] Submitted process > calling_pipeline:amrCheckpoint (29)
[5b/02ff2f] Submitted process > calling_pipeline:ingressCheckpoint (29)
[02/378976] Submitted process > calling_pipeline:amrCheckpoint (30)
[18/8b77be] Submitted process > fastcat (78)
[a2/cfabb0] Submitted process > calling_pipeline:ingressCheckpoint (30)
[59/c9c2b2] Submitted process > calling_pipeline:perSampleReportingCheckpoint (30)
[60/14ee7e] Submitted process > calling_pipeline:variantCheckpoint (30)
[93/474aa4] Submitted process > calling_pipeline:variantCheckpoint (31)
[7a/5ec7ce] Submitted process > fastcat (79)
[72/a68d93] Submitted process > calling_pipeline:perSampleReportingCheckpoint (31)
[40/54d442] Submitted process > fastcat (80)
[2b/f3ffa1] Submitted process > calling_pipeline:amrCheckpoint (31)
[6f/df16dd] Submitted process > calling_pipeline:ingressCheckpoint (31)
[4b/9afafb] Submitted process > calling_pipeline:perSampleReportingCheckpoint (32)
[45/1f49c1] Submitted process > calling_pipeline:amrCheckpoint (32)
[da/69242e] Submitted process > calling_pipeline:variantCheckpoint (32)
[83/e4cac3] Submitted process > fastcat (81)
[77/e666c1] Submitted process > calling_pipeline:ingressCheckpoint (32)
[f6/1624c1] Submitted process > calling_pipeline:variantCheckpoint (33)
[f4/bc9beb] Submitted process > calling_pipeline:ingressCheckpoint (33)
[65/c82756] Submitted process > calling_pipeline:perSampleReportingCheckpoint (33)
[f4/436873] Submitted process > fastcat (82)
[a4/474403] Submitted process > calling_pipeline:amrCheckpoint (33)
[1e/4d9664] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (4)
[b1/5a4bfc] Submitted process > calling_pipeline:ingressCheckpoint (34)
[05/022b22] Submitted process > calling_pipeline:perSampleReportingCheckpoint (34)
[af/bc2316] Submitted process > calling_pipeline:variantCheckpoint (34)
[a5/35c283] Submitted process > calling_pipeline:amrCheckpoint (34)
[68/fcda2a] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (5)
[93/b4756a] Submitted process > calling_pipeline:variantCheckpoint (35)
[8c/ad912e] Submitted process > calling_pipeline:perSampleReportingCheckpoint (35)
[7d/06df11] Submitted process > calling_pipeline:amrCheckpoint (35)
[57/181d26] Submitted process > calling_pipeline:ingressCheckpoint (35)
[e6/9768d5] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (6)
[66/3d6fe1] Submitted process > calling_pipeline:perSampleReportingCheckpoint (36)
[3b/e4f871] Submitted process > calling_pipeline:ingressCheckpoint (36)
[55/742e88] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (7)
[3f/5d3d53] Submitted process > calling_pipeline:amrCheckpoint (36)
[66/449cba] Submitted process > calling_pipeline:variantCheckpoint (36)
[c9/b9a6b8] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (8)
[2d/5cd4ff] Submitted process > calling_pipeline:ingressCheckpoint (37)
[54/4c2d31] Submitted process > calling_pipeline:perSampleReportingCheckpoint (37)
[16/0b4fd3] Submitted process > calling_pipeline:amrCheckpoint (37)
[a9/707ea1] Submitted process > calling_pipeline:variantCheckpoint (37)
[f9/f77fe8] Submitted process > calling_pipeline:variantCheckpoint (38)
[00/26aeb9] Submitted process > calling_pipeline:amrCheckpoint (38)
[c6/70345e] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (9)
[56/f13f7a] Submitted process > calling_pipeline:ingressCheckpoint (38)
[31/6228b4] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (10)
[28/0247b9] Submitted process > calling_pipeline:perSampleReportingCheckpoint (38)
[ef/15863b] Submitted process > calling_pipeline:ingressCheckpoint (39)
[b8/85b6be] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (11)
[c5/7ad1ac] Submitted process > calling_pipeline:perSampleReportingCheckpoint (39)
[08/8d4a54] Submitted process > calling_pipeline:amrCheckpoint (39)
[eb/ecfec7] Submitted process > calling_pipeline:variantCheckpoint (39)
[f4/5ec54a] Submitted process > calling_pipeline:amrCheckpoint (40)
[d3/647e50] Submitted process > calling_pipeline:ingressCheckpoint (40)
[bd/a927df] Submitted process > calling_pipeline:variantCheckpoint (40)
[a1/6d32fe] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (12)
[30/9b7aca] Submitted process > calling_pipeline:perSampleReportingCheckpoint (40)
[93/dbc782] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (13)
[59/6c39c9] Submitted process > calling_pipeline:ingressCheckpoint (41)
[46/f98466] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (14)
[20/290f85] Submitted process > calling_pipeline:variantCheckpoint (41)
[71/b63c6c] Submitted process > calling_pipeline:perSampleReportingCheckpoint (41)
[db/94345e] Submitted process > calling_pipeline:amrCheckpoint (41)
[a1/830042] Submitted process > calling_pipeline:perSampleReportingCheckpoint (42)
[60/4c923a] Submitted process > calling_pipeline:variantCheckpoint (42)
[6d/21b747] Submitted process > calling_pipeline:amrCheckpoint (42)
[61/34796c] Submitted process > calling_pipeline:ingressCheckpoint (42)
[fc/00c2af] Submitted process > calling_pipeline:variantCheckpoint (43)
[8c/866e7a] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (15)
[53/bb9831] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (16)
[f4/589629] Submitted process > calling_pipeline:amrCheckpoint (43)
[e2/970526] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (17)
[51/1cdd62] Submitted process > calling_pipeline:perSampleReportingCheckpoint (43)
[b0/76ca46] Submitted process > calling_pipeline:ingressCheckpoint (43)
[cb/d9f077] Submitted process > calling_pipeline:ingressCheckpoint (44)
[a1/82d663] Submitted process > calling_pipeline:variantCheckpoint (44)
[25/49529d] Submitted process > calling_pipeline:amrCheckpoint (44)
[9f/a759f9] Submitted process > calling_pipeline:perSampleReportingCheckpoint (44)
[79/2042e2] Submitted process > calling_pipeline:ingressCheckpoint (45)
[69/61a38d] Submitted process > calling_pipeline:perSampleReportingCheckpoint (45)
[7c/9022cf] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (18)
[d2/06aff6] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (19)
[41/e5420a] Submitted process > calling_pipeline:variantCheckpoint (45)
[aa/d73877] Submitted process > calling_pipeline:amrCheckpoint (45)
[33/963310] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (20)
[e6/ba5590] Submitted process > calling_pipeline:variantCheckpoint (46)
[b6/b82bf8] Submitted process > calling_pipeline:ingressCheckpoint (46)
[73/13bf71] Submitted process > calling_pipeline:amrCheckpoint (46)
[47/8bb017] Submitted process > calling_pipeline:perSampleReportingCheckpoint (46)
[2e/8c13e1] Submitted process > calling_pipeline:amrCheckpoint (47)
[5a/e3cb41] Submitted process > calling_pipeline:ingressCheckpoint (47)
[66/8f3cf6] Submitted process > calling_pipeline:perSampleReportingCheckpoint (47)
[c6/bf3dfc] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (21)
[78/f3e656] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (22)
[47/75e1c1] Submitted process > calling_pipeline:variantCheckpoint (47)
[7e/144018] Submitted process > calling_pipeline:ingressCheckpoint (48)
[bc/f27ab7] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (23)
[ae/4c148b] Submitted process > calling_pipeline:perSampleReportingCheckpoint (48)
[e8/2c0c6d] Submitted process > calling_pipeline:variantCheckpoint (48)
[e6/c4344e] Submitted process > calling_pipeline:amrCheckpoint (48)
[15/662688] Submitted process > calling_pipeline:ingressCheckpoint (49)
[80/ca5738] Submitted process > calling_pipeline:amrCheckpoint (49)
[11/98a765] Submitted process > calling_pipeline:variantCheckpoint (49)
[a5/315f81] Submitted process > calling_pipeline:perSampleReportingCheckpoint (49)
[b0/fc2d7a] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (24)
[48/9db93b] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (25)
[59/802c83] Submitted process > calling_pipeline:amrCheckpoint (50)
[25/7cfcc1] Submitted process > calling_pipeline:variantCheckpoint (50)
[b4/89361d] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (26)
[69/a3930f] Submitted process > calling_pipeline:perSampleReportingCheckpoint (50)
[f1/db5a53] Submitted process > calling_pipeline:ingressCheckpoint (50)
[28/01dc07] Submitted process > calling_pipeline:variantCheckpoint (51)
[9a/81ec12] Submitted process > calling_pipeline:perSampleReportingCheckpoint (51)
[61/0a1a79] Submitted process > calling_pipeline:ingressCheckpoint (51)
[c6/db001f] Submitted process > calling_pipeline:amrCheckpoint (51)
[22/2d59da] Submitted process > calling_pipeline:perSampleReportingCheckpoint (52)
[6f/369cfc] Submitted process > calling_pipeline:amrCheckpoint (52)
[7a/b79c83] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (27)
[55/1135ba] Submitted process > calling_pipeline:variantCheckpoint (52)
[2c/e207eb] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (28)
[fd/7c2e29] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (29)
[90/21998a] Submitted process > calling_pipeline:ingressCheckpoint (52)
[bc/364514] Submitted process > calling_pipeline:perSampleReportingCheckpoint (53)
[62/29e6d4] Submitted process > calling_pipeline:amrCheckpoint (53)
[5c/07aae6] Submitted process > calling_pipeline:variantCheckpoint (53)
[a0/ffe64c] Submitted process > calling_pipeline:ingressCheckpoint (53)
[b3/fca753] Submitted process > calling_pipeline:perSampleReportingCheckpoint (54)
[c8/2d357b] Submitted process > calling_pipeline:amrCheckpoint (54)
[1f/516b3f] Submitted process > calling_pipeline:variantCheckpoint (54)
[2c/d8f217] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (30)
[98/eca653] Submitted process > calling_pipeline:mlstVersion
[2e/23e6ea] Submitted process > calling_pipeline:ingressCheckpoint (54)
[d1/9fd02b] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (31)
[65/952be1] Submitted process > calling_pipeline:ingressCheckpoint (55)
[bd/9c5c61] Submitted process > calling_pipeline:perSampleReportingCheckpoint (55)
[c0/e36ea7] Submitted process > calling_pipeline:amrCheckpoint (55)
[b7/6282db] Submitted process > calling_pipeline:variantCheckpoint (55)
[9a/5ed84c] Submitted process > calling_pipeline:perSampleReportingCheckpoint (56)
[c4/085412] Submitted process > calling_pipeline:amrCheckpoint (56)
[51/1dbb88] Submitted process > calling_pipeline:ingressCheckpoint (56)
[f4/999959] Submitted process > calling_pipeline:variantCheckpoint (56)
[4f/f37da5] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (32)
[ff/dfcfd6] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (33)
[42/4198b3] Submitted process > calling_pipeline:ingressCheckpoint (57)
[6c/8893da] Submitted process > calling_pipeline:perSampleReportingCheckpoint (57)
[f0/078100] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (34)
[41/8e793e] Submitted process > calling_pipeline:variantCheckpoint (57)
[a5/610ef0] Submitted process > calling_pipeline:amrCheckpoint (57)
[c1/c0bdda] Submitted process > calling_pipeline:amrCheckpoint (58)
[47/a5639e] Submitted process > calling_pipeline:ingressCheckpoint (58)
[35/051467] Submitted process > calling_pipeline:perSampleReportingCheckpoint (58)
[1a/3449b9] Submitted process > calling_pipeline:variantCheckpoint (58)
[7d/1c0c4a] Submitted process > calling_pipeline:perSampleReportingCheckpoint (59)
[72/f98a08] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (35)
[76/334d22] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (36)
[5f/f35d15] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (37)
[f7/3a0b5d] Submitted process > calling_pipeline:variantCheckpoint (59)
[18/2b7a60] Submitted process > calling_pipeline:amrCheckpoint (59)
[17/572c0b] Submitted process > calling_pipeline:ingressCheckpoint (59)
[9b/660124] Submitted process > calling_pipeline:perSampleReportingCheckpoint (60)
[75/56dbb4] Submitted process > calling_pipeline:amrCheckpoint (60)
[e0/6df6db] Submitted process > calling_pipeline:variantCheckpoint (60)
[6a/e9bd7d] Submitted process > calling_pipeline:ingressCheckpoint (60)
[77/6ee76f] Submitted process > calling_pipeline:perSampleReportingCheckpoint (61)
[0a/57cfd3] Submitted process > calling_pipeline:ingressCheckpoint (61)
[9b/472a14] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (38)
[fa/2a919d] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (39)
[c0/1063ec] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (40)
[e7/084a04] Submitted process > calling_pipeline:variantCheckpoint (61)
[87/f1eee6] Submitted process > calling_pipeline:amrCheckpoint (61)
[91/40d200] Submitted process > calling_pipeline:perSampleReportingCheckpoint (62)
[8a/75e328] Submitted process > calling_pipeline:variantCheckpoint (62)
[50/d9b5ef] Submitted process > calling_pipeline:amrCheckpoint (62)
[43/7e0887] Submitted process > calling_pipeline:ingressCheckpoint (62)
[3e/d1ecc5] Submitted process > calling_pipeline:ingressCheckpoint (63)
[64/5b37fb] Submitted process > calling_pipeline:amrCheckpoint (63)
[fc/7d6523] Submitted process > calling_pipeline:perSampleReportingCheckpoint (63)
[cc/5a88ca] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (41)
[e1/5bad1d] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (42)
[c6/fb58a0] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (43)
[0f/d0ae14] Submitted process > calling_pipeline:variantCheckpoint (63)
[1b/1cae16] Submitted process > calling_pipeline:amrCheckpoint (64)
[53/c8aec8] Submitted process > calling_pipeline:perSampleReportingCheckpoint (64)
[aa/015196] Submitted process > calling_pipeline:variantCheckpoint (64)
[5c/94e258] Submitted process > calling_pipeline:ingressCheckpoint (64)
[e9/6eed42] Submitted process > calling_pipeline:amrCheckpoint (65)
[82/97d55e] Submitted process > calling_pipeline:perSampleReportingCheckpoint (65)
[23/80b0bc] Submitted process > calling_pipeline:ingressCheckpoint (65)
[c4/d436da] Submitted process > calling_pipeline:variantCheckpoint (65)
[f8/4b86f8] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (44)
[eb/982810] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (45)
[ab/31bba7] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (46)
[8b/105f7b] Submitted process > calling_pipeline:variantCheckpoint (66)
[eb/2c744d] Submitted process > calling_pipeline:amrCheckpoint (66)
[d4/876f76] Submitted process > calling_pipeline:perSampleReportingCheckpoint (66)
[44/0c789b] Submitted process > calling_pipeline:ingressCheckpoint (66)
[5e/aea7f2] Submitted process > calling_pipeline:variantCheckpoint (67)
[d3/4b2592] Submitted process > calling_pipeline:amrCheckpoint (67)
[30/647991] Submitted process > calling_pipeline:ingressCheckpoint (67)
[93/0401f0] Submitted process > calling_pipeline:perSampleReportingCheckpoint (67)
[f4/2280c2] Submitted process > calling_pipeline:amrCheckpoint (68)
[d4/4a462b] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (47)
[96/ff2fff] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (48)
[05/56f3a2] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (49)
[fd/aa0c72] Submitted process > calling_pipeline:perSampleReportingCheckpoint (68)
[70/3a3d1b] Submitted process > calling_pipeline:ingressCheckpoint (68)
[4e/623b87] Submitted process > calling_pipeline:variantCheckpoint (68)
[20/9541d1] Submitted process > calling_pipeline:variantCheckpoint (69)
[a8/93bcf1] Submitted process > calling_pipeline:perSampleReportingCheckpoint (69)
[e7/33f503] Submitted process > calling_pipeline:ingressCheckpoint (69)
[f0/4a4b79] Submitted process > calling_pipeline:amrCheckpoint (69)
[f0/1794a7] Submitted process > calling_pipeline:ingressCheckpoint (70)
[81/f597b3] Submitted process > calling_pipeline:perSampleReportingCheckpoint (70)
[a9/84d03c] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (50)
[2b/78ad28] Submitted process > calling_pipeline:variantCheckpoint (70)
[2d/c5a8de] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (51)
[71/75de78] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (52)
[f9/210957] Submitted process > calling_pipeline:amrCheckpoint (70)
[5c/f83909] Submitted process > calling_pipeline:variantCheckpoint (71)
[fc/1bb51b] Submitted process > calling_pipeline:ingressCheckpoint (71)
[97/b4024b] Submitted process > calling_pipeline:perSampleReportingCheckpoint (71)
[36/9c3253] Submitted process > calling_pipeline:amrCheckpoint (71)
[b7/ebc23a] Submitted process > calling_pipeline:ingressCheckpoint (72)
[2e/eecf78] Submitted process > calling_pipeline:amrCheckpoint (72)
[ac/694ceb] Submitted process > calling_pipeline:variantCheckpoint (72)
[20/260c45] Submitted process > calling_pipeline:perSampleReportingCheckpoint (72)
[02/9cfffb] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (53)
[d9/657890] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (54)
[05/639ee8] Submitted process > calling_pipeline:variantCheckpoint (73)
[db/33efdd] Submitted process > calling_pipeline:perSampleReportingCheckpoint (73)
[b2/18c237] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (55)
[e5/b043f2] Submitted process > calling_pipeline:amrCheckpoint (73)
[49/feebe0] Submitted process > calling_pipeline:ingressCheckpoint (73)
[52/3df4f3] Submitted process > calling_pipeline:variantCheckpoint (74)
[3c/067b85] Submitted process > calling_pipeline:perSampleReportingCheckpoint (74)
[10/b09bd0] Submitted process > calling_pipeline:amrCheckpoint (74)
[41/6f32de] Submitted process > calling_pipeline:ingressCheckpoint (74)
[b0/431dcb] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (56)
[d7/f09032] Submitted process > calling_pipeline:variantCheckpoint (75)
[3d/74ef72] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (57)
[aa/945e2a] Submitted process > calling_pipeline:perSampleReportingCheckpoint (75)
[a0/a72c86] Submitted process > calling_pipeline:ingressCheckpoint (75)
[5c/54cdae] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (58)
[08/06ef49] Submitted process > calling_pipeline:amrCheckpoint (75)
[c0/f88fae] Submitted process > calling_pipeline:perSampleReportingCheckpoint (76)
[a1/943bcb] Submitted process > calling_pipeline:ingressCheckpoint (76)
[4e/85db53] Submitted process > calling_pipeline:amrCheckpoint (76)
[8e/b9fb81] Submitted process > calling_pipeline:variantCheckpoint (76)
[4a/c17f9a] Submitted process > calling_pipeline:variantCheckpoint (77)
[42/f6248e] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (59)
[19/c9965d] Submitted process > calling_pipeline:ingressCheckpoint (77)
[6d/e207a0] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (60)
[6b/d90801] Submitted process > calling_pipeline:amrCheckpoint (77)
[58/85c352] Submitted process > calling_pipeline:perSampleReportingCheckpoint (77)
[4d/badf7c] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (61)
[4c/b19571] Submitted process > calling_pipeline:variantCheckpoint (78)
[0e/76eed6] Submitted process > calling_pipeline:perSampleReportingCheckpoint (78)
[79/23f245] Submitted process > calling_pipeline:ingressCheckpoint (78)
[13/61982e] Submitted process > calling_pipeline:amrCheckpoint (78)
[cb/c51fa3] Submitted process > calling_pipeline:variantCheckpoint (79)
[cb/1cc1b1] Submitted process > calling_pipeline:ingressCheckpoint (79)
[ca/7325c4] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (62)
[de/714648] Submitted process > calling_pipeline:perSampleReportingCheckpoint (79)
[5b/b5cba9] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (63)
[e2/0f9f27] Submitted process > calling_pipeline:amrCheckpoint (79)
[b4/6f9e6d] Submitted process > calling_pipeline:ingressCheckpoint (80)
[44/f84289] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (64)
[c6/17c74a] Submitted process > calling_pipeline:variantCheckpoint (80)
[64/ec40ad] Submitted process > calling_pipeline:perSampleReportingCheckpoint (80)
[39/1f1656] Submitted process > calling_pipeline:amrCheckpoint (80)
[75/69ef0f] Submitted process > calling_pipeline:amrCheckpoint (81)
[7b/540b76] Submitted process > calling_pipeline:perSampleReportingCheckpoint (81)
[f3/9a2d1a] Submitted process > calling_pipeline:ingressCheckpoint (81)
[62/34db15] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (65)
[2f/f27e19] Submitted process > calling_pipeline:variantCheckpoint (81)
[e3/1b15b2] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (66)
[4a/282604] Submitted process > calling_pipeline:ingressCheckpoint (82)
[56/fd1481] Submitted process > calling_pipeline:perSampleReportingCheckpoint (82)
[14/85e589] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (67)
[6c/5e5c76] Submitted process > calling_pipeline:variantCheckpoint (82)
[bc/65646a] Submitted process > calling_pipeline:amrCheckpoint (82)
[85/e0afb6] Submitted process > calling_pipeline:accumulateCheckpoints (1)
[d5/5a8f30] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (68)
[3f/c94a5b] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (69)
[43/b1c3f4] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (70)
[88/de30a9] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (71)
[7e/ce0f1d] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (72)
[d3/791a54] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (73)
[0f/6e1f93] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (74)
[7b/4d1632] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (75)
[04/f0489a] Submitted process > calling_pipeline:accumulateCheckpoints (2)
[35/5ba557] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (76)
[32/3d4225] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (77)
[00/8502b0] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (78)
[37/1ffe2a] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (79)
[bb/4b1010] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (80)
[5b/010ee7] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (81)
[a7/8a79e6] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (82)
[fe/e0173b] Submitted process > calling_pipeline:getVersions
[fd/680d59] Submitted process > calling_pipeline:accumulateCheckpoints (3)
[6d/5dc36f] Submitted process > calling_pipeline:deNovo (1)
[7f/d10bac] Submitted process > calling_pipeline:deNovo (2)
[78/458f0e] Submitted process > calling_pipeline:deNovo (3)
[5a/c575f3] Submitted process > calling_pipeline:deNovo (4)
WARN: Flye failed for sample 'barcode04' due to low coverage.
[29/4fe017] Submitted process > calling_pipeline:deNovo (5)
WARN: Flye failed for sample 'barcode05' due to low coverage.
[98/daad81] Submitted process > calling_pipeline:deNovo (6)
WARN: Flye failed for sample 'barcode03' due to low coverage.
WARN: Flye failed for sample 'barcode06' due to low coverage.
[d6/348376] Submitted process > calling_pipeline:deNovo (7)
WARN: Flye failed for sample 'barcode07' due to low coverage.
[fe/f81427] Submitted process > calling_pipeline:deNovo (8)
[6d/291aa4] Submitted process > calling_pipeline:deNovo (9)
WARN: Flye failed for sample 'barcode09' due to low coverage.
[4a/d12e6c] Submitted process > calling_pipeline:deNovo (10)
WARN: Flye failed for sample 'barcode10' due to low coverage.
[85/1a5916] Submitted process > calling_pipeline:deNovo (11)
[02/3add1d] Submitted process > calling_pipeline:deNovo (12)
WARN: Flye failed for sample 'barcode12' due to low coverage.
[f4/ad798a] Submitted process > calling_pipeline:deNovo (13)
WARN: Flye failed for sample 'barcode13' due to low coverage.
[dd/cb02be] Submitted process > calling_pipeline:deNovo (14)
WARN: Flye failed for sample 'barcode15' due to low coverage.
[59/069145] Submitted process > calling_pipeline:deNovo (15)
[04/64164c] Submitted process > calling_pipeline:deNovo (16)
WARN: Flye failed for sample 'barcode17' due to low coverage.
[b7/394803] Submitted process > calling_pipeline:deNovo (17)
[5f/eb2860] Submitted process > calling_pipeline:deNovo (18)
[c9/8cf992] Submitted process > calling_pipeline:deNovo (19)
WARN: Flye failed for sample 'barcode20' due to low coverage.
[27/f8845b] Submitted process > calling_pipeline:deNovo (20)
WARN: Flye failed for sample 'barcode21' due to low coverage.
[6d/0d9e9b] Submitted process > calling_pipeline:deNovo (21)
WARN: Flye failed for sample 'barcode22' due to low coverage.
[c8/372afa] Submitted process > calling_pipeline:deNovo (22)
WARN: Flye failed for sample 'barcode24' due to low coverage.
[81/e3f3bb] Submitted process > calling_pipeline:deNovo (23)
[23/675ff9] Submitted process > calling_pipeline:deNovo (24)
WARN: Flye failed for sample 'barcode26' due to low coverage.
[3c/5a2ab2] Submitted process > calling_pipeline:deNovo (25)
[c1/91d46a] Submitted process > calling_pipeline:deNovo (26)
WARN: Flye failed for sample 'barcode25' due to low coverage.
[b5/a73599] Submitted process > calling_pipeline:deNovo (27)
WARN: Flye failed for sample 'barcode27' due to low coverage.
WARN: Flye failed for sample 'barcode28' due to low coverage.
[40/beebff] Submitted process > calling_pipeline:deNovo (28)
WARN: Flye failed for sample 'barcode29' due to low coverage.
[2e/916d5e] Submitted process > calling_pipeline:deNovo (29)
WARN: Flye failed for sample 'barcode31' due to low coverage.
[ae/01e1fb] Submitted process > calling_pipeline:deNovo (30)
WARN: Flye failed for sample 'barcode32' due to low coverage.
[3d/2cebeb] Submitted process > calling_pipeline:deNovo (31)
WARN: Flye failed for sample 'barcode33' due to low coverage.
[65/fe94d0] Submitted process > calling_pipeline:deNovo (32)
WARN: Flye failed for sample 'barcode35' due to low coverage.
[fb/5d13ce] Submitted process > calling_pipeline:deNovo (33)
[5a/f8b9ed] Submitted process > calling_pipeline:deNovo (34)
WARN: Flye failed for sample 'barcode37' due to low coverage.
WARN: Flye failed for sample 'barcode36' due to low coverage.
[ec/53fee7] Submitted process > calling_pipeline:deNovo (35)
[4a/18e414] Submitted process > calling_pipeline:deNovo (36)
WARN: Flye failed for sample 'barcode41' due to low coverage.
[b9/8507aa] Submitted process > calling_pipeline:deNovo (37)
[78/8b052a] Submitted process > calling_pipeline:deNovo (38)
[c2/afcba5] Submitted process > calling_pipeline:deNovo (39)
[22/0bc659] Submitted process > calling_pipeline:deNovo (40)
[94/944957] Submitted process > calling_pipeline:deNovo (41)
WARN: Flye failed for sample 'barcode44' due to low coverage.
[50/391f19] Submitted process > calling_pipeline:deNovo (42)
WARN: Flye failed for sample 'barcode45' due to low coverage.
[16/cba003] Submitted process > calling_pipeline:deNovo (43)
[7a/3022dc] Submitted process > calling_pipeline:deNovo (44)
[f6/2e420c] Submitted process > calling_pipeline:deNovo (45)
WARN: Flye failed for sample 'barcode46' due to low coverage.
[35/7509f1] Submitted process > calling_pipeline:deNovo (46)
ERROR ~ Error executing process > 'calling_pipeline:deNovo (45)'
Caused by:
Process `calling_pipeline:deNovo (45)` terminated with an error exit status (1)
Command executed:
COV_FAIL=0
FLYE_EXIT_CODE=0
flye --nano-hq reads.fastq.gz --out-dir output --threads ""3"" || FLYE_EXIT_CODE=$?
if [[ $FLYE_EXIT_CODE -eq 0 ]]; then
mv output/assembly.fasta ""./barcode47.draft_assembly.fasta""
mv output/assembly_info.txt ""./barcode47_flye_stats.tsv""
bgzip ""barcode47.draft_assembly.fasta""
else
# flye failed --> check the log to check why
edge_cov=$(
grep -oP 'Mean edge coverage: \K\d+' output/flye.log || echo 5
)
ovlp_cov=$(
grep -oP 'Overlap-based coverage: \K\d+' output/flye.log || echo 5
)
if [[
$edge_cov -lt 5 ||
$ovlp_cov -lt 5
]]; then
echo -n ""Caught Flye failure due to low coverage (either mean edge cov. or ""
echo ""overlap-based cov. were below 5)"".
COV_FAIL=1
elif grep -q ""No disjointigs were assembled"" output/flye.log; then
echo -n ""Caught Flye failure due to disjointig assembly.""
COV_FAIL=2
else
# exit a subshell with error so that the process fails
( exit $FLYE_EXIT_CODE )
fi
fi
Command exit status:
1
Command output:
(empty)
Command error:
[2024-10-17 10:24:24] INFO: Starting Flye 2.9.3-b1797
[2024-10-17 10:24:24] INFO: >>>STAGE: configure
[2024-10-17 10:24:24] INFO: Configuring run
[2024-10-17 10:24:24] INFO: Total read length: 9712
[2024-10-17 10:24:24] INFO: Reads N50/N90: 9712 / 9712
[2024-10-17 10:24:24] INFO: Minimum overlap set to 10000
[2024-10-17 10:24:24] INFO: >>>STAGE: assembly
[2024-10-17 10:24:24] INFO: Assembling disjointigs
[2024-10-17 10:24:24] INFO: Reading sequences
[2024-10-17 10:24:24] INFO: Building minimizer index
[2024-10-17 10:24:24] INFO: Pre-calculating index storage
[2024-10-17 10:24:24] INFO: Filling index
[2024-10-17 10:24:24] ERROR: Command '['flye-modules', 'assemble', '--reads', 'reads.fastq.gz', '--out-asm', 'output/00-assembly/draft_assembly.fasta', '--config', '/home/epi2melabs/conda/lib/python3.8/site-packages/flye/config/bin_cfg/asm_nano_hq.cfg', '--log', 'output/flye.log', '--threads', '3', '--min-ovlp', '10000']' died with <Signals.SIGFPE: 8>.
[2024-10-17 10:24:24] ERROR: Pipeline aborted
Work dir:
/mnt/c/Users/Sequencing/epi2melabs/instances/wf-bacterial-genomes_01JACZ50KNN6EF71EKC6551GPZ/work/f6/2e420c9a30e20df715e5fddae210f8
Tip: you can replicate the issue by changing to the process work dir and entering the command `bash .command.run`
-- Check '/mnt/c/Users/Sequencing/epi2melabs/instances/wf-bacterial-genomes_01JACZ50KNN6EF71EKC6551GPZ/nextflow.log' file for details
WARN: Killing running tasks (1)
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

yes

### Other demo data information

_No response_",AnjaliSM22,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/46,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6b7C-N,failed to run demo data,CLOSED,2024-10-26T15:37:26Z,2024-10-29T17:10:23Z,2024-10-29T17:10:22Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

v1.4.0

### Workflow Execution

Command line (Cluster)

### Other workflow execution

_No response_

### EPI2ME Version

_No response_

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

it look like the sample sheet is invalid 
[nextflow.log](https://github.com/user-attachments/files/17531122/nextflow.log)


### Relevant log output

```shell
}                                                                                                                                                                  
  }' > params.json                                                                                                                                                       
                                                                                                                                                                         
Command exit status:                                                                                                                                                     
executor >  local (3)                                                                                                                                                    
[7f/f1c12d] validate_sample_sheet                               [100%] 1 of 1, failed: 1                                                                                
[-        ] fastcat                                             [  0%] 0 of 2                                                                                            
[-        ] calling_pipeline:ingressCheckpoint                  -                                                                                                        
[-        ] calling_pipeline:deNovo                             -                                                                                                        
[-        ] calling_pipeline:alignReads                         -                                                                                                        
[-        ] calling_pipeline:alignmentCheckpoint                -                                                                                                        
[-        ] calling_pipeline:readStats                          -                                                                                                        
[-        ] calling_pipeline:coverStats                         -                                                                                                        
[-        ] calling_pipeline:splitRegions                       -                                                                                                        
[-        ] calling_pipeline:medakaInference_consensus          -                                                                                                        
[-        ] calling_pipeline:medakaConsensus                    -                                                                                                        
[-        ] calling_pipeline:assemblyCheckpoint                 -                                                                                                        
[93/c80017] calling_pipeline:prokkaVersion                      [100%] 1 of 1, failed: 1                                                                                
[ab/893074] calling_pipeline:getParams                          [100%] 1 of 1, failed: 1                                                                                
Plus 21 more processes waiting for tasks                                                                                                                                
Running Denovo assembly.                                                                                                                                                 
ERROR ~ Error executing process > 'calling_pipeline:getParams'                                                                                                           
                                                                                                                                                                         
Caused by:                                                                                                                                                               
  Process `calling_pipeline:getParams` terminated with an error exit status (127)                                                                                        
                                                                                                                                                                         
                                                                                                                                                                         
Command executed:                                                                                                                                                        
                                                                                                                                                                         
  # Output nextflow params object to JSON                                                                                                                                
      echo '{                                                                                                                                                            
      ""fastq"": ""wf-bacterial-genomes-demo/isolates_fastq"",                                                                                                               
      ""isolates"": true,                                                                                                                                                  
      ""sample_sheet"": ""wf-bacterial-genomes-demo/isolates_sample_sheet.csv"",                                                                                             
[1] 0:[tmux]*                                                                                                                                      ""farm"" 08:36 26-Oct-24
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

no

### Other demo data information

_No response_",xiranli007,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/47,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6f2Pwc,alignment.bam output file seems to be missing,OPEN,2024-11-22T04:54:23Z,2024-11-22T12:40:05Z,,"### Ask away!

The workflow completes but I'm not able to locate the alignment.bam file that is listed as one of the outputs. I've had the same issue running in EPI2me desktop and in the command line and using both the V1.4.1 and with earlier versions of the workflow. Is there something specific I need to do to get this file as an output? ",irc47,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/48,epi2me-labs++wf-bacterial-genomes.csv
I_kwDOFIO7Dc6g5aGM,Barcode trimming,OPEN,2024-11-27T18:09:49Z,2024-11-27T18:09:49Z,,"### Ask away!

Hi, 

We are currently following the [NO-MISS protocol](https://nanoporetech.com/document/no-miss-isolate-sequencing-rapid-barcoding-v14) from nanopore. According to their protocol we leave the Minknown settings at default. In this case barcodes will not be trimmed from the FastQ files. Following their workflow they go straight from the raw data to the bacteria genomes pipeline. 

I am not sure if this pipeline trims the barcodes and if it is neccesary at all? Is there any information on this? ",kevinbretscher,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/49,epi2me-labs++wf-bacterial-genomes.csv
MDU6SXNzdWUyNTAxMjE3ODA=,Identify example datasets,CLOSED,2017-08-14T18:58:03Z,2017-08-16T22:14:43Z,2017-08-16T22:14:43Z,Note that there is an S3 bucket with 1kG data,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/1,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAxMzUzNTU=,get PSST working,CLOSED,2017-08-14T19:52:22Z,2017-08-15T16:58:04Z,2017-08-15T16:58:04Z,https://github.com/NCBI-Hackathons/PSST,daler,https://github.com/NCBI-Hackathons/GenomicRobots/issues/2,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAxMzg4ODQ=,BOT-1: Write VCF processor that outputs a N patients x M features table,OPEN,2017-08-14T20:06:25Z,2017-08-14T20:57:58Z,,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/3,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAxNDExNzc=,BOT-1: Create a simple docker container that wraps around VCF processor,OPEN,2017-08-14T20:15:24Z,2017-08-14T21:00:07Z,,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/4,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAxNDEyODE=,Create a container for PII checker program,OPEN,2017-08-14T20:15:48Z,2017-08-14T20:15:48Z,,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/5,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAxNDI3NDM=,Install docker CE on AWS,CLOSED,2017-08-14T20:21:44Z,2017-08-14T21:23:58Z,2017-08-14T21:23:58Z,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/6,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAxNDI4Mjk=,Create dockerhub or quay project for our containers,CLOSED,2017-08-14T20:22:05Z,2017-08-15T14:10:12Z,2017-08-15T14:10:12Z,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/7,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAxNTA5Njc=,"Explore beacon, it's scope and limitations",CLOSED,2017-08-14T20:53:00Z,2017-08-16T22:14:36Z,2017-08-16T22:14:36Z,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/8,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAxNTI2MDU=,BOT-2: Create a script and docker container that runs PSST and outputs a matrix,CLOSED,2017-08-14T20:59:41Z,2017-08-16T22:14:26Z,2017-08-16T22:14:26Z,https://github.com/NCBI-Hackathons/PSST,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/9,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAxNTM1Njk=,Create a simple web frontend for running bots,CLOSED,2017-08-14T21:03:38Z,2017-08-16T22:13:44Z,2017-08-16T22:13:44Z,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/10,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAxNTQyMTM=,gdfgdfg,CLOSED,2017-08-14T21:06:12Z,2017-08-15T20:50:56Z,2017-08-15T20:50:56Z,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/11,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAxNjI2ODA=,Add AWS CLI,CLOSED,2017-08-14T21:41:44Z,2017-08-16T22:14:59Z,2017-08-16T22:14:59Z,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/12,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAxNjU5MjA=,Get MAF from 1kG,CLOSED,2017-08-14T21:56:32Z,2017-08-16T22:14:16Z,2017-08-16T22:14:16Z,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/13,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAzMjUzNTU=,Tuesday Presentation,CLOSED,2017-08-15T14:08:50Z,2017-08-15T16:59:03Z,2017-08-15T16:59:03Z,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/14,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAzMjUzOTk=,Manuscript draft,CLOSED,2017-08-15T14:08:58Z,2017-08-16T22:14:08Z,2017-08-16T22:14:08Z,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/15,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAzMjg5Mjg=,Create/Edit gh project description REAME.md,CLOSED,2017-08-15T14:20:55Z,2017-08-16T22:16:14Z,2017-08-16T22:16:14Z,,neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/16,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTAzODgzNTU=,Explore the results of privacy protection effort iDASH ,CLOSED,2017-08-15T17:55:14Z,2017-08-16T22:14:02Z,2017-08-16T22:14:02Z,"http://idash.ucsd.edu/

https://www.ncbi.nlm.nih.gov/pubmed/28786359
https://www.ncbi.nlm.nih.gov/pubmed/28786360
https://www.ncbi.nlm.nih.gov/pubmed/28786363
",neksa,https://github.com/NCBI-Hackathons/GenomicRobots/issues/18,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTA3MDk5MjQ=,Address privacy in readme,CLOSED,2017-08-16T17:58:14Z,2017-08-18T15:31:02Z,2017-08-18T15:31:02Z,Could you say a little bit more about data security and patient privacy in the readme?  This is a big concern and it's only very briefly addressed here.,informationista,https://github.com/NCBI-Hackathons/GenomicRobots/issues/22,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTA3MTA3NTg=,"Sean, have you seen this repo?",CLOSED,2017-08-16T18:01:17Z,2017-08-16T18:01:27Z,2017-08-16T18:01:27Z,"@thefantasticdron

Just making sure... ",DCGenomics,https://github.com/NCBI-Hackathons/GenomicRobots/issues/23,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTE1MDMwNDU=,mvp,CLOSED,2017-08-20T17:39:15Z,2017-08-20T17:39:31Z,2017-08-20T17:39:31Z,true,brianzelip,https://github.com/NCBI-Hackathons/GenomicRobots/issues/31,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUyNTE1MDQ1NzY=,description,CLOSED,2017-08-20T18:06:43Z,2017-08-20T18:07:00Z,2017-08-20T18:07:00Z,A robotic encapsulation of a variant calling robot that can return de-identified results.,brianzelip,https://github.com/NCBI-Hackathons/GenomicRobots/issues/32,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWUzMDU3MTA2NTc=,Error when running web application,OPEN,2018-03-15T20:37:19Z,2018-03-15T20:37:19Z,,"Hi,

The web application fails on the PSST step. Any ideas on how to resolve? 

Thanks for the help,

Error: 

```
Building a new DB, current time: 03/15/2018 16:21:41
New DB name:   /home/halsteadjs/genomicsrobots/GenomicRobots/HG00096_full/snp_flanks
New DB title:  ./snp_flanks.fasta
Sequence type: Nucleotide
Deleted existing Nucleotide BLAST database named /home/halsteadjs/genomicsrobots/GenomicRobots/HG00096_full/snp_flanks
Keep MBits: T
Maximum file size: 1000000000B
Adding sequences from FASTA; added 9 sequences in 0.00220394 seconds.
Aligning SRA datasets onto the SNPs...
Calling SNPs...
Traceback (most recent call last):
  File ""/home/halsteadjs/genomicsrobots/PSST/src/call_variants.py"", line 368, in <module>
    variants_pool = pool.map(call_sra_variants,alignments_and_info_part)
  File ""/home/halsteadjs/genomicsrobots/GenomicRobots/.snakemake/conda/04333218/lib/python2.7/multiprocessing/pool.py"", line 253, in map
    return self.map_async(func, iterable, chunksize).get()
  File ""/home/halsteadjs/genomicsrobots/GenomicRobots/.snakemake/conda/04333218/lib/python2.7/multiprocessing/pool.py"", line 572, in get
    raise self._value
KeyError: '190650680'
Error in rule psst:
    jobid: 3
    output: HG00096_full/results.tsv
    conda-env: /home/halsteadjs/genomicsrobots/GenomicRobots/.snakemake/conda/04333218

RuleException:
CalledProcessError in line 69 of /home/halsteadjs/genomicsrobots/GenomicRobots/Snakefile:
Command 'source activate /home/halsteadjs/genomicsrobots/GenomicRobots/.snakemake/conda/04333218; set -euo pipefail;  mkdir -p HG00096_full && cd HG00096_full &&PATH=/home/halsteadjs/genomicsrobots/PSST:/usr/bin/magicblast/:$PATH psst.sh -f /home/halsteadjs/genomicsrobots/data/SRR077487.fastq.gz -n /tmp/2c0e3d47-21e5-4e01-935d-162c7937685d/stripped_rs.list -d . -e none@example.com -t 8 -p 8 ' returned non-zero exit status 1.
  File ""/home/halsteadjs/genomicsrobots/GenomicRobots/Snakefile"", line 69, in __rule_psst
  File ""/home/halsteadjs/miniconda3/envs/robots/lib/python3.6/concurrent/futures/thread.py"", line 56, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/halsteadjs/genomicsrobots/GenomicRobots/.snakemake/log/2018-03-15T162135.234712.snakemake.log

```",josephhalstead,https://github.com/NCBI-Hackathons/GenomicRobots/issues/33,NCBI-Hackathons++GenomicRobots.csv
MDU6SXNzdWU3NjkyNTIzNTU=,Generate summary statistics/plots,OPEN,2020-12-16T20:33:05Z,2020-12-16T20:33:05Z,,"Need to generate summary statistics about number of reads, number of read mapped, and perhaps average depth of coverage across the genome, number of unmapped reads too.",hyphaltip,https://github.com/stajichlab/PopGenomics_template/issues/1,stajichlab++PopGenomics_template.csv
I_kwDOEplSbc5tkliE,conda env,OPEN,2023-08-06T18:54:14Z,2023-08-06T19:16:04Z,,"Installing these packages inside a conda env will enable the pipeline to run outside the modules system. The scripts will need to do a `conda activate popgenomics` 


```
conda create -n popgenomics -c bioconda -c conda-forge bwa samtools gatk bcftools minimap2 fasttree iqtree snpeff==4.3.1t jellyfish mosdepth yq picard
conda activate ./popgenomics
```
or make an environment.yml file",hyphaltip,https://github.com/stajichlab/PopGenomics_template/issues/2,stajichlab++PopGenomics_template.csv
I_kwDOKDNCPM6AU-oj,Process: check inputs,CLOSED,2024-02-25T23:05:15Z,2024-02-25T23:23:03Z,2024-02-25T23:23:03Z,"**Description:** Build a process to query the user provided input samplesheet, validate fq files, and extract metadata from read headers (flowcell, lane). 

**Activities**
- [x] Find/build python script to query relevant details of samplesheet 
- [x] Write functioning process module 
- [x] Integrate with workflow and test 
",georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/2,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6AVAAB,Process: index fasta,CLOSED,2024-02-25T23:20:07Z,2024-02-25T23:23:03Z,2024-02-25T23:23:03Z,"**Description:** Build a process for bwa to index the provided reference file only if it doesn't already exist in the basedir of the provided fasta. 

**Activities**

- [x] Write functioning process module
- [x]  Integrate with the workflow with if/else loop in `main.nf` 
- [x] Add a log message to say when process isnt run because index exists 

",georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/3,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6AVATx,Code base: test data,CLOSED,2024-02-25T23:23:42Z,2024-04-30T04:51:46Z,2024-04-30T04:51:46Z,"Add some small test data to the codebase for quick testing. Currently working with data from nf-core/sarek, stored in [`test/`](https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/tree/9ac17b9a01c4d1e541f881bda9e1980a3ce1b8e6/test). 

Contains: 

- 3 fq pairs 
- samplesheet (paths relevant to er01)
- chr21 reference fasta 
- README 

Before closing this ticket, need to update README to contain:
1. Cleaned samplesheet
2. Instructions for fixing samplesheet fq paths relative to own test environment",georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/4,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6AVDi1,Process: pbrun fq2bam,CLOSED,2024-02-26T00:00:37Z,2024-03-03T22:35:13Z,2024-03-03T22:35:13Z,"**Description:** Build a process to run parabricks fq2bam for mapping of fqs to output bam file per sample.  

**Activities**
- [x] Find solution for collecting multiple fq pairs per sample
- [x] Write functioning process module 
- [x] Integrate with workflow and test 

**Requires**

- Check inputs process to capture one fq pair per row",georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/5,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6Ao8Mv,Process: validate fasta input,CLOSED,2024-02-28T06:29:17Z,2024-03-30T07:42:32Z,2024-03-30T07:42:32Z,Indexing with BWA doesn't guarantee that the fasta is correctly formatted. Need a process to validate formatting required for BWA as Parabricks' error reporting is misleading. ,georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/6,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6BZaNd,Process: deepvariant,CLOSED,2024-03-06T08:30:15Z,2024-03-06T08:33:57Z,2024-03-06T08:33:57Z,"**Description:** Build a process to run parabricks deepvariant for short variant calling for bam file per sample to generate gvcf file.  

**Activities**
- [x] Write functioning process module 
- [x] Integrate with workflow and test 

**Requires**

- Bam output by fq2bam",georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/8,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6BaViD,Process: joint genotype,CLOSED,2024-03-06T10:30:29Z,2024-03-06T10:53:00Z,2024-03-06T10:53:00Z,"**Description:** Build a process to run glnexus for joint genotyping of all samples to generate a single cohort vcf. 

**Activities**
- [x] Write functioning glnexus process module 
- [x] Write functioning bcf > vcf process module 
- [x] Integrate with workflow and test 

**Requires**

- Individual gvcfs output by pbrun_deepvariant",georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/10,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6BaYEc,Configure execution for Gadi,OPEN,2024-03-06T10:36:00Z,2024-03-06T10:36:00Z,,Configure resources allocations per process. ,georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/11,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6Bo0ut,Process: bam metrics,CLOSED,2024-03-07T22:51:12Z,2024-03-08T05:43:11Z,2024-03-08T05:43:11Z,"**Description:** Build a process to run Parabrick's implelentation of [GATK collectWGSMetrics](https://docs.nvidia.com/clara/parabricks/4.0.1/documentation/tooldocs/man_bammetrics.html#man-bammetrics) for assessing bams output by fq2bam. 

**Activities**

- [x] Write functioning process module
- [x]  Integrate with the workflow ",georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/13,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6BqWxE,Process: annotate variants,CLOSED,2024-03-08T06:28:04Z,2024-03-26T23:59:43Z,2024-03-26T23:59:42Z,"**Description:** Annotate SNVs and indels with VEP. Requires a process to download of vep_cache for specified assembly if it doesn't already exist and a later process to annotate with offline cache. 

**Activities**

- [x] Write functioning download process module
- [ ] Write functioning annotate process module
- [ ]  Integrate with the workflow with if/else loop in `main.nf` 
- [ ] Add if/else and a log to only run if VEP params specified and if cache doesn't already exist

",georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/15,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6DtJXo,Documentation: README,CLOSED,2024-03-27T01:45:38Z,2024-04-30T04:12:18Z,2024-04-30T04:12:18Z,Write the user guide following [BioCommons workflow doc guidelines](https://github.com/AustralianBioCommons/doc_guidelines/blob/master/documentation_templates/workflows.md),georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/17,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6ESp0Z,MultiQC report,CLOSED,2024-04-02T03:26:15Z,2024-04-02T03:28:35Z,2024-04-02T03:27:46Z,"Add QC summary and reporting. Include fastqc for users sake, merged into multiqc. Todo make optional run fastq only parameter for pipeline. ",georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/21,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6ESp1H,Issues templates,CLOSED,2024-04-02T03:26:18Z,2024-04-02T03:27:34Z,2024-04-02T03:26:35Z,"Set up forms for bug reports and feature requests, as per https://docs.github.com/en/communities/using-templates-to-encourage-useful-issues-and-pull-requests/configuring-issue-templates-for-your-repository ",georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/22,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6HVH-o,Add integration with Seqera platform with `nextflow.schema` ,OPEN,2024-04-30T04:11:30Z,2024-04-30T04:11:30Z,,"### Description of feature

Use `nf-core schema build` to create a graphical schema editor for the seqera platform interface. See [here](https://docs.seqera.io/platform/23.4.0/pipeline-schema/overview) for docs. ",georgiesamaha,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/24,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6JL_2W, glnexus resources,CLOSED,2024-05-17T01:10:41Z,2024-05-20T07:08:11Z,2024-05-20T07:08:11Z,"### Description of feature

Process 'glnexus_joint_call' is assigned to local executor in the Gadi config. Is this correct? Please provide some resource usage examples from real data. ",calizilla,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/30,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6ON_W1,Parabricks 4.3.1-1 failed,CLOSED,2024-07-02T11:41:28Z,2024-07-19T01:52:02Z,2024-07-19T01:52:02Z,"### Description of the bug

I want to use Parabricks to align methylation sequencing data, but I encounter the following error:cudaGetDevice() failed in geting device ID. Status: system not yet initialized, exiting
<img width=""829"" alt="" 2024-07-02 180210"" src=""https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/assets/108064090/23697d6e-db87-44bb-a49e-d64079c4e45f"">


### Command that you ran and terminal output

```console
pbrun fq2bam_meth --ref hg38.fa --in-fq ../fq2bam_test/SRR13749850_1.fastq.gz ../fq2bam_test/SRR13749850_1.fastq.gz --out-ba SRR13749850.bam --num-gpus 1
```


### Relevant files

_No response_",YettaWang,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/31,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
I_kwDOKDNCPM6bwPsc,Minimap2 in new parabricks version,CLOSED,2024-10-25T05:30:49Z,2024-11-04T23:17:49Z,2024-11-04T23:17:49Z,"### Description of feature

Dear Georgie,

The most recent version of Parabricks includes Minimap2, and I need to run simple Minimap jobs, but I am having trouble using Parabricks on Gadi. Rather than a request for a feature, could you kindly provide some instructions or recommendations on how to achieve this?

I was trying to understand the logic behind your pipeline, but I can't find where you're calling or defining the ""singularity run..."" instruction. This would be my first time trying to run GPU-accelerated analysis. Is there something Im not understanding about using Parabricks?

Thank you so much for your kind assistance.
Jess (BABS, UNSW)",xuxocast,https://github.com/Sydney-Informatics-Hub/Parabricks-Genomics-nf/issues/33,Sydney-Informatics-Hub++Parabricks-Genomics-nf.csv
