commit_sha,commit_author_name,commit_author_email,commit_message,commit_date,login
9be50296b03c0a6f5666419ba4c7a59ab55c69d7,Arvid,xesufen@gmail.com,Update README.md,2020-05-31T18:58:49Z,tichenor
3ba0ff458292baca0616e83b91855c5e39332042,Arvid,xesufen@gmail.com,Update README.md,2020-05-31T11:29:21Z,tichenor
a3714f863b318128e2bf160dce0be4b25dd4f192,Arvid,xesufen@gmail.com,Update README.md,2020-05-31T11:26:47Z,tichenor
f1b4940eb3afba7c7354526b34fedd211c7e05d1,Arvid,xesufen@gmail.com,Update README.md,2020-05-31T11:25:52Z,tichenor
4d493cabb6cec0ee992f1c55fa3f91fd47dd72e1,Arvid,xesufen@gmail.com,Update README.md,2020-05-31T11:24:59Z,tichenor
d4890479934e4fe294d110751623f330404c54ee,Arvid,xesufen@gmail.com,Update README.md,2020-05-31T11:24:14Z,tichenor
bc8522f9b531a8a772aea6c0ca7a2d299a5ef78a,Arvid,xesufen@gmail.com,"Create README.md

Brief project description",2020-05-31T11:15:59Z,tichenor
7b047a90b9543a6e197e75b36c1141a3fff4253e,tichenor,xesufen@gmail.com,Polished up the documentation,2020-05-31T10:33:12Z,tichenor
f371340707e521004a779cb41de6c2e01dd78778,tichenor,xesufen@gmail.com,"Revert ""Delete dama18proj.iml""

This reverts commit ca156233",2020-05-11T08:58:51Z,tichenor
835d9af223e092bd9571e820c0e934cff4e88666,tichenor,xesufen@gmail.com,fixed gitignore,2020-05-11T08:56:56Z,tichenor
1317f5e96512f62960ac989746a593b7d1a074be,Arvid,xesufen@gmail.com,Delete .gitignore,2020-05-11T08:48:17Z,tichenor
ca156233b446e843c178a5ed44f5d2e149a9b4e2,Arvid,xesufen@gmail.com,Delete dama18proj.iml,2020-05-11T08:47:52Z,tichenor
4a2f5862aaa4da4942c965b806e58771791c7e04,Arvid,xesufen@gmail.com,deleted a test chunk,2020-05-11T08:47:18Z,tichenor
7ad14a830feb986e469c689d74c017cb6ef64d19,tichenor,xesufen@gmail.com,Results from a full test run in raw text format.,2020-05-11T08:39:02Z,tichenor
77cc8eb9149639327d08749d08048f590af64767,tichenor,xesufen@gmail.com,Minimal changes,2020-05-11T08:35:28Z,tichenor
2d6fe2d99b413d7d70284bf98edb6232049c3803,tichenor,xesufen@gmail.com,Wrote a function for writing the contents of a list to a text file for a simple way to store results. Also wrote a method for tracking progress of longer function executions.,2020-05-11T08:34:33Z,tichenor
c9cc432519cc55644a28c7959fc688f22b855f98,tichenor,xesufen@gmail.com,Updated the indexing function and the graph generating function to track their progress better during execution.,2020-05-11T08:32:37Z,tichenor
1ae4b6eaef995aa762861a5cd3cc169670dbbfce,tichenor,xesufen@gmail.com,Implemented a method to find connected components that uses an iterative depth first search.,2020-05-11T08:31:09Z,tichenor
56234dab8f0a586b0dd609733f2586939beb007c,tichenor,xesufen@gmail.com,"Main class runs a full indexing of all filtered chunks, then generates the full graph. Then the degree distribution and connected components are computed and the results are written to two text files.",2020-05-11T08:29:07Z,tichenor
af592f46b2a98598d9f65ddf32762b25727776af,tichenor,xesufen@gmail.com,Extended functionality of Graph class to find degree distribution of its vertices. Made a custom write-to-file function to write a dictionary (HashMap) to a text file.,2020-05-10T10:50:25Z,tichenor
5d1bb5eb0292bc6c96b5dfc45bb887696b9958bc,tichenor,xesufen@gmail.com,Initial working implementation of graph generation using ArrayList,2020-05-09T19:57:24Z,tichenor
b2e48d63c837afac255ed7d67180ebb5aba3517c,tichenor,xesufen@gmail.com,"Wrote a filter and copy task that reads a chunk and copies each data point (line) into a new file based on whether the overlap is 'true' or 'false', i.e. if the overlap is a containment or not. The resulting filtered copy thus only contains true overlaps. Ran a test on 10 chunks with 2 threads and performance was acceptable. Also checked the 10 new filtered copies with the FindExclusionTask to verify that it was successful; i.e. no exclusions were found.",2020-05-08T11:11:40Z,tichenor
a1161af64adc52d725664428ecb5def877853c98,tichenor,xesufen@gmail.com,"Made an abstract line parsing task that can be extended with specific functionality. Tested this with a FindExclusionTask that checks whether one contig is contained in another, in which case the index of the file(chunk) and the line position is stored in a hash map. Tested it on the first 10 chunks (100k lines/overlaps per chunk; one million lines/overlaps total) with 2 threads: Found about 50-60 thousand exclusions per chunk (more than half!). Test took about 500 ms. Seems viable to run on the whole data set, should take less than a minute.",2020-05-08T09:52:05Z,tichenor
57197b1ca594f335333e00d648c831cc1f8207d1,tichenor,xesufen@gmail.com,Initial commit: Data file has been briefly analyzed and split into smaller files of 1 million lines each. Only the first file is included due to space limitations. Nothing is really working properly yet except the line counter in CustomReader and the parallel line parser.,2020-05-08T08:27:50Z,tichenor
