id,title,state,created_at,updated_at,closed_at,body,user,url
I_kwDOFIO7Dc5CXcLo,Medaka Model,CLOSED,2022-01-25T05:24:06Z,2023-07-07T15:03:57Z,2023-07-07T15:03:57Z,"Hi

May I know what are the `medaka models` that being supported in this pipeline?

Thank you!",llk578496,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/1
I_kwDOFIO7Dc5Ny7jr,"SyntaxWarning: ""is"" with a literal. Did you mean ""==""?",CLOSED,2022-07-14T19:23:37Z,2023-08-18T11:16:45Z,2023-08-18T11:16:45Z,"Hi,
I just wanted to bring up an issue that I have run into when using the wf-bacterial-genomes workflow. I am getting this error on the medakaNetwork process when I run the workflow on a directory of fastqs from one barcode. However, if I pre concatenate the barcode fastqs I do not run into this issue. For the time being is pre concatenating a suitable fix, would it harm the final output of the analysis?

Thank you.

`
Error executing process > 'calling_pipeline:medakaNetwork (2)'

Caused by:
  Process `calling_pipeline:medakaNetwork (2)` terminated with an error exit status (137)

Command executed:

  medaka consensus 00-480.reads2ref.bam 00-480.2.consensus_probs.hdf --threads 2 --model r941_prom_variant_g360 --region ""contig_2:0-1000000
  ""

Command exit status:
  137

Command output:
  (empty)

Command error:
  /home/epi2melabs/conda/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py:285: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?
    minval_is_zero = minval is 0  # pylint: disable=literal-comparison
  /home/epi2melabs/conda/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py:286: SyntaxWarning: ""is"" with a literal. Did you mean ""==""?
    maxval_is_one = maxval is 1  # pylint: disable=literal-comparison
  /home/epi2melabs/conda/lib/python3.8/site-packages/tensorflow/python/ops/ragged/ragged_batch_gather_with_default_op.py:84: SyntaxWarning: ""is not"" with a literal. Did you mean ""!=""?
    if (default_value.shape.ndims is not 0
  /home/epi2melabs/conda/lib/python3.8/site-packages/tensorflow/python/ops/ragged/ragged_batch_gather_with_default_op.py:85: SyntaxWarning: ""is not"" with a literal. Did you mean ""!=""?
    and default_value.shape.ndims is not 1):
  [17:13:51 - Predict] Setting tensorflow inter/intra-op threads to 2/1.
  [17:13:51 - Predict] Processing region(s): contig_2:0-1000000
  [17:13:51 - Predict] Using model: /home/epi2melabs/conda/lib/python3.8/site-packages/medaka/data/r941_prom_variant_g360_model.hdf5.
  [17:13:51 - Predict] Processing 1 long region(s) with batching.
  [17:13:51 - MdlStore] filepath /home/epi2melabs/conda/lib/python3.8/site-packages/medaka/data/r941_prom_variant_g360_model.hdf5
  [17:13:52 - Sampler] Initializing sampler for consensus of region contig_2:0-1000000.
  [17:13:52 - PWorker] Running inference for 1.0M draft bases.
  [17:14:00 - Feature] Processed contig_2:0.0-999999.2 (median depth 173.0)
  [17:14:00 - Sampler] Took 8.76s to make features.
  [17:14:22 - PWorker] Batches in cache: 3.
  [17:14:22 - PWorker] 34.1% Done (0.3/1.0 Mbases) in 30.8s
  .command.sh: line 3:    29 Killed                  medaka consensus 00-480.reads2ref.bam 00-480.2.consensus_probs.hdf --threads 2 --model r941_prom_variant_g360 --region ""contig_2:0-1000000
  ""
`",awh082834,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/2
I_kwDOFIO7Dc5UauGT,demo Workflow has terminated but no outputs are available,CLOSED,2022-10-20T09:33:21Z,2023-08-18T11:16:34Z,2023-08-18T11:16:34Z,"### What happened?

demo Workflow has terminated but no outputs are available

### Operating System

Windows 10

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

3.1.5  env 1.2.5

### Workflow Execution - Execution Profile

Docker

### Workflow Version

0.2.5

### Relevant log output

```shell
N E X T F L O W ~ version 21.10.6

Launching `epi2me-labs/wf-bacterial-genomes` [trusting_hopper] - revision: 24db269e21 [v0.2.5]

NOTE: Your local project version looks outdated - a different revision is available in the remote repository [9b59bc5d52]

Core Nextflow options

revision : v0.2.5

runName : trusting_hopper

containerEngine: docker

launchDir : /mnt/c/Users/alessiosoggiu/epi2melabs-data/nextflow

workDir : /mnt/c/Users/alessiosoggiu/epi2melabs-data/nextflow/instances/2022-10-20-11-32_wf-bacterial-genomes_LV36YMTkYBavTzSe4b6eLV/work

projectDir : /root/.nextflow/assets/epi2me-labs/wf-bacterial-genomes

userName : root

profile : standard

configFiles : /root/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config

Input/output options

fastq : /root/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/test_data/fastq

out_dir : /mnt/c/Users/alessiosoggiu/epi2melabs-data/nextflow/instances/2022-10-20-11-32_wf-bacterial-genomes_LV36YMTkYBavTzSe4b6eLV/output

Reference genome options

reference : /root/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/test_data/ref

!! Only displaying parameters that differ from the pipeline defaults !!

------------------------------------------------------

If you use epi2me-labs/wf-template for your analysis please cite:

* The nf-core framework

https://doi.org/10.1038/s41587-020-0439-x

Checking fastq input.

Barcoded directories detected.

[28/5a5158] Submitted process > calling_pipeline:getVersions

[cc/76fc24] Submitted process > calling_pipeline:getParams

[4d/bac24c] Submitted process > calling_pipeline:concatFastq (1)

[ba/5bf686] Submitted process > calling_pipeline:concatFastq (2)

[cf/39ffea] Submitted process > calling_pipeline:alignReads (1)

[25/26eca3] Submitted process > calling_pipeline:alignReads (2)

Error executing process > 'calling_pipeline:alignReads (1)'

Caused by:

Process `calling_pipeline:alignReads (1)` terminated with an error exit status (1)

Command executed:

mini_align -i barcode02.reads.fastq -r ref -p barcode02.reads2ref -t 1 -m

Command exit status:

1

Command output:

(empty)

Command error:

Constructing minimap index.

[E::fai_build3_core] Failed to open the file ref

[faidx] Could not build fai index ref.fai

Work dir:

/mnt/c/Users/alessiosoggiu/epi2melabs-data/nextflow/instances/2022-10-20-11-32_wf-bacterial-genomes_LV36YMTkYBavTzSe4b6eLV/work/cf/39ffea222a7cca01477cc1eb288a01

Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`

WARN: Killing pending tasks (2)
```
",asogg,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/3
I_kwDOFIO7Dc5gwuXf,[Bug]: Report not taking top hit of 16s quast blast ,CLOSED,2023-03-14T12:31:53Z,2023-08-18T11:16:07Z,2023-08-18T11:16:07Z,"### What happened?

Hi, 

Report appears to be showing 3rd top hit of blast results from metaquast against SILVA 16s database. 

Example metaquast blast result:

```
# BLASTN 2.13.0+
# Query: NZ_CP027798.1
# Database: /home/epi2melabs/conda/lib/python3.8/site-packages/quast_libs/silva/silva.138.1.db
# Fields: query acc.ver, subject acc.ver, % identity, alignment length, mismatches, gap opens, q. start, q. end, s. start, s. end, evalue, bit score
# 4000 hits found
NZ_CP027798.1	CP012639.1795630.1797181_Bacteria;Proteobacteria;Gammaproteobacteria;Enterobacterales;Yersiniaceae;Serratia;Serratia_marcescens	100.000	1552	0	0	3730374	3731925	1552	1	0.0	2867
NZ_CP027798.1	CP012639.1795630.1797181_Bacteria;Proteobacteria;Gammaproteobacteria;Enterobacterales;Yersiniaceae;Serratia;Serratia_marcescens	99.936	1552	0	1	652578	654128	1	1552	0.0	2859
NZ_CP027798.1	CP012639.1795630.1797181_Bacteria;Proteobacteria;Gammaproteobacteria;Enterobacterales;Yersiniaceae;Serratia;Serratia_marcescens	99.807	1552	2	1	5036064
```
Report shows %identity of 99.807 (image attached)
![quast_error_AM90](https://user-images.githubusercontent.com/38727026/225002270-b40a7d88-3c68-4d1d-b2a6-05071e943753.png)


Appears to be the run_species_stats function in report.py where species_data df has top hit as header, and top_hit takes 2nd row (i.e 3rd row of quast blast output). 
```
def run_species_stats(species_stats_path, sample_names):    
    """"""Analysis of metaquast data.""""""
    results = []
    for indexs, sample_name in enumerate(sample_names):
        species_data_path = os.path.join(
            species_stats_path, ""blast.res_""+sample_name+""-medaka"")
        species_data = pd.read_csv(species_data_path, sep='\t', comment=""#"")
        top_hit = species_data.iloc[1, :]
        species_split = re.split(""\\."", top_hit[1])[2].split("";"")
        species = species_split[len(species_split)-1]
        species = re.sub(""_"", "" "", species)
        results.append(
            {'Sample': sample_name,
             'Species': species,
             'Perc_identity': top_hit[2]})
    results_df = pd.DataFrame(results, index=sample_names).iloc[:, 1:3]
    results_df.columns = ['Species ID', 'Identity (%)']
    return results_df
```

Possible fix:
```
def run_species_stats(species_stats_path, sample_names):    
    """"""Analysis of metaquast data.""""""
    results = []
    for indexs, sample_name in enumerate(sample_names):
        species_data_path = os.path.join(
            species_stats_path, ""blast.res_""+sample_name+""-medaka"")
        species_data = pd.read_csv(species_data_path, sep='\t', comment=""#"", header=None)
        top_hit = species_data.iloc[0, :]
        species_split = re.split(""\\."", top_hit[1])[2].split("";"")
        species = species_split[len(species_split)-1]
        species = re.sub(""_"", "" "", species)
        results.append(
            {'Sample': sample_name,
             'Species': species,
             'Perc_identity': top_hit[2]})
    results_df = pd.DataFrame(results, index=sample_names).iloc[:, 1:3]
    results_df.columns = ['Species ID', 'Identity (%)']
    return results_df
```




### Operating System

ubuntu 20.04

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

None

### Workflow Version

0.2.12

### Relevant log output

```shell
N/A
```
",cjalder,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/4
I_kwDOFIO7Dc5g8JpH,workflow fails with demo data,CLOSED,2023-03-15T22:38:49Z,2023-03-22T07:16:46Z,2023-03-21T20:46:55Z,"### What happened?

Hi,

I have been trying to get this workflow to run for awhile with no success. When attempting to run the workflow on demo data it rapidly fails and produces a ""stops with error"" outcome. 

The log shows that there is an error when calling prokka:
Command error:
touch: cannot touch '.command.trace': Permission denied

I have tried altering permissions to the directory to be the most permissive with no success. 

Would you be able to help?

Thanks,
Charlie

### Operating System

Ubuntu 20.04

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

V4.1.3

### Workflow Execution - CLI Execution Profile

None

### Workflow Version

v0.2.12

### Relevant log output

```shell
NOTE: Nextflow is not tested with Java 1.8.0_362 -- It's recommended the use of version 11 up to 18
N E X T F L O W  ~  version 22.04.5
Launching `/home/nanopore-catalyst/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/main.nf` [goofy_kalam] DSL2 - revision: f4f74b71cb
||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.2.12
--------------------------------------------------------------------------------
Core Nextflow options
  runName             : goofy_kalam
  containerEngine     : docker
  launchDir           : /home/nanopore-catalyst/epi2melabs/instances/wf-bacterial-genomes_07513228-afc6-44a5-b9f8-494da672e466
  workDir             : /home/nanopore-catalyst/epi2melabs/instances/wf-bacterial-genomes_07513228-afc6-44a5-b9f8-494da672e466/work
  projectDir          : /home/nanopore-catalyst/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes
  userName            : nanopore-catalyst
  profile             : standard
  configFiles         : /home/nanopore-catalyst/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/nextflow.config, /home/nanopore-catalyst/epi2melabs/instances/wf-bacterial-genomes_07513228-afc6-44a5-b9f8-494da672e466/demo.config
Input Options
  fastq               : /home/nanopore-catalyst/epi2melabs/demo/epi2me-labs/wf-bacterial-genomes/wf-bacterial-genomes-demo/fastq
  summarise_assemblies: true
Output Options
  out_dir             : /home/nanopore-catalyst/epi2melabs/instances/wf-bacterial-genomes_07513228-afc6-44a5-b9f8-494da672e466/output
!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:
* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x
--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v0.2.12.
--------------------------------------------------------------------------------
Checking fastq input.
Barcoded directories detected.
Running Denovo assembly.
[1a/dc8277] Submitted process > calling_pipeline:prokkaVersion
[41/fbfb49] Submitted process > calling_pipeline:concatFastq (1)
[d5/485863] Submitted process > calling_pipeline:concatFastq (2)
[0e/d5e754] Submitted process > calling_pipeline:getParams
[29/445c44] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
Error executing process > 'calling_pipeline:prokkaVersion'
Caused by:
  Process `calling_pipeline:prokkaVersion` terminated with an error exit status (1)
Command executed:
  prokka --version | sed 's/ /,/' >> ""prokka_version.txt""
Command exit status:
  1
Command output:
  (empty)
Command error:
  touch: cannot touch '.command.trace': Permission denied
Work dir:
  /home/nanopore-catalyst/epi2melabs/instances/wf-bacterial-genomes_07513228-afc6-44a5-b9f8-494da672e466/work/1a/dc827712d6c17f9700b49dcaa836ba
Tip: when you have fixed the problem you can continue the execution adding the option `-resume` to the run command line
WARN: Killing running tasks (4)
```
",baynec2,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/5
I_kwDOFIO7Dc5jwrWR,[Bug]: No VCF file output? ,CLOSED,2023-04-18T19:21:44Z,2023-07-07T15:01:00Z,2023-07-07T15:01:00Z,"### What happened?

Hello, 
I am using the command-line version of the wf-bacterial-genomes workflow. 
It successfully finished and provided me the FASTA file, genbank file, and html report, but no VCF file was found.
Is there a setting I may be missing?
Here is my command:
`nextflow run epi2me-labs/wf-bacterial-genomes -profile standard --fastq ../Lab_Z6X_2_AK029-A.fastq --reference ../avinelandiidj_genome.fasta --threads 4`

### Operating System

ubuntu 20.04

### Workflow Execution

Command line

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

Docker

### Workflow Version

v0.2.12-g8ded2f0

### Relevant log output

```shell
N E X T F L O W  ~  version 22.10.6
Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [fervent_aryabhata] DSL2 - revision: 8ded2f04e8 [master]

||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.2.12-g8ded2f0
--------------------------------------------------------------------------------
Core Nextflow options
  revision            : master
  runName             : fervent_aryabhata
  containerEngine     : docker
  launchDir           : /home/msobol/test
  workDir             : /home/msobol/test/work
  projectDir          : /home/msobol/.nextflow/assets/epi2me-labs/wf-bacterial-genomes
  userName            : msobol
  profile             : standard
  configFiles         : /home/msobol/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config

Input Options
  fastq               : ../Lab_Z6X_2_AK029-A.fastq
  reference           : ../avinelandiidj_genome.fasta
  summarise_assemblies: true

Advanced Options
  threads             : 4

!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:

* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x


--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v0.2.12-g8ded2f0.
--------------------------------------------------------------------------------
Checking fastq input.
Single file input detected.
WARN: Access to undefined parameter `process_label` -- Initialise it to a default value eg. `params.process_label = some_value`
executor >  local (26)
[d6/c83249] process > isolateSingleFile (1)                              [100%] 1 of 1 âœ”
[cd/e197b6] process > calling_pipeline:concatFastq (1)                   [100%] 1 of 1 âœ”
[e8/38fa6c] process > calling_pipeline:deNovo (1)                        [100%] 1 of 1 âœ”
[bf/fa8d4b] process > calling_pipeline:alignReads (1)                    [100%] 1 of 1 âœ”
[a5/a3288f] process > calling_pipeline:readStats (1)                     [100%] 1 of 1 âœ”
[e7/4ab1f9] process > calling_pipeline:coverStats (1)                    [100%] 1 of 1 âœ”
[c3/b7bb3e] process > calling_pipeline:splitRegions (1)                  [100%] 1 of 1 âœ”
[80/11003a] process > calling_pipeline:lookup_medaka_consensus_model (1) [100%] 1 of 1 âœ”
[3b/6f7688] process > calling_pipeline:lookup_medaka_variant_model (1)   [100%] 1 of 1 âœ”
[f5/1eaada] process > calling_pipeline:medakaNetwork (5)                 [100%] 6 of 6 âœ”
[26/51465e] process > calling_pipeline:medakaConsensus (1)               [100%] 1 of 1 âœ”
[1b/70978d] process > calling_pipeline:assemblyStats                     [100%] 1 of 1 âœ”
[8c/ed8b7e] process > calling_pipeline:runProkka (1)                     [100%] 1 of 1 âœ”
[18/cccd7a] process > calling_pipeline:prokkaVersion                     [100%] 1 of 1 âœ”
[68/f6f220] process > calling_pipeline:medakaVersion                     [100%] 1 of 1 âœ”
[a8/c32d1b] process > calling_pipeline:getVersions                       [100%] 1 of 1 âœ”
[96/03fc69] process > calling_pipeline:getParams                         [100%] 1 of 1 âœ”
[75/806f5d] process > calling_pipeline:makeReport                        [100%] 1 of 1 âœ”
[69/3a2ebd] process > output (2)                                         [100%] 3 of 3 âœ”
Completed at: 18-Apr-2023 14:02:30
Duration    : 31m 38s
CPU hours   : 1.7
Succeeded   : 26
```
",morgansobol,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/6
I_kwDOFIO7Dc5kj-LW,[Bug]: program doesn't run,CLOSED,2023-04-27T16:06:14Z,2023-07-07T15:01:20Z,2023-07-07T15:01:20Z,"### What happened?

First off thank you for this great program <3

The program unfortunately does not run. I have attached the screenshot of my termainal to show the error message that I am getting. It says this:
No such variable: Exception evaluating property 'out' for nextflow.script.ChannelOut, Reason: groovy.lang.MissingPropertyException: No such property: out for class: groovyx.gpars.dataflow.DataflowBroadcast


Thank you for the help!

![Screenshot from 2023-04-27 09-01-50](https://user-images.githubusercontent.com/81880944/234920542-eac6b603-e1e4-4547-b68e-72140c6e26d5.png)


### Operating System

ubuntu 20.04

### Workflow Execution

Command line

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

None

### Workflow Version

0.2.5

### Relevant log output

```shell
There is no log output in my output directory.
```
",matteo1313,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/7
I_kwDOFIO7Dc5lDQFW,[Bug]: Problem with Metaquast-part of report,CLOSED,2023-05-04T06:40:05Z,2023-08-18T11:15:48Z,2023-08-18T11:15:47Z,"### What happened?

Hi Team,

When running the workflow, it stops (either when using reference-based assembly or de novo assembly) with an error because the report cannot be compiled. This might be due to missing reference files for metaquast (see log output). I am using a proxy server for internet connection.
Is there any workaround for this? I did not find the folder mentioned in the error message to manually provide the reference file.

Thank you very much in advance!

### Operating System

ubuntu 20.04

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

4.1.4

### Workflow Execution - CLI Execution Profile

Docker

### Workflow Version

v0.2.12

### Relevant log output

```shell
Workflow execution completed unsuccessfully!

The exit status of the task that caused the workflow execution to fail was: 1.

The full error message was:

Error executing process > 'calling_pipeline:makeReport'

Caused by:
  Process `calling_pipeline:makeReport` terminated with an error exit status (1)

Command executed:

  workflow-glue report     --prokka      --versions versions     --params params.json     --output wf-bacterial-genomes-report.html     --sample_ids 2639127-28052-01

Command exit status:
  1

Command output:
  (empty)

Command error:
  /home/epi2melabs/conda/lib/python3.8/site-packages/pkg_resources/__init__.py:2804: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)
  /home/epi2melabs/conda/lib/python3.8/site-packages/pkg_resources/__init__.py:2804: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('repoze')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)
  /home/epi2melabs/conda/lib/python3.8/site-packages/pkg_resources/__init__.py:2804: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)
  /home/epi2melabs/conda/lib/python3.8/site-packages/pkg_resources/__init__.py:2804: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.
  Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
    declare_namespace(pkg)
  /home/epi2melabs/conda/lib/python3.8/site-packages/BCBio/GFF/GFFParser.py:66: DeprecationWarning: invalid escape sequence \w
    gff3_kw_pat = re.compile(""\w+="")
  [09:08:04 - workflow_glue] Starting entrypoint.
  Traceback (most recent call last):
    File ""/home/nanopore/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/bin/workflow-glue"", line 7, in 
      cli()
    File ""/home/nanopore/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/bin/workflow_glue/__init__.py"", line 62, in cli
      args.func(args)
    File ""/home/nanopore/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/bin/workflow_glue/report.py"", line 275, in main
      species_stats = run_species_stats(
    File ""/home/nanopore/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/bin/workflow_glue/report.py"", line 146, in run_species_stats
      species_data = pd.read_csv(species_data_path, sep='\t', comment=""#"")
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/util/_decorators.py"", line 211, in wrapper
      return func(*args, **kwargs)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/util/_decorators.py"", line 331, in wrapper
      return func(*args, **kwargs)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 950, in read_csv
      return _read(filepath_or_buffer, kwds)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 605, in _read
      parser = TextFileReader(filepath_or_buffer, **kwds)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 1442, in __init__
      self._engine = self._make_engine(f, self.engine)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 1735, in _make_engine
      self.handles = get_handle(
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/common.py"", line 856, in get_handle
      handle = open(
  FileNotFoundError: [Errno 2] No such file or directory: 'quast_stats/quast_downloaded_references/blast.res_2639127-28052-01-medaka'

Work dir:
  /home/nanopore/epi2melabs/instances/wf-bacterial-genomes_278008ab-61d9-4c96-8600-5e4e4c7d1453/work/d7/31ebbb6a71721aa9651db0b7fb89e2

Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`


And also Metaquast.log:

/home/epi2melabs/conda/bin/metaquast.py -o quast_output -t 1 2639127-28052-01.medaka.fasta.gz

Version: 5.2.0

System information:
  OS: Linux-5.15.0-71-generic-x86_64-with-glibc2.10 (linux_64)
  Python version: 3.8.15
  CPUs number: 48

Started: 2023-05-03 08:59:05

Logging to /home/nanopore/epi2melabs/instances/wf-bacterial-genomes_278008ab-61d9-4c96-8600-5e4e4c7d1453/work/06/ae06638763ae742c301cf76dd9e858/quast_output/metaquast.log

Contigs:
  Pre-processing...
  2639127-28052-01.medaka.fasta.gz ==> 2639127-28052-01.medaka

No references are provided, starting to search for reference genomes in SILVA 16S rRNA database and to download them from NCBI...

2023-05-03 08:59:08

Downloading SILVA 16S ribosomal RNA gene database (version 138.1)...

ERROR! Failed downloading SILVA 16S rRNA gene database (http://www.arb-silva.de/fileadmin/silva_databases/release_138.1/Exports/SILVA_138.1_SSURef_NR99_tax_silva.fasta.gz)! The search for reference genomes cannot be performed. Try to download it manually, put under /home/epi2melabs/conda/lib/python3.8/site-packages/quast_libs/silva/ and restart your command.
Reference genomes are not found.

NOTICE: No references are provided, starting regular QUAST with MetaGeneMark gene finder
```
",lknegendorf,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/8
I_kwDOFIO7Dc5ln7fl,[Bug]: Error in checking FASTQ and Script,CLOSED,2023-05-11T02:56:53Z,2023-07-07T15:06:06Z,2023-07-07T15:06:06Z,"### What happened?

Hi, I got an error while running wf-bacterial-genomes using demo data. However, I successfully executed the others such as wf-transcriptomes and wf-metagenomics without any issues. I also attempted to resolve the issue by deleting and re-installingl the workflow, but it still doesn't work. 

nextflow.log
https://drive.google.com/file/d/1U9TybH7EfQaYLwebU-Y7O3UKQVSF29X_/view?usp=share_link

Could you please help me with this?

### Operating System

Windows 11

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

4.1.3

### Workflow Execution - CLI Execution Profile

Docker

### Workflow Version

0.2.13

### Relevant log output

```shell
N E X T F L O W  ~  version 22.04.5
Launching `/mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/workflows/epi2me-labs/wf-bacterial-genomes/main.nf` [blissful_aryabhata] DSL2 - revision: 85754a734d
||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.2.13
--------------------------------------------------------------------------------
Core Nextflow options
  runName        : blissful_aryabhata
  containerEngine: docker
  launchDir      : /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/instances/wf-bacterial-genomes_082be453-ed96-4e18-8f7f-7c0fe5725e46
  workDir        : /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/instances/wf-bacterial-genomes_082be453-ed96-4e18-8f7f-7c0fe5725e46/work
  projectDir     : /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/workflows/epi2me-labs/wf-bacterial-genomes
  userName       : jump
  profile        : standard
  configFiles    : /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/workflows/epi2me-labs/wf-bacterial-genomes/nextflow.config, /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/instances/wf-bacterial-genomes_082be453-ed96-4e18-8f7f-7c0fe5725e46/demo.config
Input Options
  fastq          : /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/demo/epi2me-labs/wf-bacterial-genomes/wf-bacterial-genomes-demo/fastq
Output Options
  out_dir        : /mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/instances/wf-bacterial-genomes_082be453-ed96-4e18-8f7f-7c0fe5725e46/output
!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:
* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x
--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v0.2.13.
--------------------------------------------------------------------------------
Checking fastq input.
Input directory '/mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/demo/epi2me-labs/wf-bacterial-genomes/wf-bacterial-genomes-demo/fastq' cannot contain FASTQ files and sub-directories with FASTQ files.
 -- Check script '/mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/workflows/epi2me-labs/wf-bacterial-genomes/./lib/fastqingress.nf' at line: 293 or see '/mnt/wsl/docker-desktop-bind-mounts/Ubuntu/3c273db223050d5cc07c2940af95c7595e6656d16e5332b9b39e30b9c8ec06cc/instances/wf-bacterial-genomes_082be453-ed96-4e18-8f7f-7c0fe5725e46/nextflow.log' file for more details
```
",phongphak,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/9
I_kwDOFIO7Dc5nFGBE,[Bug]: Failed to build prokka singularity image,CLOSED,2023-05-28T10:45:15Z,2023-05-31T15:54:53Z,2023-05-31T15:54:53Z,"### What happened?

```
Error executing process > 'calling_pipeline:prokkaVersion'

Caused by:
  Failed to pull singularity image
  command: singularity pull  --name ontresearch-prokka-sha08669655982fbef7c750c7895e97e100196c4967.img.pulling.1685270451064 docker://ontresearch/prokka:sha08669655982fbef7c750c7895e97e100196c4967 > /dev/null
  status : 255
  message:
    INFO:    Converting OCI blobs to SIF format
    INFO:    Starting build...
    Getting image source signatures
    Copying blob sha256:0d9e0007c6ce71ae58e9bc7f851c00164171d6f0692e16461df735bf76533804
    Copying blob sha256:3b65ec22a9e96affe680712973e88355927506aa3f792ff03330f3a3eb601a98
    Copying blob sha256:841971ce0eda383b58744bb8ddbd52b52f4a97756fd995ff31d24276df207477
    Copying blob sha256:5d642c3b6198dd371ea8a09ba12867f66c5e127febcbeb1791446af033ae97a4
    Copying blob sha256:d96d7215a062c674c82c408836f9c89cf3728322ee56a49010c396ca679a0b1c
    Copying blob sha256:27a9f84bae05e2575847f4e95ac0955fb4f5cdb87faf7410c44905eaeae20040
    Copying blob sha256:b3bf890f25149ff8980e2f9f3b484ad6ab8cdd75fef4e6cb8b268fce944c308f
    Copying blob sha256:b3bf890f25149ff8980e2f9f3b484ad6ab8cdd75fef4e6cb8b268fce944c308f
    Copying config sha256:36b6725b02a33e75bd952fd7e0f56c3d8ddaccd52a91ad5cac5533bf41cd034a
    Writing manifest to image destination
    Storing signatures
    FATAL:   While making image from oci registry: error fetching image to cache: while building SIF from layers: conveyor failed to get: no descriptor found for reference ""sha256.e9a0243edee458b0ba7af7426107908ae91d9a17f813e628f872c3ee23560cea""

```

**singularity version 3.10**

### Operating System

ubuntu 20.04

### Workflow Execution

Command line

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

Singularity

### Workflow Version

wf-bacterial-genomes v0.2.9-g4d009af

### Relevant log output

```shell
Posted in ""What happened?""
```
",thanhleviet,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/10
I_kwDOFIO7Dc5nbGwQ,Medaka model for dna_r10.4.1_e8.2_260bps_sup ??,CLOSED,2023-05-31T23:08:30Z,2023-08-18T11:20:43Z,2023-08-18T11:20:42Z,"### What happened?

Hello,

There is no medaka model for the R10.4.1, 260bps, super accurate basecalling. What should I do? 

### Operating System

Windows 10

### Workflow Execution

Command line

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

None

### Workflow Version

0.2.12

### Relevant log output

```shell
ERROR: Validation pipeline of parameters failed!

*--basecaller_cfg: dna_r10.4.1_e8.2_260bps_sup is not a valid enum value (dna_r10.4.1_e8.2_260bps_sup)
```
",lagphase,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/11
I_kwDOFIO7Dc5pENwk,[Bug]: Pipeline terminates with error when specifying more than 4 --threads ,CLOSED,2023-06-19T04:35:35Z,2023-07-28T13:58:11Z,2023-07-28T13:58:11Z,"### What happened?

The pipeline is terminating with an error when running the command with --threads specified higher than 4
I am running it on a 16 CPU VM on our cluster, and would like to take advantage of that for de novo assembly

However, the following error is generated and the pipeline exits when specifying --threads 8 for example

`ERROR ~ Error executing process > 'calling_pipeline:deNovo (1)'

Caused by:
  Process requirement exceeds available CPUs -- req: 8; avail: 4

Command executed:

  LOW_COV_FAIL=0
  FLYE_EXIT_CODE=0
  flye --nano-raw reads.fastq.gz --out-dir output --threads ""8"" ||     FLYE_EXIT_CODE=$?
  
  if [[ $FLYE_EXIT_CODE -eq 0 ]]; then
      mv output/assembly.fasta ""./sa19_filtered.draft_assembly.fasta""
      mv output/assembly_info.txt ""./sa19_filtered_flye_stats.tsv""
      bgzip ""sa19_filtered.draft_assembly.fasta""
  else
      # flye failed --> check the log to see if low coverage caused the failure
      edge_cov=$(grep -oP 'Mean edge coverage: \K\d+' output/flye.log)
      ovlp_cov=$(grep -oP 'Overlap-based coverage: \K\d+' output/flye.log)
      if [[
          $edge_cov -lt 5 ||
          $ovlp_cov -lt 5
      ]]; then
          echo -n ""Caught Flye failure due to low coverage (either mean edge cov. or ""
          echo ""overlap-based cov. were below 5)"".
          LOW_COV_FAIL=1
      else
          # exit a subshell with error so that the process fails
          ( exit $FLYE_EXIT_CODE )
      fi
  fi

Command exit status:
  -

Command output:
  (empty)`

### Operating System

ubuntu 20.04

### Workflow Execution

Command line

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

Docker

### Workflow Version

v0.3.0-g0d2379f

### Relevant log output

```shell
Jun-19 02:15:25.721 [main] DEBUG nextflow.cli.Launcher - $> nextflow run epi2me-labs/wf-bacterial-genomes --fastq sa19_filtered.fastq.gz --threads 8 --out_dir wf-bac-genome
Jun-19 02:15:25.795 [main] INFO  nextflow.cli.CmdRun - N E X T F L O W  ~  version 23.04.1
Jun-19 02:15:25.811 [main] DEBUG nextflow.plugin.PluginsFacade - Setting up plugin manager > mode=prod; embedded=false; plugins-dir=/home/ubuntu/.nextflow/plugins; core-plugins: nf-amazon@1.16.2,nf-azure@1.0.1,nf-codecommit@0.1.4,nf-console@1.0.5,nf-ga4gh@1.0.5,nf-google@1.7.3,nf-tower@1.5.12,nf-wave@0.8.2
Jun-19 02:15:25.820 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Enabled plugins: []
Jun-19 02:15:25.821 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Disabled plugins: []
Jun-19 02:15:25.824 [main] INFO  org.pf4j.DefaultPluginManager - PF4J version 3.4.1 in 'deployment' mode
Jun-19 02:15:25.832 [main] INFO  org.pf4j.AbstractPluginManager - No plugins
Jun-19 02:15:25.844 [main] DEBUG nextflow.scm.ProviderConfig - Using SCM config path: /home/ubuntu/.nextflow/scm
Jun-19 02:15:26.611 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/.git/config; branch: master; remote: origin; url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Jun-19 02:15:26.628 [main] DEBUG nextflow.scm.RepositoryFactory - Found Git repository result: [RepositoryFactory]
Jun-19 02:15:26.635 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/.git/config; branch: master; remote: origin; url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Jun-19 02:15:27.903 [main] DEBUG nextflow.config.ConfigBuilder - Found config base: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Jun-19 02:15:27.904 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Jun-19 02:15:27.916 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Jun-19 02:15:28.055 [main] DEBUG nextflow.cli.CmdRun - Applied DSL=2 from script declararion
Jun-19 02:15:28.056 [main] INFO  nextflow.cli.CmdRun - Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [suspicious_mendel] DSL2 - revision: 0d2379f52b [master]
Jun-19 02:15:28.056 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins default=[]
Jun-19 02:15:28.056 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins resolved requirement=[]
Jun-19 02:15:28.060 [main] DEBUG nextflow.secret.LocalSecretsProvider - Secrets store: /home/ubuntu/.nextflow/secrets/store.json
Jun-19 02:15:28.062 [main] DEBUG nextflow.secret.SecretsLoader - Discovered secrets providers: [nextflow.secret.LocalSecretsProvider@7e5efcab] - activable => nextflow.secret.LocalSecretsProvider@7e5efcab
Jun-19 02:15:28.107 [main] DEBUG nextflow.Session - Session UUID: 8602c007-fc97-495e-a8b8-e2bcb6dffea8
Jun-19 02:15:28.108 [main] DEBUG nextflow.Session - Run name: suspicious_mendel
Jun-19 02:15:28.108 [main] DEBUG nextflow.Session - Executor pool size: 16
Jun-19 02:15:28.118 [main] DEBUG nextflow.util.ThreadPoolBuilder - Creating thread pool 'FileTransfer' minSize=10; maxSize=48; workQueue=LinkedBlockingQueue[10000]; allowCoreThreadTimeout=false
Jun-19 02:15:28.135 [main] DEBUG nextflow.cli.CmdRun - 
  Version: 23.04.1 build 5866
  Created: 15-04-2023 06:51 UTC 
  System: Linux 5.15.0-67-generic
  Runtime: Groovy 3.0.16 on OpenJDK 64-Bit Server VM 20-internal-adhoc..src
  Encoding: UTF-8 (UTF-8)
  Process: 2467608@rnaseq [127.0.1.1]
  CPUs: 16 - Mem: 62.8 GB (8.6 GB) - Swap: 0 (0)
Jun-19 02:15:28.149 [main] DEBUG nextflow.Session - Work-dir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work [ext2/ext3]
Jun-19 02:15:28.166 [main] DEBUG nextflow.executor.ExecutorFactory - Extension executors providers=[]
Jun-19 02:15:28.175 [main] DEBUG nextflow.Session - Observer factory: DefaultObserverFactory
Jun-19 02:15:28.245 [main] DEBUG nextflow.cache.CacheFactory - Using Nextflow cache factory: nextflow.cache.DefaultCacheFactory
Jun-19 02:15:28.255 [main] DEBUG nextflow.util.CustomThreadPool - Creating default thread pool > poolSize: 17; maxThreads: 1000
Jun-19 02:15:28.610 [main] DEBUG nextflow.Session - Session start
Jun-19 02:15:28.622 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow started -- trace file: /home/ubuntu/scratch/raw_data/nanopore/sa19/wf-bac-genome/execution/trace.txt
Jun-19 02:15:28.629 [main] DEBUG nextflow.Session - Using default localLib path: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Jun-19 02:15:28.633 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Jun-19 02:15:28.634 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib/nfcore_external_java_deps.jar
Jun-19 02:15:30.611 [main] DEBUG nextflow.script.ScriptRunner - > Launching execution
Jun-19 02:15:31.341 [main] INFO  nextflow.Nextflow - 
[0;92m||||||||||   [0m[2m_____ ____ ___ ____  __  __ _____      _       _
[0;92m||||||||||  [0m[2m| ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
[0;33m|||||       [0m[2m|  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
[0;33m|||||       [0m[2m| |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
[0;94m||||||||||  [0m[2m|_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
[0;94m||||||||||  [0m[1mwf-bacterial-genomes v0.3.0-g0d2379f[0m
[2m--------------------------------------------------------------------------------[0m
[1mCore Nextflow options[0m
  [0;34mrevision       : [0;32mmaster[0m
  [0;34mrunName        : [0;32msuspicious_mendel[0m
  [0;34mcontainerEngine: [0;32mdocker[0m
  [0;34mlaunchDir      : [0;32m/home/ubuntu/scratch/raw_data/nanopore/sa19[0m
  [0;34mworkDir        : [0;32m/home/ubuntu/scratch/raw_data/nanopore/sa19/work[0m
  [0;34mprojectDir     : [0;32m/home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes[0m
  [0;34muserName       : [0;32mubuntu[0m
  [0;34mprofile        : [0;32mstandard[0m
  [0;34mconfigFiles    : [0;32m/home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config[0m

[1mInput Options[0m
  [0;34mfastq          : [0;32msa19_filtered.fastq.gz[0m

[1mOutput Options[0m
  [0;34mout_dir        : [0;32mwf-bac-genome[0m

[1mAdvanced Options[0m
  [0;34mthreads        : [0;32m8[0m

[1mOther parameters[0m
  [0;34mprocess_label  : [0;32mwfbacterialgenomes[0m

!! Only displaying parameters that differ from the pipeline defaults !!
[2m--------------------------------------------------------------------------------[0m
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:

* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x


[2m--------------------------------------------------------------------------------[0m
This is epi2me-labs/wf-bacterial-genomes v0.3.0-g0d2379f.
[2m--------------------------------------------------------------------------------[0m
Jun-19 02:15:32.535 [main] INFO  nextflow.Nextflow - Checking fastq input.
Jun-19 02:15:32.917 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name fastcat
Jun-19 02:15:32.922 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:32.922 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:33.173 [main] DEBUG nextflow.executor.Executor - [warm up] executor > local
Jun-19 02:15:33.179 [main] DEBUG n.processor.LocalPollingMonitor - Creating local task monitor for executor 'local' > cpus=4; memory=8 GB; capacity=16; pollInterval=100ms; dumpInterval=5m
Jun-19 02:15:34.444 [main] INFO  nextflow.Nextflow - Running Denovo assembly.
Jun-19 02:15:34.603 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:deNovo
Jun-19 02:15:34.604 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.604 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.615 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:alignReads
Jun-19 02:15:34.615 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.615 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.618 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:readStats
Jun-19 02:15:34.618 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.618 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.621 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:coverStats
Jun-19 02:15:34.621 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.621 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.625 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:splitRegions
Jun-19 02:15:34.625 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.625 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.638 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:lookup_medaka_consensus_model
Jun-19 02:15:34.638 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.639 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.641 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:lookup_medaka_variant_model
Jun-19 02:15:34.642 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.642 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.653 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaNetwork
Jun-19 02:15:34.654 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.654 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.661 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaConsensus
Jun-19 02:15:34.661 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.661 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.665 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:prokka` matches labels `prokka` for process with name calling_pipeline:runProkka
Jun-19 02:15:34.665 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.665 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.668 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:prokka` matches labels `prokka` for process with name calling_pipeline:prokkaVersion
Jun-19 02:15:34.668 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.668 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.670 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaVersion
Jun-19 02:15:34.670 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.670 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.672 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:mlst` matches labels `mlst` for process with name calling_pipeline:mlstVersion
Jun-19 02:15:34.672 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.672 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.674 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:getVersions
Jun-19 02:15:34.674 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.674 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.676 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:getParams
Jun-19 02:15:34.676 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.676 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.693 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:makeReport
Jun-19 02:15:34.694 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.694 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.698 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:collectFastqIngressResultsInDir
Jun-19 02:15:34.698 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.698 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.708 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name output
Jun-19 02:15:34.708 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Jun-19 02:15:34.708 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Jun-19 02:15:34.710 [main] DEBUG nextflow.Session - Workflow process names [dsl2]: resfinder, calling_pipeline:alignReads, deNovo, medakaConsensus, calling_pipeline:getParams, validate_sample_sheet, calling_pipeline:mlstVersion, calling_pipeline:lookup_medaka_variant_model, calling_pipeline:medakaVersion, medakaVersion, alignReads, readStats, output, medakaVariant, runProkka, medakaNetwork, collectFastqIngressResultsInDir, makeReport, calling_pipeline:deNovo, calling_pipeline:collectFastqIngressResultsInDir, lookup_medaka_variant_model, getVersions, calling_pipeline:coverStats, medakaVariantConsensus, calling_pipeline:readStats, prokkaVersion, calling_pipeline:medakaConsensus, lookup_medaka_consensus_model, calling_pipeline:medakaNetwork, splitRegions, getPointfinderSpecies, calling_pipeline:getVersions, coverStats, calling_pipeline:runProkka, calling_pipeline:makeReport, calling_pipeline:splitRegions, calling_pipeline:lookup_medaka_consensus_model, move_or_compress, processResfinder, mlstSearch, fastcat, mlstVersion, getParams, makePerSampleReports, calling_pipeline:prokkaVersion
Jun-19 02:15:34.712 [main] DEBUG nextflow.Session - Igniting dataflow network (28)
Jun-19 02:15:34.713 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > fastcat
Jun-19 02:15:34.713 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:deNovo
Jun-19 02:15:34.713 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:alignReads
Jun-19 02:15:34.713 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:readStats
Jun-19 02:15:34.713 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:coverStats
Jun-19 02:15:34.713 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:splitRegions
Jun-19 02:15:34.718 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:lookup_medaka_consensus_model
Jun-19 02:15:34.718 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:lookup_medaka_variant_model
Jun-19 02:15:34.718 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaNetwork
Jun-19 02:15:34.718 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaConsensus
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:runProkka
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:prokkaVersion
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaVersion
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:mlstVersion
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:getVersions
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:getParams
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:makeReport
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:collectFastqIngressResultsInDir
Jun-19 02:15:34.719 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > output
Jun-19 02:15:34.719 [main] DEBUG nextflow.script.ScriptRunner - > Awaiting termination 
Jun-19 02:15:34.719 [main] DEBUG nextflow.Session - Session await
Jun-19 02:15:35.021 [Actor Thread 4] DEBUG nextflow.util.CacheHelper - Hash asset file sha-256: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/data/medaka_models.tsv
Jun-19 02:15:35.063 [Actor Thread 6] DEBUG nextflow.util.CacheHelper - Hash asset file sha-256: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/bin/workflow-glue
Jun-19 02:15:35.099 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 02:15:35.118 [Task submitter] INFO  nextflow.Session - [54/b76301] Submitted process > calling_pipeline:prokkaVersion
Jun-19 02:15:35.125 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 02:15:35.125 [Task submitter] INFO  nextflow.Session - [53/101949] Submitted process > calling_pipeline:getParams
Jun-19 02:15:35.130 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 02:15:35.131 [Task submitter] INFO  nextflow.Session - [b9/ba8311] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
Jun-19 02:15:35.134 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 02:15:35.134 [Task submitter] INFO  nextflow.Session - [f7/19f9fe] Submitted process > calling_pipeline:lookup_medaka_consensus_model (1)
Jun-19 02:16:54.311 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 2; name: calling_pipeline:prokkaVersion; status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/54/b76301075d0155a45631eaec504c88]
Jun-19 02:16:55.316 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 02:16:55.316 [Task submitter] INFO  nextflow.Session - [95/1556bc] Submitted process > calling_pipeline:medakaVersion
Jun-19 02:17:10.826 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 4; name: calling_pipeline:getParams; status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/53/10194967aa1d0c93fe54b9406c5bb9]
Jun-19 02:17:22.256 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 1; name: calling_pipeline:lookup_medaka_variant_model (1); status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/b9/ba8311b4462575ea21affcbef22efd]
Jun-19 02:17:23.610 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 3; name: calling_pipeline:lookup_medaka_consensus_model (1); status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/f7/19f9fec5a75d56031ed0d421470710]
Jun-19 02:17:23.614 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 02:17:23.615 [Task submitter] INFO  nextflow.Session - [2c/4fb84a] Submitted process > fastcat (1)
Jun-19 02:17:46.457 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 5; name: fastcat (1); status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/2c/4fb84a5c2ee3454d3468d3f06b8e08]
Jun-19 02:17:46.470 [Task submitter] DEBUG nextflow.processor.TaskProcessor - Handling unexpected condition for
  task: name=calling_pipeline:deNovo (1); work-dir=/home/ubuntu/scratch/raw_data/nanopore/sa19/work/6a/62ce6616158344cec75d3cc8d1e421
  error [nextflow.exception.ProcessUnrecoverableException]: Process requirement exceeds available CPUs -- req: 8; avail: 4
Jun-19 02:17:46.542 [Task submitter] DEBUG nextflow.processor.TaskRun - Unable to dump error of process 'null' -- Cause: java.nio.file.NoSuchFileException: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/6a/62ce6616158344cec75d3cc8d1e421/.command.log
Jun-19 02:17:46.543 [Task submitter] ERROR nextflow.processor.TaskProcessor - Error executing process > 'calling_pipeline:deNovo (1)'

Caused by:
  Process requirement exceeds available CPUs -- req: 8; avail: 4

Command executed:

  LOW_COV_FAIL=0
  FLYE_EXIT_CODE=0
  flye --nano-raw reads.fastq.gz --out-dir output --threads ""8"" ||     FLYE_EXIT_CODE=$?
  
  if [[ $FLYE_EXIT_CODE -eq 0 ]]; then
      mv output/assembly.fasta ""./sa19_filtered.draft_assembly.fasta""
      mv output/assembly_info.txt ""./sa19_filtered_flye_stats.tsv""
      bgzip ""sa19_filtered.draft_assembly.fasta""
  else
      # flye failed --> check the log to see if low coverage caused the failure
      edge_cov=$(grep -oP 'Mean edge coverage: \K\d+' output/flye.log)
      ovlp_cov=$(grep -oP 'Overlap-based coverage: \K\d+' output/flye.log)
      if [[
          $edge_cov -lt 5 ||
          $ovlp_cov -lt 5
      ]]; then
          echo -n ""Caught Flye failure due to low coverage (either mean edge cov. or ""
          echo ""overlap-based cov. were below 5)"".
          LOW_COV_FAIL=1
      else
          # exit a subshell with error so that the process fails
          ( exit $FLYE_EXIT_CODE )
      fi
  fi

Command exit status:
  -

Command output:
  (empty)

Work dir:
  /home/ubuntu/scratch/raw_data/nanopore/sa19/work/6a/62ce6616158344cec75d3cc8d1e421

Tip: when you have fixed the problem you can continue the execution adding the option `-resume` to the run command line
Jun-19 02:17:46.545 [Task submitter] DEBUG nextflow.Session - Session aborted -- Cause: Process requirement exceeds available CPUs -- req: 8; avail: 4
Jun-19 02:17:46.558 [Task submitter] DEBUG nextflow.Session - The following nodes are still active:
[process] calling_pipeline:alignReads
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:readStats
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:coverStats
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:splitRegions
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:medakaNetwork
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:medakaConsensus
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:runProkka
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:mlstVersion
  status=ACTIVE
  port 0: (value) OPEN  ; channel: input_version.txt
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:getVersions
  status=ACTIVE
  port 0: (value) OPEN  ; channel: input_versions.txt
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:makeReport
  status=ACTIVE
  port 0: (value) OPEN  ; channel: versions/*
  port 1: (value) bound ; channel: params.json
  port 2: (value) bound ; channel: variants/*
  port 3: (value) bound ; channel: sample_ids
  port 4: (value) OPEN  ; channel: prokka/*
  port 5: (queue) OPEN  ; channel: per_read_stats
  port 6: (value) OPEN  ; channel: fwd/*
  port 7: (value) OPEN  ; channel: rev/*
  port 8: (value) OPEN  ; channel: total_depth/*
  port 9: (value) OPEN  ; channel: flye_stats/*
  port 10: (value) bound ; channel: resfinder/*
  port 11: (value) bound ; channel: mlst/*
  port 12: (cntrl) -     ; channel: $

[process] output
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: fname
  port 1: (cntrl) -     ; channel: $

Jun-19 02:17:47.509 [main] DEBUG nextflow.Session - Session await > all processes finished
Jun-19 02:17:47.510 [main] DEBUG nextflow.Session - Session await > all barriers passed
Jun-19 02:17:47.743 [main] WARN  n.processor.TaskPollingMonitor - Killing running tasks (1)
Jun-19 02:17:47.820 [Actor Thread 11] ERROR nextflow.extension.DataflowHelper - @unknown
java.nio.channels.ClosedByInterruptException: null
	at java.base/java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:199)
	at java.base/sun.nio.ch.FileChannelImpl.endBlocking(FileChannelImpl.java:171)
	at java.base/sun.nio.ch.FileChannelImpl.mapInternal(FileChannelImpl.java:1349)
	at java.base/sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:1188)
	at org.iq80.leveldb.impl.MMapLogWriter.<init>(MMapLogWriter.java:66)
	at org.iq80.leveldb.impl.Logs.createLogWriter(Logs.java:36)
	at org.iq80.leveldb.impl.VersionSet.initializeIfNeeded(VersionSet.java:107)
	at org.iq80.leveldb.impl.VersionSet.<init>(VersionSet.java:92)
	at org.iq80.leveldb.impl.DbImpl.<init>(DbImpl.java:180)
	at org.iq80.leveldb.impl.Iq80DBFactory.open(Iq80DBFactory.java:83)
	at nextflow.sort.LevelDbSort.create(LevelDbSort.java:48)
	at nextflow.file.SortFileCollector.createStoreAndIndex(SortFileCollector.groovy:174)
	at nextflow.file.SortFileCollector.add(SortFileCollector.groovy:204)
	at nextflow.file.SortFileCollector$add.call(Unknown Source)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:125)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:148)
	at nextflow.extension.CollectFileOp.processItem(CollectFileOp.groovy:162)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
	at java.base/java.lang.reflect.Method.invoke(Method.java:578)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:107)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:323)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1258)
	at groovy.lang.MetaClassImpl.invokeMethodClosure(MetaClassImpl.java:1047)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1132)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1035)
	at groovy.lang.Closure.call(Closure.java:412)
	at groovy.lang.Closure.call(Closure.java:428)
	at groovy.lang.Closure$call.call(Unknown Source)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:53)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:139)
	at nextflow.extension.DataflowHelper$_subscribeImpl_closure2.doCall(DataflowHelper.groovy:284)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
	at java.base/java.lang.reflect.Method.invoke(Method.java:578)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:107)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:323)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:274)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1035)
	at groovy.lang.Closure.call(Closure.java:412)
	at groovyx.gpars.dataflow.operator.DataflowOperatorActor.startTask(DataflowOperatorActor.java:120)
	at groovyx.gpars.dataflow.operator.DataflowOperatorActor.onMessage(DataflowOperatorActor.java:108)
	at groovyx.gpars.actor.impl.SDAClosure$1.call(SDAClosure.java:43)
	at groovyx.gpars.actor.AbstractLoopingActor.runEnhancedWithoutRepliesOnMessages(AbstractLoopingActor.java:293)
	at groovyx.gpars.actor.AbstractLoopingActor.access$400(AbstractLoopingActor.java:30)
	at groovyx.gpars.actor.AbstractLoopingActor$1.handleMessage(AbstractLoopingActor.java:93)
	at groovyx.gpars.util.AsyncMessagingCore.run(AsyncMessagingCore.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1623)
Jun-19 02:17:47.821 [main] DEBUG nextflow.trace.WorkflowStatsObserver - Workflow completed > WorkflowStats[succeededCount=5; failedCount=1; ignoredCount=0; cachedCount=0; pendingCount=2; submittedCount=0; runningCount=-1; retriesCount=0; abortedCount=1; succeedDuration=1m 48s; failedDuration=0ms; cachedDuration=0ms;loadCpus=-8; loadMemory=0; peakRunning=4; peakCpus=4; peakMemory=0; ]
Jun-19 02:17:47.823 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow completed -- saving trace file
Jun-19 02:17:47.824 [main] DEBUG nextflow.trace.ReportObserver - Workflow completed -- rendering execution report
Jun-19 02:17:47.865 [main] DEBUG nextflow.trace.ReportObserver - Execution report summary data:
  [{""cpuUsage"":{""mean"":15.2,""min"":15.2,""q1"":15.2,""q2"":15.2,""q3"":15.2,""max"":15.2,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""process"":""prokkaVersion"",""mem"":{""mean"":12091392,""min"":12091392,""q1"":12091392,""q2"":12091392,""q3"":12091392,""max"":12091392,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":22552576,""min"":22552576,""q1"":22552576,""q2"":22552576,""q3"":22552576,""max"":22552576,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""reads"":{""mean"":1554117,""min"":1554117,""q1"":1554117,""q2"":1554117,""q3"":1554117,""max"":1554117,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""cpu"":{""mean"":15.2,""min"":15.2,""q1"":15.2,""q2"":15.2,""q3"":15.2,""max"":15.2,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""time"":{""mean"":440,""min"":440,""q1"":440,""q2"":440,""q3"":440,""max"":440,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""writes"":{""mean"":252,""min"":252,""q1"":252,""q2"":252,""q3"":252,""max"":252,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""}},{""cpuUsage"":{""mean"":123.1,""min"":123.1,""q1"":123.1,""q2"":123.1,""q3"":123.1,""max"":123.1,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""process"":""getParams"",""mem"":null,""memUsage"":null,""timeUsage"":null,""vmem"":null,""reads"":{""mean"":58942,""min"":58942,""q1"":58942,""q2"":58942,""q3"":58942,""max"":58942,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""cpu"":{""mean"":123.1,""min"":123.1,""q1"":123.1,""q2"":123.1,""q3"":123.1,""max"":123.1,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""time"":{""mean"":2,""min"":2,""q1"":2,""q2"":2,""q3"":2,""max"":2,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""writes"":{""mean"":1646,""min"":1646,""q1"":1646,""q2"":1646,""q3"":1646,""max"":1646,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""}},{""cpuUsage"":{""mean"":42.1,""min"":42.1,""q1"":42.1,""q2"":42.1,""q3"":42.1,""max"":42.1,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""process"":""lookup_medaka_variant_model"",""mem"":{""mean"":414617600,""min"":414617600,""q1"":414617600,""q2"":414617600,""q3"":414617600,""max"":414617600,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":2538094592,""min"":2538094592,""q1"":2538094592,""q2"":2538094592,""q3"":2538094592,""max"":2538094592,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""reads"":{""mean"":52719589,""min"":52719589,""q1"":52719589,""q2"":52719589,""q3"":52719589,""max"":52719589,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""cpu"":{""mean"":42.1,""min"":42.1,""q1"":42.1,""q2"":42.1,""q3"":42.1,""max"":42.1,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""time"":{""mean"":34747,""min"":34747,""q1"":34747,""q2"":34747,""q3"":34747,""max"":34747,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""writes"":{""mean"":26566109,""min"":26566109,""q1"":26566109,""q2"":26566109,""q3"":26566109,""max"":26566109,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""}},{""cpuUsage"":{""mean"":40.8,""min"":40.8,""q1"":40.8,""q2"":40.8,""q3"":40.8,""max"":40.8,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""process"":""lookup_medaka_consensus_model"",""mem"":{""mean"":414904320,""min"":414904320,""q1"":414904320,""q2"":414904320,""q3"":414904320,""max"":414904320,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":2553286656,""min"":2553286656,""q1"":2553286656,""q2"":2553286656,""q3"":2553286656,""max"":2553286656,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""reads"":{""mean"":52719602,""min"":52719602,""q1"":52719602,""q2"":52719602,""q3"":52719602,""max"":52719602,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""cpu"":{""mean"":40.8,""min"":40.8,""q1"":40.8,""q2"":40.8,""q3"":40.8,""max"":40.8,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""time"":{""mean"":41009,""min"":41009,""q1"":41009,""q2"":41009,""q3"":41009,""max"":41009,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""writes"":{""mean"":26566108,""min"":26566108,""q1"":26566108,""q2"":26566108,""q3"":26566108,""max"":26566108,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""}},{""cpuUsage"":{""mean"":48.1,""min"":48.1,""q1"":48.1,""q2"":48.1,""q3"":48.1,""max"":48.1,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""process"":""fastcat"",""mem"":{""mean"":10878976,""min"":10878976,""q1"":10878976,""q2"":10878976,""q3"":10878976,""max"":10878976,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":385417216,""min"":385417216,""q1"":385417216,""q2"":385417216,""q3"":385417216,""max"":385417216,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""reads"":{""mean"":670543345,""min"":670543345,""q1"":670543345,""q2"":670543345,""q3"":670543345,""max"":670543345,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""cpu"":{""mean"":144.3,""min"":144.3,""q1"":144.3,""q2"":144.3,""q3"":144.3,""max"":144.3,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""time"":{""mean"":10678,""min"":10678,""q1"":10678,""q2"":10678,""q3"":10678,""max"":10678,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""writes"":{""mean"":678402356,""min"":678402356,""q1"":678402356,""q2"":678402356,""q3"":678402356,""max"":678402356,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""}},{""cpuUsage"":null,""process"":""deNovo"",""mem"":null,""memUsage"":null,""timeUsage"":null,""vmem"":null,""reads"":null,""cpu"":null,""time"":null,""writes"":null},{""cpuUsage"":null,""process"":""medakaVersion"",""mem"":null,""memUsage"":null,""timeUsage"":null,""vmem"":null,""reads"":null,""cpu"":null,""time"":null,""writes"":null}]
Jun-19 02:17:48.971 [main] DEBUG nextflow.trace.TimelineObserver - Workflow completed -- rendering execution timeline
Jun-19 02:17:49.032 [main] DEBUG nextflow.cache.CacheDB - Closing CacheDB done
Jun-19 02:17:49.107 [main] DEBUG nextflow.file.FileCollector - Deleting file collector temp dir: /tmp/nxf-12209019396811809986
Jun-19 02:17:49.109 [main] DEBUG nextflow.file.SortFileCollector - FileCollector temp dir not removed: null
Jun-19 02:17:49.109 [main] DEBUG nextflow.script.ScriptRunner - > Execution complete -- Goodbye
```
",samuelmontgomery,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/12
I_kwDOFIO7Dc5pERe1,[Bug]: error executing process 'calling_pipeline:run_isolates:processResfinder',CLOSED,2023-06-19T04:57:17Z,2023-08-18T11:18:01Z,2023-08-18T11:18:00Z,"### What happened?

Hi, 
I am getting a consisent error when including --isolate true in my pipeline
It appears the pipeline isn't writing the results of PointFinder to the work directory, as the pipeline is unable to find it to run 'calling_pipeline:run_isolates:processResfinder'

When navigating to the work directory, I can see that the file ""PointFinder_results.txt"" file does not exists, but the ResFinder results are there

### Operating System

Windows 10

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

None

### Workflow Version

v0.3

### Relevant log output

```shell
Jun-19 04:49:42.954 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 04:49:42.954 [Task submitter] INFO  nextflow.Session - [a4/411820] Submitted process > calling_pipeline:run_isolates:resfinder (1)
Jun-19 04:50:41.769 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 23; name: calling_pipeline:run_isolates:resfinder (1); status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/a4/4118209cff8e009ecdd2f27175e9c1]
Jun-19 04:50:41.780 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 04:50:41.780 [Task submitter] INFO  nextflow.Session - [19/c71662] Submitted process > calling_pipeline:run_isolates:processResfinder (1)
Jun-19 04:50:41.800 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Jun-19 04:50:41.800 [Task submitter] INFO  nextflow.Session - [45/602b1a] Submitted process > calling_pipeline:makePerSampleReports (1)
Jun-19 04:51:06.198 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 25; name: calling_pipeline:makePerSampleReports (1); status: COMPLETED; exit: 0; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/45/602b1a068f4d425447a8511e7acb53]
Jun-19 04:51:07.416 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 24; name: calling_pipeline:run_isolates:processResfinder (1); status: COMPLETED; exit: 1; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/19/c71662a3a4cdbd3afaaed301540476]
Jun-19 04:51:07.419 [Task monitor] DEBUG nextflow.processor.TaskProcessor - Handling unexpected condition for
  task: name=calling_pipeline:run_isolates:processResfinder (1); work-dir=/home/ubuntu/scratch/raw_data/nanopore/sa19/work/19/c71662a3a4cdbd3afaaed301540476
  error [nextflow.exception.ProcessFailedException]: Process `calling_pipeline:run_isolates:processResfinder (1)` terminated with an error exit status (1)
Jun-19 04:51:07.427 [Task monitor] ERROR nextflow.processor.TaskProcessor - Error executing process > 'calling_pipeline:run_isolates:processResfinder (1)'

Caused by:
  Process `calling_pipeline:run_isolates:processResfinder (1)` terminated with an error exit status (1)

Command executed:

  workflow-glue process_resfinder             --resfinder_file sa19_filtered_resfinder_results/ResFinder_results_tab.txt             --pointfinder_file sa19_filtered_resfinder_results/PointFinder_results.txt             --output sa19_filtered.resfinder_results.txt             --database_location sa19_filtered_resfinder_results/pointfinder_blast/tmp/

Command exit status:
  1

Command output:
  (empty)

Command error:
  [04:50:58 - workflow_glue] Starting entrypoint.
  Traceback (most recent call last):
    File ""/home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/bin/workflow-glue"", line 7, in <module>
      cli()
    File ""/home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/bin/workflow_glue/__init__.py"", line 62, in cli
      args.func(args)
    File ""/home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/bin/workflow_glue/process_resfinder.py"", line 161, in main
      pointfinder_data = pd.read_csv(args.pointfinder_file, sep=""\t"")
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 912, in read_csv
      return _read(filepath_or_buffer, kwds)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 577, in _read
      parser = TextFileReader(filepath_or_buffer, **kwds)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 1407, in __init__
      self._engine = self._make_engine(f, self.engine)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py"", line 1661, in _make_engine
      self.handles = get_handle(
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/pandas/io/common.py"", line 859, in get_handle
      handle = open(
  FileNotFoundError: [Errno 2] No such file or directory: 'sa19_filtered_resfinder_results/PointFinder_results.txt'

Work dir:
  /home/ubuntu/scratch/raw_data/nanopore/sa19/work/19/c71662a3a4cdbd3afaaed301540476

Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`
Jun-19 04:51:07.429 [Task monitor] DEBUG nextflow.Session - Session aborted -- Cause: Process `calling_pipeline:run_isolates:processResfinder (1)` terminated with an error exit status (1)
Jun-19 04:51:07.442 [Task monitor] DEBUG nextflow.Session - The following nodes are still active:
[process] calling_pipeline:makeReport
  status=ACTIVE
  port 0: (value) bound ; channel: versions/*
  port 1: (value) bound ; channel: params.json
  port 2: (value) bound ; channel: variants/*
  port 3: (value) bound ; channel: sample_ids
  port 4: (value) bound ; channel: prokka/*
  port 5: (queue) closed; channel: per_read_stats
  port 6: (value) bound ; channel: fwd/*
  port 7: (value) bound ; channel: rev/*
  port 8: (value) bound ; channel: total_depth/*
  port 9: (value) bound ; channel: flye_stats/*
  port 10: (value) bound ; channel: resfinder/*
  port 11: (value) bound ; channel: mlst/*
  port 12: (cntrl) -     ; channel: $

[process] output
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: fname
  port 1: (cntrl) -     ; channel: $

Jun-19 04:51:07.454 [Actor Thread 13] DEBUG nextflow.util.CacheHelper - Hash asset file sha-256: /home/ubuntu/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/data/OPTIONAL_FILE
Jun-19 04:51:07.457 [Task submitter] DEBUG n.processor.TaskPollingMonitor - %% executor local > tasks in the submission queue: 1 -- tasks to be submitted are shown below
~> TaskHandler[id: 26; name: calling_pipeline:makeReport (1); status: NEW; exit: -; error: -; workDir: /home/ubuntu/scratch/raw_data/nanopore/sa19/work/0e/1029af066443477807ff5d62f0630e]
Jun-19 04:51:08.400 [main] DEBUG nextflow.Session - Session await > all processes finished
Jun-19 04:51:08.400 [main] DEBUG nextflow.Session - Session await > all barriers passed
Jun-19 04:51:08.637 [main] DEBUG nextflow.trace.WorkflowStatsObserver - Workflow completed > WorkflowStats[succeededCount=24; failedCount=1; ignoredCount=0; cachedCount=0; pendingCount=1; submittedCount=0; runningCount=0; retriesCount=0; abortedCount=0; succeedDuration=55m 13s; failedDuration=25.5s; cachedDuration=0ms;loadCpus=0; loadMemory=0; peakRunning=4; peakCpus=4; peakMemory=0; ]
Jun-19 04:51:08.637 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow completed -- saving trace file
Jun-19 04:51:08.638 [main] DEBUG nextflow.trace.ReportObserver - Workflow completed -- rendering execution report
```
",samuelmontgomery,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/13
I_kwDOFIO7Dc5pS4af,[Question]: no gbk output files for the newest version?,CLOSED,2023-06-21T02:22:28Z,2023-07-28T13:54:47Z,2023-07-28T13:54:47Z,"### What happened?

Hi, 
The newest version generates gff output file but not gbk file anymore (which is not really helpful). Is there an option for gbk output file? Thanks.

### Operating System

Windows 10

### Workflow Execution

EPI2ME Labs desktop application

### Workflow Execution - EPI2ME Labs Versions

_No response_

### Workflow Execution - CLI Execution Profile

None

### Workflow Version

0.3.0

### Relevant log output

```shell
||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.3.0-g0d2379f
```
",lagphase,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/14
I_kwDOFIO7Dc5sqcWm,r1041_e82_400bps_sup_v4.2.0 missing from basecaller options,CLOSED,2023-07-26T19:51:40Z,2023-08-18T10:58:35Z,2023-08-18T10:58:35Z,"### Is your feature related to a problem?

I use the bacterial genome workflow with data from Plasmidsaurus, a commercial plasmid/genome sequencing service based on Nanopore sequencing tech. They use the r1041_e82_400bps_sup_v4.2.0 basecalling option, which seems to be absent from the current Medeka models. 

### Describe the solution you'd like

Train the Medeka model on r1041_e82_400bps_sup_v4.2.0 and include it as an option. 

### Describe alternatives you've considered

What would be the closest, currently available basecalling model?

### Additional context

_No response_",WolfgangSchmied,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/15
I_kwDOFIO7Dc5tD3Zl,Use `-profile docker` instead of `-profile standard` when using Docker,CLOSED,2023-07-31T17:43:02Z,2023-08-18T10:54:18Z,2023-08-18T10:54:17Z,"### Is your feature related to a problem?

At the moment, for using _Docker_, one needs to run the workflow with `-profile standard`. 
It might be more intuitive for users to use `-profile docker` to do this instead, which is the standard used by `nf-core` pipelines. 

### Describe the solution you'd like

I believe this could be done by changing the [current config file](https://github.com/epi2me-labs/wf-bacterial-genomes/blob/e223e1b85bd301fd73cac520048ac2d1fbd5f82a/nextflow.config#L102) to use something closer to what nf-core pipelines use ([example here](https://github.com/nf-core/rnaseq/blob/3bec2331cac2b5ff88a1dc71a21fab6529b57a0f/nextflow.config#L145)).

### Describe alternatives you've considered

Adding clearer documentation about the default behaviour to the README (and possibly the `--help` page) could be an alternative. At the moment this has to be inferred from the config source. 

### Additional context

(and thank you for all the work in developing these pipelines!)",tavareshugo,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/16
I_kwDOFIO7Dc5teEPI,"Got ""No disjointigs were assembled"" error when running denovo",CLOSED,2023-08-04T11:42:59Z,2023-08-18T11:19:39Z,2023-08-18T11:19:39Z,"I have tried to run the pipeline with single ONT sample on WSL2 with singularity profile _denovo_ i.e. running with flye assembler. The sample appears to have high coverage. It is from bacteria with 4mb genome size.  Further investigation in the .nexflow.log file indicated it is a flye related error which seemed to be the case as reported [here](https://github.com/fenderglass/Flye/issues/128).

 I manually configured the flye command in the 'main.nf' file by adding the `--asm-coverage` and `--genome-size` options which didn't throw that error anymore only threw a memory error.

Would it be convenient to add in the advanced options additional parameters in the pipeline for running flye like it is recommended [here](https://github.com/fenderglass/Flye/issues/128#issuecomment-506509828) in a similar way you hva done for running prokka or medaka which are available in the pipeline usage help (`nextflow run epi2me-labs/wf-bacterial-genomes --help`)?

Note:
The solution given in the flye issue above require to add additional paramter `--genome-size <value>` as shoen in the current flye usage [doc](https://github.com/fenderglass/Flye/blob/flye/docs/USAGE.md#-quick-usage).

Thank you!",bsalehe,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/17
I_kwDOFIO7Dc5vBCvb,Different result from flye 2.9.2,CLOSED,2023-08-23T04:26:14Z,2023-08-25T15:15:54Z,2023-08-25T15:15:54Z,"### Ask away!

I've assemble a circular bacterial genome from fastq data using flye CLI 2.9.2-b1794
I used an options: --nano=hq only.

and i tried to use this workflow to assemble same bacterial genome as well.
but i found the result fasta file of wf-bacterial-genomes is different from flye's 

I've check the flye version in the workflow and it was 2.9.2 -b1786 - same as mine
I assume the flye option that this workflow uses maybe different from my flye configuration.

How could i see the flye option that wf-bacterial-genomes uses?

and one more thing, Is there any way that i could change flye option in the EPI2ME Labs?",Yoon90,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/18
I_kwDOFIO7Dc5yZffM,Workflow execution completed unsuccessfully! Error executing process > 'calling_pipeline:medakaNetwork (2)',CLOSED,2023-09-29T13:34:34Z,2023-09-29T13:38:24Z,2023-09-29T13:38:24Z,"### Ask away!

Hello Epi2me labs team,

We tried to run the workflow 'bacterial genome' within an oracle VM with Ubuntu 22.04.3 LTS 64-bit in the Epi2me labs desktop application.
To check if it works, we tried 'Use Demo Data'

We had this report :

Workflow execution completed unsuccessfully!
The exit status of the task that caused the workflow execution to fail was: 134.

The full error message was:

Error executing process > 'calling_pipeline:medakaNetwork (2)'

Caused by:
  Process `calling_pipeline:medakaNetwork (2)` terminated with an error exit status (134)

Command executed:

  medaka --version
      echo r1041_e82_400bps_sup_v4.2.0
  
      echo r1041_e82_400bps_sup_v4.2.0
  
      medaka consensus align.bam ""test1.consensus_probs.hdf""         --threads 2 --regions ""NC_000962.3:999000-1999000
  "" --model r1041_e82_400bps_sup_v4.2.0

Command exit status:
  134

Command output:
  medaka 1.9.1
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0

Command error:
  Cannot import pyabpoa, some features may not be available.
  medaka 1.9.1
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0
  The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.
  .command.sh: line 8:    90 Aborted                 (core dumped) medaka consensus align.bam ""test1.consensus_probs.hdf"" --threads 2 --regions ""NC_000962.3:999000-1999000
  "" --model r1041_e82_400bps_sup_v4.2.0

Work dir:
  /home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/work/72/fb42aff10d6ba33fdc644968b2c3ff

Tip: you can replicate the issue by changing to the process work dir and entering the command `bash .command.run`




I tried this : https://github.com/tensorflow/tensorflow/issues/24548
(mehdirezaie commented on Mar 27, 2020)

But we still have the same error.
What could we do to solve this ?",Lenfera,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/19
I_kwDOFIO7Dc5yZjqV,Workflow execution completed unsuccessfully! Error executing process > 'calling_pipeline:medakaNetwork (2)',CLOSED,2023-09-29T13:45:12Z,2024-05-10T13:00:03Z,2024-05-10T13:00:03Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

v0.4.0

### Workflow Execution

EPI2ME Desktop application

### EPI2ME Version

v5.1.2

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

Hello Epi2me labs team,

We tried to run the workflow 'bacterial genome' within an oracle VM with Ubuntu 22.04.3 LTS 64-bit in the Epi2me labs desktop application.
To check if it works, we tried 'Use Demo Data'

We had this report :

Workflow execution completed unsuccessfully!
The exit status of the task that caused the workflow execution to fail was: 134.

The full error message was:

Error executing process > 'calling_pipeline:medakaNetwork (2)'

Caused by:
Process calling_pipeline:medakaNetwork (2) terminated with an error exit status (134)

Command executed:

medaka --version
echo r1041_e82_400bps_sup_v4.2.0

  echo r1041_e82_400bps_sup_v4.2.0

  medaka consensus align.bam ""test1.consensus_probs.hdf""         --threads 2 --regions ""NC_000962.3:999000-1999000

"" --model r1041_e82_400bps_sup_v4.2.0

Command exit status:
134

Command output:
medaka 1.9.1
r1041_e82_400bps_sup_v4.2.0
r1041_e82_400bps_sup_v4.2.0

Command error:
Cannot import pyabpoa, some features may not be available.
medaka 1.9.1
r1041_e82_400bps_sup_v4.2.0
r1041_e82_400bps_sup_v4.2.0
The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.
.command.sh: line 8: 90 Aborted (core dumped) medaka consensus align.bam ""test1.consensus_probs.hdf"" --threads 2 --regions ""NC_000962.3:999000-1999000
"" --model r1041_e82_400bps_sup_v4.2.0

Work dir:
/home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/work/72/fb42aff10d6ba33fdc644968b2c3ff

Tip: you can replicate the issue by changing to the process work dir and entering the command bash .command.run

I tried this : https://github.com/tensorflow/tensorflow/issues/24548
(mehdirezaie commented on Mar 27, 2020)

But we still have the same error.
What could we do to solve this ?

### Relevant log output

```shell
N E X T F L O W  ~  version 23.04.2
Launching `/home/sprzto/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/main.nf` [wizardly_rosalind] DSL2 - revision: 3d3482183d
||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.4.0
--------------------------------------------------------------------------------
Core Nextflow options
  runName                 : wizardly_rosalind
  containerEngine         : docker
  launchDir               : /home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK
  workDir                 : /home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/work
  projectDir              : /home/sprzto/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes
  userName                : sprzto
  profile                 : standard
  configFiles             : /home/sprzto/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/nextflow.config, /home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/demo.config
Input Options
  fastq                   : /home/sprzto/epi2melabs/demo/epi2me-labs/wf-bacterial-genomes/v0.4.0/wf-bacterial-genomes-demo/isolates_fastq
  reference_based_assembly: true
  reference               : /home/sprzto/epi2melabs/demo/epi2me-labs/wf-bacterial-genomes/v0.4.0/wf-bacterial-genomes-demo/ref/ref.fasta.gz
Sample Options
  sample_sheet            : /home/sprzto/epi2melabs/demo/epi2me-labs/wf-bacterial-genomes/v0.4.0/wf-bacterial-genomes-demo/isolates_sample_sheet.csv
Output Options
  out_dir                 : /home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/output
Isolate options
  isolates                : true
Advanced Options
  threads                 : 3
!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:
* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x
--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v0.4.0.
--------------------------------------------------------------------------------
Checking fastq input.
Reference based assembly selected.
[43/4d29ed] Submitted process > calling_pipeline:getParams
[07/745d32] Submitted process > calling_pipeline:lookup_medaka_consensus_model (1)
[81/f490ce] Submitted process > calling_pipeline:prokkaVersion
[f7/f99deb] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
[f0/d397d2] Submitted process > validate_sample_sheet
[7e/199664] Submitted process > calling_pipeline:medakaVersion
[4d/6d385d] Submitted process > calling_pipeline:mlstVersion
[5b/d1a558] Submitted process > calling_pipeline:getVersions
[b5/a842fb] Submitted process > fastcat (1)
[57/e3b0f0] Submitted process > fastcat (2)
[60/d2ab0f] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (1)
[4b/2f1d69] Submitted process > calling_pipeline:alignReads (1)
[cb/50852a] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (2)
[16/ac5817] Submitted process > calling_pipeline:alignReads (2)
[02/076eb3] Submitted process > calling_pipeline:readStats (1)
[e2/641ec3] Submitted process > calling_pipeline:splitRegions (1)
[12/82ae58] Submitted process > calling_pipeline:coverStats (1)
[ec/986fa7] Submitted process > calling_pipeline:splitRegions (2)
[df/f0eb5c] Submitted process > calling_pipeline:readStats (2)
[85/5daa57] Submitted process > calling_pipeline:coverStats (2)
[72/fb42af] Submitted process > calling_pipeline:medakaNetwork (2)
[33/178ff6] Submitted process > calling_pipeline:medakaNetwork (3)
[8f/6feb25] Submitted process > calling_pipeline:medakaVariantHdf (4)
ERROR ~ Error executing process > 'calling_pipeline:medakaNetwork (2)'
Caused by:
  Process `calling_pipeline:medakaNetwork (2)` terminated with an error exit status (134)
Command executed:
  medaka --version
      echo r1041_e82_400bps_sup_v4.2.0
  
      echo r1041_e82_400bps_sup_v4.2.0
  
      medaka consensus align.bam ""test1.consensus_probs.hdf""         --threads 2 --regions ""NC_000962.3:999000-1999000
  "" --model r1041_e82_400bps_sup_v4.2.0
Command exit status:
  134
Command output:
  medaka 1.9.1
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0
Command error:
  Cannot import pyabpoa, some features may not be available.
  medaka 1.9.1
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0
  The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.
  .command.sh: line 8:    90 Aborted                 (core dumped) medaka consensus align.bam ""test1.consensus_probs.hdf"" --threads 2 --regions ""NC_000962.3:999000-1999000
  "" --model r1041_e82_400bps_sup_v4.2.0
Work dir:
  /home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/work/72/fb42aff10d6ba33fdc644968b2c3ff
Tip: you can replicate the issue by changing to the process work dir and entering the command `bash .command.run`
 -- Check '/home/sprzto/epi2melabs/instances/wf-bacterial-genomes_01HBGHJP7JQSFKRC9P6QD7WTJK/nextflow.log' file for details
WARN: Killing running tasks (2)
```


### Application activity log entry

_No response_",Lenfera,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/20
I_kwDOFIO7Dc51JrEw,failing the test_data run,CLOSED,2023-10-27T12:53:55Z,2023-10-27T13:50:37Z,2023-10-27T13:25:54Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

v0.4.0 70714be

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

# running in the repo folder

nextflow run epi2me-labs/wf-bacterial-genomes --fastq ./test_data/fastq --isolates --reference_based_assembly --reference ./test_data/ref/reference.subseq.fa.gz --sample_sheet ./test_data/isolates_sample_sheet.csv --out_dir test_run



### Workflow Execution - CLI Execution Profile

standard (default)

### What happened?

N E X T F L O W  ~  version 23.04.3
NOTE: Your local project version looks outdated - a different revision is available in the remote repository [70714be9ef]
Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [amazing_carson] DSL2 - revision: d3fdcc0dd3 [master]

ERROR ~ ERROR: Validation of pipeline parameters failed!

 -- Check '.nextflow.log' file for details
ERROR ~ * --basecaller_cfg: dna_r10.4.1_e8.2_400bps_sup@v4.2.0 is not a valid enum value (dna_r10.4.1_e8.2_400bps_sup@v4.2.0)

 -- Check '.nextflow.log' file for details


WARN: Found unexpected parameters:
* --mlst_version: 2.23.0
* --flye_opts: null
* --process_label: wfbacterialgenomes
- Ignore this warning: params.schema_ignore_params = ""mlst_version,flye_opts,process_label"" 


### Relevant log output

```shell
Oct-27 14:51:07.248 [main] DEBUG nextflow.cli.Launcher - $> nextflow run epi2me-labs/wf-bacterial-genomes --fastq ./test_data/fastq --isolates --reference_based_assembly --reference ./test_data/ref/reference.subseq.fa.gz --sample_sheet ./test_data/isolates_sample_sheet.csv --out_dir test_run
Oct-27 14:51:07.326 [main] INFO  nextflow.cli.CmdRun - N E X T F L O W  ~  version 23.04.3
Oct-27 14:51:07.346 [main] DEBUG nextflow.plugin.PluginsFacade - Setting up plugin manager > mode=prod; embedded=false; plugins-dir=/home/luna.kuleuven.be/u0002316/.nextflow/plugins; core-plugins: nf-amazon@1.16.2,nf-azure@1.0.1,nf-codecommit@0.1.4,nf-console@1.0.5,nf-ga4gh@1.0.5,nf-google@1.7.3,nf-tower@1.5.12,nf-wave@0.8.4
Oct-27 14:51:07.357 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Enabled plugins: []
Oct-27 14:51:07.358 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Disabled plugins: []
Oct-27 14:51:07.361 [main] INFO  org.pf4j.DefaultPluginManager - PF4J version 3.4.1 in 'deployment' mode
Oct-27 14:51:07.372 [main] INFO  org.pf4j.AbstractPluginManager - No plugins
Oct-27 14:51:07.387 [main] DEBUG nextflow.scm.ProviderConfig - Using SCM config path: /home/luna.kuleuven.be/u0002316/.nextflow/scm
Oct-27 14:51:08.272 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/.git/config; branch: master; remote: origin; url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Oct-27 14:51:08.301 [main] DEBUG nextflow.scm.RepositoryFactory - Found Git repository result: [RepositoryFactory]
Oct-27 14:51:08.310 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/.git/config; branch: master; remote: origin; url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Oct-27 14:51:09.089 [main] INFO  nextflow.scm.AssetManager - NOTE: Your local project version looks outdated - a different revision is available in the remote repository [70714be9ef]
Oct-27 14:51:09.101 [main] DEBUG nextflow.config.ConfigBuilder - Found config base: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Oct-27 14:51:09.101 [main] DEBUG nextflow.config.ConfigBuilder - Found config local: /opt/biotools/wf-bacterial-genomes/nextflow.config
Oct-27 14:51:09.102 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Oct-27 14:51:09.102 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /opt/biotools/wf-bacterial-genomes/nextflow.config
Oct-27 14:51:09.112 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Oct-27 14:51:09.246 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Oct-27 14:51:09.452 [main] DEBUG nextflow.cli.CmdRun - Applied DSL=2 from script declararion
Oct-27 14:51:09.454 [main] INFO  nextflow.cli.CmdRun - Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [amazing_carson] DSL2 - revision: d3fdcc0dd3 [master]
Oct-27 14:51:09.455 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins default=[]
Oct-27 14:51:09.455 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins resolved requirement=[]
Oct-27 14:51:09.459 [main] DEBUG nextflow.secret.LocalSecretsProvider - Secrets store: /home/luna.kuleuven.be/u0002316/.nextflow/secrets/store.json
Oct-27 14:51:09.461 [main] DEBUG nextflow.secret.SecretsLoader - Discovered secrets providers: [nextflow.secret.LocalSecretsProvider@7b18658a] - activable => nextflow.secret.LocalSecretsProvider@7b18658a
Oct-27 14:51:09.519 [main] DEBUG nextflow.Session - Session UUID: 2ae9cbec-7d65-46a6-be31-81f97206f53d
Oct-27 14:51:09.519 [main] DEBUG nextflow.Session - Run name: amazing_carson
Oct-27 14:51:09.519 [main] DEBUG nextflow.Session - Executor pool size: 88
Oct-27 14:51:09.530 [main] DEBUG nextflow.util.ThreadPoolBuilder - Creating thread pool 'FileTransfer' minSize=10; maxSize=264; workQueue=LinkedBlockingQueue[10000]; allowCoreThreadTimeout=false
Oct-27 14:51:09.557 [main] DEBUG nextflow.cli.CmdRun - 
  Version: 23.04.3 build 5875
  Created: 11-08-2023 18:37 UTC (20:37 CEST)
  System: Linux 5.4.0-165-generic
  Runtime: Groovy 3.0.16 on OpenJDK 64-Bit Server VM 17.0.8.1+1-Ubuntu-0ubuntu120.04
  Encoding: UTF-8 (UTF-8)
  Process: 283897@gbw-s-pacbio01 [10.118.132.7]
  CPUs: 88 - Mem: 503.8 GB (2.9 GB) - Swap: 0 (0)
Oct-27 14:51:09.572 [main] DEBUG nextflow.Session - Work-dir: /opt/biotools/wf-bacterial-genomes/work [ext2/ext3]
Oct-27 14:51:09.585 [main] DEBUG nextflow.executor.ExecutorFactory - Extension executors providers=[]
Oct-27 14:51:09.593 [main] DEBUG nextflow.Session - Observer factory: DefaultObserverFactory
Oct-27 14:51:09.659 [main] DEBUG nextflow.cache.CacheFactory - Using Nextflow cache factory: nextflow.cache.DefaultCacheFactory
Oct-27 14:51:09.668 [main] DEBUG nextflow.util.CustomThreadPool - Creating default thread pool > poolSize: 89; maxThreads: 1000
Oct-27 14:51:09.724 [main] DEBUG nextflow.Session - Session start
Oct-27 14:51:09.727 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow started -- trace file: /opt/biotools/wf-bacterial-genomes/test_run/execution/trace.txt
Oct-27 14:51:09.734 [main] DEBUG nextflow.Session - Using default localLib path: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Oct-27 14:51:09.736 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Oct-27 14:51:09.737 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib/nfcore_external_java_deps.jar
Oct-27 14:51:11.702 [main] DEBUG nextflow.script.ScriptRunner - > Launching execution
Oct-27 14:51:12.396 [main] ERROR nextflow.Nextflow - ERROR: Validation of pipeline parameters failed!
Oct-27 14:51:12.408 [main] ERROR nextflow.Nextflow - * --basecaller_cfg: dna_r10.4.1_e8.2_400bps_sup@v4.2.0 is not a valid enum value (dna_r10.4.1_e8.2_400bps_sup@v4.2.0)
Oct-27 14:51:12.412 [main] WARN  nextflow.Nextflow - Found unexpected parameters:
* --mlst_version: 2.23.0
* --flye_opts: null
* --process_label: wfbacterialgenomes
Oct-27 14:51:12.413 [main] INFO  nextflow.Nextflow - - Ignore this warning: params.schema_ignore_params = ""mlst_version,flye_opts,process_label""
```


### Application activity log entry

_No response_",splaisan,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/21
I_kwDOFIO7Dc51KHA1,failing to run test_data,CLOSED,2023-10-27T13:53:38Z,2023-10-27T14:11:32Z,2023-10-27T14:05:52Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

 v0.4.0-g70714be

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

nextflow run epi2me-labs/wf-bacterial-genomes --fastq ./test_data/fastq --isolates --reference_based_assembly --reference ./test_data/ref/reference.subseq.fa.gz --sample_sheet ./test_data/isolates_sample_sheet.csv --out_dir test_run


### Workflow Execution - CLI Execution Profile

None

### What happened?

```
N E X T F L O W  ~  version 23.04.3
Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [loving_pasteur] DSL2 - revision: 70714be9ef [master]

||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.4.0-g70714be
--------------------------------------------------------------------------------
Core Nextflow options
  revision                : master
  runName                 : loving_pasteur
  containerEngine         : docker
  launchDir               : /opt/biotools/wf-bacterial-genomes
  workDir                 : /opt/biotools/wf-bacterial-genomes/work
  projectDir              : /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes
  userName                : u0002316
  profile                 : standard
  configFiles             : /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config, /opt/biotools/wf-bacterial-genomes/nextflow.config

Input Options
  fastq                   : ./test_data/fastq
  reference_based_assembly: true
  reference               : ./test_data/ref/reference.subseq.fa.gz

Sample Options
  sample_sheet            : ./test_data/isolates_sample_sheet.csv

Output Options
  out_dir                 : test_run

Isolate options
  isolates                : true

Advanced Options
  threads                 : 3

!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:

* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x


--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v0.4.0-g70714be.
--------------------------------------------------------------------------------
Checking fastq input.
executor >  local (12)
executor >  local (12)
[5d/540bd7] process > validate_sample_sheet                                [100%] 1 of 1 âœ”
[2c/b38300] process > fastcat (2)                                          [100%] 2 of 2 âœ”
[15/a5e619] process > calling_pipeline:alignReads (1)                      [  0%] 0 of 1
[-        ] process > calling_pipeline:readStats                           -
[-        ] process > calling_pipeline:coverStats                          -
[-        ] process > calling_pipeline:splitRegions                        -
[31/2f8008] process > calling_pipeline:lookup_medaka_consensus_model (1)   [100%] 1 of 1 âœ”
[a2/68e1ce] process > calling_pipeline:lookup_medaka_variant_model (1)     [100%] 1 of 1 âœ”
[-        ] process > calling_pipeline:medakaNetwork                       -
[-        ] process > calling_pipeline:medakaConsensus                     -
[-        ] process > calling_pipeline:medakaVariantHdf                    -
[-        ] process > calling_pipeline:medakaVariant                       -
[-        ] process > calling_pipeline:runProkka                           -
[-        ] process > calling_pipeline:run_isolates:mlstSearch             -
[-        ] process > calling_pipeline:run_isolates:getPointfinderSpecies  -
[-        ] process > calling_pipeline:run_isolates:resfinder              -
[-        ] process > calling_pipeline:run_isolates:processResfinder       -
[0a/1f72d5] process > calling_pipeline:prokkaVersion                       [100%] 1 of 1 âœ”
[0e/870bc7] process > calling_pipeline:medakaVersion                       [100%] 1 of 1 âœ”
[6d/253928] process > calling_pipeline:mlstVersion                         [100%] 1 of 1 âœ”
[23/bd2054] process > calling_pipeline:getVersions                         [100%] 1 of 1 âœ”
[ab/321412] process > calling_pipeline:getParams                           [100%] 1 of 1 âœ”
[-        ] process > calling_pipeline:makeReport                          -
[-        ] process > calling_pipeline:makePerSampleReports                -
[92/60cdb1] process > calling_pipeline:collectFastqIngressResultsInDir (1) [  0%] 0 of 3
[-        ] process > output                                               -
Reference based assembly selected.
ERROR ~ Cannot invoke method resolve() on null object

 -- Check script '/home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf' at line: 586 or see '.nextflow.log' file for more details
ERROR ~ Error executing process > 'calling_pipeline:alignReads (3)'

Caused by:
  Not a valid path value type: org.codehaus.groovy.runtime.NullObject (null)


Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`

 -- Check '.nextflow.log' file for details
```

### Relevant log output

```shell
Oct-27 15:51:09.716 [main] DEBUG nextflow.cli.Launcher - $> nextflow run epi2me-labs/wf-bacterial-genomes --fastq ./test_data/fastq --isolates --reference_based_assembly --reference ./test_data/ref/reference.subseq.fa.gz --sample_sheet ./test_data/isolates_sample_sheet.csv --out_dir test_run
Oct-27 15:51:09.782 [main] INFO  nextflow.cli.CmdRun - N E X T F L O W  ~  version 23.04.3
Oct-27 15:51:09.807 [main] DEBUG nextflow.plugin.PluginsFacade - Setting up plugin manager > mode=prod; embedded=false; plugins-dir=/home/luna.kuleuven.be/u0002316/.nextflow/plugins; core-plugins: nf-amazon@1.16.2,nf-azure@1.0.1,nf-codecommit@0.1.4,nf-console@1.0.5,nf-ga4gh@1.0.5,nf-google@1.7.3,nf-tower@1.5.12,nf-wave@0.8.4
Oct-27 15:51:09.817 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Enabled plugins: []
Oct-27 15:51:09.818 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Disabled plugins: []
Oct-27 15:51:09.821 [main] INFO  org.pf4j.DefaultPluginManager - PF4J version 3.4.1 in 'deployment' mode
Oct-27 15:51:09.831 [main] INFO  org.pf4j.AbstractPluginManager - No plugins
Oct-27 15:51:09.845 [main] DEBUG nextflow.scm.ProviderConfig - Using SCM config path: /home/luna.kuleuven.be/u0002316/.nextflow/scm
Oct-27 15:51:10.824 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/.git/config; branch: master; remote: origin; url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Oct-27 15:51:10.850 [main] DEBUG nextflow.scm.RepositoryFactory - Found Git repository result: [RepositoryFactory]
Oct-27 15:51:10.859 [main] DEBUG nextflow.scm.AssetManager - Git config: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/.git/config; branch: master; remote: origin; url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Oct-27 15:51:11.654 [main] DEBUG nextflow.config.ConfigBuilder - Found config base: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Oct-27 15:51:11.654 [main] DEBUG nextflow.config.ConfigBuilder - Found config local: /opt/biotools/wf-bacterial-genomes/nextflow.config
Oct-27 15:51:11.655 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Oct-27 15:51:11.655 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /opt/biotools/wf-bacterial-genomes/nextflow.config
Oct-27 15:51:11.666 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Oct-27 15:51:11.833 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Oct-27 15:51:11.867 [main] DEBUG nextflow.cli.CmdRun - Applied DSL=2 from script declararion
Oct-27 15:51:11.867 [main] INFO  nextflow.cli.CmdRun - Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [loving_pasteur] DSL2 - revision: 70714be9ef [master]
Oct-27 15:51:11.867 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins default=[]
Oct-27 15:51:11.868 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins resolved requirement=[]
Oct-27 15:51:11.870 [main] DEBUG nextflow.secret.LocalSecretsProvider - Secrets store: /home/luna.kuleuven.be/u0002316/.nextflow/secrets/store.json
Oct-27 15:51:11.874 [main] DEBUG nextflow.secret.SecretsLoader - Discovered secrets providers: [nextflow.secret.LocalSecretsProvider@6df4af5] - activable => nextflow.secret.LocalSecretsProvider@6df4af5
Oct-27 15:51:11.934 [main] DEBUG nextflow.Session - Session UUID: c5808332-0855-466a-aced-f2c7f191bfab
Oct-27 15:51:11.934 [main] DEBUG nextflow.Session - Run name: loving_pasteur
Oct-27 15:51:11.934 [main] DEBUG nextflow.Session - Executor pool size: 88
Oct-27 15:51:11.946 [main] DEBUG nextflow.util.ThreadPoolBuilder - Creating thread pool 'FileTransfer' minSize=10; maxSize=264; workQueue=LinkedBlockingQueue[10000]; allowCoreThreadTimeout=false
Oct-27 15:51:11.971 [main] DEBUG nextflow.cli.CmdRun - 
  Version: 23.04.3 build 5875
  Created: 11-08-2023 18:37 UTC (20:37 CEST)
  System: Linux 5.4.0-165-generic
  Runtime: Groovy 3.0.16 on OpenJDK 64-Bit Server VM 17.0.8.1+1-Ubuntu-0ubuntu120.04
  Encoding: UTF-8 (UTF-8)
  Process: 343660@gbw-s-pacbio01 [10.118.132.7]
  CPUs: 88 - Mem: 503.8 GB (3.6 GB) - Swap: 0 (0)
Oct-27 15:51:11.990 [main] DEBUG nextflow.Session - Work-dir: /opt/biotools/wf-bacterial-genomes/work [ext2/ext3]
Oct-27 15:51:12.004 [main] DEBUG nextflow.executor.ExecutorFactory - Extension executors providers=[]
Oct-27 15:51:12.014 [main] DEBUG nextflow.Session - Observer factory: DefaultObserverFactory
Oct-27 15:51:12.116 [main] DEBUG nextflow.cache.CacheFactory - Using Nextflow cache factory: nextflow.cache.DefaultCacheFactory
Oct-27 15:51:12.131 [main] DEBUG nextflow.util.CustomThreadPool - Creating default thread pool > poolSize: 89; maxThreads: 1000
Oct-27 15:51:12.201 [main] DEBUG nextflow.Session - Session start
Oct-27 15:51:12.206 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow started -- trace file: /opt/biotools/wf-bacterial-genomes/test_run/execution/trace.txt
Oct-27 15:51:12.214 [main] DEBUG nextflow.Session - Using default localLib path: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Oct-27 15:51:12.217 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Oct-27 15:51:12.218 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib/nfcore_external_java_deps.jar
Oct-27 15:51:14.386 [main] DEBUG nextflow.script.ScriptRunner - > Launching execution
Oct-27 15:51:14.970 [main] INFO  nextflow.Nextflow - 
||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v0.4.0-g70714be
--------------------------------------------------------------------------------
Core Nextflow options
  revision                : master
  runName                 : loving_pasteur
  containerEngine         : docker
  launchDir               : /opt/biotools/wf-bacterial-genomes
  workDir                 : /opt/biotools/wf-bacterial-genomes/work
  projectDir              : /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes
  userName                : u0002316
  profile                 : standard
  configFiles             : /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config, /opt/biotools/wf-bacterial-genomes/nextflow.config

Input Options
  fastq                   : ./test_data/fastq
  reference_based_assembly: true
  reference               : ./test_data/ref/reference.subseq.fa.gz

Sample Options
  sample_sheet            : ./test_data/isolates_sample_sheet.csv

Output Options
  out_dir                 : test_run

Isolate options
  isolates                : true

Advanced Options
  threads                 : 3

!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:

* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x


--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v0.4.0-g70714be.
--------------------------------------------------------------------------------
Oct-27 15:51:15.219 [main] INFO  nextflow.Nextflow - Checking fastq input.
Oct-27 15:51:15.274 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wf_common` matches labels `fastq_ingress,wf_common` for process with name validate_sample_sheet
Oct-27 15:51:15.292 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.292 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.299 [main] DEBUG nextflow.executor.Executor - [warm up] executor > local
Oct-27 15:51:15.305 [main] DEBUG n.processor.LocalPollingMonitor - Creating local task monitor for executor 'local' > cpus=4; memory=8 GB; capacity=88; pollInterval=100ms; dumpInterval=5m
Oct-27 15:51:15.481 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wf_common` matches labels `fastq_ingress,wf_common` for process with name fastcat
Oct-27 15:51:15.483 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.483 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.517 [main] INFO  nextflow.Nextflow - Reference based assembly selected.
Oct-27 15:51:15.534 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:alignReads
Oct-27 15:51:15.535 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.535 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.541 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:readStats
Oct-27 15:51:15.542 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.542 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.548 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:coverStats
Oct-27 15:51:15.549 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.550 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.554 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:splitRegions
Oct-27 15:51:15.554 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.554 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.563 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:lookup_medaka_consensus_model
Oct-27 15:51:15.564 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.565 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.570 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:lookup_medaka_variant_model
Oct-27 15:51:15.571 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.571 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.583 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaNetwork
Oct-27 15:51:15.584 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.584 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.596 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaConsensus
Oct-27 15:51:15.597 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.597 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.602 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaVariantHdf
Oct-27 15:51:15.602 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.602 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.611 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaVariant
Oct-27 15:51:15.611 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.611 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.617 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:prokka` matches labels `prokka` for process with name calling_pipeline:runProkka
Oct-27 15:51:15.618 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.618 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.622 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:mlst` matches labels `mlst` for process with name calling_pipeline:run_isolates:mlstSearch
Oct-27 15:51:15.623 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.623 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.629 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:run_isolates:getPointfinderSpecies
Oct-27 15:51:15.630 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.630 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.640 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:amr` matches labels `amr` for process with name calling_pipeline:run_isolates:resfinder
Oct-27 15:51:15.641 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.641 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.648 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:run_isolates:processResfinder
Oct-27 15:51:15.649 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.649 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.654 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:prokka` matches labels `prokka` for process with name calling_pipeline:prokkaVersion
Oct-27 15:51:15.655 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.655 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.657 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:medaka` matches labels `medaka` for process with name calling_pipeline:medakaVersion
Oct-27 15:51:15.658 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.658 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.660 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:mlst` matches labels `mlst` for process with name calling_pipeline:mlstVersion
Oct-27 15:51:15.661 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.661 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.663 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:getVersions
Oct-27 15:51:15.664 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.664 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.666 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:getParams
Oct-27 15:51:15.667 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.667 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.696 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:makeReport
Oct-27 15:51:15.697 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.697 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.717 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:makePerSampleReports
Oct-27 15:51:15.718 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.718 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.722 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name calling_pipeline:collectFastqIngressResultsInDir
Oct-27 15:51:15.723 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.723 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.732 [main] DEBUG nextflow.script.ProcessConfig - Config settings `withLabel:wfbacterialgenomes` matches labels `wfbacterialgenomes` for process with name output
Oct-27 15:51:15.733 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: null
Oct-27 15:51:15.733 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'local'
Oct-27 15:51:15.735 [main] DEBUG nextflow.Session - Workflow process names [dsl2]: resfinder, deNovo, calling_pipeline:getParams, calling_pipeline:mlstVersion, medakaVersion, alignReads, output, medakaVariant, medakaNetwork, collectFastqIngressResultsInDir, makeReport, calling_pipeline:collectFastqIngressResultsInDir, getVersions, calling_pipeline:coverStats, calling_pipeline:readStats, calling_pipeline:run_isolates:processResfinder, calling_pipeline:medakaConsensus, getPointfinderSpecies, calling_pipeline:getVersions, coverStats, calling_pipeline:runProkka, fastcat, mlstVersion, calling_pipeline:medakaVariantHdf, getParams, calling_pipeline:prokkaVersion, calling_pipeline:alignReads, medakaConsensus, validate_sample_sheet, medakaVariantHdf, calling_pipeline:run_isolates:resfinder, calling_pipeline:lookup_medaka_variant_model, calling_pipeline:medakaVersion, calling_pipeline:run_isolates:mlstSearch, readStats, runProkka, calling_pipeline:run_isolates:getPointfinderSpecies, lookup_medaka_variant_model, prokkaVersion, calling_pipeline:makePerSampleReports, lookup_medaka_consensus_model, calling_pipeline:medakaNetwork, splitRegions, calling_pipeline:makeReport, calling_pipeline:splitRegions, calling_pipeline:lookup_medaka_consensus_model, move_or_compress, processResfinder, mlstSearch, calling_pipeline:medakaVariant, makePerSampleReports
Oct-27 15:51:15.738 [main] DEBUG nextflow.Session - Igniting dataflow network (32)
Oct-27 15:51:15.738 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > validate_sample_sheet
Oct-27 15:51:15.744 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > fastcat
Oct-27 15:51:15.745 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:alignReads
Oct-27 15:51:15.745 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:readStats
Oct-27 15:51:15.746 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:coverStats
Oct-27 15:51:15.746 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:splitRegions
Oct-27 15:51:15.746 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:lookup_medaka_consensus_model
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:lookup_medaka_variant_model
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaNetwork
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaConsensus
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaVariantHdf
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaVariant
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:runProkka
Oct-27 15:51:15.747 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:run_isolates:mlstSearch
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:run_isolates:getPointfinderSpecies
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:run_isolates:resfinder
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:run_isolates:processResfinder
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:prokkaVersion
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:medakaVersion
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:mlstVersion
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:getVersions
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:getParams
Oct-27 15:51:15.748 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:makeReport
Oct-27 15:51:15.749 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:makePerSampleReports
Oct-27 15:51:15.749 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > calling_pipeline:collectFastqIngressResultsInDir
Oct-27 15:51:15.749 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > output
Oct-27 15:51:15.749 [main] DEBUG nextflow.script.ScriptRunner - > Awaiting termination 
Oct-27 15:51:15.749 [main] DEBUG nextflow.Session - Session await
Oct-27 15:51:15.819 [Actor Thread 79] DEBUG nextflow.util.CacheHelper - Hash asset file sha-256: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/bin/workflow-glue
Oct-27 15:51:15.842 [Actor Thread 83] DEBUG nextflow.util.CacheHelper - Hash asset file sha-256: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/data/medaka_models.tsv
Oct-27 15:51:15.888 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:15.890 [Task submitter] INFO  nextflow.Session - [ab/321412] Submitted process > calling_pipeline:getParams
Oct-27 15:51:15.897 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:15.897 [Task submitter] INFO  nextflow.Session - [0a/1f72d5] Submitted process > calling_pipeline:prokkaVersion
Oct-27 15:51:15.903 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:15.903 [Task submitter] INFO  nextflow.Session - [5d/540bd7] Submitted process > validate_sample_sheet
Oct-27 15:51:15.908 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:15.909 [Task submitter] INFO  nextflow.Session - [a2/68e1ce] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
Oct-27 15:51:17.007 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 4; name: calling_pipeline:getParams; status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/ab/321412e265e6dfb37d01304470c290]
Oct-27 15:51:17.024 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:17.025 [Task submitter] INFO  nextflow.Session - [31/2f8008] Submitted process > calling_pipeline:lookup_medaka_consensus_model (1)
Oct-27 15:51:17.202 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 3; name: calling_pipeline:prokkaVersion; status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/0a/1f72d5cc3ca0a225bf2f31177070a2]
Oct-27 15:51:17.215 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:17.216 [Task submitter] INFO  nextflow.Session - [0e/870bc7] Submitted process > calling_pipeline:medakaVersion
Oct-27 15:51:18.675 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 6; name: calling_pipeline:medakaVersion; status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/0e/870bc758a3f3d7274743e8c5b0b5b6]
Oct-27 15:51:18.696 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:18.697 [Task submitter] INFO  nextflow.Session - [6d/253928] Submitted process > calling_pipeline:mlstVersion
Oct-27 15:51:28.452 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 7; name: calling_pipeline:mlstVersion; status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/6d/253928b88a84420488faf94a90eb04]
Oct-27 15:51:28.467 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:28.468 [Task submitter] INFO  nextflow.Session - [23/bd2054] Submitted process > calling_pipeline:getVersions
Oct-27 15:51:29.872 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 8; name: calling_pipeline:getVersions; status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/23/bd20541e8f1e6cd8dc2b2692f735fb]
Oct-27 15:51:37.325 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 2; name: calling_pipeline:lookup_medaka_variant_model (1); status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/a2/68e1ce0dce4d13116f48a9767b7922]
Oct-27 15:51:37.414 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 1; name: validate_sample_sheet; status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/5d/540bd7d4b8ae2fcbbe11d0ba96e070]
Oct-27 15:51:37.449 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:37.450 [Task submitter] INFO  nextflow.Session - [20/335c74] Submitted process > fastcat (1)
Oct-27 15:51:38.045 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 5; name: calling_pipeline:lookup_medaka_consensus_model (1); status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/31/2f80086f6d1e7368581b0ce3c0450b]
Oct-27 15:51:38.584 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 9; name: fastcat (1); status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/20/335c74a6db68e30f7fb05dc84d8bbd]
Oct-27 15:51:38.592 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:38.593 [Task submitter] INFO  nextflow.Session - [2c/b38300] Submitted process > fastcat (2)
Oct-27 15:51:39.553 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[id: 10; name: fastcat (2); status: COMPLETED; exit: 0; error: -; workDir: /opt/biotools/wf-bacterial-genomes/work/2c/b38300b76f95b72dd8b5351ace4841]
Oct-27 15:51:39.561 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:39.562 [Task submitter] INFO  nextflow.Session - [15/a5e619] Submitted process > calling_pipeline:alignReads (1)
Oct-27 15:51:39.561 [Actor Thread 84] ERROR nextflow.extension.OperatorImpl - @unknown
java.lang.NullPointerException: Cannot invoke method resolve() on null object
	at org.codehaus.groovy.runtime.NullObject.invokeMethod(NullObject.java:91)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:44)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)
	at org.codehaus.groovy.runtime.callsite.NullCallSite.call(NullCallSite.java:34)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)
	at org.codehaus.groovy.runtime.callsite.PojoMetaClassSite.call(PojoMetaClassSite.java:49)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:139)
	at Script_96e8d947$_runScript_closure22$_closure54$_closure74.doCall(Script_96e8d947:586)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:107)
	at org.codehaus.groovy.runtime.metaclass.TransformMetaMethod.invoke(TransformMetaMethod.java:55)
	at groovy.lang.MetaClassImpl$2.invoke(MetaClassImpl.java:1298)
	at org.codehaus.groovy.runtime.metaclass.TransformMetaMethod.doMethodInvoke(TransformMetaMethod.java:62)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:274)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1035)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:38)
	at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCall(CallSiteArray.java:47)
	at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.call(PogoMetaClassSite.java:53)
	at org.codehaus.groovy.runtime.callsite.AbstractCallSite.call(AbstractCallSite.java:139)
	at nextflow.extension.MapOp$_apply_closure1.doCall(MapOp.groovy:56)
	at jdk.internal.reflect.GeneratedMethodAccessor226.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:107)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:323)
	at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:274)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1035)
	at groovy.lang.Closure.call(Closure.java:412)
	at groovyx.gpars.dataflow.operator.DataflowOperatorActor.startTask(DataflowOperatorActor.java:120)
	at groovyx.gpars.dataflow.operator.DataflowOperatorActor.onMessage(DataflowOperatorActor.java:108)
	at groovyx.gpars.actor.impl.SDAClosure$1.call(SDAClosure.java:43)
	at groovyx.gpars.actor.AbstractLoopingActor.runEnhancedWithoutRepliesOnMessages(AbstractLoopingActor.java:293)
	at groovyx.gpars.actor.AbstractLoopingActor.access$400(AbstractLoopingActor.java:30)
	at groovyx.gpars.actor.AbstractLoopingActor$1.handleMessage(AbstractLoopingActor.java:93)
	at groovyx.gpars.util.AsyncMessagingCore.run(AsyncMessagingCore.java:132)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Oct-27 15:51:39.565 [Actor Thread 81] DEBUG nextflow.processor.TaskProcessor - Handling unexpected condition for
  task: name=calling_pipeline:alignReads (3); work-dir=null
  error [nextflow.exception.ProcessUnrecoverableException]: Not a valid path value type: org.codehaus.groovy.runtime.NullObject (null)
Oct-27 15:51:39.566 [Actor Thread 85] DEBUG nextflow.util.CacheHelper - Hash asset file sha-256: /home/luna.kuleuven.be/u0002316/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/data/OPTIONAL_FILE
Oct-27 15:51:39.567 [Task submitter] DEBUG n.executor.local.LocalTaskHandler - Launch cmd line: /bin/bash -ue .command.run
Oct-27 15:51:39.571 [Task submitter] INFO  nextflow.Session - [92/60cdb1] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (1)
Oct-27 15:51:39.572 [Actor Thread 84] DEBUG nextflow.Session - Session aborted -- Cause: Cannot invoke method resolve() on null object
Oct-27 15:51:39.576 [Actor Thread 81] ERROR nextflow.processor.TaskProcessor - Error executing process > 'calling_pipeline:alignReads (3)'

Caused by:
  Not a valid path value type: org.codehaus.groovy.runtime.NullObject (null)


Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`
Oct-27 15:51:39.578 [Actor Thread 87] DEBUG nextflow.processor.TaskProcessor - Handling unexpected condition for
  task: name=calling_pipeline:alignReads (4); work-dir=null
  error [nextflow.exception.ProcessUnrecoverableException]: Not a valid path value type: org.codehaus.groovy.runtime.NullObject (null)
Oct-27 15:51:39.580 [Actor Thread 79] DEBUG nextflow.processor.TaskProcessor - Handling unexpected condition for
  task: name=calling_pipeline:alignReads; work-dir=null
  error [java.lang.InterruptedException]: java.lang.InterruptedException
Oct-27 15:51:39.588 [Actor Thread 89] DEBUG nextflow.sort.BigSort - Sort completed -- entries: 2; slices: 1; internal sort time: 0.021 s; external sort time: 0.001 s; total time: 0.022 s
Oct-27 15:51:39.600 [Actor Thread 84] DEBUG nextflow.Session - The following nodes are still active:
[process] calling_pipeline:readStats
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:coverStats
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:splitRegions
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:medakaNetwork
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:medakaConsensus
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:medakaVariantHdf
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:medakaVariant
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:runProkka
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:run_isolates:mlstSearch
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:run_isolates:getPointfinderSpecies
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:run_isolates:resfinder
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (value) bound ; channel: resfinder_threshold
  port 2: (value) bound ; channel: resfinder_coverage
  port 3: (cntrl) -     ; channel: $

[process] calling_pipeline:run_isolates:processResfinder
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: -
  port 1: (cntrl) -     ; channel: $

[process] calling_pipeline:makeReport
  status=ACTIVE
  port 0: (value) bound ; channel: versions/*
  port 1: (value) bound ; channel: params.json
  port 2: (value) OPEN  ; channel: variants/*
  port 3: (value) bound ; channel: sample_ids
  port 4: (value) OPEN  ; channel: prokka/*
  port 5: (queue) OPEN  ; channel: per_read_stats
  port 6: (value) OPEN  ; channel: fwd/*
  port 7: (value) OPEN  ; channel: rev/*
  port 8: (value) OPEN  ; channel: total_depth/*
  port 9: (value) bound ; channel: flye_stats/*
  port 10: (value) OPEN  ; channel: resfinder/*
  port 11: (value) OPEN  ; channel: mlst/*
  port 12: (cntrl) -     ; channel: $

[process] calling_pipeline:makePerSampleReports
  status=ACTIVE
  port 0: (value) bound ; channel: versions.txt
  port 1: (value) bound ; channel: params.json
  port 2: (queue) OPEN  ; channel: -
  port 3: (cntrl) -     ; channel: $

[process] output
  status=ACTIVE
  port 0: (queue) OPEN  ; channel: fname
  port 1: (cntrl) -     ; channel: $

Oct-27 15:51:39.609 [Actor Thread 89] DEBUG nextflow.file.FileCollector - Saved collect-files list to: /opt/biotools/wf-bacterial-genomes/work/collect-file/d35a16d66436dbbd20902f201ee6075d
Oct-27 15:51:39.617 [Actor Thread 89] DEBUG nextflow.file.FileCollector - Deleting file collector temp dir: /tmp/nxf-662444189237774055
Oct-27 15:51:39.686 [main] DEBUG nextflow.Session - Session await > all processes finished
Oct-27 15:51:39.686 [main] DEBUG nextflow.Session - Session await > all barriers passed
Oct-27 15:51:39.727 [main] WARN  n.processor.TaskPollingMonitor - Killing running tasks (2)
Oct-27 15:51:39.744 [main] DEBUG nextflow.trace.WorkflowStatsObserver - Workflow completed > WorkflowStats[succeededCount=10; failedCount=0; ignoredCount=0; cachedCount=0; pendingCount=4; submittedCount=2; runningCount=-2; retriesCount=0; abortedCount=2; succeedDuration=1m 4s; failedDuration=0ms; cachedDuration=0ms;loadCpus=-4; loadMemory=0; peakRunning=4; peakCpus=4; peakMemory=0; ]
Oct-27 15:51:39.745 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow completed -- saving trace file
Oct-27 15:51:39.747 [main] DEBUG nextflow.trace.ReportObserver - Workflow completed -- rendering execution report
Oct-27 15:51:39.825 [main] DEBUG nextflow.trace.ReportObserver - Execution report summary data:
  [{""cpuUsage"":{""mean"":38.4,""min"":38.4,""q1"":38.4,""q2"":38.4,""q3"":38.4,""max"":38.4,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""process"":""getParams"",""mem"":null,""memUsage"":null,""timeUsage"":null,""vmem"":null,""reads"":{""mean"":65567,""min"":65567,""q1"":65567,""q2"":65567,""q3"":65567,""max"":65567,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""cpu"":{""mean"":38.4,""min"":38.4,""q1"":38.4,""q2"":38.4,""q3"":38.4,""max"":38.4,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""time"":{""mean"":6,""min"":6,""q1"":6,""q2"":6,""q3"":6,""max"":6,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""},""writes"":{""mean"":1902,""min"":1902,""q1"":1902,""q2"":1902,""q3"":1902,""max"":1902,""minLabel"":""calling_pipeline:getParams"",""maxLabel"":""calling_pipeline:getParams"",""q1Label"":""calling_pipeline:getParams"",""q2Label"":""calling_pipeline:getParams"",""q3Label"":""calling_pipeline:getParams""}},{""cpuUsage"":{""mean"":85.2,""min"":85.2,""q1"":85.2,""q2"":85.2,""q3"":85.2,""max"":85.2,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""process"":""prokkaVersion"",""mem"":{""mean"":14585856,""min"":14585856,""q1"":14585856,""q2"":14585856,""q3"":14585856,""max"":14585856,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":25321472,""min"":25321472,""q1"":25321472,""q2"":25321472,""q3"":25321472,""max"":25321472,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""reads"":{""mean"":1560531,""min"":1560531,""q1"":1560531,""q2"":1560531,""q3"":1560531,""max"":1560531,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""cpu"":{""mean"":85.2,""min"":85.2,""q1"":85.2,""q2"":85.2,""q3"":85.2,""max"":85.2,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""time"":{""mean"":165,""min"":165,""q1"":165,""q2"":165,""q3"":165,""max"":165,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""},""writes"":{""mean"":239,""min"":239,""q1"":239,""q2"":239,""q3"":239,""max"":239,""minLabel"":""calling_pipeline:prokkaVersion"",""maxLabel"":""calling_pipeline:prokkaVersion"",""q1Label"":""calling_pipeline:prokkaVersion"",""q2Label"":""calling_pipeline:prokkaVersion"",""q3Label"":""calling_pipeline:prokkaVersion""}},{""cpuUsage"":{""mean"":909.9,""min"":909.9,""q1"":909.9,""q2"":909.9,""q3"":909.9,""max"":909.9,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""},""process"":""medakaVersion"",""mem"":{""mean"":13774848,""min"":13774848,""q1"":13774848,""q2"":13774848,""q3"":13774848,""max"":13774848,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":20627456,""min"":20627456,""q1"":20627456,""q2"":20627456,""q3"":20627456,""max"":20627456,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""},""reads"":{""mean"":8475669,""min"":8475669,""q1"":8475669,""q2"":8475669,""q3"":8475669,""max"":8475669,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""},""cpu"":{""mean"":909.9,""min"":909.9,""q1"":909.9,""q2"":909.9,""q3"":909.9,""max"":909.9,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""},""time"":{""mean"":629,""min"":629,""q1"":629,""q2"":629,""q3"":629,""max"":629,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""},""writes"":{""mean"":304,""min"":304,""q1"":304,""q2"":304,""q3"":304,""max"":304,""minLabel"":""calling_pipeline:medakaVersion"",""maxLabel"":""calling_pipeline:medakaVersion"",""q1Label"":""calling_pipeline:medakaVersion"",""q2Label"":""calling_pipeline:medakaVersion"",""q3Label"":""calling_pipeline:medakaVersion""}},{""cpuUsage"":{""mean"":61.1,""min"":61.1,""q1"":61.1,""q2"":61.1,""q3"":61.1,""max"":61.1,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""},""process"":""mlstVersion"",""mem"":{""mean"":15085568,""min"":15085568,""q1"":15085568,""q2"":15085568,""q3"":15085568,""max"":15085568,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":26316800,""min"":26316800,""q1"":26316800,""q2"":26316800,""q3"":26316800,""max"":26316800,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""},""reads"":{""mean"":872236,""min"":872236,""q1"":872236,""q2"":872236,""q3"":872236,""max"":872236,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""},""cpu"":{""mean"":61.1,""min"":61.1,""q1"":61.1,""q2"":61.1,""q3"":61.1,""max"":61.1,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""},""time"":{""mean"":166,""min"":166,""q1"":166,""q2"":166,""q3"":166,""max"":166,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""},""writes"":{""mean"":265,""min"":265,""q1"":265,""q2"":265,""q3"":265,""max"":265,""minLabel"":""calling_pipeline:mlstVersion"",""maxLabel"":""calling_pipeline:mlstVersion"",""q1Label"":""calling_pipeline:mlstVersion"",""q2Label"":""calling_pipeline:mlstVersion"",""q3Label"":""calling_pipeline:mlstVersion""}},{""cpuUsage"":{""mean"":87.7,""min"":87.7,""q1"":87.7,""q2"":87.7,""q3"":87.7,""max"":87.7,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""},""process"":""getVersions"",""mem"":{""mean"":2834432,""min"":2834432,""q1"":2834432,""q2"":2834432,""q3"":2834432,""max"":2834432,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":3989504,""min"":3989504,""q1"":3989504,""q2"":3989504,""q3"":3989504,""max"":3989504,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""},""reads"":{""mean"":3791217,""min"":3791217,""q1"":3791217,""q2"":3791217,""q3"":3791217,""max"":3791217,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""},""cpu"":{""mean"":87.7,""min"":87.7,""q1"":87.7,""q2"":87.7,""q3"":87.7,""max"":87.7,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""},""time"":{""mean"":621,""min"":621,""q1"":621,""q2"":621,""q3"":621,""max"":621,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""},""writes"":{""mean"":1644274,""min"":1644274,""q1"":1644274,""q2"":1644274,""q3"":1644274,""max"":1644274,""minLabel"":""calling_pipeline:getVersions"",""maxLabel"":""calling_pipeline:getVersions"",""q1Label"":""calling_pipeline:getVersions"",""q2Label"":""calling_pipeline:getVersions"",""q3Label"":""calling_pipeline:getVersions""}},{""cpuUsage"":{""mean"":121.6,""min"":121.6,""q1"":121.6,""q2"":121.6,""q3"":121.6,""max"":121.6,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""process"":""lookup_medaka_variant_model"",""mem"":{""mean"":439128064,""min"":439128064,""q1"":439128064,""q2"":439128064,""q3"":439128064,""max"":439128064,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":12535533568,""min"":12535533568,""q1"":12535533568,""q2"":12535533568,""q3"":12535533568,""max"":12535533568,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""reads"":{""mean"":49275441,""min"":49275441,""q1"":49275441,""q2"":49275441,""q3"":49275441,""max"":49275441,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""cpu"":{""mean"":121.6,""min"":121.6,""q1"":121.6,""q2"":121.6,""q3"":121.6,""max"":121.6,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""time"":{""mean"":20162,""min"":20162,""q1"":20162,""q2"":20162,""q3"":20162,""max"":20162,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""},""writes"":{""mean"":28213285,""min"":28213285,""q1"":28213285,""q2"":28213285,""q3"":28213285,""max"":28213285,""minLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_variant_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_variant_model (1)""}},{""cpuUsage"":{""mean"":128.6,""min"":128.6,""q1"":128.6,""q2"":128.6,""q3"":128.6,""max"":128.6,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""},""process"":""validate_sample_sheet"",""mem"":{""mean"":441389056,""min"":441389056,""q1"":441389056,""q2"":441389056,""q3"":441389056,""max"":441389056,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":12534493184,""min"":12534493184,""q1"":12534493184,""q2"":12534493184,""q3"":12534493184,""max"":12534493184,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""},""reads"":{""mean"":49458298,""min"":49458298,""q1"":49458298,""q2"":49458298,""q3"":49458298,""max"":49458298,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""},""cpu"":{""mean"":128.6,""min"":128.6,""q1"":128.6,""q2"":128.6,""q3"":128.6,""max"":128.6,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""},""time"":{""mean"":20346,""min"":20346,""q1"":20346,""q2"":20346,""q3"":20346,""max"":20346,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""},""writes"":{""mean"":28295652,""min"":28295652,""q1"":28295652,""q2"":28295652,""q3"":28295652,""max"":28295652,""minLabel"":""validate_sample_sheet"",""maxLabel"":""validate_sample_sheet"",""q1Label"":""validate_sample_sheet"",""q2Label"":""validate_sample_sheet"",""q3Label"":""validate_sample_sheet""}},{""cpuUsage"":{""mean"":126.4,""min"":126.4,""q1"":126.4,""q2"":126.4,""q3"":126.4,""max"":126.4,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""process"":""lookup_medaka_consensus_model"",""mem"":{""mean"":439443456,""min"":439443456,""q1"":439443456,""q2"":439443456,""q3"":439443456,""max"":439443456,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":12535533568,""min"":12535533568,""q1"":12535533568,""q2"":12535533568,""q3"":12535533568,""max"":12535533568,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""reads"":{""mean"":49275435,""min"":49275435,""q1"":49275435,""q2"":49275435,""q3"":49275435,""max"":49275435,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""cpu"":{""mean"":126.4,""min"":126.4,""q1"":126.4,""q2"":126.4,""q3"":126.4,""max"":126.4,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""time"":{""mean"":20099,""min"":20099,""q1"":20099,""q2"":20099,""q3"":20099,""max"":20099,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""},""writes"":{""mean"":28213269,""min"":28213269,""q1"":28213269,""q2"":28213269,""q3"":28213269,""max"":28213269,""minLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""maxLabel"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q1Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q2Label"":""calling_pipeline:lookup_medaka_consensus_model (1)"",""q3Label"":""calling_pipeline:lookup_medaka_consensus_model (1)""}},{""cpuUsage"":{""mean"":88.55,""min"":74.6,""q1"":81.58,""q2"":88.55,""q3"":95.53,""max"":102.5,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (2)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""process"":""fastcat"",""mem"":{""mean"":6760448,""min"":3182592,""q1"":4971520,""q2"":6760448,""q3"":8549376,""max"":10338304,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (2)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""memUsage"":null,""timeUsage"":null,""vmem"":{""mean"":196689920,""min"":7979008,""q1"":102334464,""q2"":196689920,""q3"":291045376,""max"":385400832,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (2)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""reads"":{""mean"":13098218.5,""min"":10982098,""q1"":12040158.25,""q2"":13098218.5,""q3"":14156278.75,""max"":15214339,""minLabel"":""fastcat (2)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (2)"",""q2Label"":""fastcat (2)"",""q3Label"":""fastcat (2)""},""cpu"":{""mean"":265.65,""min"":223.8,""q1"":244.73,""q2"":265.65,""q3"":286.58,""max"":307.5,""minLabel"":""fastcat (1)"",""maxLabel"":""fastcat (2)"",""q1Label"":""fastcat (1)"",""q2Label"":""fastcat (1)"",""q3Label"":""fastcat (1)""},""time"":{""mean"":265,""min"":193,""q1"":229,""q2"":265,""q3"":301,""max"":337,""minLabel"":""fastcat (2)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (2)"",""q2Label"":""fastcat (2)"",""q3Label"":""fastcat (2)""},""writes"":{""mean"":12937781,""min"":10824139,""q1"":11880960,""q2"":12937781,""q3"":13994602,""max"":15051423,""minLabel"":""fastcat (2)"",""maxLabel"":""fastcat (1)"",""q1Label"":""fastcat (2)"",""q2Label"":""fastcat (2)"",""q3Label"":""fastcat (2)""}},{""cpuUsage"":null,""process"":""alignReads"",""mem"":null,""memUsage"":null,""timeUsage"":null,""vmem"":null,""reads"":null,""cpu"":null,""time"":null,""writes"":null},{""cpuUsage"":null,""process"":""collectFastqIngressResultsInDir"",""mem"":null,""memUsage"":null,""timeUsage"":null,""vmem"":null,""reads"":null,""cpu"":null,""time"":null,""writes"":null}]
Oct-27 15:51:40.370 [main] DEBUG nextflow.trace.TimelineObserver - Workflow completed -- rendering execution timeline
Oct-27 15:51:40.432 [main] DEBUG nextflow.cache.CacheDB - Closing CacheDB done
Oct-27 15:51:40.452 [main] DEBUG nextflow.script.ScriptRunner - > Execution complete -- Goodbye
```


### Application activity log entry

_No response_",splaisan,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/22
I_kwDOFIO7Dc51KSnL,bakta instead of prokka,CLOSED,2023-10-27T14:17:33Z,2024-05-30T10:52:51Z,2024-05-30T10:52:51Z,"### Is your feature related to a problem?

I recently [read from the Prokka author himself Torsten Seemann](https://twitter.com/torstenseemann/status/1565471892840259585) that [Bakta](https://github.com/oschwengers/bakta) would now be a better option to annotate bacterial genome as it is better maintained.


### Describe the solution you'd like

Would it be possible to add bakta to the pipeline and make this an option for those who want to stick to prokka?


### Describe alternatives you've considered

none for bacterial genomes but for bacterio-phages there is also [pharokka](https://github.com/gbouras13/pharokka) which makes an incredible good job.

### Additional context

thanks in advance for considering this (these)",splaisan,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/23
I_kwDOFIO7Dc58wTps,--profile standard should have one dash,CLOSED,2024-01-22T04:14:55Z,2024-05-30T11:11:51Z,2024-05-30T11:11:50Z,"### Ask away!

I think in the test example the argument should be -profile instead of --profile",osilander,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/24
I_kwDOFIO7Dc5_22rG,Dorado models v4.3.0,CLOSED,2024-02-20T19:07:49Z,2024-07-30T13:04:47Z,2024-07-30T13:04:46Z,"### Ask away!

Hi,

Could you update the workflow to integrate the new Medaka configuration for Dorado basecalling dna_r10.4.1_e8.2_400bps@v4.3.0 ?

Thank you.",lagphase,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/25
I_kwDOFIO7Dc5_9pyO,Does the pipeline have internal error correction?,CLOSED,2024-02-21T14:17:26Z,2024-03-11T17:10:45Z,2024-03-11T17:10:44Z,"Does the pipeline have internal error correction prior to assembly? If not, what error correction method/pipeline is recommended? Thanks.",weishwu,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/26
I_kwDOFIO7Dc6BqDQi,Information about circular contigs,CLOSED,2024-03-08T05:00:33Z,2024-11-14T05:40:15Z,2024-11-14T05:40:15Z,"### Is your feature related to a problem?

The wf-bacterial-genomes workflow enables the reconstruction of circular genomes and plasmids. In the report, the number of circular contigs is indicated. However, it is difficult to determine which contigs are circular and which are linear. It seems that this information is not provided in the report, nor in the .gbk or fasta.gz files. It is necessary to delve into the 'work' directory and locate the flye_stats.tsv file to determine whether a contig is circular or not. 

### Describe the solution you'd like

Would it be possible to indicate in the report which contigs are circular? 

### Describe alternatives you've considered

Furthermore, could this information be included in the .gbk file? Currently, all circular contigs are identified as linear in the GBK file.

Thank you in advance for your help.

Sincerly

Etienne

",frumencelab,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/27
I_kwDOFIO7Dc6Br4pl,Demo data Error: [E::fai_build3_core] Failed to open the file ref.fasta.gz,OPEN,2024-03-08T10:44:58Z,2024-03-08T12:50:45Z,,"### Ask away!

Hi,

I tried running demo data as given in your ReadMe but got below error
`[E::fai_build3_core] Failed to open the file ref.fasta.gz`",kiranpatil222,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/28
I_kwDOFIO7Dc6B1fSA,Error with Demo data,OPEN,2024-03-11T05:48:56Z,2024-03-12T05:34:07Z,,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

v1.2.0

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

```
nextflow run epi2me-labs/wf-bacterial-genomes \
    --fastq wf-bacterial-genomes-demo/isolates_fastq \
    --isolates \
    --sample_sheet wf-bacterial-genomes-demo/isolates_sample_sheet.csv \
    -profile standard
```

### Workflow Execution - CLI Execution Profile

standard (default)

### What happened?

```
ERROR ~ Error executing process > 'calling_pipeline:deNovo (2)'

Caused by:
  Process `calling_pipeline:deNovo (2)` terminated with an error exit status (1)

Command executed:

  COV_FAIL=0
  FLYE_EXIT_CODE=0
  flye    --nano-hq reads.fastq.gz --out-dir output --threads ""3"" ||     FLYE_EXIT_CODE=$?

  if [[ $FLYE_EXIT_CODE -eq 0 ]]; then
      mv output/assembly.fasta ""./test1.draft_assembly.fasta""
      mv output/assembly_info.txt ""./test1_flye_stats.tsv""
      bgzip ""test1.draft_assembly.fasta""
  else
      # flye failed --> check the log to check why
      edge_cov=$(
          grep -oP 'Mean edge coverage: \K\d+' output/flye.log             || echo 5
      )
      ovlp_cov=$(
          grep -oP 'Overlap-based coverage: \K\d+' output/flye.log             || echo 5
      )
      if [[
          $edge_cov -lt 5 ||
          $ovlp_cov -lt 5
      ]]; then
          echo -n ""Caught Flye failure due to low coverage (either mean edge cov. or ""
          echo ""overlap-based cov. were below 5)"".
          COV_FAIL=1
      elif grep -q ""No disjointigs were assembled"" output/flye.log; then
          echo -n ""Caught Flye failure due to disjointig assembly.""
          COV_FAIL=2
      else
          # exit a subshell with error so that the process fails
          ( exit $FLYE_EXIT_CODE )
      fi
  fi

Command exit status:
  1

Command output:
  (empty)

Command error:
  [2024-03-08 11:32:29] INFO: Extending reads
  [2024-03-08 11:33:26] INFO: Overlap-based coverage: 32
  [2024-03-08 11:33:26] INFO: Median overlap divergence: 0.0971861
  0% 80% 90% 100%
  [2024-03-08 11:34:32] INFO: Assembled 2 disjointigs
  [2024-03-08 11:34:32] INFO: Generating sequence
  0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
  [2024-03-08 11:34:35] INFO: Filtering contained disjointigs
  0% 50% 100%
  [2024-03-08 11:34:37] INFO: Contained seqs: 0
  [2024-03-08 11:34:37] INFO: >>>STAGE: consensus
  [2024-03-08 11:34:37] INFO: Running Minimap2
  [2024-03-08 11:35:11] INFO: Computing consensus
  Process SyncManager-1:
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap
      self.run()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/process.py"", line 108, in run
      self._target(*self._args, **self._kwargs)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 608, in _run_server
      server = cls._Server(registry, address, authkey, serializer)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 154, in __init__
      self.listener = Listener(address=address, backlog=16)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 448, in __init__
      self._listener = SocketListener(address, family, backlog)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 591, in __init__
      self._socket.bind(address)
  OSError: AF_UNIX path too long
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/bin/flye"", line 33, in <module>
      sys.exit(load_entry_point('flye==2.9.3', 'console_scripts', 'flye')())
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/main.py"", line 756, in main
      _run(args)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/main.py"", line 493, in _run
      jobs[i].run()
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/main.py"", line 284, in run
      consensus_fasta = cons.get_consensus(out_alignment, self.in_contigs,
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/polishing/consensus.py"", line 71, in get_consensus
      mp_manager = multiprocessing.Manager()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/context.py"", line 57, in Manager
      m.start()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 583, in start
      self._address = reader.recv()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 250, in recv
      buf = self._recv_bytes()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 414, in _recv_bytes
      buf = self._recv(4)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 383, in _recv
      raise EOFError
  EOFError
```

### Relevant log output

```shell
ERROR ~ Error executing process > 'calling_pipeline:deNovo (2)'

Caused by:
  Process `calling_pipeline:deNovo (2)` terminated with an error exit status (1)

Command executed:

  COV_FAIL=0
  FLYE_EXIT_CODE=0
  flye    --nano-hq reads.fastq.gz --out-dir output --threads ""3"" ||     FLYE_EXIT_CODE=$?

  if [[ $FLYE_EXIT_CODE -eq 0 ]]; then
      mv output/assembly.fasta ""./test1.draft_assembly.fasta""
      mv output/assembly_info.txt ""./test1_flye_stats.tsv""
      bgzip ""test1.draft_assembly.fasta""
  else
      # flye failed --> check the log to check why
      edge_cov=$(
          grep -oP 'Mean edge coverage: \K\d+' output/flye.log             || echo 5
      )
      ovlp_cov=$(
          grep -oP 'Overlap-based coverage: \K\d+' output/flye.log             || echo 5
      )
      if [[
          $edge_cov -lt 5 ||
          $ovlp_cov -lt 5
      ]]; then
          echo -n ""Caught Flye failure due to low coverage (either mean edge cov. or ""
          echo ""overlap-based cov. were below 5)"".
          COV_FAIL=1
      elif grep -q ""No disjointigs were assembled"" output/flye.log; then
          echo -n ""Caught Flye failure due to disjointig assembly.""
          COV_FAIL=2
      else
          # exit a subshell with error so that the process fails
          ( exit $FLYE_EXIT_CODE )
      fi
  fi

Command exit status:
  1

Command output:
  (empty)

Command error:
  [2024-03-08 11:32:29] INFO: Extending reads
  [2024-03-08 11:33:26] INFO: Overlap-based coverage: 32
  [2024-03-08 11:33:26] INFO: Median overlap divergence: 0.0971861
  0% 80% 90% 100%
  [2024-03-08 11:34:32] INFO: Assembled 2 disjointigs
  [2024-03-08 11:34:32] INFO: Generating sequence
  0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%
  [2024-03-08 11:34:35] INFO: Filtering contained disjointigs
  0% 50% 100%
  [2024-03-08 11:34:37] INFO: Contained seqs: 0
  [2024-03-08 11:34:37] INFO: >>>STAGE: consensus
  [2024-03-08 11:34:37] INFO: Running Minimap2
  [2024-03-08 11:35:11] INFO: Computing consensus
  Process SyncManager-1:
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap
      self.run()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/process.py"", line 108, in run
      self._target(*self._args, **self._kwargs)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 608, in _run_server
      server = cls._Server(registry, address, authkey, serializer)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 154, in __init__
      self.listener = Listener(address=address, backlog=16)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 448, in __init__
      self._listener = SocketListener(address, family, backlog)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 591, in __init__
      self._socket.bind(address)
  OSError: AF_UNIX path too long
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/bin/flye"", line 33, in <module>
      sys.exit(load_entry_point('flye==2.9.3', 'console_scripts', 'flye')())
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/main.py"", line 756, in main
      _run(args)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/main.py"", line 493, in _run
      jobs[i].run()
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/main.py"", line 284, in run
      consensus_fasta = cons.get_consensus(out_alignment, self.in_contigs,
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/polishing/consensus.py"", line 71, in get_consensus
      mp_manager = multiprocessing.Manager()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/context.py"", line 57, in Manager
      m.start()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 583, in start
      self._address = reader.recv()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 250, in recv
      buf = self._recv_bytes()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 414, in _recv_bytes
      buf = self._recv(4)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 383, in _recv
      raise EOFError
  EOFError
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

no

### Other demo data information

_No response_",kiranpatil222,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/29
I_kwDOFIO7Dc6CJLF-,Add option for bandage plots in report,OPEN,2024-03-13T08:54:56Z,2024-05-21T08:35:16Z,,"### Is your feature related to a problem?

Not related to a problem

### Describe the solution you'd like

An option (or default) to output the gfa file and a Bandage plot of the gfa file for a quick visual summary of the assemblies (perhaps in the full summary report). Alternatively, just the Bandage plot.

### Describe alternatives you've considered

I've tried copying and renaming the assembly_graph.gfa output files from flye into the output dir, as it's possible to then make the Bandage plot. The .gfa files in the work directory aren't named by barcode so it's not possible to take them from there.

### Additional context

_No response_",osilander,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/30
I_kwDOFIO7Dc6EYFki,Sample name not included in consensus fasta file,OPEN,2024-04-02T16:10:16Z,2024-04-03T09:36:06Z,,"### Operating System

Other Linux (please specify below)

### Other Linux

Redhat

### Workflow Version

v1.1.1

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

nextflow run epi2me-labs/wf-bacterial-genomes --fastq data/fastq_pass/ --reference_based_assembly --reference GCF_900205735.1_N16961_v2_genomic.fna --sample_sheet samplesheet_epi2me.csv -profile singularity -c cambridge.config -resume

### Workflow Execution - CLI Execution Profile

singularity

### What happened?

The pipeline ran successfully but the consensus fasta files created by the pipeline have the reference name and basecaller model in the fasta header instead of the sample id. This is not particularly helpful for building alignments to create phylogenetic trees.

### Relevant log output

```shell
grep "">"" CTMA_1402.medaka.fasta

>NZ_LT906615.1 basecall_model=dna_r10.4.1_e8.2_400bps_sup@v4.2.0
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

other (please describe below)

### Other demo data information

```shell
Not tested
```
",avantonder,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/31
I_kwDOFIO7Dc6EYWBz,Output  improvements,CLOSED,2024-04-02T16:42:11Z,2024-04-02T18:05:03Z,2024-04-02T18:05:03Z,"### Is your feature related to a problem?

Show more options for workflow rather than run in nextflow command line. At the moment you can only select input and reference file

Output is limited in Report

Zoom buttons do not work correctly in report charts

### Describe the solution you'd like

It would be useful to see an output of the lengths of each contig from Flye assemblies

MLST output - it would be useful to obtain an output if MLST analysis was successful or failed as no output is not very informative

### Describe alternatives you've considered

Run Brakta instead of Prokka

### Additional context

_No response_",fraser-combe,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/32
I_kwDOFIO7Dc6G6whR,Failed to pull singularity iamge,OPEN,2024-04-25T13:10:29Z,2024-04-26T09:10:14Z,,"### Operating System

Other Linux (please specify below)

### Other Linux

RedHat Enterprise 8.3

### Workflow Version

Latest

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

ERROR ~ Error executing process > 'calling_pipeline:getParams'

Caused by:
  Failed to pull singularity image
  command: singularity pull  --name ontresearch-wf-bacterial-genomes-shaa4cda1aeeda01242c54f4af03419e9623397dc0c.img.pulling.1714050463708 docker://ontresearch/wf-bacterial-genomes:shaa4cda1aeeda01242c54f4af03419e9623397dc0c > /dev/null
  status : 255
  message:
    WARNING: SINGULARITY_CACHEDIR and APPTAINER_CACHEDIR have different values, using the latter
    INFO:    Converting OCI blobs to SIF format
    INFO:    Starting build...
    Getting image source signatures
    Copying blob sha256:f9432144bf11a2ae3ffb7360b4e32f7b18c75c7c8c125274ec3cf49d0de28e24
    Copying blob sha256:edaedc954fb53f42a7754a6e2d1b57f091bc9b11063bc445c2e325ea448f8f68
    Copying blob sha256:e8b63ef4ca0ca489bb848ecf9f4db232528d222a2c0bb2a599b312ce6b5b551a
    Copying blob sha256:88397e6fd840152eca6643094559385065a6ab98a1c3c7e75eb676b9d97aad97
    Copying blob sha256:0456c71d8011447360dd461b49b6a1a4cb36edf8f7250817e99ceeb0d353f06b
    Copying blob sha256:38cad909cfed9fb07cc2c6612612435d52302b48ebcf94a2a4b77e02b8414142
    Copying blob sha256:cd889bc730171a0013130be60f28f869d7e7cc4d923396628660de9b67f7eec8
    Copying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1
    Copying blob sha256:2042b0824681af825bf6a3c7d48cf91a218427db24a26198aaa7a2e92145081d
    Copying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1
    Copying blob sha256:973691ee7cdac427dd9005f99675e8e77fb7feda0e94e11626a95e46e5d2973e
    Copying blob sha256:4a9d7e589e1778374b42cbdb32d978af00de957133897cdc1171659808fb6f7f
    Copying blob sha256:3fc3949421420f916ca77ede3295a7f762d493b84b0bc2e4a2212f8573b76e3c
    Copying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1
    Copying blob sha256:6de220563c5cae03fae0f6b66c78c7e1091b6d2a91b0d199ec712fd216399bc6
    Copying blob sha256:7f4c1460c3a6a5c0a29dd740394343f9e4dc867062c299febc85015eb3cf8606
    Copying blob sha256:8e13bd657a727a4c167b0e27b05aa3ee5dab63fda01f8b2643400f4c10053dd8
    Copying blob sha256:d8af254b567f3b0a15ba645cf6dee25e3223b4a610fe237a3ad31a4dedf679fc
    Copying blob sha256:786231868c62c95197f37ffa3046b4f0ccffc11bd49a4f206a032c700eb18ef6
    Copying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1
    Copying config sha256:755ac014996a07c3bf534514c4b2e0f7c0b97a0985a8be3111b8d76f22d8c30c
    Writing manifest to image destination
    FATAL:   While making image from oci registry: error fetching image to cache: while building SIF from layers: conveyor failed to get: while getting config: no descriptor found for reference ""0afe778952f0d96b21c5b5e679d0e4e7fa471a27de53375f550c47e3cfc5996f""

### Relevant log output

```shell
As above
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

no

### Other demo data information

_No response_",adbeggs,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/33
I_kwDOFIO7Dc6JUHD_,Basecalling options not included in basecaller.cfg.,CLOSED,2024-05-18T01:34:12Z,2024-07-30T12:55:49Z,2024-07-30T12:55:49Z,"### Ask away!

The latest version uses dna_r10.4.1_e8.2_400bps_sup@v4.3.0 for basecalling with MinKNOW. 
However, there are currently no available options to select. The latest version available is v4.2.0. What should be done in this case?
![image](https://github.com/epi2me-labs/wf-bacterial-genomes/assets/128474904/43941096-928d-4270-bbfe-b075e1e6c7bc)
",YoungMunLEE,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/34
I_kwDOFIO7Dc6LV5mR,Collapse contig coverage graphs,OPEN,2024-06-06T09:19:00Z,2024-06-06T09:47:08Z,,"### Is your feature related to a problem?

No problem, but if you are doing shotgun metagenomics for e.g. human stool samples, there are a lot of contigs!!

### Describe the solution you'd like

 The ability to collapse them or have the output on a separate page or chooseable like the Pavian sample level output would be very useful

### Describe alternatives you've considered

Doing my own pipeline

### Additional context

_No response_",adbeggs,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/35
I_kwDOFIO7Dc6M4vpZ,wf-bacterial-genomes stopped with error,CLOSED,2024-06-20T07:04:26Z,2024-08-23T14:45:15Z,2024-08-23T14:45:14Z,"### Operating System

Windows 10

### Other Linux

-

### Workflow Version

v1.2.0

### Workflow Execution

EPI2ME Desktop application

### EPI2ME Version

_No response_

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

[EPI2ME_issue_export.tar.gz](https://github.com/user-attachments/files/15910056/EPI2ME_issue_export.tar.gz)
The wf-bacterial-genomes stopped with error. The attached file is generated after clicking ""report issue"" in the desktop application.

### Relevant log output

```shell
N E X T F L O W  ~  version 23.04.2
Launching `/mnt/c/Users/lisun/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/main.nf` [Cheese-iso-001-genome] DSL2 - revision: 67ff77f941
WARN: NEXTFLOW RECURSION IS A PREVIEW FEATURE - SYNTAX AND FUNCTIONALITY CAN CHANGE IN FUTURE RELEASES

[0;92m||||||||||   [0m[2m_____ ____ ___ ____  __  __ _____      _       _
[0;92m||||||||||  [0m[2m| ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
[0;33m|||||       [0m[2m|  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
[0;33m|||||       [0m[2m| |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
[0;94m||||||||||  [0m[2m|_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
[0;94m||||||||||  [0m[1mwf-bacterial-genomes v1.2.0[0m
[2m--------------------------------------------------------------------------------[0m
[1mCore Nextflow options[0m
  [0;34mrunName          : [0;32mCheese-iso-001-genome[0m
  [0;34mcontainerEngine  : [0;32mdocker[0m
  [0;34mlaunchDir        : [0;32m/mnt/c/Users/lisun/epi2melabs/instances/wf-bacterial-genomes_01J0R9CF7AR99GSCPVW644T2EQ[0m
  [0;34mworkDir          : [0;32m/mnt/c/Users/lisun/epi2melabs/instances/wf-bacterial-genomes_01J0R9CF7AR99GSCPVW644T2EQ/work[0m
  [0;34mprojectDir       : [0;32m/mnt/c/Users/lisun/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes[0m
  [0;34muserName         : [0;32mepi2mewsl[0m
  [0;34mprofile          : [0;32mstandard[0m
  [0;34mconfigFiles      : [0;32m/mnt/c/Users/lisun/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/nextflow.config, /mnt/c/Users/lisun/epi2melabs/instances/wf-bacterial-genomes_01J0R9CF7AR99GSCPVW644T2EQ/local.config[0m

[1mInput Options[0m
  [0;34mfastq            : [0;32m/mnt/g/Cheese-pure-iso/Cheese-iso-001/20240612_2005_MN46760_FAY51710_ba62f739/fastq_pass[0m

[1mAdvanced Options[0m
  [0;34mflye_genome_size : [0;32m2800000[0m
  [0;34mflye_asm_coverage: [0;32m50[0m

[1mOutput Options[0m
  [0;34mout_dir          : [0;32m/mnt/c/Users/lisun/epi2melabs/instances/wf-bacterial-genomes_01J0R9CF7AR99GSCPVW644T2EQ/output[0m

[1mMiscellaneous Options[0m
  [0;34mthreads          : [0;32m6[0m

!! Only displaying parameters that differ from the pipeline defaults !!
[2m--------------------------------------------------------------------------------[0m
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:

* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x


[2m--------------------------------------------------------------------------------[0m
This is epi2me-labs/wf-bacterial-genomes v1.2.0.
[2m--------------------------------------------------------------------------------[0m
Searching input for [.fastq, .fastq.gz, .fq, .fq.gz] files.
Running Denovo assembly.
[45/a56415] Submitted process > calling_pipeline:prokkaVersion
[78/5fd76c] Submitted process > calling_pipeline:getParams
[ef/9f32b8] Submitted process > calling_pipeline:lookup_medaka_consensus_model (1)
[ad/e27640] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
[16/8541a5] Submitted process > fastcat (1)
[57/26ae79] Submitted process > calling_pipeline:medakaVersion
[bd/12b42c] Submitted process > calling_pipeline:mlstVersion
[fe/01ff37] Submitted process > calling_pipeline:getVersions
[13/ef9e13] Submitted process > calling_pipeline:amrCheckpoint (1)
[0c/555ea9] Submitted process > calling_pipeline:ingressCheckpoint (1)
[dc/ba2aed] Submitted process > calling_pipeline:perSampleReportingCheckpoint (1)
[c1/2100a1] Submitted process > calling_pipeline:variantCheckpoint (1)
[32/6ae7a1] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (1)
[cf/f0af7b] Submitted process > calling_pipeline:accumulateCheckpoints (1)
[ed/037feb] Submitted process > calling_pipeline:deNovo (1)
[08/905ab1] Submitted process > calling_pipeline:accumulateCheckpoints (2)
ERROR ~ Error executing process > 'calling_pipeline:deNovo (1)'

Caused by:
  Process `calling_pipeline:deNovo (1)` terminated with an error exit status (1)

Command executed:

  COV_FAIL=0
  FLYE_EXIT_CODE=0
  flye  --genome-size 2800000 --asm-coverage 50 --nano-hq reads.fastq.gz --out-dir output --threads ""6"" ||     FLYE_EXIT_CODE=$?
  
  if [[ $FLYE_EXIT_CODE -eq 0 ]]; then
      mv output/assembly.fasta ""./fastq_pass.draft_assembly.fasta""
      mv output/assembly_info.txt ""./fastq_pass_flye_stats.tsv""
      bgzip ""fastq_pass.draft_assembly.fasta""
  else
      # flye failed --> check the log to check why
      edge_cov=$(
          grep -oP 'Mean edge coverage: \K\d+' output/flye.log             || echo 5
      )
      ovlp_cov=$(
          grep -oP 'Overlap-based coverage: \K\d+' output/flye.log             || echo 5
      )
      if [[
          $edge_cov -lt 5 ||
          $ovlp_cov -lt 5
      ]]; then
          echo -n ""Caught Flye failure due to low coverage (either mean edge cov. or ""
          echo ""overlap-based cov. were below 5)"".
          COV_FAIL=1
      elif grep -q ""No disjointigs were assembled"" output/flye.log; then
          echo -n ""Caught Flye failure due to disjointig assembly.""
          COV_FAIL=2
      else
          # exit a subshell with error so that the process fails
          ( exit $FLYE_EXIT_CODE )
      fi
  fi

Command exit status:
  1

Command output:
  (empty)

Command error:
      ref_seq = aln_reader.get_region_sequence(ctg_region.ctg_id, ctg_region.start,
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/utils/sam_parser.py"", line 206, in get_region_sequence
      contig_str = self.ref_fasta[parsed_contig]
    File ""<string>"", line 2, in __getitem__
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 834, in _callmethod
      conn.send((self._id, methodname, args, kwds))
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 206, in send
      self._send_bytes(_ForkingPickler.dumps(obj))
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 411, in _send_bytes
      self._send(header + buf)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 368, in _send
      n = write(self._handle, buf)
  BrokenPipeError: [Errno 32] Broken pipe
  
  Process Process-11:
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/polishing/bubbles.py"", line 71, in _thread_worker
      ref_seq = aln_reader.get_region_sequence(ctg_region.ctg_id, ctg_region.start,
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/utils/sam_parser.py"", line 206, in get_region_sequence
      contig_str = self.ref_fasta[parsed_contig]
    File ""<string>"", line 2, in __getitem__
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 834, in _callmethod
      conn.send((self._id, methodname, args, kwds))
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 206, in send
      self._send_bytes(_ForkingPickler.dumps(obj))
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 411, in _send_bytes
      self._send(header + buf)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 368, in _send
      n = write(self._handle, buf)
  BrokenPipeError: [Errno 32] Broken pipe
  
  During handling of the above exception, another exception occurred:
  
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap
      self.run()
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/process.py"", line 108, in run
      self._target(*self._args, **self._kwargs)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/flye/polishing/bubbles.py"", line 108, in _thread_worker
      error_queue.put(e)
    File ""<string>"", line 2, in put
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/managers.py"", line 834, in _callmethod
      conn.send((self._id, methodname, args, kwds))
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 206, in send
      self._send_bytes(_ForkingPickler.dumps(obj))
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 411, in _send_bytes
      self._send(header + buf)
    File ""/home/epi2melabs/conda/lib/python3.8/multiprocessing/connection.py"", line 368, in _send
      n = write(self._handle, buf)
  BrokenPipeError: [Errno 32] Broken pipe

Work dir:
  /mnt/c/Users/lisun/epi2melabs/instances/wf-bacterial-genomes_01J0R9CF7AR99GSCPVW644T2EQ/work/ed/037feb94e83e8046138460d4139d33

Tip: view the complete command output by changing to the process work dir and entering the command `cat .command.out`

 -- Check '/mnt/c/Users/lisun/epi2melabs/instances/wf-bacterial-genomes_01J0R9CF7AR99GSCPVW644T2EQ/nextflow.log' file for details
WARN: Killing running tasks (1)
```


### Application activity log entry

```shell
No
```


### Were you able to successfully run the latest version of the workflow with the demo data?

yes

### Other demo data information

_No response_",liatslu,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/36
I_kwDOFIO7Dc6NdJLb,Flye circular prediction,CLOSED,2024-06-25T17:19:40Z,2024-11-14T05:39:21Z,2024-11-14T05:39:21Z,"### Is your feature related to a problem?

no

### Describe the solution you'd like

Can either the flye_stats.tsv file be saved in the output file, or the contigs be reported as circular/linear in the HTML file output.

### Describe alternatives you've considered

Manually copying file out of intermediate subdirectories.

### Additional context

_No response_",VICTO160,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/37
I_kwDOFIO7Dc6Nkz09,Script compilation error on test dataset,CLOSED,2024-06-26T12:42:31Z,2024-06-26T13:30:55Z,2024-06-26T13:30:55Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

v1.2.0

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

nextflow run epi2me-labs/wf-bacterial-genomes \
    --fastq wf-bacterial-genomes-demo/isolates_fastq \
    --isolates \
    --sample_sheet wf-bacterial-genomes-demo/isolates_sample_sheet.csv \
    -profile standard


### Workflow Execution - CLI Execution Profile

None

### What happened?

Hello, 
I tried running the test dataset before using my own data and I get the following error: 
```
 N E X T F L O W   ~  version 24.04.2

Pulling epi2me-labs/wf-bacterial-genomes ...
 downloaded from https://github.com/epi2me-labs/wf-bacterial-genomes.git
Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [hopeful_wiles] DSL2 - revision: 6af54574c3 [master]

ERROR ~ Script compilation error
- file : /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf
- cause: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^

1 error
```

I tried other workflows (like wf-metagenomes) and they work, so it does not seem related to the Nextflow installation. I also tried removing the wf with `nextflow drop` and downloading it again but the issue persists. Even trying to get the help message by running `nextflow run epi2me-labs/wf-bacterial-genomes --help` results on the same Script compilation error from above. Do you guys have any idea of what might be causing the issue? Thanks a lot for your time!
Best, 
Juan. 

### Relevant log output

```shell
Jun-26 14:26:54.503 [main] DEBUG nextflow.cli.Launcher - $> nextflow run epi2me-labs/wf-bacterial-genomes --fastq wf-bacterial-genomes-demo/isolates_fastq --isolates --sample_sheet wf-bacterial-genomes-demo
/isolates_sample_sheet.csv -profile standard
Jun-26 14:26:54.611 [main] DEBUG nextflow.cli.CmdRun - N E X T F L O W  ~  version 24.04.2
Jun-26 14:26:54.638 [main] DEBUG nextflow.plugin.PluginsFacade - Setting up plugin manager > mode=prod; embedded=false; plugins-dir=/home/bioinfoserver/.nextflow/plugins; core-plugins: nf-amazon@2.5.2,nf-az
ure@1.6.0,nf-cloudcache@0.4.1,nf-codecommit@0.2.0,nf-console@1.1.3,nf-ga4gh@1.3.0,nf-google@1.13.2,nf-tower@1.9.1,nf-wave@1.4.2
Jun-26 14:26:54.652 [main] INFO  o.pf4j.DefaultPluginStatusProvider - Enabled plugins: []
Jun-26 14:26:54.653 [main] INFO  o.pf4j.DefaultPluginStatusProvider - Disabled plugins: []
Jun-26 14:26:54.656 [main] INFO  org.pf4j.DefaultPluginManager - PF4J version 3.10.0 in 'deployment' mode
Jun-26 14:26:54.671 [main] INFO  org.pf4j.AbstractPluginManager - No plugins
Jun-26 14:26:54.688 [main] DEBUG nextflow.scm.ProviderConfig - Using SCM config path: /home/bioinfoserver/.nextflow/scm
Jun-26 14:26:54.724 [main] DEBUG nextflow.scm.RepositoryFactory - Found Git repository result: [RepositoryFactory]
Jun-26 14:26:54.736 [main] INFO  nextflow.cli.CmdRun - Pulling epi2me-labs/wf-bacterial-genomes ...
Jun-26 14:26:54.741 [main] DEBUG nextflow.scm.RepositoryProvider - Request [credentials -:-] -> https://api.github.com/repos/epi2me-labs/wf-bacterial-genomes/contents/nextflow.config
Jun-26 14:26:56.419 [main] DEBUG nextflow.scm.RepositoryProvider - Request [credentials -:-] -> https://api.github.com/repos/epi2me-labs/wf-bacterial-genomes/contents/main.nf
Jun-26 14:26:56.734 [main] DEBUG nextflow.scm.RepositoryProvider - Request [credentials -:-] -> https://api.github.com/repos/epi2me-labs/wf-bacterial-genomes
Jun-26 14:26:56.931 [main] DEBUG nextflow.scm.AssetManager - Pulling epi2me-labs/wf-bacterial-genomes -- Using remote clone url: https://github.com/epi2me-labs/wf-bacterial-genomes.git
Jun-26 14:27:06.109 [main] INFO  nextflow.cli.CmdRun -  downloaded from https://github.com/epi2me-labs/wf-bacterial-genomes.git
Jun-26 14:27:06.143 [main] DEBUG nextflow.config.ConfigBuilder - Found config base: /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Jun-26 14:27:06.145 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/nextflow.config
Jun-26 14:27:06.152 [main] DEBUG n.secret.LocalSecretsProvider - Secrets store: /home/bioinfoserver/.nextflow/secrets/store.json
Jun-26 14:27:06.156 [main] DEBUG nextflow.secret.SecretsLoader - Discovered secrets providers: [nextflow.secret.LocalSecretsProvider@578a5ce8] - activable => nextflow.secret.LocalSecretsProvider@578a5ce8
Jun-26 14:27:06.168 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Jun-26 14:27:06.404 [main] DEBUG nextflow.cli.CmdRun - Applied DSL=2 from script declaration
Jun-26 14:27:06.405 [main] DEBUG nextflow.cli.CmdRun - Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [hopeful_wiles] DSL2 - revision: 6af54574c3 [master]
Jun-26 14:27:06.407 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins default=[]
Jun-26 14:27:06.407 [main] DEBUG nextflow.plugin.PluginsFacade - Plugins resolved requirement=[]
Jun-26 14:27:06.477 [main] DEBUG nextflow.Session - Session UUID: cb1ae23f-847d-4221-90d7-8f22e4fd2928
Jun-26 14:27:06.477 [main] DEBUG nextflow.Session - Run name: hopeful_wiles
Jun-26 14:27:06.478 [main] DEBUG nextflow.Session - Executor pool size: 28
Jun-26 14:27:06.490 [main] DEBUG nextflow.file.FilePorter - File porter settings maxRetries=3; maxTransfers=50; pollTimeout=null
Jun-26 14:27:06.518 [main] DEBUG nextflow.cli.CmdRun -
  Version: 24.04.2 build 5914
  Created: 29-05-2024 06:19 UTC (08:19 CEST)
  System: Linux 4.15.0-213-generic
  Runtime: Groovy 4.0.21 on OpenJDK 64-Bit Server VM 21-internal-adhoc.conda.src
  Encoding: UTF-8 (UTF-8)
  Process: 28691@bioinfoserver [127.0.1.1]
  CPUs: 28 - Mem: 251.4 GB (192.9 GB) - Swap: 976 MB (975 MB) - Virtual threads ON
Jun-26 14:27:06.552 [main] DEBUG nextflow.Session - Work-dir: /home/bioinfoserver/projects/juan/bet/miboc/epi2me/work [ext2/ext3]
Jun-26 14:27:06.588 [main] DEBUG nextflow.executor.ExecutorFactory - Extension executors providers=[]
Jun-26 14:27:06.603 [main] DEBUG nextflow.Session - Observer factory: DefaultObserverFactory
Jun-26 14:27:06.682 [main] DEBUG nextflow.cache.CacheFactory - Using Nextflow cache factory: nextflow.cache.DefaultCacheFactory
Jun-26 14:27:06.691 [main] DEBUG nextflow.util.CustomPoolFactory - Creating virtual thread pool
Jun-26 14:27:06.761 [main] DEBUG nextflow.Session - Session start
Jun-26 14:27:06.765 [main] DEBUG nextflow.trace.TraceFileObserver - Workflow started -- trace file: /home/bioinfoserver/projects/juan/bet/miboc/epi2me/output/execution/trace.txt
Jun-26 14:27:06.770 [main] DEBUG nextflow.Session - Using default localLib path: /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Jun-26 14:27:06.774 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib
Jun-26 14:27:06.774 [main] DEBUG nextflow.Session - Adding to the classpath library: /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/lib/nfcore_external_java_deps.jar
Jun-26 14:27:07.996 [main] DEBUG nextflow.script.ScriptRunner - Parsed script files:
Jun-26 14:27:08.004 [main] ERROR nextflow.cli.Launcher - Script compilation error
- file : /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf
- cause: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^

1 error

nextflow.exception.ScriptCompilationException: Script compilation error
- file : /home/bioinfoserver/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf
- cause: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^

1 error

        at nextflow.script.ScriptParser.parse0(ScriptParser.groovy:196)
        at nextflow.script.ScriptParser.parse(ScriptParser.groovy:206)
        at nextflow.script.ScriptRunner.parseScript(ScriptRunner.groovy:229)
        at nextflow.script.ScriptRunner.execute(ScriptRunner.groovy:136)
        at nextflow.cli.CmdRun.run(CmdRun.groovy:372)
        at nextflow.cli.Launcher.run(Launcher.groovy:503)
        at nextflow.cli.Launcher.main(Launcher.groovy:657)
Caused by: org.codehaus.groovy.control.MultipleCompilationErrorsException: startup failed:
Script_e5c63c8040c5e648: 862: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^

1 error

        at org.codehaus.groovy.control.ErrorCollector.failIfErrors(ErrorCollector.java:292)
        at org.codehaus.groovy.control.CompilationUnit$IPrimaryClassNodeOperation.doPhaseOperation(CompilationUnit.java:980)
        at org.codehaus.groovy.control.CompilationUnit.processPhaseOperations(CompilationUnit.java:692)
        at org.codehaus.groovy.control.CompilationUnit.compile(CompilationUnit.java:666)
        at groovy.lang.GroovyClassLoader.doParseClass(GroovyClassLoader.java:373)
        at groovy.lang.GroovyClassLoader.lambda$parseClass$2(GroovyClassLoader.java:316)
        at org.codehaus.groovy.runtime.memoize.StampedCommonCache.compute(StampedCommonCache.java:163)
        at org.codehaus.groovy.runtime.memoize.StampedCommonCache.getAndPut(StampedCommonCache.java:154)
        at groovy.lang.GroovyClassLoader.parseClass(GroovyClassLoader.java:314)
        at groovy.lang.GroovyShell.parseClass(GroovyShell.java:572)
        at groovy.lang.GroovyShell.parse(GroovyShell.java:585)
        at groovy.lang.GroovyShell.parse(GroovyShell.java:639)
        at groovy.lang.GroovyShell.parse(GroovyShell.java:643)
        at nextflow.script.ScriptParser.parse0(ScriptParser.groovy:175)
        ... 6 common frames omitted
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

no

### Other demo data information

_No response_",jdiazsupsi,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/38
I_kwDOFIO7Dc6OZckF,Help? Error running nextflow run epi2me-labs/wf-bacterial-genomes â€“-help,CLOSED,2024-07-03T16:31:22Z,2024-07-04T10:07:45Z,2024-07-04T10:07:45Z,"### Ask away!

While trying to assist a user to run wf-bacterial-genomes on a Linux Cluster, I installed nextflow. After installation,

i tried wf-bacterial-genomes --help and got an error:


./nextflow run epi2me-labs/wf-bacterial-genomes â€“-help

 N E X T F L O W   ~  version 24.04.2

Launching `https://github.com/epi2me-labs/wf-bacterial-genomes` [focused_marconi] DSL2 - revision: 6af54574c3 [master]

ERROR ~ Script compilation error
- file : /home/xxxx/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf
- cause: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^

1 error


on .nextflow.log i got a mention to the same error


Jul-03 17:28:33.365 [main] DEBUG nextflow.script.ScriptRunner - Parsed script files:
Jul-03 17:28:33.374 [main] ERROR nextflow.cli.Launcher - Script compilation error
- file : /home/xxxx/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf
- cause: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^

1 error


Could you please provide some help on solving this?
Thanks!

",greytear,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/39
I_kwDOFIO7Dc6QutiS,Error executing process > 'calling_pipeline:medakaNetwork (1)',CLOSED,2024-07-24T17:55:45Z,2024-12-03T13:10:02Z,2024-12-03T13:10:02Z,"### Operating System

macOS

### Other Linux

_No response_

### Workflow Version

v1.2.0

### Workflow Execution

EPI2ME Desktop application

### EPI2ME Version

v5.1.14

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

standard (default)

### What happened?

Hi!!!
We are running the workflow using the desktop version (however we are also having the same error using the command line). We have several samples (files) but some of them we cannot run using the workflow. It means that with some samples (files) the workflow ran perfectly but with other samples (files) appeared the following error: 



Error executing process > 'calling_pipeline:medakaNetwork (1)'

Caused by:
  Process `calling_pipeline:medakaNetwork (1)` terminated with an error exit status (137)

Command executed:

  medaka --version
      echo r1041_e82_400bps_sup_v4.2.0
  
      echo r1041_e82_400bps_sup_v4.2.0
  
      medaka consensus align.bam ""barcode06.consensus_probs.hdf""         --threads 2 --regions ""contig_1:0-1000000
  "" --model r1041_e82_400bps_sup_v4.2.0

Command exit status:
  137

Command output:
  medaka 1.11.3
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0

Command error:
  medaka 1.11.3
  Cannot import pyabpoa, some features may not be available.
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0
  Cannot import pyabpoa, some features may not be available.
  [14:24:04 - Predict] Setting tensorflow inter/intra-op threads to 2/1.
  [14:24:04 - Predict] Processing region(s): contig_1:0-1000000
  [14:24:04 - Predict] Using model: /home/epi2melabs/conda/lib/python3.8/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.
  [14:24:04 - BAMFile] Creating pool of 16 BAM file sets.
  [14:24:04 - Predict] Processing 1 long region(s) with batching.
  [14:24:04 - MdlStrTF] Model 
  [14:24:04 - MdlStrTF] loading weights from /tmp/tmpluc93g_q/model/variables/variables (using expect partial)
  [14:24:04 - Sampler] Initializing sampler for consensus of region contig_1:0-1000000.
  [14:24:04 - PWorker] Running inference for 1.0M draft bases.
  [14:24:06 - Feature] Pileup counts do not span requested region, requested contig_1:0-1000000, received 3-999999.
  [14:24:06 - Feature] Processed contig_1:3.0-999999.0 (median depth 112.0)
  [14:24:06 - Sampler] Took 2.10s to make features.
  2024-07-24 14:24:09.796869: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:24:09.803240: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:24:09.872491: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:24:09.885988: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:24:10.262625: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  .command.sh: line 8:    98 Killed                  medaka consensus align.bam ""barcode06.consensus_probs.hdf"" --threads 2 --regions ""contig_1:0-1000000
  "" --model r1041_e82_400bps_sup_v4.2.0

Work dir:
  /Users/industria/epi2melabs/instances/wf-bacterial-genomes_01J3JHG4VTBFPSAMNT30EHY8ZZ/work/c0/d8d6038c8162f13021214ed41e53d7

Tip: you can replicate the issue by changing to the process work dir and entering the command `bash .command.run`

### Relevant log output

```shell
N E X T F L O W  ~  version 23.04.2
Launching `/Users/industria/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/main.nf` [zen_rich] DSL2 - revision: 67ff77f941
WARN: NEXTFLOW RECURSION IS A PREVIEW FEATURE - SYNTAX AND FUNCTIONALITY CAN CHANGE IN FUTURE RELEASES
||||||||||   _____ ____ ___ ____  __  __ _____      _       _
||||||||||  | ____|  _ \_ _|___ \|  \/  | ____|    | | __ _| |__  ___
|||||       |  _| | |_) | |  __) | |\/| |  _| _____| |/ _` | '_ \/ __|
|||||       | |___|  __/| | / __/| |  | | |__|_____| | (_| | |_) \__ \
||||||||||  |_____|_|  |___|_____|_|  |_|_____|    |_|\__,_|_.__/|___/
||||||||||  wf-bacterial-genomes v1.2.0
--------------------------------------------------------------------------------
Core Nextflow options
  runName        : zen_rich
  containerEngine: docker
  launchDir      : /Users/industria/epi2melabs/instances/wf-bacterial-genomes_01J3JJMARPQ4M98X7Y0P13A40J
  workDir        : /Users/industria/epi2melabs/instances/wf-bacterial-genomes_01J3JJMARPQ4M98X7Y0P13A40J/work
  projectDir     : /Users/industria/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes
  userName       : industria
  profile        : standard
  configFiles    : /Users/industria/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/nextflow.config
Input Options
  fastq          : /Library/MinKNOW/data/WGS_Microbiolo_icmt_ces/Ensayo1_18062024/20240618_1535_MN44954_FAY44725_fd76f707/fastq_pass/barcode04
Output Options
  out_dir        : /Users/industria/epi2melabs/instances/wf-bacterial-genomes_01J3JJMARPQ4M98X7Y0P13A40J/output
!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:
* The nf-core framework
  https://doi.org/10.1038/s41587-020-0439-x
--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v1.2.0.
--------------------------------------------------------------------------------
Searching input for [.fastq, .fastq.gz, .fq, .fq.gz] files.
Running Denovo assembly.
[11/4c3180] Submitted process > calling_pipeline:getParams
[aa/29977b] Submitted process > fastcat (1)
[0f/04bf97] Submitted process > calling_pipeline:prokkaVersion
[0b/dc71a8] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
[48/c46955] Submitted process > calling_pipeline:lookup_medaka_consensus_model (1)
[18/0fbf57] Submitted process > calling_pipeline:medakaVersion
[31/400630] Submitted process > calling_pipeline:mlstVersion
[d3/53ab8a] Submitted process > calling_pipeline:getVersions
[b3/5b0465] Submitted process > calling_pipeline:variantCheckpoint (1)
[8c/5133b1] Submitted process > calling_pipeline:perSampleReportingCheckpoint (1)
[2c/b95220] Submitted process > calling_pipeline:amrCheckpoint (1)
[ec/359d81] Submitted process > calling_pipeline:ingressCheckpoint (1)
[08/891809] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (1)
[3c/0d5a8e] Submitted process > calling_pipeline:deNovo (1)
[8a/fff31d] Submitted process > calling_pipeline:accumulateCheckpoints (1)
[d8/76aca0] Submitted process > calling_pipeline:accumulateCheckpoints (2)
[60/c2b2ae] Submitted process > calling_pipeline:accumulateCheckpoints (3)
[c3/815b7c] Submitted process > calling_pipeline:accumulateCheckpoints (4)
[6a/ea00bd] Submitted process > calling_pipeline:alignReads (1)
[ea/d63bb4] Submitted process > calling_pipeline:alignmentCheckpoint (1)
[cc/bdaf14] Submitted process > calling_pipeline:coverStats (1)
[85/f50ed1] Submitted process > calling_pipeline:readStats (1)
[96/4bc10b] Submitted process > calling_pipeline:splitRegions (1)
[b9/cf29f9] Submitted process > calling_pipeline:accumulateCheckpoints (5)
[d8/675260] Submitted process > calling_pipeline:medakaNetwork (2)
[0b/7a1570] Submitted process > calling_pipeline:medakaNetwork (3)
[1b/9d1a96] Submitted process > calling_pipeline:medakaNetwork (4)
[2f/97e54d] Submitted process > calling_pipeline:medakaNetwork (1)
[0b/7a1570] NOTE: Process `calling_pipeline:medakaNetwork (3)` terminated with an error exit status (137) -- Execution is retried (1)
[af/f72104] Re-submitted process > calling_pipeline:medakaNetwork (3)
[2f/97e54d] NOTE: Process `calling_pipeline:medakaNetwork (1)` terminated with an error exit status (137) -- Execution is retried (1)
[d8/675260] NOTE: Process `calling_pipeline:medakaNetwork (2)` terminated with an error exit status (137) -- Execution is retried (1)
[af/42ff0c] Re-submitted process > calling_pipeline:medakaNetwork (1)
[9f/40d55b] Re-submitted process > calling_pipeline:medakaNetwork (2)
ERROR ~ Error executing process > 'calling_pipeline:medakaNetwork (3)'
Caused by:
  Process `calling_pipeline:medakaNetwork (3)` terminated with an error exit status (137)
Command executed:
  medaka --version
      echo r1041_e82_400bps_sup_v4.2.0
  
      echo r1041_e82_400bps_sup_v4.2.0
  
      medaka consensus align.bam ""barcode04.consensus_probs.hdf""         --threads 2 --regions ""contig_1:1998000-2772987
  "" --model r1041_e82_400bps_sup_v4.2.0
Command exit status:
  137
Command output:
  medaka 1.11.3
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0
Command error:
  medaka 1.11.3
  Cannot import pyabpoa, some features may not be available.
  r1041_e82_400bps_sup_v4.2.0
  r1041_e82_400bps_sup_v4.2.0
  Cannot import pyabpoa, some features may not be available.
  [14:44:47 - Predict] Setting tensorflow inter/intra-op threads to 2/1.
  [14:44:47 - Predict] Processing region(s): contig_1:1998000-2772987
  [14:44:47 - Predict] Using model: /home/epi2melabs/conda/lib/python3.8/site-packages/medaka/data/r1041_e82_400bps_sup_v4.2.0_model.tar.gz.
  [14:44:47 - BAMFile] Creating pool of 16 BAM file sets.
  [14:44:47 - Predict] Processing 1 long region(s) with batching.
  [14:44:48 - MdlStrTF] Model <keras.engine.sequential.Sequential object at 0xffff349e4c10>
  [14:44:48 - MdlStrTF] loading weights from /tmp/tmp48_v3ah3/model/variables/variables (using expect partial)
  [14:44:48 - Sampler] Initializing sampler for consensus of region contig_1:1998000-2772987.
  [14:44:48 - PWorker] Running inference for 0.8M draft bases.
  [14:44:49 - Feature] Processed contig_1:1998000.0-2772986.0 (median depth 119.0)
  [14:44:49 - Sampler] Took 1.26s to make features.
  2024-07-24 14:44:52.874826: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:44:52.882347: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:44:53.237184: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:44:53.294152: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  2024-07-24 14:44:53.897555: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 512000000 exceeds 10% of free system memory.
  [14:45:00 - PWorker] Batches in cache: 2.
  [14:45:00 - PWorker] 79.7% Done (0.6/0.8 Mbases) in 12.0s
  .command.sh: line 8:    98 Killed                  medaka consensus align.bam ""barcode04.consensus_probs.hdf"" --threads 2 --regions ""contig_1:1998000-2772987
  "" --model r1041_e82_400bps_sup_v4.2.0
Work dir:
  /Users/industria/epi2melabs/instances/wf-bacterial-genomes_01J3JJMARPQ4M98X7Y0P13A40J/work/af/f72104527b947fbc7a372545e9aaed
Tip: you can replicate the issue by changing to the process work dir and entering the command `bash .command.run`
 -- Check '/Users/industria/epi2melabs/instances/wf-bacterial-genomes_01J3JJMARPQ4M98X7Y0P13A40J/nextflow.log' file for details
WARN: Killing running tasks (2)
Invocation logs
2024-07-24T14:34Z â”‚ Initialising
2024-07-24T14:34Z â”‚ Reading launch data
2024-07-24T14:34Z â”‚ Acquiring database record
2024-07-24T14:34Z â”‚ Starting workflow invocation
2024-07-24T14:34Z â”‚ Connecting to app via IPC
2024-07-24T14:34Z â”‚ Awaiting weblog via HTTP on 53071
2024-07-24T14:34Z â”‚ Launching nextflow subprocess
2024-07-24T14:34Z â”‚ Uplink established to app
2024-07-24T14:45Z â”‚ Subprocess closed
2024-07-24T14:45Z â”‚ Exiting
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

yes

### Other demo data information

_No response_",ycuesta,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/40
I_kwDOFIO7Dc6Q9nEv,wf-bacterial-genomes  workflow not working,CLOSED,2024-07-26T11:51:52Z,2024-07-30T12:25:30Z,2024-07-30T12:25:30Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

 N E X T F L O W   ~  version 24.04.3

### Workflow Execution

Command line

### EPI2ME Version

_No response_

### CLI command run

nextflow run epi2me-labs/wf-bacterial-genomes â€“-help

### Workflow Execution - CLI Execution Profile

standard (default)

### What happened?

I have been using wf-bacterial-genomes workflow for last 2 years. It worked fine till date. However, now it started showing following erros 

""ERROR ~ Script compilation error
- file : /home/hmn/.nextflow/assets/epi2me-labs/wf-bacterial-genomes/main.nf
- cause: Invalid output definition @ line 862, column 5.
       output(results.all_out)
       ^
I checked main.nf file fow syntax error but it is perfectly fine. Still I downloaded new file from source ""https://github.com/epi2me-labs/wf-bacterial-genomes/blob/master/main.nf""

Upgraded nextflow for latest version too.
Still not working for me. Need suggestions to troubleshoot.

### Relevant log output

```shell
na
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

yes

### Other demo data information

_No response_",bunnu27,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/41
I_kwDOFIO7Dc6ToESx,From basecalling to error correction (Fastq to Fasta) as input to wf-bacterial genome,CLOSED,2024-08-21T00:29:07Z,2024-12-03T09:34:28Z,2024-12-03T09:34:27Z,"### Ask away!

Hi 
I want to ask that downstream from base calling we do error-correction using dorrado , the step which convert fastq to fasta. However in wf-bacterial workflow we directly use fastq. Which fastq is it - uncorrected. And can we use fasta as input.
Many thanks ",jibrantahir,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/42
I_kwDOFIO7Dc6ToFBw,"Can unclassified bams from basecalling which could not be demultplexed, be of some use in reference based assembly",CLOSED,2024-08-21T00:33:07Z,2024-12-03T09:33:31Z,2024-12-03T09:33:31Z,"### Ask away!

Hi
When we basecall and demultiplex our pod5 reads, there are some unclassified bam piled up in one file. It still has reads but could not be demultiplexed. Is there a way to still utilize them- for example in a reference based assembly scenario, can we use them?
Thank you",jibrantahir,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/43
I_kwDOFIO7Dc6Vlz4R,can only analyse one barcode at a time,CLOSED,2024-09-06T07:24:21Z,2024-09-12T20:05:34Z,2024-09-12T20:05:33Z,"### Ask away!

The workflow fails or the laptop freezes when i try to run more than one sample at a time. our laptop has Inspiron G15 5530: 13th Gen Intel Core i9-13900HX (24MB Cache, up to 4.9 GHz, 12 cores),15.6"" FHD (1920x1080) ComfortViewPlus,16GB (2x8GB) DDR5 4800MHz, 1TB SSD PCIe M.2, NVIDIA GeForce RTX 4060 8GB GDDR6.

we are not even annotating with Prokka.
is there anything we can do so that we can analyse 24 barcodes? they do not need to be analysed in parallel but just a batch upload",nrt94,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/44
I_kwDOFIO7Dc6WWKz8,"Pipeline failure from process 'calling_pipeline:makeReport""",CLOSED,2024-09-12T13:24:33Z,2024-11-22T14:55:25Z,2024-11-17T19:07:05Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

1.3.0

### Workflow Execution

Command line (Cluster)

### Other workflow execution

In Conda environment

### EPI2ME Version

_No response_

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

This is an issue that seems to occur during a handful of different executions; however, today it occurred after attempting to execute the following:

nextflow run main.nf -profile singularity --bam /lab_data/daniels_lab/tysh/nanopore_seq/calls.bam  --out_dir /lab_data/des/ --reference_based_assembly --reference ../references/mycobacteria/NZ_HG964481.1.fasta --override_basecaller_cfg dna_r9.4.1_e8_hac@v3.3

### Relevant log output

```shell
Caused by:
  Process `calling_pipeline:makeReport` terminated with an error exit status (1)


Command executed:

  workflow-glue report     --stats per_read_stats/*          --prokka               --versions versions     --params params.json     --output wf-bacterial-genomes-report.html     --sample_ids calls

Command exit status:
  1

Command output:
  (empty)

Command error:
  [07:13:01 - workflow_glue] Bootstrapping CLI.
  [07:13:12 - matplotlib] Matplotlib created a temporary cache directory at /tmp/matplotlib-18dbyb0q because the default path (/home/tsherman/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
  [07:13:13 - matplotlib.font_manager] generated new fontManager
  [07:13:13 - workflow_glue] Starting entrypoint.
  Traceback (most recent call last):
    File ""/home/tsherman/wf-bacterial-genomes/bin/workflow-glue"", line 7, in <module>
      cli()
    File ""/home/tsherman/wf-bacterial-genomes/bin/workflow_glue/__init__.py"", line 82, in cli
      args.func(args)
    File ""/home/tsherman/wf-bacterial-genomes/bin/workflow_glue/report.py"", line 594, in main
      report = create_report(args, logger)
    File ""/home/tsherman/wf-bacterial-genomes/bin/workflow_glue/report.py"", line 290, in create_report
      zip(args.sample_ids_with_stats, args.stats), key=lambda x: x[0]
  TypeError: 'NoneType' object is not iterable
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

yes

### Other demo data information

_No response_",forty2wallabyway,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/45
I_kwDOFIO7Dc6bbiwg,"Bacterial genome wf ""Stopped with error""",CLOSED,2024-10-23T08:13:02Z,2024-11-29T15:17:59Z,2024-11-29T15:17:59Z,"### Operating System

Windows 11

### Other Linux

_No response_

### Workflow Version

v1.2.0

### Workflow Execution

EPI2ME Desktop (Local)

### Other workflow execution

_No response_

### EPI2ME Version

v5.2.1

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

Uploaded fastq files (92 files), it runs for about 30 mins and then shows a ""stopped with error"". Tried it a few times. I then troubleshooted with the demo-data and the workflow works.
Opted to then run the files in batches of 10 and it works.

### Relevant log output

```shell
N E X T F L O W ~ version 23.04.2
Launching `/mnt/c/Users/Sequencing/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/main.nf` [competent_rosalind] DSL2 - revision: 67ff77f941
WARN: NEXTFLOW RECURSION IS A PREVIEW FEATURE - SYNTAX AND FUNCTIONALITY CAN CHANGE IN FUTURE RELEASES
|||||||||| _____ ____ ___ ____ __ __ _____ _ _
|||||||||| | ____| _ \_ _|___ \| \/ | ____| | | __ _| |__ ___
||||| | _| | |_) | | __) | |\/| | _| _____| |/ _` | '_ \/ __|
||||| | |___| __/| | / __/| | | | |__|_____| | (_| | |_) \__ \
|||||||||| |_____|_| |___|_____|_| |_|_____| |_|\__,_|_.__/|___/
|||||||||| wf-bacterial-genomes v1.2.0
--------------------------------------------------------------------------------
Core Nextflow options
runName : competent_rosalind
containerEngine: docker
launchDir : /mnt/c/Users/Sequencing/epi2melabs/instances/wf-bacterial-genomes_01JACZ50KNN6EF71EKC6551GPZ
workDir : /mnt/c/Users/Sequencing/epi2melabs/instances/wf-bacterial-genomes_01JACZ50KNN6EF71EKC6551GPZ/work
projectDir : /mnt/c/Users/Sequencing/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes
userName : epi2mewsl
profile : standard
configFiles : /mnt/c/Users/Sequencing/epi2melabs/workflows/epi2me-labs/wf-bacterial-genomes/nextflow.config
Input Options
fastq : /mnt/c/data/Anjali_colistin_16Oct2024/no_sample/20241016_1356_MN44856_FAZ04752_0602dabf/fastq_pass
Output Options
out_dir : /mnt/c/Users/Sequencing/epi2melabs/instances/wf-bacterial-genomes_01JACZ50KNN6EF71EKC6551GPZ/output
!! Only displaying parameters that differ from the pipeline defaults !!
--------------------------------------------------------------------------------
If you use epi2me-labs/wf-bacterial-genomes for your analysis please cite:
* The nf-core framework
https://doi.org/10.1038/s41587-020-0439-x
--------------------------------------------------------------------------------
This is epi2me-labs/wf-bacterial-genomes v1.2.0.
--------------------------------------------------------------------------------
Searching input for [.fastq, .fastq.gz, .fq, .fq.gz] files.
Running Denovo assembly.
[47/7a7159] Submitted process > calling_pipeline:getParams
[5c/66f392] Submitted process > fastcat (2)
[19/fa4991] Submitted process > calling_pipeline:prokkaVersion
[14/4caee5] Submitted process > fastcat (1)
[e0/e89f79] Submitted process > fastcat (4)
[3b/f22c3d] Submitted process > fastcat (5)
[5b/a90141] Submitted process > fastcat (3)
[65/168365] Submitted process > fastcat (6)
[73/79fe56] Submitted process > calling_pipeline:lookup_medaka_consensus_model (1)
[1e/31f082] Submitted process > calling_pipeline:lookup_medaka_variant_model (1)
[ff/d1dcef] Submitted process > fastcat (7)
[b7/0c158b] Submitted process > fastcat (8)
[68/58af70] Submitted process > calling_pipeline:ingressCheckpoint (1)
[2a/e36ff6] Submitted process > fastcat (9)
[67/fb2c0f] Submitted process > fastcat (10)
[8d/06776a] Submitted process > fastcat (11)
[b9/28ca64] Submitted process > fastcat (12)
[28/4aadae] Submitted process > calling_pipeline:amrCheckpoint (1)
[27/bea04c] Submitted process > fastcat (13)
[b3/71e431] Submitted process > fastcat (14)
[69/878478] Submitted process > fastcat (15)
[15/36982e] Submitted process > fastcat (16)
[26/595280] Submitted process > calling_pipeline:variantCheckpoint (1)
[06/70d0da] Submitted process > fastcat (17)
[79/09e595] Submitted process > fastcat (18)
[7f/0ed4ef] Submitted process > fastcat (19)
[d1/3e946c] Submitted process > fastcat (20)
[3d/6085c3] Submitted process > calling_pipeline:perSampleReportingCheckpoint (1)
[8e/642502] Submitted process > fastcat (21)
[8a/36fd47] Submitted process > fastcat (22)
[a2/264c9f] Submitted process > fastcat (23)
[e8/c302db] Submitted process > calling_pipeline:perSampleReportingCheckpoint (2)
[6f/6534cb] Submitted process > fastcat (24)
[09/c152b1] Submitted process > fastcat (25)
[78/92ea46] Submitted process > calling_pipeline:ingressCheckpoint (2)
[8a/9b01d1] Submitted process > fastcat (26)
[95/7ea4f4] Submitted process > fastcat (27)
[f5/7e6e39] Submitted process > fastcat (28)
[68/44bb6f] Submitted process > calling_pipeline:amrCheckpoint (2)
[db/9afc43] Submitted process > fastcat (29)
[6a/9468b9] Submitted process > fastcat (30)
[08/628731] Submitted process > fastcat (31)
[3f/b019f2] Submitted process > fastcat (32)
[a6/bff595] Submitted process > calling_pipeline:medakaVersion
[68/d3d255] Submitted process > fastcat (33)
[98/c04318] Submitted process > calling_pipeline:variantCheckpoint (2)
[c2/f80915] Submitted process > fastcat (34)
[78/fd0edb] Submitted process > fastcat (35)
[2d/0b158a] Submitted process > fastcat (36)
[9c/635764] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (1)
[94/684993] Submitted process > fastcat (37)
[40/5e0d38] Submitted process > calling_pipeline:variantCheckpoint (3)
[86/7da59d] Submitted process > fastcat (38)
[25/ba0989] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (2)
[68/c51154] Submitted process > fastcat (39)
[a2/37e6a8] Submitted process > fastcat (40)
[27/81f971] Submitted process > fastcat (41)
[f5/417729] Submitted process > calling_pipeline:amrCheckpoint (3)
[93/c76c70] Submitted process > calling_pipeline:perSampleReportingCheckpoint (3)
[4f/2d46d0] Submitted process > calling_pipeline:ingressCheckpoint (3)
[ba/b8bbf2] Submitted process > fastcat (42)
[4a/9bffb4] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (3)
[5f/f83e85] Submitted process > fastcat (43)
[95/dbbbd7] Submitted process > calling_pipeline:ingressCheckpoint (4)
[4f/371b43] Submitted process > calling_pipeline:perSampleReportingCheckpoint (4)
[e9/066d59] Submitted process > calling_pipeline:amrCheckpoint (4)
[d0/a7f4e5] Submitted process > calling_pipeline:variantCheckpoint (4)
[55/d186c8] Submitted process > calling_pipeline:variantCheckpoint (5)
[d1/e9cb0b] Submitted process > calling_pipeline:amrCheckpoint (5)
[77/2ece43] Submitted process > calling_pipeline:ingressCheckpoint (5)
[f2/0a17d8] Submitted process > fastcat (44)
[c8/02461f] Submitted process > calling_pipeline:perSampleReportingCheckpoint (5)
[a6/65bef4] Submitted process > calling_pipeline:variantCheckpoint (6)
[18/dff1ba] Submitted process > calling_pipeline:amrCheckpoint (6)
[eb/c63ebf] Submitted process > calling_pipeline:perSampleReportingCheckpoint (6)
[7b/241d8a] Submitted process > calling_pipeline:ingressCheckpoint (6)
[18/5a008b] Submitted process > calling_pipeline:amrCheckpoint (7)
[1f/e05817] Submitted process > calling_pipeline:ingressCheckpoint (7)
[fc/73777c] Submitted process > fastcat (45)
[83/2733b1] Submitted process > fastcat (46)
[31/0f5026] Submitted process > calling_pipeline:perSampleReportingCheckpoint (7)
[62/856fce] Submitted process > calling_pipeline:variantCheckpoint (7)
[9c/1a9e44] Submitted process > calling_pipeline:variantCheckpoint (8)
[e7/278b56] Submitted process > calling_pipeline:amrCheckpoint (8)
[c0/3cb23f] Submitted process > calling_pipeline:perSampleReportingCheckpoint (8)
[7a/9a5994] Submitted process > fastcat (47)
[35/d96e68] Submitted process > fastcat (48)
[ab/335f73] Submitted process > calling_pipeline:ingressCheckpoint (8)
[eb/d9bed6] Submitted process > fastcat (49)
[8d/2fe611] Submitted process > calling_pipeline:variantCheckpoint (9)
[ac/2ea39a] Submitted process > calling_pipeline:ingressCheckpoint (9)
[f9/329882] Submitted process > calling_pipeline:amrCheckpoint (9)
[07/e4fda7] Submitted process > calling_pipeline:perSampleReportingCheckpoint (9)
[1d/ef1b47] Submitted process > fastcat (50)
[5e/337b7e] Submitted process > calling_pipeline:ingressCheckpoint (10)
[55/c381e6] Submitted process > fastcat (51)
[9e/2803c2] Submitted process > calling_pipeline:amrCheckpoint (10)
[41/a4b2d8] Submitted process > calling_pipeline:variantCheckpoint (10)
[26/1ab26c] Submitted process > calling_pipeline:perSampleReportingCheckpoint (10)
[89/cfdfd3] Submitted process > calling_pipeline:ingressCheckpoint (11)
[d7/19ce8a] Submitted process > calling_pipeline:variantCheckpoint (11)
[a7/91bb8d] Submitted process > calling_pipeline:amrCheckpoint (11)
[b3/d5b059] Submitted process > fastcat (52)
[46/c8ccd8] Submitted process > calling_pipeline:perSampleReportingCheckpoint (11)
[95/da2941] Submitted process > calling_pipeline:perSampleReportingCheckpoint (12)
[93/3946ad] Submitted process > fastcat (53)
[9d/f90e6b] Submitted process > calling_pipeline:variantCheckpoint (12)
[f6/623157] Submitted process > calling_pipeline:amrCheckpoint (12)
[0c/e747e4] Submitted process > calling_pipeline:ingressCheckpoint (12)
[f2/c9bf73] Submitted process > calling_pipeline:ingressCheckpoint (13)
[39/864f51] Submitted process > calling_pipeline:amrCheckpoint (13)
[e0/b1c1eb] Submitted process > fastcat (54)
[b1/1fb810] Submitted process > calling_pipeline:perSampleReportingCheckpoint (13)
[de/536bcb] Submitted process > fastcat (55)
[e1/5d2f43] Submitted process > calling_pipeline:variantCheckpoint (13)
[c3/90326a] Submitted process > fastcat (56)
[15/ada4ca] Submitted process > calling_pipeline:ingressCheckpoint (14)
[f2/fb495f] Submitted process > calling_pipeline:amrCheckpoint (14)
[98/2f8d84] Submitted process > calling_pipeline:variantCheckpoint (14)
[46/c9adc0] Submitted process > calling_pipeline:perSampleReportingCheckpoint (14)
[5e/3377be] Submitted process > calling_pipeline:ingressCheckpoint (15)
[23/b43659] Submitted process > calling_pipeline:variantCheckpoint (15)
[e4/05d3be] Submitted process > calling_pipeline:perSampleReportingCheckpoint (15)
[f2/a22fa1] Submitted process > fastcat (57)
[33/dfba67] Submitted process > calling_pipeline:amrCheckpoint (15)
[f2/0e6687] Submitted process > calling_pipeline:variantCheckpoint (16)
[b3/48c02e] Submitted process > fastcat (58)
[d2/d310a6] Submitted process > fastcat (59)
[e4/8c391e] Submitted process > calling_pipeline:ingressCheckpoint (16)
[ca/a6d3d7] Submitted process > calling_pipeline:amrCheckpoint (16)
[54/3fd85f] Submitted process > calling_pipeline:perSampleReportingCheckpoint (16)
[0d/fc3c70] Submitted process > calling_pipeline:amrCheckpoint (17)
[a1/7de0bb] Submitted process > calling_pipeline:ingressCheckpoint (17)
[da/4c73e7] Submitted process > fastcat (60)
[38/5fc209] Submitted process > calling_pipeline:variantCheckpoint (17)
[91/022ae5] Submitted process > fastcat (61)
[0d/a8104b] Submitted process > calling_pipeline:perSampleReportingCheckpoint (17)
[07/32a717] Submitted process > calling_pipeline:amrCheckpoint (18)
[8b/80df0b] Submitted process > calling_pipeline:ingressCheckpoint (18)
[76/8b4b6f] Submitted process > calling_pipeline:variantCheckpoint (18)
[cc/6e801b] Submitted process > calling_pipeline:perSampleReportingCheckpoint (18)
[15/7bbc79] Submitted process > calling_pipeline:amrCheckpoint (19)
[0c/f788e5] Submitted process > calling_pipeline:ingressCheckpoint (19)
[82/2bb48f] Submitted process > fastcat (62)
[a7/b380c2] Submitted process > calling_pipeline:variantCheckpoint (19)
[68/b27c25] Submitted process > calling_pipeline:perSampleReportingCheckpoint (19)
[31/f2f44b] Submitted process > calling_pipeline:perSampleReportingCheckpoint (20)
[05/1f8d0b] Submitted process > fastcat (63)
[b6/2ab54f] Submitted process > fastcat (64)
[88/b64547] Submitted process > calling_pipeline:variantCheckpoint (20)
[ff/9b12ed] Submitted process > calling_pipeline:ingressCheckpoint (20)
[3f/113604] Submitted process > calling_pipeline:amrCheckpoint (20)
[25/d532f3] Submitted process > calling_pipeline:perSampleReportingCheckpoint (21)
[f8/eb34a5] Submitted process > calling_pipeline:variantCheckpoint (21)
[0e/ef4490] Submitted process > fastcat (65)
[d8/a6ead8] Submitted process > calling_pipeline:ingressCheckpoint (21)
[95/03c016] Submitted process > calling_pipeline:amrCheckpoint (21)
[28/a268dd] Submitted process > fastcat (66)
[e9/1034b8] Submitted process > calling_pipeline:amrCheckpoint (22)
[55/d4a83c] Submitted process > calling_pipeline:ingressCheckpoint (22)
[1b/9a1017] Submitted process > fastcat (67)
[dd/eefc1b] Submitted process > calling_pipeline:perSampleReportingCheckpoint (22)
[5e/4a0431] Submitted process > calling_pipeline:variantCheckpoint (22)
[5f/25abec] Submitted process > calling_pipeline:amrCheckpoint (23)
[4d/c0d61f] Submitted process > calling_pipeline:variantCheckpoint (23)
[9e/782fe9] Submitted process > fastcat (68)
[cf/e9afd8] Submitted process > calling_pipeline:perSampleReportingCheckpoint (23)
[21/43c40c] Submitted process > fastcat (69)
[c3/036f0f] Submitted process > calling_pipeline:ingressCheckpoint (23)
[a7/8eea1d] Submitted process > calling_pipeline:ingressCheckpoint (24)
[52/7d48e7] Submitted process > calling_pipeline:variantCheckpoint (24)
[35/980b57] Submitted process > calling_pipeline:amrCheckpoint (24)
[ff/d8a3e8] Submitted process > fastcat (70)
[14/3dab15] Submitted process > calling_pipeline:perSampleReportingCheckpoint (24)
[01/aca2dc] Submitted process > fastcat (71)
[a2/70ff7c] Submitted process > calling_pipeline:perSampleReportingCheckpoint (25)
[0c/fefbe1] Submitted process > calling_pipeline:amrCheckpoint (25)
[80/b4b13c] Submitted process > calling_pipeline:ingressCheckpoint (25)
[75/f31eae] Submitted process > calling_pipeline:variantCheckpoint (25)
[8a/c21f57] Submitted process > fastcat (72)
[f5/6328a8] Submitted process > calling_pipeline:ingressCheckpoint (26)
[ed/5d7c22] Submitted process > calling_pipeline:amrCheckpoint (26)
[55/0170ee] Submitted process > calling_pipeline:variantCheckpoint (26)
[aa/abe157] Submitted process > calling_pipeline:perSampleReportingCheckpoint (26)
[92/4af525] Submitted process > fastcat (73)
[f2/e0409b] Submitted process > calling_pipeline:variantCheckpoint (27)
[4f/b05a77] Submitted process > fastcat (74)
[26/6a0b80] Submitted process > calling_pipeline:ingressCheckpoint (27)
[ce/eecd21] Submitted process > calling_pipeline:amrCheckpoint (27)
[8f/acacce] Submitted process > calling_pipeline:perSampleReportingCheckpoint (27)
[d4/0e9115] Submitted process > fastcat (75)
[d2/c973a9] Submitted process > calling_pipeline:ingressCheckpoint (28)
[52/fb164f] Submitted process > calling_pipeline:amrCheckpoint (28)
[bf/525d20] Submitted process > calling_pipeline:perSampleReportingCheckpoint (28)
[66/221f6e] Submitted process > calling_pipeline:variantCheckpoint (28)
[12/91abbb] Submitted process > calling_pipeline:variantCheckpoint (29)
[4c/13acb1] Submitted process > calling_pipeline:perSampleReportingCheckpoint (29)
[7e/398520] Submitted process > fastcat (76)
[fa/77144e] Submitted process > fastcat (77)
[37/8484c7] Submitted process > calling_pipeline:amrCheckpoint (29)
[5b/02ff2f] Submitted process > calling_pipeline:ingressCheckpoint (29)
[02/378976] Submitted process > calling_pipeline:amrCheckpoint (30)
[18/8b77be] Submitted process > fastcat (78)
[a2/cfabb0] Submitted process > calling_pipeline:ingressCheckpoint (30)
[59/c9c2b2] Submitted process > calling_pipeline:perSampleReportingCheckpoint (30)
[60/14ee7e] Submitted process > calling_pipeline:variantCheckpoint (30)
[93/474aa4] Submitted process > calling_pipeline:variantCheckpoint (31)
[7a/5ec7ce] Submitted process > fastcat (79)
[72/a68d93] Submitted process > calling_pipeline:perSampleReportingCheckpoint (31)
[40/54d442] Submitted process > fastcat (80)
[2b/f3ffa1] Submitted process > calling_pipeline:amrCheckpoint (31)
[6f/df16dd] Submitted process > calling_pipeline:ingressCheckpoint (31)
[4b/9afafb] Submitted process > calling_pipeline:perSampleReportingCheckpoint (32)
[45/1f49c1] Submitted process > calling_pipeline:amrCheckpoint (32)
[da/69242e] Submitted process > calling_pipeline:variantCheckpoint (32)
[83/e4cac3] Submitted process > fastcat (81)
[77/e666c1] Submitted process > calling_pipeline:ingressCheckpoint (32)
[f6/1624c1] Submitted process > calling_pipeline:variantCheckpoint (33)
[f4/bc9beb] Submitted process > calling_pipeline:ingressCheckpoint (33)
[65/c82756] Submitted process > calling_pipeline:perSampleReportingCheckpoint (33)
[f4/436873] Submitted process > fastcat (82)
[a4/474403] Submitted process > calling_pipeline:amrCheckpoint (33)
[1e/4d9664] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (4)
[b1/5a4bfc] Submitted process > calling_pipeline:ingressCheckpoint (34)
[05/022b22] Submitted process > calling_pipeline:perSampleReportingCheckpoint (34)
[af/bc2316] Submitted process > calling_pipeline:variantCheckpoint (34)
[a5/35c283] Submitted process > calling_pipeline:amrCheckpoint (34)
[68/fcda2a] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (5)
[93/b4756a] Submitted process > calling_pipeline:variantCheckpoint (35)
[8c/ad912e] Submitted process > calling_pipeline:perSampleReportingCheckpoint (35)
[7d/06df11] Submitted process > calling_pipeline:amrCheckpoint (35)
[57/181d26] Submitted process > calling_pipeline:ingressCheckpoint (35)
[e6/9768d5] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (6)
[66/3d6fe1] Submitted process > calling_pipeline:perSampleReportingCheckpoint (36)
[3b/e4f871] Submitted process > calling_pipeline:ingressCheckpoint (36)
[55/742e88] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (7)
[3f/5d3d53] Submitted process > calling_pipeline:amrCheckpoint (36)
[66/449cba] Submitted process > calling_pipeline:variantCheckpoint (36)
[c9/b9a6b8] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (8)
[2d/5cd4ff] Submitted process > calling_pipeline:ingressCheckpoint (37)
[54/4c2d31] Submitted process > calling_pipeline:perSampleReportingCheckpoint (37)
[16/0b4fd3] Submitted process > calling_pipeline:amrCheckpoint (37)
[a9/707ea1] Submitted process > calling_pipeline:variantCheckpoint (37)
[f9/f77fe8] Submitted process > calling_pipeline:variantCheckpoint (38)
[00/26aeb9] Submitted process > calling_pipeline:amrCheckpoint (38)
[c6/70345e] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (9)
[56/f13f7a] Submitted process > calling_pipeline:ingressCheckpoint (38)
[31/6228b4] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (10)
[28/0247b9] Submitted process > calling_pipeline:perSampleReportingCheckpoint (38)
[ef/15863b] Submitted process > calling_pipeline:ingressCheckpoint (39)
[b8/85b6be] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (11)
[c5/7ad1ac] Submitted process > calling_pipeline:perSampleReportingCheckpoint (39)
[08/8d4a54] Submitted process > calling_pipeline:amrCheckpoint (39)
[eb/ecfec7] Submitted process > calling_pipeline:variantCheckpoint (39)
[f4/5ec54a] Submitted process > calling_pipeline:amrCheckpoint (40)
[d3/647e50] Submitted process > calling_pipeline:ingressCheckpoint (40)
[bd/a927df] Submitted process > calling_pipeline:variantCheckpoint (40)
[a1/6d32fe] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (12)
[30/9b7aca] Submitted process > calling_pipeline:perSampleReportingCheckpoint (40)
[93/dbc782] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (13)
[59/6c39c9] Submitted process > calling_pipeline:ingressCheckpoint (41)
[46/f98466] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (14)
[20/290f85] Submitted process > calling_pipeline:variantCheckpoint (41)
[71/b63c6c] Submitted process > calling_pipeline:perSampleReportingCheckpoint (41)
[db/94345e] Submitted process > calling_pipeline:amrCheckpoint (41)
[a1/830042] Submitted process > calling_pipeline:perSampleReportingCheckpoint (42)
[60/4c923a] Submitted process > calling_pipeline:variantCheckpoint (42)
[6d/21b747] Submitted process > calling_pipeline:amrCheckpoint (42)
[61/34796c] Submitted process > calling_pipeline:ingressCheckpoint (42)
[fc/00c2af] Submitted process > calling_pipeline:variantCheckpoint (43)
[8c/866e7a] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (15)
[53/bb9831] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (16)
[f4/589629] Submitted process > calling_pipeline:amrCheckpoint (43)
[e2/970526] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (17)
[51/1cdd62] Submitted process > calling_pipeline:perSampleReportingCheckpoint (43)
[b0/76ca46] Submitted process > calling_pipeline:ingressCheckpoint (43)
[cb/d9f077] Submitted process > calling_pipeline:ingressCheckpoint (44)
[a1/82d663] Submitted process > calling_pipeline:variantCheckpoint (44)
[25/49529d] Submitted process > calling_pipeline:amrCheckpoint (44)
[9f/a759f9] Submitted process > calling_pipeline:perSampleReportingCheckpoint (44)
[79/2042e2] Submitted process > calling_pipeline:ingressCheckpoint (45)
[69/61a38d] Submitted process > calling_pipeline:perSampleReportingCheckpoint (45)
[7c/9022cf] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (18)
[d2/06aff6] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (19)
[41/e5420a] Submitted process > calling_pipeline:variantCheckpoint (45)
[aa/d73877] Submitted process > calling_pipeline:amrCheckpoint (45)
[33/963310] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (20)
[e6/ba5590] Submitted process > calling_pipeline:variantCheckpoint (46)
[b6/b82bf8] Submitted process > calling_pipeline:ingressCheckpoint (46)
[73/13bf71] Submitted process > calling_pipeline:amrCheckpoint (46)
[47/8bb017] Submitted process > calling_pipeline:perSampleReportingCheckpoint (46)
[2e/8c13e1] Submitted process > calling_pipeline:amrCheckpoint (47)
[5a/e3cb41] Submitted process > calling_pipeline:ingressCheckpoint (47)
[66/8f3cf6] Submitted process > calling_pipeline:perSampleReportingCheckpoint (47)
[c6/bf3dfc] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (21)
[78/f3e656] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (22)
[47/75e1c1] Submitted process > calling_pipeline:variantCheckpoint (47)
[7e/144018] Submitted process > calling_pipeline:ingressCheckpoint (48)
[bc/f27ab7] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (23)
[ae/4c148b] Submitted process > calling_pipeline:perSampleReportingCheckpoint (48)
[e8/2c0c6d] Submitted process > calling_pipeline:variantCheckpoint (48)
[e6/c4344e] Submitted process > calling_pipeline:amrCheckpoint (48)
[15/662688] Submitted process > calling_pipeline:ingressCheckpoint (49)
[80/ca5738] Submitted process > calling_pipeline:amrCheckpoint (49)
[11/98a765] Submitted process > calling_pipeline:variantCheckpoint (49)
[a5/315f81] Submitted process > calling_pipeline:perSampleReportingCheckpoint (49)
[b0/fc2d7a] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (24)
[48/9db93b] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (25)
[59/802c83] Submitted process > calling_pipeline:amrCheckpoint (50)
[25/7cfcc1] Submitted process > calling_pipeline:variantCheckpoint (50)
[b4/89361d] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (26)
[69/a3930f] Submitted process > calling_pipeline:perSampleReportingCheckpoint (50)
[f1/db5a53] Submitted process > calling_pipeline:ingressCheckpoint (50)
[28/01dc07] Submitted process > calling_pipeline:variantCheckpoint (51)
[9a/81ec12] Submitted process > calling_pipeline:perSampleReportingCheckpoint (51)
[61/0a1a79] Submitted process > calling_pipeline:ingressCheckpoint (51)
[c6/db001f] Submitted process > calling_pipeline:amrCheckpoint (51)
[22/2d59da] Submitted process > calling_pipeline:perSampleReportingCheckpoint (52)
[6f/369cfc] Submitted process > calling_pipeline:amrCheckpoint (52)
[7a/b79c83] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (27)
[55/1135ba] Submitted process > calling_pipeline:variantCheckpoint (52)
[2c/e207eb] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (28)
[fd/7c2e29] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (29)
[90/21998a] Submitted process > calling_pipeline:ingressCheckpoint (52)
[bc/364514] Submitted process > calling_pipeline:perSampleReportingCheckpoint (53)
[62/29e6d4] Submitted process > calling_pipeline:amrCheckpoint (53)
[5c/07aae6] Submitted process > calling_pipeline:variantCheckpoint (53)
[a0/ffe64c] Submitted process > calling_pipeline:ingressCheckpoint (53)
[b3/fca753] Submitted process > calling_pipeline:perSampleReportingCheckpoint (54)
[c8/2d357b] Submitted process > calling_pipeline:amrCheckpoint (54)
[1f/516b3f] Submitted process > calling_pipeline:variantCheckpoint (54)
[2c/d8f217] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (30)
[98/eca653] Submitted process > calling_pipeline:mlstVersion
[2e/23e6ea] Submitted process > calling_pipeline:ingressCheckpoint (54)
[d1/9fd02b] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (31)
[65/952be1] Submitted process > calling_pipeline:ingressCheckpoint (55)
[bd/9c5c61] Submitted process > calling_pipeline:perSampleReportingCheckpoint (55)
[c0/e36ea7] Submitted process > calling_pipeline:amrCheckpoint (55)
[b7/6282db] Submitted process > calling_pipeline:variantCheckpoint (55)
[9a/5ed84c] Submitted process > calling_pipeline:perSampleReportingCheckpoint (56)
[c4/085412] Submitted process > calling_pipeline:amrCheckpoint (56)
[51/1dbb88] Submitted process > calling_pipeline:ingressCheckpoint (56)
[f4/999959] Submitted process > calling_pipeline:variantCheckpoint (56)
[4f/f37da5] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (32)
[ff/dfcfd6] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (33)
[42/4198b3] Submitted process > calling_pipeline:ingressCheckpoint (57)
[6c/8893da] Submitted process > calling_pipeline:perSampleReportingCheckpoint (57)
[f0/078100] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (34)
[41/8e793e] Submitted process > calling_pipeline:variantCheckpoint (57)
[a5/610ef0] Submitted process > calling_pipeline:amrCheckpoint (57)
[c1/c0bdda] Submitted process > calling_pipeline:amrCheckpoint (58)
[47/a5639e] Submitted process > calling_pipeline:ingressCheckpoint (58)
[35/051467] Submitted process > calling_pipeline:perSampleReportingCheckpoint (58)
[1a/3449b9] Submitted process > calling_pipeline:variantCheckpoint (58)
[7d/1c0c4a] Submitted process > calling_pipeline:perSampleReportingCheckpoint (59)
[72/f98a08] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (35)
[76/334d22] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (36)
[5f/f35d15] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (37)
[f7/3a0b5d] Submitted process > calling_pipeline:variantCheckpoint (59)
[18/2b7a60] Submitted process > calling_pipeline:amrCheckpoint (59)
[17/572c0b] Submitted process > calling_pipeline:ingressCheckpoint (59)
[9b/660124] Submitted process > calling_pipeline:perSampleReportingCheckpoint (60)
[75/56dbb4] Submitted process > calling_pipeline:amrCheckpoint (60)
[e0/6df6db] Submitted process > calling_pipeline:variantCheckpoint (60)
[6a/e9bd7d] Submitted process > calling_pipeline:ingressCheckpoint (60)
[77/6ee76f] Submitted process > calling_pipeline:perSampleReportingCheckpoint (61)
[0a/57cfd3] Submitted process > calling_pipeline:ingressCheckpoint (61)
[9b/472a14] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (38)
[fa/2a919d] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (39)
[c0/1063ec] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (40)
[e7/084a04] Submitted process > calling_pipeline:variantCheckpoint (61)
[87/f1eee6] Submitted process > calling_pipeline:amrCheckpoint (61)
[91/40d200] Submitted process > calling_pipeline:perSampleReportingCheckpoint (62)
[8a/75e328] Submitted process > calling_pipeline:variantCheckpoint (62)
[50/d9b5ef] Submitted process > calling_pipeline:amrCheckpoint (62)
[43/7e0887] Submitted process > calling_pipeline:ingressCheckpoint (62)
[3e/d1ecc5] Submitted process > calling_pipeline:ingressCheckpoint (63)
[64/5b37fb] Submitted process > calling_pipeline:amrCheckpoint (63)
[fc/7d6523] Submitted process > calling_pipeline:perSampleReportingCheckpoint (63)
[cc/5a88ca] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (41)
[e1/5bad1d] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (42)
[c6/fb58a0] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (43)
[0f/d0ae14] Submitted process > calling_pipeline:variantCheckpoint (63)
[1b/1cae16] Submitted process > calling_pipeline:amrCheckpoint (64)
[53/c8aec8] Submitted process > calling_pipeline:perSampleReportingCheckpoint (64)
[aa/015196] Submitted process > calling_pipeline:variantCheckpoint (64)
[5c/94e258] Submitted process > calling_pipeline:ingressCheckpoint (64)
[e9/6eed42] Submitted process > calling_pipeline:amrCheckpoint (65)
[82/97d55e] Submitted process > calling_pipeline:perSampleReportingCheckpoint (65)
[23/80b0bc] Submitted process > calling_pipeline:ingressCheckpoint (65)
[c4/d436da] Submitted process > calling_pipeline:variantCheckpoint (65)
[f8/4b86f8] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (44)
[eb/982810] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (45)
[ab/31bba7] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (46)
[8b/105f7b] Submitted process > calling_pipeline:variantCheckpoint (66)
[eb/2c744d] Submitted process > calling_pipeline:amrCheckpoint (66)
[d4/876f76] Submitted process > calling_pipeline:perSampleReportingCheckpoint (66)
[44/0c789b] Submitted process > calling_pipeline:ingressCheckpoint (66)
[5e/aea7f2] Submitted process > calling_pipeline:variantCheckpoint (67)
[d3/4b2592] Submitted process > calling_pipeline:amrCheckpoint (67)
[30/647991] Submitted process > calling_pipeline:ingressCheckpoint (67)
[93/0401f0] Submitted process > calling_pipeline:perSampleReportingCheckpoint (67)
[f4/2280c2] Submitted process > calling_pipeline:amrCheckpoint (68)
[d4/4a462b] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (47)
[96/ff2fff] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (48)
[05/56f3a2] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (49)
[fd/aa0c72] Submitted process > calling_pipeline:perSampleReportingCheckpoint (68)
[70/3a3d1b] Submitted process > calling_pipeline:ingressCheckpoint (68)
[4e/623b87] Submitted process > calling_pipeline:variantCheckpoint (68)
[20/9541d1] Submitted process > calling_pipeline:variantCheckpoint (69)
[a8/93bcf1] Submitted process > calling_pipeline:perSampleReportingCheckpoint (69)
[e7/33f503] Submitted process > calling_pipeline:ingressCheckpoint (69)
[f0/4a4b79] Submitted process > calling_pipeline:amrCheckpoint (69)
[f0/1794a7] Submitted process > calling_pipeline:ingressCheckpoint (70)
[81/f597b3] Submitted process > calling_pipeline:perSampleReportingCheckpoint (70)
[a9/84d03c] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (50)
[2b/78ad28] Submitted process > calling_pipeline:variantCheckpoint (70)
[2d/c5a8de] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (51)
[71/75de78] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (52)
[f9/210957] Submitted process > calling_pipeline:amrCheckpoint (70)
[5c/f83909] Submitted process > calling_pipeline:variantCheckpoint (71)
[fc/1bb51b] Submitted process > calling_pipeline:ingressCheckpoint (71)
[97/b4024b] Submitted process > calling_pipeline:perSampleReportingCheckpoint (71)
[36/9c3253] Submitted process > calling_pipeline:amrCheckpoint (71)
[b7/ebc23a] Submitted process > calling_pipeline:ingressCheckpoint (72)
[2e/eecf78] Submitted process > calling_pipeline:amrCheckpoint (72)
[ac/694ceb] Submitted process > calling_pipeline:variantCheckpoint (72)
[20/260c45] Submitted process > calling_pipeline:perSampleReportingCheckpoint (72)
[02/9cfffb] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (53)
[d9/657890] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (54)
[05/639ee8] Submitted process > calling_pipeline:variantCheckpoint (73)
[db/33efdd] Submitted process > calling_pipeline:perSampleReportingCheckpoint (73)
[b2/18c237] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (55)
[e5/b043f2] Submitted process > calling_pipeline:amrCheckpoint (73)
[49/feebe0] Submitted process > calling_pipeline:ingressCheckpoint (73)
[52/3df4f3] Submitted process > calling_pipeline:variantCheckpoint (74)
[3c/067b85] Submitted process > calling_pipeline:perSampleReportingCheckpoint (74)
[10/b09bd0] Submitted process > calling_pipeline:amrCheckpoint (74)
[41/6f32de] Submitted process > calling_pipeline:ingressCheckpoint (74)
[b0/431dcb] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (56)
[d7/f09032] Submitted process > calling_pipeline:variantCheckpoint (75)
[3d/74ef72] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (57)
[aa/945e2a] Submitted process > calling_pipeline:perSampleReportingCheckpoint (75)
[a0/a72c86] Submitted process > calling_pipeline:ingressCheckpoint (75)
[5c/54cdae] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (58)
[08/06ef49] Submitted process > calling_pipeline:amrCheckpoint (75)
[c0/f88fae] Submitted process > calling_pipeline:perSampleReportingCheckpoint (76)
[a1/943bcb] Submitted process > calling_pipeline:ingressCheckpoint (76)
[4e/85db53] Submitted process > calling_pipeline:amrCheckpoint (76)
[8e/b9fb81] Submitted process > calling_pipeline:variantCheckpoint (76)
[4a/c17f9a] Submitted process > calling_pipeline:variantCheckpoint (77)
[42/f6248e] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (59)
[19/c9965d] Submitted process > calling_pipeline:ingressCheckpoint (77)
[6d/e207a0] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (60)
[6b/d90801] Submitted process > calling_pipeline:amrCheckpoint (77)
[58/85c352] Submitted process > calling_pipeline:perSampleReportingCheckpoint (77)
[4d/badf7c] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (61)
[4c/b19571] Submitted process > calling_pipeline:variantCheckpoint (78)
[0e/76eed6] Submitted process > calling_pipeline:perSampleReportingCheckpoint (78)
[79/23f245] Submitted process > calling_pipeline:ingressCheckpoint (78)
[13/61982e] Submitted process > calling_pipeline:amrCheckpoint (78)
[cb/c51fa3] Submitted process > calling_pipeline:variantCheckpoint (79)
[cb/1cc1b1] Submitted process > calling_pipeline:ingressCheckpoint (79)
[ca/7325c4] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (62)
[de/714648] Submitted process > calling_pipeline:perSampleReportingCheckpoint (79)
[5b/b5cba9] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (63)
[e2/0f9f27] Submitted process > calling_pipeline:amrCheckpoint (79)
[b4/6f9e6d] Submitted process > calling_pipeline:ingressCheckpoint (80)
[44/f84289] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (64)
[c6/17c74a] Submitted process > calling_pipeline:variantCheckpoint (80)
[64/ec40ad] Submitted process > calling_pipeline:perSampleReportingCheckpoint (80)
[39/1f1656] Submitted process > calling_pipeline:amrCheckpoint (80)
[75/69ef0f] Submitted process > calling_pipeline:amrCheckpoint (81)
[7b/540b76] Submitted process > calling_pipeline:perSampleReportingCheckpoint (81)
[f3/9a2d1a] Submitted process > calling_pipeline:ingressCheckpoint (81)
[62/34db15] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (65)
[2f/f27e19] Submitted process > calling_pipeline:variantCheckpoint (81)
[e3/1b15b2] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (66)
[4a/282604] Submitted process > calling_pipeline:ingressCheckpoint (82)
[56/fd1481] Submitted process > calling_pipeline:perSampleReportingCheckpoint (82)
[14/85e589] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (67)
[6c/5e5c76] Submitted process > calling_pipeline:variantCheckpoint (82)
[bc/65646a] Submitted process > calling_pipeline:amrCheckpoint (82)
[85/e0afb6] Submitted process > calling_pipeline:accumulateCheckpoints (1)
[d5/5a8f30] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (68)
[3f/c94a5b] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (69)
[43/b1c3f4] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (70)
[88/de30a9] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (71)
[7e/ce0f1d] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (72)
[d3/791a54] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (73)
[0f/6e1f93] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (74)
[7b/4d1632] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (75)
[04/f0489a] Submitted process > calling_pipeline:accumulateCheckpoints (2)
[35/5ba557] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (76)
[32/3d4225] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (77)
[00/8502b0] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (78)
[37/1ffe2a] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (79)
[bb/4b1010] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (80)
[5b/010ee7] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (81)
[a7/8a79e6] Submitted process > calling_pipeline:collectFastqIngressResultsInDir (82)
[fe/e0173b] Submitted process > calling_pipeline:getVersions
[fd/680d59] Submitted process > calling_pipeline:accumulateCheckpoints (3)
[6d/5dc36f] Submitted process > calling_pipeline:deNovo (1)
[7f/d10bac] Submitted process > calling_pipeline:deNovo (2)
[78/458f0e] Submitted process > calling_pipeline:deNovo (3)
[5a/c575f3] Submitted process > calling_pipeline:deNovo (4)
WARN: Flye failed for sample 'barcode04' due to low coverage.
[29/4fe017] Submitted process > calling_pipeline:deNovo (5)
WARN: Flye failed for sample 'barcode05' due to low coverage.
[98/daad81] Submitted process > calling_pipeline:deNovo (6)
WARN: Flye failed for sample 'barcode03' due to low coverage.
WARN: Flye failed for sample 'barcode06' due to low coverage.
[d6/348376] Submitted process > calling_pipeline:deNovo (7)
WARN: Flye failed for sample 'barcode07' due to low coverage.
[fe/f81427] Submitted process > calling_pipeline:deNovo (8)
[6d/291aa4] Submitted process > calling_pipeline:deNovo (9)
WARN: Flye failed for sample 'barcode09' due to low coverage.
[4a/d12e6c] Submitted process > calling_pipeline:deNovo (10)
WARN: Flye failed for sample 'barcode10' due to low coverage.
[85/1a5916] Submitted process > calling_pipeline:deNovo (11)
[02/3add1d] Submitted process > calling_pipeline:deNovo (12)
WARN: Flye failed for sample 'barcode12' due to low coverage.
[f4/ad798a] Submitted process > calling_pipeline:deNovo (13)
WARN: Flye failed for sample 'barcode13' due to low coverage.
[dd/cb02be] Submitted process > calling_pipeline:deNovo (14)
WARN: Flye failed for sample 'barcode15' due to low coverage.
[59/069145] Submitted process > calling_pipeline:deNovo (15)
[04/64164c] Submitted process > calling_pipeline:deNovo (16)
WARN: Flye failed for sample 'barcode17' due to low coverage.
[b7/394803] Submitted process > calling_pipeline:deNovo (17)
[5f/eb2860] Submitted process > calling_pipeline:deNovo (18)
[c9/8cf992] Submitted process > calling_pipeline:deNovo (19)
WARN: Flye failed for sample 'barcode20' due to low coverage.
[27/f8845b] Submitted process > calling_pipeline:deNovo (20)
WARN: Flye failed for sample 'barcode21' due to low coverage.
[6d/0d9e9b] Submitted process > calling_pipeline:deNovo (21)
WARN: Flye failed for sample 'barcode22' due to low coverage.
[c8/372afa] Submitted process > calling_pipeline:deNovo (22)
WARN: Flye failed for sample 'barcode24' due to low coverage.
[81/e3f3bb] Submitted process > calling_pipeline:deNovo (23)
[23/675ff9] Submitted process > calling_pipeline:deNovo (24)
WARN: Flye failed for sample 'barcode26' due to low coverage.
[3c/5a2ab2] Submitted process > calling_pipeline:deNovo (25)
[c1/91d46a] Submitted process > calling_pipeline:deNovo (26)
WARN: Flye failed for sample 'barcode25' due to low coverage.
[b5/a73599] Submitted process > calling_pipeline:deNovo (27)
WARN: Flye failed for sample 'barcode27' due to low coverage.
WARN: Flye failed for sample 'barcode28' due to low coverage.
[40/beebff] Submitted process > calling_pipeline:deNovo (28)
WARN: Flye failed for sample 'barcode29' due to low coverage.
[2e/916d5e] Submitted process > calling_pipeline:deNovo (29)
WARN: Flye failed for sample 'barcode31' due to low coverage.
[ae/01e1fb] Submitted process > calling_pipeline:deNovo (30)
WARN: Flye failed for sample 'barcode32' due to low coverage.
[3d/2cebeb] Submitted process > calling_pipeline:deNovo (31)
WARN: Flye failed for sample 'barcode33' due to low coverage.
[65/fe94d0] Submitted process > calling_pipeline:deNovo (32)
WARN: Flye failed for sample 'barcode35' due to low coverage.
[fb/5d13ce] Submitted process > calling_pipeline:deNovo (33)
[5a/f8b9ed] Submitted process > calling_pipeline:deNovo (34)
WARN: Flye failed for sample 'barcode37' due to low coverage.
WARN: Flye failed for sample 'barcode36' due to low coverage.
[ec/53fee7] Submitted process > calling_pipeline:deNovo (35)
[4a/18e414] Submitted process > calling_pipeline:deNovo (36)
WARN: Flye failed for sample 'barcode41' due to low coverage.
[b9/8507aa] Submitted process > calling_pipeline:deNovo (37)
[78/8b052a] Submitted process > calling_pipeline:deNovo (38)
[c2/afcba5] Submitted process > calling_pipeline:deNovo (39)
[22/0bc659] Submitted process > calling_pipeline:deNovo (40)
[94/944957] Submitted process > calling_pipeline:deNovo (41)
WARN: Flye failed for sample 'barcode44' due to low coverage.
[50/391f19] Submitted process > calling_pipeline:deNovo (42)
WARN: Flye failed for sample 'barcode45' due to low coverage.
[16/cba003] Submitted process > calling_pipeline:deNovo (43)
[7a/3022dc] Submitted process > calling_pipeline:deNovo (44)
[f6/2e420c] Submitted process > calling_pipeline:deNovo (45)
WARN: Flye failed for sample 'barcode46' due to low coverage.
[35/7509f1] Submitted process > calling_pipeline:deNovo (46)
ERROR ~ Error executing process > 'calling_pipeline:deNovo (45)'
Caused by:
Process `calling_pipeline:deNovo (45)` terminated with an error exit status (1)
Command executed:
COV_FAIL=0
FLYE_EXIT_CODE=0
flye --nano-hq reads.fastq.gz --out-dir output --threads ""3"" || FLYE_EXIT_CODE=$?
if [[ $FLYE_EXIT_CODE -eq 0 ]]; then
mv output/assembly.fasta ""./barcode47.draft_assembly.fasta""
mv output/assembly_info.txt ""./barcode47_flye_stats.tsv""
bgzip ""barcode47.draft_assembly.fasta""
else
# flye failed --> check the log to check why
edge_cov=$(
grep -oP 'Mean edge coverage: \K\d+' output/flye.log || echo 5
)
ovlp_cov=$(
grep -oP 'Overlap-based coverage: \K\d+' output/flye.log || echo 5
)
if [[
$edge_cov -lt 5 ||
$ovlp_cov -lt 5
]]; then
echo -n ""Caught Flye failure due to low coverage (either mean edge cov. or ""
echo ""overlap-based cov. were below 5)"".
COV_FAIL=1
elif grep -q ""No disjointigs were assembled"" output/flye.log; then
echo -n ""Caught Flye failure due to disjointig assembly.""
COV_FAIL=2
else
# exit a subshell with error so that the process fails
( exit $FLYE_EXIT_CODE )
fi
fi
Command exit status:
1
Command output:
(empty)
Command error:
[2024-10-17 10:24:24] INFO: Starting Flye 2.9.3-b1797
[2024-10-17 10:24:24] INFO: >>>STAGE: configure
[2024-10-17 10:24:24] INFO: Configuring run
[2024-10-17 10:24:24] INFO: Total read length: 9712
[2024-10-17 10:24:24] INFO: Reads N50/N90: 9712 / 9712
[2024-10-17 10:24:24] INFO: Minimum overlap set to 10000
[2024-10-17 10:24:24] INFO: >>>STAGE: assembly
[2024-10-17 10:24:24] INFO: Assembling disjointigs
[2024-10-17 10:24:24] INFO: Reading sequences
[2024-10-17 10:24:24] INFO: Building minimizer index
[2024-10-17 10:24:24] INFO: Pre-calculating index storage
[2024-10-17 10:24:24] INFO: Filling index
[2024-10-17 10:24:24] ERROR: Command '['flye-modules', 'assemble', '--reads', 'reads.fastq.gz', '--out-asm', 'output/00-assembly/draft_assembly.fasta', '--config', '/home/epi2melabs/conda/lib/python3.8/site-packages/flye/config/bin_cfg/asm_nano_hq.cfg', '--log', 'output/flye.log', '--threads', '3', '--min-ovlp', '10000']' died with <Signals.SIGFPE: 8>.
[2024-10-17 10:24:24] ERROR: Pipeline aborted
Work dir:
/mnt/c/Users/Sequencing/epi2melabs/instances/wf-bacterial-genomes_01JACZ50KNN6EF71EKC6551GPZ/work/f6/2e420c9a30e20df715e5fddae210f8
Tip: you can replicate the issue by changing to the process work dir and entering the command `bash .command.run`
-- Check '/mnt/c/Users/Sequencing/epi2melabs/instances/wf-bacterial-genomes_01JACZ50KNN6EF71EKC6551GPZ/nextflow.log' file for details
WARN: Killing running tasks (1)
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

yes

### Other demo data information

_No response_",AnjaliSM22,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/46
I_kwDOFIO7Dc6b7C-N,failed to run demo data,CLOSED,2024-10-26T15:37:26Z,2024-10-29T17:10:23Z,2024-10-29T17:10:22Z,"### Operating System

Ubuntu 22.04

### Other Linux

_No response_

### Workflow Version

v1.4.0

### Workflow Execution

Command line (Cluster)

### Other workflow execution

_No response_

### EPI2ME Version

_No response_

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

it look like the sample sheet is invalid 
[nextflow.log](https://github.com/user-attachments/files/17531122/nextflow.log)


### Relevant log output

```shell
}                                                                                                                                                                  
  }' > params.json                                                                                                                                                       
                                                                                                                                                                         
Command exit status:                                                                                                                                                     
executor >  local (3)                                                                                                                                                    
[7f/f1c12d] validate_sample_sheet                               [100%] 1 of 1, failed: 1 âœ˜                                                                               
[-        ] fastcat                                             [  0%] 0 of 2                                                                                            
[-        ] calling_pipeline:ingressCheckpoint                  -                                                                                                        
[-        ] calling_pipeline:deNovo                             -                                                                                                        
[-        ] calling_pipeline:alignReads                         -                                                                                                        
[-        ] calling_pipeline:alignmentCheckpoint                -                                                                                                        
[-        ] calling_pipeline:readStats                          -                                                                                                        
[-        ] calling_pipeline:coverStats                         -                                                                                                        
[-        ] calling_pipeline:splitRegions                       -                                                                                                        
[-        ] calling_pipeline:medakaInference_consensus          -                                                                                                        
[-        ] calling_pipeline:medakaConsensus                    -                                                                                                        
[-        ] calling_pipeline:assemblyCheckpoint                 -                                                                                                        
[93/c80017] calling_pipeline:prokkaVersion                      [100%] 1 of 1, failed: 1 âœ˜                                                                               
[ab/893074] calling_pipeline:getParams                          [100%] 1 of 1, failed: 1 âœ˜                                                                               
Plus 21 more processes waiting for tasksâ€¦                                                                                                                                
Running Denovo assembly.                                                                                                                                                 
ERROR ~ Error executing process > 'calling_pipeline:getParams'                                                                                                           
                                                                                                                                                                         
Caused by:                                                                                                                                                               
  Process `calling_pipeline:getParams` terminated with an error exit status (127)                                                                                        
                                                                                                                                                                         
                                                                                                                                                                         
Command executed:                                                                                                                                                        
                                                                                                                                                                         
  # Output nextflow params object to JSON                                                                                                                                
      echo '{                                                                                                                                                            
      ""fastq"": ""wf-bacterial-genomes-demo/isolates_fastq"",                                                                                                               
      ""isolates"": true,                                                                                                                                                  
      ""sample_sheet"": ""wf-bacterial-genomes-demo/isolates_sample_sheet.csv"",                                                                                             
[1] 0:[tmux]*                                                                                                                                      ""farm"" 08:36 26-Oct-24
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

no

### Other demo data information

_No response_",xiranli007,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/47
I_kwDOFIO7Dc6f2Pwc,alignment.bam output file seems to be missing,OPEN,2024-11-22T04:54:23Z,2024-12-17T17:14:18Z,,"### Ask away!

The workflow completes but I'm not able to locate the alignment.bam file that is listed as one of the outputs. I've had the same issue running in EPI2me desktop and in the command line and using both the V1.4.1 and with earlier versions of the workflow. Is there something specific I need to do to get this file as an output? ",irc47,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/48
I_kwDOFIO7Dc6g5aGM,Barcode trimming,CLOSED,2024-11-27T18:09:49Z,2024-12-03T09:37:09Z,2024-12-03T09:37:09Z,"### Ask away!

Hi, 

We are currently following the [NO-MISS protocol](https://nanoporetech.com/document/no-miss-isolate-sequencing-rapid-barcoding-v14) from nanopore. According to their protocol we leave the Minknown settings at default. In this case barcodes will not be trimmed from the FastQ files. Following their workflow they go straight from the raw data to the bacteria genomes pipeline. 

I am not sure if this pipeline trims the barcodes and if it is neccesary at all? Is there any information on this? ",kevinbretscher,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/49
I_kwDOFIO7Dc6iEZsS,medaka model missing?,CLOSED,2024-12-05T00:37:25Z,2024-12-05T07:31:18Z,2024-12-05T07:31:18Z,"### Ask away!

Hi,
I am trying to use v. 1.4.1 on EPI2ME to process my ONT sequences of bacterial isolates. Should I remove the barcodes in minKNOW before feeding the .fastq files to the bacterial-genomes workflow? I also encountered errors when the workflow tried to pick a medaka model. Any suggestions? 
Please see the error message below:
The full error message was:

Error executing process > 'calling_pipeline:medakaInference_consensus (6)'

Caused by:
  Process `calling_pipeline:medakaInference_consensus (6)` terminated with an error exit status (1)

Command executed:

  medaka --version
      echo dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus
      medaka inference align.bam ""barcode73.consensus_probs.hdf""         --threads 2 --regions ""contig_14:0-247046
  "" --model dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus

Command exit status:
  1

Command output:
  medaka 2.0.0
  dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus

Command error:
  Cannot import pyabpoa, some features may not be available.
  medaka 2.0.0
  dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus
  Cannot import pyabpoa, some features may not be available.
  Failed to interpret 'dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus' as a basecaller model.
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/medaka/medaka.py"", line 35, in __call__
      model_fp = medaka.models.resolve_model(val)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/medaka/models.py"", line 55, in resolve_model
      raise ValueError(
  ValueError: Model dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus is not a known model or existant file.
  
  During handling of the above exception, another exception occurred:
  
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/bin/medaka"", line 8, in 
      sys.exit(main())
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/medaka/medaka.py"", line 822, in main
      args = parser.parse_args()
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1768, in parse_args
      args, argv = self.parse_known_args(args, namespace)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1800, in parse_known_args
      namespace, args = self._parse_known_args(args, namespace)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1988, in _parse_known_args
      positionals_end_index = consume_positionals(start_index)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1965, in consume_positionals
      take_action(action, args)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1874, in take_action
      action(self, namespace, argument_values, option_string)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1159, in __call__
      subnamespace, arg_strings = parser.parse_known_args(arg_strings, None)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1800, in parse_known_args
      namespace, args = self._parse_known_args(args, namespace)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 2006, in _parse_known_args
      start_index = consume_optional(start_index)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1946, in consume_optional
      take_action(action, args, option_string)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1874, in take_action
      action(self, namespace, argument_values, option_string)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/medaka/medaka.py"", line 38, in __call__
      raise RuntimeError(msg.format(self.dest, str(e)))
  RuntimeError: Error validating model from '--model' argument: Model dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus is not a known model or existant file..

Work dir:
  /mnt/c/Users/whleo/epi2melabs/instances/wf-bacterial-genomes_01JE9XMXQTQR0SWHP1696RXH51/work/ee/d102ffc876fd82c0a20d6d03575697

Tip: when you have fixed the problem you can continue the execution adding the option `-resume` to the run command line",hwangumn,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/50
I_kwDOFIO7Dc6iEcdG,Stopped with error - medakaInference_consensus,OPEN,2024-12-05T00:49:58Z,2024-12-05T07:40:27Z,,"### Operating System

Windows 11

### Other Linux

_No response_

### Workflow Version

v.1.4.1

### Workflow Execution

EPI2ME Desktop (Local)

### Other workflow execution

_No response_

### EPI2ME Version

v5.2.2

### CLI command run

_No response_

### Workflow Execution - CLI Execution Profile

None

### What happened?

Stopped with errors when running calling_pipeline:medakaInference_consensus
Seems like the model was missing. 

### Relevant log output

```shell
The exit status of the task that caused the workflow execution to fail was: 1.

The full error message was:

Error executing process > 'calling_pipeline:medakaInference_consensus (6)'

Caused by:
  Process `calling_pipeline:medakaInference_consensus (6)` terminated with an error exit status (1)

Command executed:

  medaka --version
      echo dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus
      medaka inference align.bam ""barcode73.consensus_probs.hdf""         --threads 2 --regions ""contig_14:0-247046
  "" --model dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus

Command exit status:
  1

Command output:
  medaka 2.0.0
  dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus

Command error:
  Cannot import pyabpoa, some features may not be available.
  medaka 2.0.0
  dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus
  Cannot import pyabpoa, some features may not be available.
  Failed to interpret 'dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus' as a basecaller model.
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/medaka/medaka.py"", line 35, in __call__
      model_fp = medaka.models.resolve_model(val)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/medaka/models.py"", line 55, in resolve_model
      raise ValueError(
  ValueError: Model dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus is not a known model or existant file.
  
  During handling of the above exception, another exception occurred:
  
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/bin/medaka"", line 8, in 
      sys.exit(main())
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/medaka/medaka.py"", line 822, in main
      args = parser.parse_args()
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1768, in parse_args
      args, argv = self.parse_known_args(args, namespace)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1800, in parse_known_args
      namespace, args = self._parse_known_args(args, namespace)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1988, in _parse_known_args
      positionals_end_index = consume_positionals(start_index)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1965, in consume_positionals
      take_action(action, args)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1874, in take_action
      action(self, namespace, argument_values, option_string)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1159, in __call__
      subnamespace, arg_strings = parser.parse_known_args(arg_strings, None)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1800, in parse_known_args
      namespace, args = self._parse_known_args(args, namespace)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 2006, in _parse_known_args
      start_index = consume_optional(start_index)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1946, in consume_optional
      take_action(action, args, option_string)
    File ""/home/epi2melabs/conda/lib/python3.8/argparse.py"", line 1874, in take_action
      action(self, namespace, argument_values, option_string)
    File ""/home/epi2melabs/conda/lib/python3.8/site-packages/medaka/medaka.py"", line 38, in __call__
      raise RuntimeError(msg.format(self.dest, str(e)))
  RuntimeError: Error validating model from '--model' argument: Model dna_r10.4.1_e8.2_400bps_fast@v4.3.0:consensus is not a known model or existant file..

Work dir:
  /mnt/c/Users/whleo/epi2melabs/instances/wf-bacterial-genomes_01JE9XMXQTQR0SWHP1696RXH51/work/ee/d102ffc876fd82c0a20d6d03575697

Tip: when you have fixed the problem you can continue the execution adding the option `-resume` to the run command line
```


### Application activity log entry

_No response_

### Were you able to successfully run the latest version of the workflow with the demo data?

Yes

### Other demo data information

_No response_",hwangumn,https://github.com/epi2me-labs/wf-bacterial-genomes/issues/51
