id,title,state,created_at,updated_at,closed_at,body,user,url
MDU6SXNzdWU4OTM3OTczMTg=,Cannot write to --joblog parallel_1_call_var_bam_pileup.log,CLOSED,2021-05-17T23:34:24Z,2021-06-03T14:44:23Z,2021-06-03T14:44:23Z,"Hi, 

I'm  using Clair3 as the following:
`${HOME}/Clair3/run_clair3.sh --bam_fn ~/projects/tests/clair3/HG002.ONT.bam --ref_fn ~/hs37d5_mainchr.fa --threads 10 --platform ont --model_path ~{HOME}/Clair3/modules/ont --output SNVs`

I have this error:

`+ Clair3/scripts/clair3.sh --bam_fn ~/projects/tests/clair3/HG002.ONT.bam --ref_fn ~/hs37d5_mainchr.fa --threads 10 --model_path ${HOME}/Clair3/modules/ont --platform ont --output SNVs --bed_fn=EMPTY --vcf_fn=EMPTY --ctg_name=EMPTY --sample_name=EMPTY --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=0 --var_pct_full=0.3 --ref_pct_full=0.3 --snp_min_af=0.0 --indel_min_af=0.0 --pileup_only=False --gvcf=False --fast_mode=False --print_ref_calls=False --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=False --no_phasing_for_fa=False
[INFO] Check envrionment variables
[INFO] --include_all_ctgs not enabled, use chr{1..22,X,Y} and {1..22,X,Y} by default
[INFO] Call variant in contigs: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y
[INFO] Chunk number for each contig: 50 49 40 39 37 35 32 30 29 28 28 27 24 22 21 19 17 16 12 13 10 11 32 12
[INFO] 1/7 Calling variants using pileup model
tee: SNVs/log/1_call_var_bam_pileup.log: No such file or directory
parallel: Error: Cannot write to --joblog SNVs/log/parallel_1_call_var_bam_pileup.log.`


Thanks,
Medhat",MeHelmy,https://github.com/HKU-BAL/Clair3/issues/5
MDU6SXNzdWU4OTM5MTcxODc=,Require for Singularity image of Clair3,CLOSED,2021-05-18T03:47:15Z,2021-05-26T01:42:11Z,2021-05-26T01:42:11Z,"Hi,
    Since HPC can not support docker, could you provide the singularity image and running example. I converted the docker image to a singularity image and successfully ran `run_clair3.sh --help`.  However, when I tried to call variants, it always outputs the error message as follows:
```
[hpc_hn@node0023 120G]$ singularity exec --bind /public/home/hpc_hn/ont-quickstart/input/120G ~/tools/clair_docker_image/clair3_docker_image.sif /opt/bin/run_clair3.sh -b /public/home/hpc_hn/ont-quickstart/input/120G/hg003_120G.bam -f /public/home/hpc_hn/ont-quickstart/input/120G/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna -t 2 -p ont -m /public/home/hpc_hn/ont-quickstart/input/120G/ont -o /public/home/hpc_hn/ont-quickstart/input/120G/output
[INFO] BAM FILE PATH: /public/home/hpc_hn/ont-quickstart/input/120G/hg003_120G.bam
[INFO] REFERENCE FILE PATH: /public/home/hpc_hn/ont-quickstart/input/120G/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna
[INFO] MODEL PATH: /public/home/hpc_hn/ont-quickstart/input/120G/ont
[INFO] OUTPUT FOLDER: /public/home/hpc_hn/ont-quickstart/input/120G/output
[INFO] PLATFORM: ont
[INFO] THREADS: 2
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] CHUNK SIZE: 5000000
[INFO] CHUNK NUM: 0
[INFO] FULL ALIGN PROPORTION: 0.3
[INFO] FULL ALIGN RERFERENCE PROPORTION: 0.3
[INFO] USER DEFINED SNP THRESHOLD: 0.0
[INFO] USER DEFINED INDEL THRESHOLD: 0.0
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False

+ /opt/bin/scripts/clair3.sh --bam_fn /public/home/hpc_hn/ont-quickstart/input/120G/hg003_120G.bam --ref_fn /public/home/hpc_hn/ont-quickstart/input/120G/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna --threads 2 --model_path /public/home/hpc_hn/ont-quickstart/input/120G/ont --platform ont --output /public/home/hpc_hn/ont-quickstart/input/120G/output --bed_fn=EMPTY --vcf_fn=EMPTY --ctg_name=EMPTY --sample_name=EMPTY --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=0 --var_pct_full=0.3 --ref_pct_full=0.3 --snp_min_af=0.0 --indel_min_af=0.0 --pileup_only=False --gvcf=False --fast_mode=False --print_ref_calls=False --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=False --no_phasing_for_fa=False
[INFO] Check envrionment variables
[INFO] --include_all_ctgs not enabled, use chr{1..22,X,Y} and {1..22,X,Y} by default
[INFO] Call variant in contigs: chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY
[INFO] Chunk number for each contig: 50 49 40 39 37 35 32 30 28 27 28 27 23 22 21 19 17 17 12 13 10 11 32 12
[INFO] 1/7 Calling variants using pileup model
[INFO] Delay 7 seconds before starting variant calling ...
taskset: failed to set pid 0's affinity: Invalid argument
[mpileup] 1 samples in 1 input files
Traceback (most recent call last):
  File ""/opt/bin/clair3/../clair3.py"", line 89, in <module>
    main()
  File ""/opt/bin/clair3/../clair3.py"", line 83, in main
    submodule.main()
  File ""/opt/bin/preprocess/CreateTensorPileup.py"", line 550, in main
    CreateTensorPileup(args)
  File ""/opt/bin/preprocess/CreateTensorPileup.py"", line 414, in CreateTensorPileup
    tensor_can_fp.stdin.write(l)
BrokenPipeError: [Errno 32] Broken pipe
```",huangnengCSU,https://github.com/HKU-BAL/Clair3/issues/6
MDU6SXNzdWU4OTQ1MTE2MDE=,bai file strict input,CLOSED,2021-05-18T15:33:18Z,2021-05-25T07:50:30Z,2021-05-25T07:50:30Z,"Hi, congratulations with Clair3!

Minor issue: could not run Clair3 in docker as described [here](https://github.com/HKU-BAL/Clair3/blob/main/docs/quick_demo/ont_quick_demo.md#option-1-docker-pre-built-image) as my bai file was not found. Turns out it needed to be filename.bam.bai instead of filename.bai. A suggestion would be to make that clear/allow for more bai filenames.


",KewinOgink,https://github.com/HKU-BAL/Clair3/issues/10
MDU6SXNzdWU4OTQ4ODQ4MzQ=,Calir3 ignores the bed file supported by --bed_fn,CLOSED,2021-05-19T00:33:16Z,2021-06-03T14:44:13Z,2021-06-03T14:44:13Z,"Calling variant using bed file:

`run_clair3.sh --bam_fn ${HOME}/clair3/HG002.ONT.bam --ref_fn /${HOME}/hs37d5_mainchr.fa --threads 10 --platform ont --${HOME}/Clair3/modules/ont --output ${HOME}/chr22 --bed_fn ${HOME}/chr22.bed`

cat chr22.bed:
`22	1	10000000`

The issue is Clair3 begin to call variant for chr1 !!

I take a look at chr22/run_clair3.log

`Clair3/scripts/clair3.sh --bam_fn ${HOME}/HG002.ONT.bam --ref_fn /users/mmahmoud/home/public_workplace/scripts/snakefiles/test/hs37d5_mainchr.fa --threads 10 --model_path /users/mmahmoud/home/projects/princess/Clair3/modules/ont --platform ont --output ${HOME}/chr22 --bed_fn= --vcf_fn=EMPTY --ctg_name=EMPTY --sample_name=EMPTY --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=0 --var_pct_full=0.3 --ref_pct_full=0.3 --snp_min_af=0.0 --indel_min_af=0.0 --pileup_only=False --gvcf=False --fast_mode=False --print_ref_calls=False --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=False --no_phasing_for_fa=False`

As you can see, `--bed_fn= ` is empty.
Additionally,  we have this warning `scripts/clair3.sh: line 58: [: =: unary operator expected`


Best,
Medhat
",MeHelmy,https://github.com/HKU-BAL/Clair3/issues/12
MDU6SXNzdWU4OTU1MzE5NDk=,performance with default ont model worse than clair2,CLOSED,2021-05-19T14:40:32Z,2021-06-28T15:06:04Z,2021-05-24T03:52:43Z,"Hi,

I tested a dataset with clair2 and the pretrained ont model [HG001,2,2HD,3,4
](https://github.com/HKU-BAL/Clair#pretrained-models) and compared it with the new clair3 default ont model ([HG001,2,4,5](https://github.com/HKU-BAL/Clair3/blob/main/docs/training_data.md#pre-trained-model))on the same sample.




<meta name=""ProgId"" content=""Excel.Sheet"">
<meta name=""Generator"" content=""Microsoft Excel 15"">
<link id=""Main-File"" rel=""Main-File"" href=""file:///C:/Users/376946/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">
<link rel=""File-List"" href=""file:///C:/Users/376946/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">
<style>
<!--table
	{mso-displayed-decimal-separator:""\."";
	mso-displayed-thousand-separator:""\,"";}
@page
	{mso-header-data:""&R&\0022Calibri\0022&10&K737373Confidential&1\#"";
	margin:.75in .7in .75in .7in;
	mso-header-margin:.3in;
	mso-footer-margin:.3in;}
tr
	{mso-height-source:auto;}
col
	{mso-width-source:auto;}
br
	{mso-data-placement:same-cell;}
td
	{padding-top:1px;
	padding-right:1px;
	padding-left:1px;
	mso-ignore:padding;
	color:black;
	font-size:11.0pt;
	font-weight:400;
	font-style:normal;
	text-decoration:none;
	font-family:Calibri, sans-serif;
	mso-font-charset:0;
	mso-number-format:General;
	text-align:general;
	vertical-align:bottom;
	border:none;
	mso-background-source:auto;
	mso-pattern:auto;
	mso-protection:locked visible;
	white-space:nowrap;
	mso-rotate:0;}
.xl65
	{color:black;}
.xl66
	{color:black;
	font-weight:700;}
.xl67
	{color:black;
	font-weight:700;
	background:#B4C6E7;
	mso-pattern:black none;}
.xl68
	{color:black;
	background:#B4C6E7;
	mso-pattern:black none;}
.xl69
	{background:#B4C6E7;
	mso-pattern:black none;}
.xl70
	{font-weight:700;}
.xl71
	{color:black;
	font-weight:700;}
-->
</style>





Clair2 | Type | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.TOTAL | QUERY.FP | QUERY.UNK | FP.gt | Recall | Precision | Frac_NA | .F1_Score
-- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --
ont_DP10_AF0.7 | INDEL | 1681 | 817 | 864 | 34981 | 34129 | 0 | 7 | 0.48602 | 0.024356 | 0 | 0.046388
&nbsp; | SNP | 20759 | 19776 | 983 | 24744 | 3483 | 0 | 28 | 0.952647 | 0.859239 | 0 | 0.903535
Clair3 | &nbsp; | &nbsp; | &nbsp; | &nbsp; | &nbsp; | &nbsp; | &nbsp; | &nbsp; | &nbsp; | &nbsp; | &nbsp; | &nbsp;
ont_DP10_AF0.7_all_merge | INDEL | 1681 | 629 | 1052 | 33590 | 32932 | 0 | 9 | 0.374182 | 0.019589 | 0 | 0.037229
&nbsp; | SNP | 20759 | 19599 | 1160 | 24230 | 3112 | 0 | 27 | 0.944121 | 0.871564 | 0 | 0.906393
















The precision and f1 of clair3 here is higher on SNPs, but the SNP recall and overall INDEL score is worse. Is this due to the training data difference? I used the same (default) settings and data, but I noticed the training data for clair2 and 3 are slightly different? ",KewinOgink,https://github.com/HKU-BAL/Clair3/issues/13
MDU6SXNzdWU5MDIwNzI3NTA=,Some errors in Representation Unification,CLOSED,2021-05-26T09:15:27Z,2021-09-07T12:09:32Z,2021-09-07T12:09:32Z,"Hi, 
    In the steps of generating unified VCFs, a command is missing and a parameter is used incorrectly, which results in an error. In step 2, there should be a command `${PARALLEL} -j ${THREADS} ${TABIX} -p vcf ${PHASE_VCF_PATH}/phased_{1}.vcf.gz ::: ${CHR[@]}` behind the command `whatshap phase`. In step 4, the parameter `THRESHOLD` is not given and I think it should replaced by `MIN_AF`. 

Best,
Neng Huang
",huangnengCSU,https://github.com/HKU-BAL/Clair3/issues/16
MDU6SXNzdWU5MDUzODAyNzg=,SelectCandidates phasing default behaviour,CLOSED,2021-05-28T13:10:14Z,2021-05-30T11:16:33Z,2021-05-30T11:16:33Z,"https://github.com/HKU-BAL/Clair3/blob/c1517320e18ea0ca04f04256fb530e41219d60d0/preprocess/SelectCandidates.py#L352-353

The parameter `--phasing_info_in_bam` is defined `store_false`, which means it is true by default, in contradiction to the description. Which is the expected behaviour?",ftostevin,https://github.com/HKU-BAL/Clair3/issues/17
MDU6SXNzdWU5MDcyOTkzNTY=,errors in Pileup model fine-tune,CLOSED,2021-05-31T09:37:19Z,2021-06-01T02:11:17Z,2021-06-01T02:11:17Z,"Hi, 
    I trained a Clair3 pileup model and the output in each epoch has 2 files. But in your official ONT pileup model, there are 3 corresponding files. I think the training procedure of pileup consists of two steps. The first training step makes the parameter `--add_indel_length` false and the second fine-tune step makes the parameter `--add_indel_length` true. But when I run fine-tune, there is some error information.
Step 1, training with --add_indel_length=False:
```
CUDA_VISIBLE_DEVICES=5 python3.6 /homeb/tools/Clair3/clair3.py Train \
--bin_fn /homeb/data/NA12878-SNP/clair3_train/output/build/bins/ \
--ochk_prefix clair3 \
--pileup \
--add_indel_length False \
--validation_dataset \
--platform ont
```
best epoch result:
```
(clair3) user@ubuntu:/homeb/data/NA12878-SNP/clair3_train/clair3/29/variables$ ls -l
total 16216
-rw-rw-r-- 1 user user 16594111 May 23 14:55 variables.data-00000-of-00001
-rw-rw-r-- 1 user user     4267 May 23 14:55 variables.index
```
Step 2, fine-tune with  --add_indel_length=True:
```
CUDA_VISIBLE_DEVICES=6 python3.6 /homeb/tools/Clair3/clair3.py Train \
--pileup \
--bin_fn ""/homeb/data/NA12878-SNP/clair3_train/output/build/bins/"" \
--ochk_prefix ""/homeb/data/NA12878-SNP/clair3_train/clair3_add_indel"" \
--add_indel_length True \
--validation_dataset \
--platform ""ont"" \
--learning_rate 0.0001 \
--chkpnt_fn ""/homeb/data/NA12878-SNP/clair3_train/clair3/29""  ## use pre-trained pileup model here
```
Output error information:
```
2021-05-31 16:07:28.043909: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
/home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). 
 The versions of TensorFlow you are currently using is 2.5.0 and is not supported. 
Some things might work, some things might not.
If you were to encounter a bug, do not file an issue.
If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. 
You can find the compatibility matrix in TensorFlow Addon's readme:
https://github.com/tensorflow/addons
  UserWarning,
2021-05-31 16:07:29.909291: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2021-05-31 16:07:33.781545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:b1:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-05-31 16:07:33.781649: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-05-31 16:07:33.786525: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2021-05-31 16:07:33.786647: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2021-05-31 16:07:33.788136: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2021-05-31 16:07:33.788627: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2021-05-31 16:07:33.790647: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
2021-05-31 16:07:33.792302: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2021-05-31 16:07:33.792728: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2021-05-31 16:07:33.796474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2021-05-31 16:07:33.796918: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-05-31 16:07:33.886699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:b1:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-05-31 16:07:33.893519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2021-05-31 16:07:33.893591: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-05-31 16:07:35.053465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-31 16:07:35.053528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 
2021-05-31 16:07:35.053538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N 
2021-05-31 16:07:35.057246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9659 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:b1:00.0, compute capability: 7.5)
[INFO] total 22 training bin files: na12878_900_21_1,na12878_900_22_1,na12878_900_16_1,na12878_900_18_1,na12878_900_19_1,na12878_900_15_1,na12878_900_17_1,na12878_900_14_1,na12878_900_X_1,na12878_900_13_1,na12878_900_9_1,na12878_900_12_1,na12878_900_11_1,na12878_900_10_1,na12878_900_8_1,na12878_900_4_1,na12878_900_7_1,na12878_900_5_1,na12878_900_6_1,na12878_900_3_1,na12878_900_1_1,na12878_900_2_1
/home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  ""The `lr` argument is deprecated, use `learning_rate` instead."")
2021-05-31 16:07:36.720948: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2021-05-31 16:07:41.337494: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100
2021-05-31 16:07:41.585073: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2021-05-31 16:07:47.280088: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
Model: ""clair3_p""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
bidirectional (Bidirectional multiple                  150528    
_________________________________________________________________
bidirectional_1 (Bidirection multiple                  533760    
_________________________________________________________________
dropout (Dropout)            multiple                  0         
_________________________________________________________________
flatten (Flatten)            multiple                  0         
_________________________________________________________________
dense (Dense)                multiple                  1351808   
_________________________________________________________________
dropout_1 (Dropout)          multiple                  0         
_________________________________________________________________
dense_1 (Dense)              multiple                  16512     
_________________________________________________________________
dropout_2 (Dropout)          multiple                  0         
_________________________________________________________________
dense_2 (Dense)              multiple                  16512     
_________________________________________________________________
dropout_3 (Dropout)          multiple                  0         
_________________________________________________________________
dense_3 (Dense)              multiple                  2709      
_________________________________________________________________
dense_4 (Dense)              multiple                  387       
_________________________________________________________________
softmax (Softmax)            multiple                  0         
=================================================================
Total params: 2,072,216
Trainable params: 2,072,216
Non-trainable params: 0
_________________________________________________________________
None
[INFO] The size of dataset: 20576250
[INFO] The training batch size: 2000
[INFO] The training learning_rate: 0.0001
[INFO] Total training steps: 277777
[INFO] Maximum training epoch: 30
[INFO] Start training...
2021-05-31 16:07:47.303398: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open /homeb/tools/Clair3_train/clair3/29: Failed precondition: /homeb/tools/Clair3_train/clair3/29; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?
2021-05-31 16:07:47.382239: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2021-05-31 16:07:47.400761: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2100000000 Hz
Epoch 1/30
Traceback (most recent call last):
  File ""/homeb/tools/Clair3/clair3.py"", line 89, in <module>
    main()
  File ""/homeb/tools/Clair3/clair3.py"", line 83, in main
    submodule.main()
  File ""/homeb/tools/Clair3/clair3/Train.py"", line 304, in main
    train_model(args)
  File ""/homeb/tools/Clair3/clair3/Train.py"", line 242, in train_model
    shuffle=False)
  File ""/home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1183, in fit
    tmp_logs = self.train_function(iterator)
  File ""/home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 889, in __call__
    result = self._call(*args, **kwds)
  File ""/home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 933, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 764, in _initialize
    *args, **kwds))
  File ""/home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3050, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File ""/home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3444, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3289, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 999, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 672, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 986, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *
        return step_function(self, iterator)
    /home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica
        return fn(*args, **kwargs)
    /home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **
        outputs = model.train_step(data)
    /home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:797 train_step
        y, y_pred, sample_weight, regularization_losses=self.losses)
    /home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/compile_utils.py:187 __call__
        self.build(y_pred)
    /home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/compile_utils.py:135 build
        self._losses = self._conform_to_outputs(y_pred, self._losses)
    /home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/compile_utils.py:59 _conform_to_outputs
        struct = map_to_output_names(outputs, self._output_names, struct)
    /home/user/miniconda3/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/compile_utils.py:654 map_to_output_names
        struct.keys(), output_names))

    ValueError: Found unexpected keys that do not correspond to any Model output: dict_keys(['output_3', 'output_4']). Expected: ['output_1', 'output_2']

Closing remaining open files:/homeb/tools/Clair3_train/output/build/bins/na12878_900_18_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_X_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_10_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_17_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_22_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_12_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_7_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_6_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_2_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_21_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_4_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_1_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_19_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_13_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_10_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_22_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_17_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_12_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_8_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_7_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_6_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_3_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_2_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_19_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_13_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_8_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_16_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_14_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_11_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_5_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_3_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_9_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_15_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_9_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_4_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_16_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_14_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_11_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_5_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_1_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_21_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_18_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_15_1...done/homeb/tools/Clair3_train/output/build/bins/na12878_900_X_1...done
```
",huangnengCSU,https://github.com/HKU-BAL/Clair3/issues/19
MDU6SXNzdWU5MDg5NDIwOTc=,problem in detect variants using self-trained model,CLOSED,2021-06-02T01:22:48Z,2021-06-11T00:37:02Z,2021-06-11T00:37:02Z,"Hi,
    I have trained a pileup model (pre-trained + fine-tune) and the output model seems intact. The name of model files are replaced with `pileup` and combined with provided full_alignment model. I used the pileup model and full_alignment model to detect variants. Then the command occurs two kinds of errors. 
    The first kind of error does not occur at a fixed location or time when the command is re-executed. And sometimes this type of error does not occur. The following two log outputs are examples of this type of error.

```
Processed 640000 tensors
Processed 660000 tensors
Total process positions in chr18 with chunk 13/17 : 662097
Total time elapsed: 900.00 s
parallel: This job failed:

python3 /public/home/huangneng/code/Clair3/scripts/../clair3.py CallVarBam \
--chkpnt_fn /public/home/huangneng/tools/clair3-model/clair3_finetune/pileup \
--bam_fn /public/home/huangneng/ont-quickstart/input/120G/hg003_120G.bam \
--call_fn /public/home/huangneng/ont-quickstart/input/120G/clair3_selftraining/output/tmp/pileup_output/pileup_chr18_14.vcf \
--sampleName EMPTY \
--ref_fn /public/home/huangneng/ont-quickstart/input/120G/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna \
--extend_bed /public/home/huangneng/ont-quickstart/input/120G/clair3_selftraining/output/tmp/split_beds/chr18 \
--bed_fn \
--vcf_fn EMPTY \
--ctgName chr18 \
--chunk_id 14 \
--chunk_num 17 \
--platform ont \
--fast_mode False \
--snp_min_af 0.0 \
--indel_min_af 0.0 \
--gvcf False \
--python python3 \
--pypy pypy3 \
--samtools samtools \
--temp_file_dir /public/home/huangneng/ont-quickstart/input/120G/clair3_selftraining/output/tmp/gvcf_tmp_output \
--pileup

real    228m52.610s
user    9075m11.206s
sys     847m57.569s

[INFO] Merge chunked contigs vcf files
[INFO] 2/7 Filter Hete SNP varaints for Whatshap phasing and haplotag
[INFO] Select phasing quality cut off 17
[INFO] Total hete snp positions pass filtering: chr22: 0
[INFO] Total hete snp positions pass filtering: chr20: 19521
[INFO] Total hete snp positions pass filtering: chr19: 38371
[INFO] Total hete snp positions pass filtering: chr21: 2615
[INFO] Total hete snp positions pass filtering: chr11: 105028
[INFO] Total hete snp positions pass filtering: chrX: 0
[INFO] Total hete snp positions pass filtering: chr18: 63294
[INFO] Total hete snp positions pass filtering: chrY: 0
[INFO] Total hete snp positions pass filtering: chr16: 68964
[INFO] Total hete snp positions pass filtering: chr13: 73883
[INFO] Total hete snp positions pass filtering: chr12: 106369
[INFO] Total hete snp positions pass filtering: chr9: 109798
[INFO] Total hete snp positions pass filtering: chr8: 125622
[INFO] Total hete snp positions pass filtering: chr17: 69591
[INFO] Total hete snp positions pass filtering: chr6: 138924
[INFO] Total hete snp positions pass filtering: chr7: 128983
[INFO] Total hete snp positions pass filtering: chr10: 114092
[INFO] Total hete snp positions pass filtering: chr5: 139377
[INFO] Total hete snp positions pass filtering: chr14: 72464
[INFO] Total hete snp positions pass filtering: chr15: 70208
[INFO] Total hete snp positions pass filtering: chr4: 159925
[INFO] Total hete snp positions pass filtering: chr3: 147225
[INFO] Total hete snp positions pass filtering: chr2: 179619
[INFO] Total hete snp positions pass filtering: chr1: 169383

real    4m40.428s
user    105m48.514s
sys     2m16.621s
```
```
Total process positions in chr8 with chunk 18/30 : 659427
Total time elapsed: 606.44 s
[INFO] Delay 2 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total process positions in chr9 with chunk 9/28 : 0
Total time elapsed: 0.01 s
[INFO] No vcf output for file /public/home/huangneng/ont-quickstart/input/120G/clair3_selftraining/debug_output/tmp/pileup_output/pileup_chr9_10.vcf, remove empty file
parallel: This job failed:
python3 /public/home/huangneng/code/Clair3/scripts/../clair3.py CallVarBam \
--chkpnt_fn /public/home/huangneng/tools/clair3-model/clair3_finetune/pileup \
--bam_fn /public/home/huangneng/ont-quickstart/input/120G/hg003_120G.bam \
--call_fn /public/home/huangneng/ont-quickstart/input/120G/clair3_selftraining/debug_output/tmp/pileup_output/pileup_chr9_10.vcf \
--sampleName EMPTY \
--ref_fn /public/home/huangneng/ont-quickstart/input/120G/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna \
-extend_bed /public/home/huangneng/ont-quickstart/input/120G/clair3_selftraining/debug_output/tmp/split_beds/chr9 \
--bed_fn \
--vcf_fn EMPTY \
--ctgName chr9 \
--chunk_id 10 \
--chunk_num 28 \
--platform ont \
--fast_mode False \
--snp_min_af 0.0 \
--indel_min_af 0.0 \
--gvcf False \
--python python3 \
--pypy pypy3 \
--samtools samtools \
--temp_file_dir /public/home/huangneng/ont-quickstart/input/120G/clair3_selftraining/debug_output/tmp/gvcf_tmp_output \
--pileup

real    149m55.489s
user    4785m4.119s
sys     444m19.105s
[INFO] Merge chunked contigs vcf files
[INFO] 2/7 Filter Hete SNP varaints for Whatshap phasing and haplotag
[INFO] Select phasing quality cut off 17
[INFO] Total hete snp positions pass filtering: chr18: 0
[INFO] Total hete snp positions pass filtering: chr15: 0
[INFO] Total hete snp positions pass filtering: chr12: 0
[INFO] Total hete snp positions pass filtering: chr21: 0
[INFO] Total hete snp positions pass filtering: chr13: 0
[INFO] Total hete snp positions pass filtering: chrY: 0
[INFO] Total hete snp positions pass filtering: chr19: 0
[INFO] Total hete snp positions pass filtering: chr11: 0
[INFO] Total hete snp positions pass filtering: chr22: 0
[INFO] Total hete snp positions pass filtering: chr17: 0
[INFO] Total hete snp positions pass filtering: chr16: 0
[INFO] Total hete snp positions pass filtering: chr9: 7006
[INFO] Total hete snp positions pass filtering: chrX: 0
[INFO] Total hete snp positions pass filtering: chr10: 0
[INFO] Total hete snp positions pass filtering: chr14: 0
[INFO] Total hete snp positions pass filtering: chr4: 160039
[INFO] Total hete snp positions pass filtering: chr8: 110917
[INFO] Total hete snp positions pass filtering: chr6: 139017
[INFO] Total hete snp positions pass filtering: chr5: 139442
[INFO] Total hete snp positions pass filtering: chr20: 0
[INFO] Total hete snp positions pass filtering: chr3: 147298
[INFO] Total hete snp positions pass filtering: chr1: 169478
[INFO] Total hete snp positions pass filtering: chr7: 129048
[INFO] Total hete snp positions pass filtering: chr2: 179713

real    2m47.910s
user    60m29.533s
sys     1m19.845s
```
  
  The second type of error appears in the step of `Calling variants using Full Alignment`. Here is the output log.
```
[INFO] Delay 1 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total process positions in chr1 : 10000
Total time elapsed: 71.62 s
[INFO] Delay 2 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total process positions in chr1 : 10000
Total time elapsed: 72.46 s
parallel: This job failed:

python3 /public/home/huangneng/code/Clair3/scripts/../clair3.py CallVarBam \
--chkpnt_fn /public/home/huangneng/tools/clair3-model/RNN+CNN_finetune/full_alignment \
--bam_fn /public/home/huangneng/ont-quickstart/input/120G/clair3_modify/debug_output/tmp/phase_output/phase_bam/chr1.bam \
--call_fn /public/home/huangneng/ont-quickstart/input/120G/clair3_modify/debug_output/tmp/full_alignment_output/full_alignment_chr1.28_316.vcf \
--sampleName EMPTY \
--vcf_fn EMPTY \
--ref_fn /public/home/huangneng/ont-quickstart/input/120G/GCA_000001405.15_GRCh38_no_alt_plus_hs38d1_analysis_set.fna \
--full_aln_regions /public/home/huangneng/ont-quickstart/input/120G/clair3_modify/debug_output/tmp/full_alignment_output/candidate_bed/chr1.28_316 \
--ctgName chr1 \
--add_indel_length \
--phasing_info_in_bam \
--gvcf False \
--python python3 \
--pypy pypy3 \
--samtools samtools \
--platform ont

real    1m34.682s
user    58m25.445s
sys     4m16.988s
[INFO] 7/7 Merge pileup vcf and full alignment vcf
Merge pileup and full alignment VCF/GVCF
[INFO] Pileup variants proceeded in chrY: 56779
[INFO] Full alignment variants proceeded in chrY: 0
Merge pileup and full alignment VCF/GVCF
[INFO] Pileup variants proceeded in chr8: 438770
[INFO] Full alignment variants proceeded in chr8: 0
Merge pileup and full alignment VCF/GVCF
[INFO] Pileup variants proceeded in chr13: 314341
[INFO] Full alignment variants proceeded in chr13: 0
```
I extracted the failed job and performed this job independently, it did not occur any error, the following is the output information.
```
[mpileup] 1 samples in 1 input files
Calling variants ...
Total process positions in chr1 : 10000
Total time elapsed: 33.62 s
[INFO] Delay 6 seconds before starting variant calling ...
```",huangnengCSU,https://github.com/HKU-BAL/Clair3/issues/20
MDU6SXNzdWU5MTA0NjM0NDg=,link in docker install broken,CLOSED,2021-06-03T12:53:01Z,2021-06-08T21:03:55Z,2021-06-08T21:03:55Z,"Hi all!

Minor bug, not related to claire3. 
But the installation instruction feature a broken link:

`
Installation
Option 1. Docker pre-built image
A pre-built docker image is available here. With it you can run Clair3 using a single command.
`

I had to manually search for the image, which I think is this? https://hub.docker.com/r/hkubal/clair3

Btw, is there a preferred method of installation? or should all function pretty much the same. 

THanks!",fidibidi,https://github.com/HKU-BAL/Clair3/issues/22
MDU6SXNzdWU5MTE3OTI2Mjc=,Step 6 tmp/phase_output/phase_bam/.bam no found error,CLOSED,2021-06-04T19:51:03Z,2021-06-09T09:32:04Z,2021-06-09T07:43:52Z,"Hi, 

Thank you for developing the Clair3.

I have met the same unexpected error either running Clair3 using the singularity image or the one installed via the conda method. 
The command I used:

                run_clair3.sh \
                --bam_fn=${NANO_BAM} \
                --ref_fn=${REF} \
                --threads=32 \
                --platform=""ont"" \
                --model_path=""./models/ont"" \
                --output=${BASE}/CLAIR3_CONDA \
                --sample_name='HG002' \
                --chunk_size=10000000 \
                --include_all_ctgs

The error information of the following pattern occurred multiple times at the end the running:

                [INFO] 6/7 Calling variants using Full Alignment
                [ERROR] file /scratch1/bwu4/NEW_XIAO/CLAIR3_CONDA/tmp/phase_output/phase_bam/.bam not found
                parallel: This job failed:
                python3 /home/bwu4/bin/Clair3/scripts/../clair3.py CallVarBam     --chkpnt_fn /scratch1/bwu4/NEW_XIAO/SHASTA_RAGTAG/HG002/./models/ont/full_alignment     --bam_fn /scratch1/bwu4/N                                           EW_XIAO/CLAIR3_CONDA/tmp/phase_output/phase_bam/''.bam     --call_fn /scratch1/bwu4/NEW_XIAO/CLAIR3_CONDA/tmp/full_alignment_output/full_alignment_''.vcf     --sampleName HG002                                                --vcf_fn EMPTY     --ref_fn /scratch1/bwu4/NEW_XIAO/SHASTA_RAGTAG/HG002/HG002_SHA_RAG.fasta     --full_aln_regions ''     --ctgName ''     --add_indel_length     --phasing_info_                                           in_bam     --gvcf False     --python python3     --pypy pypy3     --samtools samtools     --platform ont
                
                real    0m0.464s
                user    0m0.499s
                sys     0m0.252s
                cat: '/scratch1/bwu4/NEW_XIAO/CLAIR3_CONDA/tmp/full_alignment_output/full_alignment_*.vcf': No such file or directory
                [ERROR] No vcf file found, please check the setting
                      
The following are the chromosomal names in my reference fasta file:

          >chr1_RagTag
          >chr10_RagTag
          >chr11_RagTag
          >chr12_RagTag
          >chr13_RagTag
          >chr14_RagTag
          >chr15_RagTag
          >chr16_RagTag
          >chr17_RagTag
          >chr18_RagTag
          >chr19_RagTag
          >chr2_RagTag
          >chr20_RagTag
          >chr21_RagTag
          >chr22_RagTag
          >chr3_RagTag
          >chr4_RagTag
          >chr5_RagTag
          >chr6_RagTag
          >chr7_RagTag
          >chr8_RagTag
          >chr9_RagTag
          >chrX_RagTag
          >chrY_RagTag
The tagged bams have been successfully generated for all 24 chromosomes. Could you help me figure out what the problem is? Thank you very much.

Best,
Bo

",aragornwubo,https://github.com/HKU-BAL/Clair3/issues/23
MDU6SXNzdWU5MTU0OTgxNzc=,ERROR /home/ec2-user/claire3/output-final/tmp/phase_output/phase_bam/.bam not found,CLOSED,2021-06-08T20:57:07Z,2021-06-10T14:26:31Z,2021-06-10T14:26:31Z,"Hello!

Been enjoying playing around with this software, and haven't had issues until running it on a ONT Flongle dataset. 
I have noted that this issue is very similar to the issue right before mine, however, reading through and trying to apply some of the suggestions there didn't seem to be the issue? 

Ran the following command, 
`./run_clair3.sh --bam_fn=${INPUT_DIR}/A0035.bam --ref_fn=${INPUT_DIR}/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --threads=""8"" --sample_name=""A0035"" --platform=""ont"" --model_path=`pwd`""/models/ont"" --output=${OUTPUT_DIR}`

It seems to make it to step 6/7, where the following error is given 


`[INFO] 6/7 Calling variants using Full Alignment
ESC[91m[ERROR] file /home/ec2-user/claire3/output-final/tmp/phase_output/phase_bam/.bam not foundESC[0m
parallel: This job failed:
python3 /home/ec2-user/Clair3/scripts/../clair3.py CallVarBam     --chkpnt_fn /home/ec2-user/Clair3/models/ont/full_alignment     --bam_fn /home/ec2-user/claire3/output-final/tmp/phase_output/phase_bam/''.bam     --call_fn /home/ec2-user/claire3/output-final/tmp/full_alignment_output/full_alignment_''.vcf     --sampleName A0035     --vcf_fn EMPTY     --ref_fn /home/ec2-user/claire3/input/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna     --full_aln_regions ''     --ctgName ''     --add_indel_length     --phasing_info_in_bam     --gvcf False     --python python3     --pypy pypy3     --samtools samtools     --platform ont
ESC[91m[ERROR] file /home/ec2-user/claire3/output-final/tmp/phase_output/phase_bam/.bam not foundESC[0m
parallel: This job failed:
python3 /home/ec2-user/Clair3/scripts/../clair3.py CallVarBam     --chkpnt_fn /home/ec2-user/Clair3/models/ont/full_alignment     --bam_fn /home/ec2-user/claire3/output-final/tmp/phase_output/phase_bam/''.bam     --call_fn /home/ec2-user/claire3/output-final/tmp/full_alignment_output/full_alignment_''.vcf     --sampleName A0035     --vcf_fn EMPTY     --ref_fn /home/ec2-user/claire3/input/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna     --full_aln_regions ''     --ctgName ''     --add_indel_length     --phasing_info_in_bam     --gvcf False     --python python3     --pypy pypy3     --samtools samtools     --platform ont

real    0m0.188s
user    0m0.767s
sys     0m0.175s
cat: /home/ec2-user/claire3/output-final/tmp/full_alignment_output/full_alignment_*.vcf: No such file or directory
ESC[91m[ERROR] No vcf file found, please check the settingESC[0m
`

I've gone ahead and made a google drive of the output, as hopefully, this can be useful for helping determine the issue.
https://drive.google.com/drive/folders/1NHXW76whGZCwRbzvcfBr5n8hYt8uafiO?usp=sharing ",fidibidi,https://github.com/HKU-BAL/Clair3/issues/24
MDU6SXNzdWU5MTU5MTYyMzg=,Corrupted VCF headers,CLOSED,2021-06-09T08:06:00Z,2021-06-10T19:18:31Z,2021-06-10T13:19:02Z,"Hi,

I am very much impressed by the speed and accuracy of Clair3! But I noticed that for some of my merge_output.vcf.gz output files the header line gets corrupted. I only have this error after adding `--vcf_fn=input_vars.vcf.gz`. 


I ran Clair3 like:
`bash /<path>/run_clair3.sh --bam_fn={} --vcf_fn=input_vars.vcf.gz --print_ref_calls --ref_fn=GRCh38.fa --threads=6  --platform=""ont"" --model_path=""/<path>/Clair3/models/ont"" --output=force_calls/{.} --haploid_sensitive --ctg_name=<a_specific_chromosome>`

I ran this in parallel for 12 bam files at a time, for >300 individuals

A few examples, in which I have to redact the chromosome name and variant positions...

The #CHROM line is not the last one in the header, and ##fileformat gets appended to the end of the next line. The ##fileformat line also happens as expected at the top of the file. Also note that chrUn_KI270372v1 is mentioned twice in the header, once correctly and once as shown below.
```
##contig=<ID=chrUn_GL000218v1,length=161147>
##contig=<ID=chrEBV,length=171823>
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  EMPTY
##contig=<ID=chrUn_KI270372v1,length=1650>##fileformat=VCFv4.2
```

The #CHROM line is not the last one in the header, and the first variant gets appended to the next line. Note that the first variant is diploid (0/1) while all other positions in the file are haploid (as they should be with  --haploid_sensitive). Also note that chrUn_KI270372v1 is mentioned twice in the header, once correctly and once as shown below
```
##contig=<ID=chrUn_GL000216v2,length=176608>
##contig=<ID=chrUn_GL000218v1,length=161147>
##contig=<ID=chrEBV,length=171823>
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  EMPTY
##contig=<ID=chrUn_KI270372v1,length=1650>chr<N> 123456        .       T       C       3.46    PASS    P       GT:GQ:DP:AF     0/1:3:1:1.0000
```

```
##contig=<ID=chrUn_GL000216v2,length=176608>
##contig=<ID=chrUn_GL000218v1,length=161147>
##contig=<ID=chrEBV,length=171823>
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  EMPTY
##contig=<ID=chrUn_KI270372v1,length=1650>##fileformat=VCFv4.2
##contig=<ID=chrUn_KI270372v1,length=1650>chr<N> 234567        .       T       T       21.02   RefCall P       GT:GQ:DP:AF     0/0:21:1:1.0000
```

Here ##fileformat=VCFv4.2 ended up in the middle of some variant records
```
chrA	pos1	.	T	C	6.97	PASS	F	GT:GQ:DP:AF	1:6:4:0.2500
chrA	pos2	.	C	C	20.33	RefCall	P	GT:GQ:DP:AF	0:20:4:1.0000
chrA	pos3	.	G	G	21.90	RefCall	F	GT:GQ:DP:AF	0:21:4:0.7500
chrA	pos4	.	T	T	23.93	RefCall	P	GT:GQ:DP:AF	0:23:4:1.0000
chrA	pos5	.	G	G	13.50	RefCall	F	GT:GQ:DP:AF	0:13:4:0.7500
chrA	pos6	.	A	A	26.66	RefCall	P	GT:GQ:DP:AF	0:26:4:1.0000##fileformat=VCFv4.2
chrA	pos7	.	G	G	18.71	RefCall	P	GT:GQ:DP:AF	0:18:4:0.7500
chrA	pos8	.	G	G	19.56	RefCall	P	GT:GQ:DP:AF	0:19:4:1.0000
```

Cheers,
Wouter",wdecoster,https://github.com/HKU-BAL/Clair3/issues/25
MDU6SXNzdWU5MTc0MjQ4Mzc=,pileup_*.vcf': No such file or directory,CLOSED,2021-06-10T14:41:13Z,2021-06-22T14:29:44Z,2021-06-22T14:29:44Z,"Hello!
I'm  using Claire3 v0.1-r3 with ONT reads. I'm running the command: 

docker run -it -v $INPUT_DIR:$INPUT_DIR -v $OUTPUT_DIR:$OUTPUT_DIR hkubal/clair3:""$BIN_VERSION"" /opt/bin/run_clair3.sh --print_ref_calls --qual=15 --bam_fn=$INPUT_DIR/bar1.bam --ref_fn=$INPUT_DIR/Serratia_UMH9.fa --threads=""1"" --platform=""ont"" --model_path=""/opt/models/ont"" --output=$OUTPUT_DIR --ctg_name=NZ_CP018923.1

However, I obtain the following error in the first step:

BrokenPipeError: [Errno 32] Broken pipe
[INFO] Delay 5 seconds before starting variant calling ...
[faidx] Truncated sequence: NZ_CP018923.1:1512296-6024592
[mpileup] 1 samples in 1 input files
Traceback (most recent call last):
  File ""/opt/bin/clair3/../clair3.py"", line 89, in <module>
    main()
  File ""/opt/bin/clair3/../clair3.py"", line 83, in main
    submodule.main()
  File ""/opt/bin/preprocess/CreateTensorPileup.py"", line 547, in main
    CreateTensorPileup(args)
  File ""/opt/bin/preprocess/CreateTensorPileup.py"", line 411, in CreateTensorPileup
    tensor_can_fp.stdin.write(l)
BrokenPipeError: [Errno 32] Broken pipe

real	0m14.781s
user	0m2.819s
sys	0m0.579s
[INFO] Merge chunked contigs vcf files
cat: '/home/andrea/Escritorio/Brote_Serratia/2021_Brote_HAV/FILT_ASSEMBLY/14_Mapeo_ref/CLAIR3/tmp/pileup_output/pileup_*.vcf': No such file or directory
[ERROR] No vcf file found, please check the setting

[output.zip](https://github.com/HKU-BAL/Clair3/files/6632202/output.zip)
",Andrea-SS,https://github.com/HKU-BAL/Clair3/issues/26
MDU6SXNzdWU5MjA2MDQ4NDI=,list index out of range,CLOSED,2021-06-14T17:02:49Z,2021-06-28T15:10:20Z,2021-06-28T15:10:19Z,"Hi, 
Everything seems to work until selection of candidates for full alignment. 

""var_qual_cut_off = variant_qual_list[:int(var_pct_full * len(variant_qual_list))][-1]
IndexError: list index out of range""

Is there a way to bypass this or the reason for this error? 

thanks 

Marc",agos316,https://github.com/HKU-BAL/Clair3/issues/28
MDU6SXNzdWU5MjcxOTc2Mjg=,Documentation - conda install,CLOSED,2021-06-22T12:50:09Z,2021-06-28T15:09:32Z,2021-06-28T15:09:32Z,"Hello,

I was following the instructions for [building the anaconda virtual environment](https://github.com/HKU-BAL/Clair3#option-3-build-an-anaconda-virtual-environment) and encountered the following error while running Clair3:

```
OSError: Cannot load library <redacted>/Clair3/preprocess/realign/realigner: <redacted>/Clair3/preprocess/realign/realigner: cannot open shared object file: No such file or directory
```

After poking around the docker image, I noticed that [these two steps](https://github.com/HKU-BAL/Clair3/blob/39c1385965d97b1e2550cc90599bc9b07dd33cfc/Dockerfile#L46-L47) were missing from the above instructions:
```
    g++ -std=c++14 -O1 -shared -fPIC -o realigner ssw_cpp.cpp ssw.c realigner.cpp && \
    g++ -std=c++11 -shared -fPIC -o debruijn_graph -O3 debruijn_graph.cpp && \
```

After running those two steps, re-running clair3 seemed to work.  Just wanted to let you know so the docs could be updated.",holtjma,https://github.com/HKU-BAL/Clair3/issues/29
MDU6SXNzdWU5MjcyNTEyMDk=,ONT Flowcells ,CLOSED,2021-06-22T13:44:13Z,2021-06-24T15:49:48Z,2021-06-24T15:49:48Z,"Hello!

Clair3 has been working great, and thank you guys for sharing such solid tech.

I just have a few questions, I was hoping you could help me with!

I've processed a few PromethION and minION samples through clair3, but those were run using R9.4.1 flowcells. 
My team is interested in ONT tech, but will likely use their newer flowcells the R10.3.

Based on this, is it a bad idea to continue using the existing ONT models in Clair3 to do variant calling? Or would creating a new model trained with these flowcells be the correct step? 

",fidibidi,https://github.com/HKU-BAL/Clair3/issues/30
MDU6SXNzdWU5MjcyNTE3MzA=,Troubles with VCFs,CLOSED,2021-06-22T13:44:47Z,2021-06-24T15:49:37Z,2021-06-24T15:49:37Z,"Hi!

Thank you guys for everything!

Just having some issues with the vcfs... 

After a run clair3, I've had problems with opening the merge.vcf.gz inside of IGV. 
I haven't run a command with the property --gvcf, yet the file is output as a vcf.gz. 

Whats odd, is then it'll appear on my computer, with the extension not visible. 
merge.vcf ( even though it is actually called merge.vcf.gz )
Trying to open in igv leads to

Unexpected error: Unable to parse header with error: Your input file has a malformed header: We never saw the required CHROM header line (starting with one #) for the input VCF file, for input source: /Users/fidibidi/Downloads/merge_output (1).vcf. See igv.log for more details

I unzip the file, and manually add a vcf extension to the end... and then I'm able to view them in IGV. 
Am I doing something wrong here? 
",fidibidi,https://github.com/HKU-BAL/Clair3/issues/31
MDU6SXNzdWU5Mjk5NDc2NTg=,IndexError: list index out of range,CLOSED,2021-06-25T08:14:43Z,2022-08-02T01:03:55Z,2021-06-30T11:12:20Z,"Hi,

I just pulled from GitHub to see if it was already solved, but also the most recent version raises the error below.

This is my command, force calling variants in a bam split by phase
```
bash <path>/run_clair3.sh --bam_fn=<path>/alignment_HP2.bam --vcf_fn=called_variants.vcf.gz --print_ref_calls --ref_fn=GRCh38.fa --threads=5 --platform=""ont"" --model_path=""<path>/Clair3/models/ont"" --output=$output --haploid_sensitive --ctg_name=<chrom> --sample_name=$name
```
There is a bunch of output before this, and I can email the log files (but not post them here publicly).
```
== SUMMARY ==
Total alignments processed:                     18712
Alignments that could be tagged:                  641
Alignments spanning multiple phase sets:            0
haplotag - total processing time: 14.516802549362183

real	0m15.604s
user	0m14.753s
sys	0m0.862s

real	0m0.507s
user	0m3.805s
sys	0m0.247s
[INFO] 5/7 Select candidates for full alignment
[INFO] Select variant quality cut off 7.0
[INFO] Select reference quality cut off 21.0
[INFO] Total low qual ref variants to procceed in <chrom>: 11607
[INFO] Total low qual variants to procceed in <chrom>: 261

real	0m0.448s
user	0m0.334s
sys	0m0.134s
[INFO] 6/7 Calling variants using Full Alignment
[INFO] Delay 9 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Traceback (most recent call last):
  File ""/home/wdecoster/repositories/Clair3/clair3/../clair3.py"", line 89, in <module>
    main()
  File ""/home/wdecoster/repositories/Clair3/clair3/../clair3.py"", line 83, in main
    submodule.main()
  File ""/home/wdecoster/repositories/Clair3/preprocess/CreateTensorFullAlignment.py"", line 945, in main
    CreateTensorFullAlignment(args)
  File ""/home/wdecoster/repositories/Clair3/preprocess/CreateTensorFullAlignment.py"", line 723, in CreateTensorFullAlignment
    pos = next(samtools_pileup_generator)
  File ""/home/wdecoster/repositories/Clair3/preprocess/CreateTensorFullAlignment.py"", line 661, in samtools_pileup_generator_from
    if hap in '12' and read_name_list[hap_idx] not in hap_dict:
IndexError: list index out of range
Calling variants ...
Total process positions in <chrom> : 0
Total time elapsed: 0.00 s
[INFO] No vcf output for file <path>/alignment_HP2/tmp/full_alignment_output/full_alignment_<chrom>.0_2.vcf, remove empty file
CreateTensor.py exited with exceptions. Exiting...
[INFO] Delay 6 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Traceback (most recent call last):
  File ""/home/wdecoster/repositories/Clair3/clair3/../clair3.py"", line 89, in <module>
    main()
  File ""/home/wdecoster/repositories/Clair3/clair3/../clair3.py"", line 83, in main
    submodule.main()
  File ""/home/wdecoster/repositories/Clair3/preprocess/CreateTensorFullAlignment.py"", line 945, in main
    CreateTensorFullAlignment(args)
  File ""/home/wdecoster/repositories/Clair3/preprocess/CreateTensorFullAlignment.py"", line 723, in CreateTensorFullAlignment
    pos = next(samtools_pileup_generator)
  File ""/home/wdecoster/repositories/Clair3/preprocess/CreateTensorFullAlignment.py"", line 661, in samtools_pileup_generator_from
    if hap in '12' and read_name_list[hap_idx] not in hap_dict:
IndexError: list index out of range
Calling variants ...
Total process positions in <chrom> : 0
Total time elapsed: 0.00 s
[INFO] No vcf output for file <path>/alignment_HP2/tmp/full_alignment_output/full_alignment_<chrom>.1_2.vcf, remove empty file
CreateTensor.py exited with exceptions. Exiting...

real	0m33.027s
user	0m9.886s
sys	0m1.735s
cat: <path>/alignment_HP2/tmp/full_alignment_output/full_alignment_*.vcf: No such file or directory
```

Thanks,
Wouter",wdecoster,https://github.com/HKU-BAL/Clair3/issues/32
MDU6SXNzdWU5NDU3NjM4MDE=,Clair3 didn't run the final merge step!,CLOSED,2021-07-15T21:25:31Z,2021-07-16T13:57:41Z,2021-07-16T13:57:41Z,,fidibidi,https://github.com/HKU-BAL/Clair3/issues/37
MDU6SXNzdWU5NDU3NjYxNDI=,Clair3 didn't run the final merge step!,CLOSED,2021-07-15T21:29:25Z,2021-07-16T20:35:15Z,2021-07-16T20:35:15Z,"Hello!

The other day, Clair3 appeared to be finished, however upon investigation, I noticed that the final merge output was never created. 

The last lines of the log are:

`[mpileup] 1 samples in 1 input files
Total process positions in chrY : 10000
Total time elapsed: 197.78 s

real	567m0.735s
user	8014m59.665s
sys	191m58.762s
[INFO] 7/7 Merge pileup vcf and full alignment vcf
`

I have the full-alignment and the pileup files, so I decided to try and run the MergeVcf.py on them. 

However I'm not sure I understand how, and if this is even a good idea? 

I tried to run

`python MergeVcf.py`

and received the following error

`Traceback (most recent call last):
  File ""MergeVcf.py"", line 9, in <module>
    from shared.utils import subprocess_popen, str2bool
ModuleNotFoundError: No module named 'shared'`

Any help greatly appreciated!
Thanks.",fidibidi,https://github.com/HKU-BAL/Clair3/issues/38
MDU6SXNzdWU5NDY0NjI2NDQ=,Segmentation fault while running hap.py,CLOSED,2021-07-16T17:08:42Z,2021-08-19T08:41:16Z,2021-07-27T14:12:16Z,"Hey! So I was running the 'run hap.py for benchmarking' script from the ont_quick_demo file and ran into an error. Variant calling ran perfectly well and I also got the required vcf files, but while running the hap.py script I ran into an issue saying 'Segmentation Fault'. Is there any way I can fix this?
![error_stuff](https://user-images.githubusercontent.com/77445861/125983974-01047108-4c53-46b7-be11-55eb49be0a5c.png)
",disha-14,https://github.com/HKU-BAL/Clair3/issues/39
MDU6SXNzdWU5NDczMTM1NTc=,Option to call SNPs only,CLOSED,2021-07-19T06:29:36Z,2021-07-27T14:12:26Z,2021-07-27T14:12:26Z,"Hi,

Thanks for developing Clair3. It is really fast and accurate for small variant calling.

I am wondering if Clair3 can have the option to be more specific to call SNPs only?

Thanks!",yekaizhou,https://github.com/HKU-BAL/Clair3/issues/40
MDU6SXNzdWU5NTAxNzk3NTA=,Bioconda install issue - Illumina only,CLOSED,2021-07-21T23:22:06Z,2021-07-26T15:15:27Z,2021-07-26T15:15:26Z,"Hi, 

I semi-recently discussed an issue with installing via Conda locally (#29), and I think that issue is persisting in the bioconda builds.

When I run with the PacBio models, I don't get any issues.  However, when I run with the Illumina models, I get the following error:
```
OSError: Cannot load library <PATH>/conda/46cb01a3/bin/preprocess/realign/realigner: <PATH>/conda/46cb01a3/bin/preprocess/realign/realigner: cannot open shared object file: No such file or directory
```

I think this can be resolved by adding the compile instructions in #29 to the [build file](https://github.com/bioconda/bioconda-recipes/blob/07055a9cb7daa2a487e25e856c7e649795c1653e/recipes/clair3/build.sh#L6) so that the binary objects are automatically created during the conda install.  ",holtjma,https://github.com/HKU-BAL/Clair3/issues/42
MDU6SXNzdWU5NjQ4OTAyMDU=,Which Reference to use during Training?,CLOSED,2021-08-10T11:41:59Z,2021-08-12T13:08:37Z,2021-08-12T13:08:37Z,"![clair3](https://user-images.githubusercontent.com/36463244/128860878-26118c6c-761b-4f49-880b-641076197e88.png)

In the highlighted portion


The reference should be the standard GRCh38 or GRCh37 fasta file OR as mentioned in the example part: the fasta seq of the sample being trained ??",champ1994,https://github.com/HKU-BAL/Clair3/issues/43
MDU6SXNzdWU5Nzc0MzQ4NjE=,Does it require root to run the singularity image?,CLOSED,2021-08-23T20:48:48Z,2021-09-01T06:23:28Z,2021-09-01T06:23:28Z,"Hi, I am using singularity image to run `/opt/bin/run_clair3.sh`
It run successfully when I add `sudo` before `singularity exec /home/charlie/singularity_imgs/clair3-latest.simg \
  /opt/bin/run_clair3.sh`
and came out the following message  if I did not add `sudo`

```
[INFO] Check environment variables
Fatal Python error: Py_Initialize: Unable to get the locale encoding
Traceback (most recent call last):
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 665, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 674, in exec_module
  File ""<frozen importlib._bootstrap_external>"", line 780, in get_code
  File ""<frozen importlib._bootstrap_external>"", line 832, in get_data
PermissionError: [Errno 13] Permission denied: '/opt/conda/envs/clair3/lib/python3.6/encodings/__init__.py'
/opt/bin/scripts/clair3.sh: line 103: 20817 Aborted                 (core dumped) ${PYTHON} ${CLAIR3} CheckEnvs --bam_fn ${BAM_FILE_PATH} --bed_fn ${BED_FILE_PATH} --output_fn_prefix ${OUTPUT_FOLDER} --ref_fn ${REFERENCE_FILE_PATH} --vcf_fn ${VCF_FILE_PATH} --ctg_name ${CONTIGS} --chunk_num ${CHUNK_NUM} --chunk_size ${CHUNK_SIZE} --include_all_ctgs ${INCLUDE_ALL_CTGS} --threads ${THREADS} --python ${PYTHON} --pypy ${PYPY} --samtools ${SAMTOOLS} --whatshap ${WHATSHAP} --parallel ${PARALLEL} --qual ${QUAL} --sampleName ${SAMPLE} --var_pct_full ${PRO} --ref_pct_full ${REF_PRO} --snp_min_af ${SNP_AF} --indel_min_af ${INDEL_AF}
```

I could run `run_clair3.sh ` with conda installation successfully.",charliechen912ilovbash,https://github.com/HKU-BAL/Clair3/issues/44
MDU6SXNzdWU5ODAyOTA4NTI=,Memory Issue on [INFO] Merge chunked contigs vcf files,CLOSED,2021-08-26T14:07:52Z,2021-09-04T13:53:53Z,2021-09-03T12:13:42Z,"Hi guys,

Running clair3, and have encountered this issue twice now. I'm not sure whats going on.

I'm running on virtual machine with 64gb of memory, and on a disk with ~85gb free. 

The bam I am processing is around 90gb.

Here is the runlog

[run_clair3.log](https://github.com/HKU-BAL/Clair3/files/7060347/run_clair3.log)

Any info appreciated,
Thanks!

",fidibidi,https://github.com/HKU-BAL/Clair3/issues/45
MDU6SXNzdWU5ODU2NTI4NDI=,singularity container missing ont_guppy5 model?,CLOSED,2021-09-01T20:40:12Z,2021-09-07T12:05:18Z,2021-09-07T12:05:18Z,"Hi folks,

I just downloaded the latest container but it doesn't appear to have the guppy5 model.

```
singularity shell /gsc/software/linux-x86_64-centos7/clair3-0.1/clair3_latest.sif
Singularity clair3_latest.sif:/projects/rcorbettprj2/TechD/promethion/clair_v3> ls /opt/models
hifi  ilmn  ont
```
",RichardCorbett,https://github.com/HKU-BAL/Clair3/issues/46
MDU6SXNzdWU5ODY2NDA1MzI=,ERROR: Too many open files,CLOSED,2021-09-02T12:17:57Z,2021-09-15T13:58:55Z,2021-09-15T13:58:55Z,"Hi,

I have run Clair on WGS ONT data an got the following error:
```
...
[mpileup] 1 samples in 1 input files
Total processed positions in chrY (chunk 4/4) : 9661
Total time elapsed: 129.47 s

real    186m27.439s
user    8776m44.801s
sys     77m56.150s
Traceback (most recent call last):
  File ""/media/Data/clair3/clair3/bin/scripts/../clair3.py"", line 89, in <module>
  File ""/media/Data/clair3/clair3/bin/scripts/../clair3.py"", line 83, in main
  File ""/media/Data/clair3/clair3/bin/preprocess/SortVcf.py"", line 193, in main
  File ""/media/Data/clair3/clair3/bin/preprocess/SortVcf.py"", line 132, in sort_vcf_from
OSError: [Errno 24] Too many open files: '/media/Data/NA12878_run1-5/NA12878_run1-5.vcf/tmp/full_alignment_output/full_alignment_chrX.101_193.vcf'

real    735m16.230s
user    31395m25.386s
sys     151m23.800s
(/media/Data/clair3/clair3) die9s@k-hg-srv3:/media/Data/clair3/clair3/bin>
```

Do you have any idea what migth be the cause of this error?
Bests
Stefan

",stefandiederich,https://github.com/HKU-BAL/Clair3/issues/47
MDU6SXNzdWU5ODk4OTY3ODI=,Disk space consumption with --gvcf option,CLOSED,2021-09-07T11:45:47Z,2021-10-20T01:50:36Z,2021-10-20T01:50:36Z,"After running analysis with `--gvcf` option on a **50 Gb BAM** file containing 4 ONT runs and HG19 reference, the resulting `tmp` output subfolder takes  **419 Gb**, plus **117 Gb** in the main output folder. Probably, it would make sense to remove VCF partial files after concatenating and sorting them and compress the output. For instance, a 117 Gb GVCF file takes only 8.5 Gb when bzip2-compressed. Some libraries as [lbzip2 ](https://lbzip2.org/)can decompress it in parallel. Perhaps you want to minimize dependencies, but disk space efficiency is also important when it comes to renting servers with fast SSDs.

```
547M	./tmp/full_alignment_output/candidate_bed
3.6G	./tmp/full_alignment_output
233G	./tmp/gvcf_tmp_output
117G	./tmp/merge_output
18G	./tmp/pileup_output
174M	./tmp/phase_output/phase_vcf
48G	./tmp/phase_output/phase_bam
48G	./tmp/phase_output
419G	./tmp
```",kim-fehl,https://github.com/HKU-BAL/Clair3/issues/48
I_kwDOFQnk2847X8fN,Homo / heterozygous call issue,CLOSED,2021-09-14T15:08:53Z,2021-09-24T01:04:18Z,2021-09-24T01:04:18Z,"We noticed the presence of such line in *.vcf result file: 
`chr1	13116	.	T	G	15.23	PASS	P	GT:GQ:DP:AD:AF:PL	1/1:15:27:18,9:0.3333:22,27,0`

With AD of 18,9 shouldn't the GT be heterozygous (0/1) and not homozygous (1/1) as in output?

Full command from the log:

```bash
clair3.sh --bam_fn fk4034.merged.hg19.bam --ref_fn hg19.fna --threads 24 --model_path ont_guppy5 \
--platform ont --output clair3.gvcf --bed_fn=EMPTY --vcf_fn=EMPTY --ctg_name=EMPTY \
--sample_name=SAMPLE --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 \
--pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=2 --var_pct_full=0.3 --ref_pct_full=0.1 \
--snp_min_af=0 --indel_min_af=0 --pileup_only=False --gvcf=True --fast_mode=False --call_snp_only=False \
--print_ref_calls=False --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=False \
--no_phasing_for_fa=False --pileup_model_prefix=pileup --fa_model_prefix=full_alignment
```
",kim-fehl,https://github.com/HKU-BAL/Clair3/issues/49
I_kwDOFQnk2847dzi6,[ERROR] BAM file not found,CLOSED,2021-09-16T01:47:09Z,2021-09-18T03:46:06Z,2021-09-18T03:46:06Z,"Hi, 

I'm trying to run clair3 on a sorted index bam file using the following command

`sudo docker run -it hkubal/clair3:latest /opt/bin/run_clair3.sh --bam_fn /mnt/memorycore4/nanopore_data/realTimeTest/basecalled/consensus/demultiplexed/Sample1.sorted.bam -f ~/refs/hg38.fa -m ~/Downloads/models/ont_guppy5 -t 30 -p ont -o ~/Downloads/test/`

But am only getting this far

`[INFO] CLAIR3 VERSION: v0.1-r6
[INFO] BAM FILE PATH: /mnt/memorycore4/nanopore_data/realTimeTest/basecalled/consensus/demultiplexed/Sample1.sorted.bam
[INFO] REFERENCE FILE PATH: /home/ig88/refs/hg38.fa
[INFO] MODEL PATH: /home/ig88/Downloads/models/ont_guppy5
[INFO] OUTPUT FOLDER: /home/ig88/Downloads/test/
[INFO] PLATFORM: ont
[INFO] THREADS: 30
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX:
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.3
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False

[ERROR] BAM file /mnt/memorycore4/nanopore_data/realTimeTest/basecalled/consensus/demultiplexed/Sample1.sorted.bam not found`


The file exists at the path that is given as does its index.

Any idea what might be happening here?

Thank you,
Chris",christopher-vollmers,https://github.com/HKU-BAL/Clair3/issues/50
I_kwDOFQnk2847ej0s,Clair3 ONT model,CLOSED,2021-09-16T07:16:02Z,2021-11-12T07:30:50Z,2021-11-12T07:30:50Z,"Hi!

Let's say I have ONT data basecalled with Guppy 5. I see there are two models trained. One of them used HG002 with Guppy5_sup. How does clair3 choose the model?

`--model_path=/opt/models/ont` will just choose the most recent model or I should enter `--model_path=/opt/models/ont_guppy5`?",kokyriakidis,https://github.com/HKU-BAL/Clair3/issues/51
I_kwDOFQnk28477SmW,Wrong allele frequency and depth for haploid Illumina data,CLOSED,2021-09-23T12:51:53Z,2021-09-24T07:04:32Z,2021-09-24T07:04:32Z,"Dear,

I have been trying out Clair3 for haploid variant calling in bacterial datasets using both Illumina and ONT data and have obtained great performance so far.
However, when I'm comparing SNPs called across different samples I noticed some strange behavior in the variant calling at some positions with mixed nucleotides.

For the screenshot below you can see that this position the reference base is present at high allele frequency (~80%), but still Clair3 calls a variant call with the wrong depth and allele frequency:
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  SAMPLE
NC_002695.2     345587  .       A       C       16.73   PASS    P       GT:GQ:DP:AF     1/1:16:10:1

![image](https://user-images.githubusercontent.com/16325875/134508931-6bfa5655-ea4a-4dc0-846e-eb0723996fd6.png)

Is this a bug, or is there another reason why this occurs?

I'm using Clair3 v0.1-r6 with the Clair3-illumina Conda environment installed according to the instruction on GitHub.
The command that I used is:
`run_clair3.sh --bam_fn=TIAC1169.bam --ref_fn=reference.fasta --platform ilmn --model_path=models/ilmn --output=out --no_phasing_for_fa --include_all_ctgs --haploid_precise --threads=2
`
I have extracted the region of the BAM file in the archive below, which also contains the reference genome and the VCF file I obtained:
[variants_tiac1169.zip](https://github.com/HKU-BAL/Clair3/files/7217637/variants_tiac1169.zip)

",BertBog,https://github.com/HKU-BAL/Clair3/issues/54
I_kwDOFQnk2847-kat,validation data not entirely held out from training,CLOSED,2021-09-24T09:16:56Z,2021-10-20T01:51:16Z,2021-10-20T01:51:16Z,"- When training with a random validation subsample, indices of chunks to be used for training and validation are set up at the start of training.
- When creating training batches, a `random_start_position` in the range `[0, batch_size)` is applied to a random selection from the shuffled list of training chunks. Therefore, for each chunk, the records between coordinates (chunk_start + random offset) and (chunk_end + random offset) are loaded
- the use of an offset means that if a validation chunk follows a training chunk, then the validation data can be loaded and used in training, so the validation data are not being truly held out as an independent sample

Example:
```
Input file chunks
|---0---|---1---|---2---|---3---|---4---|---5---|---6---|---7---|---8---|---9---|...
 
Random validation chunks: [2, 5, 6]
                |---2---|               |---5---|---6---|
Training chunks:
|---0---|---1---|       |---3---|---4---|               |---7---|---8---|---9---|...
 
Example of a training epoch
Random offset: |..OFFSET..|
Randomly selected training chunks for batch: [0, 4, 8, 9,...]
Training records:
|---0---|---1---|---2---|---3---|---4---|---5---|---6---|---7---|---8---|---9---|...
|..OFFSET..|-------|            |..OFFSET..|-------|            |..OFFSET..|-----...
```
Here, data from validation chunks 2, 5 and 6 are included in training. The data associated with chunk 4 is actually entirely validation data.

Possible solutions:
- Don't use a `random_start_position` offset
    - Chunk order within a batch is already randomised, so this might be enough randomness for training patterns not to be too much of an issue
    - Records could also be shuffled within a batch after chunks have been assembled (though this might have a performance impact)
- Prune chunks preceding validation chunks out of the training list
    - Probably requires reducing the range of `random_start_position` from `batch_size` to `chunk_size`, otherwise this would be a huge proportion of training data being excluded
    - Even then, this prevents the run-on issue but means removing approximately `validation fraction` training chunks (in addition to the chunks used for validation), and complicates the calculation of training/validation fractional split",ftostevin-ont,https://github.com/HKU-BAL/Clair3/issues/57
I_kwDOFQnk2849A1XS,"cannot get the data: Alignments, GRCh38",CLOSED,2021-10-12T10:13:26Z,2021-10-14T10:15:22Z,2021-10-14T10:15:22Z,"I cannot open the network:
http://www.bio8.cs.hku.hk/clairvoyante/orginalData_hg001/ont-hg38-minimap2-rel6/rel6_hs38d1.sorted.bam,
how can i get the BAM file?",shiying-sxu,https://github.com/HKU-BAL/Clair3/issues/59
I_kwDOFQnk284-LUX_,Error in training model ,CLOSED,2021-11-03T07:16:10Z,2021-11-07T05:39:58Z,2021-11-07T05:39:58Z,"Dear author:
Hello, I encountered some problems when running the program：
When I try to train the model, run the command：
${PYTHON3} ${CLAIR3} Train \
    --bin_fn ${BINS_FOLDER_PATH} \
    --ochk_prefix ${MODEL_FOLDER_PATH}/pileup \
    --pileup \
    --add_indel_length False \
    --random_validation \
    --platform ${PLATFORM}
An error occurred：Floating point exception (core dumped) 
When I commented out the unnecessary parameters for training, 
${PYTHON3} ${CLAIR3} Train \
    --bin_fn ${BINS_FOLDER_PATH} \
    --ochk_prefix ${MODEL_FOLDER_PATH}/pileup \
I got an error again:
ValueError: Input 0 of layer conv2d is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [0, 33, 18]

Can you help me see how to solve it?
thank you very much! 


",shiying-sxu,https://github.com/HKU-BAL/Clair3/issues/62
I_kwDOFQnk284-Yh3L,phased VCF output?,CLOSED,2021-11-06T23:19:27Z,2021-11-19T13:25:56Z,2021-11-19T13:25:56Z,"Hi folks,

I'm finding the tool works really well and much better than other tools.  I have a question about where to find the phased variants in the output.    I can see that whatshap is run on my human sample and there are many split-by-chromosome files in `/tmp/phase_output/phase_bam` and `/tmp/phase_output/phase_vcf`.   However, my final `merge_output.vcf.gz` doesn't appear to contain any phased variants.  

I am running a GM24385 30X bam file with the following command:
```
/opt/bin/run_clair3.sh 		--bam_fn=PAH62362_pass.bam 		--ref_fn=hg38_no_alt_TCGA_HTMCP_HPVs.fa 		--threads=48 		--platform=""ont"" 		--model_path=""/opt/models/ont"" 		--output=clair_3_0_1_F79937 		--whatshap=/opt/conda/envs/clair3/bin/whatshap 		--include_all_ctgs
```

Where should I be looking for the final phased results?

thanks
Richard
",RichardCorbett,https://github.com/HKU-BAL/Clair3/issues/63
I_kwDOFQnk284-ycU1,50bp deletion not detected,CLOSED,2021-11-15T09:29:53Z,2022-01-18T03:32:19Z,2022-01-18T03:32:19Z,"Im strugling with clair3 to get a ~50bp deletion detected. Any other variant I can see by eye is detected, but I have a deletion in ~ 100% of my reads, but for clair3 it seems hard to find.
![image](https://user-images.githubusercontent.com/2330901/141745714-b5f04fdb-ef16-4517-ad2d-623cfda05b4c.png)

I use the 0.1-r8 release, with the following parameters:
/opt/bin/run_clair3.sh --bam_fn ${NEWBASE}.bam  --ref_fn ${reference} --threads=4 --platform=ont --model_path=""/opt/models/ont"" \
--output ${NEWBASE}_clair3 --include_all_ctgs --snp_min_af=0.01 --indel_min_af=0.001
My data is ONT, pcr amplicon reads, >1000x coverage, downsampled to ~300x.
I've tested a few subsamplings, and in 1 case at 50x coverage it did find the deletion, but in another random sampling to again 50x, it did not find it.
Is there something I can do about this, or tweak some parameter so that it does find it?",HenrivdGeest,https://github.com/HKU-BAL/Clair3/issues/64
I_kwDOFQnk284-_f3y,How to generate the quick_demo.bed file in ONT Variant Calling Quick Demo,CLOSED,2021-11-18T01:46:27Z,2021-11-19T13:27:40Z,2021-11-19T13:27:40Z,"echo -e ""${CONTIGS}\t${START_POS}\t${END_POS}"" > ${INPUT_DIR}/quick_demo.bed
Unable to implement this command, hand-write a bed file by myself, 
chr20	100000	300000
the result shows：
[ERROR] BED file work/Clair3-main/data/datatest/chr20/quick_demo.bed provides but not found

can you help me ?",shiying-sxu,https://github.com/HKU-BAL/Clair3/issues/65
I_kwDOFQnk284_O7hf,Minimum depth and minimum base quality for haploid variant calling,CLOSED,2021-11-23T06:24:00Z,2021-11-25T03:24:47Z,2021-11-25T03:24:47Z,"Hi, could we set the minimum depth and minimum base quality in haploid variant calling for nanopore reads (e.g. > 60X and Qscore > 13)?
",llk578496,https://github.com/HKU-BAL/Clair3/issues/66
I_kwDOFQnk284_Uv34,Should supplementary alignment be considered in variant calling of bacterial genome?,CLOSED,2021-11-24T13:02:18Z,2021-12-15T01:33:54Z,2021-12-15T01:33:54Z,"Hi,

I am having a set of ONT data for bacteria WGS, I used minimap2 with default params for mapping, and I see both at the start and end of the reference genome are having many supplementary alignments (may be due to the circular genome of bacteria?). 
In Clair3, seems like the supplementary alignments will be discarded (as mentioned in #54). 
May I know it is good to include the supplementary alignment to be considered in variant calling? ",llk578496,https://github.com/HKU-BAL/Clair3/issues/67
I_kwDOFQnk284_Yqr1,the number of parameters of the trained model,CLOSED,2021-11-25T10:50:54Z,2021-11-26T03:43:28Z,2021-11-26T03:43:28Z,"Sorry for another question. I want to check the number of parameters of the trained model, but I can’t find how to calculate it. Can you help me? In addition, I want to use code to visualize model input. I can’t find the code in the doc folder. Can you provide it? Or can you guide me?
Thank you very much! Thank you!
Best wishes!
Ying",shiying-sxu,https://github.com/HKU-BAL/Clair3/issues/68
I_kwDOFQnk284_xcfF,Are spliced/cDNA ONT reads supported?,CLOSED,2021-12-02T19:52:48Z,2024-09-10T20:58:51Z,2021-12-10T01:37:13Z,This isn't clear in the documentation -- are transcriptome/spliced reads from cDNA supported by Clair3?,billytcl,https://github.com/HKU-BAL/Clair3/issues/69
I_kwDOFQnk284_xdoY,RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /venvs/anaconda/envs/clair3/bin/models/r941_prom_sup_g506//pileup,CLOSED,2021-12-02T19:58:53Z,2021-12-08T03:22:12Z,2021-12-08T03:22:12Z,"I'm trying to run some variant calling on cDNA, but I'm getting the following repeated error. I'm not sure if it has anything to do with the splicing itself or if it's another issue:

Here's the log:

```
[INFO] CLAIR3 VERSION: v0.1-r8
[INFO] BAM FILE PATH: /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/merged.sorted.bam
[INFO] REFERENCE FILE PATH: /mnt/ix1/Resources/GenomeRef/Homo_sapiens/Ensembl/GRCh38_no_alt/Sequence/WholeGenomeFasta/hs38_naa.fna
[INFO] MODEL PATH: /venvs/anaconda/envs/clair3/bin/models/r941_prom_sup_g506/
[INFO] OUTPUT FOLDER: /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out
[INFO] PLATFORM: ont
[INFO] THREADS: 20
[INFO] BED FILE PATH: /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/STAMP-foundation.panel.bed
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: /venvs/anaconda/envs/clair3
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE PHASING VCF OUTPUT: False

+ /venvs/anaconda/envs/clair3/bin/scripts/clair3.sh --bam_fn /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/merged.sorted.bam --ref_fn /mnt/ix1/Resources/GenomeRef/Homo_sapiens/Ensembl/GRCh38_no_alt/Sequence/WholeGenomeFasta/hs38_naa.fna --threads 20 --model_path /venvs/anaconda/envs/clair3/bin/models/r941_prom_sup_g506/ --platform ont --output /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out --bed_fn=/mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/STAMP-foundation.panel.bed --vcf_fn=EMPTY --ctg_name=EMPTY --sample_name=SAMPLE --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=2 --var_pct_full=0.7 --ref_pct_full=0.1 --snp_min_af=0 --indel_min_af=0 --pileup_only=False --gvcf=False --fast_mode=False --call_snp_only=False --print_ref_calls=False --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=False --no_phasing_for_fa=False --pileup_model_prefix=pileup --fa_model_prefix=full_alignment --remove_intermediate_dir=False --enable_phasing=False
[INFO] Check environment variables
[INFO] Create folder /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/log
[INFO] Create folder /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/tmp
[INFO] Create folder /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/tmp/split_beds
[INFO] Create folder /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/tmp/pileup_output
[INFO] Create folder /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/tmp/merge_output
[INFO] Create folder /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/tmp/phase_output
[INFO] Create folder /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/tmp/gvcf_tmp_output
[INFO] Create folder /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/tmp/full_alignment_output
[INFO] Create folder /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/tmp/phase_output/phase_vcf
[INFO] Create folder /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/tmp/phase_output/phase_bam
[INFO] Create folder /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/tmp/full_alignment_output/candidate_bed
[INFO] --include_all_ctgs not enabled, use chr{1..22,X,Y} and {1..22,X,Y} by default
[INFO] Call variant in contigs: chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX
[INFO] Chunk number for each contig: 50 49 40 39 37 35 32 30 28 27 28 27 23 22 21 19 17 17 12 13 10 11 32
[INFO] 1/7 Call variants using pileup model
[INFO] Delay 0 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Traceback (most recent call last):
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /venvs/anaconda/envs/clair3/bin/models/r941_prom_sup_g506//pileup

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/venvs/anaconda/envs/clair3/bin/clair3/../clair3.py"", line 91, in <module>
    main()
  File ""/venvs/anaconda/envs/clair3/bin/clair3/../clair3.py"", line 85, in main
    submodule.main()
  File ""/venvs/anaconda/envs/clair3/bin/clair3/CallVariants.py"", line 1803, in main
    Run(args)
  File ""/venvs/anaconda/envs/clair3/bin/clair3/CallVariants.py"", line 205, in Run
    call_variants(args=args, output_config=output_config, output_utilities=output_utilities)
  File ""/venvs/anaconda/envs/clair3/bin/clair3/CallVariants.py"", line 1379, in call_variants
    m.load_weights(args.chkpnt_fn)
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 250, in load_weights
    return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1231, in load_weights
    py_checkpoint_reader.NewCheckpointReader(filepath)
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /venvs/anaconda/envs/clair3/bin/models/r941_prom_sup_g506//pileup
[INFO] Delay 4 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Traceback (most recent call last):
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /venvs/anaconda/envs/clair3/bin/models/r941_prom_sup_g506//pileup

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/venvs/anaconda/envs/clair3/bin/clair3/../clair3.py"", line 91, in <module>
    main()
  File ""/venvs/anaconda/envs/clair3/bin/clair3/../clair3.py"", line 85, in main
    submodule.main()
  File ""/venvs/anaconda/envs/clair3/bin/clair3/CallVariants.py"", line 1803, in main
    Run(args)
  File ""/venvs/anaconda/envs/clair3/bin/clair3/CallVariants.py"", line 205, in Run
    call_variants(args=args, output_config=output_config, output_utilities=output_utilities)
  File ""/venvs/anaconda/envs/clair3/bin/clair3/CallVariants.py"", line 1379, in call_variants
    m.load_weights(args.chkpnt_fn)
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 250, in load_weights
    return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1231, in load_weights
    py_checkpoint_reader.NewCheckpointReader(filepath)
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /venvs/anaconda/envs/clair3/bin/models/r941_prom_sup_g506//pileup

...

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/venvs/anaconda/envs/clair3/bin/clair3/../clair3.py"", line 91, in <module>
    main()
  File ""/venvs/anaconda/envs/clair3/bin/clair3/../clair3.py"", line 85, in main
    submodule.main()
  File ""/venvs/anaconda/envs/clair3/bin/clair3/CallVariants.py"", line 1803, in main
    Run(args)
  File ""/venvs/anaconda/envs/clair3/bin/clair3/CallVariants.py"", line 205, in Run
    call_variants(args=args, output_config=output_config, output_utilities=output_utilities)
  File ""/venvs/anaconda/envs/clair3/bin/clair3/CallVariants.py"", line 1379, in call_variants
    m.load_weights(args.chkpnt_fn)
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 250, in load_weights
    return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1231, in load_weights
    py_checkpoint_reader.NewCheckpointReader(filepath)
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/venvs/anaconda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /venvs/anaconda/envs/clair3/bin/models/r941_prom_sup_g506//pileup
Traceback (most recent call last):
  File ""/venvs/anaconda/envs/clair3/bin/clair3/../clair3.py"", line 91, in <module>
    main()
  File ""/venvs/anaconda/envs/clair3/bin/clair3/../clair3.py"", line 85, in main
    submodule.main()
  File ""/venvs/anaconda/envs/clair3/bin/preprocess/CreateTensorPileup.py"", line 552, in main
    CreateTensorPileup(args)
  File ""/venvs/anaconda/envs/clair3/bin/preprocess/CreateTensorPileup.py"", line 413, in CreateTensorPileup
    tensor_can_fp.stdin.write(l)
BrokenPipeError: [Errno 32] Broken pipe

real    4m23.407s
user    25m34.373s
sys     4m59.363s
[WARNING] No vcf file found with prefix:/mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/tmp/pileup_output/pileup, output empty vcf file
[WARNING] Copying pileup.vcf.gz to /mnt/ix1/Seq_Runs/20211005_MIN_1086/vcf_selected/clair3_out/merge_output.vcf.gz
[INFO] Exit in pileup variant calling

real    4m53.091s
user    25m36.328s
sys     5m0.092s
```",billytcl,https://github.com/HKU-BAL/Clair3/issues/70
I_kwDOFQnk285AAwyx,multi bam files calling ,CLOSED,2021-12-08T02:26:29Z,2021-12-08T07:53:07Z,2021-12-08T07:53:07Z,can i used multiple bam files to calling variants by using clair3 ？,zhoudreames,https://github.com/HKU-BAL/Clair3/issues/71
I_kwDOFQnk285ARPLv,Variant Calling in Low-Complexity Regions,CLOSED,2021-12-13T09:08:44Z,2021-12-14T00:29:57Z,2021-12-14T00:29:57Z,"there are some variants where located in Low-Complexity Regions can not be identified by using clair3 HiFi mode. how to solve it ？ thanks ~
![image](https://user-images.githubusercontent.com/54714639/145783239-ab31f1e2-0357-43c1-afac-f0483fb00647.png)
",zhoudreames,https://github.com/HKU-BAL/Clair3/issues/72
I_kwDOFQnk285AoPiU,aligner for variant calling using PacBio HiFi reads,CLOSED,2021-12-20T02:32:00Z,2021-12-20T10:55:25Z,2021-12-20T10:55:25Z,"Dear the authors,

Thanks for this great tool! 
I want to try the lastest version of minimap2 (v2.23) to align PacBio HiFi reads before using Clair3 for variant calling. So I am wondering if the aligner significantly influences the results, since the pre-trained hifi model was trained on aligned reads of pbmm2 (wrapper of minimap2 v2.15), I guess?

Thanks in advance!

Best,
Peng",PengNi,https://github.com/HKU-BAL/Clair3/issues/73
I_kwDOFQnk285AveLj,Can we run Clair3 with CLR data using ONT model?,CLOSED,2021-12-21T19:56:41Z,2021-12-22T03:17:27Z,2021-12-22T03:17:26Z,"Hi,

I have a simple Q: would you expect Clair3 to run on CLR data using the ONT model?
We experimented with that but it looks like Clair3 refuses to run it.
The reason we say ""it looks like"" is because there appears to be no log. It simply quits.

Here's the command

```bash
/opt/bin/run_clair3.sh  \
    --bam_fn=/cromwell_root/fc-36ec993a-12dc-4644-9554-33f5d5508088/c09f3fd1-ec2c-4593-a742-4a474d81f8f2/PBCLRWholeGenome/f12c387f-3f0c-45cd-8434-5df1dad6bd41/call-CallVariants/CallVariants/1c224795-4983-4a48-8d6d-d7b8082bb580/call-SmallVariantsScatter/shard-0/cacheCopy/subset.bam \
    --ref_fn=/cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \
    --threads=16 \
    --platform=ont \
    --model_path=""/opt/models/ont"" \
    --sample_name=""test"" --gvcf --include_all_ctgs \
    --output=""./""
```

Thanks!
Steve",SHuang-Broad,https://github.com/HKU-BAL/Clair3/issues/74
I_kwDOFQnk285BXwYU,empty vcf output file when calling variants in a diploid genome,CLOSED,2022-01-07T23:05:12Z,2022-01-14T11:39:41Z,2022-01-14T11:39:40Z,"Hi I installed clair3 using miniconda in my HPC facilities. 
Linux version: Linux version 3.10.0-862.14.4.el7.x86_64 (mockbuild@x86-040.build.eng.bos.redhat.com) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC) ) #1 SMP Fri Sep 21 09:07:21 UTC 2018

I need to extract SNP variant from a cow diploid genome sequenced with a GridION. I have a reference genome (fasta) and the variants of interest in a vcf file.

I executed Clair3 as:
MODEL_NAME=""r941_prom_hac_g360+g422""         # e.g. r941_prom_hac_g360+g422
run_clair3.sh --bam_fn=sample.bam --ref_fn=referenceGenome.fa --vcf_fn=reference-SNPs.vcf.gz --threads=6 --platform=""ont"" --model_path=""${CONDA_PREFIX}/bin/models/${MODEL_NAME}"" --output=outdir

I got an empty output vcf file, and a long log file that I attach below.

Could you please let me know what I am doing wrong? Thank you!



[run_clair3.log](https://github.com/HKU-BAL/Clair3/files/7831744/run_clair3.log)



",ogrecio,https://github.com/HKU-BAL/Clair3/issues/75
I_kwDOFQnk285B3UnX,incorrect SNP calling at low seq depth,CLOSED,2022-01-16T11:04:53Z,2022-02-25T13:35:19Z,2022-02-25T13:35:19Z,"I need to make SNP variant calling in a sample with a low sequencing depth (<7x) with ONT. I am obtaining nearly 40% misscalled variants.
Is there any way to improve this performance? 
The [INFO] FULL ALIGN PROPORTION: 0.7 parameter can be tuned? Has this anything to do with the alignment proportion of the reads? Can I somehow be more strict?

Thank you in advance!


Here the info from clair3:
[INFO] CLAIR3 VERSION: v0.1-r9
[INFO] BAM FILE PATH: sample.fastq.bam
[INFO] REFERENCE FILE PATH: ref_genome.fa
[INFO] MODEL PATH: /mnt/lustre/scratch/home/csic/mgr/ogr/programs/conda/envs/clair3/bin/models/r941_prom_hac_g360+g422
[INFO] OUTPUT FOLDER: Clair3.barcode10
[INFO] PLATFORM: ont
[INFO] THREADS: 12
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: variants.vcf.gz
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: /mnt/lustre/scratch/home/csic/mgr/ogr/programs/conda/envs/clair3
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] USER DEFINED SNP THRESHOLD: 0.25
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: True
[INFO] ENABLE REMOVING INTERMEDIATE FILES: True
[INFO] ENABLE PHASING VCF OUTPUT: False
[INFO] ENABLE LONG INDEL CALLING: False

",ogrecio,https://github.com/HKU-BAL/Clair3/issues/76
I_kwDOFQnk285B5iyd,Importance of new ONT models ?,CLOSED,2022-01-17T09:37:19Z,2022-01-17T11:09:41Z,2022-01-17T09:59:15Z,"Hi, 

I see nanopore have released new research grade models in their rerio github repo. 

Do you recommend using these, or are they not yet well-tested enough ?

I have promethion human data, called with guppy 5.0.11

Thanks,
Colin",colindaven,https://github.com/HKU-BAL/Clair3/issues/77
I_kwDOFQnk285CMyck,Clair force calling using callVarBam calls more number of variants than included in a vcf file,CLOSED,2022-01-21T16:10:35Z,2022-01-22T00:11:21Z,2022-01-22T00:11:21Z,"Hello,
The vcf file I used for force calling had 57 million SNVs for whole genome variant calling. Force calling using callVarBam and vcf provided with --call_fn resulted in calling 322 million SNVs. Does force calling mean calling those variants in the vcf file plus additional variants or something is wrong? Normally force calling should only call variants at sites provided in the vcf file. I used the following script:

python clair.py callVarBam --chkpnt_fn ""/clair/ont/model"" --ref_fn ""ref.fasta"" --bam_fn ""alignment.bam"" --threshold ""0.2"" --minCoverage ""4"" --pypy ""pypy3"" --samtools ""samtools"" --delay ""10"" --threads ""4"" --sampleName ""sample1"" --vcf_fn ""all_merged.vcf"" --ctgName ""$CONTIG_NAME"" --call_fn ""input.vcf""

Any help please?",teketelah,https://github.com/HKU-BAL/Clair3/issues/78
I_kwDOFQnk285CZAZn,Bacteria,CLOSED,2022-01-25T12:51:21Z,2022-02-25T13:35:11Z,2022-02-25T13:35:11Z,"Hi, would clair3 also work for bacterial data? Are there special settings?
Thanks",joergFLI,https://github.com/HKU-BAL/Clair3/issues/79
I_kwDOFQnk285C-_ME,Clair3 BAM index bai file not found,CLOSED,2022-02-04T04:54:22Z,2022-04-14T04:54:16Z,2022-04-14T04:54:16Z,"Hello, 
I was trying to run Clair3 but I got this error: [ERROR] BAM index bai file not found, please use 'samtools index $BAM' first. 
I tried to index the Bam file using Samtools but I get this: samtools index: failed to create index for ""input.bam"": Numerical result out of range try using a csi index. A csi index is already in the directory and that was what I used in the previous Clair version. The chromosome size is very large for a bai index which is not uncommon in plants. Is there a work around this in Clair3? 
Thank you so much.
Regards!",Teklu67,https://github.com/HKU-BAL/Clair3/issues/80
I_kwDOFQnk285EPgkv,install runtime error ,CLOSED,2022-02-20T04:18:44Z,2022-02-21T05:56:31Z,2022-02-21T05:56:31Z,"I installed with docker image with command ""**docker pull hkubal/clair3**"". and it seems success.
however, when i run with 
docker run -it   -v ${INPUT_DIR}:${INPUT_DIR}   -v ${OUTPUT_DIR}:${OUTPUT_DIR}   hkubal/clair3:latest   /opt/bin/run_clair3.sh   --bam_fn=${INPUT_DIR}/hp119_sorted.bam   --ref_fn=${INPUT_DIR}/UA802_23S.fa   --threads=${THREADS}     --platform=""ont""   --model_path=""${INPUT_DIR}/${MODEL_NAME}""  --output=${OUTPUT_DIR}

**it shows the following error**   

**[ERROR] Conda prefix not found, please activate clair3 conda environment first, model path: /evo/Antibiotic_Resistance/clair3/r941_prom_hac_g360+g422**

it confuse me, i didn't installed with bioconda.

I also tried with bioconda also, not able to install 

clair3 -> python=3.6.10The following specifications were found to be incompatible with your system:

  - feature:/linux-64::__glibc==2.27=0
  - feature:|@/linux-64::__glibc==2.27=0
Your installed version is: 2.27
",liu2005678,https://github.com/HKU-BAL/Clair3/issues/81
I_kwDOFQnk285FIZZ4,Force calling in two different samples is not similar,CLOSED,2022-03-04T16:32:12Z,2022-03-16T12:50:06Z,2022-03-16T12:50:06Z,"Hello,
I was calling SV using clair3 pipeline in two different samples. I used the following command for force calling only at sites provided in ""input_merged.vcf"" in both samples. 
/run_clair3.sh --bam_fn=""input_sorted.bam"" --ref_fn=""reference.fasta"" --threads=""15"" --platform=""ont"" --model_path=""/clair/model/r941_prom_sup_g5014/"" --remove_intermediate_dir --sample_name=name --vcf_fn=""input_merged.vcf"" --print_ref_calls --output=""/output_dir"".

However, the resulting vcf in each sample contained nearly similar number of sites but when comparing the sites they are not quite similar. Below is the result from comparing sites in each sample using vcftools:

Comparing sites in VCF files...
Found 7832718 sites common to both files.
Found 100856 sites only in main file.
Found 95537 sites only in second file.
Found 86024 non-matching overlapping sites.
After filtering, kept 8019598 out of a possible 8019598 Sites

Technically force calling should only call at sites provided in the vcf input and the two samples have similar number of calls right? This creates problem when merging the vcf for the two samples because I get a lot of ./. for the ones missing in the other sample. Any suggestion please...",Teklu67,https://github.com/HKU-BAL/Clair3/issues/82
I_kwDOFQnk285FLZo4,minimum coverage call,CLOSED,2022-03-06T13:52:52Z,2022-04-14T04:54:21Z,2022-04-14T04:54:21Z,"Hello,
Is there any flag to specify minimum coverage for variant calling?

Thanks",rodrigopsav,https://github.com/HKU-BAL/Clair3/issues/83
I_kwDOFQnk285FglC8,Representation Unification Problem Execution,CLOSED,2022-03-11T09:03:23Z,2022-03-24T04:12:09Z,2022-03-24T04:12:09Z,"Hello!

I am trying with the RepresentationUnification module to get a unified VCF from an ONT BAM of about 100GB. I've been trying to run the RepresentationUnification module on RTX2070 and 1080 for several days but I get nothing, the processes consume all the RAM and never finish.... Any advice?",N/A,https://github.com/HKU-BAL/Clair3/issues/84
I_kwDOFQnk285Fs-Sv,"""No full-alignment output for file"" stops merged file process",CLOSED,2022-03-15T09:41:23Z,2022-03-24T04:12:23Z,2022-03-24T04:12:23Z,"Hi,

I'm doing some variant analysis on  PCR fragments(~10kb) and since switching from ONT fast to hac basecalling on some sample data I now get the following errors:

[INFO] 6/7 Call low-quality variants using full-alignment model
[INFO] Delay 4 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in xyz (chunk 1/1) : 0
[ERROR] No full-alignment output for file <path>/tmp/full_alignment_output/full_alignment_xyz.0_1.vcf
Total time elapsed: 0.00 s
[INFO] No vcf output for file <path>/tmp/full_alignment_output/full_alignment_xyz.0_1.vcf, remove empty file
...
[WARNING] No vcf file found with prefix:<path>/tmp/full_alignment_output/full_alignment, output empty vcf file
[WARNING] Copying pileup.vcf.gz to <path>/merge_output.vcf.gz
[INFO] Exit in full-alignment variant calling

The program then stops and I don't get the useful 'phased_merge_output.vcf.gz' output file I previously did using the fast basecalling. The log files 7_merge_vcf.log and  8_phase_vcf_output.log are also missing as the program exits at stage 6.

I'm presuming the issue is that switching to the hac model results in my data not having any low quality variant calls that needs the full alignment? Is there any way to switch/hack this so the empty file is ignored and the rest of the script carries on please? I could fill in a line of dummy data if that would help, but I'm unsure where that would go. 
If I use the --pileup_only switch it then doesn't do phasing  or final files either, sadly.

Thanks!
Ed

<path> added to replace full file path
xyz = custom chromosome name",EdRyder,https://github.com/HKU-BAL/Clair3/issues/86
I_kwDOFQnk285GJoCo,Can I using Clair3 on GIAB sample HG002?,CLOSED,2022-03-22T15:07:44Z,2022-03-25T23:02:44Z,2022-03-25T23:02:44Z,"Hi,

Thanks very much for this useful tool!  I have a question regarding the applicability of this tool in one specific case.

I am doing a project which uses HG002 cell line for proof of concept. The ONT data of HG002 was generated in our own lab. 

I am wondering whether in this case I can still use Clair 3 for analyzing the data, since all the available models were trained on GIAB samples including HG002?",Miffy-yan,https://github.com/HKU-BAL/Clair3/issues/87
I_kwDOFQnk285G-fuf,Clair3 cannot produce gvcf file (?),CLOSED,2022-04-03T01:45:55Z,2022-07-07T07:52:17Z,2022-04-15T10:12:35Z,"Hi Clair3 team,

I recently need to use Clair3 gVCF instead of normal VCF. In our system, we have population-scale dataset from hundreds of ONT samples. I recalled it ran OK back then before i insert the flag `--gvcf`

Wonder if disk space is an issue, similar to that highlighted in #48. 

Happy to send over the log files if need be.

Best,

Tuan
```
[INFO] 7/7 Merge pileup VCF and full-alignment VCF
parallel: Error: Output is incomplete.
parallel: Error: Cannot append to buffer file in /tmp.
parallel: Error: Is the disk full?
parallel: Error: Change $TMPDIR with --tmpdir or use --compress.
Warning: unable to close filehandle properly: Cannot allocate memory during global destruction.
real	9m49.897s
user	9m17.384s
sys	0m24.180s

```

```

[93m[WARNING] No vcf file found, output empty vcf file[0m
[93m[WARNING] Copying pileup.vcf.gz to /group/dairy/Tuan/Recessive_lethal/Nextflow/results/SNP/Daisy/merge_output.vcf.gz[0m
[INFO] Removing intermediate files in /group/dairy/Tuan/Recessive_lethal/Nextflow/results/SNP/Daisy/tmp

[INFO] Finish calling, output file: /group/dairy/Tuan/Recessive_lethal/Nextflow/results/SNP/Daisy/merge_output.vcf.gz

real	2593m55.463s
user	40179m37.328s
sys	1029m34.529s
```
",tuannguyen8390,https://github.com/HKU-BAL/Clair3/issues/88
I_kwDOFQnk285HDxej,v0.1-r11 Illumina execution errors,CLOSED,2022-04-04T18:40:10Z,2022-04-07T14:08:05Z,2022-04-07T14:08:04Z,"Hello,

I was testing out the latest version (v0.1-r11) using our benchmarking pipeline.  For reference, this pipeline is executed via snakemake and we currently use singularity to execute Clair3.  This pipeline ran fine with v0.1-r9, both from an execution and accuracy perspective.  However, when I updated to r11, I started getting crashes for all of my Illumina samples (all my PacBio samples ran, although there may be an accuracy issue that I will ask about in another issue after I poke it a bit more).  All I changed was the underlying docker image, with no change to the generated command.  Here is the command template we're using (again, I stress that this template _did not change at all_ from r9 to r11 for our Illumina data, we literally just changed the docker image):

```
        /opt/bin/run_clair3.sh \
            --bam_fn={input.bam} \
            --sample_name={wildcards.sample} \
            --ref_fn={params.reference} \
            --threads={threads} \
            --platform=""{params.data_type}"" \
            --model_path=""/opt/models/{params.data_type}"" \
            --output={params.output_dir} {params.extra_options} 
```

With the r11 update, we started getting these error messages during phase 6/7 that seems to be specifically failing for the Illumina data type:

```
...
Calling variants ...
Total processed positions in chrX (chunk 3/11) : 0
[ERROR] No full-alignment output for file chrX//cluster/home/jholt/CSL_pipeline_benchmark/pipeline/variant_calls/hg38_T2T_masked/sentieon-202112.01-recal/clair3-0.1-r11/HALB3002753/tmp/full_alignment_output/full_alignment_chrX.2_11.vcf
Total time elapsed: 52.75 s
[INFO] No vcf output for file /cluster/home/jholt/CSL_pipeline_benchmark/pipeline/variant_calls/hg38_T2T_masked/sentieon-202112.01-recal/clair3-0.1-r11/HALB3002753/tmp/full_alignment_output/full_alignment_chrX.2_11.vcf, remove empty file
...
```

For some reason, the `[ERROR]` line appears to have a `chrX/` injected before the filename that I'm assuming is the source of the error (I could obviously be wrong on this front).

Any thoughts on the error?  Do you need any more information from me to reproduce/debug the error?",holtjma,https://github.com/HKU-BAL/Clair3/issues/91
I_kwDOFQnk285HIUAY,v0.1-r11 PacBio - major accuracy drop,CLOSED,2022-04-05T15:38:21Z,2022-04-06T19:15:07Z,2022-04-06T19:15:06Z,"Hello,

As I mentioned in #91, I just added r11 to my benchmark.  For PacBio datasets, I initially added the new `--longphase_for_phasing` option and saw a large drop in accuracy.  I then removed that option and re-ran overnight and noticed I was still seeing a huge drop in accuracy (see attached result screenshot).  As noted in the previous issue, I haven't changed my command line at all just the underlying Docker image.

<img width=""1149"" alt=""Screen Shot 2022-04-05 at 10 36 52 AM"" src=""https://user-images.githubusercontent.com/649567/161791617-bbfc404b-ea84-45fc-bf2a-9b57923951ce.png"">

Any thoughts on why there's such a significant drop?  I haven't had this issue with previous updates when using the Docker images.",holtjma,https://github.com/HKU-BAL/Clair3/issues/92
I_kwDOFQnk285H29zt,Should Clair3 be re-trained with new human T2T reference?,CLOSED,2022-04-15T13:44:55Z,2022-05-04T14:04:30Z,2022-05-04T14:04:30Z,"Hi,

Given the newly released human T2T reference (v2.0), should Clair3 be re-trained against that reference?
I'm unsure what the benefits this would bring, so am interested in your thoughts.

Thank you!
Steve",SHuang-Broad,https://github.com/HKU-BAL/Clair3/issues/95
I_kwDOFQnk285IBHff,python 3.6 is EOL,CLOSED,2022-04-19T11:56:58Z,2022-08-26T06:23:41Z,2022-08-26T06:23:41Z,"The default installation environment for Clair3 uses Python 3.6.10 (https://github.com/HKU-BAL/Clair3/blob/main/Dockerfile#L25). Python 3.6 has reached end of life and has not received security updates since December 2021. Unless there are specific reasons to keep using 3.6, could I suggest updating your build to use Python 3.7 as a minimum (which is supported until 2023) and seeing if the build breaks?",SamStudio8,https://github.com/HKU-BAL/Clair3/issues/96
I_kwDOFQnk285II7CF,v0.1-r11 not outputting a phased bam file,CLOSED,2022-04-20T22:50:00Z,2022-04-21T13:54:05Z,2022-04-21T13:54:05Z,"Hi, thanks for the updates to Clair3. I was excited to see the speedup and use of longphase.

I am running clair3 by passing a reference genome, aligned bam file, output dir, as well as a target bed file with the `--bed_fn` command as well as the longphase option `--longphase_for_phasing`.

I am having trouble figuring out how to get this version to output a phased bam file. I would expect to find the file in `<outputDir>/tmp/phase_output/phase_bam/` but that directory is empty at the end of my run. I do get a phased vcf at the end, as the file `phased_merge_output.vcf.gz` is correctly populated with phased SNVs. A phased bam was available in the previous version of Clair3--so did this go away with this new version?",danrdanny,https://github.com/HKU-BAL/Clair3/issues/97
I_kwDOFQnk285IR9Yr,Failed to load reference sequence from file with docker container,CLOSED,2022-04-22T18:39:42Z,2022-05-04T14:04:39Z,2022-05-04T14:04:39Z,"I run clair3 process with nextflow using Docker container and I got error as below. There is no problem if I run on conda env. Could you help take a look at this issue and give me suggestion to fix it?Thanks

```
[INFO] 6/7 Call low-quality variants using full-alignment model
[INFO] Delay 4 seconds before starting variant calling ...
gzip: invalid magic
[E::hts_parse_region] Unexpected string ""inf-1000"" after region
[W::fai_get_val] Reference LC496345:inf-1000 not found in FASTA file, returning empty sequence
[faidx] Failed to fetch sequence in LC496345:inf-1000
[ERROR] Failed to load reference sequence from file (/home/hnguyen/Documents/LabData/Avian_Influenza/work/a1/f7d8a89b38417e4ae714bc52d6e293/WIN-CFIA-AIV-SAMPLE-1.Segment_5.LC496345.reference.fasta).
CreateTensor.py exited with exceptions. Exiting...
```

The command to run:
```
samtools faidx WIN-CFIA-AIV-SAMPLE-1.Segment_5.LC496345.reference.fasta
run_clair3.sh \
    --bam_fn=WIN-CFIA-AIV-SAMPLE-1.Segment_5.LC496345.bam \
    --ref_fn=WIN-CFIA-AIV-SAMPLE-1.Segment_5.LC496345.reference.fasta \
    --model_path=""/usr/local/bin/models/r941_prom_hac_g360+g422"" \
    --threads=2 \
    --platform=""ont"" \
    --output=clair3_variant \
    --haploid_sensitive \
    --enable_long_indel \
    --fast_mode \
    --include_all_ctgs
```
",nhhaidee,https://github.com/HKU-BAL/Clair3/issues/98
I_kwDOFQnk285Iajux,1-bp off chromosome end event generated.,CLOSED,2022-04-25T19:07:21Z,2022-05-16T01:54:19Z,2022-05-16T01:54:19Z,"Hi, 

I'd like to report a strange variant generated in the gVCF.

```
chr1	248946423	.	N	<NON_REF>	0	.	END=248956422	GT:GQ:MIN_DP:PL	./.:1:0:0,0,0
```
Note that the position data is after the `END` annotation.

The command that generated this is 

```bash
platform=""hifi""
/opt/bin/run_clair3.sh \
            --bam_fn=${bam} \
            --ref_fn=${ref_fasta} \
            --threads=${num_core} \
            --platform=${platform} \
            --model_path=""/opt/models/${platform}"" \
            --sample_name=$SM \
            --gvcf \
            ""--include_all_ctgs"" \
            --output=""./""
```

with docker `hkubal/clair3:v0.1-r6`.
The bam was subset to chr1 beforehand.


Thanks,
Steve",SHuang-Broad,https://github.com/HKU-BAL/Clair3/issues/99
I_kwDOFQnk285IkXFN,"can't detect ""--no_phasing_for_fa""",CLOSED,2022-04-27T15:05:29Z,2022-05-04T14:05:01Z,2022-05-04T14:05:01Z," i use '--no_phasing_for_fa' in command, but the error show this para is disable
run_clair3.sh -b ~/temp/snp/$n/$b.sorted.bam \
                      -f ~/refseq/$n/*/*/*/GCF*.fna \
                      -o ~/temp/snp/$n/$b -t 20 -p ont -m ~/database/clair3*/ont_guppy5 \
                      --no_phasing_for_fa \
                      --include_all_ctgs \
                      --haploid_precise \
                      --sample_name=$b    ",BaylorLyu,https://github.com/HKU-BAL/Clair3/issues/100
I_kwDOFQnk285JBtlL,[Question] Run Clair3 with .bam files obtained with LRA.,CLOSED,2022-05-04T10:27:19Z,2023-10-24T03:34:53Z,2022-05-09T08:55:38Z,"Hello,
I have some ONT fastq files that I have aligned using LRA https://github.com/ChaissonLab/LRA, as it has shown advantages over minimap2 (specially in the context of structural variation detection)

I now want to use the resulting .bam for SNP using Clair3.
However, if I understood correctly, the training data for ONT was obtained using minimap2.
Should I stick to minimap2 then, and rerun the alignment of my fastq files, or is it ok to use a .bam resulting from LRA?

Thanks",waltergallegog,https://github.com/HKU-BAL/Clair3/issues/102
I_kwDOFQnk285JJ7XC,Q. Representation unification with illumina dataset,CLOSED,2022-05-06T02:03:10Z,2022-05-09T05:09:28Z,2022-05-09T05:09:28Z,"Hi, thank you foru

I am currently trying to train the Clair3 model with Illumina dataset.

I followed the representation unification [document ](https://github.com/HKU-BAL/Clair3/blob/main/docs/representation_unification.md) to generate unified vcf truth set.

But I wasn't able to run `UnifyRepresentation`, step 5 for Illumina reads.
The error is that `chr.bam.chunkctgstart_chunkctgend` does not exists (CreateTensorFullAlignment.py).
![image](https://user-images.githubusercontent.com/26645270/167054682-1ef83402-e3cc-4372-9bd3-496690562621.png)

Files in the directory are as below.
![image](https://user-images.githubusercontent.com/26645270/167054723-1f9d9937-faae-4d29-80f1-86a4c9d4b8b2.png)


I'm not sure but is representation unification also important for short reads?

Thanks!",quito418,https://github.com/HKU-BAL/Clair3/issues/103
I_kwDOFQnk285JW0qR,Running Clair3 as a non-root user when using docker,CLOSED,2022-05-10T07:13:32Z,2022-05-11T14:35:08Z,2022-05-11T14:35:08Z,"Hi, 
May I know could I run Clair3 as a non-root user when using docker (e.g. docker run --it --user 1000:1000 .........)? 
Thank you very much!",llk578496,https://github.com/HKU-BAL/Clair3/issues/104
I_kwDOFQnk285Jl5DZ,Q. Illumina realignreads.py and createtrainingtensor.py,CLOSED,2022-05-13T02:35:10Z,2022-05-16T01:52:24Z,2022-05-14T05:58:14Z,"Hi,

I am currently, trying to train a full-alignment model with Illumina dataset (without using pileup model).

Using the realign code provided in clair3, I confronted a minor error regarding `CreateTrainingTensor`.

`RealignReads.py`  generated BAM chunks that included out of scope positions for `CreateTrainingTensor`.

In particular, realigned bam files included positions that was smaller than the variable `reference_start` in `CreateTrainingTensor`, therefore I added `if statement` in samtools_pileup_generator for a simple workaround as in below image.

![image](https://user-images.githubusercontent.com/26645270/168199833-948e63e0-e6a4-4bad-93db-0628567d6661.png)

It would be nice if there is a update for this

Thanks

P.S Below is the code I am trying to run

```sh
#!/bin/bash

source env.sh

${PARALLEL} --joblog ${DATASET_FOLDER_PATH}/realignreads.log -j${THREADS_LOW} \
""${PYPY} ${CLAIR3} RealignReads \
    --bam_fn {4} \
    --ref_fn {5} \
    --read_fn ${PHASE_BAM_PATH}/_{2}_{3}_{1} \
    --ctgName ${CHR_PREFIX}{1} \
    --samtools ${SAMTOOLS} \
    --chunk_id {6} \
    --chunk_num ${chunk_num}"" ::: ${CHR[@]} ::: ${ALL_SAMPLE[@]} :::+ ${DEPTHS[@]} :::+ ${ALL_UNPHASED_BAM_FILE_PATH[@]} :::+ ${ALL_REFERENCE_FILE_PATH[@]} ::: ${CHUNK_LIST[@]}

# Index the phased bam files using samtools, for long reads, realigned reads have contig info at the end
# ${PARALLEL} --joblog ${PHASE_BAM_PATH}/index.log -j ${THREADS} ${SAMTOOLS} index -@12 ${PHASE_BAM_PATH}/{2}_{3}_{1}.bam ::: ${CHR[@]} ::: ${ALL_SAMPLE[@]} :::+ ${DEPTHS[@]}


echo ""Running SplitExtendBed""
${PARALLEL} --joblog ${DATASET_FOLDER_PATH}/split_extend_bed.log -j${THREADS} \
""${PYPY} ${CLAIR3} SplitExtendBed \
    --bed_fn {4} \
    --output_fn ${SPLIT_BED_PATH}/{2}_{3}_{1} \
    --ctgName ${CHR_PREFIX}{1}"" ::: ${CHR[@]} ::: ${ALL_SAMPLE[@]} :::+ ${DEPTHS[@]} :::+ ${ALL_BED_FILE_PATH[@]}

echo ""Running GetTruth""
# Convert an unified VCF file into a simplified var file
${PARALLEL} --joblog ${VAR_OUTPUT_PATH}/get_truth.log -j${THREADS} \
""${PYPY} ${CLAIR3} GetTruth \
    --vcf_fn {4} \
    --ctgName ${CHR_PREFIX}{1} \
    --var_fn ${VAR_OUTPUT_PATH}/var_{2}_{3}_{1}"" ::: ${CHR[@]} ::: ${ALL_SAMPLE[@]} :::+ ${DEPTHS[@]}  :::+ ${UNIFIED_VCF_FILE_PATH[@]}

echo ""Running CreateTensor""
# Create full-alignment tensors for model training
${PARALLEL} --joblog ${DATASET_FOLDER_PATH}/create_tensor_full_alignment.log -j${THREADS_LOW} \
""${PYPY} ${CLAIR3} CreateTrainingTensor \
    --bam_fn ${PHASE_BAM_PATH}/_{2}_{3}_{1} \
    --ref_fn {5} \
    --var_fn ${VAR_OUTPUT_PATH}/var_{2}_{3}_{1} \
    --bin_fn ${TENSOR_CANDIDATE_PATH}/tensor_{2}_{3}_{1}_{7} \
    --ctgName ${CHR_PREFIX}{1} \
    --samtools ${SAMTOOLS} \
    --extend_bed ${SPLIT_BED_PATH}/{2}_{3}_{1} \
    --bed_fn {6} \
    --add_no_phasing_data_training \
    --allow_duplicate_chr_pos \
    --platform ${PLATFORM} \
    --shuffle \
    --maximum_non_variant_ratio ${MAXIMUM_NON_VARIANT_RATIO} \
    --chunk_id {7} \
    --chunk_num ${chunk_num}"" ::: ${CHR[@]} ::: ${ALL_SAMPLE[@]} :::+ ${DEPTHS[@]} :::+ ${ALL_UNPHASED_BAM_FILE_PATH[@]} :::+ ${ALL_REFERENCE_FILE_PATH[@]} :::+ ${ALL_BED_FILE_PATH[@]} ::: ${CHUNK_LIST[@]}

echo ""Running Mergebins""
# Merge compressed binaries
${PARALLEL} --joblog ${DATASET_FOLDER_PATH}/mergeBin.log -j${THREADS} \
""${PYTHON3} ${CLAIR3} MergeBin \
    --platform ilmn\
    ${TENSOR_CANDIDATE_PATH}/tensor_{2}_{3}_{1}_* \
    --out_fn ${BINS_FOLDER_PATH}/bin_{2}_{3}_{1}"" ::: ${CHR[@]} ::: ${ALL_SAMPLE[@]} :::+ ${DEPTHS[@]}
```
",quito418,https://github.com/HKU-BAL/Clair3/issues/105
I_kwDOFQnk285JowDv,Quick question about Deep Learning and Varian Calling,CLOSED,2022-05-13T15:54:08Z,2022-05-16T01:54:33Z,2022-05-16T01:54:33Z,"Hi, I love the method! But after using it for several weeks I have a doubt... what is the purpose or reason of using Deep Learning for Variant Calling? What do neural networks contribute to this task? Where can I get information about the reason of using Deep Learning in comparison with the classical perspective?

Best regards and thank you very much,

Daniel",N/A,https://github.com/HKU-BAL/Clair3/issues/106
I_kwDOFQnk285Ju4FX,clair3_ont_quick_demo.sh poor parallel scalability,CLOSED,2022-05-16T11:38:46Z,2022-05-18T15:25:23Z,2022-05-18T15:25:23Z,"We are using `clair3_ont_quick_demo.sh` to benchmark two different compute nodes with 48 physical threads. Our understanding of the documentation is that Clair3 splits the input into small chunks (13 by default for `clair3_ont_quick_demo.sh`) and assigns each chunk to a pool of 4 threads. Each pool of threads can work with up to 3 chunks simultaneously (`--threads` parameter definition: ""The chunks being processed simultaneously is `ceil($threads/4)*3`""). However, what we are experiencing is that each chunk is assigned to one single thread while the number of chunks processed simultaneously is `ceil($threads/4)*3`. Therefore, some threads are idle. For example, if we execute with `--threads=48`, only 36 chunks are processed simultaneously.

In `scripts/clair3_CallVar.sh` we observe that the parallel command runs up to `ceil($threads/4)*3` jobs (chunks) in parallel. In `clair3/CallVariants.py::call_variants()` function, the main loop only spawns two threads on each iteration (one for `load_mini_batch()` and another for `batch_output_method()`), and it joins the threads before starting a new iteration. This seems to confirm our experience. Are we missing something?

Also, what is the reason behind setting a chunk size (5Mbps) by default instead of splitting the input in `$threads` chunks? In our understanding, the best possible parallel scalability will be obtained when all chunks have similar sizes, and all chunks are processed in parallel.",LorienLV,https://github.com/HKU-BAL/Clair3/issues/107
I_kwDOFQnk285J99_J,Error when there are no candidates for full-alignment calling ,CLOSED,2022-05-19T02:05:47Z,2022-05-31T13:33:46Z,2022-05-31T13:33:46Z,"Hi,

I've included `clair3` in a snakemake pipeline I maintain. Each of the snakemake rules are run on routine _and_ negative control samples. On a recent analysis run, the pipeline errored out because `clair3` failed with our negative control. Log excerpt:

```
[INFO] 6/7 Call low-quality variants using full-alignment model
cat: '/path/to/NEG/clair3/tmp/full_alignment_output/candidate_bed/FULL_ALN_FILE_*': No such file or directory
```
(path truncated for the purpose of this issue)

The previous part of the log reads:

```
[INFO] 5/7 Select candidates for full-alignment calling
[INFO] Set variants quality cutoff 7.0
[INFO] Set reference calls quality cutoff 4.0
[WARNING] Cannot find any low-quality 0/0, 0/1 or 1/1 variant in pileup output in contig MN908947.3
[INFO] Low quality reference calls to be processed in MN908947.3: 0
[INFO] Low quality variants to be processed in MN908947.3: 0
```

Seems that the lack of a 'FULL_ALN_FILE_*' file, e.g. `/path/to/NEG/clair3/tmp/full_alignment_output/candidate_bed/FULL_ALN_FILE_MN908947.3` file causes the `cat` command to fail, which then causes the pipeline to die because of bash 'strict mode'.

To remedy this, I have to first do `mkdir -p /path/to/NEG/clair3/tmp/full_alignment_output/candidate_bed && touch /path/to/NEG/clair3/tmp/full_alignment_output/candidate_bed/FULL_ALN_FILE_MN908947.3`. Afterwards, the script no longer fails, but having to have this pre-processing step isn't ideal. Could it instead be fixed in `run_clair3.sh`?

Command used:

```
singularity run -B $CONDA_PREFIX:$CONDA_PREFIX,$PWD:$PWD ${clair3_container_simg} /opt/bin/run_clair3.sh \
--bam_fn=${BAM} \
--sample_name=NEG \
--ref_fn=${REF} \
--threads=4 \
--platform=""ont"" \
--model_path=""/opt/models/r941_prom_sup_g5014"" \
--output=NEG/clair3    \
--chunk_size=29903 \
--include_all_ctgs \
--no_phasing_for_fa \
--enable_long_indel \
--haploid_sensitive | tee clair3.log.txt
```

Version: Clair3 v0.1-r11

Thanks!",charlesfoster,https://github.com/HKU-BAL/Clair3/issues/108
I_kwDOFQnk285KR3HG,gpu version,CLOSED,2022-05-24T08:39:54Z,2022-05-31T13:33:38Z,2022-05-31T13:33:38Z,"hello !!

any plan to use gpu's?
",xgnusr,https://github.com/HKU-BAL/Clair3/issues/109
I_kwDOFQnk285KWx0O,Q. Related to RealignReads.py  - contig start and end value,CLOSED,2022-05-25T05:09:27Z,2022-05-28T09:02:13Z,2022-05-28T09:02:12Z,"Hi,

I think reference region (reference_start ~ reference_end)  should be larger than the reads region (extend_start ~ extend_end).

Given ctg_start and ctg_end, extend_start and extend_end is defined as ctg_start - max_window_size, ctg_end + max_window_size

If I am correct shouldn't reference_start and reference_end should be each extend_start - expandReferenceRegion, extend_end + expandReferenceRegion ?

(I encounter an error, where reference_sequence is shorter than reference_position inside `samtools_view_generator_from` function due to this)

Thank you!

https://github.com/HKU-BAL/Clair3/blob/b87d9d82fde81d6ba923adb0dd53175d57f7ab11/preprocess/RealignReads.py#L383",quito418,https://github.com/HKU-BAL/Clair3/issues/110
I_kwDOFQnk285KtF3F,The threshold of allele frequency to define a heterozygous SNP,CLOSED,2022-05-31T05:01:48Z,2022-06-01T06:34:11Z,2022-06-01T06:34:11Z,"Hi,
When using human genome data sequenced by Nanopore,
By default, what is the threshold of allele frequency to define a heterozygous SNP ?
Like 40%~60% 
and what is the threshold of allele frequency to define a homozygous SNP ?
Like >80%

Thanks !",charliechen912ilovbash,https://github.com/HKU-BAL/Clair3/issues/111
I_kwDOFQnk285Kz2qw,Phasing fails for bam files created by guppy 6.1.1 with modified base tags,CLOSED,2022-06-01T06:29:56Z,2022-07-14T12:23:35Z,2022-07-14T12:23:35Z,"Hi, I'm running into a problem phasing bam files generated by guppy 6.1.x that include the new modified base tags. I believe I am running into an error with the phasing step. I am interested in a specific region on chr16 and am seeing the following error in the run_clair3.log file:
```
[INFO] 2/7 Select heterozygous SNP variants for Whatshap phasing and haplotagging
[INFO] Select heterozygous pileup variants exceeding phasing quality cutoff 13
[INFO] Total heterozygous SNP positions selected: chr16: 3276

real    0m0.504s
user    0m0.442s
sys     0m0.068s

[INFO] 3/7 Phase VCF file using LongPhase
parsing VCF ... 0s
parsing SV VCF ... 0s
reading reference ... 0s
parsing contig/chromosome: chr1 ... skip
parsing contig/chromosome: chr10 ... skip
parsing contig/chromosome: chr11 ... skip
parsing contig/chromosome: chr11_KI270721v1_random ... skip
parsing contig/chromosome: chr12 ... skip
parsing contig/chromosome: chr13 ... skip
parsing contig/chromosome: chr14 ... skip
parsing contig/chromosome: chr14_GL000009v2_random ... skip
parsing contig/chromosome: chr14_GL000225v1_random ... skip
parsing contig/chromosome: chr14_KI270722v1_random ... skip
parsing contig/chromosome: chr14_GL000194v1_random ... skip
parsing contig/chromosome: chr14_KI270723v1_random ... skip
parsing contig/chromosome: chr14_KI270724v1_random ... skip
parsing contig/chromosome: chr14_KI270725v1_random ... skip
parsing contig/chromosome: chr14_KI270726v1_random ... skip
parsing contig/chromosome: chr15 ... skip
parsing contig/chromosome: chr15_KI270727v1_random ... skip
parsing contig/chromosome: chr16 ... fetch SNP ... terminate called after throwing an instance of 'std::out_of_range'
  what():  basic_string::substr: __pos (which is 1285) > this->size() (which is 4)

real    0m3.123s
user    0m0.816s
sys     0m0.449s
```

I am running clair3 with the following command:
```
clair3.sh -t 10 -r <pathToRef> -s <sampleName> -b <guppy611BamFile> -o <clairOutDir> -c ""--bed_fn=<targetRegionBed> --longphase_for_phasing""
```

Info from run_clair3.log file:
```
[INFO] CLAIR3 VERSION: v0.1-r11
[INFO] BAM FILE PATH: <guppy611BamFile>
[INFO] REFERENCE FILE PATH: <pathToRef>
[INFO] MODEL PATH: /opt/models/ont_guppy5
[INFO] OUTPUT FOLDER: <clairOutDir>
[INFO] PLATFORM: ont
[INFO] THREADS: 40
[INFO] BED FILE PATH: <targetRegionBed>
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: <path>/software/modules-sw/miniconda/4.9.2/Linux/CentOS7/x86_64/envs/python3
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: /opt/bin/longphase
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] PHASING PROPORTION: 0.8
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.08
[INFO] INDEL AF THRESHOLD: 0.15
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE PHASING VCF OUTPUT: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE LONGPHASE_FOR_PHASING: True
[INFO] ENABLE C_IMPLEMENT: True
```

I have attached an example bam file. This was called with guppy 6.1.1 using the dna_r9.4.1_450bps_modbases_5mc_cg_sup.cfg model. Target region is chr16:3200000-3300000.

[Clair3PhasingExample.zip](https://github.com/HKU-BAL/Clair3/files/8811589/Clair3PhasingExample.zip)

Thank you, please let me know if you need anything else or if phasing is failing because of something I am doing on my end.",danrdanny,https://github.com/HKU-BAL/Clair3/issues/112
I_kwDOFQnk285LOq4G,Using singularity,CLOSED,2022-06-06T17:27:50Z,2022-06-20T09:39:21Z,2022-06-20T09:39:21Z,"Hi,

I'm trying to run Clair3 but I keep getting a large error message both when I use the demo data and my own and I can't figure out why. I think this might be the root of the error but I'm not sure. I have it installed in bioconda and I've attached the full log file.

tensorflow.python.framework.errors_impl.NotFoundError: /lb/project/ioannisr/Melissa-abacus/tools/conda/clair3/lib/python3.6/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringB5cxx11EPNS_15OpKernelContextEb

Thanks for you help,
Melissa

[run_clair3.log](https://github.com/HKU-BAL/Clair3/files/8846328/run_clair3.log)

",mzwaig,https://github.com/HKU-BAL/Clair3/issues/113
I_kwDOFQnk285LXocs,Clair3 for oncopanels,CLOSED,2022-06-08T09:50:44Z,2022-06-08T11:33:37Z,2022-06-08T11:33:37Z,"Hi!

Can I use Clair3 to identify indels in oncopanels with Illumina reads? Or is it only for germline calling?",kokyriakidis,https://github.com/HKU-BAL/Clair3/issues/114
I_kwDOFQnk285LcL14,Generated GVCF file ,CLOSED,2022-06-09T06:55:05Z,2022-07-14T12:23:45Z,2022-07-14T12:23:45Z,"Hello everyone.

First I would like to thank you for this excellent tool and for your support.  

Recently, I have been looking into the output gvcf file from Clair3 and I noticed that a lot of positions being reported as ""./."" even though we have good coverages at these locations as shown below.

chr20   48172477        .       C       <NON_REF>       0       .       END=48172477    GT:GQ:MIN_DP:PL 0/0:7:62:0,6,1499
chr20   48172478        .       C       <NON_REF>       0       .       END=48172478    GT:GQ:MIN_DP:PL ./.:0:59:62,0,1352
chr20   48172479        .       A       <NON_REF>       0       .       END=48172479    GT:GQ:MIN_DP:PL 0/0:50:62:0,66,1619
chr20   48172480        .       C       <NON_REF>       0       .       END=48172480    GT:GQ:MIN_DP:PL ./.:0:63:20,0,1490
chr20   48172481        .       G       <NON_REF>       0       .       END=48172481    GT:GQ:MIN_DP:PL ./.:0:57:68,0,1298
chr20   48172482        .       G       <NON_REF>       0       .       END=48172482    GT:GQ:MIN_DP:PL 0/0:9:63:0,9,1529

Is this expected?  or there is something not right in the software algorithm.    

If this is expected,  can you please explain how the software determine when to call the GT 0/0 or ./. given the above real scenario?   

This is really important to us to know if we are going to use Clair3.  So I really appreciate your help and support.      

Best regards,
",jazihak,https://github.com/HKU-BAL/Clair3/issues/115
I_kwDOFQnk285Lj_80,Clair3 quality filtering threshold,CLOSED,2022-06-10T15:52:45Z,2022-07-14T12:23:51Z,2022-07-14T12:23:51Z,"Hello,
I read that the quality scores of variants derived from ONT data are usually bimodally distributed. What is the best quality threshold for filtering Clair3 vcf output? In Clair2, I was using a shell script kindly provided by Fritz and Medhat but it is no more working for Clair3 outputs. Any suggestion please? 
Many thanks for your time and help!",Teklu67,https://github.com/HKU-BAL/Clair3/issues/116
I_kwDOFQnk285Lvc4i,CRAM support,CLOSED,2022-06-14T12:28:45Z,2022-08-26T06:23:25Z,2022-08-26T06:23:24Z,"Hello,

Thank you for the tool Clair3. I would like to know if Clair3 supports CRAM as input instead of BAM?

Best,
S",santoshe1,https://github.com/HKU-BAL/Clair3/issues/117
I_kwDOFQnk285M0asw,Will there be a release after v0.1-r11 given ticket #92,CLOSED,2022-06-29T14:23:34Z,2022-07-14T12:24:04Z,2022-07-14T12:24:04Z,"Hi, 

I'm considering bumping up the version of Clair3 in our pipeline after #99.
However, after seeing ticket #92, I'm hesitant as it points to a major drop of performance.
Judged from the discussion in #92, there's a patch that fixed the issue.
The release date for v0.1-r11 is April 4th, and #92 happened after that.

So I'm wondering if there will be v0.1-r11.2 or v0.1-r12 soon.
(I noticed the tag v0.1-r11.1 is for Zenodo specifically).

Thanks,
Steve",SHuang-Broad,https://github.com/HKU-BAL/Clair3/issues/118
I_kwDOFQnk285M4bdO,Calculated allele frequency in VCF file,CLOSED,2022-06-30T09:33:10Z,2022-07-14T12:24:13Z,2022-07-14T12:24:13Z,"Hello,

I am using Clair3 to call variants in microbial data.
I have a position in my reference (the base T), where the bam-file (generated with minimap2) tells me, that I have a total read count of 268 reads. In this position, 6 of the reads have the alternative base C.
In the VCE file, generated with Clair3, this position is now called as heterozygous with an allele frequency of 0.2222.
`EFAU004_01163	102	.	T	C	6.77	PASS	F	GT:GQ:DP:AF	0/1:6:9:0.2222`

Can you tell me, what the reason could be for this high allele frequency?
By my calculation 6 of 268 reads should be around 0.02 (and with that below the 8% threshold for calling a variant). Maybe I missed some parameter, which I need to modify.",SebastianMeyer1989,https://github.com/HKU-BAL/Clair3/issues/119
I_kwDOFQnk285NNt7x,Clair3 model for unknown basecall version,CLOSED,2022-07-06T08:25:30Z,2022-07-14T12:23:25Z,2022-07-14T12:23:25Z,"Hi team, 

I was wondering if I download some public dataset without knowing what basecall version/mode was performed with the dataset (for example, 9.4.1 vs 10.4, HAC vs SUP), what should I use as model for Clair3 ? Is there a ""general"" model used for all ONT flowcell ?

Thanks,

Tuan

",tuannguyen8390,https://github.com/HKU-BAL/Clair3/issues/120
I_kwDOFQnk285NSwYQ,Seek for help running representation unifcation,CLOSED,2022-07-07T03:42:52Z,2022-07-15T02:35:37Z,2022-07-14T12:23:14Z,"Hi,
 I met a problem in the step of representation unification. 
After I execute the command according to representation_unification.md, my vcf output folder is empty. I carefully check the steps and find that the CreateTensorFullAlignment command is missing in step 4 in the representation_unification.md file provided now, but after I add this command Found that the files in my CANDIDATE_DETAILS_PATH are all empty. Can you help me?
Sincerely",shiying-sxu,https://github.com/HKU-BAL/Clair3/issues/121
I_kwDOFQnk285NoSwc,Empty VCF output for demo and samples,CLOSED,2022-07-12T17:26:20Z,2022-07-13T13:16:08Z,2022-07-13T13:16:07Z,"Hi,
I am using Clair3 and keep getting empty VCF files as output for my own samples and the demo files. I tested both the pre-built docker image and built it myself by cloning this repo and running clair3_ont_quick_demo.sh. It appears to exit after step 1/7 pileup variant calling, outputting no vcf file for pileup_output so it creates an empty vcf file for the pileup and merged VCFs. The process takes about 6 minutes before it exits. I have used my file with another caller with no issue so I'm suspecting something is going wrong when building the image. Anyone else having this issue or have any advice to figure out what is going wrong?

This is the error for the demo. No error message is outputted when running it with my own files:

+ /opt/bin/scripts/clair3_c_impl.sh --bam_fn /home/monica.roberts/clair3_ont_quickDemo/HG003_chr20_demo.bam --ref_fn /home/monica.roberts/clair3_ont_quickDemo/GRCh38_no_alt_chr20.fa --threads 4 --model_path /opt/models/ont --platform ont --output /home/monica.roberts/clair3_ont_quickDemo/output --bed_fn=/home/monica.roberts/clair3_ont_quickDemo/quick_demo.bed --vcf_fn=EMPTY --ctg_name=EMPTY --sample_name=SAMPLE --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=2 --var_pct_full=0.7 --ref_pct_full=0.1 --var_pct_phasing=0.7 --snp_min_af=0.08 --indel_min_af=0.15 --min_mq=5 --min_coverage=2 --min_contig_size=0 --pileup_only=False --gvcf=False --fast_mode=False --call_snp_only=False --print_ref_calls=False --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=False --no_phasing_for_fa=False --pileup_model_prefix=pileup --fa_model_prefix=full_alignment --remove_intermediate_dir=False --enable_phasing=False --enable_long_indel=False --use_gpu=False --longphase_for_phasing=False --longphase=EMPTY

[INFO] Check environment variables
[INFO] --include_all_ctgs not enabled, use chr{1..22,X,Y} and {1..22,X,Y} by default
[INFO] Call variant in contigs: chr20
[INFO] Chunk number for each contig: 13
Traceback (most recent call last):
  File ""/opt/bin/scripts/../clair3.py"", line 94, in <module>
    main()
  File ""/opt/bin/scripts/../clair3.py"", line 88, in main
    submodule.main()
  File ""/opt/bin/preprocess/CheckEnvs.py"", line 492, in main
    CheckEnvs(args)
  File ""/opt/bin/preprocess/CheckEnvs.py"", line 396, in CheckEnvs
    split_extend_bed(bed_fn=bed_fn, output_fn=split_bed_path, contig_set=contig_set)
  File ""/opt/bin/preprocess/CheckEnvs.py"", line 161, in split_extend_bed
    with open(ctg_output_fn, 'w') as output_file:
PermissionError: [Errno 13] Permission denied: '/home/monica.roberts/clair3_ont_quickDemo/output/tmp/split_beds/chr20'

Thanks in advance!",mproberts99,https://github.com/HKU-BAL/Clair3/issues/122
I_kwDOFQnk285NwZn2,"Low allele-frequencies and InDels, despite setting appropriate filters",CLOSED,2022-07-14T09:44:48Z,2022-07-15T12:40:04Z,2022-07-15T12:40:04Z,"Hi there,
I am doing a few different clair3 runs with the parameters ""--call_snp_only"" and ""--snp_min_af=0.25"".
Even so I am getting some calls like these:

```
EFAU004_00073	112	.	T	A	18.61	PASS	F	GT:GQ:DP:AF	0/1:18:461:0.2169
EFAU004_00116	320	.	T	A	9.07	PASS	F	GT:GQ:DP:AF	1/1:9:210:0.2048
EFAU004_00425	438	.	G	A	7.16	PASS	F	GT:GQ:DP:AF	0/1:7:300:0.2233
EFAU004_01676	103	.	G	T	9.02	PASS	F	GT:GQ:DP:AF	0/1:9:269:0.2342
EFAU004_01783	179	.	G	A	2.58	PASS	F	GT:GQ:DP:AF	0/1:2:270:0.2148
EFAU004_02005	352	.	T	A	10.43	PASS	F	GT:GQ:DP:AF	0/1:10:340:0.1676
EFAU004_02005	366	.	G	A	12.81	PASS	F	GT:GQ:DP:AF	0/1:12:341:0.2082
EFAU004_02005	403	.	C	A	9.69	PASS	F	GT:GQ:DP:AF	0/1:9:342:0.1959
EFAU004_02103	310	.	T	C	8.38	PASS	F	GT:GQ:DP:AF	1/1:8:291:0.2371
```

which have an allele frequency (sometimes far) below 0.25.


And while I know, that  ""--call_snp_only"" is declared as EXPERIMENTAL, I also would like to mention, that I get some seldom calls like these:

```
EFAU004_02496	296	.	GC	G	4.65	PASS	F	GT:GQ:DP:AF	0/1:4:255:0.1686
EFAU004_00620	132	.	A	AG	3.35	PASS	F	GT:GQ:DP:AF	1/1:3:246:0.1545
EFAU004_02332	95	.	GC	G	6.80	PASS	F	GT:GQ:DP:AF	0/1:6:287:0.1742
```

Do you have an idea, why these calls could slip by the used filters? Is there maybe a difference in the allele frequency used to filter out calls and the estimated allele frequency shown in the vcf file?


Thanks in advance

Sebastian",SebastianMeyer1989,https://github.com/HKU-BAL/Clair3/issues/123
I_kwDOFQnk285Oa8sA,Clair3 with Guppy 6,CLOSED,2022-07-23T15:43:30Z,2022-07-24T08:04:37Z,2022-07-24T08:04:37Z,"Hello,

I have data that is base called with Guppy 6.

```
ONT Guppy basecalling software version 6.1.3+cc1d765, minimap2 version 2.22-r1101
config file:    	/opt/ont/ont-guppy/data/dna_r9.4.1_450bps_sup.cfg
model file:     	/opt/ont/ont-guppy/data/template_r9.4.1_450bps_sup.jsn

```
Can I use Clair3 to do variant calling on it?

If yes, what should I select for the:

`--model_path=`

please?",felixm3,https://github.com/HKU-BAL/Clair3/issues/124
I_kwDOFQnk285OckVx,"Check environment variables:pysam,whatshap",CLOSED,2022-07-25T02:13:22Z,2022-07-25T06:36:57Z,2022-07-25T06:36:57Z,"The command I use is as follows：
run_clair3.sh \
--ref_fn=/home/gyc/ont/seq/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna \
--bam_fn=/home/gyc/ont/fast5/workspace/output/out166/std/out.bam \
--threads=8 \
--platform=""ont"" \
--model_path=""/home/gyc/anaconda3/envs/clair3ys/bin/models/r941_prom_hac_g360+g422"" \
--output=/home/gyc/ont/fast5/workspace/output/out166/std/out

but I have some problems：

[INFO] CLAIR3 VERSION: v0.1-r11
[INFO] BAM FILE PATH: /home/gyc/ont/fast5/workspace/output/out166/std/out.bam
[INFO] REFERENCE FILE PATH: /home/gyc/ont/seq/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna
[INFO] MODEL PATH: /home/gyc/anaconda3/envs/clair3ys/bin/models/r941_prom_hac_g360+g422
[INFO] OUTPUT FOLDER: /home/gyc/ont/fast5/workspace/output/out166/std/out
[INFO] PLATFORM: ont
[INFO] THREADS: 8
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: /home/gyc/anaconda3/envs/clair3ys
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] PHASING PROPORTION: 0.7
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.08
[INFO] INDEL AF THRESHOLD: 0.15
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE PHASING VCF OUTPUT: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE LONGPHASE_FOR_PHASING: False
[INFO] ENABLE C_IMPLEMENT: True

+ /home/gyc/anaconda3/envs/clair3ys/bin/scripts/clair3_c_impl.sh --bam_fn /home/gyc/ont/fast5/workspace/output/out166/std/out.bam --ref_fn /home/gyc/ont/seq/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --threads 8 --model_path /home/gyc/anaconda3/envs/clair3ys/bin/models/r941_prom_hac_g360+g422 --platform ont --output /home/gyc/ont/fast5/workspace/output/out166/std/out --bed_fn=EMPTY --vcf_fn=EMPTY --ctg_name=EMPTY --sample_name=SAMPLE --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=2 --var_pct_full=0.7 --ref_pct_full=0.1 --var_pct_phasing=0.7 --snp_min_af=0.08 --indel_min_af=0.15 --min_mq=5 --min_coverage=2 --min_contig_size=0 --pileup_only=False --gvcf=False --fast_mode=False --call_snp_only=False --print_ref_calls=False --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=False --no_phasing_for_fa=False --pileup_model_prefix=pileup --fa_model_prefix=full_alignment --remove_intermediate_dir=False --enable_phasing=False --enable_long_indel=False --use_gpu=False --longphase_for_phasing=False --longphase=EMPTY

[INFO] Check environment variables
**Traceback (most recent call last):
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/pkgutil.py"", line 412, in get_importer
    importer = sys.path_importer_cache[path_item]
KeyError: ('/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/site-packages', 'pysam')**

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/gyc/anaconda3/envs/clair3ys/bin/whatshap"", line 7, in <module>
    from whatshap.__main__ import main
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/site-packages/whatshap/__main__.py"", line 6, in <module>
    import whatshap.cli as cli_package
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/site-packages/whatshap/cli/__init__.py"", line 12, in <module>
    from whatshap.utils import IndexedFasta, FastaNotIndexedError, detect_file_format
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/site-packages/whatshap/utils.py"", line 2, in <module>
    import pyfaidx
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/site-packages/pyfaidx/__init__.py"", line 21, in <module>
    from pkg_resources import get_distribution
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 3242, in <module>
    @_call_aside
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 3226, in _call_aside
    f(*args, **kwargs)
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 3255, in _initialize_master_working_set
    working_set = WorkingSet._build_master()
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 559, in _build_master
    ws = cls()
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 552, in __init__
    self.add_entry(entry)
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 608, in add_entry
    for dist in find_distributions(entry, True):
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 1964, in find_distributions
    importer = get_importer(path_item)
  File ""/home/gyc/anaconda3/envs/clair3ys/lib/python3.6/pkgutil.py"", line 416, in get_importer
    importer = path_hook(path_item)
**TypeError: expected str, bytes or os.PathLike object, not tuple
[INFO] --include_all_ctgs not enabled, use chr{1..22,X,Y} and {1..22,X,Y} by default
[ERROR] whatshap not found, please check you are in clair3 virtual environment**
[ERROR] Current python execution path: /home/gyc/anaconda3/envs/clair3ys/bin/python
**How can I fix them? thanks**",oranges7,https://github.com/HKU-BAL/Clair3/issues/125
I_kwDOFQnk285Od0qv,Clair3 on HPC SLURM - Multiple nodes possible?,CLOSED,2022-07-25T08:13:02Z,2022-07-25T08:34:59Z,2022-07-25T08:34:59Z,"Hello,

I'm trying to run Clair3 on an HPC. I've requested 8 nodes with 28 CPUs each for a total of 224 CPUs.

```
#!/bin/bash
#
#SBATCH --job-name=run_clair3sh_220724
#
#SBATCH --ntasks=8
#SBATCH --cpus-per-task=28
```

However, when I run Clair3, it seems to only see one of the 8 nodes and therefore runs on only 28 CPUs.

`[33m[WARNING] Threads setting exceeds maximum available threads 28, set threads=28`

Is Clair3 capable of running on CPUs spread out over multiple nodes?

Thanks in advance.
",felixm3,https://github.com/HKU-BAL/Clair3/issues/126
I_kwDOFQnk285O__c1,A loop to run clair3 on multiple .bam files ,CLOSED,2022-08-02T07:17:53Z,2022-08-03T09:09:37Z,2022-08-03T03:54:18Z,"Hi
I am trying to run clair3 (conda) with a for loop to analyze bam files from different samples. 

The code looks like:

conda create -n clair3 -c bioconda clair3 python=3.6.10 -y
conda activate clair3

for i in {path do di/*.bam}
do
 run_clair3.sh \
--bam_fn=$i \ 
--ref_fn={path to the reference genome .fasta} \
--threads=10 \
--platform=ont \
--model_path={path to r941_prom_hac_g360+g422} \
--output= {path to output dir} \
--sample_name=x\
done

when I run this, I have the following error 
![Picture1](https://user-images.githubusercontent.com/93645991/182315584-63b2be7b-7591-4047-9c76-7b466ab4ebbb.png)


Can you help me to fix the problem?",Samcha12,https://github.com/HKU-BAL/Clair3/issues/127
I_kwDOFQnk285PG9lv,Question about Depth Coverage parameter,CLOSED,2022-08-03T13:31:35Z,2022-09-26T03:39:21Z,2022-09-26T03:39:21Z,"Hello , I use clair3 on my Nanopore data.

I have a question about the Depth.
I determine the overall depth of my bam file with MosDepth (https://github.com/brentp/mosdepth).
And when I look up to the Depth of a specific variant (parameter DP on the VCF file) on the clair3 VCF output, I see that the Depth is significantly lower that the overall depth ( for example a sample with a overall Depth of 900X will have only 100X on certain variant ).

My question are, how to justify this fluctuation of Depth ? what are the criteria of filtering used by clair3 ?
and I see also if I compare duplicat from two different run that I found also a big fluctuation for the depth. Why ?

Thanks in advance",nbargues,https://github.com/HKU-BAL/Clair3/issues/128
I_kwDOFQnk285PY5OT,Typo in example code of guppy5.md documents,CLOSED,2022-08-08T14:04:59Z,2022-08-09T07:02:45Z,2022-08-09T07:02:45Z,"Hi,

There is a small typo in the docker code sections of:
https://github.com/HKU-BAL/Clair3/blob/main/docs/guppy5_20220113.md#how-to-use-the-guppy5-model
https://github.com/HKU-BAL/Clair3/blob/main/docs/guppy5.md

`hkubal/clair3::latest` should not have a double semi-colon and should be: `hkubal/clair3:latest`

Thanks for developing this tool.

",cdebuck,https://github.com/HKU-BAL/Clair3/issues/129
I_kwDOFQnk285PcgV6,Question about default settings,CLOSED,2022-08-09T08:03:22Z,2022-09-27T08:00:59Z,2022-08-09T09:35:55Z,"Hello,
I've used clair3 with the default options like this:

```
INPUT_DIR=""/home/user/test_in""
OUTPUT_DIR=""/home/cdebuck/Data/variant_calling/test_clair3""
BAM=""test.bam""
THREADS=""28""
REF=""ref.fasta""

docker run -it \
  -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \
  -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \
  hkubal/clair3:latest \
  /opt/bin/run_clair3.sh \
  --bam_fn=""${INPUT_DIR}/${BAM}"" \
  --ref_fn=""${INPUT_DIR}/${REF}"" \
  --threads=${THREADS} \
  --platform=""ont"" \
  --include_all_ctgs \
  --model_path=""/opt/models/r941_prom_sup_g5014"" \
  --output=""${OUTPUT_DIR}""
```

Based on the documentation, I was expecting that clair3 would not perform a phasing step, but in the logs I see that it has used WhatsHap phasing, but the --help states:

```
      --enable_phasing          Output phased variants using whatshap, default: disable.
      --longphase_for_phasing   Use longphase for phasing, default: enable
```

What is the function of the --enable_phasing parameter, since clair3 has used WhatsHap without supplying this parameter?
Is the mentioned default for the --longphase_for_phasing correct, since longphase was not used?
",cdebuck,https://github.com/HKU-BAL/Clair3/issues/130
I_kwDOFQnk285PuR1H,Allele frequency (AF) of InDel alleles appears incorrect in Clair3 v0.1-r11,CLOSED,2022-08-12T17:44:08Z,2022-08-15T02:06:22Z,2022-08-15T02:04:18Z,"Hi all,
I just have some questions about the output of Clair3. Specifically, in the merge_output.vcf I'm getting an odd allele frequency output in my Indel calls.

See the IGV screenshot below:

<img width=""1903"" alt=""Wrong_Del_AF"" src=""https://user-images.githubusercontent.com/29004963/184407725-21c98ea5-a223-44e2-ad21-e9e9edbea5a5.png"">
To me the above looks like 4/11 reads are ALT allele freq = 0.3636

''

Additionally, I have seen a few other InDel type variants that seem like they should be called based on depth parameters, yet are not, any ideas? 
<img width=""1893"" alt=""Del_not_called"" src=""https://user-images.githubusercontent.com/29004963/184407728-77b85f2f-1188-45b3-82cb-33e0a3875807.png"">

again this seems like it would be 4/12 == 0.33, which is well above the call parameter defaults for clair3, i.e.: 
```
      --indel_min_af=FLOAT      Minimum Indel AF required for a candidate variant. Lowering the value might increase a bit of sensitivity in trade of speed and accuracy, default: ont:0.15,hifi:0.08,ilmn:0.08.
```

## relevant code for the above was:

#### filter for >5kb reads and remove adapters with filtlong & porechop
```
$PORECHOP --threads 16 --format auto --discard_middle -i $InputFile -o output.porechopped.fastq
$filtlong --min_length $minLength --mean_q_weight 10 output.porechopped.fastq | gzip > filtered.fq.gz
```
#### minimap 2.17
```
$minimap2 -t $HalfofThreads -L --MD -c -ax map-ont $Genome $InputFile > ${InputFile%.fq.gz}.sam
```

#### Clair3 v0.1-r11
```
MODELDIR=""/opt/miniconda/envs/clair3/bin/models""
MODEL=""ont""
$CLAIR3 --bam_fn=$InputBam --ref_fn=$Genome --platform=""ont"" --threads=$HalfofThreads --model_path=""$MODELDIR/$MODEL"" --output=$OUTPUT
```
",Sandman2127,https://github.com/HKU-BAL/Clair3/issues/131
I_kwDOFQnk285P6FVk,Intuition doc for beginner,CLOSED,2022-08-16T16:49:30Z,2022-08-19T12:14:24Z,2022-08-19T12:14:24Z,"Can you provide some intuition documations for your repo, it is confused to know about what you do for a beginner.

For example, as the viewpoint of machine learning algorithm developer, I want to know the following things:
- What is the brief description of your task, like the input/output of neural network and evalutaion metric?
- What is the advantage of using deep learning in your task than some traditional method?
- What is the difference between different datasets or tasks?",PaParaZz1,https://github.com/HKU-BAL/Clair3/issues/132
I_kwDOFQnk285QQb0p,conda package installation failure,CLOSED,2022-08-22T14:09:35Z,2022-08-24T09:13:43Z,2022-08-24T09:13:43Z,"The conda package appears to depend on a version `pigz==2.4` that can no longer be installed. Conda-forge [has version 2.6](https://anaconda.org/conda-forge/pigz/files).
```
% mamba create -n clair3 -c conda-forge -c bioconda -c defaults clair3=0.1.12
...
Looking for: ['clair3=0.1.12']
...
Encountered problems while solving:
  - package clair3-0.1.12-py39hb9dc472_0 requires pigz 2.4.*, but none of the providers can be installed
```",ftostevin-ont,https://github.com/HKU-BAL/Clair3/issues/134
I_kwDOFQnk285RDz-R,No variant calling close to the edge of reads?,CLOSED,2022-09-02T09:41:25Z,2022-10-25T13:22:05Z,2022-10-25T13:22:05Z,"Hello,

I am using clair3 for variant calling on Nanopore data (running with default parameters, excpt for --include_all_ctgs).
I observed, that clair3 seems to not call possible variants within up to ~10-15 bases on the beginning/end of reads.
I am sorry, if I overlooked something obvious, but is this generally done for all reads (because the quality normally gets worse towards the beginning/end of the reads)?
Or are these actually quality-filtered and this only happens in reads with bad quality?

In either case, is it possible to turn this „filtering“ off (I did not find a parameter for that)?

As an example I attached an IGV Screenshot of such a case.
Here you see three tracks of .vcf files (Barcode 11, 18 and 19) and three tracks of the corresponding .bam files (also barcode 11, 18 and 19)
In the .bam file of barcode 18 there is an obvious variant at position 11 (C>G) with 95% Gs, which is not called in the .vcf file. Coverage and quality should be sufficient for a calling and I saw identical cases in my data in different positions all somewhere within ~15 bases of the beginning or end of reads.

![IGV_clair3_not_calling_near_the_edge_v1](https://user-images.githubusercontent.com/47881936/188111779-19051bec-d7ea-4dc8-857f-7e7f8bda6bb9.PNG)
",SebastianMeyer1989,https://github.com/HKU-BAL/Clair3/issues/135
I_kwDOFQnk285SRB-U,Which model to use for r9.4.1 fast calls?,CLOSED,2022-09-21T01:49:47Z,2022-10-25T13:22:13Z,2022-10-25T13:22:13Z,"Hello,

I am unsure of the model I should use for Minion r9.4.1 where the base calling was performed with dna_r9.4.1_450bps_fast.cfg

I saw a ""fast"" compatible model for r10.4 from rerio but not for r9.4.1

Could you please suggest the best model?

Thank you",sagnikbanerjee15,https://github.com/HKU-BAL/Clair3/issues/136
I_kwDOFQnk285Sdp_5,Bump longphase to 1.3?,CLOSED,2022-09-23T09:06:39Z,2022-10-25T13:21:56Z,2022-10-25T13:21:56Z,"Clair3 packages [longphase 1.0](https://github.com/HKU-BAL/Clair3/blob/main/Makefile#L10), but we have been unable to use CRAM input with longphase < 1.3 due to a defect that was fixed [by this commit](https://github.com/twolinin/longphase/commit/5d450a3b7900271974a1610e73809cc3f12a60db). This requires us to overwrite the longphase binary as part of our conda installation process. Longphase 1.3 claims to improve accuracy as well as fix some bugs like the aforementioned, would it be appropriate to bump the version in the Makefile and distribute a new version of the Clair3 package to conda with longphase 1.3 included?",SamStudio8,https://github.com/HKU-BAL/Clair3/issues/137
I_kwDOFQnk285ShkTJ,ModuleNotFoundError: No module named 'libclair3',CLOSED,2022-09-24T05:27:22Z,2023-09-15T08:10:08Z,2022-09-26T03:39:08Z,"Hello, I am new to Linux and the sequencing world, I have tried Clair3 using the code that you provided on ont_quick_demo, but I received the error messages like: import libclair3 / ModuleNotFoundError: No module named 'libclair3'.

There's no page that talks about libclair3. Do I miss something? How can I fix it?
I am willing to share my script if you would need it.

Thank you in advance. ",KuoLiChung,https://github.com/HKU-BAL/Clair3/issues/138
I_kwDOFQnk285Slh9K,Variant QUAL distribution between Clair3 and Clair,CLOSED,2022-09-26T07:27:49Z,2022-09-26T09:21:29Z,2022-09-26T09:20:52Z,"Hello team, thank you for making this amazing project open source!
I just want to know if the variant QUAL distributions should follow the same bimodal distribution from Clair's previous version.
![image](https://github.com/HKU-BAL/Clair/raw/master/docs/images/QualDist-ONT.png)

Because I can see that the default QUAL filter value is 2 for Clair3 and the median for my samples' variants are around 20 while for Clair is quite high (""The best quality cutoff is 748"").

",geocarvalho,https://github.com/HKU-BAL/Clair3/issues/139
I_kwDOFQnk285TiEn9,RuntimeError: Unsuccessful TensorSliceReader constructor,CLOSED,2022-10-07T16:47:50Z,2022-10-10T07:02:53Z,2022-10-10T07:02:53Z,"Hi,
I installed clair3 using a conda environment.
I'm having this error when calling variants and using several models. 
I used kit 114 for sequencing and guppy 6.3.7 for sup basecalling. What would be the preferred trained model to use?

In any case, the error seems to be caused by TensorFlow: See details below.
Thank you!

`
MODEL_NAME="" r941_prom_sup_g5014""               # ""r941_prom_sup_g5014""
run_clair3.sh --bam_fn=$WD/Mapped/$sampleID.srt.trimm.fastq.bam --ref_fn=$referenceGenome/Bos_taurus.ARS-UCD1.2.dna.primary_assembly.fa --vcf_fn=$referenceGenome/Genome-Run7-TAU-Beagle-fixed-SNPsMAF.vcf.gz --no_phasing_for_fa --remove_intermediate_dir --threads=36 --platform=""ont"" --model_path=""${CONDA_PREFIX}/bin/models/${MODEL_NAME}"" --output=Clair3.$sampleID
/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/run_clair3.sh: line 176: [: /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models/: binary operator expected
[WARNING] No absolute output path provided, using current directory as prefix
[INFO] CLAIR3 VERSION: v0.1-r11
[INFO] BAM FILE PATH: /mnt/lustre/scratch/nlsas/home/csic/mgr/ogr/lowpass/Mapped/3130.conDuplex.srt.trimm.fastq.bam
[INFO] REFERENCE FILE PATH: /mnt/lustre/scratch/nlsas//home/csic/mgr/ogr/ReferenceGenomes/ARS-UCD1.2//Bos_taurus.ARS-UCD1.2.dna.primary_assembly.fa
[INFO] MODEL PATH: /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models/ r941_prom_sup_g5014
[INFO] OUTPUT FOLDER: /mnt/lustre/scratch/nlsas/home/csic/mgr/ogr/lowpass/Clair3.3130.conDuplex
[INFO] PLATFORM: ont
[INFO] THREADS: 36
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: /mnt/lustre/scratch/nlsas//home/csic/mgr/ogr/ReferenceGenomes/ARS-UCD1.2//Genome-Run7-TAU-Beagle-fixed-SNPsMAF.vcf.gz
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] PHASING PROPORTION: 0.7
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.08
[INFO] INDEL AF THRESHOLD: 0.15
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: True
[INFO] ENABLE REMOVING INTERMEDIATE FILES: True
[INFO] ENABLE PHASING VCF OUTPUT: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE LONGPHASE_FOR_PHASING: False
[INFO] ENABLE C_IMPLEMENT: True

/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/run_clair3.sh: line 290: [: /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models/: binary operator expected
/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/run_clair3.sh: line 291: [: /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models/: binary operator expected
/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/run_clair3.sh: line 339: [: /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models/: binary operator expected
/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/run_clair3.sh: line 340: [: /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models/: binary operator expected
+ /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/scripts/clair3_c_impl.sh --bam_fn /mnt/lustre/scratch/nlsas/home/csic/mgr/ogr/lowpass/Mapped/3130.conDuplex.srt.trimm.fastq.bam --ref_fn /mnt/lustre/scratch/nlsas//home/csic/mgr/ogr/ReferenceGenomes/ARS-UCD1.2//Bos_taurus.ARS-UCD1.2.dna.primary_assembly.fa --threads 36 --model_path /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models/ r941_prom_sup_g5014 --platform ont --output /mnt/lustre/scratch/nlsas/home/csic/mgr/ogr/lowpass/Clair3.3130.conDuplex --bed_fn=EMPTY --vcf_fn=/mnt/lustre/scratch/nlsas//home/csic/mgr/ogr/ReferenceGenomes/ARS-UCD1.2//Genome-Run7-TAU-Beagle-fixed-SNPsMAF.vcf.gz --ctg_name=EMPTY --sample_name=SAMPLE --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=2 --var_pct_full=0.7 --ref_pct_full=0.1 --var_pct_phasing=0.7 --snp_min_af=0.08 --indel_min_af=0.15 --min_mq=5 --min_coverage=2 --min_contig_size=0 --pileup_only=False --gvcf=False --fast_mode=False --call_snp_only=False --print_ref_calls=False --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=False --no_phasing_for_fa=True --pileup_model_prefix=pileup --fa_model_prefix=full_alignment --remove_intermediate_dir=True --enable_phasing=False --enable_long_indel=False --use_gpu=False --longphase_for_phasing=False --longphase=EMPTY

[INFO] Check environment variables
perl: warning: Setting locale failed.
perl: warning: Please check that your locale settings:
	LANGUAGE = (unset),
	LC_ALL = (unset),
	LC_CTYPE = ""UTF-8"",
	LANG = ""en_US.UTF-8""
    are supported and installed on your system.
perl: warning: Falling back to a fallback locale (""en_US.UTF-8"").
[INFO] --include_all_ctgs not enabled, use chr{1..22,X,Y} and {1..22,X,Y} by default
[INFO] Call variant in contigs: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X 28 24 26 25 23 29 27
[INFO] Chunk number for each contig: 32 28 25 25 25 24 23 23 22 21 22 18 17 17 18 17 15 14 13 15 14 13 28 10 13 11 9 11 11 10
[INFO] 1/7 Call variants using pileup model
perl: warning: Setting locale failed.
perl: warning: Please check that your locale settings:
	LANGUAGE = (unset),
	LC_ALL = (unset),
	LC_CTYPE = ""UTF-8"",
	LANG = ""en_US.UTF-8""
    are supported and installed on your system.
perl: warning: Falling back to a fallback locale (""en_US.UTF-8"").
Traceback (most recent call last):
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models//pileup

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/scripts/../clair3.py"", line 94, in <module>
    main()
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/scripts/../clair3.py"", line 88, in main
    submodule.main()
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 339, in main
    Run(args)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 61, in Run
    call_variants_from_cffi(args=args, output_config=output_config, output_utilities=output_utilities)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 99, in call_variants_from_cffi
    m.load_weights(args.chkpnt_fn)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 250, in load_weights
    return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1231, in load_weights
    py_checkpoint_reader.NewCheckpointReader(filepath)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models//pileup
Traceback (most recent call last):
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models//pileup

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/scripts/../clair3.py"", line 94, in <module>
    main()
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/scripts/../clair3.py"", line 88, in main
    submodule.main()
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 339, in main
    Run(args)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 61, in Run
    call_variants_from_cffi(args=args, output_config=output_config, output_utilities=output_utilities)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 99, in call_variants_from_cffi
    m.load_weights(args.chkpnt_fn)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 250, in load_weights
    return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1231, in load_weights
    py_checkpoint_reader.NewCheckpointReader(filepath)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models//pileup
Traceback (most recent call last):
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models//pileup

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/scripts/../clair3.py"", line 94, in <module>
    main()
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/scripts/../clair3.py"", line 88, in main
    submodule.main()
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 339, in main
    Run(args)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 61, in Run
    call_variants_from_cffi(args=args, output_config=output_config, output_utilities=output_utilities)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 99, in call_variants_from_cffi
    m.load_weights(args.chkpnt_fn)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 250, in load_weights
    return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1231, in load_weights
    py_checkpoint_reader.NewCheckpointReader(filepath)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models//pileup
Traceback (most recent call last):
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models//pileup

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/scripts/../clair3.py"", line 94, in <module>
    main()
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/scripts/../clair3.py"", line 88, in main
    submodule.main()
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 339, in main
    Run(args)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 61, in Run
    call_variants_from_cffi(args=args, output_config=output_config, output_utilities=output_utilities)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 99, in call_variants_from_cffi
    m.load_weights(args.chkpnt_fn)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 250, in load_weights
    return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1231, in load_weights
    py_checkpoint_reader.NewCheckpointReader(filepath)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models//pileup
Traceback (most recent call last):
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models//pileup

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/scripts/../clair3.py"", line 94, in <module>
    main()
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/scripts/../clair3.py"", line 88, in main
    submodule.main()
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 339, in main
    Run(args)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 61, in Run
    call_variants_from_cffi(args=args, output_config=output_config, output_utilities=output_utilities)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/clair3/CallVariantsFromCffi.py"", line 99, in call_variants_from_cffi
    m.load_weights(args.chkpnt_fn)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 250, in load_weights
    return super(Model, self).load_weights(filepath, by_name, skip_mismatch)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py"", line 1231, in load_weights
    py_checkpoint_reader.NewCheckpointReader(filepath)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator
    raise errors_impl.NotFoundError(None, None, error_message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models//pileup
Traceback (most recent call last):
  File ""/mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/lib/python3.6/site-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /mnt/netapp1/Store_CSIC/home/csic/mgr/ogr/.conda/envs/clair3/bin/models//pileup

During handling of the above exception, another exception occurred:


`",ogrecio,https://github.com/HKU-BAL/Clair3/issues/140
I_kwDOFQnk285UEs1D,Add source=clair3 and Clair3 version to VCF header metadata,CLOSED,2022-10-16T15:09:31Z,2023-03-06T15:02:42Z,2023-03-06T15:02:41Z,"Hello,

Would it be possible to add `##source=clair3` and Clair3 version to the VCF output metadata header for Clair3? 

```
##fileformat=VCFv4.2
##source=clair3
##clair3_version=0.1-r12
##FILTER=<ID=PASS,Description=""All filters passed"">
##FILTER=<ID=LowQual,Description=""Low quality variant"">
```

It would be nice to have some more provenance information in the VCF files by default. Right now I'm just adding `source=clair3` with awk.

Thanks!",peterk87,https://github.com/HKU-BAL/Clair3/issues/141
I_kwDOFQnk285ULzFE,merged phased bam?,CLOSED,2022-10-17T23:49:39Z,2022-10-25T13:19:19Z,2022-10-25T13:19:19Z,"Hi folks,
Sorry if this is a duplicate.  I thought I asked this a year or so ago, but I can't find the issue now.

In the temporary output folder, under `./tmp/phase_output/phase_bam/` I see chromosome-wise phased bams.   Is there a way to get a merged phased bam, or should I set up something to merge the bams if I want to use them downstream?",RichardCorbett,https://github.com/HKU-BAL/Clair3/issues/142
I_kwDOFQnk285UhLIg,Clair3 doesn't find whatshap ,CLOSED,2022-10-21T08:43:51Z,2022-10-27T02:49:25Z,2022-10-27T02:49:25Z,"Hello,
I am trying to launch Clair3 from a conda environment, I installed all the packages requested but when starting Clair I get this error:

`[ERROR] whatshap not found, please check you are in clair3 virtual environment`

I checked in the environment's bin and whatshap is there, I also tried setting the path manually and still get the same issue. 
The version I installed is 1.4. ",martabaragli,https://github.com/HKU-BAL/Clair3/issues/143
I_kwDOFQnk285UqD0W,Some issues with r11 & r12,CLOSED,2022-10-24T06:50:51Z,2022-11-14T01:58:55Z,2022-10-24T22:38:41Z,"Hi there ! 

I recently made the change from r11 -> r12, and found that for some reason clair3 cannot run pass step 1 ([INFO] 1/7 Call variants using pileup model). 

Please see attached for the log file, in the folder I can find many core.xxxxx files.

![image](https://user-images.githubusercontent.com/47171822/197463656-cfbff1fa-f3f0-4a49-8535-9d6e5a7ac603.png)

[run_clair3.log](https://github.com/HKU-BAL/Clair3/files/9849301/run_clair3.log)


================================================
With r11 - I've also seen something in the log file - Not sure if I need to worry about this also :) 

ImportError: BioPython >= 1.73 must be installed to read block gzip files.
This is WhatsHap 1.0 running under Python 3.6.10
Traceback (most recent call last):
  File ""/opt/conda/envs/clair3-env/lib/python3.6/site-packages/pyfaidx/__init__.py"", line 398, in __init__
    from packaging.version import Version

ModuleNotFoundError: No module named 'packaging'

[run_clair3-r11.log](https://github.com/HKU-BAL/Clair3/files/9849391/run_clair3-r11.log)

Cheers,

Tuan",tuannguyen8390,https://github.com/HKU-BAL/Clair3/issues/144
I_kwDOFQnk285UxmCE,'forced' genotyping missing variants,CLOSED,2022-10-25T11:08:47Z,2022-10-28T10:15:53Z,2022-10-28T10:15:53Z,"Hi,

I'm running Clair3 (through docker) with  --vcf_fn=candidates.vcf.gz and   --print_ref_calls. However, not all twelve variants from candidates.vcf.gz are included in the output file, and the number of variants varies across samples between 4 and 12. Are there other options that I should activate? I understand that not all variants could be genotyped, but then I would expect an explicit ./. for those positions.

Thanks,
Wouter",wdecoster,https://github.com/HKU-BAL/Clair3/issues/146
I_kwDOFQnk285UzfsO,Question : GVCF output 2 different REF allele at a particular position ,CLOSED,2022-10-25T16:56:35Z,2022-10-25T23:24:35Z,2022-10-25T23:24:34Z,"Hi there, 

Probably a naive question from my end, but with GVCF mode, is it normal for a given position, the REF allele can change between samples - see the below small example. I thought that the REF allele should be the nucleotide at that given on the reference genome ? (Or is it I'm inferring stuff wrongly) 

```
# Sample 1
1       64404589        .       G       <NON_REF>       0       .       END=64404589    GT:GQ:MIN_DP:PL 0/0:50:29:0,87,869
# Sample 2
1       64404589        .       G       <NON_REF>       0       .       END=64404591    GT:GQ:MIN_DP:PL 0/0:50:50:0,120,1439
# Sample 3
1       64404589        .       T       G,<NON_REF>     22.37   PASS    P       GT:GQ:DP:AD:AF:PL       1/1:22:51:9,42,0:0.8235:40,50,0,990,990,990
```

This creates a bit of an issue because GATK CombineGVCF doesn't seem allow merging of these gvcf. 

```GATKException: Exception thrown at 1:64404591 [VC /group/dairy/Tuan/Recessive_lethal/Nextflow/results/Merged_Variant/MergeSNP/1.sorted.gvcf.gz @ 1:64404591 Q0.00 of type=SYMBOLIC alleles=[G*, <NON_REF>] attr={END=64404591} GT=GT:GQ:MIN_DP:PL        ./.:0:49:1469,147,0 filters=
Caused by: java.lang.IllegalStateException: The provided variant file(s) have inconsistent references for the same position(s) at 1:64404589, G* vs. T*
```

Many thanks,

Tuan",tuannguyen8390,https://github.com/HKU-BAL/Clair3/issues/147
I_kwDOFQnk285WKrp4,Dockerfile not reproducible,CLOSED,2022-11-11T15:32:38Z,2022-11-21T23:37:29Z,2022-11-21T23:37:19Z,"Hi @zhengzhenxian, 

After the last discussion where I got the conda installation broken and creates many core dump files @ issue #144 . I started to use the official docker image on [Dockerhub](https://hub.docker.com/r/hkubal/clair3) and have great time with it - no more dump files ! However, the image itself is a little bit big, and deploying that over a lot of time create a bit of I/O friction in the pipeline. So I tried to reproduce your `Dockerfile` in the current Github repo to re-create it and see if I can make it smaller. However I could not do it, perhaps because in the Dockerfile coding @ Line 48 is currently

```COPY . .``` 

I checked the layer on Dockerhub and seems like that is a masked layer. 

Anyway, theoretically speaking I believe that instead of using Ubuntu 16.04 & install Miniconda

```
FROM ubuntu:16.04
......
.....
.....
RUN wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && \
    bash Miniconda3-latest-Linux-x86_64.sh -b -p /opt/conda && \
    rm Miniconda3-latest-Linux-x86_64.sh && \
    conda config --add channels defaults && \
    conda config --add channels bioconda && \
    conda config --add channels conda-forge && \
    conda create -n clair3 python=3.9.0 -y
```

We can simply replace it with 

```
FROM continuumio/miniconda3:latest
RUN  conda config --add channels defaults && \
conda config --add channels bioconda && \
conda config --add channels conda-forge && \
conda create -n clair3 
```
as currently Miniconda Python version is already 3.9.7. 

Many thanks !

Tuan
",tuannguyen8390,https://github.com/HKU-BAL/Clair3/issues/148
I_kwDOFQnk285Wmzyt,How to run on Mac,CLOSED,2022-11-17T09:34:44Z,2024-07-09T08:08:50Z,2023-01-24T08:33:30Z,"Hello!

I want to install and run Clair3 on my Mac, but run_clair3.sh does not work.
If I want to run on a Mac, which do you recommend, the Intel version or the M1 version?
I am studying on a sequence with Nanopore long reads, but I am not yet familiar to scripts .
So, I would appreciate it if you could give me advice.

Many thanks!",erarin,https://github.com/HKU-BAL/Clair3/issues/149
I_kwDOFQnk285Wys3-,Questions about libclair3.c,CLOSED,2022-11-19T02:28:59Z,2022-11-19T07:21:29Z,2022-11-19T07:21:29Z,"/************************************************************/


    #include ""kvec.h""
    #include ""khash.h""
    #include ""levenshtein.h""
    #include ""medaka_bamiter.h""
    #include ""medaka_common.h""
    #include ""medaka_khcounter.h""
    #include ""clair3_pileup.h""
    #include ""clair3_full_alignment.h""
    

/************************************************************/

I would like to ask where the path to these header files is, thank you",oranges7,https://github.com/HKU-BAL/Clair3/issues/150
I_kwDOFQnk285W8uxd,gvcf and gatk,CLOSED,2022-11-21T23:44:19Z,2024-04-08T00:57:12Z,2022-12-05T00:43:34Z,"I've run_clair3.sh etc. with the --gvcf flag.  However, when I run the output phased_merge_output.vcf.gz in to gatk  CombineGVCFs, I get the following error 

A USER ERROR has occurred: The list of input alleles must contain <NON_REF> as an allele but that is not the case at position 10108; please use the Haplotype Caller with gVCF output to generate appropriate records

Is there a problem with the clair3 output?  Thanks.",shinlin77,https://github.com/HKU-BAL/Clair3/issues/151
I_kwDOFQnk285XJapV,"Clair3 v0.1-r12: errors for full alignment calling, questions for merging output.",CLOSED,2022-11-23T16:48:18Z,2022-12-05T00:43:21Z,2022-12-05T00:43:21Z,"Hello,

I was testing Clair3 illumina v0.1-r12.  I downloaded and installed the package using conda. The command I was using is attached.

```
run_clair3.sh --threads=4 --min_coverage=10 --include_all_ctgs -p ilmn --snp_min_af=0.5 \
 --call_snp_only --no_phasing_for_fa --haploid_precise -b input.bam -f ref.fasta \
 -m /worksz/envs/clair3-illumina/bin/models/ilmn -o inter_dir

``` 
Then I realizes there was no variants called for chr1 using full-alignment, and found this error message in the log file. I also tested clair3 for ont data and it was running fine. So I figure this error could be only for illumina data.

```
[ERROR] Invalid bed input in 1-th row chr1 -34 1032
[mpileup] fail to read the header of -
Calling variants ...
Total processed positions in chr1 (chunk 1/1) : 0
ESC[91m[ERROR] No full-alignment output for file chr1//worksz/Var_calling/clair3_illumina/iAB3990001_clair3.intermediate/tmp/full_alignment_output/full_alignment_chr1.0_1.vcfESC[0m
Total time elapsed: 0.00 s
```

The first 5 lines of /tmp/full_alignment_output/candidate_bed/full_aln_regions_chr1 looks like this. It doesn't look right indeed. Do you  know how to fix this? Please let me know if more info is needed. 

```
chr1    -34     1032
chr1    2209966 2211032
chr1    2209966 2211032
chr1    2237966 2239032
chr1    2317966 2319032

```
The other question I have is how the output files from pileup and full alignment are merged? I have 1917 SNPs labeled as ""PASS"" in pileup.vcf.gz, and 5538 in full_alignment.vcf.gz. But there are only 495 left in merge_output.vcf.gz. Looks like a large amount of SNPs were filtered out. I was wondering how these output files merged for illumina data.

Thanks!",Shu8Zhao,https://github.com/HKU-BAL/Clair3/issues/152
I_kwDOFQnk285XPrMV,gatk compatibility,CLOSED,2022-11-24T19:11:10Z,2023-03-06T15:03:39Z,2023-03-06T15:02:54Z,"I'm using 

gatk --java-options ""-Xmx10g"" CombineGVCFs

on clair3 gvcf output.  I encountered this error.

htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 97073593: unparsable vcf record with allele TGTGB

The offending input line is

chr3    16902879        .       TGTGB   T,<NON_REF>     12.03   PASS    F       GT:GQ:DP:AD:AF:PL       0/1:12:38:26,11,0:0.2895:15,0,57,990,990,990

If this output is actually compatible with a version of GATK, could you please tell what version?  The error was generated using  v4.1.8.1.  

Thanks.



",shinlin77,https://github.com/HKU-BAL/Clair3/issues/153
I_kwDOFQnk285XaHis,Contig names not recognized,CLOSED,2022-11-28T13:50:37Z,2022-11-28T15:23:14Z,2022-11-28T15:23:13Z,"Hello,

I have problems running Clair3 on aligned ONT reads (MInimap2 used for alignment). I get the following error message:
```
[WARNING] Contig name 7 provided but no mapped reads in BAM, skip!
[WARNING] No mapped reads support in BAM for provided contigs set 7
[WARNING] No contig intersection found, output header only in /mnt/ssd_disk/Oxford_run_arrow/Clair3_output/merge_output.vcf.gz
[INFO] Exit in environment checking
```
but I clearly see reads aligned to 7 when running
`samtools view ${INPUT_DIR}/sample1.fastq.gz.sam.bam -L ${INPUT_DIR}/chr7.bed`

The same error pops up for all chromosomes when do not restrict the target. Any idea what can be the issue?",s-kubik,https://github.com/HKU-BAL/Clair3/issues/154
I_kwDOFQnk285XyHVX,secondary and supplementary alignment use,CLOSED,2022-12-02T12:00:25Z,2022-12-02T12:12:13Z,2022-12-02T12:11:57Z,"I assumed secondary and supplementary alignments were not used in snp calling from 
`VIEW_FILTER_FLAG=2316` in [param_f.py](https://github.com/HKU-BAL/Clair3/blob/main/shared/param_f.py)

Looks like the case so ignore",rob234king,https://github.com/HKU-BAL/Clair3/issues/155
I_kwDOFQnk285XyL9t,Clair3 does not call all positions with --vcf_fn,CLOSED,2022-12-02T12:14:42Z,2023-01-02T23:50:24Z,2023-01-02T23:50:24Z,"Hello!

I am using Clair3 to call SNPs from Nanopore reads on different samples and have a call for all positions detected in each samples. To do so, I ran Clair3 once on all samples, made a multivcf with all positions from all samples, and rerun Clair3 again with --vcf_fn=mypositions.vcf --print_ref_calls --include_all_ctgs. 

My datasets are small (220 contigs covering 3 Mo bp) so it is quite fast. However, many positions present in the vcf I supply with --vcf_fn are not called in the samples (ex: 24 000 positions, only 9000 calls in some samples). I do have some positions properly calls with ""refcall"" in the vcf, but many are missing. What could be the cause of this? I have a min average coverage of 10X for all samples on all these contigs.

Sincerely

David",david-roquis,https://github.com/HKU-BAL/Clair3/issues/156
I_kwDOFQnk285Yg4uY,tumour-normal mode,CLOSED,2022-12-08T16:46:27Z,2023-09-06T14:42:43Z,2023-09-06T14:42:43Z,"Hi,

Are there any plans to develop a tumour-normal joint calling mode?

Thanks",rowanhowellGE,https://github.com/HKU-BAL/Clair3/issues/157
I_kwDOFQnk285ZBSJ3,"errors for illumina full alignment calling, questions for merging output.",CLOSED,2022-12-13T06:43:21Z,2023-01-02T23:50:33Z,2023-01-02T23:50:33Z,"hello！
When I ran sh trainfullalignment_illumina_r1.sh, at the end Merge compressed binaries reported an error：
Traceback (most recent call last):
  File ""/work/Clair3-main1212/clair3.py"", line 105, in <module>
    main()
  File ""/work/Clair3-main1212/clair3.py"", line 99, in main
    submodule.main()
  File ""/work/Clair3-main1212/preprocess/MergeBin.py"", line 91, in main
    Run(args)
  File ""/work/Clair3-main1212/preprocess/MergeBin.py"", line 56, in Run
    table_dict = utils.write_table_file(table_file, table_dict, tensor_shape, param.label_size, float_type)
  File ""/work/Clair3-main1212/clair3/utils.py"", line 245, in write_table_file
    position_matrix = np.array(table_dict['position_matrix'], np.dtype(float_type)).reshape([-1] + tensor_shape)
ValueError: cannot reshape array of size 7260000 into shape (89,33,8)
Closing remaining open files:/work/Clair3-main-sy/data/datatest/Illumina/fullalign/outputref-HG001_GRCh38-1212//build/tensor_can/tensor_hg001_1000_22_1...done/work/Clair3-main-sy/data/datatest/Illumina/fullalign/outputref-HG001_GRCh38-1212//build/bins/bin_hg001_1000_22...done
[INFO] Merging file /work/Clair3-main-sy/data/datatest/Illumina/fullalign/outputref-HG001_GRCh38-1212//build/tensor_can/tensor_hg002_1000_22_1
Traceback (most recent call last):
  File ""/work/Clair3-main1212/clair3.py"", line 105, in <module>
    main()
  File ""/work/Clair3-main1212/clair3.py"", line 99, in main
    submodule.main()
  File ""/work/Clair3-main1212/preprocess/MergeBin.py"", line 91, in main
    Run(args)
  File ""/work/Clair3-main1212/preprocess/MergeBin.py"", line 56, in Run
    table_dict = utils.write_table_file(table_file, table_dict, tensor_shape, param.label_size, float_type)
  File ""/work/Clair3-main1212/clair3/utils.py"", line 245, in write_table_file
    position_matrix = np.array(table_dict['position_matrix'], np.dtype(float_type)).reshape([-1] + tensor_shape)
ValueError: cannot reshape array of size 7260000 into shape (89,33,8)
Closing remaining open files:/work/Clair3-main-sy/data/datatest/Illumina/fullalign/outputref-HG001_GRCh38-1212//build/tensor_can/tensor_hg002_1000_22_1...done/work/Clair3-main-sy/data/datatest/Illumina/fullalign/outputref-HG001_GRCh38-1212//build/bins/bin_hg002_1000_22...done


I tried changing to ont model and found it correct, but while testing sh clair3_ilmn_quick_demo.sh reported an error:.
Total processed positions in chr20 (chunk 1/1) : 0
[ERROR] No full-alignment output for file chr20//work/Clair3-main/data/datatest/Illumina/clair3_illumina_quickDemo/output/tmp/full_alignment_output/full_alignment_chr20.0_1.vcf
Total time elapsed: 0.00 s
",shiying-sxu,https://github.com/HKU-BAL/Clair3/issues/158
I_kwDOFQnk285ayB0E,Calling variants from RNA,CLOSED,2023-01-06T19:54:28Z,2023-01-16T00:55:56Z,2023-01-16T00:55:56Z,"To call variants from RNA-Seq data. Reads mapped to the humgen reference with HiSat2 typically used for RNA-Seq. Would the ilmn model work for calling?

",husamia,https://github.com/HKU-BAL/Clair3/issues/159
I_kwDOFQnk285bU3hL,Loosing information after update from R9 to R10 flowcell,CLOSED,2023-01-13T11:59:13Z,2023-08-17T03:05:50Z,2023-08-17T03:05:50Z,"Hi, 

I'm facing a curious problem. I've sequenced twice a sample : first with the R9 flowcell version and second with the R10 flowcell version, and it looks like I'm loosing some information in the clair3 results when I am interested in a particular variant. Here some results : 

Both sequencing had been proceeded with : 
```
_ Guppy : ont_guppy_for_gridion 6.3.8
_ Clair3 : Clair3 v0.1-r11 proceeded with a seqtk subsampling of 1000 reads (higher than Q7) from the initial fastq
```

##### 1. Command line with the flowcells R9.4.1 with Kit 12 chemistry :
```
/opt/bin/run_clair3.sh \
    --bam_fn=""run_minimap2_ont.bam"" --ref_fn=""hg19.fasta"" --threads=6 --platform=""ont"" \
    --model_path=""r941_prom_sup_g5014"" --output=""run"" --bed_fn=""gene.bed"" --enable_phasing
```
Result : I found my variant in 100% (among 100 tests) of my VCF outputs.

##### 2. Command line with the flowcells R10.4.1 with Kit 14 chemistry :
```
/opt/bin/run_clair3.sh \
    --bam_fn=""run_minimap2_ont.bam"" --ref_fn=""hg19.fasta"" --threads=6 --platform=""ont"" \
    --model_path=""r1041_e82_400bps_hac_g632"" --output=""run"" --bed_fn=""gene.bed"" --enable_phasing
```
Result : I found my variant in 91% (among 100 tests) of my VCF outputs.

Do you know a potential reason about why I'm loosing my interested variant in 9% of the case when I'm upgrading the flowcell version from R9 to R10? I've also tested the R10 protocol with the r1041_e82_260bps_hac_g632 and all the VCF outputs didn't contain my variant of interest.

Many thanks in advance.
Best regards,
Boris
",Lipinski-B,https://github.com/HKU-BAL/Clair3/issues/160
I_kwDOFQnk285bVU2a,Missing variants in merge_output.vcf.gz,CLOSED,2023-01-13T13:35:46Z,2023-03-08T12:51:45Z,2023-02-10T03:07:33Z,"Hi There,

I noticed that a range of variants that have passed the quality checks in `pileup.vcf.gz` and `full_alignment.vcf.gz` that are missing from `merge_output.vcf.gz`. 

Is this a known bug in the latest version of Clair3 that is available through conda? What is the best way to fix this? I see those variants present in the BAM alignments and they are picked up properly in previous stages of the pipeline, but they are missing from the final output file.

Thanks
Sej",sejmodha,https://github.com/HKU-BAL/Clair3/issues/161
I_kwDOFQnk285bVn7J,BrokenPipeError: [Errno 32] Broken pipe,CLOSED,2023-01-13T14:35:16Z,2023-01-16T11:41:45Z,2023-01-16T11:41:45Z,"If the amount of data is too large, the following errors will be reported. What parameters can I change to prevent errors?
[INFO] Delay 4 seconds before starting tensor creation ...
Loading the dataset ...
[mpileup] 1 samples in 1 input files
Note: detected 112 virtual cores but NumExpr set to maximum of 64, check ""NUMEXPR_MAX_THREADS"" environment variable.
Note: NumExpr detected 112 cores but ""NUMEXPR_MAX_THREADS"" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.
[INFO] Compressed 6456/99999 tensor
Finish!
Traceback (most recent call last):
  File ""/home/gyc/anaconda3/envs/r12/bin/preprocess/../clair3.py"", line 94, in <module>
    main()
  File ""/home/gyc/anaconda3/envs/r12/bin/preprocess/../clair3.py"", line 88, in main
    submodule.main()
  File ""/home/gyc/anaconda3/envs/r12/bin/preprocess/CreateTensorFullAlignment.py"", line 1057, in main
    CreateTensorFullAlignment(args)
  File ""/home/gyc/anaconda3/envs/r12/bin/preprocess/CreateTensorFullAlignment.py"", line 896, in CreateTensorFullAlignment
    tensor_can_fp.stdin.write(tensor)
BrokenPipeError: [Errno 32] Broken pipe",oranges7,https://github.com/HKU-BAL/Clair3/issues/162
I_kwDOFQnk285cp7Bp,Error while opening BGZF compressed FASTA reference file,CLOSED,2023-01-24T08:01:02Z,2024-07-04T01:25:12Z,2024-07-04T01:25:12Z,"Running clair3 without `--longphase_for_phasing` results in an error when using a bgzipped reference indexed with samtools:
```bash
apptainer exec clair3-v0.1-r12.sif \
/opt/bin/run_clair3.sh \
--bam_fn=test.cram \
--ref_fn=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz \
--platform=""ilmn"" \
--model_path=""/opt/models/ilmn"" \
--output=""./output""
```
Error:
```
[INFO] 3/7 Phase VCF file using Whatshap
This is WhatsHap 1.4 running under Python 3.9.0
ERROR: whatshap error: Error while opening FASTA reference file: Compressed FASTA is only supported in BGZF format. Use the samtools bgzip utility (instead of gzip) to compress your FASTA.
```
Note that the reference is actually bgzipped with the bgzip utility even though the error states that the format is not bgzip.

Possibly related issues:
- https://github.com/whatshap/whatshap/issues/151
  - https://github.com/mdshw5/pyfaidx/issues/126

Currently we are working around the issue by using an uncompressed reference.",dennishendriksen,https://github.com/HKU-BAL/Clair3/issues/163
I_kwDOFQnk285cunH1,Missing phasing on some variants,CLOSED,2023-01-24T21:47:27Z,2023-01-26T15:09:13Z,2023-01-26T15:09:13Z,"Hello,
I ran Clair3 R10 model with the --enable_phasing option and noticed not all variants are phased in the final output. The two positions I am looking at are 29 bp apart on the same amplicon. Does this indicate a failure of the phasing algorithm or do I need to change another parameter? I've pasted the VCF output below and attached an IGV screenshot of the region.
chr7	117548606	.	A	ATG	22.5	PASS	F	GT:GQ:DP:AF	0/1:22:69:0.2464
chr7	117548628	.	G	T	22.34	PASS	F	GT:GQ:DP:AF:PS	1|0:22:69:0.3913:117548628

<img width=""134"" alt=""Screenshot 2023-01-24 at 4 40 48 PM"" src=""https://user-images.githubusercontent.com/60239089/214428140-d4c5879f-d32a-4aa5-ba5a-255f7e438848.png"">
",mproberts99,https://github.com/HKU-BAL/Clair3/issues/164
I_kwDOFQnk285dAjSu,Deprecated numpy.int call in preprocess/CreateTensorPileupFromCffi.py,CLOSED,2023-01-27T20:59:28Z,2023-03-06T15:05:43Z,2023-03-06T15:05:43Z,"preprocess/CreateTensorPileupFroCffi.py contains a call to numpy.int as np.int.  This results in an empty vcf file but doesn't throw an error.  Numpy.int has been deprecated since version 1.20.0 and creates an error using the dockerfile provided by the repo.  Numpy recommends replacing numpy.int with int.  I can fork a branch and make this change for a PR if needed.

Traceback from run_clair3.log below.

[INFO] 1/7 Call variants using pileup model
Calling variants ...
Traceback (most recent call last):
  File ""/opt/bin/scripts/../clair3.py"", line 105, in <module>
    main()
  File ""/opt/bin/scripts/../clair3.py"", line 99, in main
    submodule.main()
  File ""/opt/bin/clair3/CallVariantsFromCffi.py"", line 347, in main
    Run(args)
  File ""/opt/bin/clair3/CallVariantsFromCffi.py"", line 61, in Run
    call_variants_from_cffi(args=args, output_config=output_config, output_utilities=output_utilities)
  File ""/opt/bin/clair3/CallVariantsFromCffi.py"", line 117, in call_variants_from_cffi
    tensor, all_position, all_alt_info = CT(args)
  File ""/opt/bin/preprocess/CreateTensorPileupFromCffi.py"", line 329, in CreateTensorPileup
    chunk_result, all_alt_info_list, gvcf_output = pileup_counts_clair3(region,
  File ""/opt/bin/preprocess/CreateTensorPileupFromCffi.py"", line 84, in pileup_counts_clair3
    chunk_results, all_alt_info_list, gvcf_output = __enforce_pileup_chunk_contiguity(results)
  File ""/opt/bin/preprocess/CreateTensorPileupFromCffi.py"", line 194, in __enforce_pileup_chunk_contiguity
    for counts, positions, alt_info_list, gvcf_output in pileups:
  File ""/opt/conda/envs/clair3/lib/python3.9/concurrent/futures/_base.py"", line 600, in result_iterator
    yield fs.pop().result()
  File ""/opt/conda/envs/clair3/lib/python3.9/concurrent/futures/_base.py"", line 440, in result
    return self.__get_result()
  File ""/opt/conda/envs/clair3/lib/python3.9/concurrent/futures/_base.py"", line 389, in __get_result
    raise self._exception
  File ""/opt/conda/envs/clair3/lib/python3.9/concurrent/futures/thread.py"", line 52, in run
    result = self.fn(*self.args, **self.kwargs)
  File ""/opt/bin/preprocess/CreateTensorPileupFromCffi.py"", line 63, in _process_region
    np_counts, positions, alt_info_string_list, gvcf_output = _plp_data_to_numpy(
  File ""/opt/bin/preprocess/CreateTensorPileupFromCffi.py"", line 141, in _plp_data_to_numpy
    size_sizet = np.dtype(np.int).itemsize
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/numpy/__init__.py"", line 284, in __getattr__
    raise AttributeError(""module {!r} has no attribute ""
AttributeError: module 'numpy' has no attribute 'int'
",AJTDaedalus,https://github.com/HKU-BAL/Clair3/issues/165
I_kwDOFQnk285dp4BC,Data request,CLOSED,2023-02-05T06:05:29Z,2023-02-06T07:42:27Z,2023-02-06T07:42:27Z,"I cannot download this data, could you please share it with me? I am in the mainland. 

http://www.bio8.cs.hku.hk/clairvoyante/orginalData_hg002/illumina/HG002.GRCh38.50x.rg.bam


Thank you very much!",shiying-sxu,https://github.com/HKU-BAL/Clair3/issues/167
I_kwDOFQnk285eAfso,About the Visualization of Clair3's Representation Unification,CLOSED,2023-02-09T03:52:44Z,2023-02-10T13:06:48Z,2023-02-10T13:06:48Z,"I want to do a small research on your algorithm clair3, but due to my poor programming skills, I have been unable to realize the image display (such as ont_HG002-chr1:1057428-1057485.png). I refer to the code of the visualization.ipynb in your clairvoyante work, and there are always errors. I would like to ask if you can share the code of your visualization with me, thank you very much!

http://www.bio8.cs.hku.hk/clair3/visualization/representation_unification/ont_HG002-chr1:1057428-1057485.png


",shiying-sxu,https://github.com/HKU-BAL/Clair3/issues/168
I_kwDOFQnk285eUdB4,resume pipeline from stalled process,CLOSED,2023-02-13T14:09:00Z,2023-02-27T23:53:57Z,2023-02-27T23:53:57Z,"I ran the command 

`run_clair3.sh --bam_fn=sample_GRCh38_sorted.bam --ref_fn=../Homo_sapiens_assembly38.fasta --model_path=/opt/models/ilmn/ --threads=5 --platform=ilmn -o sample_GRCh38_Clair3.vcf.gz --sample_name=name --gvcf --remove_intermediate_dir --enable_long_indel`

I have antimalware scanner running which stalled my process at this step. No error message. Just completely stopped for days. a known issue with Docker Desktop and Antimalware Service in Windows

`[INFO] 7/7 Merge pileup VCF and full-alignment VCF
`

How can I resume?",husamia,https://github.com/HKU-BAL/Clair3/issues/170
I_kwDOFQnk285emhmB,AssertionError：(len(fi.root.label) == len(fi.root.position) == len(fi.root.position_matrix) == len(fi.root.alt_info)),CLOSED,2023-02-16T07:15:02Z,2023-03-14T02:52:43Z,2023-03-14T02:52:43Z,"""assert (len(fi.root.label) == len(fi.root.position) == len(fi.root.position_matrix) == len(fi.root.alt_info))
AssertionError""

Hi，
 I get the error about above, when training the full-alignment model. The number of ""len(fi.root.label)"" is 3X comparing  ""len(fi.root.position)"",""len(fi.root.position_matrix)"" and ""len(fi.root.alt_info))"". The steps of before are correct. How can resolve this issue, thanks for your help!
 best wishes!",willow2333,https://github.com/HKU-BAL/Clair3/issues/171
I_kwDOFQnk285emviH,Does the data of training r941_prom_hac_g360+g422 model use HG002 with 432 coverage?,CLOSED,2023-02-16T08:02:42Z,2023-02-27T23:51:34Z,2023-02-27T23:51:34Z,Does the data of training r941_prom_hac_g360+g422 model use HG002 with 432 coverage?,oranges7,https://github.com/HKU-BAL/Clair3/issues/172
I_kwDOFQnk285erKcx,Wondering if you know the phasing accuracy among duplications in the human genome,CLOSED,2023-02-16T21:16:44Z,2023-03-14T02:52:53Z,2023-03-14T02:52:53Z,"Hello!

I have a 5x copy number of a 7000bp region on an autosome. It's being phased as homozygous ( I used Clair3, and then WhatsHap haplotag). It's within the same phase block. This is a little disconcerting since it's such a specific structural variant. 

I'm looking at using population data to determine if this is true, or if it's a result of the read going through the same region several times with not much flanking sequence. Wondering if you have any ideas or thoughts?

Thanks kindly,
Sarah",sarahdada,https://github.com/HKU-BAL/Clair3/issues/173
I_kwDOFQnk285fOL6w,No phased indel variants in phased_merged_output.vcf.gz,CLOSED,2023-02-23T21:29:58Z,2023-02-27T23:54:16Z,2023-02-27T23:54:16Z,"Hi,

First of all, great tool!

After running clair3 with ""--enable_phasing"", I found that all the indel variants are not phased in the final phased_merged_output.vcf.gz, is this intended?
If so, is there any option to enable the indel phasing?

Thanks!
Yan",yangao07,https://github.com/HKU-BAL/Clair3/issues/174
I_kwDOFQnk285fTEwd,Docker container fails when running with host user (`-u`),CLOSED,2023-02-24T15:21:26Z,2023-03-06T15:05:58Z,2023-03-06T15:05:57Z,"I'll try to explain the problem to the best of my ability:

Per default, the user in a Docker container is `root`. This entails that any files created in mounted directories by commands run in the container are owned by `root` and can only be read by other users, not written to. To get around this, many people are adding `-u $(id -u)` to their `docker run` command.

However, this user does not exist in the container and thus does not have a default shell. The container will therefore fall back to using `/bin/sh`. Crucially, the env variable `SHELL` is set at this stage and, as you might be aware, shells don't set `SHELL` themselves (`SHELL` is set [on login](https://unix.stackexchange.com/a/277949/367507); i.e. if you start `bash` from another shell it won't set `SHELL` to `/bin/bash`; it will just inherit the `SHELL` env variable from the previous shell; you can test this by running `SHELL=bla bash -c 'echo $SHELL'`). Taken together, this means that, when the user runs

```
docker run \
  -v ${INPUT_DIR}:${INPUT_DIR} \
  -v ${OUTPUT_DIR}:${OUTPUT_DIR} \
  -u $(id -u):$(id -g) \
  hkubal/clair3:latest \
  /opt/bin/run_clair3.sh \
  ... other options ...
```
they will get the following error: 
```
/opt/bin/scripts/clair3_c_impl.sh: 121: readarray: not found
```
This is because the following happens:
* the container starts off using `sh` since there is no default shell for the user `$(id -u)`; this sets `SHELL` to `/bin/sh`
* `/opt/bin/run_clair3.sh` is run _by `bash`_, but `SHELL` is _still_ `/bin/sh`
* in `run_clair3.sh` you use `${SHELL}` to invoke `/opt/bin/scripts/clair3_c_impl.sh` https://github.com/HKU-BAL/Clair3/blob/21e7eada8226cdd3c5bbb5ec9fe401a01bcbf1e5/run_clair3.sh#L346
* `/opt/bin/scripts/clair3_c_impl.sh` is run by `/bin/sh` which lacks the `bash` built-in `readarray` and thus fails

To fix this, I would suggest calling `${SCRIPT_PATH}/scripts/${CLAIR3_SCRIPT}` without `${SHELL}` (i.e. just `${SCRIPT_PATH}/scripts/${CLAIR3_SCRIPT} ... options ...` since the other scripts all have shebang lines anyway.",julibeg,https://github.com/HKU-BAL/Clair3/issues/175
I_kwDOFQnk285fXvzL,Can we test for SV variant calling？,CLOSED,2023-02-26T13:33:34Z,2023-02-27T23:43:30Z,2023-02-27T23:43:30Z,"I saw that Switch zygosity based on SV calls can be made in postprocessing, and I would like to ask whether Clair3 can realize SV variation detection",shiying-sxu,https://github.com/HKU-BAL/Clair3/issues/176
I_kwDOFQnk285fZhSQ,Clair3 and Dorado,CLOSED,2023-02-27T05:53:02Z,2023-02-27T18:50:06Z,2023-02-27T18:50:06Z,"Does Clair3 work with dorado base-called fastqs?

If so, what model (path) do we use please?

Thanks.",felixm3,https://github.com/HKU-BAL/Clair3/issues/177
I_kwDOFQnk285f4T_0,chrM by default,CLOSED,2023-03-03T13:05:29Z,2023-03-14T02:53:05Z,2023-03-14T02:53:05Z,"This is just a suggestion, since the solution is quite clear by specifying contigs with `--ctg_name`. 

We were running Clair3 for a large number of samples and only recently did we realize it wasn't calling variants in chrM. Since it's such a small contig and it's considered of clinical importance, would you consider adding it to the default chromosomes Clair3 considers for variant-calling?

We believe that introducing it to the defaults would be beneficial to other users as well.",Coppini,https://github.com/HKU-BAL/Clair3/issues/178
I_kwDOFQnk285gMZT4,"[WARNING] No contig intersection found, output header only",CLOSED,2023-03-07T17:05:14Z,2023-11-27T12:05:59Z,2023-03-08T08:41:00Z,"Hello, 

### My Problem :
I'm trying to run clair3 on my ONT data but I keep encountering this message which output a vcf with headers only :
`[WARNING] No contig intersection found, output header only in variant_calling/results/merge_output.vcf.gz`

### My commands :
The command I ran was :
`run_clair3.sh -b $bam -f $ref -m $model -t 8 -p ont -o $output --snp_min_af=0.05`

and it gave me : 
```
[INFO] CLAIR3 VERSION: v1.0.0
[INFO] BAM FILE PATH: variant_calling/results/minimap2/${sample}_sorted.bam
[INFO] REFERENCE FILE PATH: MN908947.fna
[INFO] MODEL PATH: model_1/r1041_e82_260bps_sup_g632
[INFO] OUTPUT FOLDER: variant_calling/results
[INFO] PLATFORM: ont
[INFO] THREADS: 8
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX:
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] PHASING PROPORTION: 0.7
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.05
[INFO] INDEL AF THRESHOLD: 0.15
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE LONGPHASE FOR INTERMEDIATE VCF PHASING: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING WHATSHAP: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING LONGPHASE: False
[INFO] ENABLE HAPLOTAGGING FINAL BAM: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE C_IMPLEMENT: True

+ /opt/bin/scripts/clair3_c_impl.sh --bam_fn variant_calling/results/minimap2/${sample}_sorted.bam --ref_fn MN908947.fna --threads 8 --model_path variant_calling/model_1/r1041_e82_260bps_sup_g632 --platform ont --output variant_calling/results --bed_fn=EMPTY --vcf_fn=EMPTY --ctg_name=EMPTY --sample_name=SAMPLE --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=2 --var_pct_full=0.7 --ref_pct_full=0.1 --var_pct_phasing=0.7 --snp_min_af=0.05 --indel_min_af=0.15 --min_mq=5 --min_coverage=2 --min_contig_size=0 --pileup_only=False --gvcf=False --fast_mode=False --call_snp_only=False --print_ref_calls=False --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=False --no_phasing_for_fa=False --pileup_model_prefix=pileup --fa_model_prefix=full_alignment --remove_intermediate_dir=False --enable_phasing=False --enable_long_indel=False --keep_iupac_bases=False --use_gpu=False --longphase_for_phasing=False --longphase=EMPTY --use_whatshap_for_intermediate_phasing=True --use_longphase_for_intermediate_phasing=False --use_whatshap_for_final_output_phasing=False --use_longphase_for_final_output_phasing=False --use_whatshap_for_final_output_haplotagging=False

[INFO] Check environment variables
[INFO] Create folder variant_calling/results/log
[INFO] Create folder variant_calling/results/tmp
[INFO] Create folder variant_calling/results/tmp/pileup_output
[INFO] Create folder variant_calling/results/tmp/merge_output
[INFO] Create folder variant_calling/results/tmp/phase_output
[INFO] Create folder variant_calling/results/tmp/gvcf_tmp_output
[INFO] Create folder variant_calling/results/tmp/full_alignment_output
[INFO] Create folder variant_calling/results/tmp/phase_output/phase_vcf
[INFO] Create folder variant_calling/results/tmp/phase_output/phase_bam
[INFO] Create folder variant_calling/results/tmp/full_alignment_output/candidate_bed
[INFO] --include_all_ctgs not enabled, use chr{1..22,X,Y} and {1..22,X,Y} by default
[WARNING] No contig intersection found, output header only in variant_calling/results/merge_output.vcf.gz
[INFO] Exit in environment checking
```

### Other commands : 

fastq come from an ONT experiment on lastest chemestry and flowcell.
The model I used r1041_e82_260bps_sup_g632 was obtained with rerio.
bam files were obtained with minimap2, sorted and indexed with samtools.
reference was indexed with samtools faidx

The flagstats report seems ok to me :
```
468581 + 0 in total (QC-passed reads + QC-failed reads)
43 + 0 secondary
45152 + 0 supplementary
0 + 0 duplicates
468581 + 0 mapped (100.00% : N/A)
0 + 0 paired in sequencing
0 + 0 read1
0 + 0 read2
0 + 0 properly paired (N/A : N/A)
0 + 0 with itself and mate mapped
0 + 0 singletons (N/A : N/A)
0 + 0 with mate mapped to a different chr
0 + 0 with mate mapped to a different chr (mapQ>=5)
```
I've checked that my bam file was correctly build with Picard ValidateSamFile and output this error message which I consider not critical :

```Error Type      Count
ERROR:MISSING_READ_GROUP        1
WARNING:RECORD_MISSING_READ_GROUP       468581
```
I'm using Clair3 v1.0.0 on a singularity image build with the singularity command given in the tutorial.

### Commentary :

Maybe I'm missing out something obvious but I could not find this warning message anywhere to guide me. I don't understand the contig intersection part of the message. If you could give me a hint on what is going on with my data, that would really help me.
If you need any extra informations let me know.

Thank you for your help !
",BoyerTheo,https://github.com/HKU-BAL/Clair3/issues/179
I_kwDOFQnk285gbWEV,Unexpected calls to www.ebi.ac.uk when using cram files,CLOSED,2023-03-09T18:27:57Z,2024-03-16T01:08:16Z,2023-05-03T15:49:38Z,"We use clair3 for out variant calling and provide it with our own reference fasta file.
We are seeing some unexpected calls to https://www.ebi.ac.uk in the cases we are using cram files as input.

From the log:
Calling variants ...
```
[W::find_file_url] Failed to read reference ""https://www.ebi.ac.uk/ena/cram/md5/3210fecf1eb92d5489da4346b3fddc6e"": Broken pipe
Total processed positions in chr4 (chunk 3/39) : 0
```

Our hypothesis is that the samtools call used to work with the cram files is not provided with the reference file (-T argument), and therefor falls back to www.ebi.ac.uk.

In addition to the fact that we would like our pipeline to be selfcontained and not dependent on external servers, this can also lead to quite severe performance losses if the connection to www.ebi.ac.uk is slow.

Currently we work around the issue by converting our crams to bams and using those for clair3.
",bartcharbon,https://github.com/HKU-BAL/Clair3/issues/180
I_kwDOFQnk285gcItv,[ERROR] No full-alignment output for file,CLOSED,2023-03-09T21:00:14Z,2023-04-06T14:23:54Z,2023-03-23T05:31:24Z,"Hi,

I'm getting a lot of ""[ERROR] No full-alignment output for file"" error lines in the log. I got the ""merge_output.vcf.gz"" file which contains a lot of variants (5,774,275 PASS ones), but the ""full_alignment.vcf.gz"" file is empty except the header lines. There are ""LowQual"" variants as indicated in the FILTER column in ""merge_output.vcf.gz"". So what does the error mean and how should I fix it?
For the final variant calling results, should I use the ""PASS"" ones from ""merge_output.vcf.gz"", or the ones in ""full_alignment.vcf.gz""?
I'm using version 1.0.0.
Thanks.",weishwu,https://github.com/HKU-BAL/Clair3/issues/181
I_kwDOFQnk285gxN2Q,Post processing via conda,CLOSED,2023-03-14T13:45:45Z,2023-03-15T10:55:40Z,2023-03-15T10:55:39Z,"Hi, 

I installed clair3 via conda and ran it successfully on ONT amplicon reads. However I was unable to run the postprocessing ""SwitchZygosityBasedOnSVCalls"" module. Upon further looks, it seems like the postprocessing directory and scripts are completely missing from the conda release. Unsure if this can be fixed by simply cloning that directory off github and inserting it into my conda install or should I follow these guidelines here: https://github.com/HKU-BAL/Clair3/issues/146#issuecomment-1294717606

",damioresegun,https://github.com/HKU-BAL/Clair3/issues/182
I_kwDOFQnk285gxpNZ,run SwitchZygosityBasedOnSVCalls with singularity image?,CLOSED,2023-03-14T14:42:01Z,2023-03-23T05:31:13Z,2023-03-23T05:31:13Z,"Hi, 
I have successfully ran clair3 with a singularity image on ONT reads. However, when I try to run ""SwitchZygosityBasedOnSVCalls"" module, I run into problems- error message does not recognize the options --clair3_vcf_input --sv_vcf_input or  --vcf_output. Is there a workaround for this or is this module not available through docker installation?

FYI, I have made my image using the latest version on docker hub (as of 8 days ago). 

Thanks,
Mari",MariBGO,https://github.com/HKU-BAL/Clair3/issues/183
I_kwDOFQnk285hAEGo,Any data on non-model organisms,CLOSED,2023-03-16T12:47:13Z,2023-03-23T05:31:02Z,2023-03-23T05:31:02Z,"Hello, 

I was wondering if you had any idea of how Clair3 would perform in a non-model organisms, with a high heterozygosity of around 2%. 
Any model available to deal with this? 

Thanks 

Alex",N/A,https://github.com/HKU-BAL/Clair3/issues/184
I_kwDOFQnk285hQR-M,Doubts about downsampling,CLOSED,2023-03-20T08:54:24Z,2023-04-17T11:44:16Z,2023-04-17T11:44:16Z,"Hi，

Are both guppy4 and guppy5 data subsampled to a depth of 8X when training the model, or are only guppy5 data subsampled?",oranges7,https://github.com/HKU-BAL/Clair3/issues/185
I_kwDOFQnk285hiaQr,SwitchZygosityBasedOnSVCalls error,CLOSED,2023-03-22T19:53:53Z,2023-04-26T16:24:01Z,2023-04-10T09:26:15Z,"SwitchZygosityBasedOnSVCalls is showing the following error when using VCF from latest version of Sniffles2:

Traceback (most recent call last):
  File ""/opt/bin/clair3.py"", line 105, in <module>
    main()
  File ""/opt/bin/clair3.py"", line 99, in main
    submodule.main()
  File ""/opt/bin/postprocess/SwitchZygosityBasedOnSVCalls.py"", line 456, in main
    Run(args)
  File ""/opt/bin/postprocess/SwitchZygosityBasedOnSVCalls.py"", line 348, in Run
    and v.af <= max_af_for_zygosity_switching \
TypeError: '<=' not supported between instances of 'NoneType' and 'float'

Sniffles2 VCF do not contain AF in the FORMAT column, it is present in INFO column and I that seems to break the execution. I'm not sure if it is related to Sniffles version but that seems the case.

I'm attaching a test.vcf with couple of records. Also have in mind there are records without AF annotated in Sniffles2 so might be safe to deal with those. 

[test.vcf.gz](https://github.com/HKU-BAL/Clair3/files/11044225/test.vcf.gz)


",biorococo,https://github.com/HKU-BAL/Clair3/issues/186
I_kwDOFQnk285iCALz,installation problem with: source activate clair3 && make PREFIX=${CONDA_PREFIX},CLOSED,2023-03-28T21:39:52Z,2023-04-17T11:45:38Z,2023-04-17T11:45:38Z,"Just following the instructions to install Clair3 using bioconda. Got to this section:

# compile samtools, longphase and cffi library for c implement
# after building, longphase binary is in `Clair3` folder
source activate clair3 && make PREFIX=${CONDA_PREFIX}

copy and pasted the command:
(clair3) heidi@heidi-VirtualBox:~/Clair3$ source activate clair3 && make PREFIX=${CONDA_PREFIX}


and got this error:
bash: activate: No such file or directory

When I try to run Clair3 I get the following error:
ModuleNotFoundError: No module named 'libclair3'

Looking through the previous issues, it seems this is related, but I'm at a loss to figure out how to fix it.

Thanks!",tickgirl,https://github.com/HKU-BAL/Clair3/issues/188
I_kwDOFQnk285i-GTW,samtools mpileup,CLOSED,2023-04-10T08:36:33Z,2023-04-17T11:46:25Z,2023-04-17T11:46:25Z,"The bed file generated after running SelectCandidates contains 34 sites on each line, but it should be （2 * 16 + 1 ）33 sites. The code says“# a windows region for create tensor # samtools mpileup not include last position”, but samtools mpileup outputs 34 sites，it will output the last position.",oranges7,https://github.com/HKU-BAL/Clair3/issues/189
I_kwDOFQnk285jS5yY,"Value ""None"" in REF column in g.vcf files",CLOSED,2023-04-13T07:46:33Z,2023-06-03T08:10:43Z,2023-04-17T11:43:25Z,"When working with the .g.vcf output of Clair3 I encounter these kind of lines:
```chr18	586947	.	None	<NON_REF>	0	.	END=586950	GT:GQ:MIN_DP:PL	0/0:6:2:0,6,59```

The value ""None"" in the REF column is not a valid value.",bartcharbon,https://github.com/HKU-BAL/Clair3/issues/190
I_kwDOFQnk285jS73k,Incorrect number of FORMAT/PL values in .g.vcf,CLOSED,2023-04-13T07:52:52Z,2023-04-28T14:24:58Z,2023-04-28T14:24:58Z,"I'm running into an issue where Clair3 produces invalid `.g.vcf` output resulting in errors when used with downstream tooling, e.g. BCFtools:
```
Incorrect number of FORMAT/PL values at chr2:14862711, cannot merge. The tag is defined as Number=G, but found
  4 values and 3 alleles. See also http://samtools.github.io/bcftools/howtos/FAQ.html#incorrect-nfields
```

Example output (unfortunately I can't share the input due to its sensitive nature):

`pileup.vcf.gz`:
```
chr2    14862711        .       C       .       7.03    RefCall P       GT:GQ:DP:AD:AF:PL       0/0:7:2:1:0.5000:2970
```
`full_alignment.vcf.gz`:
```
chr2    14862711        .       C       N       7.97    PASS    F       GT:GQ:DP:AD:AF:PL       0/1:7:3:1,1:0.3333:2970
```
`merge_output.vcf.gz`:
```
chr2    14862711        .       C       N       7.97    PASS    F       GT:GQ:DP:AD:AF:PL       0/1:7:3:1,1:0.3333:2970
```
`output.g.vcf.gz`:
```
chr2    14862711        .       C       N,<NON_REF>     7.97    PASS    F       GT:GQ:DP:AD:AF:PL       0/1:7:3:1,1,0:0.3333:2970,990,990,990
```

I think the error is in the `PL` computation in case the alternate allele value is `N`, caused by https://github.com/HKU-BAL/Clair3/blob/v1.0.0/clair3/CallVariants.py#L1395? Since the VCF field `PL` is of type `G` the field still must have one value for each possible genotype according to the VCF specification.

Possibly the following was intended in `full_alignment.vcf.gz`?
```
chr2    14862711        .       C       N       7.97    PASS    F       GT:GQ:DP:AD:AF:PL       0/1:7:3:1,1:0.3333:990,990,990
```",dennishendriksen,https://github.com/HKU-BAL/Clair3/issues/191
I_kwDOFQnk285jcXYV,colab failed,CLOSED,2023-04-14T14:40:15Z,2023-04-27T14:38:30Z,2023-04-27T14:38:30Z,"I tried Clair3 ONT quick demo in colab. It failed:

Traceback (most recent call last):
  File ""/content/Clair3/scripts/../clair3.py"", line 105, in <module>
    main()
  File ""/content/Clair3/scripts/../clair3.py"", line 99, in main
    submodule.main()
  File ""/content/Clair3/preprocess/CheckEnvs.py"", line 494, in main
    CheckEnvs(args)
  File ""/content/Clair3/preprocess/CheckEnvs.py"", line 267, in CheckEnvs
    check_tools_version(tool_version, required_tool_version)
  File ""/content/Clair3/preprocess/CheckEnvs.py"", line 64, in check_tools_version
    elif version < required_version:
  File ""/usr/local/envs/clair3/lib/python3.6/distutils/version.py"", line 52, in __lt__
    c = self._cmp(other)
  File ""/usr/local/envs/clair3/lib/python3.6/distutils/version.py"", line 337, in _cmp
    if self.version < other.version:
TypeError: '<' not supported between instances of 'str' and 'int'",yzhang-github-pub,https://github.com/HKU-BAL/Clair3/issues/192
I_kwDOFQnk285j2r6_,Bump Whatshap to v1.7?,CLOSED,2023-04-19T16:57:02Z,2023-04-27T14:26:13Z,2023-04-27T14:26:13Z,"Clair3 [pins WhatsHap at version 1.4](https://github.com/bioconda/bioconda-recipes/blob/9fba3ce5bd119835dee0242b06372b984074f797/recipes/clair3/meta.yaml#L36) and is missing out on some performance improvements, [particularly related to the `haplotag` step](https://github.com/whatshap/whatshap/commit/dd139ce445e87027a5da21e3729b98e85b48e372). Would it be appropriate to bump the version in the package and distribute a new version of Clair3 to conda with WhatsHap 1.7 pinned?",SamStudio8,https://github.com/HKU-BAL/Clair3/issues/193
I_kwDOFQnk285k5A97,A minor issue in snp call?,CLOSED,2023-05-02T15:48:17Z,2023-05-10T00:15:40Z,2023-05-10T00:15:40Z,"Dear Author,

Thanks for developing clair3 which is an excellent tool. I'd like to give feedback on some calls in vcf. Below is an example:

REF: **C**ATGCAGG, ALT: **C**. 

Since ""**C**"" in ALT is at one end of the REF (start, in this case), SNP can alternatively (or better?) be called as 
REF: ATGCAGG, ALT: - (for deletion).

The suggested call will be consistent with alignment of assembled contig against ref.",yzhang-github-pub,https://github.com/HKU-BAL/Clair3/issues/194
I_kwDOFQnk285k8PFB,Clair for identification of Cas9 insertions,CLOSED,2023-05-03T07:00:06Z,2023-05-03T15:48:33Z,2023-05-03T15:48:33Z,"Hello
I was wondering if Clair would be a good tool to study locations of Cas9 mediated insertions? The insertions are ~2kbp long",assafgrw,https://github.com/HKU-BAL/Clair3/issues/195
I_kwDOFQnk285k-x0D,model downloads links not working,CLOSED,2023-05-03T14:23:07Z,2023-05-04T15:02:43Z,2023-05-04T15:02:43Z,"Hi,

none of the model download links are working.  wonder if the server is down?

<img width=""707"" alt=""image"" src=""https://user-images.githubusercontent.com/16267955/235944770-ad5f3e16-cab0-4143-9953-81927df02158.png"">
",scfurl,https://github.com/HKU-BAL/Clair3/issues/196
I_kwDOFQnk285lk9A_,BAM file not found with Singularity,CLOSED,2023-05-10T15:29:51Z,2023-05-11T04:03:52Z,2023-05-11T04:03:52Z,"Hello,

I am running clair3 using a Singularity installation and the software cannot find my BAM file.  I've verified that the path is valid and the BAM file is present.

Here is my command:

singularity exec -B /software:/software /software/clair3/1.0.1_singularity/clair3_v1.0.1.sif /software/clair3/1.0.1_singularity/Clair3/run_clair3.sh  \
--bam_fn=/home/mjs/bams/sample1_sorted.bam  \
--ref_fn=../reference/genome.fa \
--output=/home/mjs/clair \
--threads=1 \
--platform=ont \
--model_path=../r941_prom_sup_g5

Here is the output:

[INFO] CLAIR3 VERSION: v1.0.1
[INFO] BAM FILE PATH: /home/mjs/bams/sample1_sorted.bam
[INFO] REFERENCE FILE PATH: ../reference/genome.fa
[INFO] MODEL PATH: ../r941_prom_sup_g5
[INFO] OUTPUT FOLDER: /home/mjs/clair
[INFO] PLATFORM: ont
[INFO] THREADS: 1
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: /home/mjs/miniconda3/envs/clair3
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] PHASING PROPORTION: 0.7
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.08
[INFO] INDEL AF THRESHOLD: 0.15
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE LONGPHASE FOR INTERMEDIATE VCF PHASING: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING WHATSHAP: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING LONGPHASE: False
[INFO] ENABLE HAPLOTAGGING FINAL BAM: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE C_IMPLEMENT: True

[ERROR] BAM file /home/mjs/bams/sample1_sorted.bam not found

real	0m0.001s
user	0m0.000s
sys	0m0.001s

Thank you.",schipma,https://github.com/HKU-BAL/Clair3/issues/197
I_kwDOFQnk285lzg62,FULL_ALN_FILE_*': No such file or directory,CLOSED,2023-05-12T17:55:02Z,2023-07-20T08:12:28Z,2023-05-31T23:22:28Z,"
Hi @zhengzhenxian,

I have just used latest version (1.0.1) of Clair3, I got error in one of my sample. Please note that there is no error with v0.1-r10 which I have been using for a long time. Can you help take a look on this advice me if this is bug/error of new release

`
ls: cannot access 'ERR6359501.Segment_3_PA.CY146886.clair3/tmp/full_alignment_output/candidate_bed/FULL_ALN_FILE_*': No such file or directory
`

Please see below log for more details and let me know if need more information

Thanks,
Hai



  [INFO] 2/7 Select heterozygous SNP variants for Whatshap phasing and haplotagging
  [WARNING] Cannot find any 0/1 variant in pileup output using variant quality cut-off proportion: 0.19999999999999996, total heterozygous variants: 0
  [WARNING] Set low variant quality score cut-off to 0.0
  [INFO] Select heterozygous pileup variants exceeding phasing quality cutoff 0
  [INFO] Total heterozygous SNP positions selected: CY146886: 0
  
  real	0m0.317s
  user	0m0.238s
  sys	0m0.088s
  
  [INFO] 3/7 Phase VCF file using Whatshap
  This is WhatsHap 1.7 running under Python 3.9.0
  Working on 1 sample from 1 family
  
  # Resource usage
  Maximum memory usage: 0.038 GB
  Time spent reading BAM/CRAM:                    0.0 s
  Time spent parsing VCF:                         0.0 s
  Time spent selecting reads:                     0.0 s
  Time spent phasing:                             0.0 s
  Time spent writing VCF:                         0.0 s
  Time spent finding components:                  0.0 s
  Time spent on rest:                             0.0 s
  Total elapsed time:                             0.0 s
  
  real	0m0.491s
  user	0m0.385s
  sys	0m0.117s
  
  [INFO] 5/7 Select candidates for full-alignment calling
  [WARNING] Cannot find any low-quality 0/1 or 1/1 variant in pileup output using variant quality cut-off proportion: 0.7, total variants: 0
  [WARNING] Set low variant quality score cut-off to 0.0
  [INFO] Set variants quality cutoff 0.0
  [INFO] Set reference calls quality cutoff 6.0
  [WARNING] Cannot find any low-quality 0/0, 0/1 or 1/1 variant in pileup output in contig CY146886
  [INFO] Low quality reference calls to be processed in CY146886: 0
  [INFO] Low quality variants to be processed in CY146886: 0
  
  real	0m0.337s
  user	0m0.289s
  sys	0m0.052s
  
  [INFO] 6/7 Call low-quality variants using full-alignment model
  ls: cannot access 'ERR6359501.Segment_3_PA.CY146886.clair3/tmp/full_alignment_output/candidate_bed/FULL_ALN_FILE_*': No such file or directory
  [INFO] No Candidate found! Exit in selecting full-alignment candidates
  
  real	0m6.411s
  user	0m5.689s
  sys	0m0.743s
`",nhhaidee,https://github.com/HKU-BAL/Clair3/issues/198
I_kwDOFQnk285nMeWn,Conda prefix not found,CLOSED,2023-05-29T23:43:23Z,2023-05-31T23:22:12Z,2023-05-31T23:22:12Z,"Hi @zhengzhenxian  We just ran into problem when running Clair3, we downloaded the `r1041_e82_400bps_sup_g615` model files from Rerio and provided this model for Clair3 but we got error `Conda prefix not found, please activate clair3 conda environment first, model path: /mnt/data6/FLU/nf-flu/clair3/bin/models/r1041_e82_400bps_sup_g615`. We run with docker container, can you advice us on this problem?

Thanks,
Hai

`[INFO] CLAIR3 VERSION: v0.1-r10
[INFO] BAM FILE PATH: /mnt/data6/FLU/work/0e/d71d74763126393c363708386cb7d2/23MB310073.Segment_5_NP.MT467124.bam
[INFO] REFERENCE FILE PATH: /mnt/data6/FLU/work/0e/d71d74763126393c363708386cb7d2/23MB310073.Segment_5_NP.MT467124.reference.fasta
[INFO] MODEL PATH: /mnt/data6/FLU/nf-flu/clair3/bin/models/r1041_e82_400bps_sup_g615
[INFO] OUTPUT FOLDER: /mnt/data6/FLU/work/0e/d71d74763126393c363708386cb7d2/23MB310073.Segment_5_NP.MT467124.clair3
[INFO] PLATFORM: ont
[INFO] THREADS: 2
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: 
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] PHASING PROPORTION: 0.7
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: True
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: True
[INFO] ENABLE INCLUDE ALL CTGS CALLING: True
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE PHASING VCF OUTPUT: False
[INFO] ENABLE LONG INDEL CALLING: True

[31m[ERROR] Conda prefix not found, please activate clair3 conda environment first, model path: /mnt/data6/FLU/nf-flu/clair3/bin/models/r1041_e82_400bps_sup_g615[0m

`",nhhaidee,https://github.com/HKU-BAL/Clair3/issues/199
I_kwDOFQnk285nc_Lo,Sometimes a newline is missing between the gvcf lines,CLOSED,2023-06-01T07:19:52Z,2023-10-25T14:45:14Z,2023-10-25T14:45:14Z,"Sometimes we are getting gvcf output files from clair like:
`chr1	1234	.	C	<NON_REF>	0	.	END=1235;AC=0;AN=2	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0chr1	1245	.	G	<NON_REF>	0	.	END=1246;AC=0;AN=2	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0`
instead of:
`chr1	1234	.	C	<NON_REF>	0	.	END=1235;AC=0;AN=2	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0
chr1	1245	.	G	<NON_REF>	0	.	END=1246;AC=0;AN=2	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0`

the newline is missing between the records. 

When we try again with exactly the same input, the problem does not occus, and it will result in a valid gvcf file, unfortunately this makes it hard to give you specific steps on how to reproduce.

We see this behaviour with on several different cluster and with multiple different input files.",bartcharbon,https://github.com/HKU-BAL/Clair3/issues/200
I_kwDOFQnk285ocb4Y,Diploid calls on X - is there a way to get haploid calls in male samples?,CLOSED,2023-06-12T09:10:05Z,2023-06-15T04:49:39Z,2023-06-15T04:49:39Z,"Is there a way to instruct clair3 that the input data belong to a male patient, and the calls on X should than be haploid instead of diploid?",bartcharbon,https://github.com/HKU-BAL/Clair3/issues/202
I_kwDOFQnk285oi_uw,Clair3 doesn't work with hs38DH.fa because HLA contigs contain colons,CLOSED,2023-06-13T04:21:51Z,2023-06-23T07:07:11Z,2023-06-23T07:07:11Z,"
I am running ONT's wf-human-variation nextflow pipeline. I found that it crashes when clair3 processes the HLA contigs in the hs38DH genome. Based on my understanding, the problem seems to be caused by the names of HLA contigs containing colons.

Is there a newer version of clair3 that works with the HLA contigs of hs38DH.fa? 

Error messages:
=============
  export REF_PATH=ref_cache/%2s/%2s/%s
  python $(which clair3.py) CallVariantsFromCffi             --chkpnt_fn model/pileup             --bam_fn pod5.pass.cram             --call_fn pileup_HLA-DRB1*10:01:01_1.vcf             --ref_fn hs38DH.fa             --ctgName HLA-DRB1*10:01:01             --chunk_id 1             --chunk_num 1             --platform ont             --fast_mode False             --snp_min_af 0.08             --indel_min_af 0.15             --minMQ 5             --minCoverage 2             --call_snp_only False             --gvcf false             --temp_file_dir gvcf_tmp_path             --pileup

Command exit status:
  1

Command output:
  (empty)

Command error:
  INFO:    Environment variable SINGULARITYENV_TMPDIR is set, but APPTAINERENV_TMPDIR is preferred
  INFO:    Environment variable SINGULARITYENV_NXF_DEBUG is set, but APPTAINERENV_NXF_DEBUG is preferred
  INFO:    underlay of /etc/localtime required more than 50 (78) bind mounts
  Calling variants ...
  Traceback (most recent call last):
    File ""/home/epi2melabs/conda/bin/clair3.py"", line 105, in <module>
      main()
    File ""/home/epi2melabs/conda/bin/clair3.py"", line 99, in main
      submodule.main()
    File ""/home/epi2melabs/conda/bin/clair3/CallVariantsFromCffi.py"", line 351, in main
      Run(args)
    File ""/home/epi2melabs/conda/bin/clair3/CallVariantsFromCffi.py"", line 62, in Run
      call_variants_from_cffi(args=args, output_config=output_config, output_utilities=output_utilities)
    File ""/home/epi2melabs/conda/bin/clair3/CallVariantsFromCffi.py"", line 156, in call_variants_from_cffi
      batch_output_method(position, alt_info_list, Y, output_config, output_utilities)
    File ""/home/epi2melabs/conda/bin/clair3/CallVariants.py"", line 1092, in batch_output
      output_with(
    File ""/home/epi2melabs/conda/bin/clair3/CallVariants.py"", line 1119, in output_with
      chromosome, position, reference_sequence = chr_pos_seq.rstrip().split(':')
  ValueError: too many values to unpack (expected 3)
==============",ymcki,https://github.com/HKU-BAL/Clair3/issues/203
I_kwDOFQnk285okVBs,Issue with phasing on r10 ONT model,CLOSED,2023-06-13T08:40:37Z,2023-06-23T07:06:53Z,2023-06-23T07:06:53Z,"Hello Clair3 Team,

I have an issue running Clair3 with `""r1041_e82_400bps_sup_v400""` ONT model with phasing options. The results don't provide variant calls of chromosomes [chr1 - chr22] and only have results for chrM. I use the options `--enable_phasing` and `--longphase_for_phasing` parameters. 

When I turn off these options, the results are normal. Could you check if there is any bug phasing with the r10 sup model?

Best Regards,
Santosh",santoshe1,https://github.com/HKU-BAL/Clair3/issues/204
I_kwDOFQnk285pgyfh,"Why genotype of ""0/0"" is called",CLOSED,2023-06-22T18:35:22Z,2023-06-23T07:06:46Z,2023-06-23T07:06:46Z,"

A lot of calls by clair3 (v1.0.1) like this: 

GT:GQ:DP:AF     0/0:8:176:1.0000

Is it possible to turn '0/0' call off because it does not make a lot of sense (or at least not very interesting)? Thanks.",yzhang-github-pub,https://github.com/HKU-BAL/Clair3/issues/205
I_kwDOFQnk285p1Jxy,Odd ref base?,CLOSED,2023-06-26T20:19:12Z,2023-07-03T14:13:16Z,2023-07-03T14:13:16Z,"Hello,

Wondering what this means in the Clair3 output?

```
chr3	16902879	.	TGTGB	T	18	PASS	F	GT:GQ:DP:AF	0/1:18:48:0.3125
```

This is a single sample WGS analysis.

Thanks,
Phil
",Phillip-a-richmond,https://github.com/HKU-BAL/Clair3/issues/206
I_kwDOFQnk285rrbpw,a few queries,CLOSED,2023-07-16T11:32:55Z,2023-07-21T15:13:40Z,2023-07-21T15:13:40Z,"Hi,

 I have 2 questions-

1) In the software description, it is mentioned that v1.0.4 was released on Jul 11th. However, github only shows v1.0.3. Where can I get v1.0.4?

2) Is the new model available for variant calling for the R10.4.1 flowcell?

Regards,
Prasun",prasundutta87,https://github.com/HKU-BAL/Clair3/issues/207
I_kwDOFQnk285rrdRP,Idea why Clair3 doesn't call this SNP,CLOSED,2023-07-16T11:57:22Z,2023-07-25T20:16:21Z,2023-07-25T20:16:21Z,"Hello,

comparing bcftools mpileup and Clair3

Clair3 is generally much more able, especially in high heterozygosity region, but sometimes not. On the following pic, any idea why neither the pileup (pileup.vcf.gz), nor the neural network (merge_output.vcf.gz) call a bi-allelic SNP there? 

the D5C1.sorted is an illumina read alignment
the barcode02 is the ONT alignment
Of course, same biological clonal population

The whole ONT alignment is shown. I can't show the whole illumina alignment (too many reads). 


![igv_snapshot_CLAIR3_missing_a_snp](https://github.com/HKU-BAL/Clair3/assets/81575666/858231d3-f845-42ff-ba15-40951741e5be)

The variant is the one called No Variants Found at the line cmair3_only.vcf.gz

Any idea? 

EDIT: remove a clearly false sentence, apologizes",N/A,https://github.com/HKU-BAL/Clair3/issues/208
I_kwDOFQnk285r9sFo,Clair3 1.0.4 from bioconda does not write out INFO/END header,CLOSED,2023-07-19T07:26:26Z,2023-07-21T16:50:31Z,2023-07-21T16:50:31Z,"The `clair3` package in version 1.0.4 from bioconda does not write tout the header from `INFO/END`. Consequently, gCNV merging/calling using GATK fails.",holtgrewe,https://github.com/HKU-BAL/Clair3/issues/209
I_kwDOFQnk285sB3kI,MAF minor variants,CLOSED,2023-07-19T17:51:34Z,2023-07-21T16:50:23Z,2023-07-21T16:50:23Z,"Hello

I am working on a clonal organism but we believe more and more it might not be so clonal. We have HiFi data and I want to use them to detect MAF. Is it possible with Clair3 to detect that? Do you think the models are capable of that? 

Thank you 

Cheers",N/A,https://github.com/HKU-BAL/Clair3/issues/210
I_kwDOFQnk285sOJ12,clair3 installation,CLOSED,2023-07-21T11:30:46Z,2023-08-17T03:54:36Z,2023-08-17T03:06:22Z,"Unable to install clair3 using conda create -n clair3 -c bioconda clair3 python=3.9.0 -y.  All three channels;  conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge are added.
I am installing on MobaXterm on windows. ",Ligerd5,https://github.com/HKU-BAL/Clair3/issues/211
I_kwDOFQnk285si7nm,Question on snp_min_af,CLOSED,2023-07-25T20:28:38Z,2023-08-17T03:03:46Z,2023-08-17T03:03:46Z,"is it really 0.08 for all the technologies? 
So, whatever Clair3 is fed Pacbio, ont or ilm it can detect SNP present in 8% of the reads? I would have assumed that the detection would work better with long reads and therefore, the af  would be lower. Can you tell me where I am wrong? 

Sorry for the many questions I must account for 30% of the issues here ^^' 

Alex",N/A,https://github.com/HKU-BAL/Clair3/issues/212
I_kwDOFQnk285tiegK,Questions with no vcf file out put,CLOSED,2023-08-05T13:08:33Z,2023-08-06T03:09:48Z,2023-08-06T03:09:48Z,"I manually make one target sequence and using some sequencing tools to get the reads. However, AI can not get the vcf output with the sample docker command.
```
docker run \
-v ""${INPUT_DIR_REF}"":""/input_dir_ref"" \
-v ""${original_input_bam}"":""/input_dir_bam"" \
-v ""${output_path}"":""/output"" \
hkubal/clair3:latest \
/opt/bin/run_clair3.sh \
    --ctg_name='modify' \
--ref_fn=/input_dir_ref/""${ref_name_final}"" \
--bam_fn=/input_dir_bam/$bam_name_o \
--platform=""ont"" \
--output=$main_dir_1$vcf_folder'/'$folder_level'/'$num_reads_per'/'$num \
--model_path=""/opt/models/${MODEL_NAME}"" \
--threads=10
````
 the log file is:
```
[INFO] CLAIR3 VERSION: v1.0.4
[INFO] BAM FILE PATH: /input_dir_bam/0_0_reads_bam.bam.sorted.bam.modified.bam
[INFO] REFERENCE FILE PATH: /input_dir_ref/0_0_reads_reference.fasta
[INFO] MODEL PATH: /opt/models/r941_prom_sup_g5014
[INFO] OUTPUT FOLDER: /disk18T1/scratch/project11/SNV_analysis/SNV_old_server/SNV_with_base_quality/Formal_simulation_SNV/New_generation_SNV_g3/My_new_snv_clair3/vcf/301/50/0
[INFO] PLATFORM: ont
[INFO] THREADS: 10
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: modify
[INFO] CONDA PREFIX: 
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] PHASING PROPORTION: 0.8
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.08
[INFO] INDEL AF THRESHOLD: 0.15
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE LONGPHASE FOR INTERMEDIATE VCF PHASING: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING WHATSHAP: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING LONGPHASE: False
[INFO] ENABLE HAPLOTAGGING FINAL BAM: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE C_IMPLEMENT: True

+ /opt/bin/scripts/clair3_c_impl.sh --bam_fn /input_dir_bam/0_0_reads_bam.bam.sorted.bam.modified.bam --ref_fn /input_dir_ref/0_0_reads_reference.fasta --threads 10 --model_path /opt/models/r941_prom_sup_g5014 --platform ont --output /disk18T1/scratch/project11/SNV_analysis/SNV_old_server/SNV_with_base_quality/Formal_simulation_SNV/New_generation_SNV_g3/My_new_snv_clair3/vcf/301/50/0 --bed_fn=EMPTY --vcf_fn=EMPTY --ctg_name=modify --sample_name=SAMPLE --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=2 --var_pct_full=0.7 --ref_pct_full=0.1 --var_pct_phasing=0.8 --snp_min_af=0.08 --indel_min_af=0.15 --min_mq=5 --min_coverage=2 --min_contig_size=0 --pileup_only=False --gvcf=False --fast_mode=False --call_snp_only=False --print_ref_calls=False --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=False --no_phasing_for_fa=False --pileup_model_prefix=pileup --fa_model_prefix=full_alignment --remove_intermediate_dir=False --enable_phasing=False --enable_long_indel=False --keep_iupac_bases=False --use_gpu=False --longphase_for_phasing=False --longphase=EMPTY --use_whatshap_for_intermediate_phasing=True --use_longphase_for_intermediate_phasing=False --use_whatshap_for_final_output_phasing=False --use_longphase_for_final_output_phasing=False --use_whatshap_for_final_output_haplotagging=False

[INFO] Check environment variables
[INFO] Create folder /disk18T1/scratch/project11/SNV_analysis/SNV_old_server/SNV_with_base_quality/Formal_simulation_SNV/New_generation_SNV_g3/My_new_snv_clair3/vcf/301/50/0/log
[INFO] Create folder /disk18T1/scratch/project11/SNV_analysis/SNV_old_server/SNV_with_base_quality/Formal_simulation_SNV/New_generation_SNV_g3/My_new_snv_clair3/vcf/301/50/0/tmp/pileup_output
[INFO] Create folder /disk18T1/scratch/project11/SNV_analysis/SNV_old_server/SNV_with_base_quality/Formal_simulation_SNV/New_generation_SNV_g3/My_new_snv_clair3/vcf/301/50/0/tmp/merge_output
[INFO] Create folder /disk18T1/scratch/project11/SNV_analysis/SNV_old_server/SNV_with_base_quality/Formal_simulation_SNV/New_generation_SNV_g3/My_new_snv_clair3/vcf/301/50/0/tmp/phase_output
[INFO] Create folder /disk18T1/scratch/project11/SNV_analysis/SNV_old_server/SNV_with_base_quality/Formal_simulation_SNV/New_generation_SNV_g3/My_new_snv_clair3/vcf/301/50/0/tmp/gvcf_tmp_output
[INFO] Create folder /disk18T1/scratch/project11/SNV_analysis/SNV_old_server/SNV_with_base_quality/Formal_simulation_SNV/New_generation_SNV_g3/My_new_snv_clair3/vcf/301/50/0/tmp/full_alignment_output
[INFO] Create folder /disk18T1/scratch/project11/SNV_analysis/SNV_old_server/SNV_with_base_quality/Formal_simulation_SNV/New_generation_SNV_g3/My_new_snv_clair3/vcf/301/50/0/tmp/phase_output/phase_vcf
[INFO] Create folder /disk18T1/scratch/project11/SNV_analysis/SNV_old_server/SNV_with_base_quality/Formal_simulation_SNV/New_generation_SNV_g3/My_new_snv_clair3/vcf/301/50/0/tmp/phase_output/phase_bam
[INFO] Create folder /disk18T1/scratch/project11/SNV_analysis/SNV_old_server/SNV_with_base_quality/Formal_simulation_SNV/New_generation_SNV_g3/My_new_snv_clair3/vcf/301/50/0/tmp/full_alignment_output/candidate_bed
[INFO] Call variant in contigs: modify
[INFO] Chunk number for each contig: 1
[93m[WARNING] Current maximum contig length 6546 is much smaller than default chunk size 5000000, You may set a smaller chunk size by setting --chunk_size=$ for better parallelism.[0m
[INFO] 1/7 Call variants using pileup model
Calling variants ...
Total processed positions in modify (chunk 1/1) : 261
Total time elapsed: 2.76 s

real	0m4.532s
user	0m4.109s
sys	0m0.452s

[INFO] 2/7 Select heterozygous SNP variants for Whatshap phasing and haplotagging
[INFO] Select heterozygous pileup variants exceeding phasing quality cutoff 7
[INFO] Total heterozygous SNP positions selected: modify: 37

real	0m0.209s
user	0m0.146s
sys	0m0.050s

[INFO] 3/7 Phase VCF file using Whatshap
This is WhatsHap 1.7 running under Python 3.9.0
Working on 1 sample from 1 family

# Working on contig modify in individual SAMPLE
Found 37 usable heterozygous variants (0 skipped due to missing genotypes)
Found 48 reads covering 37 variants
Kept 48 reads that cover at least two variants each
Selected 35 most phase-informative reads covering 37 variants
Phasing 1 sample by solving the MEC problem ...
Largest block contains 31 variants (83.8% of accessible variants) between position 114 and 6477
Changed 5 genotypes while writing VCF

# Resource usage
Maximum memory usage: 0.042 GB
Time spent reading BAM/CRAM:                    0.0 s
Time spent parsing VCF:                         0.0 s
Time spent selecting reads:                     0.0 s
Time spent phasing:                             0.1 s
Time spent writing VCF:                         0.0 s
Time spent finding components:                  0.0 s
Time spent on rest:                             0.0 s
Total elapsed time:                             0.1 s

real	0m0.429s
user	0m0.352s
sys	0m0.073s

[INFO] 5/7 Select candidates for full-alignment calling
[INFO] Set variants quality cutoff 11.0
[INFO] Set reference calls quality cutoff 7.0
[INFO] Low quality reference calls to be processed in modify: 20
[INFO] Low quality variants to be processed in modify: 30

real	0m0.216s
user	0m0.136s
sys	0m0.067s

[INFO] 6/7 Call low-quality variants using full-alignment model
Calling variants ...
Total processed positions in modify (chunk 1/1) : 50
Total time elapsed: 1.02 s

real	0m2.613s
user	0m2.277s
sys	0m0.349s

[INFO] 7/7 Merge pileup VCF and full-alignment VCF
[INFO] Pileup variants processed in modify: 15
[INFO] Full-alignment variants processed in modify: 32

real	0m0.249s
user	0m0.177s
sys	0m0.070s

[INFO] Finish calling, output file: /disk18T1/scratch/project11/SNV_analysis/SNV_old_server/SNV_with_base_quality/Formal_simulation_SNV/New_generation_SNV_g3/My_new_snv_clair3/vcf/301/50/0/merge_output.vcf.gz

real	0m9.341s
user	0m7.879s
sys	0m1.320s
```
However, I found nothing in the target directory. So, what is wrong with it?",masterzhen119,https://github.com/HKU-BAL/Clair3/issues/213
I_kwDOFQnk285uTYdX,Resume Clair3,CLOSED,2023-08-14T21:32:57Z,2023-08-14T22:54:39Z,2023-08-14T22:54:28Z,,trmacfarlane,https://github.com/HKU-BAL/Clair3/issues/214
I_kwDOFQnk285uWQ0V,Inconsistency between Clair3 output and IGV ,CLOSED,2023-08-15T12:08:04Z,2023-08-24T09:17:21Z,2023-08-24T09:17:20Z,"Hello,
I am encountering a problem while working with nanopore reads. Specifically, I have observed differences in base counts between the VCF output and the IGV image for a particular variant. Here are the details of the variant in question:

`chr12 | 102852875 | . | C | T | 13.06 | PASS | P | GT:GQ:DP:AD:AF:PL | 1/1:13:95:37,48:0.5053:58,14,0`

The total depth at this position is 95, with an observed allele frequency of 48 for the ALT allele and 37 for the REF allele. However, the results differ significantly in the IGV image, as shown below:

![igv_barcode24](https://github.com/HKU-BAL/Clair3/assets/141839630/02987517-9cf0-4ed9-bbec-a171891194b3)

While the ALT allele counts are identical between the VCF output and IGV, the REF allele count is much lower in the IGV image compared to the VCF output. I am curious about the factors that could lead to this type of inconsistency.

Here is the code I am using for the analysis:

`run_clair3.sh --gvcf --min_coverage=2 --platform=ont --snp_min_af=0.05 --indel_min_af=0.05 --enable_phasing  --enable_long_indel --model_path=./path/r1041_e82_400bps_fast_g632 --bam_fn=input.bam --bed_fn=input.bed --ref_fn=reference.fasta --output=output`

Thank you in advance!
",keremozdel,https://github.com/HKU-BAL/Clair3/issues/215
I_kwDOFQnk285uX485,Missing variants in one contig,CLOSED,2023-08-15T16:24:48Z,2023-09-28T02:09:42Z,2023-09-28T02:09:41Z,"Hi,
I am using Clair3 for variant calling on targeted amplicon sequencing data. Since we are using the R10 flowcell and the model provided by ONT was trained at 60x depth, we subsample the bam to 60x prior to variant calling. When the caller goes through pileup calling, it does not identify any variant candidates in one of the contigs (chr6), despite there being obvious variants in the bam file when viewing in IGV. This has happened to at least two samples. I have attached the log and can send the VCF/bam files as needed for troubleshooting.
[run_clair3.log](https://github.com/HKU-BAL/Clair3/files/12346309/run_clair3.log)

",mproberts99,https://github.com/HKU-BAL/Clair3/issues/216
I_kwDOFQnk285ufwl3,Polyploid variant calling,CLOSED,2023-08-16T19:51:50Z,2023-09-05T13:48:43Z,2023-09-05T13:48:42Z,"Hi,
I am using Clair3 on targeted amplicon sequencing data and our amplicon can have duplications and/or deletions. Is there a way to especify polyploid variant calling so that the program looks for more than 2 alleles? 
Thanks in advance",EmilioKolo,https://github.com/HKU-BAL/Clair3/issues/217
I_kwDOFQnk285vHB8p,Numpy error in Bioconda install,CLOSED,2023-08-23T22:44:19Z,2023-09-28T02:10:16Z,2023-09-28T02:10:16Z,"Hello, 

Installed using WSL on windows 10 and using the bioconda method. 

Running I appear to get this warning/error:

/home/ont/miniconda3/envs/clair3/lib/python3.9/site-packages/numpy/core/getlimits.py:542: UserWarning: Signature b'\x00\xd0\xcc\xcc\xcc\xcc\xcc\xcc\xfb\xbf\x00\x00\x00\x00\x00\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.
This warnings indicates broken support for the dtype!
  machar = _get_machar(dtype)

My final output still has results that seem accurate so really just curious whether this is not a serious issue. 

Wasn't able to find much about what to do. 

Thanks!",fidibidi,https://github.com/HKU-BAL/Clair3/issues/218
I_kwDOFQnk285vNNUU,Clair3 silently ignores read errors,CLOSED,2023-08-24T19:10:29Z,2023-09-05T13:52:07Z,2023-09-05T13:52:07Z,"We had a situation recently where a couple of samples in a large run happened to run at a time when there was network instability on our cluster. This caused about half of the chunks to fail because the subprocesses working on them couldn't read them. But it seems clair3's behaviour when chunks fail is to just ignore them. (Presumably this is due to repetitive regions, chrY, etc where failure is expected to be a frequent occurrence.) So what happened was that Clair3 just ran to completion with a perfunctory note in the logs, compiling the remaining chunks into a very incomplete vcf file. So the surrounding NextFlow workflow had no way of knowing that an error had occurred, and we didn't even pick this up until some time later when doing downstream analyses.

It would be helpful if clair3 could detect errors due to things like file I/O failing, and fail the run in those cases.",oneillkza,https://github.com/HKU-BAL/Clair3/issues/219
I_kwDOFQnk285vpBXF,Excessive GT ./. in GVCF output,CLOSED,2023-08-30T06:42:33Z,2023-12-21T13:07:27Z,2023-12-21T13:07:27Z,"Hello,
Firstly, thank you for this tool. 
I am working on amplicon sequence data and my workflow involves generating GVCFs with Clair3 with gvcf enabled which I then use as inputs for the CombineGVCFs and GenotypeGVCFs commands in GATK. However, when I compare the sample genotype in the final **merge_output.vcf** produced by Clair3 with genotype of the same sample in the final **combined.vcf** from GATK, there are some differences which affects other results downstream. See below. 

```
# 1. Results from individual calls in merge_output.vcf.gz
# sample 1
Pos     REF     ALT     GT
544     C       .       0/0:31:974:850:0.8727:990,990,990
1156    G       .       0/0:31:980:829:0.8459:990,990,990
1544    A       .       0/0:31:984:859:0.873:990,990,990
1665    A       .       0/0:33:981:879:0.896:990,990,990

# sample 2
1156    G       .       0/0:34:97:88:0.9072:990,990,990
1665    A       .       0/0:24:98:94:0.9592:990,990,990

# sample 3
544     C       .       0/0:30:579:493:0.8515:990,990,990
1156    G       .       0/0:32:581:518:0.8916:990,990,990

# 2. Results from joint calling
POS     REF     ALT     Sample 1                                Sample 2                        Sample3
544     C       A       0/1:892,0:.:892:99:1038,0,20356         0/0:11,0:.:11:33:0,33,329       0/1:567,0:.:567:99:875,0,12724
1156    G       A       0/1:940,0:.:940:99:1044,0,21501         0/0:92,0:.:92:99:0,276,2759     0/0:510,0:.:510:99:0,812,13858
1544    A       G       0/1:1013,0:.:1013:99:494,0,23802        0/0:49,0:.:49:27:0,27,1229      0/0:11,0:.:11:3:0,3,269
1665    A       C       0/1:967,0:.:967:93:93,0,23100           0/0:46,0:.:46:18:0,18,1139      0/1:18,0:.:18:95:95,0,335

```
These are the parameters I used when I generated the GVCFs

```
run_clair3.sh \
--bam_fn=${sample}.bam \
--ref_fn=${ref} \
--threads=2 \
--platform=${platform} \
--model_path=${model_path} \
--output=${working_dir}/${sample} \
--include_all_ctgs \
--sample_name=${sample} \
--bed_fn=region.bed \
--gvcf \
--chunk_size=25000 \
--var_pct_full=1 \
--ref_pct_full=1 \
--print_ref_calls \    # to generate a vcf even when there are no variants
--no_phasing_for_fa \
--use_whatshap_for_final_output_phasing
```


 I have tried filtering the population VCF using DP, allele counts or frequency thresholds but these have had little or no positive effect. So I was wondering if there are recommendations on some parameters I can modify when generating the GVCFS  with Clair3 which would improve the genotyping accuracy of GATK.

Thank you.",eiwai81,https://github.com/HKU-BAL/Clair3/issues/220
I_kwDOFQnk285v289m,"[WARNING] Threads setting exceeds maximum available threads 1, set threads=1",CLOSED,2023-09-01T03:59:46Z,2024-05-05T23:31:06Z,2023-09-28T02:13:26Z,"I'm running Clair3 on a cluster and my node has 80 cores.  I'm not sure why I'm getting this error about the maximum available threads being just 1.  I also am not very clear on what it means in the documentation when it says ""Max #threads to be used. The full genome will be divided into small chunks for parallel processing. Each chunk will use 4 threads. The #chunks being processed simultaneously is ceil(#threads/4)*3. 3 is the overloading factor.""  What does ""overloading factor"" mean?  Do I need to change the default chunk size to match the number of threads I am specifying?  

Thanks in advance for your guidance.",darbrob,https://github.com/HKU-BAL/Clair3/issues/221
I_kwDOFQnk285v7qrn,The output DP is lower than the mapping coverage,CLOSED,2023-09-01T18:52:58Z,2023-09-28T02:14:14Z,2023-09-28T02:14:14Z,"Hello, 

Thank you for developing the SNP caller Cliar3! I am using it for a PCR amplicon sample. I have about 380K reads in the sample, and there is an SNP in position 3,213 shown using IGV. 

Total     count: 382,962 on position 3213
A : 441 (0%, 365+, 76- )
C : 380655 (99%, 160821+,     219834- )
G : 486 (0%, 128+, 358- )
T : 1380 (0%, 336+, 1044- )
N     : 0

However, I encountered two challenges using clair3v0.1-r12. 

1. The pileup model has 3 SNPs detected, but the full alignment failed leading to no SNPs detected. Would you explain why the full-alignment model cannot find any variants? 
Here are the results using `--include_all_ctgs --chunk_size=5000 --pileup_only --qual=0 --min_mq=1 --enable_long_indel` 

```
POS        ID            REF        ALT        QUAL    FILTER  INFO      FORMAT              SAMPLE
2196      .               T              .               15.09    RefCall  P             GT:GQ:DP:AD:AF             0/0:15:8584:5434:0.6330
2749      .               C             .               26.66    RefCall  P             GT:GQ:DP:AD:AF             0/0:26:8787:5778:0.6576
3213      .               T              C             24.36    PASS      P             GT:GQ:DP:AD:AF             1/1:24:8709:16,8599:0.9874
```

2. The coverage DP is lower than the coverage depth. If it is because of the downsampling, is there a way to turn the downsampling off? Since we want more accurate allele frequency by calculating the whole reads.

Please let me know if you have any questions. 

Thanks, 
Ermin",ErminZ,https://github.com/HKU-BAL/Clair3/issues/222
I_kwDOFQnk285wA0nF,"run terminates, core files produced after 4 min",CLOSED,2023-09-03T23:03:38Z,2023-09-28T02:14:33Z,2023-09-28T02:14:33Z,"I'm running v0.1-r11 to be compatible with an existing dataset.  I used the 
https://github.com/HKU-BAL/Clair3/tree/v0.1-r11.1#option-4-build-an-anaconda-virtual-environment
install process, which seemed successful.
However my run, which takes several hour on the current 1.2 version, fails after about 4 minutes on v0.1-r11, and produces numerous core.XXXX files in the output dir.
The only error reported in the log output is:
`ESC[93m[WARNING] No vcf file found with  .........  output empty vcf fileESC[0m `

I cannot easily use the Singularity/Docker option as need sysadmin update our Singularity version, currently it has a permissions error inside container as its running as my user not root.",jpdna,https://github.com/HKU-BAL/Clair3/issues/223
I_kwDOFQnk285wHzoq,Question Using Clair3 in Plasmodium,CLOSED,2023-09-05T02:53:11Z,2024-08-19T10:14:36Z,2023-09-28T02:14:40Z,"Hi,

Just have a question about running Clair3 on _Plasmodium_ data. Is it possible to use exiting Clair3 models that are trained on Human data or should I consider training a new model. Are there any other recommendations I should consider?

Thanks,
Sach",sachiwije,https://github.com/HKU-BAL/Clair3/issues/224
I_kwDOFQnk285wRkrh,[ERROR] No full-alignment output for file with Docker Dockerfile,CLOSED,2023-09-06T09:50:41Z,2023-12-21T13:07:16Z,2023-12-21T13:07:16Z,"Hi, 

I installed Clair3 with the option N 5 of the Installation section (Docker Dockerfile). However, when I run Clair3 with these parameters:
docker run -it -v ${INPUT_DIR}:${INPUT_DIR} -v ${OUTPUT_DIR}:${OUTPUT_DIR} hkubal/clair3:latest /opt/bin/run_clair3.sh --bam_fn=${INPUT_DIR}/sample.srt.bam --ref_fn=${INPUT_DIR}/ref.fa --bed_fn=${INPUT_DIR}/target.bed --snp_min_af=0.05 --indel_min_af=0.05 --enable_long_indel --threads=${THREADS} --platform=""ont"" --model_path=""/opt/models/${MODEL_NAME}"" --output=${OUTPUT_DIR}

I got the error: [ERROR] No full-alignment output for file 

in the issue section there is a similar problem (https://github.com/HKU-BAL/Clair3/issues/181) resolved by hkubal/clair3:latest. However I already put hkubal/clair3:latest in the command line.

How can I fix this issue?",littleisland8,https://github.com/HKU-BAL/Clair3/issues/225
I_kwDOFQnk285whhVI,Can I concatenate ONT reads base-called with different models for SNP calling?,CLOSED,2023-09-08T14:49:56Z,2023-09-11T14:17:24Z,2023-09-11T14:17:24Z,"I have several runs of ONT data that were sequenced with a long time in between, so they were base-called with different models. I'd like to concatenate the reads to get a higher depth for SNP and methylation calling. Is this feasible? How should I deal with the difference of the models?
If I redo the base calling with the concatenated fast5 files using the latest model, will there be any incompatibility issue between the old ONT and the new model?",weishwu,https://github.com/HKU-BAL/Clair3/issues/226
I_kwDOFQnk285wh1H3,Issue with conda installation,CLOSED,2023-09-08T15:39:52Z,2023-09-28T02:17:59Z,2023-09-28T02:17:58Z,"Hi,
I am trying to install clair3 on a server, since I don't have root's rights and cannot use Docker or Singularity, but I get this error.

`UnsatisfiableError: The following specifications were found to be incompatible with your system:

  - feature:/linux-64::__glibc==2.28=0
  - clair3 -> libgcc-ng[version='>=10.3.0'] -> __glibc[version='>=2.17']

Your installed version is: 2.28`

I don't understand why glibc 2.28 version is not compatible, since a version >=2.17 is needed.
Do you have any guess how to solve this?
Thank you",martabaragli,https://github.com/HKU-BAL/Clair3/issues/227
I_kwDOFQnk285wxoLb,vcf pileup file not created,CLOSED,2023-09-12T09:17:25Z,2023-09-28T02:18:08Z,2023-09-28T02:18:08Z,"I launch Clair3 like this:

./run_clair3.sh --bam_fn=Bam/consensus_sample_sorted.bam --ref_fn=ref/ref_seq.fasta --threads=8 --platform=""ont"" --model_path=models/r941_prom_sup_g5014 --output=output/ --include_all_ctgs --chunk_size=2000

The run stop during 1/7  Call variants using pileup model Because he cannot found the file: output/tmp/pileup_output/pileup_SP9D_LR_F2/R2_1.vcf

I join the log file. 
[run_clair3.log](https://github.com/HKU-BAL/Clair3/files/12584673/run_clair3.log)
",rongiergaetan,https://github.com/HKU-BAL/Clair3/issues/228
I_kwDOFQnk285xaT9n,Variants not reported in merge_output. Why?,CLOSED,2023-09-19T10:59:49Z,2023-09-19T13:18:06Z,2023-09-19T13:18:06Z,"Hello developers!

I'm running Clair3 on WGS data from tumor biopsies. I'm a but confused to how variants are reported in the merge_output.vcf file. In the example below, two variants can be seen with AF of around 35 %.  Both are reported in the pileup.vcf file, not filtered out. Both appear in the full_alignment.vcf file but are filtered out as - RefCall. Neither appears in the merge_output file.

Why are they filtered from the full alignment if the AF is 35%? Why are they not included in the merge_output file? Clair3 was run with a reference genome and clair3 model, everything else was default. Are there settings that I need set to get these reported? Should I perhaps only be looking at the pileup file and ignore the full_alignment?

Both variants have been confirmed by illumina sequencing

![image](https://github.com/HKU-BAL/Clair3/assets/61014551/cacebff5-def3-4be2-920a-093e6219b1aa)

Thanks for you help

Skabbi",SkabbiVML,https://github.com/HKU-BAL/Clair3/issues/229
I_kwDOFQnk285x4M-Y,Issue with Tensorflow in Clair3 v1.0.4 install with Conda env: import tensorflow as tf ModuleNotFoundError: No module named 'tensorflow',CLOSED,2023-09-25T02:52:28Z,2023-10-21T12:00:31Z,2023-10-21T12:00:31Z,"Hi all,
I'll just caveat this by saying I'm still fairly new to bioinformatics and coding so it's likely a simple fix on my end!
Briefly, I am trying to perform some SV genotyping of human DNA samples sequenced with nanopore adaptive sampling. I downloaded Clair3 following the conda install and env option. The script I'm using is as follows:
```
for num in 0; 
do 
	if [[ -s $DataOut/Sample${num}Clair3/ ]] || [[ -s $TmpWD/Sample${num}Clair3/ ]]
	then
		echo ""Clair3 ${num} is already present""
		cp -rn $DataOut/Sample${num}Clair3 $TmpWD
		ls $TmpWD
	else
		if [[ ! -s $DataOut/Sample${num}Clair3/ ]] && [[ ! -s $TmpWD/Sample${num}Clair3/ ]]
		then
			export PATH=""$PATH:/dir/to/usr/Conda/envs/clair3/lib/python3.9/site-packages/""
			echo ""must make ${num} Clair3"" 
			mkdir $TmpWD/Sample${num}Clair3
			cd /group/shs001/nberthold/Conda/envs/clair3/Clair3
			INPUT_DIR=""$TmpWD""        
			OUTPUT_DIR=""$TmpWD/Sample${num}Clair3"" 
			THREADS=""8"" 
			MODEL_NAME=""r941_prom_sup_g5014""
			source /path/to/python/anaconda3/etc/profile.d/conda.sh
			conda activate clair3
			./run_clair3.sh \
			  --bam_fn=${INPUT_DIR}/S${num}DoradoWF-O_srtd.bam \
			  --ref_fn=$Ref \
			  --threads=${THREADS} \
			  --platform=""ont"" \
			  --model_path=""/dir/to/usr/Conda/envs/clair3/Clair3/models/${MODEL_NAME}"" \
			  --output=${OUTPUT_DIR} \
			  --sample_name=""Sample${num}"" \
			  --bed_fn=$Targ.bed \
			  --include_all_ctgs \
			  --whatshap=/home/usr/.local/bin/whatshap \
			  --use_whatshap_for_final_output_phasing \
			  --use_whatshap_for_final_output_haplotagging 
		fi 
	fi 
```
This outputs the following error message;

> Traceback (most recent call last):
>   File ""/dir/to/usr/Conda/envs/clair3/Clair3/scripts/../clair3.py"", line 105, in <module>
>     main()
>   File ""/dir/to/usr/Conda/envs/clair3/Clair3/scripts/../clair3.py"", line 92, in main
>     submodule = import_module(""%s.%s"" % (directory, submodule_name))
>   File ""/server/path/to/python/python/3.9.0/lib/python3.9/importlib/__init__.py"", line 127, in import_module
>     return _bootstrap._gcd_import(name[level:], package, level)
>   File ""<frozen importlib._bootstrap>"", line 1030, in _gcd_import
>   File ""<frozen importlib._bootstrap>"", line 1007, in _find_and_load
>   File ""<frozen importlib._bootstrap>"", line 986, in _find_and_load_unlocked
>   File ""<frozen importlib._bootstrap>"", line 680, in _load_unlocked
>   File ""<frozen importlib._bootstrap_external>"", line 790, in exec_module
>   File ""<frozen importlib._bootstrap>"", line 228, in _call_with_frames_removed
>   File ""/dir/to/usr/Conda/envs/clair3/Clair3/clair3/CallVariantsFromCffi.py"", line 3, in <module>
>     import tensorflow as tf
> ModuleNotFoundError: No module named 'tensorflow'

I tried it first without the export path or cd ing to the Clair3 env directory, and it didnt work either. 
Is it something to do potentially with me working within an organisation server, and conflicts are arising? I don't have root, so I also tried singularity but that didn't want to work either!

Thanks so much in advance!
Natasha",nbertholdpgc,https://github.com/HKU-BAL/Clair3/issues/230
I_kwDOFQnk285yPNUH,Unnecessary warning when phasing is disabled,CLOSED,2023-09-28T02:06:00Z,2023-12-21T13:06:21Z,2023-12-21T13:06:21Z,"https://github.com/HKU-BAL/Clair3/blob/5708e725c31c208c97c00f8803654381aec1bf7e/preprocess/CheckEnvs.py#L473

Even when I use the `--no_phasing_for_fa` flag I still get this warning message. Might be good to do a check to see if that option has already been provided before warning?",mbhall88,https://github.com/HKU-BAL/Clair3/issues/231
I_kwDOFQnk285y23Rg,Consensus sequence from Clair3 output,CLOSED,2023-10-04T21:08:21Z,2023-10-21T12:00:58Z,2023-10-21T12:00:58Z,"Hello guys,

Probably a dumb question sorry for that ...

Can anyone explain why the tools (Clair3) advised by Nanopore (from the Medaka git page and implemented in epi2me) for diploid polishing do not output fasta consensus sequence as Medaka do ?

So the next question is: what is the best way to accurately get fasta consensus from the vcf file produced by clair3 ?

Nothing better than this ? : cat reference.fa | bcftools consensus calls.vcf.gz > consensus.fa

Maybe this should appear in the manual of Clair3.

Thanks a lot for your help !",gchevignon,https://github.com/HKU-BAL/Clair3/issues/232
I_kwDOFQnk285zvSiy,"Format error, unexpected ""N"" at line 1",CLOSED,2023-10-13T11:34:29Z,2023-10-21T12:01:15Z,2023-10-21T12:01:15Z,"I can for the life of me not figure out what is going wrong... i'm variant calling a bam-file produced by dorado aligner with the T2T v2.0 reference, but when i run the program it gives many many lines of this;

Calling variants ...
[E::fai_build_core] Format error, unexpected ""N"" at line 1

In the end it gives this error;

No vcf file found, output empty vcf file

The bamfile has tags for methylation... idk if that makes any difference maybe?",LauraSkak,https://github.com/HKU-BAL/Clair3/issues/233
I_kwDOFQnk2850jdpJ,How did you establish a threshold of 2?,CLOSED,2023-10-21T11:34:51Z,2023-10-23T13:54:31Z,2023-10-23T13:54:31Z,"Hello
I have read in several threads here that a rule of thumb is to cutoff the quality score at 2. But, unless you did something different than other callers, isn't the quality (QUAL) a phread scale and therefore a value of 2 means an error probability of >0.5? Can you please clarify? Or is it your realised the Phread score is not suitable for long read application? (I am aware all those scores relies on underlying assumptions that can turn out to be wrong). I am not knowledgeable enough to go understand the code. So, please can you clarify how this is possible? I have read the paper and the Fig 2 shows indeed already shows a jump in correct call but there are still wrong calls in significant proportion. But this figure is about the pileup. So, is it that the neural net can make use of pileup qual of 2 and filter out wrong calls? But at the same time the Fig 2A suggests a threshold of 15 to me 🤔 do I interpret correctly your figure?
Thanks so much and sorry if it's a stupid question but I am quite confused. I have a presentation in a few weeks and people will ask me ""how are you sure your filters are not too stringent"" (to give you some context). 

Thanks again.
Alex

EDIT: here is your answer advising 2. https://github.com/HKU-BAL/Clair3/issues/116#issuecomment-1152826121",N/A,https://github.com/HKU-BAL/Clair3/issues/234
I_kwDOFQnk2850y4qu,Unable to Lower Mapping Quality Filter,CLOSED,2023-10-24T15:13:54Z,2023-11-05T12:35:36Z,2023-11-05T12:35:36Z,"Hello,
I am running into an issue where I cannot set the mapping quality filter to be less than 5. This is necessary for us as we have amplicon sequencing reads that have large structural variants and the mapping quality tends to be equal to 1. Whenever I try to set --min_mq=1 I get errors:

[WARNING] Invalid minimum mapping quality input --min_mq>=5 

I dug into the code, and the parameter is currently restricted to >=5:
if [[ ! ${MIN_MQ} =~ ^[\-0-9]+$ ]] || (( ${MIN_MQ} < 5)); then echo -e ""${WARNING} Invalid minimum mapping quality input --min_mq>=5 ${NC}""; MIN_MQ=5; fi

Can this be modified to allow less than 5 for the filter?

Thank you!",mproberts99,https://github.com/HKU-BAL/Clair3/issues/235
I_kwDOFQnk2851ADIs,Large difference in results between running in conda environment and running in Singularity/Docker container.,CLOSED,2023-10-26T08:05:01Z,2023-11-05T12:35:51Z,2023-11-05T12:35:51Z,"I'm using clair3 (Ive tried 1.0.0 and 1.0.4) to do some structural variant calling. Currently I'm just doing some testing on the 37 variant of this GIAB-genome: https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/

I'm noticing that the results are much better when running clair3 inside my conda environment compared to when I run it in a docker or singularity container. I'm using the containers as part of my WDL-pipeline, but I've also tested the singularity container on its own, and get similar (bad) results. This divergence in results allready happens in the first step (the pileup phase): much fewer variants are found.
These are my parameters:

        run_clair3.sh \
            --bam_fn=~{bamIn} \
            --ref_fn=~{refFastaIn} \
            --platform='ont' \
            --enable_long_indel \
            --fast_mode \
            --model_path=""/opt/models/ont"" \
            --threads=~{threads} \
            --output=output/ 

        mv output/merge_output.vcf.gz ./clair3_out.vcf.gz

I've tried the docker image you guys provide.
The singularity container has an extended base image. This did not improve the result. It can be downloaded from here: https://github.com/bioconda/bioconda-recipes/pull/43786#issuecomment-1772725050

I've attached 2 logfiles from the the runs inside the conda environment and inside the container:
[container-run_clair3.log](https://github.com/HKU-BAL/Clair3/files/13174916/container-run_clair3.log)
[conda-run_clair3.log](https://github.com/HKU-BAL/Clair3/files/13174917/conda-run_clair3.log)
(the warning about the index being older can be ignored, I've used the index GIAB provides. The reason the warning doesn't show up in the conda run is that I've done a touch command with the index in between the runs.)
",Samvkes,https://github.com/HKU-BAL/Clair3/issues/236
I_kwDOFQnk2851Qvax,do different aligner affect NGS-based SNP calling?,CLOSED,2023-10-30T02:02:48Z,2023-10-30T03:06:54Z,2023-10-30T03:06:54Z,"Hi dear developer, I would like to know whether it would affect the performance using bowtie2 instead of bwa-mem for NGS reads, thanks a lot!",tinyfallen,https://github.com/HKU-BAL/Clair3/issues/237
I_kwDOFQnk2851ekcU,Clair3 gives a large number of false negatives (amplicon sequencing on minION),CLOSED,2023-10-31T17:26:14Z,2024-05-29T14:47:03Z,2023-11-21T02:09:18Z,"Hello,
I am using Clair3 for variant calling on amplicon sequencing data from a minION, generally with a fair amount of success. However, for one particular amplicon, I get a large number of false negatives (I am sequencing NA12878 and comparing to the Illumina Platinum Genome as a truthset). In the attached IGV screenshot, all of the obvious heterozygous variants are identified as real by Illumina, but Clair3 only calls 7 out of 25. There are no obvious possible off-target sites that might be amplified.

These reads were basecalled using Dorado (using the appropriate dna_r10.4.1_e8.2_400bps_hac@v4.2.0 model for my run). I am using minimap2 for mapping (against a FASTA file containing my amplicon sequences. I had other amplicons in the run, but I used samtools view to only select the reads mapping against the problematic amplicon). For Clair3, I am using the r1041_e82_400bps_hac_v420 model (from Rerio). I am using --var_pct_full=0.1 --ref_pct_full=0.7 (to try to increase sensitivity, I may be using those flags incorrectly). The bam files are a bit large, but I can share them as well via e-mail. The merge output VCF is also attached. Thank you for your help!

![FN-amplicon](https://github.com/HKU-BAL/Clair3/assets/149518744/31ecd177-2e38-4253-b280-e964627e5758)
[merge_output.vcf.gz](https://github.com/HKU-BAL/Clair3/files/13219586/merge_output.vcf.gz)
",jamesa47,https://github.com/HKU-BAL/Clair3/issues/238
I_kwDOFQnk2851yzHH,TBI errors; support for CSI?,CLOSED,2023-11-03T13:50:40Z,2023-12-20T08:55:25Z,2023-12-20T08:55:25Z,"I am trying to use clair3 on a marsupial genome (has extra long chrs) and while clair3 does take cram format, I am still getting an error for TBI error which results in the tool failing and not producing final results.

[E::hts_idx_check_range] Region 748919259..748919260 cannot be stored in a tbi index. Try using a csi index
tbx_index_build failed: /data/temp/./tmp/phase_output/phase_vcf/phased_chr1.vcf.gz
[E::hts_idx_check_range] Region 665926387..665926388 cannot be stored in a tbi index. Try using a csi index
tbx_index_build failed: /data/temp/./tmp/phase_output/phase_vcf/phased_chr2.vcf.gz
[E::hts_idx_check_range] Region 544689956..544689957 cannot be stored in a tbi index. Try using a csi index
tbx_index_build failed: /data/temp/./tmp/phase_output/phase_vcf/phased_chr3.vcf.gz",bcantarel,https://github.com/HKU-BAL/Clair3/issues/239
I_kwDOFQnk2852wYd8,SNP missing,CLOSED,2023-11-14T09:57:26Z,2023-11-15T08:55:41Z,2023-11-15T08:55:41Z,"Hello,
I'm testing Clair3 to identify drugs resistance mutation and some snp are not found even if they are in .bam file and can be see on IGV.
![image](https://github.com/HKU-BAL/Clair3/assets/100346160/473a72f2-e39f-48c5-b59d-ac23348ea356)
![image](https://github.com/HKU-BAL/Clair3/assets/100346160/5ba45186-d9c2-495a-91f8-e5ca1a9f10a3)
 Other snp with less coverage/frequence are detect.
Here is the command I used : 
```
run_clair3.sh -b 50E150E2_MixA1.trimmed.rg.sorted.bam -f ./primer-schemes/custom_CMV/V8/custom_CMV.reference.fasta -m clair3_models/r941_prom_hac_g360+g422/ --include_all_ctgs -t 25 --snp_min_af=0.1 --indel_min_af=0.15 --haploid_sensitive -p ont -o .
```
Some idea why I can't find this two snp ?",HJArdin,https://github.com/HKU-BAL/Clair3/issues/240
I_kwDOFQnk2853BYCT,Allele frequency sum above 1,CLOSED,2023-11-16T13:22:59Z,2023-12-21T13:06:46Z,2023-12-21T13:06:46Z,"In my merge_output.vcf.gz file most of the time I'm getting just a single variant per position. However I also get one position where there are two variants, but their allele frequency does no add up to 1, nor do the allelic depths add up to the total read depth for the position. Am i misunderstanding the values or is there something wrong happening with the calculations?

A snippet of my merge_output.vcf.gz looks like this:
```
#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	SAMPLE
K03455.1	2229	.	C	A	22.46	PASS	F	GT:GQ:DP:AD:AF	1/1:22:19666:255,18257:0.9284
K03455.1	2259	.	G	A	36.43	PASS	F	GT:GQ:DP:AD:AF	1/1:36:19721:182,18951:0.9610
K03455.1	3161	.	G	A,T	18.93	PASS	F	GT:GQ:DP:AD:AF	1/2:18:20313:190,10274,17655:0.5058,0.8691
```

Where the last row is the one with multiple variants. 

Any help would be greatly appreciated",mbdabrowska1,https://github.com/HKU-BAL/Clair3/issues/241
I_kwDOFQnk2853J_sL,Request to make the samtools mpileup --max-depth variable user defined,CLOSED,2023-11-17T13:15:58Z,2023-12-01T13:12:55Z,2023-12-01T13:12:54Z,"I was wondering if it was possible to make the samtools mpileup --max-depth variable definable by the clair3 user. I'm running amplicon data (high coverage) with a very small reference genome on the institution HPC system, so the memory usage is not a worry for my data, I would like to however increase the number of reads used for the pileup (instead of the 8000 default) to increase the sensitivity to lower frequency variants. We are looking to comfortably go down to 5% minority variants if possible. Other suggestions on how to achieve that are also welcome!",mbdabrowska1,https://github.com/HKU-BAL/Clair3/issues/242
I_kwDOFQnk2853aJsp,Why doesn't clair3_c_impl.sh have step 5?,CLOSED,2023-11-21T02:43:14Z,2023-11-21T05:45:48Z,2023-11-21T05:45:47Z,Why does clair3_c_impl.sh not need to generate phase_bam files？,oranges7,https://github.com/HKU-BAL/Clair3/issues/243
I_kwDOFQnk2853pkP4,An idea to reduce FPs for calls near the end of homopolymer,CLOSED,2023-11-23T02:26:31Z,2023-12-20T08:54:45Z,2023-12-20T08:54:45Z,"Dear Clair3 team,

     As a heavy user of ONT's wf-human-variation pipeline, I am also indirectly a heavy user of Clair3.
I noticed that there are quite many false positive variant calls (mostly single base indels) near the
end of homopolymer which gave me quite many distractions when looking for disease causing variants. 
I understand that this is mostly due to the nature of nanopore technology but it would be great
if Clair3 can also do something about it.

     Since the wf-human-variation pipeline also generates a haplotagged.bam from whatshap (ie
call the phase of an aligned read by looking at heterozygous variant calls), I am able to visualize
what's going on for variant calls near the end of a homopolymer. With the help of phasing info 
from whatshap, I think I can pinpoint most of the false positive calls intuitively and significantly
reduce the false positive rate. 

     I am thinking maybe it is possible for Clair3 to take this haplotagged bam as input and remove the
wrong calls near the end of homopolymer. It would be great if a fixed bam file is also outputted 
as well for visualization in IGV. 

     In the long run, perhaps Clair3 can also do the phasing itself and correct these errors in one
go?

Thank you very much for your time.",ymcki,https://github.com/HKU-BAL/Clair3/issues/244
I_kwDOFQnk28531iGh,threads setting issue with SGE cluster,CLOSED,2023-11-25T08:02:02Z,2024-05-06T08:07:13Z,2023-11-27T13:49:57Z,"Hi dear developers,

Thanks for your work! I met a small issue when running clair3 by apptainer on a SGE cluster.

I submitted the script which using apptainer generated clair3.sif to call variations with the option ""-t 104"" to a node which has 104 threads from the SGE control node, the log said ""[WARNING] Threads setting exceeds maximum available threads 48, set threads=48"". 48 is the thread number of the control node. Anyway, it just run smoothly.

This issue may be cased by the management manner of SGE or apptainer itself, I have no idea, and will mislead the source allocation.

`clair3-1.0.4.sif run_clair3.sh -b pame.hifi.bam -f pame.fa -t 104 -p hifi -o clair3 -m /opt/models/hifi --include_all_ctgs --gvcf`
![image](https://github.com/HKU-BAL/Clair3/assets/37066354/08f25f11-3c74-4615-9367-06b826bc4714)",tinyfallen,https://github.com/HKU-BAL/Clair3/issues/245
I_kwDOFQnk28533b79,Does Clair3 normalize?,CLOSED,2023-11-26T12:24:44Z,2023-11-27T13:27:30Z,2023-11-27T13:27:30Z,"Hello, 

I know vcf normalization is a highly complex topic. There was a time when you had to use bcftools norm. But since then, I noticed more and more callers trying their best to normalize ""out of the box"". Is it the case of Clair3? I didn't find any issue asking this. I'm sorry if I already asked you before. I have a little doubt. I plan to call on seven samples and merge into a single vcf. I don't want joint calling because I am looking for variants present only in each sample (private variants), and according to Heng Li, joint calling is conservative. 

Again, apologize if I have asked this before. 

Thanks a lot (and for Clair3, it's a very excellent piece of software, I am working on a complicated genome and its performance are stellar). ",N/A,https://github.com/HKU-BAL/Clair3/issues/246
I_kwDOFQnk28538vxB,model for r10.4.1 cells called with Guppy and not Dorado,CLOSED,2023-11-27T14:33:06Z,2023-12-20T08:55:07Z,2023-12-20T08:55:07Z,"Hello, 

I have received ONT sequence data, 

I know that the base calling was done with Guppy, but there is no model I can find for cells R10.4.1, chemistry v14

The base calling command was

```guppy_basecaller -i ./fast5 -s ./fastq_guppy6.3.8_8.2 -c dna_r10.4.1_e8.2_400bps_sup.cfg -x cuda:1```

We used Guppy because we were not happy with the base quality given by Dorado, but Oxford nanopore seems to provide models only for Dorado with this chemistry. What would you advise me to do? 

Thanks a lot

EDIT: to give you an idea I will share the quality profile of Guppy, then of Dorado
",N/A,https://github.com/HKU-BAL/Clair3/issues/248
I_kwDOFQnk2853-G5N,"Inaccurate description of the ""NON_REF""? ",CLOSED,2023-11-27T17:35:11Z,2023-11-27T17:51:10Z,2023-11-27T17:51:09Z,"Hello,

I found something in your gVCF.

In the header, NON_REF it's defined this way:

`##ALT=<ID=NON_REF,Description=""Represents any possible alternative allele at this location"">`

Here is a line

```Chrom_3	5168802	.	T	<NON_REF>	0	.	END=5168853	GT:GQ:MIN_DP:PL	0/0:50:17:0,51,509```

But here, the likelihood of having alternative alleles is 0. See the pic below (block starts after the T/C).

![Screenshot from 2023-11-27 17-41-40](https://github.com/HKU-BAL/Clair3/assets/81575666/06fa6e2d-1dd3-4697-a357-cae5ce75a4fe)

This is a mapping of HiFi PacBio reads; we can't have better evidence than there is NO variant. 
It is counterintuitive that in gVCF, absolutely all the blocks are called NON_REF. I don't know why it is not a ""RefCall"". There is not a single ""RefCall"" in the gVCF. Also, why does Clair3 think the QUAL of this block is 0?

Here is the command I used:

```
MODEL_NAME=""hifi_sequel2""
THREADS=24
OUTPUT_DIR=ref_Clair3
run_clair3.sh --bam_fn=ancestor_hifi.sorted.bam --ref_fn=ref.fsa --output=${OUTPUT_DIR} --threads=${THREADS} --platform=hifi --model_path=/media/alessandro/Storage/MA/P2/ONT_fasta/models/${MODEL_NAME} --include_all_ctgs --gvcf

```
Thanks, and sorry again for the many questions. 
",N/A,https://github.com/HKU-BAL/Clair3/issues/249
I_kwDOFQnk2854FYB5,Running Clair on a .bam with mixed flowcell types,CLOSED,2023-11-28T15:14:43Z,2023-11-28T15:23:26Z,2023-11-28T15:23:26Z,"Hello, 

Would love some input in this scenario:

We have two bam files for the same sample that we've merged into one bam. 

However, one was generated from R9 flowcell, and the other R10. 

We'd like to run Clair on the samples but are unsure of how to proceed since clair uses specific models for the flowcell used. 
",fidibidi,https://github.com/HKU-BAL/Clair3/issues/250
I_kwDOFQnk2854ow16,Variants called with HiFi but not with ONT in the merge.output.vcf,CLOSED,2023-12-04T14:12:12Z,2023-12-09T18:41:30Z,2023-12-09T18:41:30Z,"Hello, see the screenshot. I have named the track guppy, dorado, hifi, for the calls done on the ONT with the guppy model, the calls done with the dorado model, and the calls done with the hifi model. I have uploaded the pileup, alignment, and merged vcf files (except for the hifi, otherwise, it becomes very cumbersome to read).

As you see, there are, visually, 4 SNPs, and Clair3 calls them 4 with the HiFi model. However, it calls only 1 with the ONT model. I have used two models for ONT because of this issue: https://github.com/HKU-BAL/Clair3/issues/248

However, the SNPs are called in the ONT datasets at the pileup level. But it seems then they are discarded. Do you know why the model would toss with ONT when it doesn't with PacBio HiFi? Could the parameter be tuned to avoid this behaviour? 
Just so you know, I am assuming the HiFi is the correct call, but I have no truth set, it could be the ONT models that are correct. Visually, the HiFi model seems to be what a human would call.


![diff_hifi_ONT png](https://github.com/HKU-BAL/Clair3/assets/81575666/9602adf4-b906-4cf9-8638-e652b9f59f74)

The ONT called was performed with r10.4.1 5 Khz. Here are the commands I used for the output in the pic:

```
MODEL_NAME=""hifi_sequel2""
THREADS=24
OUTPUT_DIR=ref_Clair3
run_clair3.sh --bam_fn=ancestor_hifi.sorted.bam --ref_fn=ref.fa --output=${OUTPUT_DIR} --threads=${THREADS} --platform=hifi --model_path=/media/alessandro/Storage/MA/P2/ONT_fasta/models/${MODEL_NAME} --include_all_ctgs --gvcf

MODEL_NAME=""r1041_e82_400bps_sup_v420_model""
THREADS=24
OUTPUT_DIR=Dorado_Clair3
mkdir -p ${OUTPUT_DIR}
run_clair3.sh --bam_fn=H2B4.sorted.bam --ref_fn=ref.fa --output=${OUTPUT_DIR} --threads=${THREADS} --platform=""ont"" --model_path=/media/alessandro/Storage/MA/P2/ONT_fasta/rerio/clair3_models/${MODEL_NAME} --include_all_ctgs --gvcf

MODEL_NAME=""r1041_e82_400bps_sup_g615_model""
OUTPUT_DIR=Guppy_Clair3
mkdir -p ${OUTPUT_DIR}
run_clair3.sh --bam_fn=H2B4.sorted.bam --ref_fn=ref.fa --output=${OUTPUT_DIR} --threads=${THREADS} --platform=""ont"" --model_path=/media/alessandro/Storage/MA/P2/ONT_fasta/rerio/clair3_models/${MODEL_NAME} --include_all_ctgs --gvcf
```

Do you have an idea? My intuition is that there is a mismatch between the cell tech and the model that prevents Clair3 to call what look like ""very obvious"" SNPs. This pattern shown here is repeated throughout the assembly, it seems. 

Do you think we should redo the base call with Dorado? Even if we have a first quality peak at 5, as shown in issue #248 ?  As background information it's a non-model organism with a SNP frequency of 1 every dozen bases (usually 1/30 to 1/50, with regions of high density). 

Thanks a lot. I am curious to hear your opinion on why the neural net ditches those variants.

EDIT: might be an error in the parameters, closing for now",N/A,https://github.com/HKU-BAL/Clair3/issues/251
I_kwDOFQnk2854r8Zb,parallel: Error: ,CLOSED,2023-12-04T21:35:44Z,2023-12-14T01:36:41Z,2023-12-14T01:36:41Z,"Hi, 
whene evr I try to run the program on my Slurm cluster, I face this error ""Command line too long (1447 >= 0) at input 0: chr20 1 1289"", will you please guid me how to solve this problem",farhangkl,https://github.com/HKU-BAL/Clair3/issues/252
I_kwDOFQnk285432Jo,Problem with minimum indel AF filter,CLOSED,2023-12-06T07:52:51Z,2023-12-20T08:54:18Z,2023-12-20T08:54:18Z,"Hello,

I'm facing an issue while trying to filter indels based on minimum allele frequency. After I set the `--indel_min_af`  parameter to 0.3, I can still observe indels with lower AF. I'm working with amplicon data and here is my code:
`run_clair3.sh --gvcf --platform=""ont"" --indel_min_af=0.3 --snp_min_af=0.08 --model_path=${PATH}/r941_prom_sup_g5014 --bam_fn=${BAM} --bed_fn=${BED} --ref_fn=${REF} --var_pct_full=1 --ref_pct_full=1 --var_pct_phasing=1 --output=${OUTPUT}`

The problem is that there are some questionable indels with lower af than the specified threshold in my result. Here are some examples:

#CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | SAMPLE
-- | -- | -- | -- | -- | -- | -- | -- | -- | --
chr17 | 43123064 | . | G | GA | 2.44 | PASS | AD=226,61;DP=719 | GT:GQ:DP:AD:AF:PL | 1/1:2:719:226,61:0.0848:17,5,0
chr17 | 43095603 | . | C | CA | 4.44 | PASS | AD=148,58;DP=408 | GT:GQ:DP:AD:AF:PL | 0/1:4:408:148,58:0.1422:16,0,9
chr17 | 43071847 | . | C | CA | 9.09 | PASS | AD=164,95;DP=654 | GT:GQ:DP:AD:AF:PL | 0/1:9:654:164,95:0.1453:13,0,36

I suspect most of the reads are filtered due to low MQ and BQ, thus I'm getting these problematic results. And that's why I want to filter them. I was wondering why Clair3 doesn't filter them as expected.

Thanks in advance!










",keremozdel,https://github.com/HKU-BAL/Clair3/issues/253
I_kwDOFQnk285453iQ,Clair3 working over Dorado base caller?,CLOSED,2023-12-06T12:31:04Z,2023-12-14T01:27:50Z,2023-12-14T01:27:50Z,"Hi,
I see that Clair3 was trained with different versions of Guppy, but what about using it over a Dorado base-called BAM?
Are there any advisable parameters to set in this situation?",ilivyatan,https://github.com/HKU-BAL/Clair3/issues/254
I_kwDOFQnk2855QbCE,Do I need to filter the input BAMs?,CLOSED,2023-12-10T12:21:45Z,2023-12-14T01:30:01Z,2023-12-14T01:30:01Z,"Hi dear developers,

Thanks for your works. 

When I used GATK to call variants, it was suggested to mark the duplicated reads in the BAM files.

So I would like to ask whether it is in need to filter the BAMs using mapping quality or some other thresholds and mark duplicates for use as inputs of Clair3?",tinyfallen,https://github.com/HKU-BAL/Clair3/issues/255
I_kwDOFQnk2856DKNa,SNP calling from bisulfite converted ONT,CLOSED,2023-12-18T23:38:23Z,2023-12-21T13:06:38Z,2023-12-21T13:06:38Z,"We are planning to use the Twist protocol to do targeted ONT sequencing. The protocol includes an enzymatic conversion step to convert all unmethylated Cs to Ts, so the analysis will be similar to Illumina BS-Seq. Our purpose is to do allele-specific methylation so we have to first call SNPs and then use them to phase methylation to the two alleles. Is there a way to use Clair3 for this type of SNP calling? If not, does anyone know of any other tool that I can try? I know there are multiple BS SNP callers for Illumina, but I'm not sure if they are applicable for ONT. Besides, my experience is that the accuracy of BS SNP calling is not that good.

Ideally, we should use adaptive sampling to do the targeted sequencing so that we can keep the DNA native. However, AS right now does not provide high enough fold enrichment and we are restricted by funding.",weishwu,https://github.com/HKU-BAL/Clair3/issues/256
I_kwDOFQnk2856D5Xa,Variant not detected within 16bp from the start/end,OPEN,2023-12-19T03:17:56Z,2024-07-04T01:21:44Z,,"Hello,

I noticed that Clair3 is not calling a variant near the end of a short reference sequence (position 2265 of Influenza A virus PB2 sequence [OP597571.1](https://www.ncbi.nlm.nih.gov/nuccore/OP597571.1); sequence length=2280). 

Bcftools calls at a G->A variant at position 2265. It's also clear from looking at the read alignment in IGV that there's a high AF variant at the position.

Clair3 `merge_output.vcf.gz`:

```
##fileformat=VCFv4.2
##source=Clair3
##clair3_version=1.0.4
##cmdline=../run_clair3.sh --bam_fn=minimap2.bam --ref_fn=OP597571.1.fasta --model_path=.../models/r941_prom_sup_g5014 --print_ref_calls --gvcf --threads=1 --platform=ont --output=clair3-out --haploid_sensitive --enable_long_indel --keep_iupac_bases --no_phasing_for_fa --include_all_ctgs
##reference=OP597571.1.fasta
##FILTER=<ID=PASS,Description=""All filters passed"">
##FILTER=<ID=LowQual,Description=""Low quality variant"">
##FILTER=<ID=RefCall,Description=""Reference call"">
##INFO=<ID=P,Number=0,Type=Flag,Description=""Result from pileup calling"">
##INFO=<ID=F,Number=0,Type=Flag,Description=""Result from full-alignment calling"">
##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">
##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">
##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ<20 or selected by 'samtools view -F 2316' are filtered)"">
##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">
##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">
##FORMAT=<ID=AF,Number=1,Type=Float,Description=""Observed allele frequency in reads, for each ALT allele, in the same order as listed, or the REF allele for a RefCall"">
##contig=<ID=OP597571.1,length=2280>
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  SAMPLE
OP597571.1      62      .       C       .       17.62   RefCall P       GT:GQ:DP:AD:AF:PL       0:17:828:641:0.7742:990
OP597571.1      185     .       G       A       9.65    PASS    F       GT:GQ:DP:AD:AF:PL       1:9:143:2,107:0.7483:18,13,0
OP597571.1      232     .       T       .       21.36   RefCall P       GT:GQ:DP:AD:AF:PL       0:21:102:75:0.7353:990
OP597571.1      252     .       C       A       25.12   PASS    P       GT:GQ:DP:AD:AF:PL       1:25:90:1,84:0.9333:80,58,0
OP597571.1      495     .       G       .       19.81   RefCall P       GT:GQ:DP:AD:AF:PL       0:19:42:36:0.8571:990
OP597571.1      510     .       C       T       33.42   PASS    F       GT:GQ:DP:AD:AF:PL       1:33:42:0,41:0.9762:79,57,0
OP597571.1      528     .       A       C       35.38   PASS    F       GT:GQ:DP:AD:AF:PL       1:35:44:0,41:0.9318:80,63,0
OP597571.1      540     .       G       C       26.34   PASS    P       GT:GQ:DP:AD:AF:PL       1:26:45:0,44:0.9778:80,54,0
OP597571.1      639     .       C       .       22.44   RefCall P       GT:GQ:DP:AD:AF:PL       0:22:44:28:0.6364:990
OP597571.1      694     .       T       .       26.30   RefCall P       GT:GQ:DP:AD:AF:PL       0:26:43:37:0.8605:990
OP597571.1      708     .       A       .       23.57   RefCall P       GT:GQ:DP:AD:AF:PL       0:23:43:33:0.7674:990
OP597571.1      741     .       A       .       23.27   RefCall P       GT:GQ:DP:AD:AF:PL       0:23:49:30:0.6122:990
OP597571.1      747     .       A       G       24.68   PASS    F       GT:GQ:DP:AD:AF:PL       1:24:47:4,40:0.8511:74,37,0
OP597571.1      888     .       T       C       24.92   PASS    P       GT:GQ:DP:AD:AF:PL       1:24:58:1,56:0.9655:80,42,0
OP597571.1      895     .       A       .       23.47   RefCall P       GT:GQ:DP:AD:AF:PL       0:23:59:51:0.8644:990
OP597571.1      1113    .       A       .       21.30   RefCall P       GT:GQ:DP:AD:AF:PL       0:21:45:40:0.8889:990
OP597571.1      1170    .       C       T       17.59   PASS    F       GT:GQ:DP:AD:AF:PL       1:17:41:25,12:0.2927:22,0,63
OP597571.1      1335    .       G       A       28.63   PASS    F       GT:GQ:DP:AD:AF:PL       1:28:43:0,40:0.9302:77,45,0
OP597571.1      1345    .       T       .       25.67   RefCall P       GT:GQ:DP:AD:AF:PL       0:25:44:30:0.6818:990
OP597571.1      1432    .       G       .       24.87   RefCall P       GT:GQ:DP:AD:AF:PL       0:24:52:43:0.8269:990
OP597571.1      1469    .       A       G       24.83   PASS    P       GT:GQ:DP:AD:AF:PL       1:24:52:2,49:0.9423:80,37,0
OP597571.1      1504    .       T       .       22.74   RefCall P       GT:GQ:DP:AD:AF:PL       0:22:50:41:0.8200:990
OP597571.1      1522    .       A       .       26.06   RefCall P       GT:GQ:DP:AD:AF:PL       0:26:54:39:0.7222:990
OP597571.1      1566    .       G       A       32.47   PASS    F       GT:GQ:DP:AD:AF:PL       1:32:54:2,52:0.9630:80,53,0
OP597571.1      1677    .       T       C       31.74   PASS    F       GT:GQ:DP:AD:AF:PL       1:31:57:4,49:0.8596:80,52,0
OP597571.1      1736    .       C       .       23.60   RefCall P       GT:GQ:DP:AD:AF:PL       0:23:59:41:0.6949:990
OP597571.1      1737    .       T       .       25.37   RefCall P       GT:GQ:DP:AD:AF:PL       0:25:59:43:0.7288:990
OP597571.1      1760    .       C       .       21.45   RefCall P       GT:GQ:DP:AD:AF:PL       0:21:60:52:0.8667:990
OP597571.1      1761    .       T       .       18.29   RefCall P       GT:GQ:DP:AD:AF:PL       0:18:60:44:0.7333:990
OP597571.1      1806    .       G       A       27.10   PASS    P       GT:GQ:DP:AD:AF:PL       1:27:58:0,54:0.9310:80,47,0
OP597571.1      1942    .       C       .       21.32   RefCall P       GT:GQ:DP:AD:AF:PL       0:21:87:73:0.8391:990
OP597571.1      1957    .       T       .       24.29   RefCall P       GT:GQ:DP:AD:AF:PL       0:24:96:72:0.7500:990
OP597571.1      2051    .       T       C       26.04   PASS    P       GT:GQ:DP:AD:AF:PL       1:26:168:1,156:0.9286:80,41,0
OP597571.1      2154    .       A       .       32.13   RefCall F       GT:GQ:DP:AD:AF:PL       0:32:713:468:0.6564:990
OP597571.1      2216    .       G       .       21.01   RefCall P       GT:GQ:DP:AD:AF:PL       0:21:834:715:0.8573:990
OP597571.1      2253    .       C       .       18.05   RefCall P       GT:GQ:DP:AD:AF:PL       0:18:767:569:0.7419:990
```

Bcftools mpileup and call output:

```
##fileformat=VCFv4.2
##FILTER=<ID=PASS,Description=""All filters passed"">
##bcftoolsVersion=1.17+htslib-1.17
##bcftoolsCommand=bcftools mpileup -d 100000 -f OP597571.1.fasta minimap2.bam
##contig=<ID=OP597571.1,length=2280>
##ALT=<ID=*,Description=""Represents allele(s) other than observed."">
##INFO=<ID=INDEL,Number=0,Type=Flag,Description=""Indicates that the variant is an INDEL."">
##INFO=<ID=IDV,Number=1,Type=Integer,Description=""Maximum number of raw reads supporting an indel"">
##INFO=<ID=IMF,Number=1,Type=Float,Description=""Maximum fraction of raw reads supporting an indel"">
##INFO=<ID=DP,Number=1,Type=Integer,Description=""Raw read depth"">
##INFO=<ID=VDB,Number=1,Type=Float,Description=""Variant Distance Bias for filtering splice-site artefacts in RNA-seq data (bigger is better)"",Version=""3"">
##INFO=<ID=RPBZ,Number=1,Type=Float,Description=""Mann-Whitney U-z test of Read Position Bias (closer to 0 is better)"">
##INFO=<ID=MQBZ,Number=1,Type=Float,Description=""Mann-Whitney U-z test of Mapping Quality Bias (closer to 0 is better)"">
##INFO=<ID=BQBZ,Number=1,Type=Float,Description=""Mann-Whitney U-z test of Base Quality Bias (closer to 0 is better)"">
##INFO=<ID=MQSBZ,Number=1,Type=Float,Description=""Mann-Whitney U-z test of Mapping Quality vs Strand Bias (closer to 0 is better)"">
##INFO=<ID=SCBZ,Number=1,Type=Float,Description=""Mann-Whitney U-z test of Soft-Clip Length Bias (closer to 0 is better)"">
##INFO=<ID=SGB,Number=1,Type=Float,Description=""Segregation based metric, http://samtools.github.io/bcftools/rd-SegBias.pdf"">
##INFO=<ID=MQ0F,Number=1,Type=Float,Description=""Fraction of MQ0 reads (smaller is better)"">
##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""List of Phred-scaled genotype likelihoods"">
##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">
##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes for each ALT allele, in the same order as listed"">
##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">
##INFO=<ID=DP4,Number=4,Type=Integer,Description=""Number of high-quality ref-forward , ref-reverse, alt-forward and alt-reverse bases"">
##INFO=<ID=MQ,Number=1,Type=Integer,Description=""Average mapping quality"">
##bcftools_callVersion=1.17+htslib-1.17
##bcftools_callCommand=call --ploidy 1 -mv -Ob -o calls.vcf; Date=Mon Dec 18 20:32:30 2023
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  WIN-AH-2023-FAV-0375-3-1C2d.Segment_1_PB2.OP597571.1.bam
OP597571.1      185     .       G       A       228.391 .       DP=139;VDB=0.979122;SGB=-0.693147;RPBZ=-0.747496;MQBZ=-0.574548;MQSBZ=-0.192448;BQBZ=1.13137;SCBZ=-0.508121;MQ0F=0;AC=1;AN=1;DP4=1,1,29,40;MQ=56       GT:PL   1:255,0
OP597571.1      252     .       C       A       225.421 .       DP=102;VDB=0.747331;SGB=-0.693147;MQSBZ=-0.642482;MQ0F=0;AC=1;AN=1;DP4=0,0,27,46;MQ=55  GT:PL 1:255,0
OP597571.1      510     .       C       T       228.402 .       DP=42;VDB=0.0719096;SGB=-0.693145;RPBZ=-0.412677;MQBZ=0;MQSBZ=0;BQBZ=1.36377;SCBZ=0.323986;MQ0F=0;AC=1;AN=1;DP4=1,0,16,25;MQ=60        GT:PL   1:255,0
OP597571.1      528     .       A       C       211.417 .       DP=41;VDB=0.278679;SGB=-0.693145;MQSBZ=0;MQ0F=0;AC=1;AN=1;DP4=0,0,19,22;MQ=60   GT:PL   1:241,0
OP597571.1      540     .       G       C       225.417 .       DP=44;VDB=0.219325;SGB=-0.693146;MQSBZ=0;MQ0F=0;AC=1;AN=1;DP4=0,0,18,26;MQ=60   GT:PL   1:255,0
OP597571.1      741     .       AGGGG   AGG     17.0828 .       INDEL;IDV=18;IMF=0.367347;DP=49;VDB=0.73002;SGB=-0.683931;RPBZ=-0.778151;MQBZ=0.124761;MQSBZ=-0.650785;BQBZ=1.02751;SCBZ=0.358316;MQ0F=0;AC=1;AN=1;DP4=14,17,8,5;MQ=58 GT:PL   1:87,42
OP597571.1      747     .       A       G       149.305 .       DP=45;VDB=0.841016;SGB=-0.693145;RPBZ=1.48153;MQBZ=1.82034;MQSBZ=0;BQBZ=2.48105;SCBZ=0.918559;MQ0F=0;AC=1;AN=1;DP4=4,1,19,21;MQ=58     GT:PL   1:176,0
OP597571.1      888     .       T       C       228.415 .       DP=57;VDB=0.0352829;SGB=-0.693147;RPBZ=0.304058;MQBZ=-0.190662;MQSBZ=0.201778;BQBZ=1.7129;SCBZ=0.309711;MQ0F=0;AC=1;AN=1;DP4=1,0,24,32;MQ=58   GT:PL   1:255,0
OP597571.1      1335    .       G       A       228.424 .       DP=42;VDB=0.713753;SGB=-0.693145;RPBZ=0.0412661;MQBZ=-0.156174;MQSBZ=-0.866025;BQBZ=1.69535;SCBZ=0.481876;MQ0F=0;AC=1;AN=1;DP4=1,0,17,24;MQ=59 GT:PL   1:255,0
OP597571.1      1469    .       A       G       221.38  .       DP=52;VDB=0.389159;SGB=-0.693147;RPBZ=0.667379;MQBZ=-0.353341;MQSBZ=-1.08356;BQBZ=2.5377;SCBZ=-1.22412;MQ0F=0;AC=1;AN=1;DP4=2,1,17,32;MQ=59    GT:PL   1:248,0
OP597571.1      1566    .       G       A       228.393 .       DP=55;VDB=0.00601305;SGB=-0.693147;RPBZ=0.899577;MQBZ=-0.498471;MQSBZ=-1.09919;BQBZ=1.93931;SCBZ=-1.1883;MQ0F=0;AC=1;AN=1;DP4=1,1,19,34;MQ=56  GT:PL   1:255,0
OP597571.1      1677    .       T       C       203.339 .       DP=55;VDB=0.0325114;SGB=-0.693147;RPBZ=-0.145875;MQBZ=-0.280056;MQSBZ=-0.785905;BQBZ=1.93259;SCBZ=-0.687735;MQ0F=0;AC=1;AN=1;DP4=2,2,19,32;MQ=58       GT:PL   1:230,0
OP597571.1      1806    .       G       A       228.42  .       DP=55;VDB=0.0163287;SGB=-0.693147;RPBZ=0.346711;MQBZ=-0.136083;MQSBZ=-0.847791;BQBZ=1.67811;SCBZ=-1.38535;MQ0F=0;AC=1;AN=1;DP4=1,0,22,32;MQ=59 GT:PL   1:255,0
OP597571.1      2051    .       T       C       228.414 .       DP=185;VDB=0.258521;SGB=-0.693147;RPBZ=-0.659562;MQBZ=-0.811578;MQSBZ=-6.21909;BQBZ=2.58014;SCBZ=-0.128242;MQ0F=0;AC=1;AN=1;DP4=1,2,100,80;MQ=55       GT:PL   1:255,0
OP597571.1      2265    .       G       A       228.4   .       DP=802;VDB=0;SGB=-0.693147;RPBZ=-0.477099;MQBZ=2.06864;MQSBZ=3.44984;BQBZ=7.12028;SCBZ=0.475257;MQ0F=0;AC=1;AN=1;DP4=23,0,710,60;MQ=54 GT:PL   1:255,0
```


Clair3 command:

```
CLAIR_BIN_DIR=$(dirname $(which run_clair3.sh))
MODEL_PATH=""$CLAIR_BIN_DIR/models/r941_prom_sup_g5014""

samtools faidx ref.fasta

run_clair3.sh \
    --bam_fn=minimap2.bam \
    --ref_fn=OP597571.1.fasta \
    --model_path=""$MODEL_PATH""\
    --threads=1 \
    --platform=""ont"" \
    --output=clair3-out \
    --haploid_sensitive \
    --enable_long_indel \
    --keep_iupac_bases \
    --no_phasing_for_fa \
    --include_all_ctgs
```

Other details:

- Clair3 version: 1.0.4 (installed from Bioconda)
- read mapper: Minimap2 v2.24
- instrument: GridION
- instrument software: MinKNOW 23.07.12 (Bream 7.7.6, Core 5.7.5, Dorado 7.1.4+d7df870c0)
- basecalling model: Super-accurate basecalling, 450 bps
- flowcell: FLO-MIN106
- kit: SQK-RBK110-96

---

Are there any parameters that need to be adjusted for variant calling of RNA virus sequence data?

Any help would be much appreciated!

Thanks!",peterk87,https://github.com/HKU-BAL/Clair3/issues/257
I_kwDOFQnk2856Yv1R,Snp prediction accuracy is low in all difficult mapping areas,CLOSED,2023-12-22T03:02:32Z,2023-12-23T00:49:12Z,2023-12-23T00:49:11Z,"Hi,
I use v3.1 stratification BED files,HG003 GUPPY3.6.0 data for testing, why the accuracy of snp and indel is not high，The results show that only 55%. I queried the results of Truth Challenge V2 and found that the accuracy of snp is more than 98%.Is this normal? I use bed files with high confidence regions, and the results are normal. What is the reason?
The default parameters I use.
[INFO] CLAIR3 VERSION: v1.0.0
[INFO] BAM FILE PATH: /mnt/usb2/data/hg003_g360.sort.bam
[INFO] REFERENCE FILE PATH: /mnt/usb2/data/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna
[INFO] MODEL PATH: /home/ywenjing/anaconda3/envs/clair3/bin/models/r941_prom_hac_g360+g422",oranges7,https://github.com/HKU-BAL/Clair3/issues/258
I_kwDOFQnk2857fAoP,Do I have to train a model for specific organism?,CLOSED,2024-01-09T06:41:52Z,2024-01-16T08:36:33Z,2024-01-12T01:28:50Z,"Hi, Developers,

I am confused about whether I have to train a model for ONT data from Pig before running the Clair3 variants calling command. Or can I use the provided model from humans?

Best,

Lingsen",Modernism-01,https://github.com/HKU-BAL/Clair3/issues/259
I_kwDOFQnk2857pSNI,Send adjacent SNP and Indel candidates both to full-alignment model,OPEN,2024-01-10T13:49:48Z,2024-07-04T01:23:06Z,,"I've been running Clair3 (v1.01) on some pig samples with ONT reads. I noticed that Clair3 has been assigning the ""1/1"" genotype to SNVs that have an allele frequency where I would expect an ""0/1"" genotype.

Example:
```
Ssc08   3369224 .       A       C       25.76   PASS    P       GT:GQ:DP:AD:AF:PL       1/1:25:42:22,20:0.4762:63,45,0
Ssc08   3369498 .       C       G       22.15   PASS    P       GT:GQ:DP:AD:AF:PL       1/1:22:43:20,20:0.4651:61,44,0
Ssc08   3374209 .       A       C       8.15    PASS    F       GT:GQ:DP:AD:AF:PL       1/1:8:49:24,23:0.4694:0,29,2
Ssc08   3374212 .       G       A       5.95    PASS    F       GT:GQ:DP:AD:AF:PL       1/1:5:49:25,23:0.4694:1,22,0
```

Do you have any idea why this might be happening?

-Best regards
Harald",haraldgrove,https://github.com/HKU-BAL/Clair3/issues/260
I_kwDOFQnk2857uUey,Ref calls not printed with `--print_ref_calls` when `--vcf_fn=FILE` is specified,CLOSED,2024-01-11T04:48:00Z,2024-03-17T05:34:40Z,2024-03-17T05:34:40Z,"Hi,

When I run the following clair3 command with --vcf_fn and --print_ref_calls provided, reference records report the genotype as ./. and don't report the other format fields (DP, etc.)

```
singularity exec \
			-B {params.INPUT_DIR} \
		  	-B {params.OUTPUT_DIR} \
		  	-B {params.REF_DIR} \
			-B {params.RESOURCE_DIR} \
		  	{input.sif_path} \
		  	/opt/bin/run_clair3.sh \
		  	--bam_fn={input.samples_to_run} \
		  	--ref_fn={input.REF} \
		  	--model_path=/opt/models/{params.MODEL_NAME} \
		  	--output={params.OUTPUT_DIR} \
		  	--threads={params.THREADS} \
		  	--platform=ont \
		  	--include_all_ctgs \
		  	--no_phasing_for_fa \
		  	--sample_name={wildcards.samples} \
		  	--gvcf \
		  	--include_all_ctgs \
			--threads=1 \
			--vcf_fn={params.targets_vcf} \
			--print_ref_calls

```
VCF output example showing missing ref fields:
<img width=""1263"" alt=""Screenshot 2024-01-10 at 11 48 37 PM"" src=""https://github.com/HKU-BAL/Clair3/assets/32968172/f924943e-7734-455f-9461-5a3fa48f0488"">


When I run a the same clair3 command but without --vcf_fn, the reference genotypes are reported as 0/0 and other format fields are reported.

```
singularity exec \
			-B {params.INPUT_DIR} \
		  	-B {params.OUTPUT_DIR} \
		  	-B {params.REF_DIR} \
			-B {params.RESOURCE_DIR} \
		  	{input.sif_path} \
		  	/opt/bin/run_clair3.sh \
		  	--bam_fn={input.samples_to_run} \
		  	--ref_fn={input.REF} \
		  	--model_path=/opt/models/{params.MODEL_NAME} \
		  	--output={params.OUTPUT_DIR} \
		  	--threads={params.THREADS} \
		  	--platform=ont \
		  	--include_all_ctgs \
		  	--no_phasing_for_fa \
		  	--sample_name={wildcards.samples} \
		  	--gvcf \
		  	--include_all_ctgs \
			--threads=1 \
			--print_ref_calls
```
VCF output example showing present ref fields:

<img width=""1221"" alt=""Screenshot 2024-01-10 at 11 49 51 PM"" src=""https://github.com/HKU-BAL/Clair3/assets/32968172/8734d738-48a0-4235-9f92-cc497b454f90"">

Is this expected behavior? I'd like to be able to run clair3 to report full records for reference calls with GT, GQ, and DP values when --vcf_fn is specified.",gtollefson,https://github.com/HKU-BAL/Clair3/issues/261
I_kwDOFQnk2858ouSk,Variants below min_coverage still being called,CLOSED,2024-01-19T18:15:03Z,2024-03-16T01:12:43Z,2024-03-16T01:12:43Z,"Hi,

I have set the min_coverage parameter to 10, but am still observing calls with read counts below that number in the final VCF. When I up the parameter to 20, then I see those have disappeared. Is there a range around the min_coverage that Clair3 still allows that would explain the presence of these calls? I have attached the VCF and the log.
[run_clair3.log](https://github.com/HKU-BAL/Clair3/files/13992803/run_clair3.log)
[merge_output.vcf.gz](https://github.com/HKU-BAL/Clair3/files/13992804/merge_output.vcf.gz)
",mproberts99,https://github.com/HKU-BAL/Clair3/issues/262
I_kwDOFQnk28589Xpp,r1041_e82_400bps_sup_v430 model contains only 4 files,CLOSED,2024-01-23T16:22:21Z,2024-01-25T01:53:19Z,2024-01-25T01:53:19Z,"Hello, according to the doc, the models should contain six files, but this one: r1041_e82_400bps_sup_v430; only contains:

```
ls
full_alignment.data-00000-of-00001  pileup.data-00000-of-00001
full_alignment.index                pileup.index

```
I downloaded it from Rerio. So far, Clair3 is running. Is it normal/expected? Do you think this will cause an issue? 

Thanks! 

Cheers
Alex",N/A,https://github.com/HKU-BAL/Clair3/issues/263
I_kwDOFQnk2859RvYS,r1041_e82_400bps_hac_v420 model of Guppy basecaller,CLOSED,2024-01-26T08:34:45Z,2024-10-09T11:41:59Z,2024-01-30T10:50:40Z,"Hi, 

    I'm aiming to execute clair3, but I couldn't find the r1041_e82_400bps_hac_v420 model of Guppy basecaller within rerio. The basecalling process was carried out by the sequencing company. Upon inspecting the read names in the Fastq files, I found the tag 'basecall_model_version_id=dna_r10.4.1_e8.2_400bps_hac@v4.2.0' embedded within. The Guppy version used is 7.1.4. Could you recommend the most suitable model for my analysis? Thank you!",cuzzlisa,https://github.com/HKU-BAL/Clair3/issues/264
I_kwDOFQnk2859mG_Z,Stack overflow seg fault in calculate_clair3_full_alignment,CLOSED,2024-01-30T07:33:23Z,2024-03-16T01:07:56Z,2024-03-15T07:37:02Z,"I ran a high coverage sample and got seg fault with clair3.py CallVariantsFromCffi running 1.0.4

Running a version of python3.9-debug allowed me to pinpoint the crash at clair3_full_alignment.c:656 which is a local array declaration.
`
HAP read_hap_array[reads_num];
`

At the time of crash, the value of reads_num was 387271

`
typedef struct HAP
{
    size_t read_index;
    size_t haplotype;
} HAP;
`

The definition of HAP reveals that it has a total of 16 bytes in my system. That means read_hap_array's memory foot print is 6,196,336 bytes. Since the stack size of my system is by default 8MB, I suspect this allocation plus other allocation in calculate_clair3_full_alignment causes stack overflow and hence seg fault.

Then I ran 'ulimit -s 16384' to double my stack size and Clair3 could run to completion without error.

My understanding is that this bug persists in 1.0.5. It would be great if future version of Clair3 can check if reads_num is greater than a certain number and then throw a stack overflow error and remind users to set increase their stack size instead of a mysterious seg fault.",ymcki,https://github.com/HKU-BAL/Clair3/issues/265
I_kwDOFQnk285_CjGt,Why are these SNPs called as RefCall?,CLOSED,2024-02-13T03:00:25Z,2024-02-16T00:32:30Z,2024-02-16T00:32:17Z,"These SNPs look true on IGV. Why are they labelled as RefCall by Clair3? The AF values in the output VCF are around 0.5.
<img width=""1440"" alt=""Screenshot 2024-02-12 at 9 55 01 PM"" src=""https://github.com/HKU-BAL/Clair3/assets/13355007/ddd30ae6-3ee7-4517-813b-0202e38d51aa"">

Another question: Clair3 is to find germline variants. However, my data is amplicon sequencing and may contain mosaic variants whose frequencies can have a wide range. Can Clair3 identify these variants? I don't have tumor-normal pairs so can't use ClairS.",weishwu,https://github.com/HKU-BAL/Clair3/issues/266
I_kwDOFQnk285_aNkR,Conda installation / cant run Clair3,CLOSED,2024-02-15T22:50:59Z,2024-04-11T15:52:26Z,2024-03-16T01:21:21Z,"Hello,
I just tried the Installation from Bioconda like this:
```
mamba create -n clair3_env -c bioconda clair3
mamba activate clair3_env
```
Unfortunately, there is no `clair.sh` in my environment that I can run, only `clair3.py`.
When I run `clair3.py --help` I get the following:
```
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 1: import: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 2: from: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 3: from: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 10: deep_learning_folder: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 11: CallVarBam,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 12: CallVariants,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 13: Train,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 14: CallVariantsFromCffi: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 15: ]: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 17: data_preprocess_folder: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 18: GetTruth,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 19: Tensor2Bin,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 20: RealignReads,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 21: CreateTensorPileup,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 22: CreateTensorFullAlignment,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 23: CreateTrainingTensor,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 24: SplitExtendBed,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 25: MergeBin,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 26: MergeVcf,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 27: SelectHetSnp,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 28: SelectCandidates,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 29: UnifyRepresentation,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 30: CheckEnvs,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 31: SortVcf,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 32: SelectQual,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 33: CreateTensorPileupFromCffi: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 34: CreateTensorFullAlignmentFromCffi,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 35: ]: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 37: post_process_scripts_folder: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 38: GetOverallMetrics,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 39: ]: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 41: vcf_post_process_scripts_folder: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 42: SwitchZygosityBasedOnSVCalls,: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 43: AddBackMissingVariantsInGenotyping: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 44: ]: command not found
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 47: syntax error near unexpected token `('
/home/kerbs/miniforge3/envs/clair3_env/bin/clair3.py: line 47: `def directory_for(submodule_name):'
```
I am using:
```
mamba 1.4.2
conda 23.3.1
```
What could be the issue? Thanks in advance.

Best,
Paul",pkerbs,https://github.com/HKU-BAL/Clair3/issues/267
I_kwDOFQnk285_u1QA,Does Clair3 take into account indels proximity when calling SNPs?,CLOSED,2024-02-19T18:59:38Z,2024-02-23T05:55:46Z,2024-02-23T05:55:46Z,"Hello, this used to be an issue that, when calling SNPs, indels were responsible for false positives. Bcftools even implemented a filter called SnpGap: Filter SNPs within <int> base pairs of an indel (the default) or any combination of indel,mnp,bnd,other,overlap

So far I haven't encountered SNPs which were ""obviously"" false due to an indel, but I was wondering if it's something you had investigated: does Clair3 reject SNPs very close to indels? I am aware that it's probably a double edge swords to implement a filter such as ""all SNP in + or - 3 bases of the indels become TN (true negative)"". 

Thanks a lot",N/A,https://github.com/HKU-BAL/Clair3/issues/268
I_kwDOFQnk285_y8BF,genome phasing,CLOSED,2024-02-20T10:34:33Z,2024-03-16T01:20:49Z,2024-03-16T01:20:49Z,"Hi,
 
I am writing because I want to phase a genome that I assembled using  nanopore long reads and then I used HiC data to scaffold chromosomes.  I was wondering if you could provide me with some advance on how to do this. What tool would you use to phase the genome?? I must say that the draft genome was assembled using flye, so, maternal and paternal might be collapsed and, therefore, I may need to use another assembler. Do you know a good option for nanopore reads?? 

 I have ~250M valid HiC reads for the genome, so I also wonder if it would be possible to phase male and female nanopore reads using Clair3, assemble them separately and then us hic for scaffold
 
My best,
Diego",DiegoSafian,https://github.com/HKU-BAL/Clair3/issues/269
I_kwDOFQnk285_9cPQ,Detect very low SNP frequencies,CLOSED,2024-02-21T13:51:42Z,2024-02-23T05:33:17Z,2024-02-23T05:33:17Z,"Hello,
We are looking to test a really low frequencies (2.5, 5, 10, 20%) SNP detection in viral sample.
We analyse two BAC with one mutation, mix in different proportion. I use Calir3 with this parameter :
-m r1041_e82_400bps_hac_v410/
--haploid_sensitive
--include_all_ctgs
--snp_min_af=0.01
--min_coverage=10
--no_phasing_for_fa
--var_pct_full=1
--ref_pct_full=1
--var_pct_phasing=1
--call_snp_only
-p ont

Clair3 catch all SNP > 20%
But when the proportion is bellow 20% even if I can see the SNP on IGV 
![image](https://github.com/HKU-BAL/Clair3/assets/100346160/6d2a18b7-8bb1-4721-803e-5a235904dfac)
It appears as RefCall in full_alignment.vcf :
![image](https://github.com/HKU-BAL/Clair3/assets/100346160/252f201e-6715-471b-9e31-87117be18549)
And in pileup.vcf:
![image](https://github.com/HKU-BAL/Clair3/assets/100346160/88198eec-a630-4a68-a850-f1160458c9a9)

Maybe I missunderstand something but why this SNP is tag as a 'RefCall' ?

Best regards,
Hugo",HJArdin,https://github.com/HKU-BAL/Clair3/issues/270
I_kwDOFQnk286AKN8h,pileup variant for identical genomes,CLOSED,2024-02-23T00:19:34Z,2024-05-07T23:59:41Z,2024-03-16T01:12:26Z,"Hi,

I have high quality ONT reads from a single cell that passed all the quality check. I assembled these reads into a genome, then used Clair3 on the reads and the assemble genome to see test out Clair3 accuracy. So theoretically I shouldn't see any SNP? 

My command was in addition to the required flag `--include_all_ctgs --no_phasing_for_fa --haploid_precise --call_snp_only`

The output is:

> [WARNING] No variant found, output empty vcf file
> [WARNING] Copying pileup.vcf.gz to /home/vdpham/Documents/dorado_basecalling/augWGS_2023/barcode11/porechop-flye-medaka-wf-alignment-clair3/clair3_haploidprecise/merge_output.vcf.gz
> 
> [INFO] Finish calling, output file: /home/vdpham/Documents/dorado_basecalling/augWGS_2023/barcode11/porechop-flye-medaka-wf-alignment-clair3/clair3_haploidprecise/merge_output.vcf.gz

So it's good that there was no variant found? But when I opened the merge_output.vcf file, it looks like this:

> #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	SAMPLE
> contig_1	58	.	G	.	11.56	RefCall	P	GT:GQ:DP:AD:AF	0/0:11:62:42:0.6774
> contig_1	239	.	C	.	29.69	RefCall	P	GT:GQ:DP:AD:AF	0/0:29:63:54:0.8571
> contig_1	966	.	C	.	21.30	RefCall	P	GT:GQ:DP:AD:AF	0/0:21:71:48:0.6761
> contig_1	969	.	C	.	7.85	RefCall	P	GT:GQ:DP:AD:AF	0/0:7:71:39:0.5493
> contig_1	970	.	T	.	26.99	RefCall	P	GT:GQ:DP:AD:AF	0/0:26:71:61:0.8592
> contig_1	1211	.	C	.	18.24	RefCall	P	GT:GQ:DP:AD:AF	0/0:18:73:50:0.6849
> contig_1	1214	.	C	.	16.75	RefCall	P	GT:GQ:DP:AD:AF	0/0:16:73:42:0.5753
> contig_1	1215	.	A	.	23.37	RefCall	P	GT:GQ:DP:AD:AF	0/0:23:73:58:0.7945
> contig_1	1219	.	C	.	17.63	RefCall	P	GT:GQ:DP:AD:AF	0/0:17:73:43:0.5890
> contig_1	1222	.	T	.	23.90	RefCall	P	GT:GQ:DP:AD:AF	0/0:23:73:59:0.8082
> contig_1	1227	.	C	.	24.19	RefCall	P	GT:GQ:DP:AD:AF	0/0:24:74:59:0.7973
> contig_1	1231	.	G	.	23.76	RefCall	P	GT:GQ:DP:AD:AF	0/0:23:74:40:0.5405

How should I interpret this result? No variant found but there are pileup variants? What are pileup variants and are they true variants?

Thank you.
",lagphase,https://github.com/HKU-BAL/Clair3/issues/271
I_kwDOFQnk286AK85B,Incorrect SNP representation when it overlaps a deletion,OPEN,2024-02-23T04:38:30Z,2024-07-04T01:24:35Z,,"When I was trying to run vcfeval with the same vcf generated by Clair3 using the following command, I find that I am getting 
3518 out of 5440881 FPs/FNs

./rtg vcfeval -t ~/genome/hs38.sdf -b sample.vcf.gz -c sample.vcf.gz --ref-overlap -o sample

Threshold  True-pos-baseline  True-pos-call  False-pos  False-neg  Precision  Sensitivity  F-measure
----------------------------------------------------------------------------------------------------
    2.000            5440881        5440881       3518       3518     0.9994       0.9994     0.9994
     None            5440881        5440881       3518       3518     0.9994       0.9994     0.9994

Upon looking at the FPs/FNs, I noticed that quite many of them are caused by incorrect SNP calls when a deletion overlaps an SNP.
For example:
chr1    4620711 .       AAAAT   A       6.41    PASS    F;ANN=A|downstream_gene_variant|MODIFIER|LOC107985376|LOC107985376|transcript|XR_001737775.1|pseudogene||n.*3157_*3160delAAAT|||||3157|,A|intergenic_region|MODIFIER|LOC107985376-AJAP1|LOC107985376-AJAP1|intergenic_region|LOC107985376-AJAP1|||n.4620712_4620715delAAAT||||||       GT:GQ:DP:AD:AF:PS      1|0:6:58:44,14:0.2414:2747268
chr1    4620715 .       T       A       7.2     PASS    F;ANN=A|downstream_gene_variant|MODIFIER|LOC107985376|LOC107985376|transcript|XR_001737775.1|pseudogene||n.*3160T>A|||||3160|,A|intergenic_region|MODIFIER|LOC107985376-AJAP1|LOC107985376-AJAP1|intergenic_region|LOC107985376-AJAP1|||n.4620715T>A||||||     GT:GQ:DP:AD:AF:PS       1/1:7:58:39,18:0.3103:.

By loading haplotagged bam to IGV, I can see that the deletion is on one haplotype and the SNP is on the other haplotype.. So the correct call should be 1|0 for the deletion and 1|2 for the SNP where 2 is for the missing allele * based on VCF spec.
https://gatk.broadinstitute.org/hc/en-us/articles/360035531912-Spanning-or-overlapping-deletions-allele

So the corrected calls should be:
chr1    4620711 .       AAAAT   A       6.41    PASS    F;ANN=A|downstream_gene_variant|MODIFIER|LOC107985376|LOC107985376|transcript|XR_001737775.1|pseudogene||n.*3157_*3160delAAAT|||||3157|,A|intergenic_region|MODIFIER|LOC107985376-AJAP1|LOC107985376-AJAP1|intergenic_region|LOC107985376-AJAP1|||n.4620712_4620715delAAAT||||||       GT:GQ:DP:AD:AF:PS      1|0:6:58:44,14:0.2414:2747268
chr1    4620715 .       T       A,*       7.2     PASS    F;ANN=A|downstream_gene_variant|MODIFIER|LOC107985376|LOC107985376|transcript|XR_001737775.1|pseudogene||n.*3160T>A|||||3160|,A|intergenic_region|MODIFIER|LOC107985376-AJAP1|LOC107985376-AJAP1|intergenic_region|LOC107985376-AJAP1|||n.4620715T>A||||||     GT:GQ:DP:AD:AF:PS       2|1:7:58:39,18:0.3103:.

and vcfeval doesn't flag them as FPs/FNs.

By assuming the hetero deletion calls are correct, I fixed the SNP calls with the following awk commands, 
awk '!/^#/&&length($4)>length($5){split($10,a,"":"");d=length($4)-length($5);if(a[1]==""0|1""||a[1]==""1|0""||a[1]==""0/1""){for(i=1;i<=d;++i){printf ""%s\t%d\t%s\n"",$1,$2+i,a[1]}}}' sample.vcf > sample.del
awk 'BEGIN{b[""0|1""]=""1|2"";b[""1|0""]=""2|1"";b[""0/1""]=""1/2"";while(getline<""sample.del""){a[sprintf(""%s:%d"",$1,$2)]=b[$3]}}/^#/{print}!/^#/&&length($4)!=length($5){print}!/^#/&&length($4)==length($5){p=sprintf(""%s:%d"",$1,$2);if(a[p]!=""""){$5=sprintf(""%s,*"",$5);$10=sprintf(""%s%s"",a[p],substr($10,4))}OFS=""\t"";print}' sample.vcf > sample_fixed.vcf

The number of FPs/FNs is reduced to 942 which improves precision/sensitivity from 99.9354% to 99.9827%

In the remaining 942, I noticed that 295 of them are caused by overlapping homo deletion and homo SNP calls. The rest are more complex calls.

It would be great if Clair3 can fix these problems in the future release. It will help greatly in benchmarking and also reducing the false homo SNP calls that are often ignored by clinicians. Thank you very much for your time.

",ymcki,https://github.com/HKU-BAL/Clair3/issues/272
I_kwDOFQnk286AMlio,Unable to install Clair3 with conda issue with tensorflow,CLOSED,2024-02-23T10:18:19Z,2024-03-16T01:21:08Z,2024-03-16T01:21:08Z,"Hi,

I am getting the following issue when trying to install clair3 using conda.

Thanks.

```
(base) ➜  ~ conda create -n clair3 -c bioconda clair3 python=3.9.0 -y
Channels:
 - bioconda
 - conda-forge
 - defaults
 - default
Platform: osx-64
Collecting package metadata (repodata.json): done
Solving environment: failed

LibMambaUnsatisfiableError: Encountered problems while solving:
  - nothing provides tensorflow 2.2.0.* needed by clair3-0.1.10-hdfd78af_0

Could not solve for environment specs
The following package could not be installed
└─ clair3 is not installable because it requires
   └─ tensorflow 2.2.0.* , which does not exist (perhaps a missing channel).

```",sachiwije,https://github.com/HKU-BAL/Clair3/issues/273
I_kwDOFQnk286ANHH3,Variant is not detected in amplicon sequencing data,CLOSED,2024-02-23T11:44:11Z,2024-03-12T13:19:57Z,2024-03-12T13:19:57Z,"Hello,

I am using Clair3 for variant calling on amplicon sequencing data. These reads were basecalled using Dorado (dna_r10.4.1_e8.2_400bps_sup@v4.3.0 model). For Clair3, I am using the r1041_e82_400bps_hac_v420 model (from Rerio). I have set the parameters to --var_pct_full=1 --ref_pct_full=1 --var_pct_phasing=1. However, Clair3 does not detect a variant at a specific position, which is visible in IGV. I also tried running Clair3 with r1041_e82_400bps_hac_v430 and r1041_e82_400bps_sup_v430 models, but the result was the same. Furthermore, I observed a decrease in recall when I used v430 models. I attached the IGV image of the variant in question:
![igv_cpt1](https://github.com/HKU-BAL/Clair3/assets/141839630/d7062723-9c4b-452f-b210-9bbb421b5b77)



Do you have any idea what might be the reason?

Thank you for your assistance.",keremozdel,https://github.com/HKU-BAL/Clair3/issues/274
I_kwDOFQnk286AZ2gY,Is there a way to report a MAPQ or MQ metrics?,CLOSED,2024-02-26T14:02:27Z,2024-02-27T08:33:52Z,2024-02-27T08:33:52Z,"Hello, 

We are dealing with non-model organisms that prevent us from having ultra-long ONT reads. Most of them are 10 Kb long. It's an issue because it's not long enough to span all repeats. Therefore, we have apparent false 0/1 calls (obvious when eyeballing in IGV). However, I understand why Clair3 made the mistake. It's important to note that my organism's Het rate is around 3%, much higher than the 0.1% seen in the human genome. Therefore, due to the repeat and relatively short reads, even if a position has an AD of 10,70, it can still have a genotype of 0/0.  I would have liked to try a mapping quality filter (we have some truth set in the form of an assembled phased genome). But there seems to be none... My understanding is that it's because Clair3 deals internally with MAPQ. 

I see there is a snp_min_af setting. But it's a vague proxy because if raised relatively high, it will prevent false calls in the repeats. Still, it will probably induce false negatives in non-repetitive regions. 

Would you have any specific advice on how to tweak Clair3? Otherwise, I will try to deal with the false calls using pileup from the genome assemblies; it's going to be a bit experimental. 

I realise it's possible to retrain Clair3, but it requires significant GPU power, right? 

Thanks for any insight you might have. I realise there might be no solution since the issue is the shortened reads we get with this organism. Feel free to close this if you think there is nothing we can do with the caller. 

Thanks a lot for your work on clair3 (I am not saying this to flatter you, but it's genuinely awesome; even if I have issues, they are already orders of magnitudes lower than with other callers). 

Alex",N/A,https://github.com/HKU-BAL/Clair3/issues/275
I_kwDOFQnk286AuO7X,"Value Error: A BGZF (e.g. a BAM file) block should start with b'\x1f\x8b\x08\x04', not b'\xf12\xdeB'",CLOSED,2024-02-28T18:37:45Z,2024-11-07T07:17:46Z,2024-03-15T15:02:22Z,"command 

using docker `docker run --rm -it -v /mnt/e/E:/EEE hkubal/clair3:latest bash`



`/opt/bin/run_clair3.sh --bam_fn=/data/41195.minimap2.bam --ref_fn=/data/Homo_sapiens_assembly38.fasta.gz --output=/data/Clair3_41195 --remove_intermediate_dir --enable_long_indel --threads=40 --platform=ont --model_path=/opt/models/r941_prom_sup_g5014 --sample_name=41195
`

Error
```

# Working on contig chr2 in individual 41195
Found 176014 usable heterozygous variants (0 skipped due to missing genotypes)
Traceback (most recent call last):
  File ""/opt/conda/envs/clair3/bin/whatshap"", line 10, in <module>
    sys.exit(main())
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/__main__.py"", line 64, in main
    module.main(args)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/cli/phase.py"", line 1169, in main
    run_whatshap(**vars(args))
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/cli/phase.py"", line 493, in run_whatshap
    readset, vcf_source_ids = phased_input_reader.read(
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/cli/__init__.py"", line 152, in read
    readset = readset_reader.read(chromosome, variants, bam_sample, reference, regions)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/variants.py"", line 98, in read
    readset = self._make_readset_from_grouped_reads(grouped_reads)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/variants.py"", line 104, in _make_readset_from_grouped_reads
    for group in groups:
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/variants.py"", line 119, in _group_paired_reads
    for read in reads:
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/variants.py"", line 166, in _alignments_to_reads
    reference = reference[:]
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/pyfaidx/__init__.py"", line 920, in __getitem__
    return self._fa.get_seq(self.name, start + 1, stop)[::step]
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/pyfaidx/__init__.py"", line 1149, in get_seq
    seq = self.faidx.fetch(name, start, end)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/pyfaidx/__init__.py"", line 727, in fetch
    seq = self.from_file(name, start, end)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/pyfaidx/__init__.py"", line 769, in from_file
    self.file.seek(i.offset)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/Bio/bgzf.py"", line 682, in seek
    self._load_block(start_offset)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/Bio/bgzf.py"", line 643, in _load_block
    block_size, self._buffer = _load_bgzf_block(handle, self._text)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/Bio/bgzf.py"", line 444, in _load_bgzf_block
    raise ValueError(
ValueError: A BGZF (e.g. a BAM file) block should start with b'\x1f\x8b\x08\x04', not b'\xf12\xdeB'; handle.tell() now says 3840
```",husamia,https://github.com/HKU-BAL/Clair3/issues/276
I_kwDOFQnk286AwdeA,[ERROR] No pileup model found in provided model path and model prefix ,CLOSED,2024-02-29T01:45:58Z,2024-03-12T13:21:55Z,2024-03-12T13:21:55Z,"Hello,

I followed installation instructions using conda and ran the follow clair3 command in bash to call variants in nanopore sequencing data:

$ run_clair3.sh --bam_fn=1026NJ4_NHEJ_FLsorted.bam --ref_fn=NHEJAssayABshortref.fas --output=/mnt/c/users/josep/Downloads/ROMANOWSKI_CUSTOM_253/NHEJassay_IGV_files --threads=16 --platform=ont --model_path=/home/joeromanowski/miniconda3/envs/clair3/bin/models/


To which I received the following output:

[INFO] CLAIR3 VERSION: v1.0.5
[INFO] BAM FILE PATH: /mnt/c/users/josep/Downloads/ROMANOWSKI_CUSTOM_253/NHEJassay_IGV_files/1026NJ4_NHEJ_FLsorted.bam
[INFO] REFERENCE FILE PATH: /mnt/c/users/josep/Downloads/ROMANOWSKI_CUSTOM_253/NHEJassay_IGV_files/NHEJAssayABshortref.fas
[INFO] MODEL PATH: /home/joeromanowski/miniconda3/envs/clair3/bin/models
[INFO] OUTPUT FOLDER: /mnt/c/users/josep/Downloads/ROMANOWSKI_CUSTOM_253/NHEJassay_IGV_files
[INFO] PLATFORM: ont
[INFO] THREADS: 16
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: /home/joeromanowski/miniconda3/envs/clair3
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] PHASING PROPORTION: 0.7
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.08
[INFO] INDEL AF THRESHOLD: 0.15
[INFO] BASE ERROR IN GVCF: 0.001
[INFO] GQ BIN SIZE IN GVCF: 5
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE LONGPHASE FOR INTERMEDIATE VCF PHASING: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING WHATSHAP: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING LONGPHASE: False
[INFO] ENABLE HAPLOTAGGING FINAL BAM: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE C_IMPLEMENT: True

[ERROR] No pileup model found in provided model path and model prefix /home/joeromanowski/miniconda3/envs/clair3/bin/models/pileup

real    0m0.065s
user    0m0.011s
sys     0m0.004s

Any help to overcome this is appreciated!

Best,

Joe",jsromanowski,https://github.com/HKU-BAL/Clair3/issues/277
I_kwDOFQnk286BYWZn,Is Representation Unification required for all depths for pileup model training?,CLOSED,2024-03-06T05:03:33Z,2024-03-07T04:00:52Z,2024-03-07T04:00:51Z,"Hi, 

According to revision 1 of the instructions for training the full-alignment model, we only need to run Representation Unification once for the full depth. Since there is no such revision for the pileup training instructions, does it mean it still requires one run of Representation Unification for each depth? 

Thank you. 

  ",dehui333,https://github.com/HKU-BAL/Clair3/issues/279
I_kwDOFQnk286Br_X7,Variant is not detected,CLOSED,2024-03-08T10:58:37Z,2024-04-09T15:55:39Z,2024-04-09T15:55:39Z,"For some reason, it's missing variants. This is the merge vcf:
```
##fileformat=VCFv4.2
##source=Clair3
##clair3_version=1.0.4
##cmdline=/opt/bin/run_clair3.sh --bam_fn=/root/clair3/input/A10.bam --ref_fn=/root/clair3/input/reference.fasta --threads=2 --platform=ont --model_path=/opt/models/r1041_e82_400bps_sup_v420 --output=/root/clair3/output --include_all_ctgs --snp_min_af=0.01 --qual=1 --no_phasing_for_fa
##reference=/root/clair3/input/reference.fasta
##FILTER=<ID=PASS,Description=""All filters passed"">
##FILTER=<ID=LowQual,Description=""Low quality variant"">
##FILTER=<ID=RefCall,Description=""Reference call"">
##INFO=<ID=P,Number=0,Type=Flag,Description=""Result from pileup calling"">
##INFO=<ID=F,Number=0,Type=Flag,Description=""Result from full-alignment calling"">
##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">
##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">
##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ<20 or selected by 'samtools view -F 2316' are filtered)"">
##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">
##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">
##FORMAT=<ID=AF,Number=1,Type=Float,Description=""Observed allele frequency in reads, for each ALT allele, in the same order as listed, or the REF allele for a RefCall"">
##contig=<ID=077fe5c3b2134307b51035f0,length=1607>
#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	SAMPLE
077fe5c3b2134307b51035f0	864	.	G	A	10.01	PASS	P	GT:GQ:DP:AD:AF	0/1:10:301:64,228:0.7575
077fe5c3b2134307b51035f0	974	.	C	A	14.29	PASS	P	GT:GQ:DP:AD:AF	1/1:14:301:55,232:0.7708
077fe5c3b2134307b51035f0	978	.	A	G	10.45	PASS	P	GT:GQ:DP:AD:AF	1/1:10:301:68,225:0.7475
077fe5c3b2134307b51035f0	980	.	C	G	11.42	PASS	P	GT:GQ:DP:AD:AF	1/1:11:301:60,224:0.7442
077fe5c3b2134307b51035f0	985	.	C	A	7.79	PASS	F	GT:GQ:DP:AD:AF	1/1:7:301:64,224:0.7442
```

But IGV shows a snp at 984:
<img width=""748"" alt=""image"" src=""https://github.com/HKU-BAL/Clair3/assets/4777566/58321c67-5b87-4fde-a316-c438699c1746"">

",hillstub,https://github.com/HKU-BAL/Clair3/issues/280
I_kwDOFQnk286B1dvu,Pileup model to use for full-alignment training step,CLOSED,2024-03-11T05:42:44Z,2024-03-11T05:57:39Z,2024-03-11T05:57:39Z,"Hi, 

In step 

**II. Build compressed binary files for full-alignment model training, 1. Run Clair3 pileup model**

in the instructions for full alignment model training/fine-tuning, the pileup model used is by default 

**--model_path=""${CONDA_PREFIX}/bin/models/ont""**

If I intend to use the fine-tuned full-alignment model together with a fine-tuned pileup model, should I replace the above with the fine-tuned pileup model or leave it as it is - the ont model? 

Thank you.   

",dehui333,https://github.com/HKU-BAL/Clair3/issues/281
I_kwDOFQnk286CVNDf,Failed to Merge gvcf files into multiple gvcf and vcf,CLOSED,2024-03-14T14:58:50Z,2024-03-15T15:02:10Z,2024-03-15T15:02:10Z,"I have finished the vcf calling with clair3, the command is below: 

```
singularity exec \
  -B ${INPUT_DIR}:${INPUT_DIR} \
  -B ${OUTPUT_DIR}:${OUTPUT_DIR} \
  $IMAGE_PATH/clair3_latest.sif \
  /opt/bin/run_clair3.sh \
  --bam_fn=${INPUT_DIR}/${BAM} \
  --ref_fn=${REF} \
  --threads=${THREADS} \
  --platform=${PLATFORM} \
  --model_path=""/opt/models/${MODEL_NAME}"" \
  --output=${OUTPUT_DIR}/${SLURM_JOB_NAME} \
  --sample_name=${SLURM_JOB_NAME} \
  --print_ref_calls \
  --gvcf \
  --no_phasing_for_fa \
  --include_all_ctgs
```
Then I attempted to merge gvcf files from different samples into a gvcf and genotype, but it was failed.

the GATK version :
The Genome Analysis Toolkit (GATK) v4.5.0.0
HTSJDK Version: 4.1.0
Picard Version: 3.1.1

```
gatk CombineGVCFs \
   -R $REF \
   --variant $gvcf1 \
   --variant $gvcf2 \
   --variant $gvcf4 \
   --variant $gvcf5 \
   -O $output1
```
the log file: 

> 21:05:10.190 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/public/home/zenglingsen/04.software/02.Anaconda/Or/envs/pytorch/share/gatk4-4.5.0.0-0/gatk-package-4.5.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so
> 21:05:10.646 INFO  CombineGVCFs - ------------------------------------------------------------
> 21:05:10.650 INFO  CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.5.0.0
> 21:05:10.650 INFO  CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/
> 21:05:10.650 INFO  CombineGVCFs - Executing as zenglingsen@comput7 on Linux v3.10.0-862.el7.x86_64 amd64
> 21:05:10.650 INFO  CombineGVCFs - Java runtime: OpenJDK 64-Bit Server VM v17.0.3-internal+0-adhoc..src
> 21:05:10.651 INFO  CombineGVCFs - Start Date/Time: 2024年3月14日 CST 下午9:05:09
> 21:05:10.651 INFO  CombineGVCFs - ------------------------------------------------------------
> 21:05:10.651 INFO  CombineGVCFs - ------------------------------------------------------------
> 21:05:10.652 INFO  CombineGVCFs - HTSJDK Version: 4.1.0
> 21:05:10.652 INFO  CombineGVCFs - Picard Version: 3.1.1
> 21:05:10.652 INFO  CombineGVCFs - Built for Spark Version: 3.5.0
> 21:05:10.653 INFO  CombineGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2
> 21:05:10.653 INFO  CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false
> 21:05:10.653 INFO  CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true
> 21:05:10.653 INFO  CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false
> 21:05:10.654 INFO  CombineGVCFs - Deflater: IntelDeflater
> 21:05:10.654 INFO  CombineGVCFs - Inflater: IntelInflater
> 21:05:10.654 INFO  CombineGVCFs - GCS max retries/reopens: 20
> 21:05:10.654 INFO  CombineGVCFs - Requester pays: disabled
> 21:05:10.655 INFO  CombineGVCFs - Initializing engine
> 21:05:11.017 INFO  FeatureManager - Using codec VCFCodec to read file file:///public/home/zenglingsen/01.data/01.ONT_data/01.ONT_20X_fastq_SNP_calling/04.clair3/AW/merge_output.gvcf.gz
> 21:05:11.319 INFO  FeatureManager - Using codec VCFCodec to read file file:///public/home/zenglingsen/01.data/01.ONT_data/01.ONT_20X_fastq_SNP_calling/04.clair3/BKS/merge_output.gvcf.gz
> 21:05:12.084 INFO  CombineGVCFs - Done initializing engine
> 21:05:12.122 INFO  ProgressMeter - Starting traversal
> 21:05:12.123 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute
> 21:05:12.291 WARN  ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location NW_018084912.1:462 the annotation F=true was not a numerical value and was ignored
> 21:05:12.892 INFO  CombineGVCFs - Shutting down engine
> [2024年3月14日 CST 下午9:05:12] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.05 minutes.
> Runtime.totalMemory()=671088640
> **_java.lang.IllegalStateException: The elements of the input Iterators are not sorted according to the comparator htsjdk.variant.variantcontext.VariantContextComparator_**
> 	at htsjdk.samtools.util.MergingIterator.next(MergingIterator.java:107)
> 	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
> 	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1845)
> 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)
> 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)
> 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
> 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
> 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
> 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)
> 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:136)
> 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:165)
> 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1098)
> 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149)
> 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198)
> 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217)
> 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:166)
> 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:209)
> 	at org.broadinstitute.hellbender.Main.main(Main.java:306)
> Using GATK jar /public/home/zenglingsen/04.software/02.Anaconda/Or/envs/pytorch/share/gatk4-4.5.0.0-0/gatk-package-4.5.0.0-local.jar
> Running:
>     java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /public/home/zenglingsen/04.software/02.Anaconda/Or/envs/pytorch/share/gatk4-4.5.0.0-0/gatk-package-4.5.0.0-local.jar CombineGVCFs -R /public/home/zenglingsen/01.data/03.Reference/GCF_000003025.6_Sscrofa11.1_genomic.fna --variant /public/home/zenglingsen/01.data/01.ONT_data/01.ONT_20X_fastq_SNP_calling/04.clair3/AW/merge_output.gvcf.gz --variant /public/home/zenglingsen/01.data/01.ONT_data/01.ONT_20X_fastq_SNP_calling/04.clair3/BKS/merge_output.gvcf.gz -O /public/home/zenglingsen/01.data/01.ONT_data/01.ONT_20X_fastq_SNP_calling/04.clair3/01.merge/test.merged.gvcf.gz

who can give me  some advice ? 
Thank you.",Modernism-01,https://github.com/HKU-BAL/Clair3/issues/283
I_kwDOFQnk286CuXrn,"Intermittent failure during parallel variant calling: Died at /opt/conda/envs/clair3/bin/parallel line 9375, <$fh> chunk 1.",CLOSED,2024-03-18T20:11:55Z,2024-04-19T04:34:43Z,2024-04-19T04:34:43Z,"I'm developing a snakemake pipeline for running clair3 variant calling which runs the clair3 singularity container over a set of individual samples. Some sample runs fail and the clair3 logs report: Died at /opt/conda/envs/clair3/bin/parallel line 9375, <$fh> chunk 1. I've attached a txt file with the error message at line 80. It looks like clair3 fails during parallelization of variant calling on a single sample. 

When I rerun the snakemake, I see that usually, all of the failed samples complete running without error. I see this intermittent error behavior each time I run the snakemake. A majority of the failed runs are in smaller samples which leads me to wonder if it's an issue with many samples being handled for parallel processing at one time.

Can you help me to troubleshoot this intermittent error? 

My Clair3 call from snakemake is as follows:

```python
rule run_clair3_raw:
	""""""
	call variants in all regions in sorted bams with clair3 and output gvcf and vcf files. Using 0.0001 as the minimum allele frequency for both snps and indels.
	""""""
	input:
		samples_to_run=config[""output_dir""]+'/mapping/bam_files/{sample}.sorted.bam',
		REF = config['genome_directory']+'/genome.fa', # TODO:make demo resources with Pf3D7 genome for built in tutorial demo data
		sif_path = config[""clair3_sif_path""] # TODO: this can be handled by the singularity container eventually so users dont install clair3 themselves.
	output:
		vcf=config[""output_dir""]+'/variant_calling/{sample}_raw'+'/merge_output.vcf.gz',
		gvcf=config[""output_dir""]+'/variant_calling/{sample}_raw'+'/merge_output.gvcf.gz'
	params:
		INPUT_DIR = config[""output_dir""]+'/mapping/bam_files',
		OUTPUT_DIR = config[""output_dir""]+'/variant_calling/{sample}_raw',
		REF_DIR = config['genome_directory'],
		RESOURCE_DIR = config[""project_resources""],
		THREADS = 4,
		MODEL_NAME = 'r941_prom_sup_g5014',
		targets_vcf = config[""project_resources""]+'/targets.vcf.gz'
	shell:
		'''
		echo 'Processing sample: {wildcards.sample}'
		singularity exec \
			-B {params.INPUT_DIR} \
			-B {params.OUTPUT_DIR} \
			-B {params.REF_DIR} \
			-B {params.RESOURCE_DIR} \
			{input.sif_path} \
			/opt/bin/run_clair3.sh \
			--bam_fn={input.samples_to_run} \
			--ref_fn={input.REF} \
			--model_path=/opt/models/{params.MODEL_NAME} \
			--output={params.OUTPUT_DIR} \
			--threads={params.THREADS} \
			--platform=ont \
			--include_all_ctgs \
			--no_phasing_for_fa \
			--sample_name={wildcards.sample} \
			--gvcf \
			--snp_min_af=0.001 \
			--indel_min_af=0.001 \
			--include_all_ctgs \
			--threads=1 \
			--print_ref_calls
		'''
```

My full clair3 log:

> gtollefs@login009 RW-17017-502502-ArtR23RW-1_raw $ more run_clair3.log
[INFO] CLAIR3 VERSION: v1.0.5
[INFO] BAM FILE PATH: /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/mapping/bam_files/RW-17017-502502-ArtR23RW-1.sorted.bam
[INFO] REFERENCE FILE PATH: /nfs/jbailey5/baileyweb/bailey_share/resources/MIP_species_resources/pf/Pf_3D7/genomes/genome.fa
[INFO] MODEL PATH: /opt/models/r941_prom_sup_g5014
[INFO] OUTPUT FOLDER: /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR23RW-1_raw
[INFO] PLATFORM: ont
[INFO] THREADS: 1
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: /users/gtollefs/mambaforge/envs/snakemake
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] PHASING PROPORTION: 0.8
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.001
[INFO] INDEL AF THRESHOLD: 0.001
[INFO] BASE ERROR IN GVCF: 0.001
[INFO] GQ BIN SIZE IN GVCF: 5
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: True
[INFO] ENABLE OUTPUT GVCF: True
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: True
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: True
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE LONGPHASE FOR INTERMEDIATE VCF PHASING: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING WHATSHAP: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING LONGPHASE: False
[INFO] ENABLE HAPLOTAGGING FINAL BAM: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE C_IMPLEMENT: True

> \+ /opt/bin/scripts/clair3_c_impl.sh --bam_fn /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/mapping/bam_files/RW-17017-502502-Ar
> tR23RW-1.sorted.bam --ref_fn /nfs/jbailey5/baileyweb/bailey_share/resources/MIP_species_resources/pf/Pf_3D7/genomes/genome.fa --threads 1 --model_path /opt/models/r941_prom_sup_g5014 --platfor
> m ont --output /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR23RW-1_raw --bed_fn=EMPTY --vc
> f_fn=EMPTY --ctg_name=EMPTY --sample_name=RW-17017-502502-ArtR23RW-1 --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatsha
> p --qual=2 --var_pct_full=0.7 --ref_pct_full=0.1 --var_pct_phasing=0.8 --snp_min_af=0.001 --indel_min_af=0.001 --min_mq=5 --min_coverage=2 --min_contig_size=0 --pileup_only=False --gvcf=True -
> -base_err=0.001 --gq_bin_size=5 --fast_mode=False --call_snp_only=False --print_ref_calls=True --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=True --no_phasing_for_fa=Tru
> e --pileup_model_prefix=pileup --fa_model_prefix=full_alignment --remove_intermediate_dir=False --enable_phasing=False --enable_long_indel=False --keep_iupac_bases=False --use_gpu=False --long
> phase_for_phasing=False --longphase=EMPTY --use_whatshap_for_intermediate_phasing=True --use_longphase_for_intermediate_phasing=False --use_whatshap_for_final_output_phasing=False --use_longph
> ase_for_final_output_phasing=False --use_whatshap_for_final_output_haplotagging=False
> 
> [INFO] Check environment variables
> [INFO] Create folder /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR23RW-1_raw/log
> [INFO] Create folder /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR23RW-1_raw/tmp/pileup_ou
> tput
> [INFO] Create folder /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR23RW-1_raw/tmp/merge_out
> put
> [INFO] Create folder /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR23RW-1_raw/tmp/phase_out
> put
> [INFO] Create folder /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR23RW-1_raw/tmp/gvcf_tmp_
> output
> [INFO] Create folder /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR23RW-1_raw/tmp/full_alig
> nment_output
> [INFO] Create folder /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR23RW-1_raw/tmp/phase_out
> put/phase_vcf
> [INFO] Create folder /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR23RW-1_raw/tmp/phase_out
> put/phase_bam
> [INFO] Create folder /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR23RW-1_raw/tmp/full_alig
> nment_output/candidate_bed
> [INFO] --include_all_ctgs enabled
> [WARNING] Contig name chr1 provided but no mapped reads in BAM, skip!
> [WARNING] Contig name chrP provided but no mapped reads in BAM, skip!
> [INFO] Call variant in contigs: chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chrM
> [INFO] Chunk number for each contig: 1 1 1 1 1 1 1 1 1 1 1 1 1 1
> [INFO] 1/7 Call variants using pileup model
> Died at /opt/conda/envs/clair3/bin/parallel line 9375, <$fh> chunk 1.
> 
> real	0m0.220s
> user	0m0.094s
> sys	0m0.063s
> [WARNING] No vcf file found with prefix:/nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR2
> 3RW-1_raw/tmp/pileup_output/pileup, output empty vcf file
> [WARNING] Copying pileup.vcf.gz to /nfs/jbailey5/baileyweb/gtollefs/mips_to_nanopore_gt/240215_MtoN_P2/second_output_rerun_for_completeness_check/variant_calling/RW-17017-502502-ArtR23RW-1
> _raw/merge_output.vcf.gz
> [INFO] Exit in pileup variant calling
> 
> real	0m2.892s
> user	0m0.684s
> sys	0m0.220s

",gtollefson,https://github.com/HKU-BAL/Clair3/issues/284
I_kwDOFQnk286DbBl0,--qual option not working? ,CLOSED,2024-03-25T05:04:35Z,2024-04-03T05:07:42Z,2024-04-03T05:07:41Z,"Hi, 

I was trying with lower --qual thresholds but the change doesn't seem to be applied? 

My command:
```
run_clair3.sh --bam_fn=${BAM} --ref_fn=${REF} --bed_fn=${BED} --threads=$THREADS --qual='1' --platform='ont' --model_path=${MODEL_PREFIX} --output=${OUTPUT_DIR}
``` 

A line from merge_output.vcf:
```
chr19   85784   .       T       TA      1.57    LowQual F       GT:GQ:DP:AD:AF  0/1:1:138:79,59:0.4275
``` 

Perhaps I am doing something wrongly? Assistance would be appreciated, thanks. ",dehui333,https://github.com/HKU-BAL/Clair3/issues/285
I_kwDOFQnk286DyQsH,Missense variant in FBN2 gene not reported by Clair3,CLOSED,2024-03-27T14:41:04Z,2024-04-02T17:20:32Z,2024-04-02T17:20:32Z,"Hi:
We just ran Clair3 on our first human ONP long-read data. In comparing SNV calls that we identified in the same genome with Illumina short-reads, we found a missense variant that did not make it into the Clair3 vcf file:

>
##fileformat=VCFv4.2
##source=Clair3
##clair3_version=1.0.4
##cmdline=/nas/longleaf/rhel8/apps/clair3/1.0.4/Clair3/run_clair3.sh   --bam_fn=FBA-0005LR_merged.bam --ref_fn=../Homo_sapiens_assembly38.fasta   --threads=40 --platform=ont --model_path=./r1041_e82_400bps_hac_v420   --output=./clair3_results/
##reference=/proj/barc/projects/GENYSIS_Nov2023/FBA-0005LR/../Homo_sapiens_assembly38.fasta
##FILTER=<ID=PASS,Description=""All   filters passed"">
##FILTER=<ID=LowQual,Description=""Low   quality variant"">
##FILTER=<ID=RefCall,Description=""Reference   call"">
##INFO=<ID=P,Number=0,Type=Flag,Description=""Result   from pileup calling"">
##INFO=<ID=F,Number=0,Type=Flag,Description=""Result   from full-alignment calling"">
##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">
##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype   Quality"">
##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate   read depth (reads with MQ<20 or selected by 'samtools view -F 2316' are   filtered)"">
##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic   depths for the ref and alt alleles in the order listed"">
##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized,   Phred-scaled likelihoods for genotypes as defined in the VCF   specification"">
##FORMAT=<ID=AF,Number=1,Type=Float,Description=""Observed   allele frequency in reads, for each ALT allele, in the same order as listed,   or the REF allele for a RefCall"">

Looking at the alignment in IGV, it seems like it should have been called:

![Screenshot 2024-03-27 at 10 27 53 AM](https://github.com/HKU-BAL/Clair3/assets/7256012/ee6c3ff5-1e01-4274-ac7a-3b15de28f474)

Any thoughts on why it is not in the Clair3 output file?
Thanks!",tsneddon,https://github.com/HKU-BAL/Clair3/issues/287
I_kwDOFQnk286D-2ax,Ref/Alt number (AD info),CLOSED,2024-03-28T22:49:33Z,2024-04-07T13:41:27Z,2024-04-07T13:41:27Z,"Hi,

I am confused with the Ref/Alt number in AD field, one example from my Clair3 result is as following:
chr19   3063757 .       G       GTTA    12.62   PASS    F       GT:GQ:DP:AD:AF  1/1:12:10:2,7:0.7000
It shows that there are 2 reads have the reference allele ('G'), 7 reads have the alternative allele ('GTTA'), however, when I check all the reads from my bam file. I found:
<img width=""387"" alt=""image"" src=""https://github.com/HKU-BAL/Clair3/assets/44386140/36e9ec40-2c69-4edb-beb1-58f800a97058"">
There are totally 10 reads, actually 9 reads have alternative allele ('GTTA'). Could you please give me some suggestion? The version of Clair3 I used is v1.0.6. Thanks.

I attached the txt
[testbamfile.txt](https://github.com/HKU-BAL/Clair3/files/14796276/testbamfile.txt)
 file with all the 10 reads. Looking forward to hearing from you.",airichli,https://github.com/HKU-BAL/Clair3/issues/288
I_kwDOFQnk286EY8vr,Calling MNVs,CLOSED,2024-04-02T18:11:22Z,2024-04-04T12:04:01Z,2024-04-04T12:04:00Z,"Hi:
We annotate our short-read FreeBayes generated SNV vcfs with SNPeff.
SNPeff can annotate MNVs.
The default running of clair3 does not call MNVs.
Is there an option to call MNVs with clair3?
Thanks,
Tam",tsneddon,https://github.com/HKU-BAL/Clair3/issues/289
I_kwDOFQnk286EZRwu,ONT R10 Model,CLOSED,2024-04-02T18:58:14Z,2024-04-03T14:57:37Z,2024-04-03T14:57:37Z,"Hi Clair3 team,

Thanks for developing this tool! I am wondering if there is pre-trained model on ONT R10.4.1, of if current ONT model has been tested on R10.4.1 data. 
",HelloYanming,https://github.com/HKU-BAL/Clair3/issues/290
I_kwDOFQnk286Ehawy,Default --qual value?,CLOSED,2024-04-03T16:14:25Z,2024-04-07T13:41:08Z,2024-04-07T13:41:08Z,"Greetings,

I'm running clair3 without using the --qual flag to specify the cutoff. Some of my reported variants have LowQual and couldn't find the default value in the documentation. What Q score does clair3 default to without specifying using the --qual option? 

Thanks",TristanJang,https://github.com/HKU-BAL/Clair3/issues/291
I_kwDOFQnk286FIy5_,Pileup calling fails for downsampled BAMs,CLOSED,2024-04-09T15:08:47Z,2024-04-19T04:34:53Z,2024-04-19T04:34:53Z,"Hello,

I've been having an odd issue when running Clair3 version 1.0.4 on downsampled BAMs. We've been able to run Clair3 just fine on the full minimap2-aligned BAM files for ONT sequencing data. However, when we use `samtools view` (full command below) to downsample the BAMs, we get two main issues when running Clair3.

```
samtools view --subsample 0.11111 --subsample-seed  2708 -b --threads ${SLURM_JOB_CPUS_PER_NODE} --output ${BAMDIR}/${sampleName}_${current_coverage}_${seed}.bam ${BAMDIR}/${BAMFILE}
```

The first issue is that, during step 3, the following error appears in the Clair3 log file:

```[INFO] 3/7 Phase VCF file using Whatshap
This is WhatsHap 1.7 running under Python 3.9.0
[E::vcf_parse_format] Invalid character 'c' in 'AF' FORMAT field at chr4:161631731
ERROR: whatshap error: unable to parse next record
This is WhatsHap 1.7 running under Python 3.9.0
Working on 1 sample from 1 family
```

When I inspect that variant in `pileup.vcf.gz`, using `zcat pileup.vcf.gz | grep -P ""chr4\t161631731""` this is what is returned:

```
chr4	161631731	.	C	T	18.26	PASS	P	GT:GQ:DP:AD:AF	0/1:18:19:8,4:0.2105chr4	162256561	.	T	.	18.07	RefCall	P	GT:GQ:DP:AD:AF	0/0:18:24:21:0.8750
```

Essentially, it appears that a newline character is missing, but this causes Clair3 to fail, with no VCF written past `pileup.vcf.gz`.

The second issue, is that even when downsampled BAMs run through Clair3, there are suspiciously few variants called on chr1. For reference, these are the number of variants on each chromosome in `phased_merge_output.vcf.gz` that was run on the 91X (not downsampled BAM):
```
zcat phased_merge_output.vcf.gz | grep -ve ""^#"" | cut -f1 | sort | uniq -c

 421337 chr1
 263451 chr10
 252921 chr11
 244749 chr12
 202196 chr13
 158896 chr14
 154596 chr15
 158762 chr16
 157615 chr17
 160051 chr18
 114335 chr19
 384804 chr2
 121525 chr20
  78178 chr21
  82399 chr22
 338028 chr3
 353767 chr4
 308948 chr5
 308730 chr6
 294777 chr7
 262141 chr8
 226676 chr9
 138383 chrX
  16041 chrY
```

and for the BAM that was downsampled to 70X coverage:

```
zcat phased_merge_output.vcf.gz | grep -ve ""^#"" | cut -f1 | sort | uniq -c

  33549 chr1
 361352 chr10
 336461 chr11
 332616 chr12
 246947 chr13
 215390 chr14
 212440 chr15
 213311 chr16
 212008 chr17
 206445 chr18
 159123 chr19
 174195 chr2
 185913 chr20
 110666 chr21
 109394 chr22
 295825 chr3
 338105 chr4
 398279 chr5
 389589 chr6
 382903 chr7
 347337 chr8
 317823 chr9
 224857 chrX
  37439 chrY
```

I'm not entirely sure if these errors are connected, but I've been using Clair3 a lot lately, and these issues only ever been a problem when variant calling on these downsampled BAMs.",fgfrost,https://github.com/HKU-BAL/Clair3/issues/293
I_kwDOFQnk286FPd1w,Define temporary directory directly from Clair3 CLI,CLOSED,2024-04-10T11:57:52Z,2024-04-19T04:34:12Z,2024-04-19T04:34:12Z,"Hi,

I have been having issues with running Clair3 v1.0.4 on a HG002 dataset from ONT.
The tool seems to write quite a lot of intermediate files, such as vcf.gz, to the TMP directory which unfortunately doesn't have that much space on our HPC cluster. This results in the final merge.vcf.gz to be incomplete.

[INFO] 1/7 Call variants using pileup model
parallel: Error: Output is incomplete.
parallel: Error: Cannot append to buffer file in /tmp.
parallel: Error: Is the disk full?
parallel: Error: Change $TMPDIR with --tmpdir or use --compress.
Warning: unable to close filehandle properly: No space left on device during global destruction.

I have tried both passing the TMPDIR environment variable to singularity to use with Clair3 and directly defining the parameter --tmpdir to the command, which resulted in an error (I think the --tmpdir parameter comes from a submodule/script within Clair3?). Also trying to bind the /tmp dir to another directory in Singularity didn't work as expected.
```
work_dir=""/mnt/example/GM24385_R103_from_2020/giab_2023.05_SUP""
cd $work_dir

export TMPDIR=$PWD/tmp

mkdir -p HG002/variants_clair3 $PWD/tmp

singularity run -B /mnt --containall clair3_latest.sif /opt/bin/run_clair3.sh \
--bam_fn=PAO89685.pass.cram \
--ref_fn=GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --threads=64 \
--platform=""ont"" \
--model_path=""r1041_e82_400bps_sup_v420"" \
--output=/mnt/example/GM24385_R103_from_2020/giab_2023.05_SUP/HG002/variants_clair3 \
--tmpdir=$PWD/tmp
```


Could someone tell me which parameter or environment variable is required to write the temp files to a directory of choice?

Thanks!",SergeWielhouwer,https://github.com/HKU-BAL/Clair3/issues/294
I_kwDOFQnk286FyV-b,No module named 'libclair3',CLOSED,2024-04-15T20:35:41Z,2024-11-05T05:18:42Z,2024-04-19T04:33:28Z,"I'm testing the workflow proposed by the Cattle Long Read Sequencing Consortium to process long read sequencing data (using minimap and sniffles), which is available online on their GitHub repository: https://github.com/BovLRC/bovLRC-documentation/blob/main/document.md

I tried to use Clair3 to call small variants within individual. To do this, I installed Clair3 according to option 4 in the repository (https://github.com/nanoporetech/Clair3/tree/main?tab=readme-ov-file#option-4-build-an-anaconda-virtual-environment)
But when I call the tool with my test data (https://www.ebi.ac.uk/ena/browser/view/ERX6660198) I receive the following message:

```
> File ""~/Clair3/preprocess/CreateTensorPileupFromCffi.py"", line 10, in <module>
      import libclair3
ModuleNotFoudError: No module named 'libclair3'
```
Any suggestions to fix this?
Thank you for your attention!

",Thaleslsilva,https://github.com/HKU-BAL/Clair3/issues/295
I_kwDOFQnk286F1py4,Clair3 application,CLOSED,2024-04-16T08:20:25Z,2024-04-19T04:33:36Z,2024-04-19T04:33:36Z,"Hello,
I hope that you can help me with this : 
- Can I use Clair3 on my fastq.gz files generated using ONT minion ? 
- Can I use it to detect variants in **oomycetes**?",QuentinPerriere,https://github.com/HKU-BAL/Clair3/issues/296
I_kwDOFQnk286F41yT,empty vcf file,CLOSED,2024-04-16T14:56:01Z,2024-04-19T04:33:39Z,2024-04-19T04:33:39Z,"Hello,

I am currently using the MinION technology from Oxford Nanopore Technologies, and basecalling was performed with Guppy version 3.2.9 or 4.3.4 for all Nanopore runs.

I am trying to use Clair3, but I encountered an issue where the output VCF file is empty. Here is the command I used:

**/opt/conda/envs/clair3/bin/run_clair3.sh --bam_fn /user/data/BAMS_1_pip/file_1.bam --ref_fn /user/data/ref_seq.fa --threads 8 --model_path /opt/conda/envs/clair3/bin/models/ont --platform ont --output /user/data/clair3**

I **suspect the problem may be related to the model_path; I am unsure which model to use.** 
I am working on a **fungus** genome. Any guidance on selecting the appropriate model for my analysis would be greatly appreciated.

",DaliBAmor,https://github.com/HKU-BAL/Clair3/issues/297
I_kwDOFQnk286GQ-Ud," No contig intersection found, output header only in /lab/user/data/test1/clair3/merge_output.vcf.gz",CLOSED,2024-04-19T10:07:43Z,2024-04-24T00:31:47Z,2024-04-24T00:31:47Z,"Hello,
my bam file was generated using minimap2.
As reference I'm using a reference sequence of a particular gene. This gene is expressed in fongus ( not a human chromosome)
I did what you asked me to do in #297 ( I installed clair3 using conda , I activated the env , then I runned the script below)
 
/opt/conda/envs/clair3/bin/run_clair3.sh \
  --bam_fn=""/lab/user/data/test1/BAMS/file_1.sorted.bam"" \
  --ref_fn=""/lab/user/data/test1/demulti/ref_seq_bioedit/ref_bioedit.fa"" \
  --threads=4 \
  --platform=""ont"" \
  --model_path=""/opt/conda/envs/clair3/bin/models/r941_prom_sup_g5014/"" \
  --output=""/lab/user/data/test1/clair3""

_but I'm getting this error :_ 

**[INFO] Check environment variables
[INFO] --include_all_ctgs not enabled, use chr{1..22,X,Y} and {1..22,X,Y} by default
[WARNING] No contig intersection found, output header only in /lab/user/data/test1/clair3/merge_output.vcf.gz
[INFO] Exit in environment checking**


note : I have already used freebayes on the same bam file and I generated multiple variants.
note: my log folder is empty
I hope that you could help me with this !! ",DaliBAmor,https://github.com/HKU-BAL/Clair3/issues/298
I_kwDOFQnk286GTehV,Issues with Variant Detection in ONT Dataset Using Clair3,CLOSED,2024-04-19T15:13:25Z,2024-05-07T08:09:38Z,2024-05-07T08:09:38Z,"Hello,

**I have previously confirmed a SNP at position 1246 using freebayes and IGV on my Oxford Nanopore Technologies (ONT) dataset. Here's how the variant appears in my VCF file:**

gene1	1246	.	G	C	3087.9	.	AB=0.086395;ABP=11853;AC=2;AF=0.333333;AN=6;AO=812;CIGAR=9M1X3M;DP=11815;DPB=10819.4;DPRA=0;EPP=127.779;EPPR=543.768;GTI=2;LEN=1;MEANALT=716.333;MQM=59.9273;MQMR=60;NS=3;NUMALT=1;ODDS=124.895;PAIRED=0;PAIREDR=0;PAO=0;PQA=0;PQR=0;PRO=0;QA=15889;QR=47363;RO=2289;RPL=5;RPP=1723.08;RPPR=4835.51;RPR=807;RUN=1;SAF=299;SAP=125.479;SAR=513;SRF=765;SRP=549.513;SRR=1524;TYPE=snp;technology.Nanopore=1	GT:DP:AD:RO:QR:AO:QA:GL	0/1:3998:817,477:817:17097:477:9526:-467.744,0,-1149.15	0/0:3840:543,123:543:10741:123:2110:0,-10.5991,-776.774	0/1:3977:929,212:929:19525:212:4253:-39.186,0,-1413.72

**I am dealing with three samples. When I used Clair3 on the first and third samples, this variant was missing from my merge_output.vcf, but appeared as a RefCall in pileup.vcf:**

**sample1**
gene1	1246	.	G	.	13.46	RefCall	P	GT:GQ:DP:AD:AF	0/0:13:4922:3318:0.6741

**sample2**
gene2	1246	.	G	.	18.57	RefCall	P	GT:GQ:DP:AD:AF	0/0:18:4926:3871:0.7858

**sample3**

gene3	1246	.	G	.	19.14	RefCall	P	GT:GQ:DP:AD:AF	0/0:19:4928:3977:0.8070

**this is the command that I'm using for each bam file ( I have 3 bams) :** 

/opt/conda/envs/clair3/bin/run_clair3.sh \
  --bam_fn=""/lab/user/data/test1/BAMS/file_1.sorted.bam"" \
  --ref_fn=""/lab/user/data/test1/demulti/ref_seq_bioedit/ref_bioedit.fa"" \
  --threads=4 \
  --platform=""ont"" \
  --model_path=""/opt/conda/envs/clair3/bin/models/r941_prom_sup_g5014/"" \
  --output=""/lab/user/data/test1/clair3_qual_13"" \
  --include_all_ctgs \
  --chunk_size=1000 \
  --min_mq=0 \
  --snp_min_af=0.001 \
  --qual=0 \
  --indel_min_af=0.001 \
  --ref_pct_full=0.05 \
  --var_pct_full=0.05 \
  --min_coverage=0 .

**Is there a specific parameter I should modify or add to ensure all possible variants are generated, even those with very low frequency? I aim to capture as many variants as possible for subsequent filtering. I am working with a diploid organism.

Thank you for your assistance.**
",DaliBAmor,https://github.com/HKU-BAL/Clair3/issues/299
I_kwDOFQnk286GbvFG,training model,CLOSED,2024-04-22T01:49:19Z,2024-05-07T08:09:33Z,2024-05-07T08:09:33Z,"Hi,
Can I train the model myself, or do I need to provide you with data to train the model for me?
Thank you for your response.",Mona3130,https://github.com/HKU-BAL/Clair3/issues/300
I_kwDOFQnk286Gthvb,Split chromosomes for calling variant like gatk.,CLOSED,2024-04-24T01:26:09Z,2024-04-27T08:45:02Z,2024-04-27T08:45:02Z,"Is it possible for Clair3 to use the BAM files split by chromosome for calling variant separately and finally merge the resulting VCF files to reduce the run time?
Or is there any other way to reduce the runtime?",RADIOMUMM,https://github.com/HKU-BAL/Clair3/issues/301
I_kwDOFQnk286HGcSq,Best practices to use different and/or new models for variant calling,CLOSED,2024-04-26T23:17:31Z,2024-04-27T17:37:14Z,2024-04-27T17:37:13Z,"Hello, 
I'm trying to add new models from Rerio to my pipeline using Clair3. I'm currently using the prebuilt docker image and need to use a new model. I've come to the solution of building a new image every time I need to use a new model, but it feels a bit rudimentary if I need to do it every other update. Is there an already existing way to use models from Rerio or other similar packages? Rerio in particular says nothing about how to use its models on Clair3 and just redirects to Dorado, which says nothing about variant calling, and this page also seems to say nothing about using models from outside the prebuilt ones. 

Thanks in advance.",EmilioKolo,https://github.com/HKU-BAL/Clair3/issues/302
I_kwDOFQnk286HGgKH,"The same input bam, fasta and models, but different output size of merge_output.vcf.gz",CLOSED,2024-04-26T23:39:56Z,2024-05-28T01:24:28Z,2024-05-28T01:24:28Z,"Hi, when I use clair3(v1.0.5) to call variants in HG002's PacBio HiFi 15-20kb chemistry2 reads, I typed the run_clair3.sh command twice in the command line, using the same inputs, but the results of merge_output.vcf.gz were of different sizes. Is it right or in other words, this result is caused by the principle and algorithm clair3 used?",Jerry-bioinformatics,https://github.com/HKU-BAL/Clair3/issues/303
I_kwDOFQnk286IXm7p,print_version reports wrong version in 1.0.8,CLOSED,2024-05-09T15:08:43Z,2024-05-28T01:24:20Z,2024-05-28T01:24:20Z,"Clair3 1.0.8 reports itself as v1.0.7 when calling `run_clair3.sh --version`, I think [this line](https://github.com/HKU-BAL/Clair3/blob/main/run_clair3.sh#L4) needs updating.",SamStudio8,https://github.com/HKU-BAL/Clair3/issues/304
I_kwDOFQnk286IYn-Z,Read Depth in VCF,CLOSED,2024-05-09T17:38:14Z,2024-05-28T01:23:44Z,2024-05-28T01:23:44Z,"Hi,
I found a typo in the output VCF that is causing errors when parsing. The AF parameter has NUMBER=1, so it must have exactly 1 entry, but with the recent update of adding af for all alternate alleles, it has more than one value so it should be NUMBER=G I believe.
##FORMAT=<ID=AF,Number=G,Type=Float,Description=""Observed allele frequency in reads, for each ALT allele, in the same order as listed, or the REF allele for a RefCall"">
Also, because we use amplicon sequencing, we have to lower the MQ filter to 0 so having the DP automatically display reads with MQ>20 rather than what was specified in the command may be misleading?
",mproberts99,https://github.com/HKU-BAL/Clair3/issues/305
I_kwDOFQnk286JJBNx,"Inefficient in high-throughput, targeted amplicon use case",CLOSED,2024-05-16T16:25:48Z,2024-07-26T06:45:04Z,2024-07-26T06:45:04Z,"Our use case is variant calling on the output of a targeted amplicon assay on many samples in parallel. The way that `clair3_c_impl.sh` parallelizes the pileup calling step in this case is inefficient. A single process that accumulates all of the candidates across all of the contigs and then does variant calling on them works great, but the best case for the current script is a separate process per contig (if you edit the hard coded max_chunk_size and set the chunk_size to be bigger than any single contig). 

In the current implementation, each process works on a number of candidates far smaller than the networks batch size. This involves a number of threads that are doing nothing or very little which limits the amount of real parallelization we can do in our pipeline before the CPU gets heavily overloaded. The example I have been looking at compares the current implementation vs a single process batching all of the pileup candidates, both using a single thread, and the results are over 12 minutes vs under 2 minutes.

Currently we have a patch that works for us but I'd prefer this use case were officially supported so there's no chance my patch will break on new versions. Two possible solutions are 1) when a bed file is provided, don't use GNU parallel and instead use a single process that accumulates candidates from the bed file regions, or 2) a new flag that bypasses GNU parallel and accumulates candidates across the entire genome. It might be nice in these cases for the user provided number of threads to be used by tensorflow instead.

In general, since the candidate proposal step is so fast compared the network prediction or even process start time, it seems to me like accumulating all of the candidates and then using the available threads for processing those batches would be much more efficient in all cases. This would fully utilize the network batch size where chunking the genome will never give even and consistent batches of candidates. So I wonder if the current parallelization strategy is beneficial over my proposal in any situations.

I'd be happy to start a pull request once I know what you are open to having changed.

Thanks!",Permafacture,https://github.com/HKU-BAL/Clair3/issues/306
I_kwDOFQnk286JOz3a,Link to fa file is broken ,CLOSED,2024-05-17T10:26:45Z,2024-05-28T01:23:59Z,2024-05-28T01:23:59Z,"I am following this documentation - https://github.com/HKU-BAL/Clair3/blob/main/docs/quick_demo/ont_quick_demo.md

Here there is a shell script to download - the fa file mentioned here cannot be downloaded

Link - http://www.bio8.cs.hku.hk/clair3/demo/quick_demo/ont/GRCh38_no_alt_chr20.fa

![image](https://github.com/HKU-BAL/Clair3/assets/84500633/e4355561-3230-4c93-83c6-4dc10b752451)
",v-lakhujani,https://github.com/HKU-BAL/Clair3/issues/307
I_kwDOFQnk286LDjl4,HG003 pacbio CCS hifi data cannot get,CLOSED,2024-06-04T08:59:54Z,2024-06-27T05:09:37Z,2024-06-27T05:09:37Z,"I cannot get the HG003 pacbio CCS hifi data(CCS-15kb Sequel II, chemistry 2.0) from your trainning data.doc file,  I searched for it again from https://nist-midas.s3.amazonaws.com/pdrsrv/mds2-2336/input_fastqs/HG003_35x_PacBio_14kb-15kb.fastq.gz This link does not exist either. Is there a new link for downloading data?",shiying-sxu,https://github.com/HKU-BAL/Clair3/issues/309
I_kwDOFQnk286LsdpI,Using a bam file with haplotag information with Clair3 ,CLOSED,2024-06-10T11:42:57Z,2024-06-27T05:09:33Z,2024-06-27T05:09:33Z,"Dear developers,

I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool.

I was wondering if it is possible to pass Clair3 an already phased file and that Clair3 takes the haplotype/haplotag information with it in the variant calling process?

I saw the --phasing_info_in_bam parameter in the full_alignment_training steps but if i add that to a standard Clair3 run i get an error : `run_clair3.sh: unrecognized option '--phasing_info_in_bam'`

kind regards, 
Ewoud ",eaooms,https://github.com/HKU-BAL/Clair3/issues/310
I_kwDOFQnk286MOGXw,Error merging GVCFs of multiple samples in cDNA sequencing experiment,CLOSED,2024-06-14T04:57:49Z,2024-06-18T08:23:14Z,2024-06-18T08:23:13Z,"Hello Developers,
I am trying to merge gvcfs generated with Clair3 based on reads from a cDNA sequencing experiment involving 10 samples. The details of the workflow so far are as follows:

1. Use Minimap2 to align cDNA reads to a reference (This was done as part of  nf-core/nanoseq pipeline).

2. Generate VCFs and GVCFs for each sample with Clair3 v1.0.8
```
run_clair3.sh \
--bam_fn=${bam_dir}/${sample_name}.sorted.bam \
--ref_fn=${ref} \
--threads=16 \
--platform=${platform} \
--model_path=${model_path} \
--output=${out_dir}/${sample_name} \
--print_ref_calls --gvcf --base_err=0.06 \
--include_all_ctgs \
--no_phasing_for_fa \
--sample_name=${sample_name}
```

3. Sort each GVCF with GATK v4.3.0.0
```
$HOME/.conda/envs/clair3/bin/gatk SortVcf \
-I ${out_dir}/sample_01/merge_output.gvcf.gz \
-O ${out_dir}/sample_01/merge_output.sorted.gvcf.gz
```

4.  Merge sorted GVCFs with GATK v4.3.0.0
```
$HOME/.conda/envs/clair3/bin/gatk CombineGVCFs \
-R ${ref} \
--variant ${out_dir}/sample_01/merge_output.sorted.gvcf.gz \
--variant ${out_dir}/sample_02/merge_output.sorted.gvcf.gz \
.
.
--variant ${out_dir}/sample_09/merge_output.sorted.gvcf.gz \
--variant ${out_dir}/sample_10/merge_output.sorted.gvcf.gz \
-O ${out_dir}/combined.gvcf.gz
```

However, this still raises an error: **The elements of the input Iterators are not sorted according to the comparator htsjdk.variant.variantcontext.VariantContextComparator**

May I also mention that headers of the GVCFs have variable lengths. For example `bcftools view -h ${sample_name}/merge_output.gvcf.gz | wc -l` shows:
sample01: 758
Sample 04: 618
Sample_10: 467

Also, GLNexus fails to merge the GVCFs as well. 

I would greatly appreciate any recommendations or suggestions on this matter. 

Thank you.

",eiwai81,https://github.com/HKU-BAL/Clair3/issues/311
I_kwDOFQnk286MwNqC,It took 10 hrs to call variants against ~40MB reads via Docker Clair3,CLOSED,2024-06-19T06:36:30Z,2024-06-19T10:16:58Z,2024-06-19T10:16:58Z,"Hello,

Thanks a lot for developing this great variant caller Clair3. But I'm facing an issue when calling the variants against a small 2MB bacteria genome.

In particular, I have ONT read data with 40MB base called via Dorado sup mode. I pulled docker image via `docker pull hkubal/clair3`, and I used the model `r1041_e82_400bps_sup_v410` from https://github.com/nanoporetech/rerio/tree/master/clair3_models for Clair3. I used the following command for Clair3.


```sh
        docker run -it --rm \
            -v ${ALN_DIR}:${ALN_DIR} \
            -v ${REF_DIR}:${REF_DIR} \
            -v ${VC_DIR}:${VC_DIR} \
            -v ${MODEL_NAME}:${MODEL_NAME} \
            hkubal/clair3:latest \
            /opt/bin/run_clair3.sh \
            --include_all_ctgs \
            --no_phasing_for_fa \
            --haploid_precise \
            --sample_name=${sample_id} \
            --bam_fn=${ALN_DIR}/${sample_id}.bam \
            --ref_fn=${REF_FILE} \
            --threads=${THREADS} \
            --platform=""ont"" \
            --model_path=""${MODEL_NAME}"" \
            --output=${vcf_dir} \
            1>$LOG_DIR/${sample_id}.clair3.out \
            2>$LOG_DIR/${sample_id}.clair3.err
```

I've got the following logs.

```
[INFO] CLAIR3 VERSION: v1.0.9
[INFO] BAM FILE PATH: /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/Alignment/RB49.bam
[INFO] REFERENCE FILE PATH: /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/reference_RB59.fasta
[INFO] MODEL PATH: /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/clair_models/r1041_e82_400bps_sup_v410
[INFO] OUTPUT FOLDER: /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/VarCall/RB49
[INFO] PLATFORM: ont
[INFO] THREADS: 5
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: 
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] PHASING PROPORTION: 0.7
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.08
[INFO] INDEL AF THRESHOLD: 0.15
[INFO] BASE ERROR IN GVCF: 0.001
[INFO] GQ BIN SIZE IN GVCF: 5
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: True
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: True
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: True
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE LONGPHASE FOR INTERMEDIATE VCF PHASING: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING WHATSHAP: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING LONGPHASE: False
[INFO] ENABLE HAPLOTAGGING FINAL BAM: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE C_IMPLEMENT: True

+ /opt/bin/scripts/clair3_c_impl.sh --bam_fn /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/Alignment/RB49.bam --ref_fn /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/reference_RB59.fasta --threads 5 --model_path /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/clair_models/r1041_e82_400bps_sup_v410 --platform ont --output /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/VarCall/RB49 --bed_fn=EMPTY --vcf_fn=EMPTY --ctg_name=EMPTY --sample_name=RB49 --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=2 --var_pct_full=0.7 --ref_pct_full=0.1 --var_pct_phasing=0.7 --snp_min_af=0.08 --indel_min_af=0.15 --min_mq=5 --min_coverage=2 --min_contig_size=0 --pileup_only=False --gvcf=False --base_err=0.001 --gq_bin_size=5 --fast_mode=False --call_snp_only=False --print_ref_calls=False --haploid_precise=True --haploid_sensitive=False --include_all_ctgs=True --no_phasing_for_fa=True --pileup_model_prefix=pileup --fa_model_prefix=full_alignment --remove_intermediate_dir=False --enable_phasing=False --enable_long_indel=False --keep_iupac_bases=False --use_gpu=False --longphase_for_phasing=False --longphase=EMPTY --use_whatshap_for_intermediate_phasing=True --use_longphase_for_intermediate_phasing=False --use_whatshap_for_final_output_phasing=False --use_longphase_for_final_output_phasing=False --use_whatshap_for_final_output_haplotagging=False

[INFO] Check environment variables
[INFO] Create folder /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/VarCall/RB49/log
[INFO] Create folder /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/VarCall/RB49/tmp/pileup_output
[INFO] Create folder /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/VarCall/RB49/tmp/merge_output
[INFO] Create folder /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/VarCall/RB49/tmp/phase_output
[INFO] Create folder /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/VarCall/RB49/tmp/gvcf_tmp_output
[INFO] Create folder /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/VarCall/RB49/tmp/full_alignment_output
[INFO] Create folder /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/VarCall/RB49/tmp/phase_output/phase_vcf
[INFO] Create folder /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/VarCall/RB49/tmp/phase_output/phase_bam
[INFO] Create folder /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/VarCall/RB49/tmp/full_alignment_output/candidate_bed
Warning: cannot find your CPU L2 cache size in /proc/cpuinfo
[INFO] --include_all_ctgs enabled
[INFO] Call variant in contigs: sample_RB59_2179196
[INFO] Chunk number for each contig: 1
[INFO] 1/7 Call variants using pileup model
Calling variants ...
Total processed positions in sample_RB59_2179196 (chunk 1/1) : 71447
Total time elapsed: 13958.19 s

real	232m46.485s
user	192m1.469s
sys	0m2.607s
Warning: cannot find your CPU L2 cache size in /proc/cpuinfo
[INFO] 2/7 No phasing for full alignment calling

[INFO] 5/7 Select candidates for full-alignment calling
Warning: cannot find your CPU L2 cache size in /proc/cpuinfo
[INFO] Set variants quality cutoff 12.0
[INFO] Set reference calls quality cutoff 14.0
Warning: cannot find your CPU L2 cache size in /proc/cpuinfo
[INFO] Low quality reference calls to be processed in sample_RB59_2179196: 6633
[INFO] Low quality variants to be processed in sample_RB59_2179196: 3535

real	0m1.715s
user	0m1.693s
sys	0m0.099s

[INFO] 6/7 Call low-quality variants using full-alignment model
Calling variants ...
Total processed positions in sample_RB59_2179196 (chunk 2/2) : 168
Total time elapsed: 386.20 s
Calling variants ...
Total processed positions in sample_RB59_2179196 (chunk 1/2) : 10000
Total time elapsed: 22662.64 s

real	377m49.507s
user	382m54.863s
sys	0m4.867s
Warning: cannot find your CPU L2 cache size in /proc/cpuinfo

[INFO] 7/7 Merge pileup VCF and full-alignment VCF
Warning: cannot find your CPU L2 cache size in /proc/cpuinfo
[INFO] Pileup variants processed in sample_RB59_2179196: 1518
[INFO] Full-alignment variants processed in sample_RB59_2179196: 2362

real	0m2.378s
user	0m2.393s
sys	0m0.136s
Warning: cannot find your CPU L2 cache size in /proc/cpuinfo

[INFO] Finish calling, output file: /Users/luorunpeng/Downloads/all-e/Research/project-benjamin_lab/gonorrhoeae/20240418_ACTHealth_gonorrhea/output_clair3/VarCall/RB49/merge_output.vcf.gz

real	610m49.312s
user	575m9.000s
sys	0m8.469s
```

It took nearly 10 hrs to finish the whole execution under MacOS M2 chip, and I can see that the docker is running in full demand but doesn't seem to be paralleled throughout the execution (CPU utilisation is ~100%). Even when I downsample the reads to 1x, it still takes ~1.5hrs to finish the pileup step and stuck at the calling step. Just wondering whether this is normal and if there is any parameters I can use to speed it up, thanks a lot for your help!

John",RunpengLuo,https://github.com/HKU-BAL/Clair3/issues/312
I_kwDOFQnk286NLR7D,Clair3 docker numpy compatibility,CLOSED,2024-06-23T12:43:08Z,2024-07-04T20:22:24Z,2024-07-04T01:18:10Z,"Hello,

I am trying to run clair3 using the docker image running on singularity. I have gotten this to work in the past with no issues, but today when I ran my script (which I did not change since the last successful run some time ago), I am seeing errors with the numpy version being not compatible. Error log is attached below. I am hoping that this bug can be patched soon. Many thanks.

```
+ singularity pull docker://hkubal/clair3:latest
INFO:    Using cached SIF image
+ singularity exec -B /mnt/isilon/xing_lab/aspera/wud3/BDB clair3_latest.sif /opt/bin/run_clair3.sh --bam_fn=/mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332.bam --ref_fn=/mnt/isilon/xing_lab/aspera/wud3/BDB/clair3/inputs/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --threads=18 --platform=ont --model_path=/mnt/isilon/xing_lab/aspera/wud3/BDB/clair3/inputs/rerio/clair3_models/r1041_e82_400bps_sup_v500 --output=/mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output --vcf_fn=/mnt/isilon/xing_lab/aspera/wud3/BDB/clair3/inputs/clair3.vcf
INFO:    Converting SIF file to temporary sandbox...
[INFO] CLAIR3 VERSION: v1.0.9
[INFO] BAM FILE PATH: /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332.bam
[INFO] REFERENCE FILE PATH: /mnt/isilon/xing_lab/aspera/wud3/BDB/clair3/inputs/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna
[INFO] MODEL PATH: /mnt/isilon/xing_lab/aspera/wud3/BDB/clair3/inputs/rerio/clair3_models/r1041_e82_400bps_sup_v500
[INFO] OUTPUT FOLDER: /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output
[INFO] PLATFORM: ont
[INFO] THREADS: 18
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: /mnt/isilon/xing_lab/aspera/wud3/BDB/clair3/inputs/clair3.vcf
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: /home/wud3/anaconda3/envs/main/envs/singularity-env
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] PHASING PROPORTION: 0.7
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.08
[INFO] INDEL AF THRESHOLD: 0.15
[INFO] BASE ERROR IN GVCF: 0.001
[INFO] GQ BIN SIZE IN GVCF: 5
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE LONGPHASE FOR INTERMEDIATE VCF PHASING: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING WHATSHAP: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING LONGPHASE: False
[INFO] ENABLE HAPLOTAGGING FINAL BAM: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE C_IMPLEMENT: True

+ /opt/bin/scripts/clair3_c_impl.sh --bam_fn /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332.bam --ref_fn /mnt/isilon/xing_lab/aspera/wud3/BDB/clair3/inputs/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna --threads 18 --model_path /mnt/isilon/xing_lab/aspera/wud3/BDB/clair3/inputs/rerio/clair3_models/r1041_e82_400bps_sup_v500 --platform ont --output /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output --bed_fn=EMPTY --vcf_fn=/mnt/isilon/xing_lab/aspera/wud3/BDB/clair3/inputs/clair3.vcf --ctg_name=EMPTY --sample_name=SAMPLE --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=2 --var_pct_full=0.7 --ref_pct_full=0.1 --var_pct_phasing=0.7 --snp_min_af=0.0 --indel_min_af=0.0 --min_mq=5 --min_coverage=2 --min_contig_size=0 --pileup_only=False --gvcf=False --base_err=0.001 --gq_bin_size=5 --fast_mode=False --call_snp_only=False --print_ref_calls=False --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=False --no_phasing_for_fa=False --pileup_model_prefix=pileup --fa_model_prefix=full_alignment --remove_intermediate_dir=False --enable_phasing=False --enable_long_indel=False --keep_iupac_bases=False --use_gpu=False --longphase_for_phasing=False --longphase=EMPTY --use_whatshap_for_intermediate_phasing=True --use_longphase_for_intermediate_phasing=False --use_whatshap_for_final_output_phasing=False --use_longphase_for_final_output_phasing=False --use_whatshap_for_final_output_haplotagging=False

[INFO] Check environment variables
[INFO] Create folder /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output/log
[INFO] Create folder /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output/tmp/split_beds
[INFO] Create folder /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output/tmp/pileup_output
[INFO] Create folder /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output/tmp/merge_output
[INFO] Create folder /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output/tmp/phase_output
[INFO] Create folder /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output/tmp/gvcf_tmp_output
[INFO] Create folder /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output/tmp/full_alignment_output
[INFO] Create folder /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output/tmp/phase_output/phase_vcf
[INFO] Create folder /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output/tmp/phase_output/phase_bam
[INFO] Create folder /mnt/isilon/xing_lab/aspera/wud3/BDB/BDB_91_cohort/clair3/BDB_PBMC/1017332/output/tmp/full_alignment_output/candidate_bed
[INFO] --include_all_ctgs not enabled, use chr{1..22,X,Y} and {1..22,X,Y} by default
[INFO] Call variant in contigs: chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY
[INFO] Chunk number for each contig: 50 49 40 39 37 35 32 30 28 27 28 27 23 22 21 19 17 17 12 13 10 11 32 12
[INFO] 1/7 Call variants using pileup model

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.0 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File ""/opt/bin/scripts/../clair3.py"", line 105, in <module>
    main()
  File ""/opt/bin/scripts/../clair3.py"", line 92, in main
    submodule = import_module(""%s.%s"" % (directory, submodule_name))
  File ""/opt/conda/envs/clair3/lib/python3.9/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""/opt/bin/clair3/CallVariantsFromCffi.py"", line 3, in <module>
    import tensorflow as tf
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/tensorflow/__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/tensorflow/python/__init__.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/tensorflow/python/eager/context.py"", line 35, in <module>
    from tensorflow.python.client import pywrap_tf_session
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/tensorflow/python/client/pywrap_tf_session.py"", line 19, in <module>
    from tensorflow.python.client._pywrap_tf_session import *
AttributeError: _ARRAY_API not found

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.0.0 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.
```

",DNA-Dave,https://github.com/HKU-BAL/Clair3/issues/313
I_kwDOFQnk286Nb8DF,Run does not respect AF settings,CLOSED,2024-06-25T14:53:59Z,2024-06-26T09:11:38Z,2024-06-26T09:11:37Z,"Dear Clair3 dev team,

## Background
I am using Clair3 for SNV/indel detection from ONT sequence data. The sequence data is from an amplicon sequencing experiment (high read coverage) of a mixed SARS-CoV-2 sample.

## Clair3 call
```Nextflow
run_clair3.sh \
    --bam_fn=""${bam}"" \
    --bed_fn=""${params.bed}"" \
    --ref_fn=""${params.ref}"" \
    --threads=""${task.cpus}"" \
    --platform=""ont"" \
    --model_path=""${params.model}"" \
    --snp_min_af=0.08 \
    --indel_min_af=0.15 \
    --no_phasing_for_fa \
    --var_pct_full=1 \
    --ref_pct_full=1 \
    --output=""${baseDir}/${params.outdir}""
```

## Issue
The run of Clair3 does not respect the set `snp_min_af` and `indel_min_af`. Does any combination of parameters here interfere or overwrite each other? In the `merge_output.vcf.gz` as well as the `full_alignment.vcf.gz` I see a line 
```
NC_045512.2     22386   .       TTC     T       16.05   PASS    F       GT:GQ:DP:AD:AF  0/1:16:846:634,9:0.0106
```
which should not be present according to the parameters because AF=0.01.

## Expected behavior
I expected to not have any variant records (at least not with a FILTER=PASS) in the VCF files that are of AF lower than 0.08 and 0.15 for SNPs and indels, respectively.

## Additional info
Clair3 version: 1.0.8
Clair3 model: r1041_e82_400bps_hac_g632
OS: Ubuntu 20.04.6 LTS ",Krannich479,https://github.com/HKU-BAL/Clair3/issues/314
I_kwDOFQnk286Ncbv8,Unexpected 0/0 records,CLOSED,2024-06-25T15:51:33Z,2024-06-27T05:09:50Z,2024-06-27T05:09:50Z,"Dear Clair3 dev team,

## Background
I am using Clair3 for SNV/indel detection from ONT sequence data. The sequence data is from an amplicon sequencing experiment (high read coverage) of a mixed SARS-CoV-2 sample.

## Clair3 call
```Nextflow
run_clair3.sh \
    --bam_fn=""${bam}"" \
    --bed_fn=""${params.bed}"" \
    --ref_fn=""${params.ref}"" \
    --threads=""${task.cpus}"" \
    --platform=""ont"" \
    --model_path=""${params.model}"" \
    --snp_min_af=0.08 \
    --indel_min_af=0.15 \
    --no_phasing_for_fa \
    --var_pct_full=1 \
    --ref_pct_full=1 \
    --output=""${baseDir}/${params.outdir}""
```

## Issue
I can identify multiple variant sites in IGV that are missing or 0/0 in the resulting VCF files.
E.g. below, a SNV with ~0.17 ALT-allele ratio and a 9bp indel with ~150/770 reads supporting ALT
![Clair3-issue-IGV](https://github.com/HKU-BAL/Clair3/assets/12402420/cd47214a-4cdb-4aa2-86bc-bfab93e1db17)
The only two variant records of `full_alignment.vcf.gz` in the screenshot region are 
```
NC_045512.2     21618   .       C       .       20.38   RefCall F       GT:GQ:DP:AD:AF  0/0:20:884:692:0.7828
NC_045512.2     21632   .       T       .       9.12    RefCall F       GT:GQ:DP:AD:AF  0/0:9:883:721:0.8165
```
The record at 21618 has a `FILTER=RefCall` but has ~0.22 ALT allele ratio according to the VCF record. Since the `snp_min_af` is 0.08, shouldn't this be some sort of ALT call?

Also, the 21632 position's record is a REF call. With an AF of ~0.19, shouldn't this be some sort of an indel ALT call?

Both records are not within `merge_output.vcf.gz`. I assume only `FILTER=PASS` records are making it to the merged output?

## Expected behavior
According to my Clair3 call I expected SNVs >0.08 AF to be 0/1 or 1/1 and FILTER equal PASS or LowQual. I expected an indel call at 21632.

## Additional info
Clair3 version: 1.0.8
Clair3 model: r1041_e82_400bps_hac_g632
OS: Ubuntu 20.04.6 LTS 

---
Might be related to #314 ",Krannich479,https://github.com/HKU-BAL/Clair3/issues/315
I_kwDOFQnk286Ncirj,Correct variant found by pileup is changed after full alignment,CLOSED,2024-06-25T16:02:32Z,2024-07-23T03:26:28Z,2024-07-23T03:26:27Z,"Hi, 
Thanks for your work with clair3! 

We are running clair3 v1.0.9 via docker and we encountered an expected result that we would like your opinion about. 

We have a previously known and validated variant in EHMT1.

We recently sequenced the same sample with ONT (SUP basecalling, dna_r10.4.1_e8.2_400bps_sup@v5.0.0) and we didn't find this variant in the clair3 merge_output.vcf. We initially suspected something went wrong with the sequencing itself but the variant is clearly visible in the bam. We however realized that the variant is found in the pileup vcf but it's changed into another variant after the full alignment. Below you can see the screenshot of the variant and zooming out a bit more of the region. 
Do you perhaps have any suggestions? 
Thanks in advance! 
Federico 

![image](https://github.com/HKU-BAL/Clair3/assets/58588827/b34d6c33-d44d-4119-9ad0-5f0ffdc6cfd8)

![image](https://github.com/HKU-BAL/Clair3/assets/58588827/bebf3e4a-0dd9-4f76-be13-221f4bf0cca9)
",f-ferraro,https://github.com/HKU-BAL/Clair3/issues/316
I_kwDOFQnk286N7M9a,Clair3 GVCF created file is 1bp of the end sequence so validatevariants fails,CLOSED,2024-06-28T20:10:43Z,2024-07-31T05:43:23Z,2024-07-31T05:43:23Z,"Hi,

Im trying to combine my gvcfs, first using gatks validatevariants but i get the error:

A GVCF must cover the entire region. Found 16 loci with no VariantContext covering it. The first uncovered segment is:Pf3D7_01_v3:640851

Looking at a sample that worked from illumina the bp is always 1 short for each chromosome and 640851 is the end of the chromosome in this case so i think thats the problem.

I used clair3 to get the gvcf using:
barcode=\$(basename ""\$barcode_dir"")
            run_clair3.sh \\
            --bam_fn=barcodes/\$barcode/calls_""\$barcode""_sorted.bam \\
            --ref_fn=${ref_seq} \\
            --threads=${threads} \\
            --platform=""ont"" \\
            --model_path=/mnt/storageG1/data/software/rerio/clair3_models/r1041_e82_${bps}_${type}_v500 \\
            --output=vcf/\$barcode/ \\
            --include_all_ctgs \\
            --gvcf
            
I then used sortvcf from gatk because the variants were all in the wrong order and I was getting this error, hoping it would fix it but alas it did not.
            
Any help with this is greatly appreciated.

Thanks
",JosephThorpe,https://github.com/HKU-BAL/Clair3/issues/317
I_kwDOFQnk286OJ644,"choose pileup call over full-alignment call if pileup call has 1) a way higher QUAL, 2) is an indel",OPEN,2024-07-02T00:35:28Z,2024-12-02T05:37:06Z,,"Hi!

Thanks for making a good tool!

We have been doing testing and benchmarking with (clinical) trio data, and have found a corner case where the behaviour of the merge between the pileup calls and the full alignment call results in a real variant being discarded.

The pileup VCF file contains the row

```
chr12   132836482   .   A   ACTCACAGTGACAGGCTCCCAGCAGGGCGCACGGCACTCACAGTGACAGGCTCCCAGCACGGCGCACGGCACTCACAGTGACAGGCTCCCAGCACGGCGCTCGGCC  28.66   PASS    P   GT:GQ:DP:AD:AF:PL   1/1:28:32:3,29:0.9062:56,48,0
```

And the full alignment has the row

```
chr12   132836482   .   A   .   0.00    RefCall F   GT:GQ:DP:AD:AF:PL   0/0:0:32:3:0.0938:990
```

The VCF produced by `MergeVcf` outputs the `RefCall`, which causes the insertion to be dropped.

It's a bit of a corner case, since the position of insertion variants in a VCF is the base before the inserted sequence, and that *is* ref, but in this case, we do want to report the insertion!

I don't fully understand how the positions of the `RefCall` variants are determined, so I can't tell if this is a freak event, or if there is a systematic process that means these collisions are likely to occur elsewhere. If you could explain how these `RefCall` events are generated, that would help us understand how the caller works.

Looking at the code of `MergeVcf` (e.g. https://github.com/HKU-BAL/Clair3/blob/b975475a24eae2dc564acc5d4788d99599d83feb/preprocess/MergeVcf.py#L191 and https://github.com/HKU-BAL/Clair3/blob/b975475a24eae2dc564acc5d4788d99599d83feb/preprocess/MergeVcf.py#L228), I think I understand how the merge code is dropping the insertion event. I can think of a few possible ways to fix the code, but I haven't thought through all the semantics in detail, to work out what the best way to fix the code would be.

Again, thanks for making a good tool, and I hope this report helps you make it even better.

Tom.",drtconway,https://github.com/HKU-BAL/Clair3/issues/318
I_kwDOFQnk286OqlDr,[ERROR] Model path not found,CLOSED,2024-07-06T11:27:10Z,2024-09-02T02:24:18Z,2024-07-23T03:11:51Z,"Hi，
I have used Rerio to download the models for R10.4.1 data and I run :
run_clair3.sh 
--bam_fn=../LR1D.sort.bam 
--ref_fn=/share/home/yzwl_hanxs/basecalling/referenceGene/Sus_scrofa.Sscrofa11.1.dna_sm.toplevel.fa 
--threads=4 --platform='ont' 
--model_path='/share/home/yzwl_hanxs/app/rerio/clair3_models/r1041_e82_400bps_sup_g615_model' 
--output=/share/home/yzwl_hanxs/company-third/LR1D/bam/SNP
And then the error was reported：
[INFO] CLAIR3 VERSION: v1.0.8
[INFO] BAM FILE PATH: /share/home/yzwl_hanxs/company-third/LR1D/bam/SNP/../LR1D.sort.bam
[INFO] REFERENCE FILE PATH: /share/home/yzwl_hanxs/basecalling/referenceGene/Sus_scrofa.Sscrofa11.1.dna_sm.toplevel.fa
[INFO] MODEL PATH: /share/home/yzwl_hanxs/app/rerio/clair3_models/r1041_e82_400bps_sup_g615_model
[INFO] OUTPUT FOLDER: /share/home/yzwl_hanxs/company-third/LR1D/bam/SNP
[INFO] PLATFORM: ont
[INFO] THREADS: 4
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: /share/home/yzwl_hanxs/anaconda3/envs/clair3
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.7
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.1
[INFO] PHASING PROPORTION: 0.7
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.08
[INFO] INDEL AF THRESHOLD: 0.15
[INFO] BASE ERROR IN GVCF: 0.001
[INFO] GQ BIN SIZE IN GVCF: 5
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE LONGPHASE FOR INTERMEDIATE VCF PHASING: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING WHATSHAP: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING LONGPHASE: False
[INFO] ENABLE HAPLOTAGGING FINAL BAM: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE C_IMPLEMENT: True

ESC[31m[ERROR] Model path not foundESC[0m

and then I checked this :
![1720265139733](https://github.com/HKU-BAL/Clair3/assets/145557567/71ba7c9f-674e-4eeb-8d13-526417ea7b7b)
Why does this happen
Any help to overcome this is appreciated!

Best",Wshengquan,https://github.com/HKU-BAL/Clair3/issues/319
I_kwDOFQnk286PWtm0,show more allele counts in INFO,OPEN,2024-07-12T09:00:26Z,2024-07-23T03:12:49Z,,"I have enjoyed using Clair3 (clair3-arm64) for examining natural variants at the whole-genome level. However, I've recently noticed some irregularities that likely need correction.

Specifically, I have observed a large number of variants that Clair3 could recognize as variants with GT=1/1 and AF=1 but does not. Instead, these variants are labeled (in my opinion, mislabeled) as either RefCalls with AF=0 or variants with GT=0/1 and AF=1.

I have examined 15 Illumina samples aligned with bwa-mem. The number of RefCalls with AF=0 ranges from over 100 to over 7000, along with smaller numbers of called variants with GT=0/1 and AF=1. When examining these using IGV, they typically appear as 100% mutant (ALT).

Additionally, RefCalls with very low AF values above 0 should probably be labeled as variants as well.",hoyonh,https://github.com/HKU-BAL/Clair3/issues/320
I_kwDOFQnk286P2KAv,upgrading longphase to 1.7.3,CLOSED,2024-07-17T11:18:28Z,2024-07-31T05:43:56Z,2024-07-31T05:43:56Z,"There is a bug in longphase 1.7 that causes an error on reading FASTA files.  For example:

```reading reference ... [E::fai_load3_core] Failed to open FASTA file```

This has been fixed in longphase 1.7.3:

[https://github.com/twolinin/longphase/issues/74](url)

Please can you update longphase in Clair3?  We are using ClairS but presumably if fixed in Clair3 it will be picked up in the conda clair3-illumina package used by ClairS?",signalbox2,https://github.com/HKU-BAL/Clair3/issues/321
I_kwDOFQnk286QJWi8,Clair3 with T2T aligned reads,CLOSED,2024-07-19T08:34:49Z,2024-07-28T15:16:20Z,2024-07-28T15:16:20Z,"Hi,
I'm having problems getting clair3 to call variants in T2T that it will call in Hg38, done alot of troubleshooting and the variants are called in the merge_output.vcf but not the full_alignment... in fact in full_alignment it is making strange calls and missing all obvious SNVs.
Dave",DHmeduni,https://github.com/HKU-BAL/Clair3/issues/322
I_kwDOFQnk286QhnYS,Which model?,CLOSED,2024-07-23T09:36:14Z,2024-08-14T20:40:20Z,2024-07-31T05:44:24Z,"Hi all, I don't know if this is the correct section (first time posting on github, sorry!) but I would like to do a variant call analysis, I have 3 DNA samples sequenced with ONT platform with an old model r9.4.1_e8_sup@v3.3 and I was wondering which model should or could I use? 

Thanks in advance 🙏🏼 ",ascialla,https://github.com/HKU-BAL/Clair3/issues/323
I_kwDOFQnk286QjJbq,descriptions of outputs available?,CLOSED,2024-07-23T12:47:32Z,2024-07-31T05:44:19Z,2024-07-31T05:44:19Z,"Is there a description of the output files and how to interpret them available anywhere?

I was able to successfully run a test of Clair3 on ONT data and I am trying to interpret the outputs.",osvatic,https://github.com/HKU-BAL/Clair3/issues/324
I_kwDOFQnk286QjRGE,Exit in environment checking,CLOSED,2024-07-23T13:01:57Z,2024-07-28T15:16:04Z,2024-07-28T15:16:04Z,"Hello,
I encountered an issue while running Clair3. Could you please advise me on how to resolve this problem?

[INFO] Check environment variables
[INFO] Create folder /opt/synData2/2024/kazak_sheep/SNP/BH2/log
[INFO] Create folder /opt/synData2/2024/kazak_sheep/SNP/BH2/tmp/pileup_output
[INFO] Create folder /opt/synData2/2024/kazak_sheep/SNP/BH2/tmp/merge_output
[INFO] Create folder /opt/synData2/2024/kazak_sheep/SNP/BH2/tmp/phase_output
[INFO] Create folder /opt/synData2/2024/kazak_sheep/SNP/BH2/tmp/gvcf_tmp_output
[INFO] Create folder /opt/synData2/2024/kazak_sheep/SNP/BH2/tmp/full_alignment_output
[INFO] Create folder /opt/synData2/2024/kazak_sheep/SNP/BH2/tmp/phase_output/phase_vcf
[INFO] Create folder /opt/synData2/2024/kazak_sheep/SNP/BH2/tmp/phase_output/phase_bam
[INFO] Create folder /opt/synData2/2024/kazak_sheep/SNP/BH2/tmp/full_alignment_output/candidate_bed
[INFO] --include_all_ctgs not enabled, use chr{1..22,X,Y} and {1..22,X,Y} by default
[WARNING] No contig intersection found, output header only in /opt/synData2/2024/kazak_sheep/SNP/BH2/merge_output.vcf.gz
[INFO] Exit in environment checking
",xiaolongliang,https://github.com/HKU-BAL/Clair3/issues/325
I_kwDOFQnk286Qo2T1,REF=TGTGB,CLOSED,2024-07-24T05:25:53Z,2024-08-02T03:31:05Z,2024-07-31T05:44:12Z,"Hello,

I hope you're doing well. Thank you for developing this tool! 😊

There is an unknown locus at `(hg38) chr3:16,902,859-16,902,898` labeled as `TGTGN`, which I've highlighted in yellow in the attached IGV and UCSC screenshots.

<img width=""1325"" alt=""Figure1"" src=""https://github.com/user-attachments/assets/0610418d-5d8d-4652-8001-9b3af8044aeb"">

![Figure2](https://github.com/user-attachments/assets/d6245e54-3475-4cfa-80fb-4a7986a7dc04)

Clair3 has identified this site in the REF field as `TGTGB`:
```
gunzip -c tumor.clair3.vcf.gz | grep TGTGB
chr3	16902879	.	TGTGB	T	25.68	PASS	P	GT:GQ:DP:AD:AF	1/1:25:25:2,22:0.88
``` 

`TGTGB` has caused the following error when I tried to load the VCF file into IGV: 
```
Error loading features for interval: chr3:16902858-16902898 htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 215: unparsable vcf record with allele TGTGB
```

When I tested with TGTGN, the file loaded successfully.

I just wanted to bring this to your attention.

Many thanks,
Min
",minw2828,https://github.com/HKU-BAL/Clair3/issues/326
I_kwDOFQnk286RYrby,minor bug with conda install `import: command not found`,CLOSED,2024-07-31T05:32:44Z,2024-11-15T01:31:56Z,2024-11-15T01:31:56Z,"Hi developers, 

Thanks for the great tool - very fast and accurate!

I installed clair3 via option 3 Bioconda. Linux system with GPU available Ubuntu 20.04

I ran Clair3 as follows:

```
run_clair3.sh \
    --bam_fn=""$aln"" \
    --ref_fn=""$ref"" \
    --threads=24 \
    --platform=""ont"" \
    --model_path=""$model_path"" \
    --output=""$outdir"" \
    --sample_name=""$sample"" \
    --include_all_ctgs \
    --haploid_precise \
    --no_phasing_for_fa \
    --enable_long_indel
```

with relevant correct variables. There was an error:

```
/home/user/miniforge3/envs/clair3/bin/clair3.py: line 1: import: command not found
from: can't read /var/mail/importlib
from: can't read /var/mail/shared.param_p
```

Solved by adding a shebang:

`#!/usr/bin/env python3` to the file `/home/user/miniforge3/envs/clair3/bin/clair3.py`

George",gbouras13,https://github.com/HKU-BAL/Clair3/issues/327
I_kwDOFQnk286RqeVg,erro corrected reads,CLOSED,2024-08-02T02:04:42Z,2024-08-13T15:14:24Z,2024-08-13T15:14:23Z,"Hi developers,

Thanks for the great tool!

I correct ",KANGYUlab,https://github.com/HKU-BAL/Clair3/issues/328
I_kwDOFQnk286Rqfg7,Using HERRO corrected reads in Clair3,CLOSED,2024-08-02T02:07:06Z,2024-08-28T05:23:54Z,2024-08-28T05:23:54Z,"Hi developers,

Thanks for the great tool!

Does Clair3 work with herro-corrected ONT reads? If so, what model should be used?

Thanks.
 ",KANGYUlab,https://github.com/HKU-BAL/Clair3/issues/329
I_kwDOFQnk286R8WnO,Broken pipe error,CLOSED,2024-08-05T13:06:37Z,2024-08-28T05:23:02Z,2024-08-28T05:23:02Z,"I installed Clair3 using the bioconda and anaconda (once each) and get a broken pipe error when running this following command on data.

```
Clair3/run_clair3.sh --bam_fn=$DIR/10N.286.55.E8_N03_JMF-2403-01-0004A.mapped.sorted.bam --ref_fn=$DIR/../../genomes/10N.286.55.E8_N03.fa --threads=8 --platform=ilmn --model_path=Clair3/models/ilmn/ --output=$DIR/${f%%.bam}_CLAIR3 --no_phasing_for_fa --haploid_precise --include_all_ctgs
```
I am using an illumina dataset that was aligned to the reference and sorted before running the command. 

Is there a clear reason that this isn't working?

[run_clair3.log](https://github.com/user-attachments/files/16496076/run_clair3.log)
",osvatic,https://github.com/HKU-BAL/Clair3/issues/330
I_kwDOFQnk286R9meG,Clair3 with polyploids,CLOSED,2024-08-05T15:29:24Z,2024-08-28T05:23:20Z,2024-08-28T05:23:20Z,"Hello,

Thank you very much for the development of this tool!
I saw in the README that it is possible to call variants in non-diploid organisms. 
Is this meant for polyploid genomes? And in what way does it differ with the diploid variant calling? I do not seem to find anything about it in the publication and I would like to use Clair3 for tetraploid data. Many thanks in advance.",ewoutcrombez,https://github.com/HKU-BAL/Clair3/issues/331
I_kwDOFQnk286SOpVh,Very slow processing of low-quality chrX variants with full-alignment model,CLOSED,2024-08-07T12:02:47Z,2024-08-28T05:18:42Z,2024-08-28T05:18:42Z,"Greetings, I have been using the Clair3 docker image for months, and i never ran into the issue of the models being stuck or performing too slow while processing a chunk, but this week while trying to rerun a dataset, the full alignment model seemed to be very slow when it starts on low quality chromosomes, it ran for 4 days and seemed to be nowhere near finishing, each chunk took about more than 90 minutes to finish.

I terminated the job because something seemed abnormal, and when i re-ran it, the slow processing started only at chromosome X chunks.

I do not really know what seems to be causing this strange performance, it is to note that i purged all of my unused docker containers at the beginning of the week because they were taking about half of my space, could that be the issue? Or is it something do with the model or sample itself?

Commnad:
**docker run -v $(pwd):$(pwd) -w $(pwd)  hkubal/clair3:latest   /opt/bin/run_clair3.sh   --bam_fn mapped.bam --ref_fn GRCh38_full_analysis_set_plus_decoy_hla.fa --threads 16 --model_path /opt/models/ont --platform ont --output Clair3/**",esraaelmligy,https://github.com/HKU-BAL/Clair3/issues/332
I_kwDOFQnk286SrIaf,No vcf output from clair3 run,CLOSED,2024-08-12T11:48:29Z,2024-08-13T11:04:18Z,2024-08-13T11:04:17Z,"I have setup clair3 to run via docker and while the output from the command shows processing happening, no output file is written.  The BAM file  I'm using was created by aligning illumina short reads against a reference fasta file.

Here is my script to run clair3 via docker:

```
INPUT_DIR=/workdir/lcj34/phg_v2/clair3/p39top39BamFastas
OUTPUT_DIR=/workdir/lcj34/phg_v2/clair3/p39top39_clair3Output
THREADS=""10""

docker1 run \
        -v ${INPUT_DIR}/:/input/ \
        -v ${OUTPUT_DIR}/:/output/ \
        hkubal/clair3:latest \
        /opt/bin/run_clair3.sh \
        --ref_fn=/input/P39.fa \
        --bam_fn=/input/P39toP39MergedBams.sorted.bam \
        --ctg_name=""chr9"" \
        --output=${OUTPUT_DIR} \
        --platform=""ilmn"" \
        --model_path=""/opt/models/ilmn"" \
        --threads=${THREADS}
```
I""ve attached the output file from the run.  I don't see any errors and it appears to be processing the data.  At the end it says ""Finished calling, output file: ..."" What would prevent the vcf file from being created ?  I ran this twice with the same result.  

[clair3p39top39_output.txt](https://github.com/user-attachments/files/16581083/clair3p39top39_output.txt)
",lynnjo,https://github.com/HKU-BAL/Clair3/issues/333
I_kwDOFQnk286UNpeL,Missing calls with --min_coverage=1,CLOSED,2024-08-26T11:14:32Z,2024-08-28T08:22:32Z,2024-08-28T05:14:35Z,"Hello,

I have a specific use case where I need to call variants even if the position is covered by only one read. However, setting --min_coverage=1 doesn't seem to lower the limit below the default, as only positions covered by at least two reads are reported.

Is there any way to configure Clair for this purpose?

Best regards,
Piotr
",gc-content,https://github.com/HKU-BAL/Clair3/issues/334
I_kwDOFQnk286UY2aC,Not detecting variants below 10% and incorrect allele frequencies,CLOSED,2024-08-27T14:26:31Z,2024-10-14T10:34:05Z,2024-10-14T10:34:05Z,"Hello, 

I have tested dozens of samples and keep running into the same issues. First, despite --snp_min_af=0.0, clair3 has yet to call any variant below ten percent. Secondly, for the variants it does call, the allele frequency does not equate to sample.dp/mapped reads. For instance, in my clair3 output, sample.dp will be 9825 and total mapped reads will be 9833, yet the allele frequency is 0.7318 instead of 9825/9833 = 0.999186. Additionally, when working with dorado base calling hac and fast models, it generates multiple variants that do not exist whatsoever (these is more common with indels than SNPs) when I check the bam files (this issue is resolved when changing to sup model in dorado base calling). I've also ran the same data on different variant callers that report other mutations that do exist in bams where allele frequency was as high as 25% and as low as 4%. 

Here is the general command I have been running to get these issues: 
 run_clair3.sh --bam_fn=$BAM --ref_fn=$REF --threads=4 --qual=0 --platform=""ont"" --model_path=/path_to_models/r941_prom_sup_g5014 --output=./clairout/ --bed_fn=$BED --snp_min_af=0.0 --haploid_sensitive --chunk_size=5000 

I have tried guppy, dorado (fast, hac, and sup were all tested) for base calling to determine if there was issues with the data. From all of these base calling methods, only variants that are basically unanimously found across all reads are consistently called by clair3. I am running clair3 from a conda install. 

Thanks, 
Daisy 
























































",daysmcgrath,https://github.com/HKU-BAL/Clair3/issues/335
I_kwDOFQnk286U6xTz,malformed metadata and header in temporary vcfs when running clair3 with whatshap phase with large bam file ,CLOSED,2024-08-30T23:44:05Z,2024-10-14T10:35:37Z,2024-10-14T10:35:37Z,"I'm running clair3 with the --use_whatshap_for_final_output_haplotagging option (see clair3 command at bottom) on a 1.1TB bam generated on the ONT platform (basecalling and alignment with dorado/minimap2) and the final output bam is missing haplotype info. On step 7/7 ""Phasing VCF output in parallel using WhatsHap"" whatshap throws parse and invalid contig errors that indicate it is trying to read a ##cmdline comment in the vcf as a contig:

```
[INFO] 7/7 Phasing VCF output in parallel using WhatsHap
This is WhatsHap 1.7 running under Python 3.9.0
[W::vcf_parse] Contig '##cmdline=/path/to/mambaforge/envs/clair3/bin/run_clair3.sh --bam_fn=/path/to/input.bam --ref_fn=/path/to/ref_files/hg38/no_chr/Homo_sapiens.GRCh38.dna.primary_assembly.fa --model_path=/path/to/mambaforge/envs/clair3/bin/models/r941_prom_hac_g360+g422 --output=/path/to/clair3_output --threads=8 --platform=ont --snp_min_af=0.3 --min_coverage=10 --use_whatshap_for_final_output_haplotagging --call_snp_only' is not defined in the header. (Quick workaround: index the file with tabix.)
[W::bcf_hrec_check] Invalid contig name: ""##cmdline=/path/to/mambaforge/envs/clair3/bin/run_clair3.sh --bam_fn ....
```
After checking input vcf used for this step (called ""merge_1.vcf""), I found what appears to be a malformed vcf metadata where there is a ""##cmdline"" entry AFTER the field header line, #CHROM  POS ... etc., like so: 

```
##fileformat=VCFv4.2
##source=Clair3
##clair3_version=1.0.10
##cmdline=/mambaforge/envs/clair3/bin/run_clair3.sh --bam_fn=input.bam --ref_fn=/ref_files/hg38/no_chr/Homo_sapiens.GRCh38.dna.primary_assembly.fa --model_path=mambaforge/envs/clair3/bin/models/r941_prom_hac_g360+g422 --output=/clair3_output --threads=8 --platform=ont --snp_min_af=0.3 --min_coverage=10 --use_whatshap_for_final_output_haplotagging --call_snp_only
...
##contig=<ID=KI270419.1,length=1029>
##contig=<ID=KI270336.1,length=1026>
##contig=<ID=KI270312.1,length=998>
##contig=<ID=KI270539.1,length=993>
##contig=<ID=KI270385.1,length=990>
##contig=<ID=KI270423.1,length=981>
##contig=<ID=KI270392.1,length=971>
##contig=<ID=KI270394.1,length=970>
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  SAMPLE
##cmdline=/mambaforge/envs/clair3/bin/run_clair3.sh --bam_fn=input.bam --ref_fn=/ref_files/hg38/no_chr/Homo_sapiens.GRCh38.dna.primary_assembly.fa --model_path=mambaforge/envs/clair3/bin/models/r941_prom_hac_g360+g422 --output=/clair3_output --threads=8 --platform=ont --snp_min_af=0.3 --min_coverage=10 --use_whatshap_for_final_output_haplotagging --call_snp_only
1       10108   .       C       CT      10.79   PASS    F       GT:GQ:DP:AD:AF  1/1:10:245:89,86:0.3510
1       10321   .       C       T       5.62    PASS    F       GT:GQ:DP:AD:AF  0/1:5:310:122,131:0.4226
1       10622   .       T       G       22.59   PASS    P       GT:GQ:DP:AD:AF  1/1:22:378:10,289:0.7646
```

I'm not sure what is causing this but my hacky fix was to remove that line from the temporary vcfs (merge_{n}.vcf) and rerun clair3_c_impl.sh from the `whatshap phase` step... I removed the incorrectly placed vcf lines with this grep command (ran in the tmp/merged_output/ directory), although now the metadata will be missing the command line record (oh well):
`for i in merge_*.vcf; do mv $i $i.tmp; cat $i.tmp | grep -v ""##cmdline"" > $i; done`

Thanks,
Chris


Original Clair3 command line:
```
run_clair3.sh --bam_fn=input.bam --ref_fn=path_to/ref_files/hg38/no_chr/Homo_sapiens.GRCh38.dna.primary_a
ssembly.fa --threads=8 --platform=ont --snp_min_af=0.3 --indel_min_af=0.3 --model_path=path_to/mambaforge/envs/clair
3/bin/models/r941_prom_hac_g360+g422 --output=path_to/clair3_output --use_what
shap_for_final_output_haplotagging
```",blackbeerd,https://github.com/HKU-BAL/Clair3/issues/336
I_kwDOFQnk286VzyEe,Updated models,CLOSED,2024-09-09T09:06:20Z,2024-10-14T10:35:21Z,2024-10-14T10:35:21Z,"Hello and thanks for this tool.

I am trying to install it via option 4 (Build an anaconda virtual environment)

Will I get updated version that way?

I already see that the model repo refereed there is not updated (no R10 models)

Does anyone know where can I find a link to the updated model repo?

Kind regards
Assaf",assafgrw,https://github.com/HKU-BAL/Clair3/issues/337
I_kwDOFQnk286ZNBMa,Mito variant calling,CLOSED,2024-10-07T12:40:03Z,2024-10-14T10:35:12Z,2024-10-14T10:35:12Z,"Hello,

for our samples we would like to call also variants on chrM. Would you recommend to simply add the region to the target region, or to do a separate calling with adjusted parameters (and if so, which settings do you recommend)?
(On the short-read data we do mito calling in an extra step with adjusted parameters ( no_ploidy, ...) and merge the files afterwards.) 

Best,
Leon
",leonschuetz,https://github.com/HKU-BAL/Clair3/issues/338
I_kwDOFQnk286Zhf14,Which model should I use for R9.4.1 data basecalled with dorado,CLOSED,2024-10-09T11:48:54Z,2024-10-30T03:41:32Z,2024-10-30T03:41:32Z,I have R9.4.1 data basecalled with dorado (HAC). What is the most suitable model to use? ,eesiribloom,https://github.com/HKU-BAL/Clair3/issues/339
I_kwDOFQnk286aCNqm,"Variant calling in mito: No vcf file found, output empty vcf file",CLOSED,2024-10-13T21:00:43Z,2024-10-14T03:24:22Z,2024-10-14T03:24:22Z,"Hello developers!

Thank you for your work

I am trying to do a variant calling for mitochondria. I am using Clair3 v1.0.10 from conda on Linux. 
This is the command:

```
run_clair3.sh --bam_fn=""$BAM"" --ref_fn=""$REF"" --threads=32 --platform=""ont"" --ctg_name=""NC_012920.1"" --chunk_num=-1  --model_path=""/home/jjpiconc/biocomp_tools/rerio/clair3_models/r1041_e82_400bps_sup_v500"" --haploid_sensitive --output=""$WD_DIR/VariantCall/clair3/""
```

but the code returns:
```
[INFO] Call variant in contigs: NC_012920.1
[INFO] No genome chunking due to chunk_num == -1
[INFO] 1/7 Call variants using pileup model
Calling variants ...
Total processed positions in None : 1
Total time elapsed: 4.40 s

real	0m7.115s
user	0m6.260s
sys	0m0.525s
[WARNING] No vcf file found, output empty vcf file
[WARNING] Copying pileup.vcf.gz to /home/jjpiconc/COL-HUMAN-PROJECT/MT/VariantCall/clair3/merge_output.vcf.gz
[INFO] Exit in pileup variant calling

real	0m7.999s
user	0m6.777s
sys	0m0.669s
```
What might be happening?

I hope you can help me,

Thank you very much,
Juan",juanjo255,https://github.com/HKU-BAL/Clair3/issues/340
I_kwDOFQnk286bdqcj,Segmentation fault in full_alignment,CLOSED,2024-10-23T11:28:00Z,2024-11-15T01:31:07Z,2024-11-15T01:31:07Z,"Hey there, I am running the containerised version of clair3 with 32GB of mem. Its running on a small viral genome so shouldnt be too taxing. The seg fault happens and then the merged vcf is just the pileup vcf instead of the true merged. Any ideas?

```[INFO] CLAIR3 VERSION: v1.0.10
[INFO] BAM FILE PATH: /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/FAY66992_BC23.primertrimmed.rg.sorted.bam
[INFO] REFERENCE FILE PATH: /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/SARS-CoV-2.fasta
[INFO] MODEL PATH: /opt/models/r941_prom_hac_g360+g422
[INFO] OUTPUT FOLDER: /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/.
[INFO] PLATFORM: ont
[INFO] THREADS: 10
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: 
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 800
[INFO] FULL ALIGN PROPORTION: 1.0
[INFO] FULL ALIGN REFERENCE PROPORTION: 1.0
[INFO] PHASING PROPORTION: 0.7
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.08
[INFO] INDEL AF THRESHOLD: 0.15
[INFO] BASE ERROR IN GVCF: 0.001
[INFO] GQ BIN SIZE IN GVCF: 5
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: True
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: True
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: True
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE LONGPHASE FOR INTERMEDIATE VCF PHASING: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING WHATSHAP: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING LONGPHASE: False
[INFO] ENABLE HAPLOTAGGING FINAL BAM: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE C_IMPLEMENT: True

[33m[WARNING] Threads setting exceeds maximum available threads 4, set threads=4[0m
+ /opt/bin/scripts/clair3_c_impl.sh --bam_fn /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/FAY66992_BC23.primertrimmed.rg.sorted.bam --ref_fn /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/SARS-CoV-2.fasta --threads 4 --model_path /opt/models/r941_prom_hac_g360+g422 --platform ont --output /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/. --bed_fn=EMPTY --vcf_fn=EMPTY --ctg_name=EMPTY --sample_name=FAY66992_BC23 --chunk_num=0 --chunk_size=800 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=2 --var_pct_full=1.0 --ref_pct_full=1.0 --var_pct_phasing=0.7 --snp_min_af=0.08 --indel_min_af=0.15 --min_mq=5 --min_coverage=2 --min_contig_size=0 --pileup_only=False --gvcf=False --base_err=0.001 --gq_bin_size=5 --fast_mode=False --call_snp_only=False --print_ref_calls=False --haploid_precise=True --haploid_sensitive=False --include_all_ctgs=True --no_phasing_for_fa=True --pileup_model_prefix=pileup --fa_model_prefix=full_alignment --remove_intermediate_dir=False --enable_phasing=False --enable_long_indel=False --keep_iupac_bases=False --use_gpu=False --longphase_for_phasing=False --longphase=EMPTY --use_whatshap_for_intermediate_phasing=True --use_longphase_for_intermediate_phasing=False --use_whatshap_for_final_output_phasing=False --use_longphase_for_final_output_phasing=False --use_whatshap_for_final_output_haplotagging=False

[INFO] Check environment variables
[INFO] Create folder /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/log
[INFO] Create folder /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/tmp/pileup_output
[INFO] Create folder /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/tmp/merge_output
[INFO] Create folder /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/tmp/phase_output
[INFO] Create folder /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/tmp/gvcf_tmp_output
[INFO] Create folder /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/tmp/full_alignment_output
[INFO] Create folder /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/tmp/phase_output/phase_vcf
[INFO] Create folder /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/tmp/phase_output/phase_bam
[INFO] Create folder /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/tmp/full_alignment_output/candidate_bed
Warning: cannot find your CPU L2 cache size in /proc/cpuinfo
[INFO] --include_all_ctgs enabled
[93m[WARNING] For efficiency, we use a maximum 30% reference candidates for full-alignment calling[0m
[INFO] Call variant in contigs: NC_045512.2
[INFO] Chunk number for each contig: 38
[INFO] 1/7 Call variants using pileup model
Calling variants ...
Total processed positions in NC_045512.2 (chunk 1/38) : 100
Total time elapsed: 1.77 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 3/38) : 72
Total time elapsed: 1.73 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 2/38) : 112
Total time elapsed: 2.10 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 4/38) : 63
Total time elapsed: 1.71 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 5/38) : 73
Total time elapsed: 1.70 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 6/38) : 82
Total time elapsed: 1.74 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 8/38) : 60
Total time elapsed: 1.69 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 7/38) : 62
Total time elapsed: 1.68 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 9/38) : 76
Total time elapsed: 1.66 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 10/38) : 69
Total time elapsed: 1.68 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 11/38) : 47
Total time elapsed: 1.67 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 12/38) : 48
Total time elapsed: 1.61 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 14/38) : 44
Total time elapsed: 1.62 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 13/38) : 67
Total time elapsed: 1.71 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 15/38) : 57
Total time elapsed: 1.68 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 16/38) : 51
Total time elapsed: 1.70 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 17/38) : 61
Total time elapsed: 1.68 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 18/38) : 58
Total time elapsed: 1.63 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 19/38) : 51
Total time elapsed: 1.64 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 21/38) : 63
Total time elapsed: 1.67 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 20/38) : 78
Total time elapsed: 2.02 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 22/38) : 61
Total time elapsed: 1.67 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 23/38) : 56
Total time elapsed: 1.67 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 24/38) : 54
Total time elapsed: 1.72 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 25/38) : 56
Total time elapsed: 1.71 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 26/38) : 55
Total time elapsed: 1.71 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 27/38) : 61
Total time elapsed: 1.70 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 28/38) : 74
Total time elapsed: 1.76 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 29/38) : 100
Total time elapsed: 1.74 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 30/38) : 78
Total time elapsed: 1.68 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 31/38) : 61
Total time elapsed: 1.70 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 32/38) : 67
Total time elapsed: 1.65 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 33/38) : 71
Total time elapsed: 1.64 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 34/38) : 72
Total time elapsed: 1.73 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 35/38) : 57
Total time elapsed: 1.74 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 36/38) : 68
Total time elapsed: 1.73 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 37/38) : 81
Total time elapsed: 1.59 s
Calling variants ...
Total processed positions in NC_045512.2 (chunk 38/38) : 69
Total time elapsed: 1.57 s

real	0m46.009s
user	2m2.892s
sys	0m4.457s
Warning: cannot find your CPU L2 cache size in /proc/cpuinfo
[INFO] 2/7 No phasing for full alignment calling

[INFO] 5/7 Select candidates for full-alignment calling
Warning: cannot find your CPU L2 cache size in /proc/cpuinfo
[INFO] Set variants quality cutoff 28.0
[INFO] Set reference calls quality cutoff 32.0
Warning: cannot find your CPU L2 cache size in /proc/cpuinfo
[INFO] Low quality reference calls to be processed in NC_045512.2: 2268
[INFO] Low quality variants to be processed in NC_045512.2: 156

real	0m0.945s
user	0m0.893s
sys	0m0.058s

[INFO] 6/7 Call low-quality variants using full-alignment model
Calling variants ...
Segmentation fault

real	0m7.052s
user	0m6.251s
sys	0m0.473s
Warning: cannot find your CPU L2 cache size in /proc/cpuinfo
[93m[WARNING] No vcf file found, output empty vcf file[0m
[93m[WARNING] Copying pileup.vcf.gz to /Users/cheshic/dev/repos/pipelines-tech/wic-viral-assembler/work/9c/7bfa116a33775c60e7dc6c3b2a0065/./merge_output.vcf.gz[0m
[INFO] Exit in full-alignment variant calling

real	0m57.367s
user	2m13.145s
sys	0m5.249s
",chris-cheshire,https://github.com/HKU-BAL/Clair3/issues/341
I_kwDOFQnk286cBPRz,The pipeline seems to have stopped with no error,CLOSED,2024-10-28T07:36:55Z,2024-10-30T03:07:56Z,2024-10-30T03:07:56Z,"Hi developers,
First, thank you for creating such a great tool! I installed clair3 (1.0.10) via mamba (1.5.9).I ran Clair3 with the suggested commands, including  '--enable_phasing  --longphase_for_phasing' as recommended by Severus. However, the pipeline consistently appears to stop after generating **1_call_var_bam_pileup.log** and **parallel_1_call_var_bam_pileup.log** , without any obvious error messages in the log file or reported by Python. I have successfully completed two samples in the same environment; one sample stopped at this stage then was rerun successfully. Other samples continue to stop without errors. What steps should I take to troubleshoot this issue? 
Thank you very much! 

Here is the end of  run_clair3.log:
> Total processed positions in chrX (chunk 31/32) : 652228
Total time elapsed: 1462.12 s
Calling variants ...
Total processed positions in chrX (chunk 28/32) : 659880
Total time elapsed: 1518.45 s
Calling variants ...
Total processed positions in chrX (chunk 32/32) : 684354
Total time elapsed: 1505.64 s
",hxlei,https://github.com/HKU-BAL/Clair3/issues/342
I_kwDOFQnk286cBWfo,Pileup Models for every dorado basecalling model,OPEN,2024-10-28T07:50:53Z,2024-12-10T15:05:57Z,,"Dear Developers

In the readme section, you mention that ONT models can be used with Clair3. I downloaded one of these model `dna_r10.4.1_e8.2_400bps_fast@v4.3.0` and gave it as input to Clair3. However, I get the following error

```
ONT-provided Models
ONT provides models for some latest or specific chemistries and basecallers (including both Guppy and Dorado) through [Rerio](https://github.com/nanoporetech/rerio). These models are tested and supported by the ONT developers.
```

```bash
 No pileup model found in provided model path and model prefix /home/satyamr/dorado-0.8.2-linux-x64/models/dna_r10.4.1_e8.2_400bps_fast@v4.3.0/pileup [0m
```

Should I use [r1041_e82_400bps_sup_v420.tar.gz](https://www.bio8.cs.hku.hk/clair3/clair3_models/r1041_e82_400bps_sup_v420.tar.gz) instead even the basecaller version is slightly different and the basecalling was run in fast mode ? Is there a way to convert the dorado models to pileup?

```
## Viral ONT samples
run_clair3.sh --bam_fn=p41530_barcode59_denv2.bam --ref_fn=reference.fasta \
--threads=20 --model_path=/home/satyamr/dorado-0.8.2-linux-x64/models/dna_r10.4.1_e8.2_400bps_fast@v4.3.0 \
--output=p41530_barcode59_clair3 --platform=""ont"" --haploid_precise --include_all_ctgs --no_phasing_for_fa --enable_long_indel
```",Rohit-Satyam,https://github.com/HKU-BAL/Clair3/issues/343
I_kwDOFQnk286dSCHj,Difference in number of calls: CRAM vs BAM,OPEN,2024-11-06T17:26:28Z,2024-12-10T00:52:14Z,,"Hi there,

I’m currently comparing the results of Clair3 v1.0.5 when alignments are stored within a BAM file vs CRAM. I am using HG002 replicates, and CRAM files were converted from the BAM file.

When comparing total number of variants called from the BAM file vs converted CRAM, I am seeing a 1-5 variant difference for 6 out of 8 HG002 replicates (out of on average 6 million variants called per replicate). Another thing I found interesting is that once the CRAM is converted back to BAM and is processed through Clair3, the total number of variant calls from the converted BAM matches the calls from original BAM.

Here is an example of what I am seeing:
| Sample  | File type | Clair3 total number of calls |
| :---------------- | :------: | ----: |
| HG002_replicate_A |   BAM   | 6095272 |
| HG002_replicate_A |   CRAM   | 6095277 |
| HG002_replicate_A |  BAM (converted back from CRAM)   | 6095272 |

Would you know why this might be happening?

Clair3 command used:

```
run_clair3.sh \
--bam_fn=$IN_ALN \
--ref_fn=$REF \
--threads=16 \
--platform=""ont"" \
--var_pct_full=0.7 \
--ref_pct_full=0.1 \
--snp_min_af=0.08 \
--indel_min_af=0.15 \
--model_path=$MODEL \
--output=$OUTPUT_DIR \
--remove_intermediate_dir
```

Kind regards,
Nicole
",nicolechai,https://github.com/HKU-BAL/Clair3/issues/344
I_kwDOFQnk286efj4o,Wrong FORMAT specification in VCF file,CLOSED,2024-11-14T14:50:32Z,2024-11-15T07:22:05Z,2024-11-15T07:22:05Z,"Hi,

I've encountered a small bug in the formatting of the output VCF files. 

In the header of the VCF it says:

`##FORMAT=<ID=AF,Number=1,Type=Float,Description=""Observed allele frequency in reads, for each ALT allele, in the same order as listed, or the REF allele for a RefCall"">`

Where `Number=1` is specified. As I understand it, this is not correct in the case of a multi allelic sites as the following:

`chr1    180847  .       C       CCCCT,CCT       10.68   PASS    F       GT:GQ:DP:AD:AF  1/2:10:102:14,11,24:0.1078,0.2353`

where `AF` has the value `0.1078,0.2353`, which is a list of multiple floats. I think the correct specification would be `Number=G`, so that is corresponds to the number of genotypes. 

Thanks for a great tool!",simondrue,https://github.com/HKU-BAL/Clair3/issues/346
I_kwDOFQnk286fuieo,parallel 20191122.* bioconda pin,OPEN,2024-11-21T14:46:05Z,2024-11-28T08:19:22Z,,"Hi, 

Thanks for maintaining such a handy variant caller, I am however running into problems with the bioconda recipe of clair3 since it is currently unsolvable for ARM processors due to `parallel 20191122.*` not existing for arm, would it be possible to loosen this pin in a future release?

I am aware that there are plenty of options for running clair3 on ARM already but I use clair3 as the variant caller in the [artic fieldbioinformatics pipeline](https://github.com/artic-network/fieldbioinformatics) and this pin seems to be the only thing in the way of full fieldbioinformatics ARM compatibility!

Thanks again for all the effort!",BioWilko,https://github.com/HKU-BAL/Clair3/issues/347
I_kwDOFQnk286iBUfA,Running error during whatshap phase,CLOSED,2024-12-04T16:28:35Z,2024-12-09T15:16:05Z,2024-12-09T15:16:05Z,"Hi, I was using singularity, and here are the parameters and error info. 
Any suggestions are appreciated! 
Thank you!

```
[INFO] CLAIR3 VERSION: v1.0.9
[INFO] BAM FILE PATH: /homes2/yangao/data/HG002/HG002_PacBio-HiFi-Revio_20231031_48x_GRCh38-GIABv3.bam
[INFO] REFERENCE FILE PATH: /homes2/yangao/data/HG002/GRCh38_GIABv3_no_alt_analysis_set_maskedGRC_decoys_MAP2K3_KMT2C_KCNJ18.fasta.gz
[INFO] MODEL PATH: /opt/models/hifi_revio
[INFO] OUTPUT FOLDER: /homes2/yangao/data/HG002/Clair3
[INFO] PLATFORM: hifi
[INFO] THREADS: 16
[INFO] BED FILE PATH: EMPTY
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX:
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.3
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.3
[INFO] PHASING PROPORTION: 0.7
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.08
[INFO] INDEL AF THRESHOLD: 0.08
[INFO] BASE ERROR IN GVCF: 0.001
[INFO] GQ BIN SIZE IN GVCF: 5
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: False
[INFO] ENABLE INCLUDE ALL CTGS CALLING: False
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: False
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE LONGPHASE FOR INTERMEDIATE VCF PHASING: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING WHATSHAP: True
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING LONGPHASE: False
[INFO] ENABLE HAPLOTAGGING FINAL BAM: True
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE C_IMPLEMENT: True

+ /opt/bin/scripts/clair3_c_impl.sh --bam_fn /homes2/yangao/data/HG002/HG002_PacBio-HiFi-Revio_20231031_48x_GRCh38-GIABv3.bam --ref_fn /homes2/yangao/data/HG002/GRCh38_GIABv3_no_alt_analysis_set_maskedGRC_decoys_MAP2K3_KMT2C_KCNJ18.fasta.gz --threads 16 --model_path /opt/models/hifi_revio --platform hifi --output /homes2/yangao/data/HG002/Clair3 --bed_fn=EMPTY --vcf_fn=EMPTY --ctg_name=EMPTY --sample_name=SAMPLE --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=2 --var_pct_full=0.3 --ref_pct_full=0.3 --var_pct_phasing=0.7 --snp_min_af=0.08 --indel_min_af=0.08 --min_mq=5 --min_coverage=2 --min_contig_size=0 --pileup_only=False --gvcf=False --base_err=0.001 --gq_bin_size=5 --fast_mode=False --call_snp_only=False --print_ref_calls=False --haploid_precise=False --haploid_sensitive=False --include_all_ctgs=False --no_phasing_for_fa=False --pileup_model_prefix=pileup --fa_model_prefix=full_alignment --remove_intermediate_dir=False --enable_phasing=True --enable_long_indel=False --keep_iupac_bases=False --use_gpu=False --longphase_for_phasing=False --longphase=EMPTY --use_whatshap_for_intermediate_phasing=True --use_longphase_for_intermediate_phasing=False --use_whatshap_for_final_output_phasing=True --use_longphase_for_final_output_phasing=False --use_whatshap_for_final_output_haplotagging=True

... ...

[INFO] 3/7 Phase VCF file using Whatshap
This is WhatsHap 1.7 running under Python 3.9.0
[W::hts_idx_load3] The index file is older than the data file: /homes2/yangao/data/HG002/HG002_PacBio-HiFi-Revio_20231031_48x_GRCh38-GIABv3.bam.bai
[W::hts_idx_load3] The index file is older than the data file: /homes2/yangao/data/HG002/HG002_PacBio-HiFi-Revio_20231031_48x_GRCh38-GIABv3.bam.bai
Working on 1 sample from 1 family

# Working on contig chr16 in individual SAMPLE
Found 53463 usable heterozygous variants (0 skipped due to missing genotypes)
Traceback (most recent call last):
  File ""/opt/conda/envs/clair3/bin/whatshap"", line 10, in <module>
    sys.exit(main())
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/__main__.py"", line 64, in main
    module.main(args)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/cli/phase.py"", line 1169, in main
    run_whatshap(**vars(args))
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/cli/phase.py"", line 493, in run_whatshap
    readset, vcf_source_ids = phased_input_reader.read(
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/cli/__init__.py"", line 152, in read
    readset = readset_reader.read(chromosome, variants, bam_sample, reference, regions)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/variants.py"", line 98, in read
    readset = self._make_readset_from_grouped_reads(grouped_reads)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/variants.py"", line 104, in _make_readset_from_grouped_reads
    for group in groups:
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/variants.py"", line 119, in _group_paired_reads
    for read in reads:
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/whatshap/variants.py"", line 166, in _alignments_to_reads
    reference = reference[:]
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/pyfaidx/__init__.py"", line 920, in __getitem__
    return self._fa.get_seq(self.name, start + 1, stop)[::step]
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/pyfaidx/__init__.py"", line 1149, in get_seq
    seq = self.faidx.fetch(name, start, end)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/pyfaidx/__init__.py"", line 727, in fetch
    seq = self.from_file(name, start, end)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/pyfaidx/__init__.py"", line 769, in from_file
    self.file.seek(i.offset)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/Bio/bgzf.py"", line 682, in seek
    self._load_block(start_offset)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/Bio/bgzf.py"", line 643, in _load_block
    block_size, self._buffer = _load_bgzf_block(handle, self._text)
  File ""/opt/conda/envs/clair3/lib/python3.9/site-packages/Bio/bgzf.py"", line 444, in _load_bgzf_block
    raise ValueError(
ValueError: A BGZF (e.g. a BAM file) block should start with b'\x1f\x8b\x08\x04', not b'T\x1bC!'; handle.tell() now says 37155
This is WhatsHap 1.7 running under Python 3.9.0
[W::hts_idx_load3] The index file is older than the data file: /homes2/yangao/data/HG002/HG002_PacBio-HiFi-Revio_20231031_48x_GRCh38-GIABv3.bam.bai
[W::hts_idx_load3] The index file is older than the data file: /homes2/yangao/data/HG002/HG002_PacBio-HiFi-Revio_20231031_48x_GRCh38-GIABv3.bam.bai
Working on 1 sample from 1 family

# Working on contig chr15 in individual SAMPLE
Found 53378 usable heterozygous variants (0 skipped due to missing genotypes)

... ...
```",yangao07,https://github.com/HKU-BAL/Clair3/issues/348
I_kwDOFQnk286iHGHk,Missed Variant,OPEN,2024-12-05T08:49:59Z,2024-12-13T21:00:48Z,,"Hi,

I have a sample with a variant which was not called with clair3, but looks quiet good in IGV:
![grafik](https://github.com/user-attachments/assets/97cd5f24-8d4d-44d9-9a1c-1ff978a030f8)

I looked in the output VCFs and the variant is called in the `pileup.vcf`:

```
chr16	1568260	.	C	T	19.57	PASS	P	GT:GQ:DP:AD:AF:PL	0/1:19:37:25,12:0.3243:26,0,62
```
But in the `full_alignment.vcf` it is called as wildtype:

```
chr16	1568260	.	C	.	5.32	RefCall	F	GT:GQ:DP:AD:AF:PL	0/0:5:37:25:0.6757:990
```

If I see it correctly, variants in the `pileup.vcf` has to have at least a quality of 20 to make it in the `merged.vcf`? Is there an option to lower this threshold?

Best,
Leon
",leonschuetz,https://github.com/HKU-BAL/Clair3/issues/349
I_kwDOFQnk286jlkIN,[ERROR] No full-alignment output for file (Illumina),OPEN,2024-12-17T10:26:02Z,2024-12-17T10:26:02Z,,"Hi,

I'm using the Clair3-Illumina conda package on haploid data and I'm getting these ""[ERROR] No full-alignment output for file"" errors. Something related to clair3 or my data?


```
[INFO] CLAIR3 VERSION: v1.0.6
[INFO] BAM FILE PATH: /home/genomics/dslos/06_development/fusarium/01_mapping/./MY0231.BWA.bam
[INFO] REFERENCE FILE PATH: /home/genomics/dslos/06_development/fusarium/ref/polished.fasta
[INFO] MODEL PATH: /opt/miniforge3/envs/clair3-illumina/bin/models/ilmn
[INFO] OUTPUT FOLDER: /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231
[INFO] PLATFORM: ilmn
[INFO] THREADS: 20
[INFO] BED FILE PATH: /home/genomics/dslos/06_development/fusarium/02_delineate_c90/final_stack_positions_fusarium_C90.0_SMAP10_CL40_275.bed
[INFO] VCF FILE PATH: EMPTY
[INFO] CONTIGS: EMPTY
[INFO] CONDA PREFIX: /opt/miniforge3/envs/clair3-illumina
[INFO] SAMTOOLS PATH: samtools
[INFO] PYTHON PATH: python3
[INFO] PYPY PATH: pypy3
[INFO] PARALLEL PATH: parallel
[INFO] WHATSHAP PATH: whatshap
[INFO] LONGPHASE PATH: EMPTY
[INFO] CHUNK SIZE: 5000000
[INFO] FULL ALIGN PROPORTION: 0.3
[INFO] FULL ALIGN REFERENCE PROPORTION: 0.3
[INFO] PHASING PROPORTION: 0.7
[INFO] MINIMUM MQ: 5
[INFO] MINIMUM COVERAGE: 2
[INFO] SNP AF THRESHOLD: 0.08
[INFO] INDEL AF THRESHOLD: 0.08
[INFO] BASE ERROR IN GVCF: 0.001
[INFO] GQ BIN SIZE IN GVCF: 5
[INFO] ENABLE FILEUP ONLY CALLING: False
[INFO] ENABLE FAST MODE CALLING: False
[INFO] ENABLE CALLING SNP CANDIDATES ONLY: False
[INFO] ENABLE PRINTING REFERENCE CALLS: False
[INFO] ENABLE OUTPUT GVCF: False
[INFO] ENABLE HAPLOID PRECISE MODE: False
[INFO] ENABLE HAPLOID SENSITIVE MODE: True
[INFO] ENABLE INCLUDE ALL CTGS CALLING: True
[INFO] ENABLE NO PHASING FOR FULL ALIGNMENT: True
[INFO] ENABLE REMOVING INTERMEDIATE FILES: False
[INFO] ENABLE LONGPHASE FOR INTERMEDIATE VCF PHASING: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING WHATSHAP: False
[INFO] ENABLE PHASING FINAL VCF OUTPUT USING LONGPHASE: False
[INFO] ENABLE HAPLOTAGGING FINAL BAM: False
[INFO] ENABLE LONG INDEL CALLING: False
[INFO] ENABLE C_IMPLEMENT: True

[WARNING] Illumina platform will disable C implement to support short read realignment process!
+ /opt/miniforge3/envs/clair3-illumina/bin/scripts/clair3.sh --bam_fn /home/genomics/dslos/06_development/fusarium/01_mapping/./MY0231.BWA.bam --ref_fn /home/genomics/dslos/06_development/fusarium/ref/polished.fasta --threads 20 --model_path /opt/miniforge3/envs/clair3-illumina/bin/models/ilmn --platform ilmn --output /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231 --bed_fn=/home/genomics/dslos/06_development/fusarium/02_delineate_c90/final_stack_positions_fusarium_C90.0_SMAP10_CL40_275.bed --vcf_fn=EMPTY --ctg_name=EMPTY --sample_name=MY0231 --chunk_num=0 --chunk_size=5000000 --samtools=samtools --python=python3 --pypy=pypy3 --parallel=parallel --whatshap=whatshap --qual=2 --var_pct_full=0.3 --ref_pct_full=0.3 --var_pct_phasing=0.7 --snp_min_af=0.08 --indel_min_af=0.08 --min_mq=5 --min_coverage=2 --min_contig_size=0 --pileup_only=False --gvcf=False --base_err=0.001 --gq_bin_size=5 --fast_mode=False --call_snp_only=False --print_ref_calls=False --haploid_precise=False --haploid_sensitive=True --include_all_ctgs=True --no_phasing_for_fa=True --pileup_model_prefix=pileup --fa_model_prefix=full_alignment --remove_intermediate_dir=False --enable_phasing=False --enable_long_indel=False --keep_iupac_bases=False --use_gpu=False --longphase_for_phasing=False --longphase=EMPTY --use_whatshap_for_intermediate_phasing=True --use_longphase_for_intermediate_phasing=False --use_whatshap_for_final_output_phasing=False --use_longphase_for_final_output_phasing=False --use_whatshap_for_final_output_haplotagging=False

[INFO] Check environment variables
[INFO] --include_all_ctgs enabled
[INFO] Call variant in contigs: contig_50 contig_41 contig_18 contig_42 contig_20 contig_69 contig_12 contig_193 contig_25 contig_16 contig_27 contig_21 contig_49 contig_192 contig_36 contig_90 contig_33 contig_200 contig_194 contig_29 contig_61 contig_161 contig_35 contig_32 contig_190 contig_31
[INFO] Chunk number for each contig: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
[INFO] 1/7 Call variants using pileup model
[INFO] Delay 0 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_192 (chunk 1/1) : 14
Total time elapsed: 2.02 s
[INFO] Delay 0 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_50 (chunk 1/1) : 32
Total time elapsed: 2.10 s
[INFO] Delay 2 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_193 (chunk 1/1) : 4
Total time elapsed: 2.64 s
[INFO] Delay 3 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_36 (chunk 1/1) : 46
Total time elapsed: 2.79 s
[INFO] Delay 3 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_16 (chunk 1/1) : 99
Total time elapsed: 3.42 s
[INFO] Delay 4 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_42 (chunk 1/1) : 31
Total time elapsed: 2.52 s
[INFO] Delay 4 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_20 (chunk 1/1) : 75
Total time elapsed: 2.74 s
[INFO] Delay 4 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_49 (chunk 1/1) : 143
Total time elapsed: 4.24 s
[INFO] Delay 0 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_90 (chunk 1/1) : 163
Total time elapsed: 5.52 s
[INFO] Delay 3 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_18 (chunk 1/1) : 328
Total time elapsed: 8.65 s
[INFO] Delay 3 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_69 (chunk 1/1) : 267
Total time elapsed: 8.21 s
[INFO] Delay 2 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_12 (chunk 1/1) : 404
Total time elapsed: 9.59 s
[INFO] Delay 0 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_200 (chunk 1/1) : 152
Total time elapsed: 4.97 s
[INFO] Delay 4 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_41 (chunk 1/1) : 387
Total time elapsed: 8.88 s
[INFO] Delay 0 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_21 (chunk 1/1) : 465
Total time elapsed: 16.27 s
[INFO] Delay 1 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_61 (chunk 1/1) : 135
Total time elapsed: 5.16 s
[INFO] Delay 4 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_27 (chunk 1/1) : 547
Total time elapsed: 14.39 s
[INFO] Delay 2 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_190 (chunk 1/1) : 24
Total time elapsed: 2.64 s
[INFO] Delay 0 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_194 (chunk 1/1) : 332
Total time elapsed: 11.39 s
[INFO] Delay 3 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_25 (chunk 1/1) : 759
Total time elapsed: 17.16 s
[INFO] Delay 0 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_35 (chunk 1/1) : 375
Total time elapsed: 11.41 s
[INFO] Delay 1 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_29 (chunk 1/1) : 363
Total time elapsed: 11.71 s
[INFO] Delay 4 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_161 (chunk 1/1) : 285
Total time elapsed: 8.75 s
[INFO] Delay 2 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_33 (chunk 1/1) : 458
Total time elapsed: 18.36 s
[INFO] Delay 1 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_32 (chunk 1/1) : 433
Total time elapsed: 13.14 s
[INFO] Delay 3 seconds before starting variant calling ...
[mpileup] 1 samples in 1 input files
Calling variants ...
Total processed positions in contig_31 (chunk 1/1) : 573
Total time elapsed: 12.08 s

real    0m32.658s
user    6m21.829s
sys     0m31.780s
[INFO] 2/7 No phasing for full alignment calling

[INFO] 5/7 Select candidates for full-alignment calling
[INFO] Set variants quality cutoff 15.0
[INFO] Set reference calls quality cutoff 6.0
[INFO] Low quality reference calls to be processed in contig_20: 2
[INFO] Low quality variants to be processed in contig_20: 21
[INFO] Low quality reference calls to be processed in contig_25: 24
[INFO] Low quality variants to be processed in contig_25: 193
[INFO] Low quality reference calls to be processed in contig_41: 8
[INFO] Low quality variants to be processed in contig_41: 97
[INFO] Low quality reference calls to be processed in contig_18: 13
[INFO] Low quality variants to be processed in contig_18: 107
[WARNING] Cannot find any low-quality 0/0, 0/1 or 1/1 variant in pileup output in contig contig_193
[WARNING] Copying pileup.vcf.gz to /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/merge_output.vcf.gz
[INFO] Low quality reference calls to be processed in contig_193: 0
[INFO] Low quality variants to be processed in contig_193: 0
[INFO] Low quality reference calls to be processed in contig_42: 2
[INFO] Low quality variants to be processed in contig_42: 7
[INFO] Low quality reference calls to be processed in contig_27: 8
[INFO] Low quality variants to be processed in contig_27: 159
[INFO] Low quality reference calls to be processed in contig_49: 3
[INFO] Low quality variants to be processed in contig_49: 39
[INFO] Low quality reference calls to be processed in contig_12: 10
[INFO] Low quality variants to be processed in contig_12: 102
[INFO] Low quality reference calls to be processed in contig_16: 2
[INFO] Low quality variants to be processed in contig_16: 24
[INFO] Low quality reference calls to be processed in contig_21: 13
[INFO] Low quality variants to be processed in contig_21: 128
[INFO] Low quality reference calls to be processed in contig_192: 1
[INFO] Low quality variants to be processed in contig_192: 3
[INFO] Low quality reference calls to be processed in contig_200: 3
[INFO] Low quality variants to be processed in contig_200: 35
[INFO] Low quality reference calls to be processed in contig_33: 5
[INFO] Low quality variants to be processed in contig_33: 139
[INFO] Low quality reference calls to be processed in contig_50: 1
[INFO] Low quality variants to be processed in contig_50: 10
[INFO] Low quality reference calls to be processed in contig_90: 3
[INFO] Low quality variants to be processed in contig_90: 42
[INFO] Low quality reference calls to be processed in contig_29: 8
[INFO] Low quality variants to be processed in contig_29: 87
[INFO] Low quality reference calls to be processed in contig_36: 3
[INFO] Low quality variants to be processed in contig_36: 9
[INFO] Low quality reference calls to be processed in contig_194: 4
[INFO] Low quality variants to be processed in contig_194: 103
[INFO] Low quality reference calls to be processed in contig_69: 6
[INFO] Low quality variants to be processed in contig_69: 78
[INFO] Low quality reference calls to be processed in contig_61: 4
[INFO] Low quality variants to be processed in contig_61: 39
[INFO] Low quality reference calls to be processed in contig_35: 9
[INFO] Low quality variants to be processed in contig_35: 111
[INFO] Low quality reference calls to be processed in contig_161: 8
[INFO] Low quality variants to be processed in contig_161: 71
[INFO] Low quality reference calls to be processed in contig_32: 12
[INFO] Low quality variants to be processed in contig_32: 135
[INFO] Low quality reference calls to be processed in contig_190: 1
[INFO] Low quality variants to be processed in contig_190: 7
[INFO] Low quality reference calls to be processed in contig_31: 18
[INFO] Low quality variants to be processed in contig_31: 145

real    0m0.693s
user    0m4.550s
sys     0m1.888s

[INFO] 6/7 Call low-quality variants using full-alignment model
[INFO] Delay 0 seconds before starting variant calling ...
[WARNING] Skip full-alignment variant calling for empty full-alignment regions
[INFO] Delay 0 seconds before starting variant calling ...
samtools view: writing to standard output failed[mpileup] fail to read the header of -
: Broken pipe
samtools view: error closing standard output: -1
Calling variants ...
Total processed positions in contig_12 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_12//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_12.0_1.vcf
Total time elapsed: 0.00 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_12.0_1.vcf, remove empty file
[INFO] Delay 0 seconds before starting variant calling ...
Calling variants ...
samtools view: writing to standard output failed: Broken pipe
[mpileup] fail to read the header of -
samtools view: error closing standard output: -1
Total processed positions in contig_18 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_18//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_18.0_1.vcf
Total time elapsed: 0.20 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_18.0_1.vcf, remove empty file
[INFO] Delay 0 seconds before starting variant calling ...
Calling variants ...
samtools view: writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
[mpileup] fail to read the header of -
Total processed positions in contig_29 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_29//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_29.0_1.vcf
Total time elapsed: 1.61 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_29.0_1.vcf, remove empty file
[INFO] Delay 0 seconds before starting variant calling ...
Calling variants ...
[mpileup] fail to read the header of -
samtools view: writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
Total processed positions in contig_32 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_32//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_32.0_1.vcf
Total time elapsed: 2.65 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_32.0_1.vcf, remove empty file
[INFO] Delay 1 seconds before starting variant calling ...
Calling variants ...
samtools view: writing to standard output failed: Broken pipe
[mpileup] fail to read the header of -
samtools view: error closing standard output: -1
Total processed positions in contig_200 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_200//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_200.0_1.vcf
Total time elapsed: 2.75 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_200.0_1.vcf, remove empty file
[INFO] Delay 4 seconds before starting variant calling ...
[mpileup] fail to read the header of -
samtools view: writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
Calling variants ...
Total processed positions in contig_192 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_192//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_192.0_1.vcf
Total time elapsed: 0.00 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_192.0_1.vcf, remove empty file
[INFO] Delay 4 seconds before starting variant calling ...
samtools view: [mpileup] fail to read the header of -
writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
Calling variants ...
Total processed positions in contig_21 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_21//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_21.0_1.vcf
Total time elapsed: 0.00 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_21.0_1.vcf, remove empty file
[INFO] Delay 1 seconds before starting variant calling ...
Calling variants ...
samtools view: [mpileup] fail to read the header of -
writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
Total processed positions in contig_27 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_27//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_27.0_1.vcf
Total time elapsed: 3.37 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_27.0_1.vcf, remove empty file
[INFO] Delay 1 seconds before starting variant calling ...
Calling variants ...
samtools view: writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
[mpileup] fail to read the header of -
Total processed positions in contig_31 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_31//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_31.0_1.vcf
Total time elapsed: 4.22 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_31.0_1.vcf, remove empty file
[INFO] Delay 2 seconds before starting variant calling ...
Calling variants ...
samtools view: writing to standard output failed: Broken pipe
[mpileup] fail to read the header of -
samtools view: error closing standard output: -1
Total processed positions in contig_20 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_20//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_20.0_1.vcf
Total time elapsed: 4.51 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_20.0_1.vcf, remove empty file
[INFO] Delay 2 seconds before starting variant calling ...
Calling variants ...
samtools view: [mpileup] fail to read the header of -
writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
Total processed positions in contig_161 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_161//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_161.0_1.vcf
Total time elapsed: 5.10 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_161.0_1.vcf, remove empty file
[INFO] Delay 2 seconds before starting variant calling ...
samtools view: [mpileup] fail to read the header of -
writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
Calling variants ...
Total processed positions in contig_42 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_42//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_42.0_1.vcf
Total time elapsed: 0.00 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_42.0_1.vcf, remove empty file
[INFO] Delay 3 seconds before starting variant calling ...
Calling variants ...
[mpileup] fail to read the header of -
samtools view: writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
Total processed positions in contig_190 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_190//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_190.0_1.vcf
Total time elapsed: 5.91 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_190.0_1.vcf, remove empty file
[INFO] Delay 4 seconds before starting variant calling ...
samtools view: writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
[mpileup] fail to read the header of -
Calling variants ...
Total processed positions in contig_41 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_41//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_41.0_1.vcf
Total time elapsed: 0.00 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_41.0_1.vcf, remove empty file
[INFO] Delay 3 seconds before starting variant calling ...
Calling variants ...
samtools view: writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
[mpileup] fail to read the header of -
Total processed positions in contig_16 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_16//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_16.0_1.vcf
Total time elapsed: 6.90 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_16.0_1.vcf, remove empty file
[INFO] Delay 3 seconds before starting variant calling ...
Calling variants ...
samtools view: writing to standard output failed[mpileup] fail to read the header of -
: Broken pipe
samtools view: error closing standard output: -1
Total processed positions in contig_194 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_194//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_194.0_1.vcf
Total time elapsed: 7.97 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_194.0_1.vcf, remove empty file
[INFO] Delay 3 seconds before starting variant calling ...
Calling variants ...
samtools view: writing to standard output failed[mpileup] fail to read the header of -
: Broken pipe
samtools view: error closing standard output: -1
Total processed positions in contig_25 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_25//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_25.0_1.vcf
Total time elapsed: 8.58 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_25.0_1.vcf, remove empty file
[INFO] Delay 1 seconds before starting variant calling ...
Calling variants ...
[mpileup] fail to read the header of -
samtools view: writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
Total processed positions in contig_33 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_33//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_33.0_1.vcf
Total time elapsed: 8.81 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_33.0_1.vcf, remove empty file
[INFO] Delay 2 seconds before starting variant calling ...
Calling variants ...
[mpileup] fail to read the header of -
samtools view: writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
Total processed positions in contig_35 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_35//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_35.0_1.vcf
Total time elapsed: 7.88 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_35.0_1.vcf, remove empty file
[INFO] Delay 3 seconds before starting variant calling ...
Calling variants ...
samtools view: writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
[mpileup] fail to read the header of -
Total processed positions in contig_36 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_36//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_36.0_1.vcf
Total time elapsed: 7.69 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_36.0_1.vcf, remove empty file
[INFO] Delay 1 seconds before starting variant calling ...
Calling variants ...
samtools view: writing to standard output failed: Broken pipe
[mpileup] fail to read the header of -
samtools view: error closing standard output: -1
Total processed positions in contig_50 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_50//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_50.0_1.vcf
Total time elapsed: 7.57 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_50.0_1.vcf, remove empty file
[INFO] Delay 2 seconds before starting variant calling ...
Calling variants ...
samtools view: writing to standard output failed: Broken pipe
[mpileup] fail to read the header of -
samtools view: error closing standard output: -1
Total processed positions in contig_49 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_49//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_49.0_1.vcf
Total time elapsed: 7.96 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_49.0_1.vcf, remove empty file
[INFO] Delay 1 seconds before starting variant calling ...
Calling variants ...
[mpileup] fail to read the header of -
samtools view: writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
Total processed positions in contig_69 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_69//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_69.0_1.vcf
Total time elapsed: 8.35 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_69.0_1.vcf, remove empty file
[INFO] Delay 3 seconds before starting variant calling ...
Calling variants ...
[mpileup] fail to read the header of -
samtools view: writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
Total processed positions in contig_61 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_61//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_61.0_1.vcf
Total time elapsed: 8.01 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_61.0_1.vcf, remove empty file
[INFO] Delay 2 seconds before starting variant calling ...
Calling variants ...
samtools view: [mpileup] fail to read the header of -
writing to standard output failed: Broken pipe
samtools view: error closing standard output: -1
Total processed positions in contig_90 (chunk 1/1) : 0
[ERROR] No full-alignment output for file contig_90//home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_90.0_1.vcf
Total time elapsed: 8.31 s
[INFO] No vcf output for file /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment_contig_90.0_1.vcf, remove empty file

real    0m22.977s
user    1m20.538s
sys     0m16.302s
[WARNING] No vcf file found with prefix:/home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/tmp/full_alignment_output/full_alignment, output empty vcf file
[WARNING] Copying pileup.vcf.gz to /home/genomics/dslos/06_development/fusarium/03_variant_calling2/MY0231/merge_output.vcf.gz
[INFO] Exit in full-alignment variant calling
```
",dgslos,https://github.com/HKU-BAL/Clair3/issues/350
