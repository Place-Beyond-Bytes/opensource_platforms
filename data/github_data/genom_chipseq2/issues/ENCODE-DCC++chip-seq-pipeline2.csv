id,title,state,created_at,updated_at,closed_at,body,user,url
MDU6SXNzdWUzMzk2NTg1MTU=,Failed to find index Success(WomInteger(0)),CLOSED,2018-07-10T01:11:39Z,2019-09-09T22:04:17Z,2019-09-09T22:04:16Z,"2018-07-08 17:12:05,62] [info] Running with database db.url = jdbc:hsqldb:mem:b928854f-1b26-4f74-8a45-e72f73b30968;shutdown=false;hsqldb.tx=mvcc
[2018-07-08 17:12:11,01] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000
[2018-07-08 17:12:11,02] [info] [RenameWorkflowOptionsInMetadata] 100%
[2018-07-08 17:12:11,10] [info] Running with database db.url = jdbc:hsqldb:mem:b55a6427-b864-4e72-9858-1211b6533178;shutdown=false;hsqldb.tx=mvcc
[2018-07-08 17:12:11,42] [warn] This actor factory is deprecated. Please use cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory for PAPI v1 or cromwell.backend.google.pipelines                                .v2alpha1.PipelinesApiLifecycleActorFactory for PAPI v2
[2018-07-08 17:12:11,42] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.
[2018-07-08 17:12:11,43] [info] Using noop to send events.
[2018-07-08 17:12:11,69] [info] Slf4jLogger started
[2018-07-08 17:12:11,87] [info] Workflow heartbeat configuration:
{
  ""cromwellId"" : ""cromid-df3d320"",
  ""heartbeatInterval"" : ""2 minutes"",
  ""ttl"" : ""10 minutes"",
  ""writeBatchSize"" : 10000,
  ""writeThreshold"" : 10000
}
[2018-07-08 17:12:11,91] [info] Metadata summary refreshing every 2 seconds.
[2018-07-08 17:12:11,95] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.
[2018-07-08 17:12:11,95] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.
[2018-07-08 17:12:11,95] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.
[2018-07-08 17:12:12,71] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.
[2018-07-08 17:12:12,73] [info] JES batch polling interval is 33333 milliseconds
[2018-07-08 17:12:12,73] [info] JES batch polling interval is 33333 milliseconds
[2018-07-08 17:12:12,73] [info] JES batch polling interval is 33333 milliseconds
[2018-07-08 17:12:12,73] [info] PAPIQueryManager Running with 3 workers
[2018-07-08 17:12:12,74] [info] SingleWorkflowRunnerActor: Submitting workflow
[2018-07-08 17:12:12,78] [info] Unspecified type (Unspecified version) workflow 068f45d8-f29a-4335-8c0e-a711391af811 submitted
[2018-07-08 17:12:12,83] [info] SingleWorkflowRunnerActor: Workflow submitted 068f45d8-f29a-4335-8c0e-a711391af811
[2018-07-08 17:12:12,83] [info] 1 new workflows fetched
[2018-07-08 17:12:12,83] [info] WorkflowManagerActor Starting workflow 068f45d8-f29a-4335-8c0e-a711391af811
[2018-07-08 17:12:12,84] [info] WorkflowManagerActor Successfully started WorkflowActor-068f45d8-f29a-4335-8c0e-a711391af811
[2018-07-08 17:12:12,84] [info] Retrieved 1 workflows from the WorkflowStoreActor
[2018-07-08 17:12:12,84] [warn] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData
[2018-07-08 17:12:12,85] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.
[2018-07-08 17:12:12,89] [info] MaterializeWorkflowDescriptorActor [068f45d8]: Parsing workflow as WDL draft-2
[2018-07-08 17:13:26,22] [info] MaterializeWorkflowDescriptorActor [068f45d8]: Call-to-Backend assignments: chip.macs2 -> Local, chip.bam2ta_ctl -> Local, chip.spp_ppr2 -> Local, chip.bwa -> Local, chip                                .qc_report -> Local, chip.bwa_ctl -> Local, chip.filter -> Local, chip.overlap -> Local, chip.pool_ta -> Local, chip.idr_ppr -> Local, chip.filter_ctl -> Local, chip.macs2_pr2 -> Local, chip.spp_pr1 ->                                 Local, chip.read_genome_tsv -> Local, chip.merge_fastq_ctl -> Local, chip.macs2_ppr1 -> Local, chip.pool_ta_pr2 -> Local, chip.trim_fastq -> Local, chip.overlap_ppr -> Local, chip.bam2ta -> Local, chip.                                pool_ta_ctl -> Local, chip.reproducibility_idr -> Local, chip.spp_pooled -> Local, chip.fraglen_mean -> Local, chip.spr -> Local, chip.bam2ta_no_filt -> Local, chip.macs2_pr1 -> Local, chip.fingerprint                                 -> Local, chip.xcor -> Local, chip.spp_pr2 -> Local, chip.spp -> Local, chip.merge_fastq -> Local, chip.bam2ta_no_filt_R1 -> Local, chip.reproducibility_overlap -> Local, chip.overlap_pr -> Local, chip.                                idr -> Local, chip.macs2_ppr2 -> Local, chip.bwa_R1 -> Local, chip.spp_ppr1 -> Local, chip.macs2_pooled -> Local, chip.idr_pr -> Local, chip.choose_ctl -> Local, chip.pool_ta_pr1 -> Local
[2018-07-08 17:13:26,34] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,35] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,35] [warn] Local [068f45d8]: Key/s [preemptible, disks, cpu, time, memory] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,35] [warn] Local [068f45d8]: Key/s [preemptible, disks, cpu, time, memory] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,35] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,35] [warn] Local [068f45d8]: Key/s [preemptible, disks, cpu, time, memory] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,35] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,35] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,35] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,35] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,35] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,35] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [preemptible, disks, cpu, time, memory] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [preemptible, disks, cpu, time, memory] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,36] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [preemptible, disks, cpu, time, memory] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [preemptible, disks, cpu, time, memory] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [preemptible, disks, cpu, time, memory] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [preemptible, disks, cpu, time, memory] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:26,37] [warn] Local [068f45d8]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-07-08 17:13:28,66] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Starting chip.read_genome_tsv
[2018-07-08 17:13:28,67] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Condition met: '!align_only && !true_rep_only'. Running conditional section
[2018-07-08 17:13:28,68] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Condition met: '!true_rep_only'. Running conditional section
[2018-07-08 17:13:28,87] [warn] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.read_genome_tsv:NA:1]: Unrecognized runtime attribute keys: disks, cpu, time, memory
[2018-07-08 17:13:29,34] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.read_genome_tsv:NA:1]: echo ""Reading genome_tsv /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068                                f45d8-f29a-4335-8c0e-a711391af811/call-read_genome_tsv/inputs/1532045310/mm10.tsv ...""
[2018-07-08 17:13:29,46] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.read_genome_tsv:NA:1]: executing: /bin/bash /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d                                8-f29a-4335-8c0e-a711391af811/call-read_genome_tsv/execution/script
[2018-07-08 17:13:29,70] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Condition NOT met: 'peak_caller_ == ""macs2""'. Bypassing conditional section
[2018-07-08 17:13:29,70] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Condition met: 'enable_idr'. Running conditional section
[2018-07-08 17:13:29,70] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Condition met: 'enable_idr'. Running conditional section
[2018-07-08 17:13:29,70] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Condition met: 'peak_caller_ == ""spp""'. Running conditional section
[2018-07-08 17:13:29,70] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Condition met: 'peak_caller_ == ""spp""'. Running conditional section
[2018-07-08 17:13:29,71] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Condition met: '!align_only && !true_rep_only && enable_idr'. Running conditional section
[2018-07-08 17:13:31,99] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.read_genome_tsv:NA:1]: job id: 18903
[2018-07-08 17:13:32,00] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.read_genome_tsv:NA:1]: Status change from - to Done
[2018-07-08 17:13:32,80] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Starting chip.merge_fastq_ctl, chip.merge_fastq
[2018-07-08 17:13:33,74] [warn] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.merge_fastq_ctl:0:1]: Unrecognized runtime attribute keys: disks, cpu, time, memory
[2018-07-08 17:13:33,74] [warn] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.merge_fastq:0:1]: Unrecognized runtime attribute keys: disks, cpu, time, memory
[2018-07-08 17:13:33,85] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.merge_fastq_ctl:0:1]: python $(which encode_merge_fastq.py) \
        /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a-4335-8c0e-a711391af811/call-merge_fastq_ctl/shard-0/execution/write_tsv_609523603b8830d2bf2d45a4a71d8dd7.tmp \
         \
        --nth 2
[2018-07-08 17:13:33,85] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.merge_fastq:0:1]: python $(which encode_merge_fastq.py) \
        /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a-4335-8c0e-a711391af811/call-merge_fastq/shard-0/execution/write_tsv_577d047f7bb8a8ea8c6ee89ee3d97c7b.tmp \
         \
        --nth 2
[2018-07-08 17:13:33,85] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.merge_fastq:0:1]: executing: /bin/bash /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29                                a-4335-8c0e-a711391af811/call-merge_fastq/shard-0/execution/script
[2018-07-08 17:13:33,85] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.merge_fastq_ctl:0:1]: executing: /bin/bash /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8                                -f29a-4335-8c0e-a711391af811/call-merge_fastq_ctl/shard-0/execution/script
[2018-07-08 17:13:36,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.merge_fastq:0:1]: job id: 18944
[2018-07-08 17:13:36,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.merge_fastq_ctl:0:1]: job id: 18946
[2018-07-08 17:13:36,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.merge_fastq:0:1]: Status change from - to Done
[2018-07-08 17:13:36,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.merge_fastq_ctl:0:1]: Status change from - to Done
[2018-07-08 17:13:38,92] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Starting chip.bwa, chip.bwa_ctl
[2018-07-08 17:13:39,74] [warn] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bwa:0:1]: Unrecognized runtime attribute keys: preemptible, disks, cpu, time, memory
[2018-07-08 17:13:39,74] [warn] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bwa_ctl:0:1]: Unrecognized runtime attribute keys: preemptible, disks, cpu, time, memory
[2018-07-08 17:13:39,76] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bwa:0:1]: python $(which encode_bwa.py) \
        /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a-4335-8c0e-a711391af811/call-bwa/shard-0/inputs/1424220334/mm10_no_alt_analysis_set_ENCODE.fasta.tar \
        /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a-4335-8c0e-a711391af811/call-bwa/shard-0/inputs/-1993312639/merge_fastqs_R1_RYBP.merged.fastq.gz \
         \
        --nth 4
[2018-07-08 17:13:39,76] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bwa_ctl:0:1]: python $(which encode_bwa.py) \
        /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a-4335-8c0e-a711391af811/call-bwa_ctl/shard-0/inputs/1424220334/mm10_no_alt_analysis_set_ENCODE.fasta.tar \
        /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a-4335-8c0e-a711391af811/call-bwa_ctl/shard-0/inputs/1654728541/merge_fastqs_R1_IgG.merged.fastq.gz \
         \
        --nth 4
[2018-07-08 17:13:39,77] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bwa_ctl:0:1]: executing: /bin/bash /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a-43                                35-8c0e-a711391af811/call-bwa_ctl/shard-0/execution/script
[2018-07-08 17:13:39,77] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bwa:0:1]: executing: /bin/bash /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a-4335-8                                c0e-a711391af811/call-bwa/shard-0/execution/script
[2018-07-08 17:13:41,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bwa_ctl:0:1]: job id: 19040
[2018-07-08 17:13:41,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bwa:0:1]: job id: 19041
[2018-07-08 17:13:41,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bwa_ctl:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-07-08 17:13:41,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bwa:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-07-08 18:03:30,01] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bwa_ctl:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-07-08 18:03:35,69] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Starting chip.filter_ctl
[2018-07-08 18:03:35,73] [warn] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.filter_ctl:0:1]: Unrecognized runtime attribute keys: disks, cpu, time, memory
[2018-07-08 18:03:35,77] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.filter_ctl:0:1]: python $(which encode_filter.py) \
        /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a-4335-8c0e-a711391af811/call-filter_ctl/shard-0/inputs/1613485654/IgG.merged.bam \
         \
         \
        --dup-marker picard \
        --mapq-thresh 30 \
         \

# ugly part to deal with optional outputs with Google JES backend

touch null
[2018-07-08 18:03:35,88] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.filter_ctl:0:1]: executing: /bin/bash /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a                                -4335-8c0e-a711391af811/call-filter_ctl/shard-0/execution/script
[2018-07-08 18:03:36,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.filter_ctl:0:1]: job id: 1170
[2018-07-08 18:03:36,99] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.filter_ctl:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-07-08 18:07:57,26] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bwa:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-07-08 18:08:02,93] [info] WorkflowExecutionActor-068f45d8-f29a-4335-8c0e-a711391af811 [068f45d8]: Starting chip.bam2ta_no_filt, chip.filter
[2018-07-08 18:08:03,73] [warn] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bam2ta_no_filt:0:1]: Unrecognized runtime attribute keys: disks, cpu, time, memory
[2018-07-08 18:08:03,73] [warn] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.filter:0:1]: Unrecognized runtime attribute keys: disks, cpu, time, memory
[2018-07-08 18:08:03,74] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bam2ta_no_filt:0:1]: python $(which encode_bam2ta.py) \
        /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a-4335-8c0e-a711391af811/call-bam2ta_no_filt/shard-0/inputs/600163450/RYBP.merged.bam \
         \
        --disable-tn5-shift \
        --regex-grep-v-ta 'chrM' \
        --subsample 0 \
[2018-07-08 18:08:03,74] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bam2ta_no_filt:0:1]: executing: /bin/bash /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-                                f29a-4335-8c0e-a711391af811/call-bam2ta_no_filt/shard-0/execution/script
[2018-07-08 18:08:03,76] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.filter:0:1]: python $(which encode_filter.py) \
        /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a-4335-8c0e-a711391af811/call-filter/shard-0/inputs/600163450/RYBP.merged.bam \
         \
         \
        --dup-marker picard \
        --mapq-thresh 30 \
         \

# ugly part to deal with optional outputs with Google JES backend

touch null
[2018-07-08 18:08:03,77] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.filter:0:1]: executing: /bin/bash /home/chengwsh/Encode/chip-seq-pipeline2/cromwell-executions/chip/068f45d8-f29a-433                                5-8c0e-a711391af811/call-filter/shard-0/execution/script
[2018-07-08 18:08:06,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bam2ta_no_filt:0:1]: job id: 2502
[2018-07-08 18:08:06,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.filter:0:1]: job id: 2516
[2018-07-08 18:08:06,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bam2ta_no_filt:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-07-08 18:08:06,97] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.filter:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-07-08 18:10:26,92] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.bam2ta_no_filt:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-07-08 18:11:32,77] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.filter_ctl:0:                                                                                                                                        1]: Status change from WaitingForReturnCodeFile to Done
[2018-07-08 18:16:25,24] [info] BackgroundConfigAsyncJobExecutionActor [068f45d8chip.filter:0:1]:                                                                                                                                         Status change from WaitingForReturnCodeFile to Done
[2018-07-08 18:16:26,14] [error] WorkflowManagerActor Workflow 068f45d8-f29a-4335-8c0e-a711391af81                                                                                                                                        1 failed (during ExecutingWorkflowState): Failed to evaluate job outputs:
Bad output 'filter_ctl.nodup_bai': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'filter_ctl.flagstat_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'filter_ctl.dup_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'filter_ctl.pbc_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
cromwell.backend.standard.StandardAsyncExecutionActor$$anon$2: Failed to evaluate job outputs:
Bad output 'filter_ctl.nodup_bai': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'filter_ctl.flagstat_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'filter_ctl.dup_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'filter_ctl.pbc_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
        at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionSuccess$1                                                                                                                                        (StandardAsyncExecutionActor.scala:786)
        at scala.util.Success.$anonfun$map$1(Try.scala:251)
        at scala.util.Success.map(Try.scala:209)
        at scala.concurrent.Future.$anonfun$map$1(Future.scala:288)
        at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)
        at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)
        at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)
        at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
        at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)
        at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
        at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)
        at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)
        at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
        at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfig                                                                                                                                        urator.scala:43)
        at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
        at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
        at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
        at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)

Failed to evaluate job outputs:
Bad output 'filter.nodup_bai': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'filter.flagstat_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'filter.dup_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'filter.pbc_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
cromwell.backend.standard.StandardAsyncExecutionActor$$anon$2: Failed to evaluate job outputs:
Bad output 'filter.nodup_bai': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'filter.flagstat_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'filter.dup_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'filter.pbc_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
        at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionSuccess$1                                                                                                                                        (StandardAsyncExecutionActor.scala:786)
        at scala.util.Success.$anonfun$map$1(Try.scala:251)
        at scala.util.Success.map(Try.scala:209)
        at scala.concurrent.Future.$anonfun$map$1(Future.scala:288)
        at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)
        at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)
        at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)
        at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
        at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)
        at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
        at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)
        at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)
        at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
        at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfig                                                                                                                                        urator.scala:43)
        at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
        at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
        at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
        at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)

[2018-07-08 18:16:26,14] [info] WorkflowManagerActor WorkflowActor-068f45d8-f29a-4335-8c0e-a711391                                                                                                                                        af811 is in a terminal state: WorkflowFailedState
[2018-07-08 18:17:28,68] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.
[2018-07-08 18:17:31,99] [info] Workflow polling stopped
[2018-07-08 18:17:32,12] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds
[2018-07-08 18:17:32,12] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds
[2018-07-08 18:17:32,15] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds
[2018-07-08 18:17:32,17] [info] Aborting all running workflows.
[2018-07-08 18:17:32,19] [info] JobExecutionTokenDispenser stopped
[2018-07-08 18:17:32,19] [info] WorkflowStoreActor stopped
[2018-07-08 18:17:32,24] [info] WorkflowLogCopyRouter stopped
[2018-07-08 18:17:32,24] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds
[2018-07-08 18:17:32,24] [info] WorkflowManagerActor stopped
[2018-07-08 18:17:32,24] [info] WorkflowManagerActor All workflows finished
[2018-07-08 18:17:32,24] [info] Connection pools shut down
[2018-07-08 18:17:32,24] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds
[2018-07-08 18:17:32,24] [info] Shutting down JobStoreActor - Timeout = 1800 seconds
[2018-07-08 18:17:32,24] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds
[2018-07-08 18:17:32,24] [info] SubWorkflowStoreActor stopped
[2018-07-08 18:17:32,24] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds
[2018-07-08 18:17:32,24] [info] Shutting down DockerHashActor - Timeout = 1800 seconds
[2018-07-08 18:17:32,24] [info] Shutting down IoProxy - Timeout = 1800 seconds
[2018-07-08 18:17:32,27] [info] DockerHashActor stopped
[2018-07-08 18:17:32,27] [info] IoProxy stopped
[2018-07-08 18:17:32,30] [info] KvWriteActor Shutting down: 0 queued messages to process
[2018-07-08 18:17:32,30] [info] WriteMetadataActor Shutting down: 0 queued messages to process
[2018-07-08 18:17:32,30] [info] CallCacheWriteActor Shutting down: 0 queued messages to process
[2018-07-08 18:17:32,30] [info] CallCacheWriteActor stopped
[2018-07-08 18:17:32,33] [info] JobStoreActor stopped
[2018-07-08 18:17:32,34] [info] ServiceRegistryActor stopped
[2018-07-08 18:17:32,36] [info] Database closed
[2018-07-08 18:17:32,36] [info] Stream materializer shut down
Workflow 068f45d8-f29a-4335-8c0e-a711391af811 transitioned to state Failed
[2018-07-08 18:17:32,46] [info] Automatic shutdown of the async connection
[2018-07-08 18:17:32,46] [info] Gracefully shutdown sentry threads.
[2018-07-08 18:17:32,46] [info] Shutdown finished.",chengwsh,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/15
MDU6SXNzdWUzNDIzODQzMzU=,Bad output 'qc_report.qc_json_match',CLOSED,2018-07-18T15:39:32Z,2019-09-09T22:04:26Z,2019-09-09T22:04:26Z,"**Describe the bug**

This is a bug that pops up at the end of the pipeline run:

```
[2018-07-18 14:31:17,39] [info] PipelinesApiAsyncBackendJobExecutionActor [eca1fbc4chip.qc_report:NA:1]: Status change from Running to Success
[2018-07-18 14:31:19,33] [error] WorkflowManagerActor Workflow eca1fbc4-8be6-4401-90c4-8af43c017326 failed (during ExecutingWorkflowState): cromwell.backend.standard.StandardAsyncExecutionActor$$anon$2: Failed to evaluate job outputs:
Bad output 'qc_report.qc_json_match': java.nio.file.NoSuchFileException: gs://workflow-challenge/vanessasaurus/chip/eca1fbc4-8be6-4401-90c4-8af43c017326/call-qc_report/qc_json_match.txt
    at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionSuccess$1(StandardAsyncExecutionActor.scala:824)
    at scala.util.Success.$anonfun$map$1(Try.scala:251)
    at scala.util.Success.map(Try.scala:209)
    at scala.concurrent.Future.$anonfun$map$1(Future.scala:288)
    at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)
    at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)
    at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)
    at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
    at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)
    at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
    at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)
    at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)
    at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
    at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43)
    at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
    at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
    at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
    at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
```

**OS/Platform and dependencies**
Google Cloud, run via a Docker Container, per instructions here -->

https://vsoch.github.io/wdl-pipelines/pipeline-chip-seq

**Attach logs**
The run, by way of a container, exited after finish so there aren't any logs. This should probably be advised to do as a bind to the container so they persist when it poops out.
",vsoch,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/16
MDU6SXNzdWUzNTIyNTg4NDI=,No access to quay.io/encode-dcc/chip-seq-pipeline2:v1,CLOSED,2018-08-20T19:07:26Z,2019-09-09T22:05:57Z,2019-09-09T22:05:57Z,"403: Unauthorized
You are not authorized to view this resource",ZhifeiLuo,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/17
MDU6SXNzdWUzNTc4NDYzMDA=,split into subworkflows,CLOSED,2018-09-06T22:08:30Z,2019-09-09T22:06:12Z,2019-09-09T22:06:12Z,"As you try to make it work with any input time possible the chip.wdl is a big mess and hard to deal with, I suggest that you make chip.wdl as a wrapper that deals with different types of intputs and then redirects execution to proper subworkflows depending on input types.",antonkulaga,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/20
MDU6SXNzdWUzNjAzNjUwODA=,Failed to access â€˜*.jsd.qcâ€™ (ENCSR936XTK test sample),CLOSED,2018-09-14T16:04:31Z,2019-01-31T21:21:22Z,2019-01-31T21:21:22Z,"When attempting to run AQUAS on the test sample datasets (ENCSR936XTK FASTQs), I receive:

`[2018-09-13 15:32:39,95] [error] WorkflowManagerActor Workflow 0846c6f1-989d-4622-8512-b1aebfb5ea97 failed (during ExecutingWorkflowState): Job chip.fingerprint:NA:1 exited with return code 1 which has not been declared as a valid return code.`

which seems to arise from

`ln: failed to access â€˜*.jsd.qcâ€™: No such file or directory`.

Any suggestions would be greatly appreciated. Thank you!

**Details:**
I installed AQUAS on a SGE cluster.
**Cromwell:** cromwell-34
**Conda:** conda 4.3.30

[debug_22.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2384060/debug_22.tar.gz)",dcdxy,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/22
MDU6SXNzdWUzNjI0NTk4NjY=,How to build other genome besides human and mouse ,CLOSED,2018-09-21T05:25:05Z,2018-09-25T14:00:22Z,2018-09-25T14:00:22Z,"**Describe the bug**
A clear and concise description of what the problem is.

**OS/Platform and dependencies**
- OS or Platform: [e.g. Ubuntu 16.04, Google Cloud, Stanford Sherlock/SCG cluster, ...]
- Cromwell/dxWDL version: [e.g. cromwell-30, dxWDL-60.2]
- Conda version: If you have used Conda.

**Attach logs**
For Cromwell users only.

1) Move to your working directory where you ran a pipeline. You should be able to find a directory named `cromwell-executions/` which includes all outputs and logs for debugging.

2) Run the following command to collect all logs. For developer's convenience, please add `[ISSUE_ID]` to the name of the tar ball file. This command will generate a tar ball including all debugging information.
```
$ find . -type f -name 'stdout' -or -name 'stderr' -or -name 'script' -or \
-name '*.qc' -or -name '*.txt' -or -name '*.log' -or -name '*.png' -or -name '*.pdf' \
| xargs tar -zcvf debug_[ISSUE_ID].tar.gz
```

3) Post an issue with the tar ball (`.tar.gz`) attached.
",YutingPKU,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/23
MDU6SXNzdWUzNjI1ODg0MzA=,Error during running the test data,CLOSED,2018-09-21T12:12:32Z,2018-09-22T04:37:23Z,2018-09-22T04:37:23Z,"OS or Platform: CentOS Linux release 7.4.1708
Cromwell/dxWDL version: cromwell-34.jar
Conda version: conda 4.3.30

I am trying to run the chip-seq pipeline on the test data (ENCSR936XTK) as per the SGE installation guidelines. I get the same error for 

`[2018-09-20 14:56:32,34] [error] WorkflowManagerActor Workflow 6e1aee94-5c4d-451d-99c3-5ae5990a7548 failed (during ExecutingWorkflowState): Job chip.xcor:0:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.`

which is related to this 

`Traceback (most recent call last):
  File ""~/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_common.py"", line 224, in run_shell_cmd
    p.returncode, cmd)
subprocess.CalledProcessError: Command 'Rscript --max-ppsize=500000 $(which run_spp.R) -rf -c=rep2-R1.subsampled.67.merged.trim_50bp.no_chrM.15.0M.tagAlign.gz -p=2 -filtchr=chrM -savp=rep2-R1.subsampled.67.merged.trim_50bp.no_chrM.15.0M.cc.plot.pdf -out=rep2-R1.subsampled.67.merged.trim_50bp.no_chrM.15.0M.cc.qc ' returned non-zero exit status 1`

I have attached the debug files here.
[debug_22.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2402736/debug_22.tar.gz)

I am working on SGE and ran the command using cromwell-34.jar.

_Originally posted by @shanmukhasampath in https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/22#issuecomment-423302664_",shanmukhasampath,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/24
MDU6SXNzdWUzNjQ5Nzk4MDM=,Can we still run this pipeline with bam file as input?,CLOSED,2018-09-28T17:38:13Z,2018-09-28T19:07:09Z,2018-09-28T19:07:09Z,As title. Thanks!,mkmwong,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/27
MDU6SXNzdWUzNjUwNDg3MTM=,call-spp_ppr1 wall time exceeds 48h,CLOSED,2018-09-28T21:35:04Z,2018-09-28T21:53:26Z,2018-09-28T21:53:26Z,"Hi,

I'm running the pipeline on the test data on slurm. I encountered the problem that when call-spp_ppr1 script is being submitted, the request wall-time is 72 hours. Can this be lowered somehow? I looked at the input.json and it doesn't look like we could change the wall-time for this particular thing?",mkmwong,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/28
MDU6SXNzdWUzNjgzMTc2OTM=,Questions re. 1)IDR and 2)broad peaks,CLOSED,2018-10-09T17:30:14Z,2019-02-19T00:14:26Z,2018-10-17T05:57:17Z,"Hi guys,
It's more of a question - not an issue, hope that's ok:
I'm using your pipeline to look at some of the published ChIP results, and most are unreplicated. From what I noticed and understand is that the pipeline will in most cases still run the self-consistency IDR with pseudoreplicates and so on, but it doesn't always do that and sometimes returns just overlap (?) between replicate and pseudoreplicate without attempting IDR? Would it be possible for you to explain when one vs the other happens?
And second thing - what would you recommend in case of ChIPs that give 'broad' signals, like h3k27me3 seems to, or mixed like Pol2 apparently does? Is there a way to adjust the peak calling parameters etc?",jusu-E404,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/30
MDU6SXNzdWUzNjkyMzUzNTI=,Bad output 'macs2.bfilt_npeak': Failed to find index Success(WomInteger(0)) on array,CLOSED,2018-10-11T17:52:18Z,2018-10-25T23:46:43Z,2018-10-25T23:46:43Z,"I have run this pipeline with deduplicated bam as input and that worked. However, when I ran with fastq.gz as input, I encounter following error: 

[2018-10-10 15:34:55,23] [info] Running with database db.url = jdbc:hsqldb:mem:ecd30a73-9553-4e46-8424-5f4227afb55b;shutdown=false;hsqldb.tx=mvcc
[2018-10-10 15:35:05,14] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000
[2018-10-10 15:35:05,16] [info] [RenameWorkflowOptionsInMetadata] 100%
[2018-10-10 15:35:05,26] [info] Running with database db.url = jdbc:hsqldb:mem:1170c126-8f24-448b-99cb-8c3254c2f7dc;shutdown=false;hsqldb.tx=mvcc
[2018-10-10 15:35:05,66] [[38;5;220mwarn[0m] This actor factory is deprecated. Please use cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory for PAPI v1 or cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory for PAPI v2
[2018-10-10 15:35:05,66] [[38;5;220mwarn[0m] Couldn't find a suitable DSN, defaulting to a Noop one.
[2018-10-10 15:35:05,67] [info] Using noop to send events.
[2018-10-10 15:35:05,97] [info] Slf4jLogger started
[2018-10-10 15:35:06,27] [info] Workflow heartbeat configuration:
{
  ""cromwellId"" : ""cromid-bac7c2f"",
  ""heartbeatInterval"" : ""2 minutes"",
  ""ttl"" : ""10 minutes"",
  ""writeBatchSize"" : 10000,
  ""writeThreshold"" : 10000
}
[2018-10-10 15:35:06,42] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.
[2018-10-10 15:35:06,45] [info] Metadata summary refreshing every 2 seconds.
[2018-10-10 15:35:06,47] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.
[2018-10-10 15:35:06,52] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.
[2018-10-10 15:35:07,62] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.
[2018-10-10 15:35:07,66] [info] SingleWorkflowRunnerActor: Version 34
[2018-10-10 15:35:07,68] [info] SingleWorkflowRunnerActor: Submitting workflow
[2018-10-10 15:35:07,72] [info] PAPIQueryManager Running with 3 workers
[2018-10-10 15:35:07,72] [info] JES batch polling interval is 33333 milliseconds
[2018-10-10 15:35:07,72] [info] JES batch polling interval is 33333 milliseconds
[2018-10-10 15:35:07,73] [info] JES batch polling interval is 33333 milliseconds
[2018-10-10 15:35:07,82] [info] Unspecified type (Unspecified version) workflow f99b0390-cc7a-43a0-a7fa-294cf7d512af submitted
[2018-10-10 15:35:07,88] [info] SingleWorkflowRunnerActor: Workflow submitted [38;5;2mf99b0390-cc7a-43a0-a7fa-294cf7d512af[0m
[2018-10-10 15:35:07,88] [info] 1 new workflows fetched
[2018-10-10 15:35:07,88] [info] WorkflowManagerActor Starting workflow [38;5;2mf99b0390-cc7a-43a0-a7fa-294cf7d512af[0m
[2018-10-10 15:35:07,90] [info] WorkflowManagerActor Successfully started WorkflowActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af
[2018-10-10 15:35:07,90] [info] Retrieved 1 workflows from the WorkflowStoreActor
[2018-10-10 15:35:07,91] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.
[2018-10-10 15:35:07,92] [[38;5;220mwarn[0m] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData
[2018-10-10 15:35:08,03] [info] MaterializeWorkflowDescriptorActor [[38;5;2mf99b0390[0m]: Parsing workflow as WDL draft-2
[2018-10-10 15:35:39,69] [info] MaterializeWorkflowDescriptorActor [[38;5;2mf99b0390[0m]: Call-to-Backend assignments: chip.overlap_ppr -> slurm, chip.bam2ta -> slurm, chip.qc_report -> slurm, chip.filter_ctl -> slurm, chip.idr_ppr -> slurm, chip.macs2_ppr2 -> slurm, chip.choose_ctl -> slurm, chip.fingerprint -> slurm, chip.xcor -> slurm, chip.spp_pooled -> slurm, chip.overlap_pr -> slurm, chip.spp_ppr1 -> slurm, chip.bam2ta_no_filt -> slurm, chip.macs2 -> slurm, chip.pool_ta_ctl -> slurm, chip.spp -> slurm, chip.merge_fastq_ctl -> slurm, chip.fraglen_mean -> slurm, chip.idr -> slurm, chip.pool_ta -> slurm, chip.overlap -> slurm, chip.read_genome_tsv -> slurm, chip.reproducibility_overlap -> slurm, chip.filter -> slurm, chip.macs2_pr1 -> slurm, chip.merge_fastq -> slurm, chip.idr_pr -> slurm, chip.spr -> slurm, chip.bam2ta_ctl -> slurm, chip.macs2_pr2 -> slurm, chip.macs2_ppr1 -> slurm, chip.macs2_pooled -> slurm, chip.pool_ta_pr2 -> slurm, chip.spp_pr1 -> slurm, chip.bwa -> slurm, chip.bam2ta_no_filt_R1 -> slurm, chip.spp_ppr2 -> slurm, chip.bwa_R1 -> slurm, chip.trim_fastq -> slurm, chip.bwa_ctl -> slurm, chip.pool_ta_pr1 -> slurm, chip.spp_pr2 -> slurm, chip.reproducibility_idr -> slurm
[2018-10-10 15:35:39,84] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,85] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,85] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,85] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,85] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,85] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,85] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,85] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,85] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,85] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,85] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,86] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:39,87] [[38;5;220mwarn[0m] slurm [[38;5;2mf99b0390[0m]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
[2018-10-10 15:35:42,12] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.read_genome_tsv
[2018-10-10 15:35:42,13] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition met: '!align_only && !true_rep_only'. Running conditional section
[2018-10-10 15:35:42,13] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition met: '!true_rep_only'. Running conditional section
[2018-10-10 15:35:42,74] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.read_genome_tsv:NA:1]: Unrecognized runtime attribute keys: disks
[2018-10-10 15:35:43,20] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: 'enable_idr'. Bypassing conditional section
[2018-10-10 15:35:43,22] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: 'peak_caller_ == ""spp""'. Bypassing conditional section
[2018-10-10 15:35:43,22] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition met: 'peak_caller_ == ""macs2""'. Running conditional section
[2018-10-10 15:35:43,22] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: '!align_only && !true_rep_only && enable_idr'. Bypassing conditional section
[2018-10-10 15:35:43,22] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: 'enable_idr'. Bypassing conditional section
[2018-10-10 15:35:43,22] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: 'peak_caller_ == ""spp""'. Bypassing conditional section
[2018-10-10 15:35:43,41] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.read_genome_tsv:NA:1]: [38;5;5mcat /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-read_genome_tsv/inputs/58336912/hg19.tsv[0m
[2018-10-10 15:35:43,49] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.read_genome_tsv:NA:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_read_genome_tsv \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-read_genome_tsv \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-read_genome_tsv/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-read_genome_tsv/execution/stderr \
-t 60 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=1 \
--mem=4000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-read_genome_tsv/execution/script""
[2018-10-10 15:35:46,30] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.merge_fastq_ctl, chip.merge_fastq
[2018-10-10 15:35:46,47] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.read_genome_tsv:NA:1]: job id: 28445729
[2018-10-10 15:35:46,47] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.read_genome_tsv:NA:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 15:35:46,64] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.merge_fastq:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-10 15:35:46,65] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.merge_fastq_ctl:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-10 15:35:46,72] [[38;5;220mwarn[0m] Localization via hard link has failed: /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq_ctl/shard-0/inputs/661839578/SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R1.fastq.gz -> /scratch/users/mkmwong/RbKO_WT_ChIP/allFastq/original/SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R1.fastq.gz: Invalid cross-device link
[2018-10-10 15:35:46,72] [[38;5;220mwarn[0m] Localization via hard link has failed: /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq/shard-0/inputs/661839578/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.fastq.gz -> /scratch/users/mkmwong/RbKO_WT_ChIP/allFastq/original/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.fastq.gz: Invalid cross-device link
[2018-10-10 15:35:46,74] [[38;5;220mwarn[0m] Localization via hard link has failed: /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq/shard-0/inputs/661839578/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R2.fastq.gz -> /scratch/users/mkmwong/RbKO_WT_ChIP/allFastq/original/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R2.fastq.gz: Invalid cross-device link
[2018-10-10 15:35:46,74] [[38;5;220mwarn[0m] Localization via hard link has failed: /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq_ctl/shard-0/inputs/661839578/SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R2.fastq.gz -> /scratch/users/mkmwong/RbKO_WT_ChIP/allFastq/original/SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R2.fastq.gz: Invalid cross-device link
[2018-10-10 15:35:46,79] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.merge_fastq:0:1]: [38;5;5mpython $(which encode_merge_fastq.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq/shard-0/execution/write_tsv_82e931bc7d1a525bafe0ce1331b4b615.tmp \
	--paired-end \
	--nth 2[0m
[2018-10-10 15:35:46,80] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.merge_fastq_ctl:0:1]: [38;5;5mpython $(which encode_merge_fastq.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq_ctl/shard-0/execution/write_tsv_5318eadf4f1e11ea3b195ca44b819fac.tmp \
	--paired-end \
	--nth 2[0m
[2018-10-10 15:35:46,81] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.merge_fastq:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_merge_fastq \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq/shard-0/execution/stderr \
-t 360 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=2 \
--mem=12000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq/shard-0/execution/script""
[2018-10-10 15:35:46,83] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.merge_fastq_ctl:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_merge_fastq_ctl \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq_ctl/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq_ctl/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq_ctl/shard-0/execution/stderr \
-t 360 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=2 \
--mem=12000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-merge_fastq_ctl/shard-0/execution/script""
[2018-10-10 15:35:51,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.merge_fastq:0:1]: job id: 28445734
[2018-10-10 15:35:51,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.merge_fastq_ctl:0:1]: job id: 28445732
[2018-10-10 15:35:51,47] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.merge_fastq:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 15:35:51,47] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.merge_fastq_ctl:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 15:37:11,58] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.merge_fastq:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-10 15:37:17,02] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.trim_fastq
[2018-10-10 15:37:17,64] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.trim_fastq:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-10 15:37:17,69] [[38;5;220mwarn[0m] Localization via hard link has failed: /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-trim_fastq/shard-0/inputs/-567840873/merge_fastqs_R1_SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.fastq.gz -> /scratch/users/mkmwong/RbKO_WT_ChIP/allFastq/original/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.fastq.gz: Invalid cross-device link
[2018-10-10 15:37:17,70] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.trim_fastq:0:1]: [38;5;5mpython $(which encode_trim_fastq.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-trim_fastq/shard-0/inputs/-567840873/merge_fastqs_R1_SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.fastq.gz \
	--trim-bp 50[0m
[2018-10-10 15:37:17,74] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.trim_fastq:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_trim_fastq \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-trim_fastq/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-trim_fastq/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-trim_fastq/shard-0/execution/stderr \
-t 60 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=1 \
--mem=8000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-trim_fastq/shard-0/execution/script""
[2018-10-10 15:37:21,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.trim_fastq:0:1]: job id: 28445811
[2018-10-10 15:37:21,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.trim_fastq:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 15:37:21,71] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.merge_fastq_ctl:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-10 15:37:42,59] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.read_genome_tsv:NA:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-10 15:37:45,57] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.bwa, chip.bwa_ctl
[2018-10-10 15:37:45,64] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa:0:1]: Unrecognized runtime attribute keys: preemptible, disks
[2018-10-10 15:37:45,64] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa_ctl:0:1]: Unrecognized runtime attribute keys: preemptible, disks
[2018-10-10 15:37:45,72] [[38;5;220mwarn[0m] Localization via hard link has failed: /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_ctl/shard-0/inputs/44672371/merge_fastqs_R1_SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R1.merged.fastq.gz -> /scratch/users/mkmwong/RbKO_WT_ChIP/allFastq/original/SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R1.fastq.gz: Invalid cross-device link
[2018-10-10 15:37:45,73] [[38;5;220mwarn[0m] Localization via hard link has failed: /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa/shard-0/inputs/-567840873/merge_fastqs_R1_SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.fastq.gz -> /scratch/users/mkmwong/RbKO_WT_ChIP/allFastq/original/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.fastq.gz: Invalid cross-device link
[2018-10-10 15:37:45,74] [[38;5;220mwarn[0m] Localization via hard link has failed: /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_ctl/shard-0/inputs/44672371/merge_fastqs_R2_SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R2.merged.fastq.gz -> /scratch/users/mkmwong/RbKO_WT_ChIP/allFastq/original/SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R2.fastq.gz: Invalid cross-device link
[2018-10-10 15:37:45,74] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa_ctl:0:1]: [38;5;5mpython $(which encode_bwa.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_ctl/shard-0/inputs/-1093316416/male.hg19.fa.tar \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_ctl/shard-0/inputs/44672371/merge_fastqs_R1_SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R1.merged.fastq.gz /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_ctl/shard-0/inputs/44672371/merge_fastqs_R2_SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R2.merged.fastq.gz \
	--paired-end \
	--nth 4[0m
[2018-10-10 15:37:45,75] [[38;5;220mwarn[0m] Localization via hard link has failed: /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa/shard-0/inputs/-567840873/merge_fastqs_R2_SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R2.merged.fastq.gz -> /scratch/users/mkmwong/RbKO_WT_ChIP/allFastq/original/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R2.fastq.gz: Invalid cross-device link
[2018-10-10 15:37:45,76] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa:0:1]: [38;5;5mpython $(which encode_bwa.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa/shard-0/inputs/-1093316416/male.hg19.fa.tar \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa/shard-0/inputs/-567840873/merge_fastqs_R1_SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.fastq.gz /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa/shard-0/inputs/-567840873/merge_fastqs_R2_SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R2.merged.fastq.gz \
	--paired-end \
	--nth 4[0m
[2018-10-10 15:37:45,78] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa_ctl:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_bwa_ctl \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_ctl/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_ctl/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_ctl/shard-0/execution/stderr \
-t 2880 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=4 \
--mem=20000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_ctl/shard-0/execution/script""
[2018-10-10 15:37:45,79] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_bwa \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa/shard-0/execution/stderr \
-t 2880 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=4 \
--mem=20000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa/shard-0/execution/script""
[2018-10-10 15:37:51,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa:0:1]: job id: 28445834
[2018-10-10 15:37:51,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa_ctl:0:1]: job id: 28445836
[2018-10-10 15:37:51,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa_ctl:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 15:37:51,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 15:49:55,18] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.trim_fastq:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-10 15:50:00,71] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.bwa_R1
[2018-10-10 15:50:01,64] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa_R1:0:1]: Unrecognized runtime attribute keys: preemptible, disks
[2018-10-10 15:50:01,74] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa_R1:0:1]: [38;5;5mpython $(which encode_bwa.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_R1/shard-0/inputs/-1093316416/male.hg19.fa.tar \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_R1/shard-0/inputs/913187384/merge_fastqs_R1_SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.trim_50bp.fastq.gz \
	 \
	--nth 4[0m
[2018-10-10 15:50:01,77] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa_R1:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_bwa_R1 \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_R1/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_R1/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_R1/shard-0/execution/stderr \
-t 2880 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=4 \
--mem=20000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bwa_R1/shard-0/execution/script""
[2018-10-10 15:50:06,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa_R1:0:1]: job id: 28447299
[2018-10-10 15:50:06,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa_R1:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 16:34:37,99] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa_R1:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-10 16:34:40,06] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.bam2ta_no_filt_R1
[2018-10-10 16:34:40,64] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_no_filt_R1:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-10 16:34:40,71] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_no_filt_R1:0:1]: [38;5;5mpython $(which encode_bam2ta.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_no_filt_R1/shard-0/inputs/-55055628/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.trim_50bp.bam \
	 \
	--disable-tn5-shift \
	--regex-grep-v-ta 'chrM' \
	--subsample 0 \[0m
[2018-10-10 16:34:40,75] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_no_filt_R1:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_bam2ta_no_filt_R1 \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_no_filt_R1/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_no_filt_R1/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_no_filt_R1/shard-0/execution/stderr \
-t 360 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=2 \
--mem=10000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_no_filt_R1/shard-0/execution/script""
[2018-10-10 16:34:41,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_no_filt_R1:0:1]: job id: 28451098
[2018-10-10 16:34:41,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_no_filt_R1:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 16:40:22,98] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_no_filt_R1:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-10 20:41:30,97] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-10 20:41:36,17] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.filter, chip.bam2ta_no_filt
[2018-10-10 20:41:36,64] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_no_filt:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-10 20:41:36,69] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.filter:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-10 20:41:36,75] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.filter:0:1]: [38;5;5mpython $(which encode_filter.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-filter/shard-0/inputs/1119499152/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.bam \
	--paired-end \
	 \
	--dup-marker picard \
	--mapq-thresh 30 \
	 \
	
# ugly part to deal with optional outputs with Google JES backend

touch null[0m
[2018-10-10 20:41:36,76] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_no_filt:0:1]: [38;5;5mpython $(which encode_bam2ta.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_no_filt/shard-0/inputs/1119499152/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.bam \
	--paired-end \
	--disable-tn5-shift \
	--regex-grep-v-ta 'chrM' \
	--subsample 0 \[0m
[2018-10-10 20:41:36,79] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_no_filt:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_bam2ta_no_filt \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_no_filt/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_no_filt/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_no_filt/shard-0/execution/stderr \
-t 360 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=2 \
--mem=10000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_no_filt/shard-0/execution/script""
[2018-10-10 20:41:36,81] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.filter:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_filter \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-filter/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-filter/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-filter/shard-0/execution/stderr \
-t 1440 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=2 \
--mem=20000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-filter/shard-0/execution/script""
[2018-10-10 20:41:41,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_no_filt:0:1]: job id: 28469190
[2018-10-10 20:41:41,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.filter:0:1]: job id: 28469189
[2018-10-10 20:41:41,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.filter:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 20:41:41,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_no_filt:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 21:26:40,43] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_no_filt:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-10 22:34:18,23] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.filter:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-10 22:34:23,63] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.bam2ta
[2018-10-10 22:34:24,62] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-10 22:34:24,70] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta:0:1]: [38;5;5mpython $(which encode_bam2ta.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta/shard-0/inputs/-1132106790/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.nodup.bam \
	--paired-end \
	--disable-tn5-shift \
	--regex-grep-v-ta 'chrM' \
	--subsample 0 \[0m
[2018-10-10 22:34:24,73] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_bam2ta \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta/shard-0/execution/stderr \
-t 360 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=2 \
--mem=10000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta/shard-0/execution/script""
[2018-10-10 22:34:26,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta:0:1]: job id: 28473079
[2018-10-10 22:34:26,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 23:00:31,64] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-10 23:00:34,78] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: '!true_rep_only && length(tas_) > 1 && peak_caller_ == ""macs2""'. Bypassing conditional section
[2018-10-10 23:00:34,78] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: '!true_rep_only && length(tas_) > 1'. Bypassing conditional section
[2018-10-10 23:00:34,78] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: 'length(tas_) > 1 && peak_caller_ == ""spp""'. Bypassing conditional section
[2018-10-10 23:00:34,78] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: 'length(tas_) > 1'. Bypassing conditional section
[2018-10-10 23:00:34,78] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: '!true_rep_only && length(tas_) > 1 && peak_caller_ == ""spp""'. Bypassing conditional section
[2018-10-10 23:00:34,78] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: '!true_rep_only && length(tas_) > 1 && peak_caller_ == ""spp""'. Bypassing conditional section
[2018-10-10 23:00:34,79] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: '!true_rep_only && length(tas_) > 1 && peak_caller_ == ""macs2""'. Bypassing conditional section
[2018-10-10 23:00:34,79] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: 'length(tas_) > 1'. Bypassing conditional section
[2018-10-10 23:00:36,84] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.xcor, chip.spr
[2018-10-10 23:00:37,64] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.spr:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-10 23:00:37,64] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.xcor:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-10 23:00:37,73] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.spr:0:1]: [38;5;5mpython $(which encode_spr.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-spr/shard-0/inputs/-922975244/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.nodup.tagAlign.gz \
	--paired-end[0m
[2018-10-10 23:00:37,73] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.xcor:0:1]: [38;5;5mpython $(which encode_xcor.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-xcor/shard-0/inputs/-155087896/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.trim_50bp.tagAlign.gz \
	 \
	--subsample 15000000 \
	--nth 2[0m
[2018-10-10 23:00:37,76] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.spr:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_spr \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-spr/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-spr/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-spr/shard-0/execution/stderr \
-t 60 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=1 \
--mem=16000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-spr/shard-0/execution/script""
[2018-10-10 23:00:37,77] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.xcor:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_xcor \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-xcor/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-xcor/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-xcor/shard-0/execution/stderr \
-t 360 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=2 \
--mem=16000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-xcor/shard-0/execution/script""
[2018-10-10 23:00:41,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.xcor:0:1]: job id: 28475398
[2018-10-10 23:00:41,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.spr:0:1]: job id: 28475397
[2018-10-10 23:00:41,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.xcor:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 23:00:41,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.spr:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 23:06:01,11] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.spr:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-10 23:20:11,72] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.xcor:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-10 23:20:15,40] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.fraglen_mean
[2018-10-10 23:20:15,63] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.fraglen_mean:NA:1]: Unrecognized runtime attribute keys: disks
[2018-10-10 23:20:15,66] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.fraglen_mean:NA:1]: [38;5;5mpython <<CODE
arr = [-5]
if len(arr):
    sum_ = sum(arr)
    mean_ = sum(arr)/float(len(arr))
    print(int(round(mean_)))
else:
    print(0)
CODE[0m
[2018-10-10 23:20:15,69] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.fraglen_mean:NA:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_fraglen_mean \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-fraglen_mean \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-fraglen_mean/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-fraglen_mean/execution/stderr \
-t 60 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=1 \
--mem=4000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-fraglen_mean/execution/script""
[2018-10-10 23:20:21,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.fraglen_mean:NA:1]: job id: 28476124
[2018-10-10 23:20:21,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.fraglen_mean:NA:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-10 23:22:22,12] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.fraglen_mean:NA:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-11 00:22:07,64] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bwa_ctl:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-11 00:22:13,31] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.filter_ctl
[2018-10-11 00:22:13,63] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.filter_ctl:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-11 00:22:13,71] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.filter_ctl:0:1]: [38;5;5mpython $(which encode_filter.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-filter_ctl/shard-0/inputs/42388076/SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R1.merged.bam \
	--paired-end \
	 \
	--dup-marker picard \
	--mapq-thresh 30 \
	 \
	
# ugly part to deal with optional outputs with Google JES backend

touch null[0m
[2018-10-11 00:22:13,75] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.filter_ctl:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_filter_ctl \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-filter_ctl/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-filter_ctl/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-filter_ctl/shard-0/execution/stderr \
-t 1440 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=2 \
--mem=20000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-filter_ctl/shard-0/execution/script""
[2018-10-11 00:22:16,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.filter_ctl:0:1]: job id: 28479287
[2018-10-11 00:22:16,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.filter_ctl:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-11 03:16:26,86] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.filter_ctl:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-11 03:16:30,91] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition NOT met: '!no_jsd && length(nodup_bams_) > 0 && length(ctl_nodup_bams_) > 0 && basename(blacklist) != ""null""'. Bypassing conditional section
[2018-10-11 03:16:32,95] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.bam2ta_ctl
[2018-10-11 03:16:33,62] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_ctl:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-11 03:16:33,70] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_ctl:0:1]: [38;5;5mpython $(which encode_bam2ta.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_ctl/shard-0/inputs/-1207382602/SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R1.merged.nodup.bam \
	--paired-end \
	--disable-tn5-shift \
	--regex-grep-v-ta 'chrM' \
	--subsample 0 \[0m
[2018-10-11 03:16:33,73] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_ctl:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_bam2ta_ctl \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_ctl/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_ctl/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_ctl/shard-0/execution/stderr \
-t 360 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=2 \
--mem=10000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-bam2ta_ctl/shard-0/execution/script""
[2018-10-11 03:16:36,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_ctl:0:1]: job id: 28483144
[2018-10-11 03:16:36,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_ctl:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-11 03:47:39,16] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.bam2ta_ctl:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-11 03:47:42,63] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition met: 'length(tas_) > 0 && length(ctl_tas_) > 0'. Running conditional section
[2018-10-11 03:47:42,63] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Condition met: 'length(ctl_tas_) > 0'. Running conditional section
[2018-10-11 03:47:44,66] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.pool_ta_ctl
[2018-10-11 03:47:45,62] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.pool_ta_ctl:NA:1]: Unrecognized runtime attribute keys: disks
[2018-10-11 03:47:45,68] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.pool_ta_ctl:NA:1]: [38;5;5mpython $(which encode_pool_ta.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-pool_ta_ctl/inputs/1500631376/SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R1.merged.nodup.tagAlign.gz[0m
[2018-10-11 03:47:45,71] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.pool_ta_ctl:NA:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_pool_ta_ctl \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-pool_ta_ctl \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-pool_ta_ctl/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-pool_ta_ctl/execution/stderr \
-t 60 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=1 \
--mem=4000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-pool_ta_ctl/execution/script""
[2018-10-11 03:47:46,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.pool_ta_ctl:NA:1]: job id: 28485165
[2018-10-11 03:47:46,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.pool_ta_ctl:NA:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-11 03:50:16,49] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.pool_ta_ctl:NA:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-11 03:50:18,63] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.choose_ctl
[2018-10-11 03:50:19,62] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.choose_ctl:NA:1]: Unrecognized runtime attribute keys: disks
[2018-10-11 03:50:19,74] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.choose_ctl:NA:1]: [38;5;5mpython $(which encode_choose_ctl.py) \
	--tas /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-choose_ctl/inputs/-922975244/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.nodup.tagAlign.gz \
	--ctl-tas /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-choose_ctl/inputs/1500631376/SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R1.merged.nodup.tagAlign.gz \
	 \
	--ctl-ta-pooled /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-choose_ctl/inputs/311943167/SCGPM_RbWTK9K27_HTYFT_L7_CTTGTA_R1.merged.nodup.tagAlign.gz \
	--always-use-pooled-ctl \
	--ctl-depth-ratio 1.2[0m
[2018-10-11 03:50:19,78] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.choose_ctl:NA:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_choose_ctl \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-choose_ctl \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-choose_ctl/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-choose_ctl/execution/stderr \
-t 60 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=1 \
--mem=8000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-choose_ctl/execution/script""
[2018-10-11 03:50:21,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.choose_ctl:NA:1]: job id: 28485274
[2018-10-11 03:50:21,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.choose_ctl:NA:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-11 03:52:47,47] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.choose_ctl:NA:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-11 03:52:51,57] [info] WorkflowExecutionActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af [[38;5;2mf99b0390[0m]: Starting chip.macs2, chip.macs2_pr2, chip.macs2_pr1
[2018-10-11 03:52:51,63] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-11 03:52:51,64] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2_pr2:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-11 03:52:51,64] [[38;5;220mwarn[0m] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2_pr1:0:1]: Unrecognized runtime attribute keys: disks
[2018-10-11 03:52:52,44] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2:0:1]: [38;5;5mpython $(which encode_macs2_chip.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2/shard-0/inputs/-922975244/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.nodup.tagAlign.gz /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2/shard-0/inputs/-1900987009/ctl_for_rep1.tagAlign.gz \
	--gensz hs \
	--chrsz /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2/shard-0/inputs/58336912/hg19.chrom.sizes \
	--fraglen -5 \
	--cap-num-peak 500000 \
	--pval-thresh 0.01 \
	--make-signal \
	--blacklist /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2/shard-0/inputs/58336912/wgEncodeDacMapabilityConsensusExcludable.bed.gz


touch null # ugly part to deal with optional outputs[0m
[2018-10-11 03:52:52,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2_pr2:0:1]: [38;5;5mpython $(which encode_macs2_chip.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr2/shard-0/inputs/-303265875/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.nodup.pr2.tagAlign.gz /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr2/shard-0/inputs/-1900987009/ctl_for_rep1.tagAlign.gz \
	--gensz hs \
	--chrsz /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr2/shard-0/inputs/58336912/hg19.chrom.sizes \
	--fraglen -5 \
	--cap-num-peak 500000 \
	--pval-thresh 0.01 \
	 \
	--blacklist /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr2/shard-0/inputs/58336912/wgEncodeDacMapabilityConsensusExcludable.bed.gz

touch null.pval.signal.bigwig null.fc.signal.bigwig
touch null # ugly part to deal with optional outputs[0m
[2018-10-11 03:52:52,47] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2_pr1:0:1]: [38;5;5mpython $(which encode_macs2_chip.py) \
	/home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr1/shard-0/inputs/1660355428/SCGPM_RbWTK9K27_HTYFT_L7_TAGCTT_R1.merged.nodup.pr1.tagAlign.gz /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr1/shard-0/inputs/-1900987009/ctl_for_rep1.tagAlign.gz \
	--gensz hs \
	--chrsz /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr1/shard-0/inputs/58336912/hg19.chrom.sizes \
	--fraglen -5 \
	--cap-num-peak 500000 \
	--pval-thresh 0.01 \
	 \
	--blacklist /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr1/shard-0/inputs/58336912/wgEncodeDacMapabilityConsensusExcludable.bed.gz

touch null.pval.signal.bigwig null.fc.signal.bigwig
touch null # ugly part to deal with optional outputs[0m
[2018-10-11 03:52:52,48] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_macs2 \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2/shard-0/execution/stderr \
-t 1440 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=1 \
--mem=16000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2/shard-0/execution/script""
[2018-10-11 03:52:52,50] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2_pr2:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_macs2_pr2 \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr2/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr2/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr2/shard-0/execution/stderr \
-t 1440 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=1 \
--mem=16000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr2/shard-0/execution/script""
[2018-10-11 03:52:52,52] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2_pr1:0:1]: executing: sbatch \
--export=ALL \
-J cromwell_f99b0390_macs2_pr1 \
-D /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr1/shard-0 \
-o /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr1/shard-0/execution/stdout \
-e /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr1/shard-0/execution/stderr \
-t 1440 \
-n 1 \
--ntasks-per-node=1 \
--cpus-per-task=1 \
--mem=16000 \
 \
 \
 \
 \
--wrap ""/bin/bash /home/groups/ashbym/mandy/chip-seq-pipeline2/cromwell-executions/chip/f99b0390-cc7a-43a0-a7fa-294cf7d512af/call-macs2_pr1/shard-0/execution/script""
[2018-10-11 03:52:56,45] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2_pr1:0:1]: job id: 28485366
[2018-10-11 03:52:56,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2_pr2:0:1]: job id: 28485368
[2018-10-11 03:52:56,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2:0:1]: job id: 28485367
[2018-10-11 03:52:56,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2_pr1:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-11 03:52:56,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2_pr2:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-11 03:52:56,46] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2:0:1]: Status change from - to WaitingForReturnCodeFile
[2018-10-11 03:54:05,40] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2_pr1:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-11 03:54:19,71] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-11 03:54:30,01] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mf99b0390[0mchip.macs2_pr2:0:1]: Status change from WaitingForReturnCodeFile to Done
[2018-10-11 03:54:30,47] [[38;5;1merror[0m] WorkflowManagerActor Workflow f99b0390-cc7a-43a0-a7fa-294cf7d512af failed (during ExecutingWorkflowState): cromwell.backend.standard.StandardAsyncExecutionActor$$anon$2: Failed to evaluate job outputs:
Bad output 'macs2_pr1.npeak': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'macs2_pr1.bfilt_npeak': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'macs2_pr1.bfilt_npeak_bb': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'macs2_pr1.frip_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionSuccess$1(StandardAsyncExecutionActor.scala:839)
	at scala.util.Success.$anonfun$map$1(Try.scala:251)
	at scala.util.Success.map(Try.scala:209)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:288)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)

cromwell.backend.standard.StandardAsyncExecutionActor$$anon$2: Failed to evaluate job outputs:
Bad output 'macs2.npeak': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'macs2.bfilt_npeak': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'macs2.bfilt_npeak_bb': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'macs2.sig_pval': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'macs2.sig_fc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'macs2.frip_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionSuccess$1(StandardAsyncExecutionActor.scala:839)
	at scala.util.Success.$anonfun$map$1(Try.scala:251)
	at scala.util.Success.map(Try.scala:209)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:288)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)

cromwell.backend.standard.StandardAsyncExecutionActor$$anon$2: Failed to evaluate job outputs:
Bad output 'macs2_pr2.npeak': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'macs2_pr2.bfilt_npeak': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'macs2_pr2.bfilt_npeak_bb': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
Bad output 'macs2_pr2.frip_qc': Failed to find index Success(WomInteger(0)) on array:

Success([])

0
	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionSuccess$1(StandardAsyncExecutionActor.scala:839)
	at scala.util.Success.$anonfun$map$1(Try.scala:251)
	at scala.util.Success.map(Try.scala:209)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:288)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:29)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:29)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)
	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)

[2018-10-11 03:54:30,48] [info] WorkflowManagerActor WorkflowActor-f99b0390-cc7a-43a0-a7fa-294cf7d512af is in a terminal state: WorkflowFailedState
[2018-10-11 03:54:32,98] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.
[2018-10-11 03:54:36,49] [info] Workflow polling stopped
[2018-10-11 03:54:36,50] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds
[2018-10-11 03:54:36,51] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds
[2018-10-11 03:54:36,51] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds
[2018-10-11 03:54:36,51] [info] JobExecutionTokenDispenser stopped
[2018-10-11 03:54:36,51] [info] Aborting all running workflows.
[2018-10-11 03:54:36,51] [info] WorkflowStoreActor stopped
[2018-10-11 03:54:36,52] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds
[2018-10-11 03:54:36,52] [info] WorkflowLogCopyRouter stopped
[2018-10-11 03:54:36,52] [info] Connection pools shut down
[2018-10-11 03:54:36,52] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds
[2018-10-11 03:54:36,52] [info] Shutting down JobStoreActor - Timeout = 1800 seconds
[2018-10-11 03:54:36,52] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds
[2018-10-11 03:54:36,52] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds
[2018-10-11 03:54:36,52] [info] Shutting down DockerHashActor - Timeout = 1800 seconds
[2018-10-11 03:54:36,52] [info] Shutting down IoProxy - Timeout = 1800 seconds
[2018-10-11 03:54:36,52] [info] WorkflowManagerActor stopped
[2018-10-11 03:54:36,52] [info] DockerHashActor stopped
[2018-10-11 03:54:36,52] [info] IoProxy stopped
[2018-10-11 03:54:36,52] [info] CallCacheWriteActor Shutting down: 0 queued messages to process
[2018-10-11 03:54:36,52] [info] SubWorkflowStoreActor stopped
[2018-10-11 03:54:36,52] [info] CallCacheWriteActor stopped
[2018-10-11 03:54:36,52] [info] WorkflowManagerActor All workflows finished
[2018-10-11 03:54:36,52] [info] JobStoreActor stopped
[2018-10-11 03:54:36,53] [info] WriteMetadataActor Shutting down: 0 queued messages to process
[2018-10-11 03:54:36,53] [info] KvWriteActor Shutting down: 0 queued messages to process
[2018-10-11 03:54:36,54] [info] ServiceRegistryActor stopped
[2018-10-11 03:54:36,54] [info] Database closed
[2018-10-11 03:54:36,54] [info] Stream materializer shut down
Workflow f99b0390-cc7a-43a0-a7fa-294cf7d512af transitioned to state Failed
[2018-10-11 03:54:36,57] [info] Automatic shutdown of the async connection
[2018-10-11 03:54:36,57] [info] Gracefully shutdown sentry threads.
[2018-10-11 03:54:36,57] [info] Shutdown finished.


And here's the path after I activated conda environment:
/home/groups/ashbym/mandy/anaconda3/envs/encode-chip-seq-pipeline/bin:/home/users/mkmwong/perl5/bin:/share/software/user/open/perl/5.26.0/bin:/home/groups/ashbym/mandy/anaconda3/bin:/share/software/user/srcc/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/dell/srvadmin/bin:/opt/dell/srvadmin/iSM/bin:/home/groups/ashbym/mandy/.bds:/home/groups/ashbym/mandy/anaconda3/bin/samtools:/home/groups/ashbym/mandy/bowtie2-2.3.4.3-linux-x86_64:/home/groups/ashbym/mandy/bedtools2/bin:/home/groups/ashbym/mandy/sratoolkit.2.9.2-centos_linux64/bin:/home/users/mkmwong/bin:/home/users/mkmwong/localperl/bin

Thank you !",mkmwong,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/31
MDU6SXNzdWUzNzQxNDM3NzI=,Pipeline issue with call-bwa step,CLOSED,2018-10-25T21:39:59Z,2018-10-29T15:30:38Z,2018-10-29T15:30:38Z,"**Describe the bug**
Whenever I run the pipeline using raw fastq files as the input I get this error:
Exception: bwa index does not exists. Prefix = ~/cromwell-executions/chip/621c36a5-68e0-4ad4-b201-b5c477fb5cfc/call-bwa/shard-0/inputs/1499526/null
ln: failed to access â€˜*.bamâ€™: No such file or directory
ln: failed to access â€˜*.baiâ€™: No such file or directory
ln: failed to access â€˜*.flagstat.qcâ€™: No such file or directory

**OS/Platform and dependencies**
- CentOS 7.5, running SLURM scheduler
- cromwell-34
- Conda 4.5.11

**Attach logs**
[debug_33.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2516884/debug_33.tar.gz)
",Scubatuba99,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/33
MDU6SXNzdWUzNzQxNzYwMTQ=,Where to find reo1/rep2 signal track?,CLOSED,2018-10-25T23:52:08Z,2018-11-03T00:50:20Z,2018-11-03T00:50:20Z,"As topic. is it in call_macs-ppr1/2 or is it in call_macs-pr1/2? Inside all those folder, I can only fine null.fc.signal.bigwig, which is the size of 0.",mkmwong,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/34
MDU6SXNzdWUzNzU1NzY1ODA=,problem preventing xcor from running,CLOSED,2018-10-30T16:20:35Z,2019-09-09T22:15:10Z,2019-09-09T22:15:10Z,"I'm running the pipeline with one replicate and one control and I noticed that even when I include the ""disable.xcor"" parameter on the .json file it still tries to run it and it fails the run at the xcor step. I don't mind having to do the rest of qc stuff, I just was hoping to finish the pipeline so I won't have to do each step manually (or write my own pipeline/script).  I also have the ""true_reps_only"" parameter set to true, do they cancel each other out? 

**OS/Platform and dependencies**
- CentOS 7
- Cromwell-34
- conda version 4.5.11

**Attach logs**
[debug_36.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2530539/debug_36.tar.gz)
",Scubatuba99,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/36
MDU6SXNzdWUzODAyNjUzMjY=,Failed to access â€˜*.pr1.tagAlign.gzâ€™,CLOSED,2018-11-13T14:57:07Z,2018-11-13T17:22:39Z,2018-11-13T17:22:39Z,"I received the following error message on two separate runs of the TF pipeline (first with MACS2 peak calling on 3 WT replicate PE FASTQs, second with spp peak calling on 3 WT and 3 control PE FASTQs):

`[2018-11-12 16:41:57,70] [error] WorkflowManagerActor Workflow 3466d7a1-80d8-4d4a-b8ac-41f3fa027979 failed (during ExecutingWorkflowState): Job chip.spr:1:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.`

which arises from:

```
ln: failed to access â€˜*.pr1.tagAlign.gzâ€™: No such file or directory
ln: failed to access â€˜*.pr2.tagAlign.gzâ€™: No such file or directory
```
Any help would be appreciated.

**Details:**
I installed AQUAS on a SGE cluster.
**Cromwell:** cromwell 34-unknown-SNAP
**Conda:** conda 4.3.30

**Logs:** [debug_37.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2576747/debug_37.tar.gz)


",dcdxy,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/37
MDU6SXNzdWUzODI2ODc4OTU=,Unmatched control,CLOSED,2018-11-20T14:27:15Z,2019-01-24T00:57:03Z,2018-12-12T17:07:00Z,"Is there a way to use controls without specifying the pairing? For example, if I have three biological `""chip.fastqs""` replicates and only one control `""chip.ctl_fastqs""` replicate, can I avoid arbitrarily matching the control or must I assign it to one of `""chip.ctl_fastqs_rep1""`, `""chip.ctl_fastqs_rep2""`, or `""chip.ctl_fastqs_rep3""`? I assume that by assigning it, there will be differential peak calling (in the MACS2 context) for the specified pair only?",dcdxy,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/39
MDU6SXNzdWUzODYzOTY1MzI=,Mix single-end and paired-end,CLOSED,2018-12-01T00:19:46Z,2018-12-12T17:06:54Z,2018-12-12T17:06:54Z,"Can this pipeline handle a mixture of single-end and paired-end replicates?  If so, what value should I put for ""chip.paired_end"" : true/false in the .json?
",kirstyjamieson,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/42
MDU6SXNzdWUzOTEzODU4MTg=,Unable to download ATACQ file when building hg19 database,CLOSED,2018-12-15T15:06:15Z,2019-09-09T22:14:33Z,2019-09-09T22:14:27Z,,dcheng1,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/44
MDU6SXNzdWUzOTY5OTYwNjE=,call-reproducibility_overlap step is failing,CLOSED,2019-01-08T16:55:24Z,2019-01-14T12:26:31Z,2019-01-14T12:26:31Z,"Hi,

I am running in an issue on one of the last steps during the pipeline. It seems that there are files missing:

`chip/1f86b29f-f80b-4bb5-abf4-a5201fb58c05/call-reproducibility_overlap/execution`

stderr
```
ln: accessing 'optimal_peak.gz': No such file or directory
ln: accessing 'conservative_peak.gz': No such file or directory
```


The following files are in the directory:

![image](https://user-images.githubusercontent.com/6357820/50845937-54b52a00-136e-11e9-995d-12cb7d990999.png)

Any idea what is wrong here?

Thanks a lot!

Best,
Florian",Flowdihow,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/46
MDU6SXNzdWUzOTk4NjAwMTQ=,Pipeline stalls at peak-calling steps,CLOSED,2019-01-16T15:25:05Z,2019-02-04T22:25:56Z,2019-02-04T22:25:56Z,"I've been trying to run the pipeline on the test data, and it seems to stall when it gets to peak-calling every time. I've been using qlogin on our SGE server and putting in the command manually, after activating the proper conda environment. 

command: 
`java -jar -Dconfig.file=backends/backend.conf cromwell-36.jar run chip.wdl -i ${INPUT}` 

I've attached the log.

[workflow.ed8d0870-e114-4af9-8a75-3b85625caa50.log](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2764732/workflow.ed8d0870-e114-4af9-8a75-3b85625caa50.log)
",kdemuren,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/47
MDU6SXNzdWU0MDQxMDU2NTM=,Job chip.macs2_ppr2:NA:1 failed,CLOSED,2019-01-29T03:24:22Z,2019-04-01T04:02:48Z,2019-04-01T04:02:48Z,"I encountered the following error during the call-macs2-ppr2 step.

==> ./call-macs2_ppr2/execution/stderr <==
Traceback (most recent call last):
  File ""/rbc/yixiang/anaconda2/envs/encode-chip-seq-pipeline/bin/encode_macs2_chip.py"", line 223, in <module>
    main()
  File ""/rbc/yixiang/anaconda2/envs/encode-chip-seq-pipeline/bin/encode_macs2_chip.py"", line 215, in main
    args.chrsz, args.fraglen, args.out_dir)
  File ""/rbc/yixiang/anaconda2/envs/encode-chip-seq-pipeline/bin/encode_frip.py"", line 84, in frip_shifted
    write_txt(frip_qc, str(float(val1)/float(val2)))
ValueError: could not convert string to float: Differing number of BED fields encountered at line: 40330138.  Exiting...
5740102

==> ./call-macs2_pr2/shard-1/execution/stderr <==
Traceback (most recent call last):
  File ""/rbc/yixiang/anaconda2/envs/encode-chip-seq-pipeline/bin/encode_macs2_chip.py"", line 223, in <module>
    main()
  File ""/rbc/yixiang/anaconda2/envs/encode-chip-seq-pipeline/bin/encode_macs2_chip.py"", line 215, in main
    args.chrsz, args.fraglen, args.out_dir)
  File ""/rbc/yixiang/anaconda2/envs/encode-chip-seq-pipeline/bin/encode_frip.py"", line 84, in frip_shifted
    write_txt(frip_qc, str(float(val1)/float(val2)))
ValueError: could not convert string to float: Differing number of BED fields encountered at line: 17163938.  Exiting...
2522395

**OS/Platform and dependencies**
- Cromwell/dxWDL version: cromwell-34.jar
- Conda version: 4.3.30

[debug_49.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2805905/debug_49.tar.gz)


",yxsee,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/49
MDU6SXNzdWU0MDQxNDcxNTg=,BWA mem instead of aln,CLOSED,2019-01-29T06:53:29Z,2019-09-09T22:16:54Z,2019-09-09T22:16:53Z,"I am currently running the pipeline on 2 x 151 bp ChIP seq datasets and I find that the BWA 'mem' works better than the 'aln' algorithm for my datasets. In particular, the mapped ratio improved from 59% to 95%, and properly paired ratio improved from 53% to 95%. The BWA documentation seems to recommend 'mem' for reads longer than 70bp and the ENCODE ChIP seq guidelines also encourage longer read lengths (more than 50bp). Will it be possible to add the BWA aligner option into the workflow?

Thanks for your consideration!",yxsee,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/50
MDU6SXNzdWU0MDY5Nzk5Njk=,duplicate key in qc_report call input,CLOSED,2019-02-05T21:22:08Z,2019-09-09T22:21:26Z,2019-09-09T22:21:26Z,"The input macs2_cap_num_peak appears to be there twice

https://github.com/ENCODE-DCC/chip-seq-pipeline2/blob/a5cfe39835f9322f770a19f1ff1b777e6111cdb6/chip.wdl#L929-L938",mlin,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/53
MDU6SXNzdWU0MDc3ODg5OTM=,Failure to find peak file,CLOSED,2019-02-07T16:34:26Z,2019-09-09T22:21:52Z,2019-09-09T22:21:52Z,"Now, running the pipeline on my actual data, one run stopped when it came to the IDR steps, with this specific error:
```
[2019-02-07 03:01:30,91] [[38;5;1merror[0m] WorkflowManagerActor Workflow 73108c41-3432-4ab2-9f3d-92b89dd0b538 failed (during ExecutingWorkflowState): Job chip.idr:0:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.
Check the content of stderr for potential additional information: /net/bmc-pub9/data/boyerlab/users/kdemuren/chip-seq-pipeline2/cromwell-executions/chip/73108c41-3432-4ab2-9f3d-92b89dd0b538/call-idr/shard-0/execution/stderr.
 Traceback (most recent call last):
  File ""/home/kdemuren/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_idr.py"", line 169, in <module>
    main()
  File ""/home/kdemuren/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_idr.py"", line 144, in main
    assert_file_not_empty(bfilt_idr_peak)
  File ""/net/bmc-pub9/data/boyerlab/users/kdemuren/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_common.py"", line 176, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f,help))
Exception: File is empty (rep1-rep2.idr0.05.bfilt.narrowPeak.gz). Help: 
```
With the same JSON file (but different ChIP data), I've had two successful runs, again using qlogin with memory/time allocation.

Log attached: 
[log_CM_Rad21.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2841791/log_CM_Rad21.txt)

Error tarball: 
[debug_54.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2841803/debug_54.tar.gz)

",kdemuren,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/54
MDU6SXNzdWU0MDc4MzA3MjI=,chip-seq-pipeline2-1.1.6 slurm singularity tutorial questions,CLOSED,2019-02-07T18:13:56Z,2019-02-07T19:49:47Z,2019-02-07T19:49:47Z,"**Describe the bug**
A clear and concise description of what the problem is.

**OS/Platform and dependencies**
- OS or Platform: [e.g. Ubuntu 16.04, Google Cloud, Stanford Sherlock/SCG cluster, ...]
- Cromwell/dxWDL version: [e.g. `cromwell-34.jar`, `dxWDL-78.jar`]
- Conda version: If you have used Conda (`$ conda --version`).
- singularity version: If you have used singularity (`$ singularity --version`).

**Attach error logs**
For Cromwell users only.
1) Move to your working directory where you ran a pipeline. You should be able to find a directory named `cromwell-executions/` which includes all outputs and logs for debugging.

2) Run the following command line to print all non-empty STDERR outputs. This will be greatly helpful for developers to figure out the problem. Copy-paste its output to the issue page.
```
$ find -name stderr -not -empty | xargs tail -n +1
```

3) (OPTIONAL) Run the following command to collect all logs. For developer's convenience, please add `[ISSUE_ID]` to the name of the tar ball file. This command will generate a tar ball including all debugging information. Post an issue with the tar ball (`.tar.gz`) attached.
```
$ find . -type f -name 'stdout' -or -name 'stderr' -or -name 'script' -or \
-name '*.qc' -or -name '*.txt' -or -name '*.log' -or -name '*.png' -or -name '*.pdf' \
| xargs tar -zcvf debug_[ISSUE_ID].tar.gz
```
",RichardCorbett,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/55
MDU6SXNzdWU0MTMxNjI4MTM=,results are not consistent from xcor analysis,CLOSED,2019-02-21T22:55:10Z,2020-02-20T18:22:59Z,2020-02-20T18:22:59Z,"Hi,
Thanks for making this great pipeline!

I ran the pipeline three times with the same data but get the very different results from xcor analysis, especially on the value of RSC. 

I have two replicates for the ChIP samples. The first time I used the fastq files as input and got the RSC as 0.58 and 0.69, respectively, which indicated the low quality of libraries but I don't believe it at all since other QC metrics look good. The second time I used the bam removing the duplicates (nodup_bam gotten from the first time) as input and reran the xcor analysis in your pipeline and got the RSC as 1.08 and 1.07, which is expected.  Then, I ran the xcor analysis again and got the RSC around 1.08 for both samples. I know your pipeline integrated the Phantompeakqualtools for xcor analysis which uses the 15M randomly selected reads as input and the variation from the reads selection would affect the results. But I didn't expect the results were so inconsistent! It is possible that people would make wrong decision about the library quality. So what do you think about this issue? Is there any way to avoid this? Increase the number of reads as input? Many thanks.

BTW, I attached the figures generated from xcor analysis in case you would like to take a look.

[1st_sample2.pdf](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2891596/1st_sample2.pdf)
[1st_sample1.pdf](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2891597/1st_sample1.pdf)
[2nd_sample1.pdf](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2891598/2nd_sample1.pdf)
[2nd_sample2.pdf](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/2891599/2nd_sample2.pdf)
    


",icanwinwyz,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/57
MDU6SXNzdWU0MTgzOTgxMzI=,Error in Test Due to Failure to Find Genome Data File,CLOSED,2019-03-07T16:23:39Z,2019-03-20T19:26:15Z,2019-03-20T19:26:15Z,"**Describe the bug**
I tried running the test and it failed.  I looked through the output from slurm and found that a localization via a hard link had failed.  It could not find the following file: chip-seq-pipeline2/test_genome_database/hg38_chr19_chrM/hg38.chrom.sizes.  I went into the chip-seq-pipeline2/test_genome_database/hg38_chr19_chrM directory, and the file did not exist.  I did see a file with this name: hg38_chr19_chrM.chrom.sizes.

**OS/Platform and dependencies**
- OS or Platform: Linux cluster with Ubuntu and Slurm
- Cromwell/dxWDL version: cromwell-34.jar
- Conda version: 4.5.11

**Attach error logs**
For Cromwell users only.
Run the following command line to print all non-empty STDERR outputs. This will be greatly helpful for developers to figure out the problem. Copy-paste its output to the issue page.
```
$ find -name stderr -not -empty | xargs tail -n +1
```
This did not return anything.
",imk1,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/58
MDU6SXNzdWU0MjEwODUzNjU=,WomLong error for slurm execution,CLOSED,2019-03-14T15:25:08Z,2019-09-09T22:52:38Z,2019-09-09T22:52:37Z,"**Describe the bug**
Running with slurm_singularity backend doesn't work for me. I have narrowed it down to this bug in cromwell:

https://github.com/broadinstitute/cromwell/issues/4659

Applying the suggested workaround to the memory parameter makes it work. Just to let you know if you stumbles upon something similar

**OS/Platform and dependencies**
- OS or Platform: Ubuntu 16.04
- Cromwell/dxWDL version: cromwell 38-unknown-SNAP (cromwell --version)
- Conda version: 4.5.12
- singularity version: 2.6.1-dist

**Attach error logs**
Same/similar as reported in the cromwell bug above


3) (OPTIONAL) Run the following command to collect all logs. For developer's convenience, please add `[ISSUE_ID]` to the name of the tar ball file. This command will generate a tar ball including all debugging information. Post an issue with the tar ball (`.tar.gz`) attached.
```
$ find . -type f -name 'stdout' -or -name 'stderr' -or -name 'script' -or \
-name '*.qc' -or -name '*.txt' -or -name '*.log' -or -name '*.png' -or -name '*.pdf' \
| xargs tar -zcvf debug_[ISSUE_ID].tar.gz
```
",karl616,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/59
MDU6SXNzdWU0MjM0MzQxNDE=,Leveraging Cluster to Run Parts of Pipeline in Parallel,CLOSED,2019-03-20T19:30:13Z,2019-03-22T17:32:17Z,2019-03-22T13:46:45Z,"I am running the ChIP-seq pipeline on a slurm cluster, and I would like to use the cluster to run parts of the pipeline in parallel (like map the reads from the different replicates in parallel).  Am I correct in thinking that I need to use #SBATCH -n 2 (or > 2) in order to do this?  If so, it would be great if you could clarify this somewhere.  The current example script says:
""do not touch these settings
number of tasks and nodes are fixed at 1""
which suggests that the pipeline will fail if -n is not set to 1.
Thanks so much!",imk1,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/61
MDU6SXNzdWU0MjU2NTczNTA=,OSError: [Errno 1] Operation not permitted,CLOSED,2019-03-26T21:28:13Z,2019-10-04T17:30:27Z,2019-09-09T22:23:11Z,"Running chip-seq-pipeline2 test fails with:
File ""/beevol/home/paulk/.conda/envs/encode-chip-seq-pipeline/lib/python2.7/multiprocessing/pool.py"", line 567, in get
    raise self._value
OSError: [Errno 1] Operation not permitted

Platform is Centos 7.5.1804
Cromwell-34.jar
Conda 4.3.30


[cromwell-executions.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3010420/cromwell-executions.tar.gz)

[stderr.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3010425/stderr.txt)
",dfarrell20,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/63
MDU6SXNzdWU0MjkxMjU3NDc=,unrecognized arguments: --mito-chr-name chrM,CLOSED,2019-04-04T07:34:52Z,2019-04-05T06:49:49Z,2019-04-05T06:49:49Z,"**Describe the bug**
I've installed the pipeline using Conda RedHatEnterpriseServer. I get the  unrecognized argument error at the filter step (error from stderr is attached below). 

**OS/Platform and dependencies**
- OS or Platform: `Red Hat Enterprise Linux Server release 7.6 (Maipo)`
- Cromwell/dxWDL version: `cromwell-34.jar`
- Conda version: `conda v.4.3.21`.

**Attach error logs**
```
[2019-04-04 00:52:03,01] [error] WorkflowManagerActor Workflow 6a90302c-a328-4d5e-a7a8-2db0423feeb5 failed (during ExecutingWorkflowState): Job chip.filter_ctl:0:1 exited with return code 2 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.
Check the content of stderr for potential additional information: ~/chip-seq-pipeline2/cromwell-executions/chip/6a90302c-a328-4d5e-a7a8-2db0423feeb5/call-filter_ctl/shard-0/execution/stderr.
 usage: ENCODE DCC filter. [-h] [--dup-marker {picard,sambamba}]
                          [--mapq-thresh MAPQ_THRESH] [--no-dup-removal]
                          [--paired-end] [--multimapping MULTIMAPPING]
                          [--nth NTH] [--out-dir OUT_DIR]
                          [--log-level {NOTSET,DEBUG,INFO,WARNING,CRITICAL,ERROR,CRITICAL}]
                          bam
ENCODE DCC filter.: error: unrecognized arguments: --mito-chr-name chrM
```

Thanks in advance!
",asntech,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/64
MDU6SXNzdWU0MzM5NjgwOTk=,[error] Error parsing generated wdl:,CLOSED,2019-04-16T20:22:43Z,2019-09-09T22:25:25Z,2019-09-09T22:25:25Z,"Got issues when running the test samples. 

(encode-chip-seq-pipeline) [ye.liu@submit chip-seq-pipeline2]$ java -jar -Dconfig.file=backends/backend.conf cromwell-34.jar run chip.wdl -i ${INPUT} -o workflow_opts/singularity.json -m ${PIPELINE_METADATA}
[2019-04-16 16:17:55,29] [info] Running with database db.url = jdbc:hsqldb:mem:56b66269-54d2-4a0e-af42-3e525d21846c;shutdown=false;hsqldb.tx=mvcc
[2019-04-16 16:18:04,19] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000
[2019-04-16 16:18:04,20] [info] [RenameWorkflowOptionsInMetadata] 100%
[2019-04-16 16:18:04,29] [info] Running with database db.url = jdbc:hsqldb:mem:079abec0-ecbf-460b-972f-53d84fcb434c;shutdown=false;hsqldb.tx=mvcc
[2019-04-16 16:18:04,66] [warn] This actor factory is deprecated. Please use cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory for PAPI v1 or cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory for PAPI v2
[2019-04-16 16:18:04,69] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.
[2019-04-16 16:18:04,69] [info] Using noop to send events.
[2019-04-16 16:18:05,00] [info] Slf4jLogger started
[2019-04-16 16:18:05,25] [info] Workflow heartbeat configuration:
{
  ""cromwellId"" : ""cromid-4749fc3"",
  ""heartbeatInterval"" : ""2 minutes"",
  ""ttl"" : ""10 minutes"",
  ""writeBatchSize"" : 10000,
  ""writeThreshold"" : 10000
}
[2019-04-16 16:18:05,29] [info] Metadata summary refreshing every 2 seconds.
[2019-04-16 16:18:05,36] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.
[2019-04-16 16:18:05,36] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.
[2019-04-16 16:18:05,36] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.
[2019-04-16 16:18:06,17] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.
[2019-04-16 16:18:06,19] [info] SingleWorkflowRunnerActor: Version 34
[2019-04-16 16:18:06,19] [info] JES batch polling interval is 33333 milliseconds
[2019-04-16 16:18:06,19] [info] JES batch polling interval is 33333 milliseconds
[2019-04-16 16:18:06,19] [info] JES batch polling interval is 33333 milliseconds
[2019-04-16 16:18:06,19] [info] PAPIQueryManager Running with 3 workers
[2019-04-16 16:18:06,20] [info] SingleWorkflowRunnerActor: Submitting workflow
[2019-04-16 16:18:06,26] [info] Unspecified type (Unspecified version) workflow 7f0b27fc-a2c9-42c2-b9ea-2cd6517162c3 submitted
[2019-04-16 16:18:06,31] [info] SingleWorkflowRunnerActor: Workflow submitted 7f0b27fc-a2c9-42c2-b9ea-2cd6517162c3
[2019-04-16 16:18:06,32] [info] 1 new workflows fetched
[2019-04-16 16:18:06,32] [info] WorkflowManagerActor Starting workflow 7f0b27fc-a2c9-42c2-b9ea-2cd6517162c3
[2019-04-16 16:18:06,33] [warn] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData
[2019-04-16 16:18:06,33] [info] WorkflowManagerActor Successfully started WorkflowActor-7f0b27fc-a2c9-42c2-b9ea-2cd6517162c3
[2019-04-16 16:18:06,33] [info] Retrieved 1 workflows from the WorkflowStoreActor
[2019-04-16 16:18:06,34] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.
[2019-04-16 16:18:06,41] [info] MaterializeWorkflowDescriptorActor [7f0b27fc]: Parsing workflow as WDL draft-2
[2019-04-16 16:19:25,60] [info] MaterializeWorkflowDescriptorActor [7f0b27fc]: Call-to-Backend assignments: chip.idr -> local, chip.bam2ta_no_filt -> local, chip.pool_ta_pr2 -> local, chip.spp_ppr2 -> local, chip.overlap -> local, chip.idr_pr -> local, chip.macs2_ppr2 -> local, chip.bam2ta_no_filt_R1 -> local, chip.overlap_ppr -> local, chip.fingerprint -> local, chip.macs2_pr2 -> local, chip.choose_ctl -> local, chip.bam2ta -> local, chip.bwa -> local, chip.merge_fastq_ctl -> local, chip.macs2 -> local, chip.idr_ppr -> local, chip.pool_ta -> local, chip.macs2_pooled -> local, chip.filter_ctl -> local, chip.read_genome_tsv -> local, chip.bwa_R1 -> local, chip.spp_pr2 -> local, chip.spp -> local, chip.spp_pooled -> local, chip.filter -> local, chip.xcor -> local, chip.macs2_ppr1 -> local, chip.bwa_ctl -> local, chip.macs2_pr1 -> local, chip.spr -> local, chip.qc_report -> local, chip.spp_pr1 -> local, chip.reproducibility_idr -> local, chip.spp_ppr1 -> local, chip.fraglen_mean -> local, chip.overlap_pr -> local, chip.bam2ta_ctl -> local, chip.reproducibility_overlap -> local, chip.trim_fastq -> local, chip.merge_fastq -> local, chip.pool_ta_ctl -> local, chip.pool_ta_pr1 -> local
[2019-04-16 16:19:25,66] [error] Error parsing generated wdl:

java.lang.RuntimeException: Error parsing generated wdl:

	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:55)
	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:39)
	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:39)
	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:42)
	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:41)
	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:53)
	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:52)
	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:82)
	at cromwell.backend.BackendWorkflowInitializationActor.initSequence(BackendWorkflowInitializationActor.scala:154)
	at cromwell.backend.BackendWorkflowInitializationActor.initSequence$(BackendWorkflowInitializationActor.scala:152)
	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:44)
	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1.$anonfun$applyOrElse$1(BackendWorkflowInitializationActor.scala:145)
	at cromwell.backend.BackendLifecycleActor.performActionThenRespond(BackendLifecycleActor.scala:44)
	at cromwell.backend.BackendLifecycleActor.performActionThenRespond$(BackendLifecycleActor.scala:40)
	at cromwell.backend.standard.StandardInitializationActor.performActionThenRespond(StandardInitializationActor.scala:44)
	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1.applyOrElse(BackendWorkflowInitializationActor.scala:145)
	at akka.actor.Actor.aroundReceive(Actor.scala:517)
	at akka.actor.Actor.aroundReceive$(Actor.scala:515)
	at cromwell.backend.standard.StandardInitializationActor.aroundReceive(StandardInitializationActor.scala:44)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588)
	at akka.actor.ActorCell.invoke(ActorCell.scala:557)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
	at akka.dispatch.Mailbox.run(Mailbox.scala:225)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.NullPointerException: null
	at wdl.draft2.model.WdlNamespace$.apply(WdlNamespace.scala:196)
	at wdl.draft2.model.WdlNamespace$.$anonfun$load$1(WdlNamespace.scala:160)
	at scala.util.Try$.apply(Try.scala:209)
	at wdl.draft2.model.WdlNamespace$.load(WdlNamespace.scala:160)
	at wdl.draft2.model.WdlNamespace$.loadUsingSource(WdlNamespace.scala:156)
	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:53)
	... 27 common frames omitted
",Runuply,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/65
MDU6SXNzdWU0MzU4NDQ5MTI=,Error Using Singularity,CLOSED,2019-04-22T18:57:00Z,2019-04-30T10:53:59Z,2019-04-30T10:53:59Z,"
**Even correctly using the Singularity_BINDPATH, and adding the necessary folders, the system breaks during xcor. The error msg claims that it can't find mm10.blacklist.bed.gz but all other files were located. I tried to add extra path but it didn't work.**

**singularity --version
2.6.1-dist**

```
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_fingerprint.py"", line 109, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_fingerprint.py"", line 101, in main
    args.bams, args.ctl_bam, args.blacklist, args.nth, args.out_dir)
  File ""/software/chip-seq-pipeline/src/encode_fingerprint.py"", line 76, in fingerprint
    run_shell_cmd(cmd)
  File ""/software/chip-seq-pipeline/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=25419, PGID=25419, RC=1
STDERR=/usr/local/lib/python2.7/dist-packages/matplotlib-1.5.1-py2.7-linux-x86_64.egg/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.
  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')
Traceback (most recent call last):
  File ""/usr/local/bin/plotFingerprint"", line 11, in <module>
    main(args)
  File ""/usr/local/lib/python2.7/dist-packages/deeptools/plotFingerprint.py"", line 376, in main
    num_reads_per_bin = cr.run()
  File ""/usr/local/lib/python2.7/dist-packages/deeptools/countReadsPerBin.py"", line 318, in run
    transcript_id_designator=transcript_id_designator)
  File ""/usr/local/lib/python2.7/dist-packages/deeptools/mapReduce.py"", line 88, in mapReduce
    blackList = GTF(blackListFileName)
  File ""/usr/local/lib/python2.7/dist-packages/deeptoolsintervals/parse.py"", line 584, in __init__
    fp = openPossiblyCompressed(fname)
  File ""/usr/local/lib/python2.7/dist-packages/deeptoolsintervals/parse.py"", line 102, in openPossiblyCompressed
    with open(fname, ""rb"") as f:
IOError: [Errno 2] No such file or directory: '/gamma_data1/trezende/Mariy/FirstBatch/raw/ChIP/cromwell-executions/chip/c9a3a637-0769-48f4-b338-d5f5dc7776ea/call-fingerprint/inputs/961135001/mm10.blacklist.bed.gz'
STDOUT=

```


Thanks for your help,



Tiago",tiagobrc,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/66
MDU6SXNzdWU0Mzg0MzQ1MzI=,resumer.py fails on metadata.json generated for histone chipseq run ,CLOSED,2019-04-29T17:54:27Z,2019-09-09T22:25:54Z,2019-09-09T22:25:53Z,"@leepc12  The pipeline is run on sherlock. 

1. The original json input file is: 

`/oak/stanford/groups/akundaje/projects/GECCO/scacheri_46_h3k27ac_chipseq/output_hg19/589N/589N.json`

The resulting metadata file is: 
`/oak/stanford/groups/akundaje/projects/GECCO/scacheri_46_h3k27ac_chipseq/output_hg19/589N/metadata.json`

The output log file is: 
`/oak/stanford/groups/akundaje/projects/GECCO/scacheri_46_h3k27ac_chipseq/logs_hg19/589N.o`

The error log file is: 
`/oak/stanford/groups/akundaje/projects/GECCO/scacheri_46_h3k27ac_chipseq/logs_hg19/589N.e`

(basically the job was cancelled because it hit the 24 hour time limit, I want to restart and allocate more time). 

2. I am running: 

```
 python ~/chip-seq-pipeline2/utils/resumer/resumer.py /oak/stanford/groups/akundaje/projects/GECCO/scacheri_46_h3k27ac_chipseq/output_hg19/589N/metadata.json
```
The code fails with the following stack trace: 

Traceback (most recent call last):
  File ""/home/users/annashch/chip-seq-pipeline2/utils/resumer/resumer.py"", line 100, in <module>
    main()
  File ""/home/users/annashch/chip-seq-pipeline2/utils/resumer/resumer.py"", line 86, in main
    workflow_id, org_input_json, calls = parse_cromwell_metadata_json_file(args.metadata_json_file)
  File ""/home/users/annashch/chip-seq-pipeline2/utils/resumer/resumer.py"", line 44, in parse_cromwell_metadata_json_file
    org_input_json = json.loads(metadata_json['submittedFiles']['inputs'], object_pairs_hook=OrderedDict)
  File ""/scratch/users/annashch/miniconda3/lib/python3.6/json/__init__.py"", line 367, in loads
    return cls(**kw).decode(s)
  File ""/scratch/users/annashch/miniconda3/lib/python3.6/json/decoder.py"", line 339, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File ""/scratch/users/annashch/miniconda3/lib/python3.6/json/decoder.py"", line 355, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 9 column 1 (char 1168)

```
",annashcherbina,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/67
MDU6SXNzdWU0Mzg0NDUwNzY=,resumer.py default template  is missing mandatory chip.pipeline_type argument. ,CLOSED,2019-04-29T18:21:59Z,2019-09-09T22:26:22Z,2019-09-09T22:26:22Z,"output of resumer.py is mising ""chip.pipeline_type"", even though this argument is present in the original input.json file. ",annashcherbina,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/68
MDU6SXNzdWU0NDUwODYyODg=,Failed execution with test data,CLOSED,2019-05-16T17:57:28Z,2019-05-17T19:05:58Z,2019-05-17T19:05:58Z,"
[debug_70.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3188368/debug_70.tar.gz)
I've just installed the chip-seq-pipeline2. When I run the pipeline with the test data, I get an error message and the pipeline exits.

WorkflowManagerActor Workflow f7557e2f-ce80-45ca-86e4-062f8d562b37 failed (during ExecutingWorkflowState): Job chip.filter:0:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.

**OS/Platform and dependencies**
- macOS High Sierra Version 10.13.6
- cromwell-34.jar
-docker 2.0.0.0-mac81

**Attach error logs**
$ find -name stderr -not -empty | xargs tail -n +1

This command does not work. I get the following message.

find: illegal option -- n

",sjquon,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/70
MDU6SXNzdWU0NDYzMDkzNjE=,Error with Chip-Seq Singularity Pipeline at Macs2 Peak Calling,CLOSED,2019-05-20T21:03:51Z,2019-06-01T02:54:52Z,2019-06-01T02:54:52Z,"During MACS2 processing with Singularity Chip-Seq pipeline, the pipeline throws up an error. I Tried but couldn't identify the origin of the error.

Can you help me? What am I missing?

I appreciate a lot thanks!

```
singularity --version
2.6.1-dist
```

Input.json:
```
{
    ""chip.genome_tsv"" : ""mm10.tsv"",
    ""chip.paired_end"" : false,

    ""chip.fastqs_rep1_R1"" : [ ""ChIP_R1.fastq.gz""],
    ""chip.ctl_fastqs_rep1_R1"" : [ ""ChIP_Input_R1.fastq.gz"" ],

    ""chip.title"" : ""ChIP"",
    ""chip.description"" : ""ChIP Project"",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.peak_caller"" : ""spp"",

    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.disable_fingerprint"" : false,
    ""chip.enable_count_signal_track"" : false,

    ""chip.xcor_pe_trim_bp"" : 50,

    ""chip.dup_marker"" : ""picard"",
    ""chip.mapq_thresh"" : 30,
    ""chip.no_dup_removal"" : false,

    ""chip.mito_chr_name"" : ""chrM"",
    ""chip.regex_filter_reads"" : ""chrM"",
    ""chip.subsample_reads"" : 0,
    ""chip.ctl_subsample_reads"" : 0,
    ""chip.xcor_subsample_reads"" : 15000000,

    ""chip.keep_irregular_chr_in_bfilt_peak"" : false,
    
    ""chip.always_use_pooled_ctl"" : true,
    ""chip.ctl_depth_ratio"" : 1.2,

    ""chip.macs2_cap_num_peak"" : 500000,
    ""chip.pval_thresh"" : 0.01,
    ""chip.idr_thresh"" : 0.05,
    ""chip.spp_cap_num_peak"" : 300000,

    ""chip.bwa_cpu"" : 12,
    ""chip.bwa_mem_mb"" : 200000,
    ""chip.bwa_time_hr"" : 480,
    ""chip.bwa_disks"" : ""local-disk 100 HDD"",

    ""chip.filter_cpu"" : 12,
    ""chip.filter_mem_mb"" : 20000,
    ""chip.filter_time_hr"" : 24,
    ""chip.filter_disks"" : ""local-disk 100 HDD"",

    ""chip.bam2ta_cpu"" : 12,
    ""chip.bam2ta_mem_mb"" : 100000,
    ""chip.bam2ta_time_hr"" : 6,
    ""chip.bam2ta_disks"" : ""local-disk 100 HDD"",

    ""chip.spr_mem_mb"" : 16000,

    ""chip.fingerprint_cpu"" : 12,
    ""chip.fingerprint_mem_mb"" : 12000,
    ""chip.fingerprint_time_hr"" : 6,
    ""chip.fingerprint_disks"" : ""local-disk 100 HDD"",

    ""chip.xcor_cpu"" : 12,
    ""chip.xcor_mem_mb"" : 16000,
    ""chip.xcor_time_hr"" : 24,
    ""chip.xcor_disks"" : ""local-disk 100 HDD"",

    ""chip.macs2_mem_mb"" : 16000,
    ""chip.macs2_time_hr"" : 24,
    ""chip.macs2_disks"" : ""local-disk 100 HDD"",

    ""chip.spp_cpu"" : 12,
    ""chip.spp_mem_mb"" : 16000,
    ""chip.spp_time_hr"" : 72,
    ""chip.spp_disks"" : ""local-disk 100 HDD""
}
```


```
find -name stderr -not -empty | xargs tail -n +1
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_macs2_chip.py"", line 225, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_macs2_chip.py"", line 200, in main
    args.out_dir)
  File ""/software/chip-seq-pipeline/src/encode_macs2_chip.py"", line 88, in macs2
    run_shell_cmd(cmd0)
  File ""/software/chip-seq-pipeline/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=28849, PGID=28849, RC=1
STDERR=ERROR:root:--extsize must >= 1!
STDOUT=

```",tiagobrc,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/71
MDU6SXNzdWU0NTU4OTg2NzU=,dcc spp callpeak error,CLOSED,2019-06-13T18:48:17Z,2019-09-09T22:31:27Z,2019-09-09T22:31:27Z,"I used conda to install dependencies and tried running the pipeline with cromwell-38. I got the following error message: 

[2019-06-13 12:11:16,40] [info] BackgroundConfigAsyncJobExecutionActor [ESC[38;5;2m60e7fe00ESC[0mchip.spp_pr2:0:1]: job id: 20957
[2019-06-13 12:11:16,40] [info] BackgroundConfigAsyncJobExecutionActor [ESC[38;5;2m60e7fe00ESC[0mchip.spp_pr2:0:1]: Status change from - to Done
[2019-06-13 12:12:29,96] [info] BackgroundConfigAsyncJobExecutionActor [ESC[38;5;2m60e7fe00ESC[0mchip.macs2:1:1]: Status change from WaitingForReturnCode to Done
[2019-06-13 12:12:30,64] [ESC[38;5;1merrorESC[0m] WorkflowManagerActor Workflow 60e7fe00-99a7-4c88-a4e4-e41bac251a21 failed (during ExecutingWorkflowState): Job chip.spp:0:1 exited with return code 2 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.
Check the content of stderr for potential additional information: /gpfs/fs1/data/shenlab/lw/chip-seq-pipeline2/cromwell-executions/chip/60e7fe00-99a7-4c88-a4e4-e41bac251a21/call-spp/shard-0/execution/stderr.
 usage: ENCODE DCC spp callpeak [-h] [--chrsz CHRSZ] --fraglen FRAGLEN
                               [--cap-num-peak CAP_NUM_PEAK] --blacklist
                               BLACKLIST [--keep-irregular-chr] [--nth NTH]
                               [--out-dir OUT_DIR]
                               [--log-level {NOTSET,DEBUG,INFO,WARNING,CRITICAL,ERROR,CRITICAL}]
                               tas tas
ENCODE DCC spp callpeak: error: too few arguments

If this is a conda dependency error I can switch to singularity. ",andrewucla,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/75
MDU6SXNzdWU0NjIxOTAwMDk=,cannot get the testing file to work,CLOSED,2019-06-28T20:08:41Z,2019-09-09T22:31:41Z,2019-09-09T22:31:41Z,"i git clone the folder
cd into the folder
dont have docker or singularity
have to use conda
bash conda/uninstall_dependencies.sh
bash conda/install_dependencies.sh
conda activate encode-chip-seq-pipeline
caper run chip.wdl -i examples/caper/ENCSR936XTK_subsampled_chr19_only.json --deepcopy


Thanks very much


[metadata.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3340712/metadata.txt)

",yinshiyi,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/77
MDU6SXNzdWU0NjM5NDE2ODc=,IDR-related issue on histone pipeline,CLOSED,2019-07-03T20:35:52Z,2019-07-09T16:33:59Z,2019-07-09T16:33:59Z,"I'm having a persistent issue that seems to be related to IDR. I'm running the pipeline on a SLURM cluster with Conda version 4.6.14 and cromwell-38. I am also running the pipeline for histone ChIP-seq, so I'm not supposed to be finding IDR. To try and fix this, I disabled IDR in my chip.wdl file, but still got the error.
I attached the debug.tar.gz file below. Thanks!

**Error Log:**
```
Traceback (most recent call last):
  File ""/home/amulyag/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_idr.py"", line 169, in <module>
    main()
  File ""/home/amulyag/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_idr.py"", line 137, in main
    args.idr_thresh, args.idr_rank, args.out_dir)
  File ""/home/amulyag/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_idr.py"", line 93, in idr
    run_shell_cmd(cmd1)
  File ""/home/amulyag/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=73703, PGID=73703, RC=127
STDERR=/bin/bash: line 1: idr: command not found
STDOUT=
```

[debug.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3356742/debug.tar.gz)
",amulyagarimella,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/78
MDU6SXNzdWU0NjU0NTg2NzQ=,JSD-related error on conda pipeline for histone ChIP-seq,CLOSED,2019-07-08T21:02:58Z,2019-08-26T07:12:11Z,2019-07-11T01:15:39Z,"I'm having a persistent JSD-related error. I'm running the pipeline on a SLURM cluster with Conda version 4.6.14 and cromwell-38. I have no control data so it seems like I can't create a JSD plot. I disabled JSD, but the error persists. Also, this error began to occur when I disabled all instances where IDR was called in an attempt to fix issue #78.

**Error Logs**
```
cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor$$anonfun$1$$anon$1: Call inp
ut and runtime attributes evaluation failed for qc_report:
Failed to evaluate input 'jsd_qcs' (reason 1 of 1): Failed to lookup input value for required input jsd_qcs
Â  Â  Â  Â  at cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor$$anonfun$1.applyOrElse(JobPreparationActo
r.scala:70)
Â  Â  Â  Â  at cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor$$anonfun$1.applyOrElse(JobPreparationActo
r.scala:66)
Â  Â  Â  Â  at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34)
Â  Â  Â  Â  at akka.actor.FSM.processEvent(FSM.scala:684)
Â  Â  Â  Â  at akka.actor.FSM.processEvent$(FSM.scala:681)
Â  Â  Â  Â  at cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor.processEvent(JobPreparationActor.scala:42
)
Â  Â  Â  Â  at akka.actor.FSM.akka$actor$FSM$$processMsg(FSM.scala:678)
Â  Â  Â  Â  at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:672)
Â  Â  Â  Â  at akka.actor.Actor.aroundReceive(Actor.scala:517)
Â  Â  Â  Â  at akka.actor.Actor.aroundReceive$(Actor.scala:515)
Â  Â  Â  Â  at cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor.aroundReceive(JobPreparationActor.scala:4
2)
Â  Â  Â  Â  at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588)
Â  Â  Â  Â  at akka.actor.ActorCell.invoke(ActorCell.scala:557)
Â  Â  Â  Â  at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)
Â  Â  Â  Â  at akka.dispatch.Mailbox.run(Mailbox.scala:225)
Â  Â  Â  Â  at akka.dispatch.Mailbox.exec(Mailbox.scala:235)
Â  Â  Â  Â  at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
Â  Â  Â  Â  at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
Â  Â  Â  Â  at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
Â  Â  Â  Â  at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
```
This didn't show up in stderr, but the workflow failed when I got this error.

[debug_79.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3370290/debug_79.tar.gz)

",amulyagarimella,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/79
MDU6SXNzdWU0NzIxNDUxNzI=,Pipeline crashes because fragment length is negative,CLOSED,2019-07-24T08:22:39Z,2019-09-09T22:32:29Z,2019-09-09T22:32:29Z,"Hi,
Thank you for great pipeline! The version I am working with is 1.2.2. Some of my pipelines crash on the `macs2` step (with error `--extsize must >= 1!`). I have investigated this and it turned out that that the fragment length estimated by the `xcor` is negative (-420):
```
...
Control data: NA 
strandshift(min): -500 
strandshift(step): 5 
strandshift(max) 1500 
user-defined peak shift NA 
exclusion(min): -500 
exclusion(max): 100 
num parallel nodes: 4 
FDR threshold: 0.01 
NumPeaks Threshold: NA 
Output Directory: . 
narrowPeak output file name: NA 
regionPeak output file name: NA 
Rdata filename: NA 
...
Top 3 cross-correlation values 0.0117837272740937,0.0117782782163765,0.011773314474586 
Top 3 estimates for fragment length -420,1450,1310
Window half size 1475 
```

I noticed that this was previously reported and it was addressed in version 1.2.0:

> exclusion range for cross-correlation analysis
adding -x=min:max to run_spp.R in xcor
this will prevent xcor estimates wrong (negative) fragment len

So I modified my file to and added `""chip.xcor_exclusion_range_min"": 10` to the input file. However the results was the same.

So my question is how I can prevent the negative values coming from xcor? I might not understood the purpose of the parameter so I could have used it wrongly. In the #71 there is a possible solution but I do not want to provide data to all the pipelines because I would prefer it to be calculated. As far as I understand, if the `fraglen` is provided by me the `xcor` is skipped. It would be nice that if the `xcor` fails, it would take the `fraglen` from the table. Otherwise, I need to launch the pipeline for the second time and it is a waste of time and resources.

Also for me the `macs2` as a peak caller is not of interest and the pipeline could continue even without it. 

Thanks
",guma44,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/80
MDU6SXNzdWU0NzIzODI5MTc=,"""Failed to evaluate 'chip.macs2.tas'"" when running pipeline from BAM files",CLOSED,2019-07-24T16:33:04Z,2019-07-29T19:01:49Z,2019-07-29T19:01:32Z,"I'm running the pipeline on a SLURM cluster with Conda version 4.6.14 and cromwell-38. I'm not entirely sure what the error is caused by, and the error is too long to post in full. I've attached the output file containing the error, as well as the debug tarball. The error does not show up in stderr.

**Error Snippet**
[2019-07-23 15:52:48,29] [ESC[38;5;1merrorESC[0m] WorkflowManagerActor Workflow 669812ad-7194-4160-ab58-5bfa9b7c8520 failed (during ExecutingWorkflow
State): java.lang.RuntimeException: Failed to evaluate 'chip.macs2.tas' (reason 1 of 1): Evaluating flatten([[ta_[i]], chosen_ctl_tas[i]]) failed: :
Failed to find index Success(WomInteger(23)) on array:

Success([[], [], [], [], [], [], [], [], [], []])

**Output**
[slurm.out.11839572.2.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3427841/slurm.out.11839572.2.txt)

[debug_81.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3427837/debug_81.tar.gz)

",amulyagarimella,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/81
MDU6SXNzdWU0NzQxMDgxMDM=,encode_bwa.py error,CLOSED,2019-07-29T15:13:26Z,2019-07-30T20:09:56Z,2019-07-30T20:09:56Z,"**Describe the bug**
I failed to follow the tutorial. it look like the missing out-dir for encode_bwa.py, thanks a lot!

**OS/Platform and dependencies**
- OS or Platform: CentOS 6
- Conda version: 4.6.14
- Caper version: 0.3.15


**Attach error logs**
Traceback (most recent call last):
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 246, in <module>
    main()
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 214, in main
    bwa_index_prefix, args.nth, args.out_dir)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 98, in bwa_se
    run_shell_cmd(cmd)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=64122, PGID=64122, RC=1
STDERR=[bam_sort] Use -T PREFIX / -o FILE to specify temporary and final output files
Usage: samtools sort [options...] [in.bam]
Options:
  -l INT     Set compression level, from 0 (uncompressed) to 9 (best)
  -m INT     Set maximum memory per thread; suffix K/M/G recognized [768M]
  -n         Sort by read name
  -t TAG     Sort by value of TAG. Uses position as secondary index (or read name if -n is set)
  -o FILE    Write final output to FILE rather than standard output
  -T PREFIX  Write temporary files to PREFIX.nnnn.bam
      --input-fmt-option OPT[=VAL]
               Specify a single input file format option in the form
               of OPTION or OPTION=VALUE
  -O, --output-fmt FORMAT[,OPT[=VAL]]..v
```
$ caper troubleshoot [WORKFLOW_ID_OR_METADATA_JSON_FILE]
```
[Caper] troubleshooting 3349340c-1f95-497c-8b50-9cd699c7a2ec ...
Found failures:
[
    {
        ""causedBy"": [
            {
                ""causedBy"": [],
                ""message"": ""Job chip.bwa_R1:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            },
            {
                ""causedBy"": [],
                ""message"": ""Job chip.bwa_R1:1:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            }
        ],
        ""message"": ""Workflow failed""
    }
]

chip.bwa_R1 RetryableFailure. SHARD_IDX=0, RC=1, JOB_ID=70989, RUN_START=2019-07-29T15:08:22.205Z, RUN_END=2019-07-29T15:09:20.111Z, STDOUT=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa_R1/shard-0/execution/stdout, STDERR=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa_R1/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 246, in <module>
    main()
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 214, in main
    bwa_index_prefix, args.nth, args.out_dir)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 98, in bwa_se
    run_shell_cmd(cmd)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=71241, PGID=71241, RC=1
STDERR=[bam_sort] Use -T PREFIX / -o FILE to specify temporary and final output files
Usage: samtools sort [options...] [in.bam]
Options:
  -l INT     Set compression level, from 0 (uncompressed) to 9 (best)
  -m INT     Set maximum memory per thread; suffix K/M/G recognized [768M]
  -n         Sort by read name
  -t TAG     Sort by value of TAG. Uses position as secondary index (or read name if -n is set)
  -o FILE    Write final output to FILE rather than standard output
  -T PREFIX  Write temporary files to PREFIX.nnnn.bam
      --input-fmt-option OPT[=VAL]
               Specify a single input file format option in the form
               of OPTION or OPTION=VALUE
  -O, --output-fmt FORMAT[,OPT[=VAL]]...
               Specify output format (SAM, BAM, CRAM)
      --output-fmt-option OPT[=VAL]
               Specify a single output file format option in the form
               of OPTION or OPTION=VALUE
      --reference FILE
               Reference sequence FASTA FILE [null]
  -@, --threads INT
               Number of additional threads to use [0]
[bwa_read_seq] 0.0% bases are trimmed.
[bwa_aln_core] convert to sequence coordinate... 0.28 sec
[bwa_aln_core] refine gapped alignments... 0.12 sec
[bwa_aln_core] print alignments...
STDOUT=


chip.bwa_R1 Failed. SHARD_IDX=0, RC=1, JOB_ID=71425, RUN_START=2019-07-29T15:09:22.201Z, RUN_END=2019-07-29T15:10:07.018Z, STDOUT=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa_R1/shard-0/attempt-2/execution/stdout, STDERR=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa_R1/shard-0/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 246, in <module>
    main()
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 214, in main
    bwa_index_prefix, args.nth, args.out_dir)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 98, in bwa_se
    run_shell_cmd(cmd)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=71629, PGID=71629, RC=1
STDERR=[bam_sort] Use -T PREFIX / -o FILE to specify temporary and final output files
Usage: samtools sort [options...] [in.bam]
Options:
  -l INT     Set compression level, from 0 (uncompressed) to 9 (best)
  -m INT     Set maximum memory per thread; suffix K/M/G recognized [768M]
  -n         Sort by read name
  -t TAG     Sort by value of TAG. Uses position as secondary index (or read name if -n is set)
  -o FILE    Write final output to FILE rather than standard output
  -T PREFIX  Write temporary files to PREFIX.nnnn.bam
      --input-fmt-option OPT[=VAL]
               Specify a single input file format option in the form
               of OPTION or OPTION=VALUE
  -O, --output-fmt FORMAT[,OPT[=VAL]]...
               Specify output format (SAM, BAM, CRAM)
      --output-fmt-option OPT[=VAL]
               Specify a single output file format option in the form
               of OPTION or OPTION=VALUE
      --reference FILE
               Reference sequence FASTA FILE [null]
  -@, --threads INT
               Number of additional threads to use [0]
[bwa_read_seq] 0.0% bases are trimmed.
[bwa_aln_core] convert to sequence coordinate... 0.27 sec
[bwa_aln_core] refine gapped alignments... 0.09 sec
[bwa_aln_core] print alignments...
STDOUT=


chip.bwa_R1 RetryableFailure. SHARD_IDX=1, RC=1, JOB_ID=71020, RUN_START=2019-07-29T15:08:24.207Z, RUN_END=2019-07-29T15:09:30.106Z, STDOUT=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa_R1/shard-1/execution/stdout, STDERR=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa_R1/shard-1/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 246, in <module>
    main()
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 214, in main
    bwa_index_prefix, args.nth, args.out_dir)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 98, in bwa_se
    run_shell_cmd(cmd)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=71285, PGID=71285, RC=1
STDERR=[bam_sort] Use -T PREFIX / -o FILE to specify temporary and final output files
Usage: samtools sort [options...] [in.bam]
Options:
  -l INT     Set compression level, from 0 (uncompressed) to 9 (best)
  -m INT     Set maximum memory per thread; suffix K/M/G recognized [768M]
  -n         Sort by read name
  -t TAG     Sort by value of TAG. Uses position as secondary index (or read name if -n is set)
  -o FILE    Write final output to FILE rather than standard output
  -T PREFIX  Write temporary files to PREFIX.nnnn.bam
      --input-fmt-option OPT[=VAL]
               Specify a single input file format option in the form
               of OPTION or OPTION=VALUE
  -O, --output-fmt FORMAT[,OPT[=VAL]]...
               Specify output format (SAM, BAM, CRAM)
      --output-fmt-option OPT[=VAL]
               Specify a single output file format option in the form
               of OPTION or OPTION=VALUE
      --reference FILE
               Reference sequence FASTA FILE [null]
  -@, --threads INT
               Number of additional threads to use [0]
[bwa_read_seq] 0.0% bases are trimmed.
[bwa_aln_core] convert to sequence coordinate... 0.28 sec
[bwa_aln_core] refine gapped alignments... 0.11 sec
[bwa_aln_core] print alignments...
STDOUT=


chip.bwa_R1 Failed. SHARD_IDX=1, RC=1, JOB_ID=71496, RUN_START=2019-07-29T15:09:32.202Z, RUN_END=2019-07-29T15:10:24.828Z, STDOUT=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa_R1/shard-1/attempt-2/execution/stdout, STDERR=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa_R1/shard-1/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 246, in <module>
    main()
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 214, in main
    bwa_index_prefix, args.nth, args.out_dir)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 98, in bwa_se
    run_shell_cmd(cmd)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=71866, PGID=71866, RC=1
STDERR=[bam_sort] Use -T PREFIX / -o FILE to specify temporary and final output files
Usage: samtools sort [options...] [in.bam]
Options:
  -l INT     Set compression level, from 0 (uncompressed) to 9 (best)
  -m INT     Set maximum memory per thread; suffix K/M/G recognized [768M]
  -n         Sort by read name
  -t TAG     Sort by value of TAG. Uses position as secondary index (or read name if -n is set)
  -o FILE    Write final output to FILE rather than standard output
  -T PREFIX  Write temporary files to PREFIX.nnnn.bam
      --input-fmt-option OPT[=VAL]
               Specify a single input file format option in the form
               of OPTION or OPTION=VALUE
  -O, --output-fmt FORMAT[,OPT[=VAL]]...
               Specify output format (SAM, BAM, CRAM)
      --output-fmt-option OPT[=VAL]
               Specify a single output file format option in the form
               of OPTION or OPTION=VALUE
      --reference FILE
               Reference sequence FASTA FILE [null]
  -@, --threads INT
               Number of additional threads to use [0]
[bwa_read_seq] 0.0% bases are trimmed.
[bwa_aln_core] convert to sequence coordinate... 0.24 sec
[bwa_aln_core] refine gapped alignments... 0.09 sec
[bwa_aln_core] print alignments...
STDOUT=


chip.bwa RetryableFailure. SHARD_IDX=0, RC=1, JOB_ID=70956, RUN_START=2019-07-29T15:08:18.210Z, RUN_END=2019-07-29T15:12:10.107Z, STDOUT=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa/shard-0/execution/stdout, STDERR=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 246, in <module>
    main()
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 211, in main
    bwa_index_prefix, args.nth, args.use_bwa_mem_for_pe, args.out_dir)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 162, in bwa_pe
    run_shell_cmd(cmd3)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=72252, PGID=72252, RC=1
STDERR=[bam_sort] Use -T PREFIX / -o FILE to specify temporary and final output files
Usage: samtools sort [options...] [in.bam]
Options:
  -l INT     Set compression level, from 0 (uncompressed) to 9 (best)
  -m INT     Set maximum memory per thread; suffix K/M/G recognized [768M]
  -n         Sort by read name
  -t TAG     Sort by value of TAG. Uses position as secondary index (or read name if -n is set)
  -o FILE    Write final output to FILE rather than standard output
  -T PREFIX  Write temporary files to PREFIX.nnnn.bam
      --input-fmt-option OPT[=VAL]
               Specify a single input file format option in the form
               of OPTION or OPTION=VALUE
  -O, --output-fmt FORMAT[,OPT[=VAL]]...
               Specify output format (SAM, BAM, CRAM)
      --output-fmt-option OPT[=VAL]
               Specify a single output file format option in the form
               of OPTION or OPTION=VALUE
      --reference FILE
               Reference sequence FASTA FILE [null]
  -@, --threads INT
               Number of additional threads to use [0]
STDOUT=


chip.bwa RetryableFailure. SHARD_IDX=1, RC=1, JOB_ID=70923, RUN_START=2019-07-29T15:08:14.208Z, RUN_END=2019-07-29T15:12:25.104Z, STDOUT=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa/shard-1/execution/stdout, STDERR=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa/shard-1/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 246, in <module>
    main()
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 211, in main
    bwa_index_prefix, args.nth, args.use_bwa_mem_for_pe, args.out_dir)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 162, in bwa_pe
    run_shell_cmd(cmd3)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=72499, PGID=72499, RC=1
STDERR=[bam_sort] Use -T PREFIX / -o FILE to specify temporary and final output files
Usage: samtools sort [options...] [in.bam]
Options:
  -l INT     Set compression level, from 0 (uncompressed) to 9 (best)
  -m INT     Set maximum memory per thread; suffix K/M/G recognized [768M]
  -n         Sort by read name
  -t TAG     Sort by value of TAG. Uses position as secondary index (or read name if -n is set)
  -o FILE    Write final output to FILE rather than standard output
  -T PREFIX  Write temporary files to PREFIX.nnnn.bam
      --input-fmt-option OPT[=VAL]
               Specify a single input file format option in the form
               of OPTION or OPTION=VALUE
  -O, --output-fmt FORMAT[,OPT[=VAL]]...
               Specify output format (SAM, BAM, CRAM)
      --output-fmt-option OPT[=VAL]
               Specify a single output file format option in the form
               of OPTION or OPTION=VALUE
      --reference FILE
               Reference sequence FASTA FILE [null]
  -@, --threads INT
               Number of additional threads to use [0]
STDOUT=


chip.bwa_ctl RetryableFailure. SHARD_IDX=0, RC=1, JOB_ID=70893, RUN_START=2019-07-29T15:08:10.209Z, RUN_END=2019-07-29T15:12:10.107Z, STDOUT=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa_ctl/shard-0/execution/stdout, STDERR=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa_ctl/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 246, in <module>
    main()
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 211, in main
    bwa_index_prefix, args.nth, args.use_bwa_mem_for_pe, args.out_dir)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 162, in bwa_pe
    run_shell_cmd(cmd3)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=72162, PGID=72162, RC=1
STDERR=[bam_sort] Use -T PREFIX / -o FILE to specify temporary and final output files
Usage: samtools sort [options...] [in.bam]
Options:
  -l INT     Set compression level, from 0 (uncompressed) to 9 (best)
  -m INT     Set maximum memory per thread; suffix K/M/G recognized [768M]
  -n         Sort by read name
  -t TAG     Sort by value of TAG. Uses position as secondary index (or read name if -n is set)
  -o FILE    Write final output to FILE rather than standard output
  -T PREFIX  Write temporary files to PREFIX.nnnn.bam
      --input-fmt-option OPT[=VAL]
               Specify a single input file format option in the form
               of OPTION or OPTION=VALUE
  -O, --output-fmt FORMAT[,OPT[=VAL]]...
               Specify output format (SAM, BAM, CRAM)
      --output-fmt-option OPT[=VAL]
               Specify a single output file format option in the form
               of OPTION or OPTION=VALUE
      --reference FILE
               Reference sequence FASTA FILE [null]
  -@, --threads INT
               Number of additional threads to use [0]
STDOUT=


chip.bwa_ctl RetryableFailure. SHARD_IDX=1, RC=1, JOB_ID=70872, RUN_START=2019-07-29T15:08:08.212Z, RUN_END=2019-07-29T15:11:25.106Z, STDOUT=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa_ctl/shard-1/execution/stdout, STDERR=/data/kun/TF_pipeline/test/chip/3349340c-1f95-497c-8b50-9cd699c7a2ec/call-bwa_ctl/shard-1/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 246, in <module>
    main()
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 211, in main
    bwa_index_prefix, args.nth, args.use_bwa_mem_for_pe, args.out_dir)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_bwa.py"", line 162, in bwa_pe
    run_shell_cmd(cmd3)
  File ""/data/kun/TF_pipeline/chip-seq-pipeline2/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=72180, PGID=72180, RC=1
STDERR=[bam_sort] Use -T PREFIX / -o FILE to specify temporary and final output files
Usage: samtools sort [options...] [in.bam]
Options:
  -l INT     Set compression level, from 0 (uncompressed) to 9 (best)
  -m INT     Set maximum memory per thread; suffix K/M/G recognized [768M]
  -n         Sort by read name
  -t TAG     Sort by value of TAG. Uses position as secondary index (or read name if -n is set)
  -o FILE    Write final output to FILE rather than standard output
  -T PREFIX  Write temporary files to PREFIX.nnnn.bam
      --input-fmt-option OPT[=VAL]
               Specify a single input file format option in the form
               of OPTION or OPTION=VALUE
  -O, --output-fmt FORMAT[,OPT[=VAL]]...
               Specify output format (SAM, BAM, CRAM)
      --output-fmt-option OPT[=VAL]
               Specify a single output file format option in the form
               of OPTION or OPTION=VALUE
      --reference FILE
               Reference sequence FASTA FILE [null]
  -@, --threads INT
               Number of additional threads to use [0]
STDOUT=
```
",KunFang93,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/82
MDU6SXNzdWU0NzgxOTA5MTg=,call-qc-report fails with unequal number of samples and inputs,CLOSED,2019-08-08T00:08:47Z,2019-08-09T21:02:16Z,2019-08-09T21:02:16Z,"Hello,

The pipeline runs well with 3 replicates of sample and input files, but fails at the call-qc report step in runs with 2 replicates of sample and 3 of input.

**OS/Platform and dependencies**
- CentOS release 6.8
- Conda version 4.7.10
- Caper version 0.3.15

**Error logs**
```
Found failures:
[
    {
        ""message"": ""Workflow failed"",
        ""causedBy"": [
            {
                ""message"": ""Job chip.qc_report:NA:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            }
        ]
    }
]

chip.qc_report RetryableFailure. SHARD_IDX=-1, RC=1, JOB_ID=96011, RUN_START=2019-08-05T17:44:38.559Z, RUN_END=2019-08-05T17:44:53.501Z, STDOUT=/gpfs2/well/mccarthy/production/chip-seq/data/Islet_diff_2016/merged/trimmed/BLC/chip/5ece5f92-6320-459b-90b6-d522fc61871f/call-qc_report/execution/stdout, STDERR=/gpfs2/well/mccarthy/production/chip-seq/data/Islet_diff_2016/merged/trimmed/BLC/chip/5ece5f92-6320-459b-90b6-d522fc61871f/call-qc_report/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/well/mccarthy/production/chip-seq/dependencies/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_qc_report.py"", line 633, in <module>
    main()
  File ""/well/mccarthy/production/chip-seq/dependencies/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_qc_report.py"", line 301, in main
    row_header.extend(get_ctl_labels(json_objs, args.ctl_paired_ends))
  File ""/well/mccarthy/production/chip-seq/dependencies/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_qc_report.py"", line 244, in get_ctl_labels
    if paired_ends[i]:
IndexError: list index out of range


chip.qc_report Failed. SHARD_IDX=-1, RC=1, JOB_ID=96048, RUN_START=2019-08-05T17:44:54.555Z, RUN_END=2019-08-05T17:45:07.690Z, STDOUT=/gpfs2/well/mccarthy/production/chip-seq/data/Islet_diff_2016/merged/trimmed/BLC/chip/5ece5f92-6320-459b-90b6-d522fc61871f/call-qc_report/attempt-2/execution/stdout, STDERR=/gpfs2/well/mccarthy/production/chip-seq/data/Islet_diff_2016/merged/trimmed/BLC/chip/5ece5f92-6320-459b-90b6-d522fc61871f/call-qc_report/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/well/mccarthy/production/chip-seq/dependencies/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_qc_report.py"", line 633, in <module>
    main()
  File ""/well/mccarthy/production/chip-seq/dependencies/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_qc_report.py"", line 301, in main
    row_header.extend(get_ctl_labels(json_objs, args.ctl_paired_ends))
  File ""/well/mccarthy/production/chip-seq/dependencies/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_qc_report.py"", line 244, in get_ctl_labels
    if paired_ends[i]:
IndexError: list index out of range
```
Thank you for your work and your help.
Attached are the log tar files (the GOOD one is an example of successful run, while the other two threw the error described).
[debug_ISSUE_83_GOOD.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3479321/debug_ISSUE_83_GOOD.tar.gz)
[debug_ISSUE_83_B.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3479322/debug_ISSUE_83_B.tar.gz)
[debug_ISSUE_83_A.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3479323/debug_ISSUE_83_A.tar.gz)


",mperalc,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/83
MDU6SXNzdWU0ODA5MTI5Mzg=,SyntaxError in early stages,CLOSED,2019-08-14T22:15:45Z,2019-09-09T22:32:49Z,2019-09-09T22:32:49Z,"On JSON files that I had run before without issues, I am now getting an error in which it appears a command is getting submitted that brings up a syntax error. Running using conda 4.6.14 with Cromwell 34, locally on qlogin. Here's the specific error:

```
[2019-08-14 16:43:05,68] [[38;5;1merror[0m] WorkflowManagerActor Workflow 3848d0ac-e20b-4990-9767-e7be125d9cdb failed (during ExecutingWorkflowState): Job chip.merge_fastq_ctl:0:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.
Check the content of stderr for potential additional information: /net/bmc-pub9/data/boyerlab/users/kdemuren/chip-seq-pipeline2/cromwell-executions/chip/3848d0ac-e20b-4990-9767-e7be125d9cdb/call-merge_fastq_ctl/shard-0/execution/stderr.
   File ""/net/bmc-pub9/data/boyerlab/users/kdemuren/chip-seq-pipeline2/cromwell-executions/chip/3848d0ac-e20b-4990-9767-e7be125d9cdb/call-merge_fastq_ctl/shard-0/execution/write_tsv_23c0aaf69298859c0524049ae9d633b4.tmp"", line 1
    /net/bmc-pub9/data/boyerlab/users/kdemuren/chip-seq-pipeline2/cromwell-executions/chip/3848d0ac-e20b-4990-9767-e7be125d9cdb/call-merge_fastq_ctl/shard-0/inputs/-2129304561/190422Boy_D19-3814_NA_sequence.fastq.gz
    ^
SyntaxError: invalid syntax

Job chip.merge_fastq_ctl:1:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.
Check the content of stderr for potential additional information: /net/bmc-pub9/data/boyerlab/users/kdemuren/chip-seq-pipeline2/cromwell-executions/chip/3848d0ac-e20b-4990-9767-e7be125d9cdb/call-merge_fastq_ctl/shard-1/execution/stderr.
   File ""/net/bmc-pub9/data/boyerlab/users/kdemuren/chip-seq-pipeline2/cromwell-executions/chip/3848d0ac-e20b-4990-9767-e7be125d9cdb/call-merge_fastq_ctl/shard-1/execution/write_tsv_e811db57824b4b92a7589ec48a15739e.tmp"", line 1
    /net/bmc-pub9/data/boyerlab/users/kdemuren/chip-seq-pipeline2/cromwell-executions/chip/3848d0ac-e20b-4990-9767-e7be125d9cdb/call-merge_fastq_ctl/shard-1/inputs/-1395404184/190711Boy_D19-7698_NA_sequence.fastq.gz
    ^
SyntaxError: invalid syntax

Job chip.merge_fastq:0:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.
Check the content of stderr for potential additional information: /net/bmc-pub9/data/boyerlab/users/kdemuren/chip-seq-pipeline2/cromwell-executions/chip/3848d0ac-e20b-4990-9767-e7be125d9cdb/call-merge_fastq/shard-0/execution/stderr.
   File ""/net/bmc-pub9/data/boyerlab/users/kdemuren/chip-seq-pipeline2/cromwell-executions/chip/3848d0ac-e20b-4990-9767-e7be125d9cdb/call-merge_fastq/shard-0/execution/write_tsv_56f71273653d6e64b060b2f1ee90945c.tmp"", line 1
    /net/bmc-pub9/data/boyerlab/users/kdemuren/chip-seq-pipeline2/cromwell-executions/chip/3848d0ac-e20b-4990-9767-e7be125d9cdb/call-merge_fastq/shard-0/inputs/-650451612/190711Boy_D19-7694_NA_sequence.fastq.gz
    ^
SyntaxError: invalid syntax
```
Error tarball attached. 
[debug_84.tar.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3503556/debug_84.tar.gz)

",kdemuren,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/84
MDU6SXNzdWU0OTQ5Mjg4MzY=,bwa mem compatible?,CLOSED,2019-09-18T00:55:08Z,2020-02-20T18:23:07Z,2020-02-20T18:23:07Z,"This is not an issue but a inquire. Is this version officially compatible with ""bwa mem""? Or is it still experimental? How should I specify the parameters to turn on the ""bwa mem"" in the pipeline? Thanks.  ",icanwinwyz,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/87
MDU6SXNzdWU0OTczMTg4NDE=,no encode_merge_fastq.py in PATH,CLOSED,2019-09-23T20:44:35Z,2020-02-20T18:25:51Z,2020-02-20T18:25:51Z,"There appears to be something missing in v1.2.2.  When we run ""caper run chip.wdl -i examples/local/ENCSR936XTK_subsampled_chr19_only.json"" from the git clone directory, it fails with the above error.  Is this code that should be in the Singularity image?

If I try to fix this by adding the path for ""src"" (which contains that program as well as others), then I get a different error.

""ENCODE DCC reproducibility QC.: error: argument --peaks-pr: expected at least one argument""

This is using the Singularity/SGE method, which worked fine for v1.1.6.",caldodge,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/88
MDU6SXNzdWU1MDI3NTY0ODE=,Problems running on filesystems that do not allow hard-links,CLOSED,2019-10-04T17:29:56Z,2020-02-20T18:27:18Z,2020-02-20T18:27:18Z,"I'm running on a filesystem (beegfs) that does not allow hardlinks between different directories, and encountered the same problem as  [#63](https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/63)

Seems this is related to encode_merge_fastq.py using a hardlink when there is only one file to merge. I have successfully run the pipeline off a non-beeGFS filesystem

When I edit encode_merge_fastq.py to avoid using hard links even when 'merging' a single file, I am able to generate the expected fastq.gz files (/call-merge_fastq/shard-0/execution/R1/rep1-R1.subsampled.67.merged.fastq.gz), whereas I wasn't able to before. However, the pipeline still stalls with the following error

[error] WorkflowManagerActor Workflow f3c071d7-2d66-4047-b961-e6e9cfdaeec2 failed (during ExecutingWorkflowState): cromwell.backend.standard.StandardAsyncExecutionActor$$anon$2: Failed to evaluate job outputs:
Bad output 'merge_fastq_ctl.merged_fastq_R1': Failed to find index Success(WomInteger(0)) on array:
Success([])
0

It seems the merged fastq.gz is being created, but for some reason not found?

[output.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3691628/output.txt)
",xiaofanjin,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/91
MDU6SXNzdWU1MDYzNTY0NjI=,Error at run_spp.R,CLOSED,2019-10-13T17:47:38Z,2020-01-01T06:35:00Z,2020-01-01T06:35:00Z,"**Describe the bug**
A clear and concise description of what the problem is.
I followed the instruction at https://github.com/ENCODE-DCC/chip-seq-pipeline2 and successfully installed the pipeline. I have a single end ChIPSeq and control FASTQ file. The process from Fastq to tagAlign was good but I got error at running ""run_spp.R"".

**OS/Platform and dependencies**
- OS or Platform: [e.g. Ubuntu 16.04, Google Cloud, Stanford Sherlock/SCG cluster, ...]
LSB Version:    :core-4.1-amd64:core-4.1-noarch
Distributor ID: Fedora
Description:    Fedora release 26 (Twenty Six)
Release:        26
Codename:       TwentySix
Linux lri-107577 4.15.6-200.fc26.x86_64 #1 SMP Mon Feb 26 18:51:32 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

- Conda version: If you have used Conda (`$ conda --version`).
conda 4.7.10

- Caper version
0.4.1

- If not using Caper
  - Cromwell/dxWDL version: [e.g. `cromwell-42.jar`, `dxWDL-78.jar`]

**Attach error logs**
Caper users:
Caper automatically run troubleshooter for failed workflows. If not and If you ran a Caper server and then get workflow_id of your failed workflow with `caper list`. Or directory use a `metadata.json` file on Cromwell's output directory
```
$ caper troubleshoot [WORKFLOW_ID_OR_METADATA_JSON_FILE]

The output log file can be found at 

https://drive.google.com/open?id=1iDKjGAlW1duK85MoPACkIeH9opiAKznr

In summary,
/bin/bash: line 1: 125412 Segmentation fault      (core dumped) Rscript --max-ppsize=500000 $(which run_spp.R) -rf -c=16_05T9_00S9CCF_HCT116-AHT_TotalRNAPol2_hs_i95.merged.trim_50bp.filt.no_chrM.15M.tagAlign.gz -p=2 -filtchr=""chrM"" -savp=16_05T9_00S9CCF_HCT116-AHT_TotalRNAPol2_hs_i95.merged.trim_50bp.filt.no_chrM.15M.cc.plot.pdf -out=16_05T9_00S9CCF_HCT116-AHT_TotalRNAPol2_hs_i95.merged.trim_50bp.filt.no_chrM.15M.cc.qc -x=-500:100
",cjhong,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/94
MDU6SXNzdWU1MDg3NTQ4ODc=,Issue with pdf2png within encode_task_xcor.py,CLOSED,2019-10-17T22:35:51Z,2019-10-21T16:22:45Z,2019-10-21T16:22:45Z,"**Describe the bug**
The pipeline fails with an error message describing a failure in the pdf2png function of encode_task_xcor.py. I have verified that my copy of ghostscript, which the function seems to use, works.

**OS/Platform and dependencies**
- OS or Platform: RedHat 7
- Conda version: 4.7.10
- Caper version: 0.4.1


**Attach error logs**
Caper users:
Caper automatically run troubleshooter for failed workflows. If not and If you ran a Caper server and then get workflow_id of your failed workflow with `caper list`. Or directory use a `metadata.json` file on Cromwell's output directory
```
Error log attached.

[pipeline_error.log](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3741525/pipeline_error.log)

",schafferde,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/96
MDU6SXNzdWU1MTA2NzkwOTY=,Errors when running the pipeline with PBS,CLOSED,2019-10-22T14:03:41Z,2019-10-24T23:53:20Z,2019-10-24T23:51:16Z,"I run the pipeline with pbs and got some errors. The bash file to submit the job and the error messages are attached. It seems that the environment variables didn't pass even with ""-V"" specified. Please help with the issue.

Thanks,
Haowen Zhang

**OS/Platform and dependencies**
- OS or Platform: PBS
- Conda version: conda 4.7.12
- Caper version: 0.4.1

",haowenz,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/97
MDU6SXNzdWU1MTI3NzAyNDc=,qc_report task not recognizing arguments,CLOSED,2019-10-26T00:51:29Z,2020-02-20T18:27:29Z,2020-02-20T18:27:29Z,"I'm running into issues at the qc_report task in the workflow - the errors look slightly different if I'm running using conda environment or singularity container. Using the latest singularity image, I get:

`STDERR_CONTENTS=
Unknown option: --
usage: python3 [option] ... [-c cmd | -m mod | file | -] [arg] ...
Try `python -h' for more information.`

with conda:
`STDERR_CONTENTS=
usage: ENCODE Final QC report/JSON generator. [...]
ENCODE Final QC report/JSON generator.: error: unrecognized arguments: --xcor-pe-trim-bp 50 --xcor-subsample-reads 15000000`

[output_singularity.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3774263/output_singularity.txt)
[output_conda.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3774264/output_conda.txt)

Not sure if the argument flags have changed between different versions?",xiaofanjin,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/101
MDU6SXNzdWU1MTk4OTAxMDY=,ERROR: Finished parsing without consuming all tokens,CLOSED,2019-11-08T08:55:12Z,2020-02-20T18:27:38Z,2020-02-20T18:27:38Z,"Hello,

I have a problem during processing the pipeline. The issue is :

[Caper] Validating WDL/input JSON with womtool...
[Caper] Error (womtool): WDL or input JSON is invalid.

with my own .json file but also with ""template.full.json"" you provide.
This issue is the same on a local computer or on a SGE cluster.

- OS : Ubuntu 16.04 and SGE cluster
- caper 0.5.4

Thanks in advance
",CRichard21,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/104
MDU6SXNzdWU1MjE4MTg3MDc=,Problem with running install_conda_env.sh,OPEN,2019-11-12T21:39:41Z,2020-02-20T18:55:43Z,,"Hi,

I am new to this package. I would like to install and use chip-seq-pipeline2 on my mac but had problem configuring the environment. I followed the installation instruction but failed to run install_conda_env.sh. I got the following message at the end:
 



=== Configuring for pipeline's Conda environments ===
usage: grep [-abcDEFGHhIiJLlmnOoqRSsUVvwxZ] [-A num] [-B num] [-C[num]]
	[-e pattern] [-f file] [--binary-files=value] [--color=when]
	[--context[=num]] [--directories=action] [--label] [--line-buffered]
	[--null] [pattern] [file ...]
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>
BrokenPipeError: [Errno 32] Broken pipe
usage: grep [-abcDEFGHhIiJLlmnOoqRSsUVvwxZ] [-A num] [-B num] [-C[num]]
	[-e pattern] [-f file] [--binary-files=value] [--color=when]
	[--context[=num]] [--directories=action] [--label] [--line-buffered]
	[--null] [pattern] [file ...]
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>
BrokenPipeError: [Errno 32] Broken pipe
Error: Pipeline's Conda environments not found.






I am using a Mac system, version 10.14.4. I had python version 2.7 and version 3.5 installed on my Mac. I am not an expert on python too so I could not figure out what the ""Bronken pipe"" error is all about. Any help will be appreciated. Thanks a lot!",pangwopi,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/105
MDU6SXNzdWU1MjMxMTcyOTQ=,Stream terminated without completing IO operation,CLOSED,2019-11-14T21:34:31Z,2019-11-14T21:49:51Z,2019-11-14T21:49:51Z,"**Describe the bug**
Hi, I'm running into this issue below. I tried both conda and docker and they both give me this issue. I tried it on multiple mac machines and a machine running ubuntu, and they give the exact same error. I also tried both the 1.3.3 version and the one in the master branch. 

**OS/Platform**
- OS/Platform: macOS 10.15.1
- Conda version: conda 4.7.12
- Pipeline version: v1.3.3
- Caper version: v0.6.0

**Caper configuration file**
```
backend=local

tmp-dir=""/Users/chenghaozhu/temp""
```

**Input JSON file**
```
{
    ""chip.title"" : ""RORgamma_XY018"",
    ""chip.description"" : ""RORgamma_XY018 chiseq"",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"" : ""bwa"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""../hg38_caper.tsv"",

    ""chip.paired_end"" : false,
    ""chip.ctl_paired_end"" : false,

    ""chip.always_use_pooled_ctl"" : false,

    ""chip.fastqs_rep1_R1"" : [ ""../RORgamma_XY018/IP_RORgamma_F18.fq.gz"" ],

    ""chip.ctl_fastqs_rep1_R1"" : [ ""../RORgamma_XY018/INPUT_RORgamma_F18.fq.gz"" ],

    ""chip.align_cpu"": 4,
    ""chip.align_mem_mb"": 16000,
    ""chip.filter_mem_mb"": 16000
}
```

**Error log**
```
[Caper] troubleshooting e64fe92b-2d80-4c64-8108-049851981320 ...
Found failures:
[
    {
        ""causedBy"": [
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [
                            {
                                ""causedBy"": [
                                    {
                                        ""causedBy"": [],
                                        ""message"": "":\nStream terminated without completing IO operation.\n\tEntityStreamSizeException: actual entity size (Some(5424916480)) exceeded content length limit (8388608 bytes)! You can configure this by setting `akka.http.[server|client].parsing.max-content-length` or calling `HttpEntity.withSizeLimit` before materializing the dataBytes stream.""
                                    }
                                ],
                                ""message"": ""Error(s)""
                            }
                        ],
                        ""message"": ""Failed command instantiation""
                    }
                ],
                ""message"": ""java.lang.Exception: Failed command instantiation""
            },
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [
                            {
                                ""causedBy"": [
                                    {
                                        ""causedBy"": [],
                                        ""message"": "":\nStream terminated without completing IO operation.\n\tEntityStreamSizeException: actual entity size (Some(5424916480)) exceeded content length limit (8388608 bytes)! You can configure this by setting `akka.http.[server|client].parsing.max-content-length` or calling `HttpEntity.withSizeLimit` before materializing the dataBytes stream.""
                                    }
                                ],
                                ""message"": ""Error(s)""
                            }
                        ],
                        ""message"": ""Failed command instantiation""
                    }
                ],
                ""message"": ""java.lang.Exception: Failed command instantiation""
            },
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [
                            {
                                ""causedBy"": [
                                    {
                                        ""causedBy"": [],
                                        ""message"": "":\nStream terminated without completing IO operation.\n\tEntityStreamSizeException: actual entity size (Some(5424916480)) exceeded content length limit (8388608 bytes)! You can configure this by setting `akka.http.[server|client].parsing.max-content-length` or calling `HttpEntity.withSizeLimit` before materializing the dataBytes stream.""
                                    }
                                ],
                                ""message"": ""Error(s)""
                            }
                        ],
                        ""message"": ""Failed command instantiation""
                    }
                ],
                ""message"": ""java.lang.Exception: Failed command instantiation""
            }
        ],
        ""message"": ""Workflow failed""
    }
]

chip.align Failed. SHARD_IDX=0, RC=None, JOB_ID=None, RUN_START=2019-11-14T21:17:43.947Z, RUN_END=2019-11-14T21:18:17.172Z, STDOUT=/Users/chenghaozhu/seq_data/yatian/output2/chip/e64fe92b-2d80-4c64-8108-049851981320/call-align/shard-0/execution/stdout, STDERR=/Users/chenghaozhu/seq_data/yatian/output2/chip/e64fe92b-2d80-4c64-8108-049851981320/call-align/shard-0/execution/stderr

chip.align_ctl Failed. SHARD_IDX=0, RC=None, JOB_ID=None, RUN_START=2019-11-14T21:17:47.940Z, RUN_END=2019-11-14T21:18:34.602Z, STDOUT=/Users/chenghaozhu/seq_data/yatian/output2/chip/e64fe92b-2d80-4c64-8108-049851981320/call-align_ctl/shard-0/execution/stdout, STDERR=/Users/chenghaozhu/seq_data/yatian/output2/chip/e64fe92b-2d80-4c64-8108-049851981320/call-align_ctl/shard-0/execution/stderr

chip.align_R1 Failed. SHARD_IDX=0, RC=None, JOB_ID=None, RUN_START=2019-11-14T21:17:45.939Z, RUN_END=2019-11-14T21:18:29.330Z, STDOUT=/Users/chenghaozhu/seq_data/yatian/output2/chip/e64fe92b-2d80-4c64-8108-049851981320/call-align_R1/shard-0/execution/stdout, STDERR=/Users/chenghaozhu/seq_data/yatian/output2/chip/e64fe92b-2d80-4c64-8108-049851981320/call-align_R1/shard-0/execution/stderr
```",zhuchcn,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/106
MDU6SXNzdWU1MjQ1ODY2MDI=,Why use SPP as default TF peak caller instead of MACS?,CLOSED,2019-11-18T19:56:28Z,2019-11-19T02:46:16Z,2019-11-19T02:46:16Z,"Hi,

It took more than 30h to finish the pipeline even on a normal size TF ChIP-seq dataset from ENCODE project. And it seems that most of the time are spent on running SPP to call peaks. I also found that if I set the peak caller to MACS, it only took about 3h. MACS looks like a popular peak caller which have already got thousands of citations. Could you kindly tell me why the pipeline uses SPP rather than MACS?

Thanks,
Haowen",haowenz,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/109
MDU6SXNzdWU1MjcxNDA0NjY=,libreadline problem,CLOSED,2019-11-22T11:23:14Z,2020-03-04T16:35:49Z,2020-02-20T19:24:42Z,"**Describe the bug**
The workflow breaks when it gets to running the `encode_task_xcor.py` script and on investigation it is cause by missing `libreadline.so.6` which is not supported by my version of ubuntu. Kindly is there a way to make the pipeline work with `libreadline.so.7`?

**OS/Platform**
- OS/Platform: Ubuntu 18.04
- Conda version: 4.7.12
- Pipeline version: v1.3.4
- Caper version: v0.6.1


**Input JSON file**
ENCSR000DYI_subsampled_chr19_only_caper.json.

**Error log**
error while loading shared libraries: libreadline.so.6: cannot open shared object file: No such file or directory.
```
chip.xcor Failed. SHARD_IDX=1, RC=1, JOB_ID=6989, RUN_START=2019-11-22T09:28:13.001Z, RUN_END=2019-11-22T09:28:24.308Z, STDOUT=/home/festo/Documents/MARStool/try2/chip/8e8159b1-fe67-41da-840c-8d693897e9df/call-xcor/shard-1/attempt-2/execution/stdout, STDERR=/home/festo/Documents/MARStool/try2/chip/8e8159b1-fe67-41da-840c-8d693897e9df/call-xcor/shard-1/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/home/festo/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/home/festo/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/home/festo/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/home/festo/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=7018, PGID=7018, RC=127
STDERR=/home/festo/miniconda3/envs/encode-chip-seq-pipeline/lib/R/bin/exec/R: error while loading shared libraries: libreadline.so.6: cannot open shared object file: No such file or directory
STDOUT=

```
",Fnyasimi,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/110
MDU6SXNzdWU1MzUwODU0MzA=,call-gc-bias error,CLOSED,2019-12-09T17:47:20Z,2019-12-09T18:04:55Z,2019-12-09T18:04:55Z,"Hello:

The pipeline is still running but I just saw the stderr file for the call-gc-bias step is not empty, so I opened it up, it looked like this ( all four output files seem to be written, and stdout has "" ALL DONE"" int the end), should I worry or change anything, Thanks!

Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/sc/orga/projects/walshm02a/Yifei/bsub/chip-caper/chip/3ec5a3d4-32cc-4a79-877b-6fa71b6e09c4/call-gc_bias/shard-0/tmp.ccb9e018
INFO  2019-12-09 04:56:51 CollectGcBiasMetrics

********** NOTE: Picard's command line syntax is changing.
**********
********** For more information, please see:
********** https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)
**********
********** The command line looks like this in the new syntax:
**********
**********    CollectGcBiasMetrics -R /sc/orga/projects/walshm02a/Yifei/bsub/chip-caper/chip/3ec5a3d4-32cc-4a79-877b-6fa71b6e09c4/call-gc_bias/shard-0/inputs/-599812846/GRCh38_no_alt_analysis_set_GCA_000\
001405.15.fasta.gz -I ./A15_CKDL190138594-1a-AK445_HMFLWDSXX_L1_1.merged.nodup.no_rg.bam -O A15_CKDL190138594-1a-AK445_HMFLWDSXX_L1_1.merged.nodup.gc.txt -USE_JDK_DEFLATER TRUE -USE_JDK_INFLATER TRUE -VE\
RBOSITY ERROR -QUIET TRUE -ASSUME_SORTED FALSE -CHART A15_CKDL190138594-1a-AK445_HMFLWDSXX_L1_1.merged.nodup.gcPlot.pdf -S A15_CKDL190138594-1a-AK445_HMFLWDSXX_L1_1.merged.nodup.gcSummary.txt
**********




**OS/Platform**
- OS/Platform: hpc cluster
- Pipeline version: [e.g. v1.3.4]
- Caper version: [e.g. v0.6.1]



",yifeisun03,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/112
MDU6SXNzdWU1MzU4NDY2MDI=,spp step without output for a long time,CLOSED,2019-12-10T16:34:40Z,2019-12-16T16:51:59Z,2019-12-16T16:51:59Z,"Hello:

Do you know how long does spp peak calling normally takes? 

The pipeline still seems to be running( LSF mem use around 50G), and the only steps not ""all done"" are the call peaks steps(spp), I see all the output directly in my outdir( call-call-peak, call-call-peak-ppr1,etc). It's already been 24h since this step started, but there's no output at all in the ""execution"",stderr empty, tep empty. Is this normal, or should I be seeing some intermediate files being made? Thanks!


stdout(only for spp step) as below
[2019-12-09 11:28:32,489 INFO] ['/hpc/users/suny04/.conda/envs/encode-chip-seq-pipeline/bin/encode_task_spp.py', '/sc/orga/projects/walshm02a/Yifei/bsub/chip-caper/chip/3ec5a3d4-32cc-4a79-877b-6fa71b6e09\
c4/call-call_peak_pooled/inputs/32247729/A15_CKDL190138594-1a-AK445_HMFLWDSXX_L1_1.merged.nodup.pooled.tagAlign.gz', '/sc/orga/projects/walshm02a/Yifei/bsub/chip-caper/chip/3ec5a3d4-32cc-4a79-877b-6fa71b\
6e09c4/call-call_peak_pooled/inputs/-23361139/A20_CKDL190138594-1a-AK1668_HMFLWDSXX_L1_1.merged.nodup.pooled.tagAlign.gz', '--fraglen', '105', '--cap-num-peak', '300000', '--nth', '2']
[2019-12-09 11:28:32,489 INFO] Initializing and making output directory...
[2019-12-09 11:28:32,489 INFO] Calling peaks with spp...
[2019-12-09 11:28:32,518 INFO] run_shell_cmd: PID=337446, PGID=337446, CMD=Rscript --max-ppsize=500000 $(which run_spp.R) -c=/sc/orga/projects/walshm02a/Yifei/bsub/chip-caper/chip/3ec5a3d4-32cc-4a79-877b\
-6fa71b6e09c4/call-call_peak_pooled/inputs/32247729/A15_CKDL190138594-1a-AK445_HMFLWDSXX_L1_1.merged.nodup.pooled.tagAlign.gz -i=/sc/orga/projects/walshm02a/Yifei/bsub/chip-caper/chip/3ec5a3d4-32cc-4a79-\
877b-6fa71b6e09c4/call-call_peak_pooled/inputs/-23361139/A20_CKDL190138594-1a-AK1668_HMFLWDSXX_L1_1.merged.nodup.pooled.tagAlign.gz -npeak=300000 -odir=/sc/orga/projects/walshm02a/Yifei/bsub/chip-caper/c\
hip/3ec5a3d4-32cc-4a79-877b-6fa71b6e09c4/call-call_peak_pooled/execution -speak=105 -savr=A15_CKDL190138594-1a-AK445_HMFLWDSXX_L1_1.merged.nodup.pooled_x_A20_CKDL190138594-1a-AK1668_HMFLWDSXX_L1_1.merged\
.nodup.pooled.300K.regionPeak.gz.tmp -rf

**OS/Platform**
- OS/Platform: [LSF]
- Conda version: anaconda3/2018.12
- Pipeline version: [e.g. v1.3.4]
- Caper version: [e.g. v0.6.1]

",yifeisun03,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/113
MDU6SXNzdWU1MzcyNzA2NDQ=,Pipeline Execution Early Lock-up Issue,CLOSED,2019-12-12T23:36:42Z,2020-02-20T18:35:31Z,2020-02-20T18:35:31Z,"I am new to troubleshooting on here so apologies if this is improperly formatted.

Two months ago I was able to execute the pipeline on my data with no concerns or problems. When I tried to repeat the analysis this month, I am running into this recurring issue. The pipeline execution locks up very early on the following lines. 

```
2019-12-12 18:07:08,706 cromwell-system-akka.dispatchers.engine-dispatcher-114 INFO  - Not triggering log of token queue status. Effective log interval = None
2019-12-12 18:07:11,771 cromwell-system-akka.dispatchers.engine-dispatcher-41 INFO  - WorkflowExecutionActor-b5628076-8f0b-407b-b095-3c467129d7b9 [UUID(b5628076)]: Starting chip.read_genome_tsv
2019-12-12 18:07:13,721 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO  - Assigned new job execution tokens to the following groups: b5628076: 1
2019-12-12 18:07:13,923 cromwell-system-akka.dispatchers.backend-dispatcher-139 WARN  - BackgroundConfigAsyncJobExecutionActor [UUID(b5628076)chip.read_genome_tsv:NA:1]: Unrecognized runtime attribute keys: disks, cpu, time, memory
2019-12-12 18:07:14,143 cromwell-system-akka.dispatchers.backend-dispatcher-139 INFO  - BackgroundConfigAsyncJobExecutionActor [UUID(b5628076)chip.read_genome_tsv:NA:1]: `# create empty files for all entries
touch genome_name
touch ref_fa bowtie2_idx_tar bwa_idx_tar chrsz gensz blacklist blacklist2
touch custom_aligner_idx_tar
touch tss tss_enrich # for backward compatibility
touch dnase prom enh reg2map reg2map_bed roadmap_meta
touch mito_chr_name
touch regex_bfilt_peak_chr_name
python <<CODE
import os
with open('/chip_seq/2019/sample1_IDR_Stanford/chip/b5628076-8f0b-407b-b095-3c467129d7b9/call-read_genome_tsv/inputs/-1189284398/hg19.tsv','r') as fp:
        for line in fp:
                arr = line.strip('\n').split('\t')
                if arr:
                        key, val = arr
                        with open(key,'w') as fp2:
                                fp2.write(val)
CODE`
2019-12-12 18:07:14,308 cromwell-system-akka.dispatchers.backend-dispatcher-139 INFO  - BackgroundConfigAsyncJobExecutionActor [UUID(b5628076)chip.read_genome_tsv:NA:1]: executing: /chip_seq/2019/sample1_IDR_Stanford/chip/b5628076-8f0b-407b-b095-3c467129d7b9/call-read_genome_tsv/execution/script #         if [ -z ""$SINGULARITY_BINDPATH"" ]; then         export SINGULARITY_BINDPATH=; fi;         if [ -z ""$SINGULARITY_CACHEDIR"" ]; then         export SINGULARITY_CACHEDIR=; fi;         singularity exec --cleanenv --home /chip_seq/2019/sample1_IDR_Stanford/chip/b5628076-8f0b-407b-b095-3c467129d7b9/call-read_genome_tsv                   /chip_seq/2019/sample1_IDR_Stanford/chip/b5628076-8f0b-407b-b095-3c467129d7b9/call-read_genome_tsv/execution/script
2019-12-12 18:07:18,257 cromwell-system-akka.dispatchers.backend-dispatcher-139 INFO  - BackgroundConfigAsyncJobExecutionActor [UUID(b5628076)chip.read_genome_tsv:NA:1]: job id: 3993
2019-12-12 18:07:18,264 cromwell-system-akka.dispatchers.backend-dispatcher-140 INFO  - BackgroundConfigAsyncJobExecutionActor [UUID(b5628076)chip.read_genome_tsv:NA:1]: Status change from - to WaitingForReturnCode
```

This is prefaced by several dozen lines of 

`2019-12-12 18:07:06,957 cromwell-system-akka.dispatchers.backend-dispatcher-107 WARN  - Local [UUID(b5628076)]: Key/s [cpu, memory, time, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.`

[sample1.json.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/3958229/sample1.json.txt)

conda 4.7.12
caper 0.6.2

Any assistance would be greatly appreciated as this pipeline has worked well for the lab thus far. Thank you, ",AlekhP,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/114
MDU6SXNzdWU1Mzg1MTM5MjY=,error installing conda environment,CLOSED,2019-12-16T16:20:52Z,2020-02-20T18:52:54Z,2020-02-20T18:52:53Z,"**Describe the bug**
I get this error when running install_conda_env.sh

PaddingError: Placeholder of length '80' too short in package /net/waterston/vol2/home/waterston-jboss/miniconda3/envs/encode-chip-seq-pipeline/bin/Rscript.
The package must be rebuilt with conda-build > 2.0.

I have installed miniconda and conda --version is:
conda 4.8.0




",gevirl,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/115
MDU6SXNzdWU1Mzg1ODMxMzU=,call-idr-pr failed,CLOSED,2019-12-16T18:37:23Z,2019-12-17T20:59:22Z,2019-12-17T20:59:22Z,"Hello:

The pipeline failed with one line""Workflow 28f1a662-12b1-496e-b971-a71fe591901c transitioned to state Failed""in the .err file, but when I open the .out file and check for the detail, something looks wired.

In the .out file, I see ""Successfully completed"", but when I scroll down I see ""chip.idr_pr Failed."" on the bottom. This seems to be the only error in the workflow since ""[Caper] run:  1 28f1a662-12b1-496e-b971-a71fe591901c bsub/chip-caper/chip/28f1a662-12b1-496e-b971-a71fe591901c/metadata.json"" only found 1 error.

My other jobs finished ok with qc_report for the last step, but since spp takes too long, and sometimes overrun the wall time(144h), I add ""chip.peak_caller"" : ""macs2"" in my input json file, and this is the only difference from other finished jobs. 

In my output directory, I only see call-idr-pr and call-overlap-pr(finished fine), but lacking _ppr for both and call-idr and call-overlap compared to other fully finished jobs. In two independent jobs with ""mac2"" callers, I got the same error at the call-idr-pr step, and only in ""shard1"", while the parallel ""shard0"" finished ok, so I'm really not sure what's the problem here.

------------------------------------------------------
call-idr_pr stderr, the error messages are as below(basically the same as caper debug):
""Traceback (most recent call last):
  File ""/hpc/users/suny04/.conda/envs/encode-chip-seq-pipeline/bin/encode_task_idr.py"", line 180, in <module>
    main()
  File ""/hpc/users/suny04/.conda/envs/encode-chip-seq-pipeline/bin/encode_task_idr.py"", line 152, in main
    idr_peak, args.blacklist, args.regex_bfilt_peak_chr_name, args.out_dir)
  File ""/hpc/users/suny04/.conda/envs/encode-chip-seq-pipeline/bin/encode_lib_blacklist_filter.py"", line 54, in blacklist_filter
    run_shell_cmd(cmd)
  File ""/hpc/users/suny04/.conda/envs/encode-chip-seq-pipeline/bin/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=369350, PGID=369350, RC=1
STDERR=
STDOUT=""


- OS/Platform: hpc
- Pipeline version: [e.g. v1.3.4]
- Caper version: [e.g. v0.6.1]

Thank for your help!

",yifeisun03,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/116
MDU6SXNzdWU1NDI3MTg1NDU=,"call-call_peak error, file is empty",CLOSED,2019-12-27T02:24:18Z,2020-01-06T18:39:54Z,2020-01-06T18:39:53Z,"**Describe the bug**
Hi, I was running the pipeline for TF today with an error. The error message was pasted in the bottom. When I dig deeper, I found this message from the file chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak/shard-0/execution/stdout

```
...
processing chrUn_KI270754v1 in 1 steps [.] done ( 0 positions)
processing chrUn_KI270755v1 in 1 steps [.] done ( 0 positions)
processing chrUn_KI270756v1 in 1 steps [.] done ( 0 positions)
processing chrUn_KI270757v1 in 1 steps [.] done ( 1 positions)
processing chrUn_GL000214v1 in 1 steps [.] done ( 0 positions)
processing chrUn_KI270742v1 in 1 steps [.] done ( 2 positions)
processing chrUn_GL000216v2 in 1 steps [.] done ( 1 positions)
processing chrUn_GL000218v1 in 1 steps [.] done ( 1 positions)
excluding systematic background anomalies ... done
calculating statistical thresholds
FDR 0.99 threshold= Inf 
Detected 0 peaks
[2019-12-19 22:59:22,514 INFO] run_shell_cmd: PID=32, PGID=32, CMD=zcat -f RORgamma_SR8278.merged.nodup_x_ctl_for_rep1.300K.regionPeak.gz.tmp | awk 'BEGIN{OFS=""\t""}{if ($2<0) $2=0; print $1,int($2),int($3),$4,$5,$6,$7,$8,$9,$10;}' | gzip -f -nc > RORgamma_SR8278.merged.nodup_x_ctl_for_rep1.300K.regionPeak.gz
[2019-12-19 22:59:22,520 INFO] PID=32, PGID=32, RC=0
STDERR=
STDOUT=
[2019-12-19 22:59:22,523 INFO] run_shell_cmd: PID=36, PGID=36, CMD=rm -f RORgamma_SR8278.merged.nodup_x_ctl_for_rep1.300K.regionPeak.gz.tmp RORgamma_SR8278.merged.nodup_x_ctl_for_rep1.300K.regionPeak.gz.tmp.gz
[2019-12-19 22:59:22,527 INFO] PID=36, PGID=36, RC=0
STDERR=
STDOUT=
[2019-12-19 22:59:22,529 INFO] Checking if output is empty...
[2019-12-19 22:59:22,531 INFO] run_shell_cmd: PID=38, PGID=38, CMD=zcat -f RORgamma_SR8278.merged.nodup_x_ctl_for_rep1.300K.regionPeak.gz | wc -l
[2019-12-19 22:59:22,537 INFO] PID=38, PGID=38, RC=0
STDERR=
STDOUT=0
```

So it looks like the threshold calculated run_spp.R is somehow Inf thus no peak was kept.

**OS/Platform**
- OS/Platform: Ubuntu 18.01
- Pipeline version: 1.3.3
- Caper version: 0.6.1

**Caper configuration file**
```
backend=local

tmp-dir=temp
```

**Input JSON file**
```
{
    ""chip.title"" : ""RORgamma"",
    ""chip.description"" : ""RORgamma chip seq"",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"" : ""bwa"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/hg38_caper.tsv"",

    ""chip.paired_end"" : false,
    ""chip.ctl_paired_end"" : false,

    ""chip.always_use_pooled_ctl"" : false,

    ""chip.fastqs_rep1_R1"" : [ ""/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/RORgamma_SR8278.fq.gz"" ],
    ""chip.fastqs_rep2_R1"" : [ ""/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/RORgamma_SR2211.fq.gz"" ],
    ""chip.fastqs_rep3_R1"" : [ ""/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/RORgamma_Vehicle.fq.gz"" ],

    ""chip.ctl_fastqs_rep1_R1"" : [ ""/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/Input-RORgamma_SR8278.fq.gz"" ],
    ""chip.ctl_fastqs_rep2_R1"" : [ ""/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/Input-RORgamma_SR2211.fq.gz"" ],
    ""chip.ctl_fastqs_rep3_R1"" : [ ""/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/Input-RORgamma_Vehicle.fq.gz"" ],


    ""chip.align_cpu"": 32,
    ""chip.align_mem_mb"": 98304,

    ""chip.filter_cpu"": 8,
    ""chip.filter_mem_mb"": 49152,

    ""chip.bam2ta_cpu"": 4,
    ""chip.bam2ta_mem_mb"": 49152,

    ""chip.spr_mem_mb"": 49152,

    ""chip.jsd_cpu"": 8,
    ""chip.jsd_mem_mb"": 49152,

    ""chip.xcor_cpu"": 8,
    ""chip.xcor_mem_mb"": 49152,

    ""chip.call_peak_cpu"": 8,
    ""chip.call_peak_mem_mb"": 49152,

    ""chip.macs2_signal_track_mem_mb"": 49152
}
```

**Error log**

```
[Caper] troubleshooting 3516233a-e8eb-4cca-9c61-f05ce8c6881e ...
Found failures:
[
    {
        ""message"": ""Workflow failed"",
        ""causedBy"": [
            {
                ""causedBy"": [],
                ""message"": ""Job chip.call_peak_ppr2:NA:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            },
            {
                ""causedBy"": [],
                ""message"": ""Job chip.call_peak:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            },
            {
                ""causedBy"": [],
                ""message"": ""Job chip.call_peak:1:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            },
            {
                ""message"": ""Job chip.call_peak_ppr1:NA:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            }
        ]
    }
]

chip.call_peak_ppr1 RetryableFailure. SHARD_IDX=-1, RC=1, JOB_ID=376, RUN_START=2019-12-19T21:19:12.647Z, RUN_END=2019-12-19T23:19:54.449Z, STDOUT=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak_ppr1/execution/stdout, STDERR=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak_ppr1/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 103, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 94, in main
    assert_file_not_empty(rpeak)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 212, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (RORgamma_SR8278.merged.nodup.pr1.pooled_x_Input-RORgamma_SR8278.merged.nodup.pooled.300K.regionPeak.gz). Help: 


chip.call_peak_ppr1 Failed. SHARD_IDX=-1, RC=1, JOB_ID=24440, RUN_START=2019-12-19T23:19:54.643Z, RUN_END=2019-12-20T01:16:32.414Z, STDOUT=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak_ppr1/attempt-2/execution/stdout, STDERR=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak_ppr1/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 103, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 94, in main
    assert_file_not_empty(rpeak)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 212, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (RORgamma_SR8278.merged.nodup.pr1.pooled_x_Input-RORgamma_SR8278.merged.nodup.pooled.300K.regionPeak.gz). Help: 


chip.call_peak RetryableFailure. SHARD_IDX=0, RC=1, JOB_ID=2177, RUN_START=2019-12-19T21:20:22.643Z, RUN_END=2019-12-19T23:01:24.449Z, STDOUT=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak/shard-0/execution/stdout, STDERR=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 103, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 94, in main
    assert_file_not_empty(rpeak)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 212, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (RORgamma_SR8278.merged.nodup_x_ctl_for_rep1.300K.regionPeak.gz). Help: 


chip.call_peak Failed. SHARD_IDX=0, RC=1, JOB_ID=22683, RUN_START=2019-12-19T23:01:26.643Z, RUN_END=2019-12-20T00:34:51.143Z, STDOUT=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak/shard-0/attempt-2/execution/stdout, STDERR=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak/shard-0/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 103, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 94, in main
    assert_file_not_empty(rpeak)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 212, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (RORgamma_SR8278.merged.nodup_x_ctl_for_rep1.300K.regionPeak.gz). Help: 


chip.call_peak RetryableFailure. SHARD_IDX=1, RC=1, JOB_ID=1207, RUN_START=2019-12-19T21:20:10.646Z, RUN_END=2019-12-19T23:06:09.449Z, STDOUT=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak/shard-1/execution/stdout, STDERR=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak/shard-1/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 103, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 94, in main
    assert_file_not_empty(rpeak)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 212, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (RORgamma_SR2211.merged.nodup_x_ctl_for_rep2.300K.regionPeak.gz). Help: 


chip.call_peak Failed. SHARD_IDX=1, RC=1, JOB_ID=23352, RUN_START=2019-12-19T23:06:10.647Z, RUN_END=2019-12-20T00:49:40.991Z, STDOUT=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak/shard-1/attempt-2/execution/stdout, STDERR=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak/shard-1/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 103, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 94, in main
    assert_file_not_empty(rpeak)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 212, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (RORgamma_SR2211.merged.nodup_x_ctl_for_rep2.300K.regionPeak.gz). Help: 


chip.call_peak_ppr2 RetryableFailure. SHARD_IDX=-1, RC=1, JOB_ID=723, RUN_START=2019-12-19T21:19:16.646Z, RUN_END=2019-12-19T22:52:09.486Z, STDOUT=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak_ppr2/execution/stdout, STDERR=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak_ppr2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 103, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 94, in main
    assert_file_not_empty(rpeak)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 212, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (RORgamma_SR8278.merged.nodup.pr2.pooled_x_Input-RORgamma_SR8278.merged.nodup.pooled.300K.regionPeak.gz). Help: 


chip.call_peak_ppr2 Failed. SHARD_IDX=-1, RC=1, JOB_ID=22098, RUN_START=2019-12-19T22:52:10.643Z, RUN_END=2019-12-20T00:17:59.830Z, STDOUT=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak_ppr2/attempt-2/execution/stdout, STDERR=/home/hwclab/NGS_Data/ChIPseq_Rawdata_RORgamma_Lncap/caper_output_docker/chip/3516233a-e8eb-4cca-9c61-f05ce8c6881e/call-call_peak_ppr2/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 103, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 94, in main
    assert_file_not_empty(rpeak)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 212, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (RORgamma_SR8278.merged.nodup.pr2.pooled_x_Input-RORgamma_SR8278.merged.nodup.pooled.300K.regionPeak.gz). Help:
```
",zhuchcn,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/117
MDU6SXNzdWU1NDMwMzMwODc=,"Failed to access  *.gc.txt , for peak calling ",CLOSED,2019-12-28T00:52:04Z,2019-12-29T05:16:42Z,2019-12-29T05:16:42Z,"hi, 
I have the latest pipeline and the caper installed and the miniconda3 is also correctly installed.
The pipeline runs fine until it reaches to peak calling and it stops with this error:

****
File ""pandas/_libs/parsers.pyx"", line 382, in pandas._libs.parsers.TextReader.__cinit__

  File ""pandas/_libs/parsers.pyx"", line 689, in pandas._libs.parsers.TextReader._setup_parser_source

FileNotFoundError: [Errno 2] File b'hs_cpseq_cll_C1_bd_S9_R1_001.sorted.rmdup2.gc.txt' does not exist: b'hs_cpseq_cll_C1_bd_S9_R1_001.sorted.rmdup2.gc.txt'
****

### I ran this:

""caper debug ~/afs-home/../metadata.json
### and I got this:
ln: failed to access '/farmshare/user_data/baharehh/chip-seq-pipeline2/chip/52031527-edbb-4130-a1d7-3e61c6b5f39c/call-gc_bias/shard-0/attempt-2/execution/*.gc.txt': No such file or directory
chip.call_peak_pr2 Failed. SHARD_IDX=0, RC=None, JOB_ID=None, RUN_START=2019-12-28T00:01:51.844Z, RUN_END=2019-12-28T00:01:52.709Z, STDOUT=/farmshare/user_data/baharehh/chip-seq-pipeline2/chip/52031527-edbb-4130-a1d7-3e61c6b5f39c/call-call_peak_pr2/shard-0/execution/stdout, STDERR=/farmshare/user_data/baharehh/chip-seq-pipeline2/chip/52031527-edbb-4130-a1d7-3e61c6b5f39c/call-call_peak_pr2/shard-0/execution/stderr

would be great if you give me some advice on how to keep the run going
my best regards

April/B




",Baharehh,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/118
MDU6SXNzdWU1NDY2ODA2MDU=,pipeline fails to complete,CLOSED,2020-01-08T07:00:20Z,2020-02-20T18:53:37Z,2020-02-20T18:53:37Z,"**Describe the bug**
workflow fails at some point before peak calling. No peak calling output after croo.

**OS/Platform**
- OS/Platform: Ubuntu 18.04
- Conda version: 4.7.12
- Pipeline version: 1.3.4
- Caper version: 0.6.3

**Caper configuration file**
**backend=local
  
# DO NOT use /tmp here
# Caper stores all important temp files and cached big data files here
tmp-dir=/usr/local/lib/caper/**



**Input JSON file**
    ],
    ""chip.ctl_fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR936XTK/fastq_subsampled/ctl1-R1.subsampled.80.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R2"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR936XTK/fastq_subsampled/ctl1-R2.subsampled.80.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR936XTK/fastq_subsampled/ctl2-R1.subsampled.80.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep2_R2"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR936XTK/fastq_subsampled/ctl2-R2.subsampled.80.fastq.gz""
    ],
    ""chip.paired_end"" : true,
    ""chip.always_use_pooled_ctl"" : true,
    ""chip.title"" : ""ENCSR936XTK (subsampled 1/50, chr19 and chrM Only)"",
    ""chip.description"" : ""ZNF143 ChIP-seq on human GM12878""
}
~   

**Error log**
[metadata.json.zip](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4033936/metadata.json.zip)

",ychsiao1,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/119
MDU6SXNzdWU1NDY5NDkzMzU=,Pipeline fails in spp ,CLOSED,2020-01-08T15:56:00Z,2020-02-20T18:53:17Z,2020-02-20T18:53:17Z,"**Describe the bug**
A clear and concise description of what the problem is.

**OS/Platform** UGE cluster
- Conda version: 4.8.0
- Pipeline version: v1.3.4
- Caper version:  0.6.2

**Caper configuration file**
backend=sge
sge-pe=serial

tmp-dir=/net/waterston/vol9


**Input JSON file**
{""chip.title"":""hmg-20_RW12240_youngadult_1_1"",""chip.description"":""mkudron"",""chip.pipeline_type"":""tf"",""chip.always_use_pooled_ctl"":true,""chip.true_rep_only"":false,""chip.enable_count_signal_track"":true,""chip.aligner"":""bwa"",""chip.use_bwa_mem_for_pe"":true,""chip.align_only"":false,""chip.genome_tsv"":""/net/waterston/vol9/WS245/WS245.tsv"",""chip.peak_caller"":""spp"",""chip.fastqs_rep1_R1"":[""/net/waterston/vol9/ChipSeqPipeline/hmg-20_RW12240_youngadult_1/HMGIP1_371_206_S28_L002_R1_001.fastq.gz""],""chip.fastqs_rep1_R2"":[""/net/waterston/vol9/ChipSeqPipeline/hmg-20_RW12240_youngadult_1/HMGIP1_371_206_S28_L002_R2_001.fastq.gz""],""chip.fastqs_rep2_R1"":[""/net/waterston/vol9/ChipSeqPipeline/hmg-20_RW12240_youngadult_1/HMGIP2_359_218_S29_L002_R1_001.fastq.gz""],""chip.fastqs_rep2_R2"":[""/net/waterston/vol9/ChipSeqPipeline/hmg-20_RW12240_youngadult_1/HMGIP2_359_218_S29_L002_R2_001.fastq.gz""],""chip.paired_ends"":[true,true],""chip.ctl_fastqs_rep1_R1"":[""/net/waterston/vol9/ChipSeqPipeline/hmg-20_RW12240_youngadult_1/HMGinp_347_230_S30_L002_R1_001.fastq.gz""],""chip.ctl_fastqs_rep1_R2"":[""/net/waterston/vol9/ChipSeqPipeline/hmg-20_RW12240_youngadult_1/HMGinp_347_230_S30_L002_R2_001.fastq.gz""],""chip.ctl_paired_ends"":[true]}


output metadata.json
[metadata.json.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4036088/metadata.json.txt)

caper troubleshoot output
[troubleshoot.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4036096/troubleshoot.txt)
",gevirl,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/120
MDU6SXNzdWU1NTM1MjkyNTM=,Error while trimming when one fastq file present,CLOSED,2020-01-22T13:07:16Z,2020-02-20T18:56:35Z,2020-02-20T18:56:35Z,"When I have only one file in each rep and they are not gzipped, merging makes int copy with gz extension, however not actually compressing it.
This cause problems while trimming later.


def merge_fastqs(fastqs, end, out_dir):
    """"""make merged fastqs on $out_dir/R1, $out_dir/R2
    """"""
    out_dir = os.path.join(out_dir, end)
    mkdir_p(out_dir)
    prefix = os.path.join(out_dir,
                          os.path.basename(strip_ext_fastq(fastqs[0])))
    merged = '{}.merged.fastq.gz'.format(prefix)

    if len(fastqs) > 1:
        cmd = 'zcat -f {} | gzip -nc > {}'.format(
            ' '.join(fastqs),
            merged)
        run_shell_cmd(cmd)
        return merged
    else:
        **return copy_f_to_f(fastqs[0], merged)**

",irzhegalova,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/122
MDU6SXNzdWU1NTcxNTgxMzU=,"Error when organizing output from the function call ""count_signal_track_pooled"" using croo",CLOSED,2020-01-29T22:35:01Z,2020-01-30T03:13:18Z,2020-01-30T03:13:18Z,"**Describe the bug**
When I ran croo to organize the output from a successfully finished chip-seq pipeline, I got ""TypeError"" when it tried to gather results from the `call-count_signal_track_pooled` folder (see error log below)

**OS/Platform**
- OS/Platform: Ubuntu 16.04.3 LTS
- Conda version: 4.7.11
- Pipeline version: v1.3.5.1
- Caper version: 0.6.3
- Croo version: 0.3.4

**Caper configuration file**
backend=local
tmp-dir=/scratch

**Error log**

```
[CaperURI] copying done, target: /cndd2/junhao/dnmt3aKO/chipseq/run_encode_chipseq_pipeline2/organized_results_FC_Control_MTF2/signal/rep1/FC_Control_MTF2_rep1_R1.merged.nodup.no_chrM.negative.bigwig
[CaperURI] copying from local to local, src: /cndd2/junhao/dnmt3aKO/chipseq/run_encode_chipseq_pipeline2/chip/ae1cef94-09f3-415c-91e0-d2abf9bd51ce/call-count_signal_track/shard-1/execution/glob-f8fdf5221d9fbe0d1140ab1532779443/FC_Control_MTF2_rep2_R1.merged.nodup.no_chrM.negative.bigwig
[CaperURI] copying done, target: /cndd2/junhao/dnmt3aKO/chipseq/run_encode_chipseq_pipeline2/organized_results_FC_Control_MTF2/signal/rep2/FC_Control_MTF2_rep2_R1.merged.nodup.no_chrM.negative.bigwig
[CaperURI] copying from local to local, src: /cndd2/junhao/dnmt3aKO/chipseq/run_encode_chipseq_pipeline2/chip/ae1cef94-09f3-415c-91e0-d2abf9bd51ce/call-count_signal_track_pooled/execution/glob-079074fef208d29e859788ed8db804b6/basename_prefix.pooled.positive.bigwig
[CaperURI] copying done, target: /cndd2/junhao/dnmt3aKO/chipseq/run_encode_chipseq_pipeline2/organized_results_FC_Control_MTF2/signal/pooled-rep/basename_prefix.pooled.positive.bigwig
Traceback (most recent call last):
  File ""/cndd/junhao/anaconda3/envs/encode-chip-seq-pipeline/bin/croo"", line 13, in <module>
    main()
  File ""/cndd/junhao/anaconda3/envs/encode-chip-seq-pipeline/lib/python3.7/site-packages/croo/croo.py"", line 306, in main
    co.organize_output()
  File ""/cndd/junhao/anaconda3/envs/encode-chip-seq-pipeline/lib/python3.7/site-packages/croo/croo.py"", line 182, in organize_output
    subgraph, full_path, shard_idx)
  File ""/cndd/junhao/anaconda3/envs/encode-chip-seq-pipeline/lib/python3.7/site-packages/croo/croo.py"", line 237, in __interpret_inline_exp
    result = result.replace(m.group(0), str(eval(m.group(1))), 1)
  File ""<string>"", line 1, in <module>
TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'
```

**solution**

I believe this is because that line 346 and line 354 in the file `chip.croo.v3.json` are swapped: 
https://github.com/ENCODE-DCC/chip-seq-pipeline2/blob/209a71d1041a6e185c8ec9c113ebbeffc6c43abd/chip.croo.v3.json#L335-L362

Simply swap these two lines will resolve the issue:
```
  ""chip.count_signal_track"": {
    ""pos_bw"": {
      ""path"": ""signal/rep${i+1}/${basename}"",
      ""table"": ""Signal/Replicate ${i+1}/Count signal track (positive)"",
      ""node"": ""[shape=box style=\""filled, rounded\"" fillcolor=lightyellow label=\""Count +\\nSignal\""]"",
      ""subgraph"": ""cluster_rep${i+1}""
    },
    ""neg_bw"": {
      ""path"": ""signal/rep${i+1}/${basename}"",
      ""table"": ""Signal/Replicate ${i+1}/Count signal track (negative)"",
      ""node"": ""[shape=box style=\""filled, rounded\"" fillcolor=lightyellow label=\""Count -\\nSignal\""]"",
      ""subgraph"": ""cluster_rep${i+1}""
    }
  },
  ""chip.count_signal_track_pooled"": {
    ""pos_bw"": {
      ""path"": ""signal/pooled-rep/${basename}"",
      ""table"": ""Signal/Pooled replicate/Count signal track (positive)"",
      ""node"": ""[shape=box style=\""filled, rounded\"" fillcolor=lightyellow label=\""Count +\\nSignal\""]"",
      ""subgraph"": ""cluster_pooled_rep""
    },
    ""neg_bw"": {
      ""path"": ""signal/pooled-rep/${basename}"",
      ""table"": ""Signal/Pooled replicate/Count signal track (negative)"",
      ""node"": ""[shape=box style=\""filled, rounded\"" fillcolor=lightyellow label=\""Count -\\nSignal\""]"",
      ""subgraph"": ""cluster_pooled_rep""
    }
  },
```",hoholee,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/125
MDU6SXNzdWU1NjE4MzIxNzU=,spp fails processing one pseudo rep,CLOSED,2020-02-07T19:39:34Z,2020-02-20T18:56:21Z,2020-02-20T18:56:20Z,"**Describe the bug**
spp fails in step call-call_peak_pr2 for shard-1 , but has not problem with shard-0

**OS/Platform**
-Centos 6.10  and UGE 
- Conda version: 4.7.12
- Pipeline version: v1.3.2
- Caper version:0.6.3

**Caper configuration file**
backend=sge
sge-pe=serial

# DO NOT use /tmp here
# Caper stores all important temp files and cached big data files here
tmp-dir=/net/waterston/vol9


**Input JSON file**
{""chip.title"":""dmd-8_OP775_L4larva_1_1"",""chip.description"":""gevirl"",""chip.always_use_pooled_ctl"":false,""chip.true_rep_only"":false,""chip.enable_count_signal_track"":true,""chip.aligner"":""bwa"",""chip.use_bwa_mem_for_pe"":true,""chip.align_only"":false,""chip.genome_tsv"":""/net/waterston/vol9/WS245/WS245.tsv"",""chip.peak_caller"":""spp"",""chip.pipeline_type"":""tf"",""chip.idr_thresh"":0.05,""chip.call_peak_mem_mb"":16000,""chip.align_mem_mb"":24000,""chip.fastqs_rep1_R1"":[""/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/DMDIP1_018_175_S73_L004_R1_001.fastq.gz""],""chip.fastqs_rep1_R2"":[""/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/DMDIP1_018_175_S73_L004_R2_001.fastq.gz""],""chip.fastqs_rep2_R1"":[""/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/DMDIP2_006_187_S74_L004_R1_001.fastq.gz""],""chip.fastqs_rep2_R2"":[""/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/DMDIP2_006_187_S74_L004_R2_001.fastq.gz""],""chip.paired_ends"":[true,true],""chip.ctl_fastqs_rep1_R1"":[""/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/DMDinp_089_104_S75_L004_R1_001.fastq.gz""],""chip.ctl_fastqs_rep1_R2"":[""/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/DMDinp_089_104_S75_L004_R2_001.fastq.gz""],""chip.ctl_paired_ends"":[true]}

**Error log**
Caper automatically runs a troubleshooter for failed workflows. If it doesn't then get a `WORKFLOW_ID` of your failed workflow with `caper list` or directly use a `metadata.json` file on Caper's output directory.
```
$ caper debug [WORKFLOW_ID_OR_METADATA_JSON_FILE]
caper debug metadata.json
[Caper] troubleshooting 103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3 ...
Found failures:
[
    {
        ""causedBy"": [
            {
                ""message"": ""Job chip.call_peak_pr2:1:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            }
        ],
        ""message"": ""Workflow failed""
    }
]

chip.call_peak_pr2 RetryableFailure. SHARD_IDX=1, RC=1, JOB_ID=151133162, RUN_START=2020-02-07T17:32:28.216Z, RUN_END=2020-02-07T18:05:01.934Z, STDOUT=/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution/stdout, STDERR=/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/net/waterston/vol2/home/waterston-jboss/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_spp.py"", line 103, in <module>
    main()
  File ""/net/waterston/vol2/home/waterston-jboss/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_spp.py"", line 91, in main
    args.fraglen, args.cap_num_peak, args.nth, args.out_dir)
  File ""/net/waterston/vol2/home/waterston-jboss/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_spp.py"", line 66, in spp
    run_shell_cmd(cmd0)
  File ""/net/waterston/vol2/home/waterston-jboss/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=4156, PGID=4156, RC=1
STDERR=Loading required package: Rcpp
Error in lwcc(x, y, s, e, return.peaks = return.peaks, bg.x = bg.x, bg.y = bg.y,  : 
  INTEGER() can only be applied to a 'integer', not a 'NULL'
Calls: find.binding.positions ... FUN -> window.chr.call.mirror.binding -> method -> lwcc
Execution halted
STDOUT=################
ChIP data: /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/inputs/1771568480/DMDIP2_006_187_S74_L004_R1_001.merged.nodup.pr2.tagAlign.gz 
Control data: /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/inputs/2045518733/ctl_for_rep2.tagAlign.gz 
strandshift(min): -500 
strandshift(step): 5 
strandshift(max) 1500 
user-defined peak shift 150 
exclusion(min): 10 
exclusion(max): NaN 
num parallel nodes: NA 
FDR threshold: 0.01 
NumPeaks Threshold: 3e+05 
Output Directory: /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution 
narrowPeak output file name: NA 
regionPeak output file name: DMDIP2_006_187_S74_L004_R1_001.merged.nodup.pr2_x_ctl_for_rep2.300K.regionPeak.gz.tmp 
Rdata filename: NA 
plot pdf filename: NA 
result filename: NA 
Overwrite files?: TRUE

Decompressing ChIP file
Decompressing control file
Reading ChIP tagAlign/BAM file /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/inputs/1771568480/DMDIP2_006_187_S74_L004_R1_001.merged.nodup.pr2.tagAlign.gz 
opened /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/tmp.f62e18c0/RtmptCaU3P/DMDIP2_006_187_S74_L004_R1_001.merged.nodup.pr2.tagAlign103e4a4390ed
done. read 8804966 fragments
ChIP data read length 101 
[1] TRUE
Reading Control tagAlign/BAM file /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/inputs/2045518733/ctl_for_rep2.tagAlign.gz 
opened /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/tmp.f62e18c0/RtmptCaU3P/ctl_for_rep2.tagAlign103e26419335
done. read 18000300 fragments
Control data read length 101 
Calculating peak characteristics
Minimum cross-correlation value 0.770026 
Minimum cross-correlation shift 1500 
Top 3 cross-correlation values 0.784787400538734 
Top 3 estimates for fragment length 150 
Window half size 230 
Phantom peak location 105 
Phantom peak Correlation 0.7851819 
Normalized Strand cross-correlation coefficient (NSC) 1.01917 
Relative Strand cross-correlation Coefficient (RSC) 0.9739724 
Phantom Peak Quality Tag 0 
Removing read stacks
Finding peaks
finding background exclusion regions ... done
determining peaks on provided 1 control datasets:
using reversed signal for FDR calculations
bg.weight= 2.055662  processing X in 1 steps [.] done ( 27093 positions)
processing V in 1 steps [
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution/*[!.][!b][!f][!i][!l][!t].regionPeak.gz': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution/*.bfilt.regionPeak.gz': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution/*.bfilt.regionPeak.bb': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory
mkdir: cannot create directory `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution/glob-c71d4cca8627aab27dc3503b7db7a39d': File exists
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution/*.frip.qc': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution/*.peak_region_size.qc': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution/*.peak_region_size.png': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/execution/*.num_peak.qc': No such file or directory


chip.call_peak_pr2 Failed. SHARD_IDX=1, RC=1, JOB_ID=151134594, RUN_START=2020-02-07T18:05:04.213Z, RUN_END=2020-02-07T18:38:03.771Z, STDOUT=/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution/stdout, STDERR=/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/net/waterston/vol2/home/waterston-jboss/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_spp.py"", line 103, in <module>
    main()
  File ""/net/waterston/vol2/home/waterston-jboss/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_spp.py"", line 91, in main
    args.fraglen, args.cap_num_peak, args.nth, args.out_dir)
  File ""/net/waterston/vol2/home/waterston-jboss/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_spp.py"", line 66, in spp
    run_shell_cmd(cmd0)
  File ""/net/waterston/vol2/home/waterston-jboss/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=12235, PGID=12235, RC=1
STDERR=Loading required package: Rcpp
Error in lwcc(x, y, s, e, return.peaks = return.peaks, bg.x = bg.x, bg.y = bg.y,  : 
  INTEGER() can only be applied to a 'integer', not a 'character'
Calls: find.binding.positions ... FUN -> window.chr.call.mirror.binding -> method -> lwcc
Execution halted
STDOUT=################
ChIP data: /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/inputs/1771568480/DMDIP2_006_187_S74_L004_R1_001.merged.nodup.pr2.tagAlign.gz 
Control data: /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/inputs/2045518733/ctl_for_rep2.tagAlign.gz 
strandshift(min): -500 
strandshift(step): 5 
strandshift(max) 1500 
user-defined peak shift 150 
exclusion(min): 10 
exclusion(max): NaN 
num parallel nodes: NA 
FDR threshold: 0.01 
NumPeaks Threshold: 3e+05 
Output Directory: /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution 
narrowPeak output file name: NA 
regionPeak output file name: DMDIP2_006_187_S74_L004_R1_001.merged.nodup.pr2_x_ctl_for_rep2.300K.regionPeak.gz.tmp 
Rdata filename: NA 
plot pdf filename: NA 
result filename: NA 
Overwrite files?: TRUE

Decompressing ChIP file
Decompressing control file
Reading ChIP tagAlign/BAM file /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/inputs/1771568480/DMDIP2_006_187_S74_L004_R1_001.merged.nodup.pr2.tagAlign.gz 
opened /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/tmp.cacea48b/RtmpYgK4Lo/DMDIP2_006_187_S74_L004_R1_001.merged.nodup.pr2.tagAlign2fcd5e172b85
done. read 8804966 fragments
ChIP data read length 101 
[1] TRUE
Reading Control tagAlign/BAM file /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/inputs/2045518733/ctl_for_rep2.tagAlign.gz 
opened /net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/tmp.cacea48b/RtmpYgK4Lo/ctl_for_rep2.tagAlign2fcd5bfa31af
done. read 18000300 fragments
Control data read length 101 
Calculating peak characteristics
Minimum cross-correlation value 0.770026 
Minimum cross-correlation shift 1500 
Top 3 cross-correlation values 0.784787400538734 
Top 3 estimates for fragment length 150 
Window half size 230 
Phantom peak location 105 
Phantom peak Correlation 0.7851819 
Normalized Strand cross-correlation coefficient (NSC) 1.01917 
Relative Strand cross-correlation Coefficient (RSC) 0.9739724 
Phantom Peak Quality Tag 0 
Removing read stacks
Finding peaks
finding background exclusion regions ... done
determining peaks on provided 1 control datasets:
using reversed signal for FDR calculations
bg.weight= 2.055662  processing X in 1 steps [.] done ( 27093 positions)
processing V in 1 steps [
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution/*[!.][!b][!f][!i][!l][!t].regionPeak.gz': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution/*.bfilt.regionPeak.gz': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution/*.bfilt.regionPeak.bb': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory
mkdir: cannot create directory `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution/glob-c71d4cca8627aab27dc3503b7db7a39d': File exists
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution/*.frip.qc': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution/*.peak_region_size.qc': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution/*.peak_region_size.png': No such file or directory
ln: accessing `/net/waterston/vol9/ChipSeqPipeline/dmd-8_OP775_L4larva_1/chip/103b5ab5-d9d5-41ca-8b00-1e8fc71ef8b3/call-call_peak_pr2/shard-1/attempt-2/execution/*.num_peak.qc': No such file or directory
",gevirl,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/126
MDU6SXNzdWU1NjYzNjU1Mjc=,p-val vs fc,CLOSED,2020-02-17T15:18:06Z,2020-02-17T18:00:29Z,2020-02-17T18:00:29Z,"Hello. Sorry if this is a basic question but I think this is the best place for it. 
In both versions of the AQUAS pipeline, two bigwig files are generated, pval and fold-change. My question is to which one is a more reliable metric for ChIP-seq signal generated at a given locus. Pval is usually much cleaner when viewed on a track browser, but I am worried that this signal-noise ratio is somewhat artificial. If I wanted to generate a table of all peaks with their average signal taken from a bigwig, which bigwig would be most appropriate to use? The narrowPeak files have some signal score information, but I have found it to be an unreliable quantitative measure of the signal for a given peak.
Thank you very much.",jloupe,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/127
MDU6SXNzdWU1NzQyMzI4ODc=,SGE qsub not requesting enough virtual memory to initialize Java virtual machine,OPEN,2020-03-02T20:36:52Z,2020-11-16T22:44:00Z,,"**Describe the bug**
Hi I am running the pipeline in an SGE environment, but running into issues at the encode_task_filter step with virtual memory.

Currently it seems the default memory request for encode_task_filter step is 20GB, and so the SGE qsub requests 4 cores with 5GB each of virtual memory (-pe smp 4 -l h_vmem=5GB -l s_vmem=5GB). However, to run picard in this task, the java virtual machine upon initialization will request 20GB for its heap, plus usually 1GB default for metaspace, on top of other requirements. As a result, this step ends up requiring more than 20GB in virtual memory, resulting in the error:

Error occurred during initialization of VM
Could not reserve enough space for 20971520KB object heap

I have played around with this and increasing the qsub virtual memory request to 23GB seems likely to solve the problem. Less than that, but more than 20GB and the JVM has trouble allocating metaspace, resulting in something like:

Error occurred during initialization of VM
Could not allocate metaspace: 1073741824 bytes

For now, adding the following line to the default.conf file fixes the issue, but its a little hacky
sge-extra-param=-l h_vmem=23G -l s_vmem=23G

Would it be possible to modify the qsub -l h_vmem and -l s_vmem parameters in a future release so instead of requesting X/#threads of virtual memory, where X=memory-limit for a particular task, have qsub request something like (X+5GB)/#threads so there is a little extra space to initialize the JVM? Thanks

**OS/Platform**
- OS/Platform: CentOS Linux 7
- Conda version: conda 4.8.0
- Pipeline version: 1.3.6
- Caper version: 0.4.1

**Caper configuration file**
backend=sge
sge-pe=smp

tmp-dir=/wynton/scratch

**Input JSON file**
{
    ""chip.pipeline_type"" : ""tf"",
    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v1/hg38_chr19_chrM_caper.tsv"",
    ""chip.fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR936XTK/fastq_subsampled/rep1-R1.subsampled.50.fastq.gz""
    ],
    ""chip.fastqs_rep1_R2"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR936XTK/fastq_subsampled/rep1-R2.subsampled.50.fastq.gz""
    ],
    ""chip.fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR936XTK/fastq_subsampled/rep2-R1.subsampled.50.fastq.gz""
    ],
    ""chip.fastqs_rep2_R2"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR936XTK/fastq_subsampled/rep2-R2.subsampled.50.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR936XTK/fastq_subsampled/ctl1-R1.subsampled.80.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R2"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR936XTK/fastq_subsampled/ctl1-R2.subsampled.80.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR936XTK/fastq_subsampled/ctl2-R1.subsampled.80.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep2_R2"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR936XTK/fastq_subsampled/ctl2-R2.subsampled.80.fastq.gz""
    ],
    ""chip.paired_end"" : true,
    ""chip.always_use_pooled_ctl"" : true,
    ""chip.title"" : ""ENCSR936XTK (subsampled 1/50, chr19 and chrM Only)"",
    ""chip.description"" : ""ZNF143 ChIP-seq on human GM12878""
}

**Error log**
[errorlog.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4277759/errorlog.txt)

",xiaofanjin,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/132
MDU6SXNzdWU1NzQzMTk4MTQ=,spp. chip.call_peak RetryableFailure,OPEN,2020-03-02T23:42:04Z,2020-03-30T19:09:17Z,,"**Describe the bug**
Hi, i was running the pipeline for TF with error. And the error was pasted in the bottom. 

....
[Caper] troubleshooting 49bc38e3-3a8d-4c65-8d22-5c4dc2f37f74 ...
Found failures:
[
    {
        ""causedBy"": [
            {
                ""message"": ""Job chip.call_peak_pooled:NA:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            },
            {
                ""message"": ""Job chip.call_peak:1:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            },
            {
                ""message"": ""Job chip.call_peak_pr2:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            },
            {
                ""message"": ""Job chip.call_peak:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            },
            {
                ""message"": ""Job chip.call_peak_ppr2:NA:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            }
        ],
        ""message"": ""Workflow failed""
    }
]

chip.call_peak RetryableFailure. SHARD_IDX=0, RC=1, JOB_ID=20508, RUN_START=2020-02-28T19:20:16.079Z, RUN_END=2020-02-28T23:39:13.988Z, STDOUT=/home/hwclab/NGS_Data/reverb-project/201904_DCai_REV-ERBa_EvansLba_abs_SR8278_7.5_ENZ_20_24hrs-ing/Clean/caper_output_docker/chip/49bc38e3-3a8d-4c65-8d22-5c4dc2f37f74/call-call_peak/shard-0/execution/stdout, STDERR=/home/hwclab/NGS_Data/reverb-project/201904_DCai_REV-ERBa_EvansLba_abs_SR8278_7.5_ENZ_20_24hrs-ing/Clean/caper_output_docker/chip/49bc38e3-3a8d-4c65-8d22-5c4dc2f37f74/call-call_peak/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 103, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 91, in main
    args.fraglen, args.cap_num_peak, args.nth, args.out_dir)
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 66, in spp
    run_shell_cmd(cmd0)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=16, PGID=16, RC=1
STDERR=Loading required package: caTools
There were 24 warnings (use warnings() to see them)
Error in data.frame(..., check.names = FALSE) : 
  arguments imply differing number of rows: 1, 0
Calls: find.binding.positions ... calculate.enrichment.estimates -> lapply -> FUN -> cbind -> cbind -> data.frame
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Execution halted
STDOUT=################
ChIP data: /cromwell-executions/chip/49bc38e3-3a8d-4c65-8d22-5c4dc2f37f74/call-call_peak/shard-0/inputs/-623737054/reverb_SR8278.merged.nodup.tagAlign.gz 
Control data: /cromwell-executions/chip/49bc38e3-3a8d-4c65-8d22-5c4dc2f37f74/call-call_peak/shard-0/inputs/812910509/ctl_for_rep1.tagAlign.gz 
:


****
- OS/Platform:Ubuntu 18.01
- Pipeline version: 1.3.3
- Caper version: 0.6.1

**Caper configuration file**
backend=local
tmp-dir=temp

**Input JSON file**
""chip.title"" : ""reverb"",
    ""chip.description"" : ""reverb chip seq"",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"" : ""bwa"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""/home/hwclab/NGS_Data/reverb-project/201904_DCai_REV-ERBa_EvansLba_abs_SR8278_7.5_ENZ_20_24hrs-ing/Clean/hg38_caper.tsv"",

    ""chip.paired_end"" : false,
    ""chip.ctl_paired_end"" : false,

    ""chip.always_use_pooled_ctl"" : false,

    ""chip.fastqs_rep1_R1"" : [ ""/home/hwclab/NGS_Data/reverb-project/201904_DCai_REV-ERBa_EvansLba_abs_SR8278_7.5_ENZ_20_24hrs-ing/Clean/reverb_SR8278.fq.gz"" ],
    ""chip.fastqs_rep2_R1"" : [ ""/home/hwclab/NGS_Data/reverb-project/201904_DCai_REV-ERBa_EvansLba_abs_SR8278_7.5_ENZ_20_24hrs-ing/Clean/reverb_Vehicle.fq.gz"" ],

    ""chip.ctl_fastqs_rep1_R1"" : [ ""/home/hwclab/NGS_Data/reverb-project/201904_DCai_REV-ERBa_EvansLba_abs_SR8278_7.5_ENZ_20_24hrs-ing/Clean/Input_SR8278.fq.gz"" ],
    ""chip.ctl_fastqs_rep2_R1"" : [ ""/home/hwclab/NGS_Data/reverb-project/201904_DCai_REV-ERBa_EvansLba_abs_SR8278_7.5_ENZ_20_24hrs-ing/Clean/Input_Vehicle.fq.gz"" ],


    ""chip.align_cpu"": 16,
    ""chip.align_mem_mb"": 32768,

    ""chip.filter_cpu"": 4,
    ""chip.filter_mem_mb"": 24576,

    ""chip.bam2ta_cpu"": 2,
    ""chip.bam2ta_mem_mb"": 24576,

    ""chip.spr_mem_mb"": 24576,

    ""chip.jsd_cpu"": 4,
    ""chip.jsd_mem_mb"": 24576,

    ""chip.xcor_cpu"": 4,
    ""chip.xcor_mem_mb"": 24576,

    ""chip.call_peak_cpu"": 4,
    ""chip.call_peak_mem_mb"": 24576,

    ""chip.macs2_signal_track_mem_mb"": 24576
}

**Error log**
[Caper] troubleshooting 49bc38e3-3a8d-4c65-8d22-5c4dc2f37f74 ...
Found failures:
[
    {
        ""causedBy"": [
            {
                ""message"": ""Job chip.call_peak_pooled:NA:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            },
            {
                ""message"": ""Job chip.call_peak:1:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            },
            {
                ""message"": ""Job chip.call_peak_pr2:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            },
            {
                ""message"": ""Job chip.call_peak:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            },
            {
                ""message"": ""Job chip.call_peak_ppr2:NA:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            }
        ],
        ""message"": ""Workflow failed""
    }
]

chip.call_peak RetryableFailure. SHARD_IDX=0, RC=1, JOB_ID=20508, RUN_START=2020-02-28T19:20:16.079Z, RUN_END=2020-02-28T23:39:13.988Z, STDOUT=/home/hwclab/NGS_Data/reverb-project/201904_DCai_REV-ERBa_Eva
nsLba_abs_SR8278_7.5_ENZ_20_24hrs-ing/Clean/caper_output_docker/chip/49bc38e3-3a8d-4c65-8d22-5c4dc2f37f74/call-call_peak/shard-0/execution/stdout, STDERR=/home/hwclab/NGS_Data/reverb-project/201904_DCai_R
EV-ERBa_EvansLba_abs_SR8278_7.5_ENZ_20_24hrs-ing/Clean/caper_output_docker/chip/49bc38e3-3a8d-4c65-8d22-5c4dc2f37f74/call-call_peak/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 103, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 91, in main
    args.fraglen, args.cap_num_peak, args.nth, args.out_dir)
  File ""/software/chip-seq-pipeline/src/encode_task_spp.py"", line 66, in spp
    run_shell_cmd(cmd0)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=16, PGID=16, RC=1
STDERR=Loading required package: caTools
There were 24 warnings (use warnings() to see them)
Error in data.frame(..., check.names = FALSE) : 
  arguments imply differing number of rows: 1, 0
Calls: find.binding.positions ... calculate.enrichment.estimates -> lapply -> FUN -> cbind -> cbind -> data.frame
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Execution halted
STDOUT=################
ChIP data: /cromwell-executions/chip/49bc38e3-3a8d-4c65-8d22-5c4dc2f37f74/call-call_peak/shard-0/inputs/-623737054/reverb_SR8278.merged.nodup.tagAlign.gz 
Control data: /cromwell-executions/chip/49bc38e3-3a8d-4c65-8d22-5c4dc2f37f74/call-call_peak/shard-0/inputs/812910509/ctl_for_rep1.tagAlign.gz 
:

```
",yatianyang2019,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/133
MDU6SXNzdWU1NzY0NTYzMjU=,Errors at end of pipeline,CLOSED,2020-03-05T18:42:30Z,2020-05-29T15:42:05Z,2020-05-29T15:42:05Z,"**Describe the bug**
I was able to run the ECODE chip seq pipeline on my own dataset starting from adapter-trimmed fastq.gz files. However, near the end of the pipeline I encountered a few errors which I am having trouble interpreting. 

**OS/Platform**
- OS/Platform: Ubuntu 16.04
- Conda version: 4.7.12
- Pipeline version: 1.3.6
- Caper version: 0.6.4

**Caper configuration file**
backend=local

# DO NOT use /tmp here
# Caper stores all important temp files and cached big data files here
tmp-dir=./intermediate_caper_files

**Input JSON file**
{
    ""chip.pipeline_type"" : ""tf"",
    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v1/hg19_caper.tsv"",
    ""chip.fastqs_rep1_R1"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_ChIP-JF_GTACIndex1_TGAGGTTATC_AGATCTCG_S5_R1_001.fastq_trim.gz""],
    ""chip.fastqs_rep1_R2"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_ChIP-JF_GTACIndex1_TGAGGTTATC_AGATCTCG_S5_R2_001.fastq_trim.gz""],
    ""chip.fastqs_rep2_R1"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_ChIP-EZH2-Rep-2_GTAC-Index3_ATGACAGATC_S12_R1_001.fastq_trim.gz""],
    ""chip.fastqs_rep2_R2"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_ChIP-EZH2-Rep-2_GTAC-Index3_ATGACAGATC_S12_R2_001.fastq.gz""],
    ""chip.fastqs_rep3_R1"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_Jen-EZH2R1_GTACIndex2_GCTTAGAATC_S6_R1_001.fastq_trim.gz""],
    ""chip.fastqs_rep3_R2"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_Jen-EZH2R1_GTACIndex2_GCTTAGAATC_S6_R2_001.fastq_trim.gz""],
    ""chip.fastqs_rep4_R1"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_Jen-EZH2R2_GTACIndex5_ATCGAGCATC_S8_R1_001.fastq_trim.gz""],
    ""chip.fastqs_rep4_R2"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_Jen-EZH2R2_GTACIndex5_ATCGAGCATC_S8_R2_001.fastq_trim.gz""],
    ""chip.ctl_fastqs_rep1_R1"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_ChIP_ChIP-input_GTAC_Index45_GATAGTTATC_S4_R1_001.fastq_trim.gz""],
    ""chip.ctl_fastqs_rep1_R2"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_ChIP_ChIP-input_GTAC_Index45_GATAGTTATC_S4_R2_001.fastq_trim.gz""],
    ""chip.ctl_fastqs_rep2_R1"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_ChIP-Input-Rep-2_GTAC-Index2_GCTTAGAATC_S10_R1_001.fastq_trim.gz""],
    ""chip.ctl_fastqs_rep2_R2"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_ChIP-Input-Rep-2_GTAC-Index2_GCTTAGAATC_S10_R2_001.fastq_trim.gz""],
    ""chip.ctl_fastqs_rep3_R1"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_Jen-InputR1_GTACIndex4_CACCTCCATC_S7_R1_001.fastq_trim.gz""],
    ""chip.ctl_fastqs_rep3_R2"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_Jen-InputR1_GTACIndex4_CACCTCCATC_S7_R2_001.fastq_trim.gz""],
    ""chip.ctl_fastqs_rep4_R1"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_Jen-InputR2_GTACIndex6_TACTCTAATC_S9_R1_001.fastq_trim.gz""],
    ""chip.ctl_fastqs_rep4_R2"" : [""https://wangftp.wustl.edu/~jflynn/H1299/adapter_trimmed_fastq_files_reps_1_through_4/WangT_Jen-InputR2_GTACIndex6_TACTCTAATC_S9_R2_001.fastq_trim.gz""],
    ""chip.paired_end"" : true,
    ""chip.ctl_paired_end"" : true,
    ""chip.title"" : ""EZH2 in H1299 Reps 1-4"",
    ""chip.description"" : ""EZH2 ChIP-seq on H1299 for Replicates 1-4""
}
**Error log**
[Caper] troubleshooting 2d9dd1b7-c037-44f7-937b-3687b81eb5c7 ...
Found failures:
[
    {
        ""causedBy"": [
            {
                ""causedBy"": [],
                ""message"": ""Job chip.idr:2:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            }
        ],
        ""message"": ""Workflow failed""
    }
]

chip.idr RetryableFailure. SHARD_IDX=2, RC=1, JOB_ID=40041, RUN_START=2020-03-05T07:16:51.118Z, RUN_END=2020-03-05T07:20:36.014Z, STDOUT=/tavern/jflynn/Projects/metastasis/ChIP_seq_EZH2_H1299/calculate_cross_correlation/my_data/chip/2d9dd1b7-c037-44f7-937b-3687b81eb5c7/call-idr/shard-2/execution/stdout, STDERR=/tavern/jflynn/Projects/metastasis/ChIP_seq_EZH2_H1299/calculate_cross_correlation/my_data/chip/2d9dd1b7-c037-44f7-937b-3687b81eb5c7/call-idr/shard-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/bar/jflynn/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_idr.py"", line 182, in <module>
    main()
  File ""/bar/jflynn/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_idr.py"", line 157, in main
    idr_peak, args.blacklist, args.regex_bfilt_peak_chr_name, args.out_dir)
  File ""/bar/jflynn/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_blacklist_filter.py"", line 72, in blacklist_filter
    run_shell_cmd(cmd)
  File ""/bar/jflynn/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=42464, PGID=42464, RC=1
STDERR=
STDOUT=


chip.idr Failed. SHARD_IDX=2, RC=1, JOB_ID=42534, RUN_START=2020-03-05T07:20:37.008Z, RUN_END=2020-03-05T07:23:24.421Z, STDOUT=/tavern/jflynn/Projects/metastasis/ChIP_seq_EZH2_H1299/calculate_cross_correlation/my_data/chip/2d9dd1b7-c037-44f7-937b-3687b81eb5c7/call-idr/shard-2/attempt-2/execution/stdout, STDERR=/tavern/jflynn/Projects/metastasis/ChIP_seq_EZH2_H1299/calculate_cross_correlation/my_data/chip/2d9dd1b7-c037-44f7-937b-3687b81eb5c7/call-idr/shard-2/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/bar/jflynn/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_idr.py"", line 182, in <module>
    main()
  File ""/bar/jflynn/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_idr.py"", line 157, in main
    idr_peak, args.blacklist, args.regex_bfilt_peak_chr_name, args.out_dir)
  File ""/bar/jflynn/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_blacklist_filter.py"", line 72, in blacklist_filter
    run_shell_cmd(cmd)
  File ""/bar/jflynn/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=42623, PGID=42623, RC=1
STDERR=
STDOUT=
",jaflynn5,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/135
MDU6SXNzdWU1ODQ2NjI1NDM=,Error in the pipeline when running it for histone data,CLOSED,2020-03-19T19:57:35Z,2020-04-06T12:13:29Z,2020-04-06T12:13:29Z,"Hello,

I am having problems running the ChIP-seq pipeline. I managed to run it for transcription factor data without issues, but for some reason I can't understand I am having problems for histone data.

Here I am uploading the log file of the execution:
[log.bad.mod.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4359021/log.bad.mod.txt)

And an example of json file I use when running the pipeline with caper in my local server:
[H3K4me3-condition.json.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4359044/H3K4me3-condition.json.txt)

The command I use to run the pipeline is:
caper run $wdl -i $json --db ""file"" --out-dir $outdir > $outdir/log.txt 2> $outdir/err.txt

Best regards,
Leonor",leonorrib,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/137
MDU6SXNzdWU1OTE0Mzg1Mzg=,Problems running on filesystems that uses softlink,CLOSED,2020-03-31T21:23:12Z,2020-04-03T14:53:30Z,2020-04-03T14:53:30Z,"**Describe the bug**

**OS/Platform**
- OS/Platform: Redhat 7, Slurm cluster, singularity
- Pipeline version: [e.g. v1.5.3.1]
- Caper version: [e.g. v0.6.3]

I'm running on a filesystem (beegfs) that does not allow hardlinks between different directories. This problem has been reported at

https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/91

Based on the discussion, this problem is resolved. I can run the pipeline using ENCSR356KRQ_subsampled_caper.json as input.

However, when I changed to ENCSR000DYI sample, the pipeline failed at merge_fastq step. 

It states that '/bgfs/sam/fangping/encode_chipseq/ENCSR000DYI/chip/1a32d36f-91a2-44d1-9514-561f1b990615/call-align/shard-0/inputs/522247075/rep1.fastq.gz': No such file or directory. This file exists, and it is a soft link.

chip.align RetryableFailure. SHARD_IDX=0, RC=1, JOB_ID=686860, RUN_START=2020-03-31T20:29:37.150Z, RUN_END=2020-03-31T20:34:39.852Z, STDOUT=/bgfs/sam/fangping/encode_chipseq/ENCSR000DYI/chip/1a32d36f-91a2-44d1-9514-561f1b990615/call-align/shard-0/execution/stdout, STDERR=/bgfs/sam/fangping/encode_chipseq/ENCSR000DYI/chip/1a32d36f-91a2-44d1-9514-561f1b990615/call-align/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 104, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 92, in main
    merge_fastqs(fastqs_R1, 'R1', args.out_dir)
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 72, in merge_fastqs
    return copy_f_to_f(fastqs[0], merged)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 265, in copy_f_to_f
    run_shell_cmd(cmd)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=9099, PGID=9099, RC=1
STDERR=cp: cannot stat '/bgfs/sam/fangping/encode_chipseq/ENCSR000DYI/chip/1a32d36f-91a2-44d1-9514-561f1b990615/call-align/shard-0/inputs/522247075/rep1.fastq.gz': No such file or directory
STDOUT=

[fangping@login0b 522247075]$ ls -l
total 1
lrwxr-xr-x 1 fangping sam 59 Mar 31 16:29 rep1.fastq.gz -> /bgfs/sam/fangping/encode_chipseq/ENCSR000DYI/rep1.fastq.gz

I have tried version 1.3.6. Similar errors appear at the same step.
",fangpingmu,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/142
MDU6SXNzdWU1OTMxNjM5NTc=,SLURM sbatch failure?,CLOSED,2020-04-03T07:10:32Z,2020-07-07T21:11:18Z,2020-07-07T21:11:18Z,"Hi, I'm trying to run the pipeline on scg4 (slurm). 
The script I'm running is:
caper run chip.wdl -c $caper_config --singularity -i $INPUT --tmp-dir $OUTPUT_DIR --out-dir $OUTPUT_DIR

Error in metadata.json:
    ""failures"": [
        {
            ""causedBy"": [
                {
                    ""message"": ""java.lang.RuntimeException: Could not find job ID from stdout file.Check the stderr file for possible errors: /labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test2/chip/0f069612-8711-4c13-b728-560bb8ea259f/call-read_genome_tsv/execution/stderr.submit"",
                    ""causedBy"": [
                        {
                            ""message"": ""Could not find job ID from stdout file.Check the stderr file for possible errors: /labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test2/chip/0f069612-8711-4c13-b728-560bb8ea259f/call-read_genome_tsv/execution/stderr.submit"",
                            ""causedBy"": []
                        }
                    ]
                }
            ],
            ""message"": ""Workflow failed""
        }
    ],",simingzhang,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/146
MDU6SXNzdWU1OTY4NzQwOTI=,Error at chip.overlap_pr ,CLOSED,2020-04-08T21:26:08Z,2020-05-29T15:46:04Z,2020-05-29T15:46:03Z,"**Describe the bug**
I'm using the newest pipeline version and updated caper within conda to 0.8.2. 
My script:
conda activate encode-chip-seq-pipeline
cd $OUTPUT_DIR
sbatch -A aeurban -J chipseq --export=ALL --mem 3G -t 7-0 --wrap ""caper run /labs/dflev/siming/software/chip-seq-pipeline2/chip.wdl -i $INPUT --out-dir $OUTPUT_DIR""

There is an error at chip.overlap_pr step.
""chip.overlap_pr"": [
            {
                ""retryableFailure"": true,
                ""executionStatus"": ""RetryableFailure"",

**OS/Platform**
- OS/Platform: Stanford SCG cluster
- Conda version: conda 4.8.2
- Pipeline version: v1.3.6
- Caper version: 0.8.2

**Caper configuration file**
Paste contents of `~/.caper/default.conf`.

backend=slurm
slurm-account=aeurban

tmp-dir=

cromwell=/home/simingz/.caper/cromwell_jar/cromwell-47.jar
womtool=/home/simingz/.caper/womtool_jar/womtool-47.jar

**Input JSON file**
Paste contents of your input JSON file.

{
    ""chip.title"" : ""chipseq miseq nano"",
    ""chip.description"" : ""chip-seq test miseq nano ipsc"",
    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,
    ""chip.genome_tsv"" : ""/reference/ENCODE/pipeline_genome_data/genome_tsv/v1/hg38_scg.tsv"",
    ""chip.paired_end"" : true,
    ""chip.ctl_paired_end"" : true,
    ""chip.fastqs_rep1_R1"" : [ ""/labs/dflev/siming/chipseq/raw_fastq/test_miseqnano/0425-3-cetch1-flag_subsample1_R1.fastq.gz"" ],
    ""chip.fastqs_rep1_R2"" : [ ""/labs/dflev/siming/chipseq/raw_fastq/test_miseqnano/0425-3-cetch1-flag_subsample1_R2.fastq.gz"" ],
    ""chip.ctl_fastqs_rep1_R1"" : [ ""/labs/dflev/siming/chipseq/raw_fastq/test_miseqnano/0425-3-cetch1-input_subsample1_R1.fastq.gz"" ],
    ""chip.ctl_fastqs_rep1_R2"" : [ ""/labs/dflev/siming/chipseq/raw_fastq/test_miseqnano/0425-3-cetch1-input_subsample1_R2.fastq.gz"" ],
    ""chip.crop_length"" : 0,
    ""chip.mapq_thresh"" : 30,
    ""chip.dup_marker"" : ""picard"",
    ""chip.no_dup_removal"" : false,
    ""chip.subsample_reads"" : 0,
    ""chip.ctl_subsample_reads"" : 0,
    ""chip.xcor_subsample_reads"" : 15000000,
    ""chip.xcor_trim_bp"" : 50,
    ""chip.use_filt_pe_ta_for_xcor"" : false,
    ""chip.always_use_pooled_ctl"" : false,
    ""chip.ctl_depth_ratio"" : 1.2,
    ""chip.peak_caller"" : null,
    ""chip.cap_num_peak_macs2"" : 500000,
    ""chip.pval_thresh"" : 0.01,
    ""chip.fdr_thresh"" : 0.01,
    ""chip.idr_thresh"" : 0.05,
    ""chip.cap_num_peak_spp"" : 300000,
    ""chip.enable_jsd"" : true,
    ""chip.enable_gc_bias"" : true,
    ""chip.enable_count_signal_track"" : false,
    ""chip.filter_chrs"" : [],
    ""chip.align_cpu"" : 4,
    ""chip.align_mem_mb"" : 20000,
    ""chip.align_time_hr"" : 144,
    ""chip.align_disks"" : ""local-disk 400 HDD"",
    ""chip.filter_cpu"" : 2,
    ""chip.filter_mem_mb"" : 20000,
    ""chip.filter_time_hr"" : 144,
    ""chip.filter_disks"" : ""local-disk 400 HDD"",
    ""chip.bam2ta_cpu"" : 2,
    ""chip.bam2ta_mem_mb"" : 10000,
    ""chip.bam2ta_time_hr"" : 144,
    ""chip.bam2ta_disks"" : ""local-disk 100 HDD"",
    ""chip.spr_mem_mb"" : 16000,
    ""chip.jsd_cpu"" : 2,
    ""chip.jsd_mem_mb"" : 12000,
    ""chip.jsd_time_hr"" : 144,
    ""chip.jsd_disks"" : ""local-disk 200 HDD"",
    ""chip.xcor_cpu"" : 2,
    ""chip.xcor_mem_mb"" : 16000,
    ""chip.xcor_time_hr"" : 144,
    ""chip.xcor_disks"" : ""local-disk 100 HDD"",
    ""chip.call_peak_cpu"" : 2,
    ""chip.call_peak_mem_mb"" : 16000,
    ""chip.call_peak_time_hr"" : 144,
    ""chip.call_peak_disks"" : ""local-disk 200 HDD"",
    ""chip.macs2_signal_track_mem_mb"" : 16000,
    ""chip.macs2_signal_track_time_hr"" : 144,
    ""chip.macs2_signal_track_disks"" : ""local-disk 400 HDD"",
    ""chip.gc_bias_picard_java_heap"" : ""10G""
}


**Error log**
Caper automatically runs a troubleshooter for failed workflows. If it doesn't then get a `WORKFLOW_ID` of your failed workflow with `caper list` or directly use a `metadata.json` file on Caper's output directory.
```
$ caper debug [WORKFLOW_ID_OR_METADATA_JSON_FILE]
```
I can't get the caper debug or troubleshoot to work (get message. Help: cannot connect to server. Check if server is dead or still spinning up.). Instead, I attached the metadata.json file below:

[metadata.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4452905/metadata.txt)

The failed parts are here:
{
    ""workflowName"": ""chip"",
    ""workflowProcessingEvents"": [
        {
            ""cromwellId"": ""cromid-242b9e3"",
            ""description"": ""PickedUp"",
            ""timestamp"": ""2020-04-07T20:46:51.509Z"",
            ""cromwellVersion"": ""47""
        },
        {
            ""cromwellId"": ""cromid-242b9e3"",
            ""description"": ""Finished"",
            ""timestamp"": ""2020-04-07T21:31:11.658Z"",
            ""cromwellVersion"": ""47""
        }
    ],
    ""actualWorkflowLanguageVersion"": ""draft-2"",
    ""submittedFiles"": {
        ""workflow"": ""# ENCODE TF/Histone ChIP-Seq pipeline\n# Author: Jin Lee (leepc12@gmail.com)\n\n#CAPER docker quay.io/encode-dcc/chip-seq-pipeline:v1.3.6\n#CAPER singularity docker://quay.io/encode-dcc/chip-seq-pipeline:v1.3.6\n#CROO out_def https://storage.googleapis.com/encode-pipeline-output-definition/chip.croo.v3.json\n\nworkflow chip {\n\tString pipeline_ver = 'v1.3.6'\n\t### sample name, description\n\tString title = 'Untitled'\n\tString description = 'No description'\n\n\t# endedness for input data\n\tBoolean? paired_end\t\t\t\t# to define endedness for all replciates\n\t\t\t\t\t\t\t\t\t#\tif defined, this will override individual endedness below\n\tArray[Boolean] paired_ends = []\t# to define endedness for individual replicate\n\tBoolean? ctl_paired_end\n\tArray[Boolean] ctl_paired_ends = []\n\n\t### mandatory genome param\n\tFile? genome_tsv \t\t\t\t# reference genome data TSV file including\n\t\t\t\t\t\t\t\t\t# all genome-specific file paths and parameters\n\t# individual genome parameters\n\tString? genome_name\t\t\t\t# genome name\n\tFile? ref_fa\t\t\t\t\t# reference fasta (*.fa.gz)\n\tFile? bwa_idx_tar \t\t\t\t# bwa index tar (uncompressed .tar)\n\tFile? bowtie2_idx_tar \t\t\t# bowtie2 index tar (uncompressed .tar)\n\tFile? custom_aligner_idx_tar \t# custom aligner's index tar (uncompressed .tar)\n\tFile? chrsz \t\t\t\t\t# 2-col chromosome sizes file\n\tFile? blacklist \t\t\t\t# blacklist BED (peaks overlapping will be filtered out)\n\tFile? blacklist2 \t\t\t\t# 2nd blacklist (will be merged with 1st one)\n\tString? mito_chr_name\n\tString? regex_bfilt_peak_chr_name\n\tString? gensz \t\t\t\t\t# genome sizes (hs for human, mm for mouse or sum of 2nd col in chrsz)\n\tFile? tss \t\t\t\t\t\t# TSS BED file\n\tFile? dnase \t\t\t\t\t# open chromatin region BED file\n\tFile? prom \t\t\t\t\t\t# promoter region BED file\n\tFile? enh \t\t\t\t\t\t# enhancer region BED file\n\tFile? reg2map \t\t\t\t\t# file with cell type signals\n\tFile? reg2map_bed \t\t\t\t# file of regions used to generate reg2map signals\n\tFile? roadmap_meta \t\t\t\t# roadmap metedata\n\n\t### pipeline type\n\tString pipeline_type  \t\t\t# tf or histone chip-seq\n\n\tString aligner = 'bowtie2'\n\tFile? custom_align_py \t\t\t# custom align python script\n\n\tString? peak_caller \t\t\t# default: (spp for tf) and (macs2 for histone)\n\t\t\t\t\t\t\t\t\t# this will override the above defaults\n\tString? peak_type \t\t\t\t# default: narrowPeak for macs2, regionPeak for spp\n\t\t\t\t\t\t\t\t\t# this will override the above defaults\n\tFile? custom_call_peak_py \t\t# custom call_peak python script\n\n\t## parameters for alignment\n\tBoolean align_only = false \t\t# disable all post-align analysis (peak-calling, overlap, idr, ...)\n\tBoolean true_rep_only = false \t# disable all analyses involving pseudo replicates (including overlap/idr)\n\tBoolean enable_count_signal_track = false \t\t# generate count signal track\n\tBoolean enable_jsd = true \t\t# enable JSD plot generation (deeptools fingerprint)\n\tBoolean enable_gc_bias = true\n\n\t# parameters for aligner and filter\n\tBoolean use_bwa_mem_for_pe = false # THIS IS EXPERIMENTAL and BWA ONLY (use bwa mem instead of bwa aln/sam)\n\t\t\t\t\t\t\t\t\t# available only for PE dataset with READ_LEN>=70bp\n\tInt crop_length = 0 \t\t\t# crop reads in FASTQs with Trimmomatic (0 by default, i.e. disabled)\n\tInt xcor_trim_bp = 50 \t\t\t# for cross-correlation analysis only (R1 of paired-end fastqs)\n\tBoolean use_filt_pe_ta_for_xcor = false # PE only. use filtered PE BAM for cross-corr.\n\tString dup_marker = 'picard'\t# picard, sambamba\n\tBoolean no_dup_removal = false\t# keep all dups in final BAM\n\tInt? mapq_thresh \t\t\t\t# threshold for low MAPQ reads removal\n\tInt mapq_thresh_bwa = 30\n\tInt mapq_thresh_bowtie2 = 30\n\tArray[String] filter_chrs = [] \t# array of chromosomes to be removed from nodup/filt BAM\n\t\t\t\t\t\t\t\t\t# chromosomes will be removed from both BAM header/contents\n\t\t\t\t\t\t\t\t\t# e.g. ['chrM', 'MT']\n\tInt subsample_reads = 0\t\t\t# number of reads to subsample TAGALIGN\n\t\t\t\t\t\t\t\t\t# 0 for no subsampling. this affects all downstream analysis\n\tInt ctl_subsample_reads = 0\t\t# number of reads to subsample control TAGALIGN\n\tInt xcor_subsample_reads = 15000000 # subsample TAG-ALIGN for xcor only (not used for other downsteam analyses)\n\tInt xcor_exclusion_range_min = -500\n\tInt? xcor_exclusion_range_max\n\n\t# parameters for peak calling\n\tBoolean always_use_pooled_ctl = false # always use pooled control for all exp rep.\n\tFloat ctl_depth_ratio = 1.2 \t# if ratio between controls is higher than this\n\t\t\t\t\t\t\t\t\t# then always use pooled control for all exp rep.\n\tInt? cap_num_peak\n\tInt cap_num_peak_spp = 300000\t# cap number of raw peaks called from SPP\n\tInt cap_num_peak_macs2 = 500000\t# cap number of raw peaks called from MACS2\n\tFloat pval_thresh = 0.01\t\t# p.value threshold (for MACS2 peak caller only)\n\tFloat fdr_thresh = 0.01\t\t\t# FDR threshold (for SPP peak caller only: Rscript run_spp.R -fdr)\n\tFloat idr_thresh = 0.05\t\t\t# IDR threshold\n\n\t### resources\n\tInt align_cpu = 4\n\tInt align_mem_mb = 20000\n\tInt align_time_hr = 48\n\tString align_disks = 'local-disk 400 HDD'\n\n\tInt filter_cpu = 2\n\tInt filter_mem_mb = 20000\n\tInt filter_time_hr = 24\n\tString filter_disks = 'local-disk 400 HDD'\n\n\tInt bam2ta_cpu = 2\n\tInt bam2ta_mem_mb = 10000\n\tInt bam2ta_time_hr = 6\n\tString bam2ta_disks = 'local-disk 100 HDD'\n\n\tInt spr_mem_mb = 16000\n\n\tInt jsd_cpu = 2\n\tInt jsd_mem_mb = 12000\n\tInt jsd_time_hr = 6\n\tString jsd_disks = 'local-disk 200 HDD'\n\n\tInt xcor_cpu = 2\n\tInt xcor_mem_mb = 16000\t\n\tInt xcor_time_hr = 24\n\tString xcor_disks = 'local-disk 100 HDD'\n\n\tInt macs2_signal_track_mem_mb = 16000\n\tInt macs2_signal_track_time_hr = 24\n\tString macs2_signal_track_disks = 'local-disk 400 HDD'\n\n\tInt call_peak_cpu = 2\n\tInt call_peak_mem_mb = 16000\n\tInt call_peak_time_hr = 72\n\tString call_peak_disks = 'local-disk 200 HDD'\n\n\tString? align_trimmomatic_java_heap\n\tString? filter_picard_java_heap\n\tString? gc_bias_picard_java_heap\n\n\t#### input file definition\n\t# pipeline can start from any type of inputs and then leave all other types undefined\n\t# supported types: fastq, bam, nodup_bam (filtered bam), ta (tagAlign), peak\n\t# define up to 4 replicates\n\t# [rep_id] is for each replicate\n\n \t### fastqs\n\tArray[File] fastqs_rep1_R1 = []\t\t# FASTQs to be merged for rep1 R1\n\tArray[File] fastqs_rep1_R2 = [] \t# do not define if single-ended\n\tArray[File] fastqs_rep2_R1 = [] \t# do not define if unreplicated\n\tArray[File] fastqs_rep2_R2 = []\t\t# ...\n\tArray[File] fastqs_rep3_R1 = []\n\tArray[File] fastqs_rep3_R2 = []\n\tArray[File] fastqs_rep4_R1 = []\n\tArray[File] fastqs_rep4_R2 = []\n\tArray[File] fastqs_rep5_R1 = []\n\tArray[File] fastqs_rep5_R2 = []\n\tArray[File] fastqs_rep6_R1 = []\n\tArray[File] fastqs_rep6_R2 = []\n\tArray[File] fastqs_rep7_R1 = []\n\tArray[File] fastqs_rep7_R2 = []\n\tArray[File] fastqs_rep8_R1 = []\n\tArray[File] fastqs_rep8_R2 = []\n\tArray[File] fastqs_rep9_R1 = []\n\tArray[File] fastqs_rep9_R2 = []\n\tArray[File] fastqs_rep10_R1 = []\n\tArray[File] fastqs_rep10_R2 = []\n\n\tArray[File] ctl_fastqs_rep1_R1 = []\t\t# Control FASTQs to be merged for rep1 R1\n\tArray[File] ctl_fastqs_rep1_R2 = [] \t# do not define if single-ended\n\tArray[File] ctl_fastqs_rep2_R1 = [] \t# do not define if unreplicated\n\tArray[File] ctl_fastqs_rep2_R2 = []\t\t# ...\n\tArray[File] ctl_fastqs_rep3_R1 = []\n\tArray[File] ctl_fastqs_rep3_R2 = []\n\tArray[File] ctl_fastqs_rep4_R1 = []\n\tArray[File] ctl_fastqs_rep4_R2 = []\n\tArray[File] ctl_fastqs_rep5_R1 = []\n\tArray[File] ctl_fastqs_rep5_R2 = []\n\tArray[File] ctl_fastqs_rep6_R1 = []\n\tArray[File] ctl_fastqs_rep6_R2 = []\n\tArray[File] ctl_fastqs_rep7_R1 = []\n\tArray[File] ctl_fastqs_rep7_R2 = []\n\tArray[File] ctl_fastqs_rep8_R1 = []\n\tArray[File] ctl_fastqs_rep8_R2 = []\n\tArray[File] ctl_fastqs_rep9_R1 = []\n\tArray[File] ctl_fastqs_rep9_R2 = []\n\tArray[File] ctl_fastqs_rep10_R1 = []\n\tArray[File] ctl_fastqs_rep10_R2 = []\n\n\t### other input types (bam, nodup_bam, ta)\n\tArray[File?] bams = [] \t\t\t# [rep_id]\n\tArray[File?] ctl_bams = [] \t\t# [rep_id]\n\tArray[File?] nodup_bams = [] \t# [rep_id]\n\tArray[File?] ctl_nodup_bams = [] # [rep_id]\n\tArray[File?] tas = []\t\t\t# [rep_id]\n\tArray[File?] ctl_tas = []\t\t# [rep_id]\n\n\t### other input types (peak)\n\tArray[Int?] fraglen = [] \t# [rep_id]. fragment length if inputs are peaks\n\tArray[File?] peaks = []\t\t# [PAIR(rep_id1,rep_id2)]. example for 3 reps: [rep1_rep2, rep1_rep3, rep2_rep3]\n\tArray[File?] peaks_pr1 = []\t# [rep_id]. do not define if true_rep=true\n\tArray[File?] peaks_pr2 = []\t# [rep_id]. do not define if true_rep=true\n\tFile? peak_ppr1\t\t\t\t# do not define if you have a single replicate or true_rep=true\n\tFile? peak_ppr2\t\t\t\t# do not define if you have a single replicate or true_rep=true\n\tFile? peak_pooled\t\t\t# do not define if you have a single replicate or true_rep=true\n\n\t####################### pipeline starts here #######################\n\t# DO NOT DEFINE ANY VARIABLES DECLARED BELOW IN AN INPUT JSON FILE #\n\t# THEY ARE TEMPORARY/INTERMEDIATE SYSTEM VARIABLES                 #\n\t####################### pipeline starts here #######################\n\n\t# read genome data and paths\n\tif ( defined(genome_tsv) ) {\n\t\tcall read_genome_tsv { input: genome_tsv = genome_tsv }\n\t}\n\tFile? ref_fa_ = if defined(ref_fa) then ref_fa\n\t\telse read_genome_tsv.ref_fa\n\tFile? bwa_idx_tar_ = if defined(bwa_idx_tar) then bwa_idx_tar\n\t\telse read_genome_tsv.bwa_idx_tar\n\tFile? bowtie2_idx_tar_ = if defined(bowtie2_idx_tar) then bowtie2_idx_tar\n\t\telse read_genome_tsv.bowtie2_idx_tar\n\tFile? custom_aligner_idx_tar_ = if defined(custom_aligner_idx_tar) then custom_aligner_idx_tar\n\t\telse read_genome_tsv.custom_aligner_idx_tar\n\tFile? chrsz_ = if defined(chrsz) then chrsz\n\t\telse read_genome_tsv.chrsz\n\tString? gensz_ = if defined(gensz) then gensz\n\t\telse read_genome_tsv.gensz\n\tFile? blacklist1_ = if defined(blacklist) then blacklist\n\t\telse read_genome_tsv.blacklist\n\tFile? blacklist2_ = if defined(blacklist2) then blacklist2\n\t\telse read_genome_tsv.blacklist2\n\t# merge multiple blacklists\n\t# two blacklists can have different number of columns (3 vs 6)\n\t# so we limit merged blacklist's columns to 3\n\tArray[File] blacklists = select_all([blacklist1_, blacklist2_])\n\tif ( length(blacklists) > 1 ) {\n\t\tcall pool_ta as pool_blacklist { input:\n\t\t\ttas = blacklists,\n\t\t\tcol = 3,\n\t\t}\n\t}\n\tFile? blacklist_ = if length(blacklists) > 1 then pool_blacklist.ta_pooled\n\t\telse if length(blacklists) > 0 then blacklists[0]\n\t\telse blacklist2_\n\tString? mito_chr_name_ = if defined(mito_chr_name) then mito_chr_name\n\t\telse read_genome_tsv.mito_chr_name\t\t\n\tString? regex_bfilt_peak_chr_name_ = if defined(regex_bfilt_peak_chr_name) then regex_bfilt_peak_chr_name\n\t\telse read_genome_tsv.regex_bfilt_peak_chr_name\n\tString? genome_name_ = if defined(genome_name) then genome_name\n\t\telse if defined(read_genome_tsv.genome_name) then read_genome_tsv.genome_name\n\t\telse basename(select_first([genome_tsv, ref_fa_, chrsz_, 'None']))\n\n\t# read additional annotation data\n\tFile? tss_ = if defined(tss) then tss\n\t\telse read_genome_tsv.tss\n\tFile? dnase_ = if defined(dnase) then dnase\n\t\telse read_genome_tsv.dnase\n\tFile? prom_ = if defined(prom) then prom\n\t\telse read_genome_tsv.prom\n\tFile? enh_ = if defined(enh) then enh\n\t\telse read_genome_tsv.enh\n\tFile? reg2map_ = if defined(reg2map) then reg2map\n\t\telse read_genome_tsv.reg2map\n\tFile? reg2map_bed_ = if defined(reg2map_bed) then reg2map_bed\n\t\telse read_genome_tsv.reg2map_bed\n\tFile? roadmap_meta_ = if defined(roadmap_meta) then roadmap_meta\n\t\telse read_genome_tsv.roadmap_meta\n\n\t### temp vars (do not define these)\n\tString aligner_ = if defined(custom_align_py) then 'custom' else aligner\n\tString peak_caller_ = if defined(custom_call_peak_py) then 'custom'\n\t\t\t\t\t\telse if pipeline_type=='tf' then select_first([peak_caller, 'spp'])\n\t\t\t\t\t\telse select_first([peak_caller, 'macs2'])\n\tString peak_type_ = if peak_caller_=='spp' then select_first([peak_type, 'regionPeak'])\n\t\t\t\t\t\telse if peak_caller_=='macs2' then select_first([peak_type, 'narrowPeak'])\n\t\t\t\t\t\telse select_first([peak_type, 'narrowPeak'])\n\tBoolean enable_idr = pipeline_type=='tf' # enable_idr for TF chipseq only\n\tString idr_rank_ = if peak_caller_=='spp' then 'signal.value'\n\t\t\t\t\t\telse if peak_caller_=='macs2' then 'p.value'\n\t\t\t\t\t\telse 'p.value'\n\tInt cap_num_peak_ = if peak_caller_ == 'spp' then select_first([cap_num_peak, cap_num_peak_spp])\n\t\telse select_first([cap_num_peak, cap_num_peak_macs2])\n\tInt mapq_thresh_ = if aligner=='bowtie2' then select_first([mapq_thresh, mapq_thresh_bowtie2])\n\t\t\t\t\t\telse select_first([mapq_thresh, mapq_thresh_bwa])\n\n\t# temporary 2-dim fastqs array [rep_id][merge_id]\n\tArray[Array[File]] fastqs_R1 = \n\t\tif length(fastqs_rep10_R1)>0 then\n\t\t\t[fastqs_rep1_R1, fastqs_rep2_R1, fastqs_rep3_R1, fastqs_rep4_R1, fastqs_rep5_R1,\n\t\t\tfastqs_rep6_R1, fastqs_rep7_R1, fastqs_rep8_R1, fastqs_rep9_R1, fastqs_rep10_R1]\n\t\telse if length(fastqs_rep9_R1)>0 then\n\t\t\t[fastqs_rep1_R1, fastqs_rep2_R1, fastqs_rep3_R1, fastqs_rep4_R1, fastqs_rep5_R1,\n\t\t\tfastqs_rep6_R1, fastqs_rep7_R1, fastqs_rep8_R1, fastqs_rep9_R1]\n\t\telse if length(fastqs_rep8_R1)>0 then\n\t\t\t[fastqs_rep1_R1, fastqs_rep2_R1, fastqs_rep3_R1, fastqs_rep4_R1, fastqs_rep5_R1,\n\t\t\tfastqs_rep6_R1, fastqs_rep7_R1, fastqs_rep8_R1]\n\t\telse if length(fastqs_rep7_R1)>0 then\n\t\t\t[fastqs_rep1_R1, fastqs_rep2_R1, fastqs_rep3_R1, fastqs_rep4_R1, fastqs_rep5_R1,\n\t\t\tfastqs_rep6_R1, fastqs_rep7_R1]\n\t\telse if length(fastqs_rep6_R1)>0 then\n\t\t\t[fastqs_rep1_R1, fastqs_rep2_R1, fastqs_rep3_R1, fastqs_rep4_R1, fastqs_rep5_R1,\n\t\t\tfastqs_rep6_R1]\n\t\telse if length(fastqs_rep5_R1)>0 then\n\t\t\t[fastqs_rep1_R1, fastqs_rep2_R1, fastqs_rep3_R1, fastqs_rep4_R1, fastqs_rep5_R1]\n\t\telse if length(fastqs_rep4_R1)>0 then\n\t\t\t[fastqs_rep1_R1, fastqs_rep2_R1, fastqs_rep3_R1, fastqs_rep4_R1]\n\t\telse if length(fastqs_rep3_R1)>0 then\n\t\t\t[fastqs_rep1_R1, fastqs_rep2_R1, fastqs_rep3_R1]\n\t\telse if length(fastqs_rep2_R1)>0 then\n\t\t\t[fastqs_rep1_R1, fastqs_rep2_R1]\n\t\telse if length(fastqs_rep1_R1)>0 then\n\t\t\t[fastqs_rep1_R1]\n\t\telse []\n\t# no need to do that for R2 (R1 array will be used to determine presense of fastq for each rep)\n\tArray[Array[File]] fastqs_R2 = \n\t\t[fastqs_rep1_R2, fastqs_rep2_R2, fastqs_rep3_R2, fastqs_rep4_R2, fastqs_rep5_R2,\n\t\tfastqs_rep6_R2, fastqs_rep7_R2, fastqs_rep8_R2, fastqs_rep9_R2, fastqs_rep10_R2]\n\n\t# temporary 2-dim ctl fastqs array [rep_id][merge_id]\n\tArray[Array[File]] ctl_fastqs_R1 = \n\t\tif length(ctl_fastqs_rep10_R1)>0 then\n\t\t\t[ctl_fastqs_rep1_R1, ctl_fastqs_rep2_R1, ctl_fastqs_rep3_R1, ctl_fastqs_rep4_R1, ctl_fastqs_rep5_R1,\n\t\t\tctl_fastqs_rep6_R1, ctl_fastqs_rep7_R1, ctl_fastqs_rep8_R1, ctl_fastqs_rep9_R1, ctl_fastqs_rep10_R1]\n\t\telse if length(ctl_fastqs_rep9_R1)>0 then\n\t\t\t[ctl_fastqs_rep1_R1, ctl_fastqs_rep2_R1, ctl_fastqs_rep3_R1, ctl_fastqs_rep4_R1, ctl_fastqs_rep5_R1,\n\t\t\tctl_fastqs_rep6_R1, ctl_fastqs_rep7_R1, ctl_fastqs_rep8_R1, ctl_fastqs_rep9_R1]\n\t\telse if length(ctl_fastqs_rep8_R1)>0 then\n\t\t\t[ctl_fastqs_rep1_R1, ctl_fastqs_rep2_R1, ctl_fastqs_rep3_R1, ctl_fastqs_rep4_R1, ctl_fastqs_rep5_R1,\n\t\t\tctl_fastqs_rep6_R1, ctl_fastqs_rep7_R1, ctl_fastqs_rep8_R1]\n\t\telse if length(ctl_fastqs_rep7_R1)>0 then\n\t\t\t[ctl_fastqs_rep1_R1, ctl_fastqs_rep2_R1, ctl_fastqs_rep3_R1, ctl_fastqs_rep4_R1, ctl_fastqs_rep5_R1,\n\t\t\tctl_fastqs_rep6_R1, ctl_fastqs_rep7_R1]\n\t\telse if length(ctl_fastqs_rep6_R1)>0 then\n\t\t\t[ctl_fastqs_rep1_R1, ctl_fastqs_rep2_R1, ctl_fastqs_rep3_R1, ctl_fastqs_rep4_R1, ctl_fastqs_rep5_R1,\n\t\t\tctl_fastqs_rep6_R1]\n\t\telse if length(ctl_fastqs_rep5_R1)>0 then\n\t\t\t[ctl_fastqs_rep1_R1, ctl_fastqs_rep2_R1, ctl_fastqs_rep3_R1, ctl_fastqs_rep4_R1, ctl_fastqs_rep5_R1]\n\t\telse if length(ctl_fastqs_rep4_R1)>0 then\n\t\t\t[ctl_fastqs_rep1_R1, ctl_fastqs_rep2_R1, ctl_fastqs_rep3_R1, ctl_fastqs_rep4_R1]\n\t\telse if length(ctl_fastqs_rep3_R1)>0 then\n\t\t\t[ctl_fastqs_rep1_R1, ctl_fastqs_rep2_R1, ctl_fastqs_rep3_R1]\n\t\telse if length(ctl_fastqs_rep2_R1)>0 then\n\t\t\t[ctl_fastqs_rep1_R1, ctl_fastqs_rep2_R1]\n\t\telse if length(ctl_fastqs_rep1_R1)>0 then\n\t\t\t[ctl_fastqs_rep1_R1]\n\t\telse []\n\t# no need to do that for R2 (R1 array will be used to determine presense of fastq for each rep)\n\tArray[Array[File]] ctl_fastqs_R2 = \n\t\t[ctl_fastqs_rep1_R2, ctl_fastqs_rep2_R2, ctl_fastqs_rep3_R2, ctl_fastqs_rep4_R2, ctl_fastqs_rep5_R2,\n\t\tctl_fastqs_rep6_R2, ctl_fastqs_rep7_R2, ctl_fastqs_rep8_R2, ctl_fastqs_rep9_R2, ctl_fastqs_rep10_R2]\n\n\t# temporary variables to get number of replicates\n\t# \tWDLic implementation of max(A,B,C,...)\n\tInt num_rep_fastq = length(fastqs_R1)\n\tInt num_rep_bam = if length(bams)<num_rep_fastq then num_rep_fastq\n\t\telse length(bams)\n\tInt num_rep_nodup_bam = if length(nodup_bams)<num_rep_bam then num_rep_bam\n\t\telse length(nodup_bams)\n\tInt num_rep_ta = if length(tas)<num_rep_nodup_bam then num_rep_nodup_bam\n\t\telse length(tas)\n\tInt num_rep_peak = if length(peaks)<num_rep_ta then num_rep_ta\n\t\telse length(peaks)\n\tInt num_rep = num_rep_peak\n\n\t# temporary variables to get number of controls\n\tInt num_ctl_fastq = length(ctl_fastqs_R1)\n\tInt num_ctl_bam = if length(ctl_bams)<num_ctl_fastq then num_ctl_fastq\n\t\telse length(ctl_bams)\n\tInt num_ctl_nodup_bam = if length(ctl_nodup_bams)<num_ctl_bam then num_ctl_bam\n\t\telse length(ctl_nodup_bams)\n\tInt num_ctl_ta = if length(ctl_tas)<num_ctl_nodup_bam then num_ctl_nodup_bam\n\t\telse length(ctl_tas)\n\tInt num_ctl = num_ctl_ta\n\n\t# sanity check for inputs\n\tif ( num_rep == 0 && num_ctl == 0 ) {\n\t\tcall raise_exception as error_input_data { input:\n\t\t\tmsg = 'No FASTQ/BAM/TAG-ALIGN/PEAK defined in your input JSON. Check if your FASTQs are defined as \""chip.fastqs_repX_RY\"". DO NOT MISS suffix _R1 even for single ended FASTQ.'\n\t\t}\n\t}\n\tif ( !defined(chrsz_) ) {\n\t\tcall raise_exception as error_genome_database { input:\n\t\t\tmsg = 'No genome database found in your input JSON. Did you define \""chip.genome_tsv\"" correctly?'\n\t\t}\n\t}\n\tif ( !align_only && peak_caller_ == 'spp' && num_ctl == 0 ) {\n\t\tcall raise_exception as error_control_required { input:\n\t\t\tmsg = 'SPP requires control inputs. Define control input files (\""chip.ctl_*\"") in an input JSON file.'\n\t\t}\n\t}\n\n\t# align each replicate\n\tscatter(i in range(num_rep)) {\n\t\t# to override endedness definition for individual replicate\n\t\t# \tpaired_end will override paired_ends[i]\n\t\tBoolean? paired_end_ = if !defined(paired_end) && i<length(paired_ends) then paired_ends[i]\n\t\t\telse paired_end\n\n\t\tBoolean has_input_of_align = i<length(fastqs_R1) && length(fastqs_R1[i])>0\n\t\tBoolean has_output_of_align = i<length(bams) && defined(bams[i])\n\t\tif ( has_input_of_align && !has_output_of_align ) {\n\t\t\tcall align { input :\n\t\t\t\tfastqs_R1 = fastqs_R1[i],\n\t\t\t\tfastqs_R2 = fastqs_R2[i],\n\t\t\t\tcrop_length = crop_length,\n\n\t\t\t\taligner = aligner_,\n\t\t\t\tmito_chr_name = mito_chr_name_,\n\t\t\t\tcustom_align_py = custom_align_py,\n\t\t\t\tidx_tar = if aligner=='bwa' then bwa_idx_tar_\n\t\t\t\t\telse if aligner=='bowtie2' then bowtie2_idx_tar_\n\t\t\t\t\telse custom_aligner_idx_tar_,\n\t\t\t\tpaired_end = paired_end_,\n\t\t\t\tuse_bwa_mem_for_pe = use_bwa_mem_for_pe,\n\n\t\t\t\ttrimmomatic_java_heap = align_trimmomatic_java_heap,\n\t\t\t\tcpu = align_cpu,\n\t\t\t\tmem_mb = align_mem_mb,\n\t\t\t\ttime_hr = align_time_hr,\n\t\t\t\tdisks = align_disks,\n\t\t\t}\n\t\t}\n\t\tFile? bam_ = if has_output_of_align then bams[i] else align.bam\n\n\t\tBoolean has_input_of_filter = has_output_of_align || defined(align.bam)\n\t\tBoolean has_output_of_filter = i<length(nodup_bams) && defined(nodup_bams[i])\n\t\t# skip if we already have output of this step\n\t\tif ( has_input_of_filter && !has_output_of_filter ) {\n\t\t\tcall filter { input :\n\t\t\t\tbam = bam_,\n\t\t\t\tpaired_end = paired_end_,\n\t\t\t\tdup_marker = dup_marker,\n\t\t\t\tmapq_thresh = mapq_thresh_,\n\t\t\t\tfilter_chrs = filter_chrs,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t\tno_dup_removal = no_dup_removal,\n\t\t\t\tmito_chr_name = mito_chr_name_,\n\n\t\t\t\tcpu = filter_cpu,\n\t\t\t\tmem_mb = filter_mem_mb,\n\t\t\t\tpicard_java_heap = filter_picard_java_heap,\n\t\t\t\ttime_hr = filter_time_hr,\n\t\t\t\tdisks = filter_disks,\n\t\t\t}\n\t\t}\n\t\tFile? nodup_bam_ = if has_output_of_filter then nodup_bams[i] else filter.nodup_bam\n\n\t\tBoolean has_input_of_bam2ta = has_output_of_filter || defined(filter.nodup_bam)\n\t\tBoolean has_output_of_bam2ta = i<length(tas) && defined(tas[i])\n\t\tif ( has_input_of_bam2ta && !has_output_of_bam2ta ) {\n\t\t\tcall bam2ta { input :\n\t\t\t\tbam = nodup_bam_,\n\t\t\t\tsubsample = subsample_reads,\n\t\t\t\tpaired_end = paired_end_,\n\t\t\t\tmito_chr_name = mito_chr_name_,\n\n\t\t\t\tcpu = bam2ta_cpu,\n\t\t\t\tmem_mb = bam2ta_mem_mb,\n\t\t\t\ttime_hr = bam2ta_time_hr,\n\t\t\t\tdisks = bam2ta_disks,\n\t\t\t}\n\t\t}\n\t\tFile? ta_ = if has_output_of_bam2ta then tas[i] else bam2ta.ta\n\n\t\tBoolean has_input_of_spr = has_output_of_bam2ta || defined(bam2ta.ta)\n\t\tif ( has_input_of_spr && !align_only && !true_rep_only ) {\n\t\t\tcall spr { input :\n\t\t\t\tta = ta_,\n\t\t\t\tpaired_end = paired_end_,\n\t\t\t\tmem_mb = spr_mem_mb,\n\t\t\t}\n\t\t}\n\n\t\tBoolean has_input_of_count_signal_track = has_output_of_bam2ta || defined(bam2ta.ta)\n\t\tif ( has_input_of_count_signal_track && enable_count_signal_track ) {\n\t\t\t# generate count signal track\n\t\t\tcall count_signal_track { input :\n\t\t\t\tta = ta_,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t}\n\t\t}\n\n\t\tif ( enable_gc_bias && defined(nodup_bam_) && defined(ref_fa_) ) {\n\t\t\tcall gc_bias { input :\n\t\t\t\tnodup_bam = nodup_bam_,\n\t\t\t\tref_fa = ref_fa_,\n\t\t\t\tpicard_java_heap = gc_bias_picard_java_heap,\n\t\t\t}\n\t\t}\n\n\t\t# special trimming/mapping for xcor (when starting from FASTQs)\n\t\tif ( has_input_of_align ) {\n\t\t\tcall align as align_R1 { input :\n\t\t\t\tfastqs_R1 = fastqs_R1[i],\n\t\t\t\tfastqs_R2 = [],\n\t\t\t\ttrim_bp = xcor_trim_bp,\n\t\t\t\tcrop_length = 0,\n\n\t\t\t\taligner = aligner_,\n\t\t\t\tmito_chr_name = mito_chr_name_,\n\t\t\t\tcustom_align_py = custom_align_py,\n\t\t\t\tidx_tar = if aligner=='bwa' then bwa_idx_tar_\n\t\t\t\t\telse if aligner=='bowtie2' then bowtie2_idx_tar_\n\t\t\t\t\telse custom_aligner_idx_tar_,\n\t\t\t\tpaired_end = false,\n\t\t\t\tuse_bwa_mem_for_pe = use_bwa_mem_for_pe,\n\n\t\t\t\tcpu = align_cpu,\n\t\t\t\tmem_mb = align_mem_mb,\n\t\t\t\ttime_hr = align_time_hr,\n\t\t\t\tdisks = align_disks,\n\t\t\t}\n\t\t\t# no bam deduping for xcor\n\t\t\tcall filter as filter_R1 { input :\n\t\t\t\tbam = align_R1.bam,\n\t\t\t\tpaired_end = false,\n\t\t\t\tdup_marker = dup_marker,\n\t\t\t\tmapq_thresh = mapq_thresh_,\n\t\t\t\tfilter_chrs = filter_chrs,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t\tno_dup_removal = true,\n\t\t\t\tmito_chr_name = mito_chr_name_,\n\n\t\t\t\tcpu = filter_cpu,\n\t\t\t\tmem_mb = filter_mem_mb,\n\t\t\t\tpicard_java_heap = filter_picard_java_heap,\n\t\t\t\ttime_hr = filter_time_hr,\n\t\t\t\tdisks = filter_disks,\n\t\t\t}\n\t\t\tcall bam2ta as bam2ta_no_dedup_R1 { input :\n\t\t\t\tbam = filter_R1.nodup_bam,  # it's named as nodup bam but it's not deduped but just filtered\n\t\t\t\tpaired_end = false,\n\t\t\t\tsubsample = 0,\n\t\t\t\tmito_chr_name = mito_chr_name_,\n\n\t\t\t\tcpu = bam2ta_cpu,\n\t\t\t\tmem_mb = bam2ta_mem_mb,\n\t\t\t\ttime_hr = bam2ta_time_hr,\n\t\t\t\tdisks = bam2ta_disks,\n\t\t\t}\n\t\t}\n\n\t\t# special trimming/mapping for xcor (when starting from BAMs)\n\t\tBoolean has_input_of_bam2ta_no_dedup = (has_output_of_align || defined(align.bam))\n\t\t\t&& !defined(bam2ta_no_dedup_R1.ta)\n\t\tif ( has_input_of_bam2ta_no_dedup ) {\n\t\t\tcall filter as filter_no_dedup { input :\n\t\t\t\tbam = bam_,\n\t\t\t\tpaired_end = paired_end_,\n\t\t\t\tdup_marker = dup_marker,\n\t\t\t\tmapq_thresh = mapq_thresh_,\n\t\t\t\tfilter_chrs = filter_chrs,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t\tno_dup_removal = true,\n\t\t\t\tmito_chr_name = mito_chr_name_,\n\n\t\t\t\tcpu = filter_cpu,\n\t\t\t\tmem_mb = filter_mem_mb,\n\t\t\t\tpicard_java_heap = filter_picard_java_heap,\n\t\t\t\ttime_hr = filter_time_hr,\n\t\t\t\tdisks = filter_disks,\n\t\t\t}\n\t\t\tcall bam2ta as bam2ta_no_dedup { input :\n\t\t\t\tbam = filter_no_dedup.nodup_bam,  # output name is nodup but it's not deduped\n\t\t\t\tpaired_end = paired_end_,\n\t\t\t\tsubsample = 0,\n\t\t\t\tmito_chr_name = mito_chr_name_,\n\n\t\t\t\tcpu = bam2ta_cpu,\n\t\t\t\tmem_mb = bam2ta_mem_mb,\n\t\t\t\ttime_hr = bam2ta_time_hr,\n\t\t\t\tdisks = bam2ta_disks,\n\t\t\t}\n\t\t}\n\n\t\t# use trimmed/unfilitered R1 tagAlign for paired end dataset \t\t\n\t\t# if not starting from fastqs, keep using old method\n\t\t#  (mapping with both ends for tag-aligns to be used for xcor)\n\t\t# subsample tagalign (non-mito) and cross-correlation analysis\n\t\tFile? ta_xcor = if defined(bam2ta_no_dedup_R1.ta) then bam2ta_no_dedup_R1.ta\n\t\t\telse if defined(bam2ta_no_dedup.ta) then bam2ta_no_dedup.ta\n\t\t\telse ta_\n\t\tBoolean? paired_end_xcor = if defined(bam2ta_no_dedup_R1.ta) then false\n\t\t\telse paired_end_\n\n\t\tBoolean has_input_of_xcor = defined(ta_xcor)\n\t\tif ( has_input_of_xcor ) {\n\t\t\tcall xcor { input :\n\t\t\t\tta = ta_xcor,\n\t\t\t\tpaired_end = paired_end_xcor,\n\t\t\t\tsubsample = xcor_subsample_reads,\n\t\t\t\tmito_chr_name = mito_chr_name_,\n\t\t\t\tchip_seq_type = pipeline_type,\n\t\t\t\texclusion_range_min = xcor_exclusion_range_min,\n\t\t\t\texclusion_range_max = xcor_exclusion_range_max,\n\t\t\t\tcpu = xcor_cpu,\n\t\t\t\tmem_mb = xcor_mem_mb,\n\t\t\t\ttime_hr = xcor_time_hr,\n\t\t\t\tdisks = xcor_disks,\n\t\t\t}\n\t\t}\n\n\t\t# before peak calling, get fragment length from xcor analysis or given input\n\t\t# if fraglen [] is defined in the input JSON, fraglen from xcor will be ignored\n\t\tInt? fraglen_ = if i<length(fraglen) && defined(fraglen[i]) then fraglen[i]\n\t\t\telse xcor.fraglen\n\t}\n\n\t# align each control\n\tscatter(i in range(num_ctl)) {\n\t\t# to override endedness definition for individual control\n\t\t# \tctl_paired_end will override ctl_paired_ends[i]\n\t\tBoolean? ctl_paired_end_ = if !defined(ctl_paired_end) && i<length(ctl_paired_ends) then ctl_paired_ends[i]\n\t\t\telse if defined(ctl_paired_end) then ctl_paired_end\n\t\t\telse paired_end\n\n\t\tBoolean has_input_of_align_ctl = i<length(ctl_fastqs_R1) && length(ctl_fastqs_R1[i])>0\n\t\tBoolean has_output_of_align_ctl = i<length(ctl_bams) && defined(ctl_bams[i])\n\t\tif ( has_input_of_align_ctl && !has_output_of_align_ctl ) {\n\t\t\tcall align as align_ctl { input :\n\t\t\t\tfastqs_R1 = ctl_fastqs_R1[i],\n\t\t\t\tfastqs_R2 = ctl_fastqs_R2[i],\n\t\t\t\tcrop_length = crop_length,\n\n\t\t\t\taligner = aligner_,\n\t\t\t\tmito_chr_name = mito_chr_name_,\n\t\t\t\tcustom_align_py = custom_align_py,\n\t\t\t\tidx_tar = if aligner=='bwa' then bwa_idx_tar_\n\t\t\t\t\telse if aligner=='bowtie2' then bowtie2_idx_tar_\n\t\t\t\t\telse custom_aligner_idx_tar_,\n\t\t\t\tpaired_end = ctl_paired_end_,\n\t\t\t\tuse_bwa_mem_for_pe = use_bwa_mem_for_pe,\n\n\t\t\t\ttrimmomatic_java_heap = align_trimmomatic_java_heap,\n\t\t\t\tcpu = align_cpu,\n\t\t\t\tmem_mb = align_mem_mb,\n\t\t\t\ttime_hr = align_time_hr,\n\t\t\t\tdisks = align_disks,\n\t\t\t}\n\t\t}\n\t\tFile? ctl_bam_ = if has_output_of_align_ctl then ctl_bams[i] else align_ctl.bam\n\n\t\tBoolean has_input_of_filter_ctl = has_output_of_align_ctl || defined(align_ctl.bam)\n\t\tBoolean has_output_of_filter_ctl = i<length(ctl_nodup_bams) && defined(ctl_nodup_bams[i])\n\t\t# skip if we already have output of this step\n\t\tif ( has_input_of_filter_ctl && !has_output_of_filter_ctl ) {\n\t\t\tcall filter as filter_ctl { input :\n\t\t\t\tbam = ctl_bam_,\n\t\t\t\tpaired_end = ctl_paired_end_,\n\t\t\t\tdup_marker = dup_marker,\n\t\t\t\tmapq_thresh = mapq_thresh_,\n\t\t\t\tfilter_chrs = filter_chrs,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t\tno_dup_removal = no_dup_removal,\n\t\t\t\tmito_chr_name = mito_chr_name_,\n\n\t\t\t\tcpu = filter_cpu,\n\t\t\t\tmem_mb = filter_mem_mb,\n\t\t\t\tpicard_java_heap = filter_picard_java_heap,\n\t\t\t\ttime_hr = filter_time_hr,\n\t\t\t\tdisks = filter_disks,\n\t\t\t}\n\t\t}\n\t\tFile? ctl_nodup_bam_ = if has_output_of_filter_ctl then ctl_nodup_bams[i] else filter_ctl.nodup_bam\n\n\t\tBoolean has_input_of_bam2ta_ctl = has_output_of_filter_ctl || defined(filter_ctl.nodup_bam)\n\t\tBoolean has_output_of_bam2ta_ctl = i<length(ctl_tas) && defined(ctl_tas[i])\n\t\tif ( has_input_of_bam2ta_ctl && !has_output_of_bam2ta_ctl ) {\n\t\t\tcall bam2ta as bam2ta_ctl { input :\n\t\t\t\tbam = ctl_nodup_bam_,\n\t\t\t\tsubsample = subsample_reads,\n\t\t\t\tpaired_end = ctl_paired_end_,\n\t\t\t\tmito_chr_name = mito_chr_name_,\n\n\t\t\t\tcpu = bam2ta_cpu,\n\t\t\t\tmem_mb = bam2ta_mem_mb,\n\t\t\t\ttime_hr = bam2ta_time_hr,\n\t\t\t\tdisks = bam2ta_disks,\n\t\t\t}\n\t\t}\n\t\tFile? ctl_ta_ = if has_output_of_bam2ta_ctl then ctl_tas[i] else bam2ta_ctl.ta\n\t}\n\n\t# if there are TAs for ALL replicates then pool them\n\tBoolean has_all_inputs_of_pool_ta = length(select_all(ta_))==num_rep\n\tif ( has_all_inputs_of_pool_ta && num_rep>1 ) {\n\t\t# pool tagaligns from true replicates\n\t\tcall pool_ta { input :\n\t\t\ttas = ta_,\n\t\t\tprefix = 'rep',\n\t\t}\n\t}\n\n\t# if there are pr1 TAs for ALL replicates then pool them\n\tBoolean has_all_inputs_of_pool_ta_pr1 = length(select_all(spr.ta_pr1))==num_rep\n\tif ( has_all_inputs_of_pool_ta_pr1 && num_rep>1 && !align_only && !true_rep_only ) {\n\t\t# pool tagaligns from pseudo replicate 1\n\t\tcall pool_ta as pool_ta_pr1 { input :\n\t\t\ttas = spr.ta_pr1,\n\t\t\tprefix = 'rep-pr1',\n\t\t}\n\t}\n\n\t# if there are pr2 TAs for ALL replicates then pool them\n\tBoolean has_all_inputs_of_pool_ta_pr2 = length(select_all(spr.ta_pr2))==num_rep\n\tif ( has_all_inputs_of_pool_ta_pr1 && num_rep>1 && !align_only && !true_rep_only ) {\n\t\t# pool tagaligns from pseudo replicate 2\n\t\tcall pool_ta as pool_ta_pr2 { input :\n\t\t\ttas = spr.ta_pr2,\n\t\t\tprefix = 'rep-pr2',\n\t\t}\n\t}\n\n\t# if there are CTL TAs for ALL replicates then pool them\n\tBoolean has_all_inputs_of_pool_ta_ctl = length(select_all(ctl_ta_))==num_ctl\n\tif ( has_all_inputs_of_pool_ta_ctl && num_ctl>1 ) {\n\t\t# pool tagaligns from true replicates\n\t\tcall pool_ta as pool_ta_ctl { input :\n\t\t\ttas = ctl_ta_,\n\t\t\tprefix = 'ctl',\n\t\t}\n\t}\n\n\tBoolean has_input_of_count_signal_track_pooled = defined(pool_ta.ta_pooled)\n\tif ( has_input_of_count_signal_track_pooled && enable_count_signal_track && num_rep>1 ) {\n\t\tcall count_signal_track as count_signal_track_pooled { input :\n\t\t\tta = pool_ta.ta_pooled,\n\t\t\tchrsz = chrsz_,\n\t\t}\n\t}\n\n\tBoolean has_input_of_jsd = defined(blacklist_) && length(select_all(nodup_bam_))==num_rep\n\tif ( has_input_of_jsd && num_rep > 0 && enable_jsd ) {\n\t\t# fingerprint and JS-distance plot\n\t\tcall jsd { input :\n\t\t\tnodup_bams = nodup_bam_,\n\t\t\tctl_bams = ctl_nodup_bam_, # use first control only\n\t\t\tblacklist = blacklist_,\n\t\t\tmapq_thresh = mapq_thresh_,\n\n\t\t\tcpu = jsd_cpu,\n\t\t\tmem_mb = jsd_mem_mb,\n\t\t\ttime_hr = jsd_time_hr,\n\t\t\tdisks = jsd_disks,\n\t\t}\n\t}\n\n\tBoolean has_all_input_of_choose_ctl = length(select_all(ta_))==num_rep\n\t\t&& length(select_all(ctl_ta_))==num_ctl && num_ctl > 0\n\tif ( has_all_input_of_choose_ctl && !align_only ) {\n\t\t# choose appropriate control for each exp IP replicate\n\t\t# outputs:\n\t\t# \tchoose_ctl.idx : control replicate index for each exp replicate \n\t\t#\t\t\t\t\t-1 means pooled ctl replicate\n\t\tcall choose_ctl { input:\n\t\t\ttas = ta_,\n\t\t\tctl_tas = ctl_ta_,\n\t\t\tta_pooled = pool_ta.ta_pooled,\n\t\t\tctl_ta_pooled = pool_ta_ctl.ta_pooled,\n\t\t\talways_use_pooled_ctl = always_use_pooled_ctl,\n\t\t\tctl_depth_ratio = ctl_depth_ratio,\n\t\t}\n\t}\n\n\t# make control ta array [[1,2,3,4]] -> [[1],[2],[3],[4]], will be zipped with exp ta array latter\n\tArray[Array[File]] chosen_ctl_tas =\n\t\tif has_all_input_of_choose_ctl then transpose(select_all([choose_ctl.chosen_ctl_tas]))\n\t\telse [[],[],[],[],[],[],[],[],[],[]]\n\n\t# workaround for dx error (Unsupported combination: womType: Int womValue: ([225], Array[Int]))\n\tArray[Int] fraglen_tmp = select_all(fraglen_)\n\n\t# we have all tas and ctl_tas (optional for histone chipseq) ready, let's call peaks\n\tscatter(i in range(num_rep)) {\n\t\tBoolean has_input_of_call_peak = defined(ta_[i])\n\t\tBoolean has_output_of_call_peak = i<length(peaks) && defined(peaks[i])\n\t\tif ( has_input_of_call_peak && !has_output_of_call_peak && !align_only ) {\n\t\t\tcall call_peak { input :\n\t\t\t\tpeak_caller = peak_caller_,\n\t\t\t\tpeak_type = peak_type_,\n\t\t\t\tcustom_call_peak_py = custom_call_peak_py,\n\t\t\t\ttas = flatten([[ta_[i]], chosen_ctl_tas[i]]),\n\t\t\t\tgensz = gensz_,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t\tcap_num_peak = cap_num_peak_,\n\t\t\t\tpval_thresh = pval_thresh,\n\t\t\t\tfdr_thresh = fdr_thresh,\n\t\t\t\tfraglen = fraglen_tmp[i],\n\t\t\t\tblacklist = blacklist_,\n\t\t\t\tregex_bfilt_peak_chr_name = regex_bfilt_peak_chr_name_,\n\n\t\t\t\tcpu = call_peak_cpu,\n\t\t\t\tmem_mb = call_peak_mem_mb,\n\t\t\t\tdisks = call_peak_disks,\n\t\t\t\ttime_hr = call_peak_time_hr,\n\t\t\t}\n\t\t}\n\t\tFile? peak_ = if has_output_of_call_peak then peaks[i]\n\t\t\telse call_peak.peak\n\n\t\t# signal track\n\t\tif ( has_input_of_call_peak && !align_only ) {\n\t\t\tcall macs2_signal_track { input :\n\t\t\t\ttas = flatten([[ta_[i]], chosen_ctl_tas[i]]),\n\t\t\t\tgensz = gensz_,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t\tpval_thresh = pval_thresh,\n\t\t\t\tfraglen = fraglen_tmp[i],\n\n\t\t\t\tmem_mb = macs2_signal_track_mem_mb,\n\t\t\t\tdisks = macs2_signal_track_disks,\n\t\t\t\ttime_hr = macs2_signal_track_time_hr,\n\t\t\t}\n\t\t}\n\n\t\t# call peaks on 1st pseudo replicated tagalign\n\t\tBoolean has_input_of_call_peak_pr1 = defined(spr.ta_pr1[i])\n\t\tBoolean has_output_of_call_peak_pr1 = i<length(peaks_pr1) && defined(peaks_pr1[i])\n\t\tif ( has_input_of_call_peak_pr1 && !has_output_of_call_peak_pr1 && !true_rep_only ) {\n\t\t\tcall call_peak as call_peak_pr1 { input :\n\t\t\t\tpeak_caller = peak_caller_,\n\t\t\t\tpeak_type = peak_type_,\n\t\t\t\tcustom_call_peak_py = custom_call_peak_py,\n\t\t\t\ttas = flatten([[spr.ta_pr1[i]], chosen_ctl_tas[i]]),\n\t\t\t\tgensz = gensz_,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t\tcap_num_peak = cap_num_peak_,\n\t\t\t\tpval_thresh = pval_thresh,\n\t\t\t\tfdr_thresh = fdr_thresh,\n\t\t\t\tfraglen = fraglen_tmp[i],\n\t\t\t\tblacklist = blacklist_,\n\t\t\t\tregex_bfilt_peak_chr_name = regex_bfilt_peak_chr_name_,\n\t\n\t\t\t\tcpu = call_peak_cpu,\n\t\t\t\tmem_mb = call_peak_mem_mb,\n\t\t\t\tdisks = call_peak_disks,\n\t\t\t\ttime_hr = call_peak_time_hr,\n\t\t\t}\n\t\t}\n\t\tFile? peak_pr1_ = if has_output_of_call_peak_pr1 then peaks_pr1[i]\n\t\t\telse call_peak_pr1.peak\n\n\t\t# call peaks on 2nd pseudo replicated tagalign\n\t\tBoolean has_input_of_call_peak_pr2 = defined(spr.ta_pr2[i])\n\t\tBoolean has_output_of_call_peak_pr2 = i<length(peaks_pr2) && defined(peaks_pr2[i])\n\t\tif ( has_input_of_call_peak_pr2 && !has_output_of_call_peak_pr2 && !true_rep_only ) {\n\t\t\tcall call_peak as call_peak_pr2 { input :\n\t\t\t\tpeak_caller = peak_caller_,\n\t\t\t\tpeak_type = peak_type_,\n\t\t\t\tcustom_call_peak_py = custom_call_peak_py,\n\t\t\t\ttas = flatten([[spr.ta_pr2[i]], chosen_ctl_tas[i]]),\n\t\t\t\tgensz = gensz_,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t\tcap_num_peak = cap_num_peak_,\n\t\t\t\tpval_thresh = pval_thresh,\n\t\t\t\tfdr_thresh = fdr_thresh,\n\t\t\t\tfraglen = fraglen_tmp[i],\n\t\t\t\tblacklist = blacklist_,\n\t\t\t\tregex_bfilt_peak_chr_name = regex_bfilt_peak_chr_name_,\n\n\t\t\t\tcpu = call_peak_cpu,\n\t\t\t\tmem_mb = call_peak_mem_mb,\n\t\t\t\tdisks = call_peak_disks,\n\t\t\t\ttime_hr = call_peak_time_hr,\n\t\t\t}\n\t\t}\n\t\tFile? peak_pr2_ = if has_output_of_call_peak_pr2 then peaks_pr2[i]\n\t\t\telse call_peak_pr2.peak\n\t}\n\n\t# if ( !align_only && num_rep > 1 ) {\n\t# rounded mean of fragment length, which will be used for \n\t#  1) calling peaks for pooled true/pseudo replicates\n\t#  2) calculating FRiP\n\tcall rounded_mean as fraglen_mean { input :\n\t\tints = fraglen_tmp,\n\t}\n\t# }\n\n\t# actually not an array\n\tArray[File?] chosen_ctl_ta_pooled = if !has_all_input_of_choose_ctl then []\n\t\telse if num_ctl < 2 then [ctl_ta_[0]] # choose first (only) control\n\t\telse select_all([pool_ta_ctl.ta_pooled]) # choose pooled control\n\n\tBoolean has_input_of_call_peak_pooled = defined(pool_ta.ta_pooled)\n\tBoolean has_output_of_call_peak_pooled = defined(peak_pooled)\n\tif ( has_input_of_call_peak_pooled && !has_output_of_call_peak_pooled && !align_only && num_rep>1 ) {\n\t\t# call peaks on pooled replicate\n\t\t# always call peaks for pooled replicate to get signal tracks\n\t\tcall call_peak as call_peak_pooled { input :\n\t\t\tpeak_caller = peak_caller_,\n\t\t\tpeak_type = peak_type_,\n\t\t\tcustom_call_peak_py = custom_call_peak_py,\n\t\t\ttas = flatten([select_all([pool_ta.ta_pooled]), chosen_ctl_ta_pooled]),\n\t\t\tgensz = gensz_,\n\t\t\tchrsz = chrsz_,\n\t\t\tcap_num_peak = cap_num_peak_,\n\t\t\tpval_thresh = pval_thresh,\n\t\t\tfdr_thresh = fdr_thresh,\n\t\t\tfraglen = fraglen_mean.rounded_mean,\n\t\t\tblacklist = blacklist_,\n\t\t\tregex_bfilt_peak_chr_name = regex_bfilt_peak_chr_name_,\n\n\t\t\tcpu = call_peak_cpu,\n\t\t\tmem_mb = call_peak_mem_mb,\n\t\t\tdisks = call_peak_disks,\n\t\t\ttime_hr = call_peak_time_hr,\n\t\t}\n\t}\n\tFile? peak_pooled_ = if has_output_of_call_peak_pooled then peak_pooled\n\t\telse call_peak_pooled.peak\t\n\n\t# macs2 signal track for pooled rep\n\tif ( has_input_of_call_peak_pooled && !align_only && num_rep>1 ) {\n\t\tcall macs2_signal_track as macs2_signal_track_pooled { input :\n\t\t\ttas = flatten([select_all([pool_ta.ta_pooled]), chosen_ctl_ta_pooled]),\n\t\t\tgensz = gensz_,\n\t\t\tchrsz = chrsz_,\n\t\t\tpval_thresh = pval_thresh,\n\t\t\tfraglen = fraglen_mean.rounded_mean,\n\n\t\t\tmem_mb = macs2_signal_track_mem_mb,\n\t\t\tdisks = macs2_signal_track_disks,\n\t\t\ttime_hr = macs2_signal_track_time_hr,\n\t\t}\n\t}\n\n\tBoolean has_input_of_call_peak_ppr1 = defined(pool_ta_pr1.ta_pooled)\n\tBoolean has_output_of_call_peak_ppr1 = defined(peak_ppr1)\n\tif ( has_input_of_call_peak_ppr1 && !has_output_of_call_peak_ppr1 && !align_only && !true_rep_only && num_rep>1 ) {\n\t\t# call peaks on 1st pooled pseudo replicates\n\t\tcall call_peak as call_peak_ppr1 { input :\n\t\t\tpeak_caller = peak_caller_,\n\t\t\tpeak_type = peak_type_,\n\t\t\tcustom_call_peak_py = custom_call_peak_py,\n\t\t\ttas = flatten([select_all([pool_ta_pr1.ta_pooled]), chosen_ctl_ta_pooled]),\n\t\t\tgensz = gensz_,\n\t\t\tchrsz = chrsz_,\n\t\t\tcap_num_peak = cap_num_peak_,\n\t\t\tpval_thresh = pval_thresh,\n\t\t\tfdr_thresh = fdr_thresh,\n\t\t\tfraglen = fraglen_mean.rounded_mean,\n\t\t\tblacklist = blacklist_,\n\t\t\tregex_bfilt_peak_chr_name = regex_bfilt_peak_chr_name_,\n\n\t\t\tcpu = call_peak_cpu,\n\t\t\tmem_mb = call_peak_mem_mb,\n\t\t\tdisks = call_peak_disks,\n\t\t\ttime_hr = call_peak_time_hr,\n\t\t}\n\t}\n\tFile? peak_ppr1_ = if has_output_of_call_peak_ppr1 then peak_ppr1\n\t\telse call_peak_ppr1.peak\n\n\tBoolean has_input_of_call_peak_ppr2 = defined(pool_ta_pr2.ta_pooled)\n\tBoolean has_output_of_call_peak_ppr2 = defined(peak_ppr2)\n\tif ( has_input_of_call_peak_ppr2 && !has_output_of_call_peak_ppr2 && !align_only && !true_rep_only && num_rep>1 ) {\n\t\t# call peaks on 2nd pooled pseudo replicates\n\t\tcall call_peak as call_peak_ppr2 { input :\n\t\t\tpeak_caller = peak_caller_,\n\t\t\tpeak_type = peak_type_,\n\t\t\tcustom_call_peak_py = custom_call_peak_py,\n\t\t\ttas = flatten([select_all([pool_ta_pr2.ta_pooled]), chosen_ctl_ta_pooled]),\n\t\t\tgensz = gensz_,\n\t\t\tchrsz = chrsz_,\n\t\t\tcap_num_peak = cap_num_peak_,\n\t\t\tpval_thresh = pval_thresh,\n\t\t\tfdr_thresh = fdr_thresh,\n\t\t\tfraglen = fraglen_mean.rounded_mean,\n\t\t\tblacklist = blacklist_,\n\t\t\tregex_bfilt_peak_chr_name = regex_bfilt_peak_chr_name_,\n\n\t\t\tcpu = call_peak_cpu,\n\t\t\tmem_mb = call_peak_mem_mb,\n\t\t\tdisks = call_peak_disks,\n\t\t\ttime_hr = call_peak_time_hr,\n\t\t}\n\t}\n\tFile? peak_ppr2_ = if has_output_of_call_peak_ppr2 then peak_ppr2\n\t\telse call_peak_ppr2.peak\n\n\t# do IDR/overlap on all pairs of two replicates (i,j)\n\t# \twhere i and j are zero-based indices and 0 <= i < j < num_rep\n\tArray[Pair[Int, Int]] pairs_ = cross(range(num_rep),range(num_rep))\n\tscatter( pair in pairs_ ) {\n\t\tPair[Int, Int]? null_pair\n\t\tPair[Int, Int]? pairs__ = if pair.left<pair.right then pair else null_pair\n\t}\n\tArray[Pair[Int, Int]] pairs = select_all(pairs__)\n\n\tif ( !align_only ) {\n\t\tscatter( pair in pairs ) {\n\t\t\t# pair.left = 0-based index of 1st replicate\n\t\t\t# pair.right = 0-based index of 2nd replicate\n\t\t\t# Naive overlap on every pair of true replicates\n\t\t\tcall overlap { input :\n\t\t\t\tprefix = 'rep'+(pair.left+1)+'_vs_rep'+(pair.right+1),\n\t\t\t\tpeak1 = peak_[pair.left],\n\t\t\t\tpeak2 = peak_[pair.right],\n\t\t\t\tpeak_pooled = peak_pooled_,\n\t\t\t\tfraglen = fraglen_mean.rounded_mean,\n\t\t\t\tpeak_type = peak_type_,\n\t\t\t\tblacklist = blacklist_,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t\tregex_bfilt_peak_chr_name = regex_bfilt_peak_chr_name_,\n\t\t\t\tta = pool_ta.ta_pooled,\n\t\t\t}\n\t\t}\n\t}\n\n\tif ( enable_idr && !align_only ) {\n\t\tscatter( pair in pairs ) {\n\t\t\t# pair.left = 0-based index of 1st replicate\n\t\t\t# pair.right = 0-based index of 2nd replicate\n\t\t\t# IDR on every pair of true replicates\n\t\t\tcall idr { input :\n\t\t\t\tprefix = 'rep'+(pair.left+1)+'_vs_rep'+(pair.right+1),\n\t\t\t\tpeak1 = peak_[pair.left],\n\t\t\t\tpeak2 = peak_[pair.right],\n\t\t\t\tpeak_pooled = peak_pooled_,\n\t\t\t\tfraglen = fraglen_mean.rounded_mean,\n\t\t\t\tidr_thresh = idr_thresh,\n\t\t\t\tpeak_type = peak_type_,\n\t\t\t\trank = idr_rank_,\n\t\t\t\tblacklist = blacklist_,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t\tregex_bfilt_peak_chr_name = regex_bfilt_peak_chr_name_,\n\t\t\t\tta = pool_ta.ta_pooled,\n\t\t\t}\n\t\t}\n\t}\n\n\t# overlap on pseudo-replicates (pr1, pr2) for each true replicate\n\tif ( !align_only && !true_rep_only ) {\n\t\tscatter( i in range(num_rep) ) {\n\t\t\tcall overlap as overlap_pr { input :\n\t\t\t\tprefix = 'rep'+(i+1)+'-pr1_vs_rep'+(i+1)+'-pr2',\n\t\t\t\tpeak1 = peak_pr1_[i],\n\t\t\t\tpeak2 = peak_pr2_[i],\n\t\t\t\tpeak_pooled = peak_[i],\n\t\t\t\tfraglen = fraglen_[i],\n\t\t\t\tpeak_type = peak_type_,\n\t\t\t\tblacklist = blacklist_,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t\tregex_bfilt_peak_chr_name = regex_bfilt_peak_chr_name_,\n\t\t\t\tta = ta_[i],\n\t\t\t}\n\t\t}\n\t}\n\n\tif ( !align_only && !true_rep_only && enable_idr ) {\n\t\tscatter( i in range(num_rep) ) {\n\t\t\t# IDR on pseduo replicates\n\t\t\tcall idr as idr_pr { input :\n\t\t\t\tprefix = 'rep'+(i+1)+'-pr1_vs_rep'+(i+1)+'-pr2',\n\t\t\t\tpeak1 = peak_pr1_[i],\n\t\t\t\tpeak2 = peak_pr2_[i],\n\t\t\t\tpeak_pooled = peak_[i],\n\t\t\t\tfraglen = fraglen_[i],\n\t\t\t\tidr_thresh = idr_thresh,\n\t\t\t\tpeak_type = peak_type_,\n\t\t\t\trank = idr_rank_,\n\t\t\t\tblacklist = blacklist_,\n\t\t\t\tchrsz = chrsz_,\n\t\t\t\tregex_bfilt_peak_chr_name = regex_bfilt_peak_chr_name_,\n\t\t\t\tta = ta_[i],\n\t\t\t}\n\t\t}\n\t}\n\n\tif ( !align_only && !true_rep_only && num_rep > 1 ) {\n\t\t# Naive overlap on pooled pseudo replicates\n\t\tcall overlap as overlap_ppr { input :\n\t\t\tprefix = 'pooled-pr1_vs_pooled-pr2',\n\t\t\tpeak1 = peak_ppr1_,\n\t\t\tpeak2 = peak_ppr2_,\n\t\t\tpeak_pooled = peak_pooled_,\n\t\t\tpeak_type = peak_type_,\n\t\t\tfraglen = fraglen_mean.rounded_mean,\n\t\t\tblacklist = blacklist_,\n\t\t\tchrsz = chrsz_,\n\t\t\tregex_bfilt_peak_chr_name = regex_bfilt_peak_chr_name_,\n\t\t\tta = pool_ta.ta_pooled,\n\t\t}\n\t}\n\n\tif ( !align_only && !true_rep_only && num_rep > 1 ) {\n\t\t# IDR on pooled pseduo replicates\n\t\tcall idr as idr_ppr { input :\n\t\t\tprefix = 'pooled-pr1_vs_pooled-pr2',\n\t\t\tpeak1 = peak_ppr1_,\n\t\t\tpeak2 = peak_ppr2_,\n\t\t\tpeak_pooled = peak_pooled_,\n\t\t\tidr_thresh = idr_thresh,\n\t\t\tpeak_type = peak_type_,\n\t\t\tfraglen = fraglen_mean.rounded_mean,\n\t\t\trank = idr_rank_,\n\t\t\tblacklist = blacklist_,\n\t\t\tchrsz = chrsz_,\n\t\t\tregex_bfilt_peak_chr_name = regex_bfilt_peak_chr_name_,\n\t\t\tta = pool_ta.ta_pooled,\n\t\t}\n\t}\n\n\t# reproducibility QC for overlap/IDR peaks\n\tif ( !align_only && !true_rep_only && num_rep > 0 ) {\n\t\t# reproducibility QC for overlapping peaks\n\t\tcall reproducibility as reproducibility_overlap { input :\n\t\t\tprefix = 'overlap',\n\t\t\tpeaks = overlap.bfilt_overlap_peak,\n\t\t\tpeaks_pr = overlap_pr.bfilt_overlap_peak,\n\t\t\tpeak_ppr = overlap_ppr.bfilt_overlap_peak,\n\t\t\tpeak_type = peak_type_,\n\t\t\tchrsz = chrsz_,\n\t\t}\n\t}\n\n\tif ( !align_only && !true_rep_only && num_rep > 0 && enable_idr ) {\n\t\t# reproducibility QC for IDR peaks\n\t\tcall reproducibility as reproducibility_idr { input :\n\t\t\tprefix = 'idr',\n\t\t\tpeaks = idr.bfilt_idr_peak,\n\t\t\tpeaks_pr = idr_pr.bfilt_idr_peak,\n\t\t\tpeak_ppr = idr_ppr.bfilt_idr_peak,\n\t\t\tpeak_type = peak_type_,\n\t\t\tchrsz = chrsz_,\n\t\t}\n\t}\n\n\t# Generate final QC report and JSON\n\tcall qc_report { input :\n\t\tpipeline_ver = pipeline_ver,\n\t\ttitle = title,\n\t\tdescription = description,\n\t\tgenome = genome_name_,\n\t\tpaired_ends = paired_end_,\n\t\tctl_paired_ends = ctl_paired_end_,\n\t\tpipeline_type = pipeline_type,\n\t\taligner = aligner_,\n\t\tpeak_caller = peak_caller_,\n\t\tcap_num_peak = cap_num_peak_,\n\t\tidr_thresh = idr_thresh,\n\t\tpval_thresh = pval_thresh,\n\t\txcor_trim_bp = xcor_trim_bp,\n\t\txcor_subsample_reads = xcor_subsample_reads,\n\n\t\tsamstat_qcs = align.samstat_qc,\n\t\tnodup_samstat_qcs = filter.samstat_qc,\n\t\tdup_qcs = filter.dup_qc,\n\t\tlib_complexity_qcs = filter.lib_complexity_qc,\n\t\txcor_plots = xcor.plot_png,\n\t\txcor_scores = xcor.score,\n\n\t\tctl_samstat_qcs = align_ctl.samstat_qc,\n\t\tctl_nodup_samstat_qcs = filter_ctl.samstat_qc,\n\t\tctl_dup_qcs = filter_ctl.dup_qc,\n\t\tctl_lib_complexity_qcs = filter_ctl.lib_complexity_qc,\n\n\t\tjsd_plot = jsd.plot,\n\t\tjsd_qcs = jsd.jsd_qcs,\n\n\t\tfrip_qcs = call_peak.frip_qc,\n\t\tfrip_qcs_pr1 = call_peak_pr1.frip_qc,\n\t\tfrip_qcs_pr2 = call_peak_pr2.frip_qc,\n\t\tfrip_qc_pooled = call_peak_pooled.frip_qc,\n\t\tfrip_qc_ppr1 = call_peak_ppr1.frip_qc,\n\t\tfrip_qc_ppr2 = call_peak_ppr2.frip_qc,\n\n\t\tidr_plots = idr.idr_plot,\n\t\tidr_plots_pr = idr_pr.idr_plot,\n\t\tidr_plot_ppr = idr_ppr.idr_plot,\n\t\tfrip_idr_qcs = idr.frip_qc,\n\t\tfrip_idr_qcs_pr = idr_pr.frip_qc,\n\t\tfrip_idr_qc_ppr = idr_ppr.frip_qc,\n\t\tfrip_overlap_qcs = overlap.frip_qc,\n\t\tfrip_overlap_qcs_pr = overlap_pr.frip_qc,\n\t\tfrip_overlap_qc_ppr = overlap_ppr.frip_qc,\n\t\tidr_reproducibility_qc = reproducibility_idr.reproducibility_qc,\n\t\toverlap_reproducibility_qc = reproducibility_overlap.reproducibility_qc,\n\n\t\tgc_plots = gc_bias.gc_plot,\n\n\t\tpeak_region_size_qcs = call_peak.peak_region_size_qc,\n\t\tpeak_region_size_plots = call_peak.peak_region_size_plot,\n\t\tnum_peak_qcs = call_peak.num_peak_qc,\n\n\t\tidr_opt_peak_region_size_qc = reproducibility_idr.peak_region_size_qc,\n\t\tidr_opt_peak_region_size_plot = reproducibility_overlap.peak_region_size_plot,\n\t\tidr_opt_num_peak_qc = reproducibility_idr.num_peak_qc,\n\n\t\toverlap_opt_peak_region_size_qc = reproducibility_overlap.peak_region_size_qc,\n\t\toverlap_opt_peak_region_size_plot = reproducibility_overlap.peak_region_size_plot,\n\t\toverlap_opt_num_peak_qc = reproducibility_overlap.num_peak_qc,\n\t}\n\n\toutput {\n\t\tFile report = qc_report.report\n\t\tFile qc_json = qc_report.qc_json\n\t\tBoolean qc_json_ref_match = qc_report.qc_json_ref_match\n\t}\n}\n\ntask align {\n\tArray[File] fastqs_R1 \t\t# [merge_id]\n\tArray[File] fastqs_R2\n\tInt? trim_bp\t\t\t# this is for R1 only\n\tInt crop_length\n\tString aligner\n\tString mito_chr_name\n\tInt? multimapping\n\tFile? custom_align_py\t\n\tFile? idx_tar\t\t\t# reference index tar\n\tBoolean paired_end\n\tBoolean use_bwa_mem_for_pe\n\n\tString? trimmomatic_java_heap\n\tInt cpu\n\tInt mem_mb\n\tInt time_hr\n\tString disks\n\n\tArray[Array[File]] tmp_fastqs = if paired_end then transpose([fastqs_R1, fastqs_R2])\n\t\t\t\telse transpose([fastqs_R1])\n\tcommand {\n\t\tset -e\n\n\t\t# check if pipeline dependencies can be found\n\t\tif [[ -z \""$(which encode_task_merge_fastq.py 2> /dev/null || true)\"" ]]\n\t\tthen\n\t\t  echo -e \""\\n* Error: pipeline dependencies not found.\"" 1>&2\n\t\t  echo 'Conda users: Did you activate Conda environment (conda activate encode-chip-seq-pipeline)?' 1>&2\n\t\t  echo '    Or did you install Conda and environment correctly (bash scripts/install_conda_env.sh)?' 1>&2\n\t\t  echo 'GCP/AWS/Docker users: Did you add --docker flag to Caper command line arg?' 1>&2\n\t\t  echo 'Singularity users: Did you add --singularity flag to Caper command line arg?' 1>&2\n\t\t  echo -e \""\\n\"" 1>&2\n\t\t  exit 3\n\t\tfi\n\t\tpython3 $(which encode_task_merge_fastq.py) \\\n\t\t\t${write_tsv(tmp_fastqs)} \\\n\t\t\t${if paired_end then '--paired-end' else ''} \\\n\t\t\t${'--nth ' + cpu}\n\n\t\tif [ -z '${trim_bp}' ]; then\n\t\t\tSUFFIX=\n\t\telse\n\t\t\tSUFFIX=_trimmed\n\t\t\tpython3 $(which encode_task_trim_fastq.py) \\\n\t\t\t\tR1/*.fastq.gz \\\n\t\t\t\t--trim-bp ${trim_bp} \\\n\t\t\t\t--out-dir R1$SUFFIX\n\t\t\tif [ '${paired_end}' == 'true' ]; then\n\t\t\t\tpython3 $(which encode_task_trim_fastq.py) \\\n\t\t\t\t\tR2/*.fastq.gz \\\n\t\t\t\t\t--trim-bp ${trim_bp} \\\n\t\t\t\t\t--out-dir R2$SUFFIX\n\t\t\tfi\n\t\tfi\n\t\tif [ '${crop_length}' == '0' ]; then\n\t\t\tSUFFIX=$SUFFIX\n\t\telse\n\t\t\tNEW_SUFFIX=\""$SUFFIX\""_cropped\n\t\t\tpython3 $(which encode_task_trimmomatic.py) \\\n\t\t\t\t--fastq1 R1$SUFFIX/*.fastq.gz \\\n\t\t\t\t${if paired_end then '--fastq2 R2$SUFFIX/*.fastq.gz' else ''} \\\n\t\t\t\t${if paired_end then '--paired-end' else ''} \\\n\t\t\t\t--crop-length ${crop_length} \\\n\t\t\t\t--out-dir-R1 R1$NEW_SUFFIX \\\n\t\t\t\t${if paired_end then '--out-dir-R2 R2$NEW_SUFFIX' else ''} \\\n\t\t\t\t${'--trimmomatic-java-heap ' + if defined(trimmomatic_java_heap) then trimmomatic_java_heap else (mem_mb + 'M')} \\\n\t\t\t\t${'--nth ' + cpu}\n\t\t\tSUFFIX=$NEW_SUFFIX\n\t\tfi\n\n\t\tif [ '${aligner}' == 'bwa' ]; then\n\t\t \tpython3 $(which encode_task_bwa.py) \\\n\t\t\t\t${idx_tar} \\\n\t\t\t\tR1$SUFFIX/*.fastq.gz \\\n\t\t\t\t${if paired_end then 'R2$SUFFIX/*.fastq.gz' else ''} \\\n\t\t\t\t${if paired_end then '--paired-end' else ''} \\\n\t\t\t\t${if use_bwa_mem_for_pe then '--use-bwa-mem-for-pe' else ''} \\\n\t\t\t\t${'--nth ' + cpu}\n\n\t\telif [ '${aligner}' == 'bowtie2' ]; then\n\t\t \tpython3 $(which encode_task_bowtie2.py) \\\n\t\t\t\t${idx_tar} \\\n\t\t\t\tR1$SUFFIX/*.fastq.gz \\\n\t\t\t\t${if paired_end then 'R2$SUFFIX/*.fastq.gz' else ''} \\\n\t\t\t\t${'--multimapping ' + multimapping} \\\n\t\t\t\t${if paired_end then '--paired-end' else ''} \\\n\t\t\t\t${'--nth ' + cpu}\n\t\telse\n\t\t\tpython3 ${custom_align_py} \\\n\t\t\t\t${idx_tar} \\\n\t\t\t\tR1$SUFFIX/*.fastq.gz \\\n\t\t\t\t${if paired_end then 'R2$SUFFIX/*.fastq.gz' else ''} \\\n\t\t\t\t${if paired_end then '--paired-end' else ''} \\\n\t\t\t\t${'--nth ' + cpu}\n\t\tfi \n\n\t\tpython3 $(which encode_task_post_align.py) \\\n\t\t\tR1$SUFFIX/*.fastq.gz $(ls *.bam) \\\n\t\t\t${'--mito-chr-name ' + mito_chr_name} \\\n\t\t\t${'--nth ' + cpu}\n\t\trm -rf R1 R2 R1$SUFFIX R2$SUFFIX\n\t}\n\toutput {\n\t\tFile bam = glob('*.bam')[0]\n\t\tFile bai = glob('*.bai')[0]\n\t\tFile samstat_qc = glob('*.samstats.qc')[0]\n\t\tFile read_len_log = glob('*.read_length.txt')[0]\n\t}\n\truntime {\n\t\tcpu : cpu\n\t\tmemory : '${mem_mb} MB'\n\t\ttime : time_hr\n\t\tdisks : disks\n\t\tpreemptible: 0\n\t}\n}\n\ntask filter {\n\tFile bam\n\tBoolean paired_end\n\tString dup_marker \t\t\t# picard.jar MarkDuplicates (picard) or \n\t\t\t\t\t\t\t\t# sambamba markdup (sambamba)\n\tInt mapq_thresh\t\t\t\t# threshold for low MAPQ reads removal\n\tArray[String] filter_chrs \t# chrs to be removed from final (nodup/filt) BAM\n\tFile chrsz\t\t\t\t\t# 2-col chromosome sizes file\n\tBoolean no_dup_removal \t\t# no dupe reads removal when filtering BAM\n\tString mito_chr_name\n\n\tInt cpu\n\tInt mem_mb\n\tString? picard_java_heap\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\tpython3 $(which encode_task_filter.py) \\\n\t\t\t${bam} \\\n\t\t\t${if paired_end then '--paired-end' else ''} \\\n\t\t\t--multimapping 0 \\\n\t\t\t${'--dup-marker ' + dup_marker} \\\n\t\t\t${'--mapq-thresh ' + mapq_thresh} \\\n\t\t\t--filter-chrs ${sep=' ' filter_chrs} \\\n\t\t\t${'--chrsz ' + chrsz} \\\n\t\t\t${if no_dup_removal then '--no-dup-removal' else ''} \\\n\t\t\t${'--mito-chr-name ' + mito_chr_name} \\\n\t\t\t${'--nth ' + cpu} \\\n\t\t\t${'--picard-java-heap ' + if defined(picard_java_heap) then picard_java_heap else (mem_mb + 'M')}\n\t}\n\toutput {\n\t\tFile nodup_bam = glob('*.bam')[0]\n\t\tFile nodup_bai = glob('*.bai')[0]\n\t\tFile samstat_qc = glob('*.samstats.qc')[0]\n\t\tFile dup_qc = glob('*.dup.qc')[0]\n\t\tFile lib_complexity_qc = glob('*.lib_complexity.qc')[0]\n\t}\n\truntime {\n\t\tcpu : cpu\n\t\tmemory : '${mem_mb} MB'\n\t\ttime : time_hr\n\t\tdisks : disks\n\t}\n}\n\ntask bam2ta {\n\tFile bam\n\tBoolean paired_end\n\tString mito_chr_name \t\t# mito chromosome name\n\tInt subsample \t\t\t\t# number of reads to subsample TAGALIGN\n\t\t\t\t\t\t\t\t# this affects all downstream analysis\n\tInt cpu\n\tInt mem_mb\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\tpython3 $(which encode_task_bam2ta.py) \\\n\t\t\t${bam} \\\n\t\t\t--disable-tn5-shift \\\n\t\t\t${if paired_end then '--paired-end' else ''} \\\n\t\t\t${'--mito-chr-name ' + mito_chr_name} \\\n\t\t\t${'--subsample ' + subsample} \\\n\t\t\t${'--nth ' + cpu}\n\t}\n\toutput {\n\t\tFile ta = glob('*.tagAlign.gz')[0]\n\t}\n\truntime {\n\t\tcpu : cpu\n\t\tmemory : '${mem_mb} MB'\n\t\ttime : time_hr\n\t\tdisks : disks\n\t}\n}\n\ntask spr { # make two self pseudo replicates\n\tFile ta\n\tBoolean paired_end\n\n\tInt mem_mb\n\n\tcommand {\n\t\tpython3 $(which encode_task_spr.py) \\\n\t\t\t${ta} \\\n\t\t\t${if paired_end then '--paired-end' else ''}\n\t}\n\toutput {\n\t\tFile ta_pr1 = glob('*.pr1.tagAlign.gz')[0]\n\t\tFile ta_pr2 = glob('*.pr2.tagAlign.gz')[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : '${mem_mb} MB'\n\t\ttime : 1\n\t\tdisks : 'local-disk 50 HDD'\n\t}\n}\n\ntask pool_ta {\n\tArray[File?] tas\n\tInt? col \t\t\t# number of columns in pooled TA\n\tString? prefix \t\t# basename prefix\n\n\tcommand {\n\t\tpython3 $(which encode_task_pool_ta.py) \\\n\t\t\t${sep=' ' tas} \\\n\t\t\t${'--prefix ' + prefix} \\\n\t\t\t${'--col ' + col}\n\t}\n\toutput {\n\t\tFile ta_pooled = glob('*.tagAlign.gz')[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : '4000 MB'\n\t\ttime : 1\n\t\tdisks : 'local-disk 50 HDD'\n\t}\n}\n\ntask xcor {\n\tFile ta\n\tBoolean paired_end\n\tString mito_chr_name\n\tInt subsample  # number of reads to subsample TAGALIGN\n\t\t\t\t\t# this will be used for xcor only\n\t\t\t\t\t# will not affect any downstream analysis\n\tString? chip_seq_type\n\tInt? exclusion_range_min\n\tInt? exclusion_range_max\n\n\tInt cpu\n\tInt mem_mb\t\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\tpython3 $(which encode_task_xcor.py) \\\n\t\t\t${ta} \\\n\t\t\t${if paired_end then '--paired-end' else ''} \\\n\t\t\t${'--mito-chr-name ' + mito_chr_name} \\\n\t\t\t${'--subsample ' + subsample} \\\n\t\t\t${'--chip-seq-type ' + chip_seq_type} \\\n\t\t\t${'--exclusion-range-min ' + exclusion_range_min} \\\n\t\t\t${'--exclusion-range-max ' + exclusion_range_max} \\\n\t\t\t${'--subsample ' + subsample} \\\n\t\t\t${'--nth ' + cpu}\n\t}\n\toutput {\n\t\tFile plot_pdf = glob('*.cc.plot.pdf')[0]\n\t\tFile plot_png = glob('*.cc.plot.png')[0]\n\t\tFile score = glob('*.cc.qc')[0]\n\t\tInt fraglen = read_int(glob('*.cc.fraglen.txt')[0])\n\t}\n\truntime {\n\t\tcpu : cpu\n\t\tmemory : '${mem_mb} MB'\n\t\ttime : time_hr\n\t\tdisks : disks\n\t}\n}\n\ntask jsd {\n\tArray[File?] nodup_bams\n\tArray[File?] ctl_bams\n\tFile blacklist\n\tInt mapq_thresh\n\n\tInt cpu\n\tInt mem_mb\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\tpython3 $(which encode_task_jsd.py) \\\n\t\t\t${sep=' ' nodup_bams} \\\n\t\t\t${if length(ctl_bams)>0 then '--ctl-bam '+ select_first(ctl_bams) else ''} \\\n\t\t\t${'--mapq-thresh '+ mapq_thresh} \\\n\t\t\t${'--blacklist '+ blacklist} \\\n\t\t\t${'--nth ' + cpu}\n\t}\n\toutput {\n\t\tFile plot = glob('*.png')[0]\n\t\tArray[File] jsd_qcs = glob('*.jsd.qc')\n\t}\n\truntime {\n\t\tcpu : cpu\n\t\tmemory : '${mem_mb} MB'\n\t\ttime : time_hr\n\t\tdisks : disks\n\t}\n}\n\ntask choose_ctl {\n\tArray[File?] tas\n\tArray[File?] ctl_tas\n\tFile? ta_pooled\n\tFile? ctl_ta_pooled\n\tBoolean always_use_pooled_ctl # always use pooled control for all exp rep.\n\tFloat ctl_depth_ratio \t\t# if ratio between controls is higher than this\n\t\t\t\t\t\t\t\t# then always use pooled control for all exp rep.\n\tcommand {\n\t\tpython3 $(which encode_task_choose_ctl.py) \\\n\t\t\t--tas ${sep=' ' tas} \\\n\t\t\t--ctl-tas ${sep=' ' ctl_tas} \\\n\t\t\t${'--ta-pooled ' + ta_pooled} \\\n\t\t\t${'--ctl-ta-pooled ' + ctl_ta_pooled} \\\n\t\t\t${if always_use_pooled_ctl then '--always-use-pooled-ctl' else ''} \\\n\t\t\t${'--ctl-depth-ratio ' + ctl_depth_ratio}\n\t}\n\toutput {\n\t\tArray[File] chosen_ctl_tas = glob('ctl_for_rep*.tagAlign.gz')\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : '8000 MB'\n\t\ttime : 1\n\t\tdisks : 'local-disk 50 HDD'\n\t}\t\n}\n\ntask count_signal_track {\n\tFile ta \t\t\t# tag-align\n\tFile chrsz\t\t\t# 2-col chromosome sizes file\n\n\tcommand {\n\t\tpython3 $(which encode_task_count_signal_track.py) \\\n\t\t\t${ta} \\\n\t\t\t${'--chrsz ' + chrsz}\n\t}\n\toutput {\n\t\tFile pos_bw = glob('*.positive.bigwig')[0]\n\t\tFile neg_bw = glob('*.negative.bigwig')[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : '8000 MB'\n\t\ttime : 4\n\t\tdisks : 'local-disk 50 HDD'\n\t}\n}\n\ntask call_peak {\n\tString peak_caller\n\tString peak_type\n\tFile? custom_call_peak_py\n\n\tArray[File?] tas\t# [ta, control_ta]. control_ta is optional\n\tInt fraglen \t\t# fragment length from xcor\n\tString gensz\t\t# Genome size (sum of entries in 2nd column of \n                        # chr. sizes file, or hs for human, ms for mouse)\n\tFile chrsz\t\t\t# 2-col chromosome sizes file\n\tInt cap_num_peak\t# cap number of raw peaks called from MACS2\n\tFloat pval_thresh \t# p.value threshold for MACS2\n\tFloat? fdr_thresh \t# FDR threshold for SPP\n\n\tFile? blacklist \t# blacklist BED to filter raw peaks\n\tString? regex_bfilt_peak_chr_name\n\n\tInt cpu\t\n\tInt mem_mb\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\tset -e\n\n\t\tif [ '${peak_caller}' == 'macs2' ]; then\n\t\t\tpython3 $(which encode_task_macs2_chip.py) \\\n\t\t\t\t${sep=' ' tas} \\\n\t\t\t\t${'--gensz '+ gensz} \\\n\t\t\t\t${'--chrsz ' + chrsz} \\\n\t\t\t\t${'--fraglen ' + fraglen} \\\n\t\t\t\t${'--cap-num-peak ' + cap_num_peak} \\\n\t\t\t\t${'--pval-thresh '+ pval_thresh}\n\n\t\telif [ '${peak_caller}' == 'spp' ]; then\n\t\t\tpython3 $(which encode_task_spp.py) \\\n\t\t\t\t${sep=' ' tas} \\\n\t\t\t\t${'--fraglen ' + fraglen} \\\n\t\t\t\t${'--cap-num-peak ' + cap_num_peak} \\\n\t\t\t\t${'--fdr-thresh '+ fdr_thresh} \\\n\t\t\t\t${'--nth ' + cpu}\n\n\t\telse\n\t\t\tpython3 ${custom_call_peak_py} \\\n\t\t\t\t${sep=' ' tas} \\\n\t\t\t\t${'--gensz '+ gensz} \\\n\t\t\t\t${'--chrsz ' + chrsz} \\\n\t\t\t\t${'--fraglen ' + fraglen} \\\n\t\t\t\t${'--cap-num-peak ' + cap_num_peak} \\\n\t\t\t\t${'--pval-thresh '+ pval_thresh}\n\t\t\t\t${'--fdr-thresh '+ fdr_thresh}\n\t\t\t\t${'--nth ' + cpu}\n\t\tfi\n\n\t\tpython3 $(which encode_task_post_call_peak_chip.py) \\\n\t\t\t$(ls *Peak.gz) \\\n\t\t\t${'--ta ' + tas[0]} \\\n\t\t\t${'--regex-bfilt-peak-chr-name \\'' + regex_bfilt_peak_chr_name + '\\''} \\\n\t\t\t${'--chrsz ' + chrsz} \\\n\t\t\t${'--fraglen ' + fraglen} \\\n\t\t\t${'--peak-type ' + peak_type} \\\n\t\t\t${'--blacklist ' + blacklist}\t\t\n\t}\n\toutput {\n\t\t# generated by custom_call_peak_py\n\t\tFile peak = glob('*[!.][!b][!f][!i][!l][!t].'+peak_type+'.gz')[0]\n\t\t# generated by post_call_peak py\n\t\tFile bfilt_peak = glob('*.bfilt.'+peak_type+'.gz')[0]\n\t\tFile bfilt_peak_bb = glob('*.bfilt.'+peak_type+'.bb')[0]\n\t\tFile bfilt_peak_hammock = glob('*.bfilt.'+peak_type+'.hammock.gz*')[0]\n\t\tFile bfilt_peak_hammock_tbi = glob('*.bfilt.'+peak_type+'.hammock.gz*')[1]\n\t\tFile frip_qc = glob('*.frip.qc')[0]\n\t\tFile peak_region_size_qc = glob('*.peak_region_size.qc')[0]\n\t\tFile peak_region_size_plot = glob('*.peak_region_size.png')[0]\n\t\tFile num_peak_qc = glob('*.num_peak.qc')[0]\n\t}\n\truntime {\n\t\tcpu : if peak_caller == 'macs2' then 1 else cpu\n\t\tmemory : '${mem_mb} MB'\n\t\ttime : time_hr\n\t\tdisks : disks\n\t\tpreemptible: 0\t\t\n\t}\n}\n\ntask macs2_signal_track {\n\tArray[File?] tas\t# [ta, control_ta]. control_ta is optional\n\tInt fraglen \t\t# fragment length from xcor\n\tString gensz\t\t# Genome size (sum of entries in 2nd column of \n                        # chr. sizes file, or hs for human, ms for mouse)\n\tFile chrsz\t\t\t# 2-col chromosome sizes file\n\tFloat pval_thresh \t# p.value threshold\n\n\tInt mem_mb\n\tInt time_hr\n\tString disks\n\n\tcommand {\n\t\tpython3 $(which encode_task_macs2_signal_track_chip.py) \\\n\t\t\t${sep=' ' tas} \\\n\t\t\t${'--gensz '+ gensz} \\\n\t\t\t${'--chrsz ' + chrsz} \\\n\t\t\t${'--fraglen ' + fraglen} \\\n\t\t\t${'--pval-thresh '+ pval_thresh}\n\t}\n\toutput {\n\t\tFile pval_bw = glob('*.pval.signal.bigwig')[0]\n\t\tFile fc_bw = glob('*.fc.signal.bigwig')[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : '${mem_mb} MB'\n\t\ttime : time_hr\n\t\tdisks : disks\n\t\tpreemptible: 0\n\t}\n}\n\ntask idr {\n\tString prefix \t\t# prefix for IDR output file\n\tFile peak1 \t\t\t\n\tFile peak2\n\tFile peak_pooled\n\tFloat idr_thresh\n\tFile? blacklist \t# blacklist BED to filter raw peaks\n\tString regex_bfilt_peak_chr_name\n\t# parameters to compute FRiP\n\tFile? ta\t\t\t# to calculate FRiP\n\tInt fraglen \t\t# fragment length from xcor\n\tFile chrsz\t\t\t# 2-col chromosome sizes file\n\tString peak_type\n\tString rank\n\n\tcommand {\n\t\t${if defined(ta) then '' else 'touch null.frip.qc'}\n\t\ttouch null \n\t\tpython3 $(which encode_task_idr.py) \\\n\t\t\t${peak1} ${peak2} ${peak_pooled} \\\n\t\t\t${'--prefix ' + prefix} \\\n\t\t\t${'--idr-thresh ' + idr_thresh} \\\n\t\t\t${'--peak-type ' + peak_type} \\\n\t\t\t--idr-rank ${rank} \\\n\t\t\t${'--fraglen ' + fraglen} \\\n\t\t\t${'--chrsz ' + chrsz} \\\n\t\t\t${'--blacklist '+ blacklist} \\\n\t\t\t${'--regex-bfilt-peak-chr-name \\'' + regex_bfilt_peak_chr_name + '\\''} \\\n\t\t\t${'--ta ' + ta}\n\t}\n\toutput {\n\t\tFile idr_peak = glob('*[!.][!b][!f][!i][!l][!t].'+peak_type+'.gz')[0]\n\t\tFile bfilt_idr_peak = glob('*.bfilt.'+peak_type+'.gz')[0]\n\t\tFile bfilt_idr_peak_bb = glob('*.bfilt.'+peak_type+'.bb')[0]\n\t\tFile bfilt_idr_peak_hammock = glob('*.bfilt.'+peak_type+'.hammock.gz*')[0]\n\t\tFile bfilt_idr_peak_hammock_tbi = glob('*.bfilt.'+peak_type+'.hammock.gz*')[1]\n\t\tFile idr_plot = glob('*.txt.png')[0]\n\t\tFile idr_unthresholded_peak = glob('*.txt.gz')[0]\n\t\tFile idr_log = glob('*.idr*.log')[0]\n\t\tFile frip_qc = if defined(ta) then glob('*.frip.qc')[0] else glob('null')[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : '4000 MB'\n\t\ttime : 1\n\t\tdisks : 'local-disk 50 HDD'\n\t}\t\n}\n\ntask overlap {\n\tString prefix \t# prefix for IDR output file\n\tFile peak1\n\tFile peak2\n\tFile peak_pooled\n\tFile? blacklist # blacklist BED to filter raw peaks\n\tString regex_bfilt_peak_chr_name\n\t# parameters to compute FRiP\n\tFile? ta\t\t# to calculate FRiP\n\tInt fraglen \t# fragment length from xcor (for FRIP)\n\tFile chrsz\t\t# 2-col chromosome sizes file\n\tString peak_type\n\n\tcommand {\n\t\t${if defined(ta) then '' else 'touch null.frip.qc'}\n\t\ttouch null \n\t\tpython3 $(which encode_task_overlap.py) \\\n\t\t\t${peak1} ${peak2} ${peak_pooled} \\\n\t\t\t${'--prefix ' + prefix} \\\n\t\t\t${'--peak-type ' + peak_type} \\\n\t\t\t${'--fraglen ' + fraglen} \\\n\t\t\t${'--chrsz ' + chrsz} \\\n\t\t\t${'--blacklist '+ blacklist} \\\n\t\t\t--nonamecheck \\\n\t\t\t${'--regex-bfilt-peak-chr-name \\'' + regex_bfilt_peak_chr_name + '\\''} \\\n\t\t\t${'--ta ' + ta}\n\t}\n\toutput {\n\t\tFile overlap_peak = glob('*[!.][!b][!f][!i][!l][!t].'+peak_type+'.gz')[0]\n\t\tFile bfilt_overlap_peak = glob('*.bfilt.'+peak_type+'.gz')[0]\n\t\tFile bfilt_overlap_peak_bb = glob('*.bfilt.'+peak_type+'.bb')[0]\n\t\tFile bfilt_overlap_peak_hammock = glob('*.bfilt.'+peak_type+'.hammock.gz*')[0]\n\t\tFile bfilt_overlap_peak_hammock_tbi = glob('*.bfilt.'+peak_type+'.hammock.gz*')[1]\n\t\tFile frip_qc = if defined(ta) then glob('*.frip.qc')[0] else glob('null')[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : '4000 MB'\n\t\ttime : 1\n\t\tdisks : 'local-disk 50 HDD'\n\t}\t\n}\n\ntask reproducibility {\n\tString prefix\n\tArray[File]? peaks # peak files from pair of true replicates\n\t\t\t\t\t\t# in a sorted order. for example of 4 replicates,\n\t\t\t\t\t\t# 1,2 1,3 1,4 2,3 2,4 3,4.\n                        # x,y means peak file from rep-x vs rep-y\n\tArray[File?] peaks_pr\t# peak files from pseudo replicates\n\tFile? peak_ppr\t\t\t# Peak file from pooled pseudo replicate.\n\tString peak_type\n\tFile chrsz\t\t\t# 2-col chromosome sizes file\n\n\tcommand {\n\t\tpython3 $(which encode_task_reproducibility.py) \\\n\t\t\t${sep=' ' peaks} \\\n\t\t\t--peaks-pr ${sep=' ' peaks_pr} \\\n\t\t\t${'--peak-ppr '+ peak_ppr} \\\n\t\t\t--prefix ${prefix} \\\n\t\t\t${'--peak-type ' + peak_type} \\\n\t\t\t${'--chrsz ' + chrsz}\n\t}\n\toutput {\n\t\tFile optimal_peak = glob('*optimal_peak.*.gz')[0]\n\t\tFile optimal_peak_bb = glob('*optimal_peak.*.bb')[0]\n\t\tFile optimal_peak_hammock = glob('*optimal_peak.*.hammock.gz*')[0]\n\t\tFile optimal_peak_hammock_tbi = glob('*optimal_peak.*.hammock.gz*')[1]\n\t\tFile conservative_peak = glob('*conservative_peak.*.gz')[0]\n\t\tFile conservative_peak_bb = glob('*conservative_peak.*.bb')[0]\n\t\tFile conservative_peak_hammock = glob('*conservative_peak.*.hammock.gz*')[0]\n\t\tFile conservative_peak_hammock_tbi = glob('*conservative_peak.*.hammock.gz*')[1]\n\t\tFile reproducibility_qc = glob('*reproducibility.qc')[0]\n\t\t# QC metrics for optimal peak\n\t\tFile peak_region_size_qc = glob('*.peak_region_size.qc')[0]\n\t\tFile peak_region_size_plot = glob('*.peak_region_size.png')[0]\n\t\tFile num_peak_qc = glob('*.num_peak.qc')[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : '4000 MB'\n\t\ttime : 1\n\t\tdisks : 'local-disk 50 HDD'\n\t}\t\n}\n\ntask gc_bias {\n\tFile nodup_bam\n\tFile ref_fa\n\n\tString? picard_java_heap\n\n\tcommand {\n\t\tpython3 $(which encode_task_gc_bias.py) \\\n\t\t\t${'--nodup-bam ' + nodup_bam} \\\n\t\t\t${'--ref-fa ' + ref_fa} \\\n\t\t\t${'--picard-java-heap ' + if defined(picard_java_heap) then picard_java_heap else '10G'}\n\t}\n\toutput {\n\t\tFile gc_plot = glob('*.gc_plot.png')[0]\n\t\tFile gc_log = glob('*.gc.txt')[0]\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : '10000 MB'\n\t\ttime : 6\n\t\tdisks : 'local-disk 100 HDD'\n\t}\n}\n\n# gather all outputs and generate \n# - qc.html\t\t: organized final HTML report\n# - qc.json\t\t: all QCs\ntask qc_report {\n\t# optional metadata\n\tString pipeline_ver\n \tString title # name of sample\n\tString description # description for sample\n\tString? genome\n\t#String? encode_accession_id\t# ENCODE accession ID of sample\n\t# workflow params\n\tArray[Boolean?] paired_ends\n\tArray[Boolean?] ctl_paired_ends\n\tString pipeline_type\n\tString aligner\n\tString peak_caller\n\tInt cap_num_peak\n\tFloat idr_thresh\n\tFloat pval_thresh\n\tInt xcor_trim_bp\n\tInt xcor_subsample_reads\n\t# QCs\n\tArray[File?] samstat_qcs\n\tArray[File?] nodup_samstat_qcs\n\tArray[File?] dup_qcs\n\tArray[File?] lib_complexity_qcs\n\tArray[File?] ctl_samstat_qcs\n\tArray[File?] ctl_nodup_samstat_qcs\n\tArray[File?] ctl_dup_qcs\n\tArray[File?] ctl_lib_complexity_qcs\n\tArray[File?] xcor_plots\n\tArray[File?] xcor_scores\n\tFile? jsd_plot\n\tArray[File]? jsd_qcs\n\tArray[File]? idr_plots\n\tArray[File]? idr_plots_pr\n\tFile? idr_plot_ppr\n\tArray[File?] frip_qcs\n\tArray[File?] frip_qcs_pr1\n\tArray[File?] frip_qcs_pr2\n\tFile? frip_qc_pooled\n\tFile? frip_qc_ppr1 \n\tFile? frip_qc_ppr2 \n\tArray[File]? frip_idr_qcs\n\tArray[File]? frip_idr_qcs_pr\n\tFile? frip_idr_qc_ppr \n\tArray[File]? frip_overlap_qcs\n\tArray[File]? frip_overlap_qcs_pr\n\tFile? frip_overlap_qc_ppr\n\tFile? idr_reproducibility_qc\n\tFile? overlap_reproducibility_qc\n\n\tArray[File?] gc_plots\n\n\tArray[File?] peak_region_size_qcs\n\tArray[File?] peak_region_size_plots\n\tArray[File?] num_peak_qcs\n\n\tFile? idr_opt_peak_region_size_qc\n\tFile? idr_opt_peak_region_size_plot\n\tFile? idr_opt_num_peak_qc\n\n\tFile? overlap_opt_peak_region_size_qc\n\tFile? overlap_opt_peak_region_size_plot\n\tFile? overlap_opt_num_peak_qc\n\n\tFile? qc_json_ref\n\n\tcommand {\n\t\tpython3 $(which encode_task_qc_report.py) \\\n\t\t\t${'--pipeline-ver ' + pipeline_ver} \\\n\t\t\t${\""--title '\"" + sub(title,\""'\"",\""_\"") + \""'\""} \\\n\t\t\t${\""--desc '\"" + sub(description,\""'\"",\""_\"") + \""'\""} \\\n\t\t\t${'--genome ' + genome} \\\n\t\t\t${'--multimapping ' + 0} \\\n\t\t\t--paired-ends ${sep=' ' paired_ends} \\\n\t\t\t--ctl-paired-ends ${sep=' ' ctl_paired_ends} \\\n\t\t\t--pipeline-type ${pipeline_type} \\\n\t\t\t--aligner ${aligner} \\\n\t\t\t--peak-caller ${peak_caller} \\\n\t\t\t${'--cap-num-peak ' + cap_num_peak} \\\n\t\t\t--idr-thresh ${idr_thresh} \\\n\t\t\t--pval-thresh ${pval_thresh} \\\n\t\t\t--xcor-trim-bp ${xcor_trim_bp} \\\n\t\t\t--xcor-subsample-reads ${xcor_subsample_reads} \\\n\t\t\t--samstat-qcs ${sep='_:_' samstat_qcs} \\\n\t\t\t--nodup-samstat-qcs ${sep='_:_' nodup_samstat_qcs} \\\n\t\t\t--dup-qcs ${sep='_:_' dup_qcs} \\\n\t\t\t--lib-complexity-qcs ${sep='_:_' lib_complexity_qcs} \\\n\t\t\t--xcor-plots ${sep='_:_' xcor_plots} \\\n\t\t\t--xcor-scores ${sep='_:_' xcor_scores} \\\n\t\t\t--idr-plots ${sep='_:_' idr_plots} \\\n\t\t\t--idr-plots-pr ${sep='_:_' idr_plots_pr} \\\n\t\t\t--ctl-samstat-qcs ${sep='_:_' ctl_samstat_qcs} \\\n\t\t\t--ctl-nodup-samstat-qcs ${sep='_:_' ctl_nodup_samstat_qcs} \\\n\t\t\t--ctl-dup-qcs ${sep='_:_' ctl_dup_qcs} \\\n\t\t\t--ctl-lib-complexity-qcs ${sep='_:_' ctl_lib_complexity_qcs} \\\n\t\t\t${'--jsd-plot ' + jsd_plot} \\\n\t\t\t--jsd-qcs ${sep='_:_' jsd_qcs} \\\n\t\t\t${'--idr-plot-ppr ' + idr_plot_ppr} \\\n\t\t\t--frip-qcs ${sep='_:_' frip_qcs} \\\n\t\t\t--frip-qcs-pr1 ${sep='_:_' frip_qcs_pr1} \\\n\t\t\t--frip-qcs-pr2 ${sep='_:_' frip_qcs_pr2} \\\n\t\t\t${'--frip-qc-pooled ' + frip_qc_pooled} \\\n\t\t\t${'--frip-qc-ppr1 ' + frip_qc_ppr1} \\\n\t\t\t${'--frip-qc-ppr2 ' + frip_qc_ppr2} \\\n\t\t\t--frip-idr-qcs ${sep='_:_' frip_idr_qcs} \\\n\t\t\t--frip-idr-qcs-pr ${sep='_:_' frip_idr_qcs_pr} \\\n\t\t\t${'--frip-idr-qc-ppr ' + frip_idr_qc_ppr} \\\n\t\t\t--frip-overlap-qcs ${sep='_:_' frip_overlap_qcs} \\\n\t\t\t--frip-overlap-qcs-pr ${sep='_:_' frip_overlap_qcs_pr} \\\n\t\t\t${'--frip-overlap-qc-ppr ' + frip_overlap_qc_ppr} \\\n\t\t\t${'--idr-reproducibility-qc ' + idr_reproducibility_qc} \\\n\t\t\t${'--overlap-reproducibility-qc ' + overlap_reproducibility_qc} \\\n\t\t\t--gc-plots ${sep='_:_' gc_plots} \\\n\t\t\t--peak-region-size-qcs ${sep='_:_' peak_region_size_qcs} \\\n\t\t\t--peak-region-size-plots ${sep='_:_' peak_region_size_plots} \\\n\t\t\t--num-peak-qcs ${sep='_:_' num_peak_qcs} \\\n\t\t\t${'--idr-opt-peak-region-size-qc ' + idr_opt_peak_region_size_qc} \\\n\t\t\t${'--idr-opt-peak-region-size-plot ' + idr_opt_peak_region_size_plot} \\\n\t\t\t${'--idr-opt-num-peak-qc ' + idr_opt_num_peak_qc} \\\n\t\t\t${'--overlap-opt-peak-region-size-qc ' + overlap_opt_peak_region_size_qc} \\\n\t\t\t${'--overlap-opt-peak-region-size-plot ' + overlap_opt_peak_region_size_plot} \\\n\t\t\t${'--overlap-opt-num-peak-qc ' + overlap_opt_num_peak_qc} \\\n\t\t\t--out-qc-html qc.html \\\n\t\t\t--out-qc-json qc.json \\\n\t\t\t${'--qc-json-ref ' + qc_json_ref}\n\t}\n\toutput {\n\t\tFile report = glob('*qc.html')[0]\n\t\tFile qc_json = glob('*qc.json')[0]\n\t\tBoolean qc_json_ref_match = read_string('qc_json_ref_match.txt')=='True'\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : '4000 MB'\n\t\ttime : 1\n\t\tdisks : 'local-disk 50 HDD'\n\t}\t\n}\n\n### workflow system tasks\ntask read_genome_tsv {\n\tFile genome_tsv\n\n\tString? null_s\n\tcommand <<<\n\t\t# create empty files for all entries\n\t\ttouch genome_name\n\t\ttouch ref_fa bowtie2_idx_tar bwa_idx_tar chrsz gensz blacklist blacklist2\n\t\ttouch custom_aligner_idx_tar\n\t\ttouch tss tss_enrich # for backward compatibility\n\t\ttouch dnase prom enh reg2map reg2map_bed roadmap_meta\n\t\ttouch mito_chr_name\n\t\ttouch regex_bfilt_peak_chr_name\n\n\t\tpython <<CODE\n\t\timport os\n\t\twith open('${genome_tsv}','r') as fp:\n\t\t\tfor line in fp:\n\t\t\t\tarr = line.strip('\\n').split('\\t')\n\t\t\t\tif arr:\n\t\t\t\t\tkey, val = arr\n\t\t\t\t\twith open(key,'w') as fp2:\n\t\t\t\t\t\tfp2.write(val)\n\t\tCODE\n\t>>>\n\toutput {\n\t\tString? genome_name = if size('genome_name')==0 then basename(genome_tsv) else read_string('genome_name')\n\t\tString? ref_fa = if size('ref_fa')==0 then null_s else read_string('ref_fa')\n\t\tString? bwa_idx_tar = if size('bwa_idx_tar')==0 then null_s else read_string('bwa_idx_tar')\n\t\tString? bowtie2_idx_tar = if size('bowtie2_idx_tar')==0 then null_s else read_string('bowtie2_idx_tar')\n\t\tString? custom_aligner_idx_tar = if size('custom_aligner_idx_tar')==0 then null_s else read_string('custom_aligner_idx_tar')\n\t\tString? chrsz = if size('chrsz')==0 then null_s else read_string('chrsz')\n\t\tString? gensz = if size('gensz')==0 then null_s else read_string('gensz')\n\t\tString? blacklist = if size('blacklist')==0 then null_s else read_string('blacklist')\n\t\tString? blacklist2 = if size('blacklist2')==0 then null_s else read_string('blacklist2')\n\t\tString? mito_chr_name = if size('mito_chr_name')==0 then null_s else read_string('mito_chr_name')\n\t\tString? regex_bfilt_peak_chr_name = if size('regex_bfilt_peak_chr_name')==0 then 'chr[\\\\dXY]+'\n\t\t\telse read_string('regex_bfilt_peak_chr_name')\n\t\t# optional data\n\t\tString? tss = if size('tss')!=0 then read_string('tss')\n\t\t\telse if size('tss_enrich')!=0 then read_string('tss_enrich') else null_s\n\t\tString? dnase = if size('dnase')==0 then null_s else read_string('dnase')\n\t\tString? prom = if size('prom')==0 then null_s else read_string('prom')\n\t\tString? enh = if size('enh')==0 then null_s else read_string('enh')\n\t\tString? reg2map = if size('reg2map')==0 then null_s else read_string('reg2map')\n\t\tString? reg2map_bed = if size('reg2map_bed')==0 then null_s else read_string('reg2map_bed')\n\t\tString? roadmap_meta = if size('roadmap_meta')==0 then null_s else read_string('roadmap_meta')\n\t}\n\truntime {\n\t\tmaxRetries : 0\n\t\tcpu : 1\n\t\tmemory : '4000 MB'\n\t\ttime : 1\n\t\tdisks : 'local-disk 50 HDD'\t\t\n\t}\n}\n\ntask rounded_mean {\n\tArray[Int] ints\n\tcommand <<<\n\t\tpython <<CODE\n\t\tarr = [${sep=',' ints}]\n\t\twith open('tmp.txt','w') as fp:\n\t\t\tif len(arr):\n\t\t\t    sum_ = sum(arr)\n\t\t\t    mean_ = sum(arr)/float(len(arr))\n\t\t\t    fp.write('{}'.format(int(round(mean_))))\n\t\t\telse:\n\t\t\t    fp.write('0')\n\t\tCODE\n\t>>>\n\toutput {\n\t\tInt rounded_mean = read_int('tmp.txt')\n\t}\n\truntime {\n\t\tcpu : 1\n\t\tmemory : '4000 MB'\n\t\ttime : 1\n\t\tdisks : 'local-disk 50 HDD'\n\t}\t\n}\n\ntask raise_exception {\n\tString msg\n\tcommand {\n\t\techo -e \""\\n* Error: ${msg}\\n\"" >&2\n\t\texit 2\n\t}\n\toutput {\n\t\tString error_msg = '${msg}'\n\t}\n\truntime {\n\t\tmaxRetries : 0\n\t}\n}\n"",
        ""root"": """",
        ""options"": ""{\n  \""backend\"": \""slurm\"",\n  \""default_runtime_attributes\"": {\n    \""maxRetries\"": 1,\n    \""slurm_account\"": \""aeurban\""\n  }\n}"",
        ""inputs"": ""{\n    \""chip.title\"" : \""chipseq miseq nano\"",\n    \""chip.description\"" : \""chip-seq test miseq nano ipsc\"",\n\n    \""chip.pipeline_type\"" : \""tf\"",\n    \""chip.aligner\"" : \""bowtie2\"",\n    \""chip.align_only\"" : false,\n    \""chip.true_rep_only\"" : false,\n\n    \""chip.genome_tsv\"" : \""/reference/ENCODE/pipeline_genome_data/genome_tsv/v1/hg38_scg.tsv\"",\n\n    \""chip.paired_end\"" : true,\n    \""chip.ctl_paired_end\"" : true,\n\n    \""chip.fastqs_rep1_R1\"" : [ \""/labs/dflev/siming/chipseq/raw_fastq/test_miseqnano/0425-3-cetch1-flag_subsample1_R1.fastq.gz\"" ],\n    \""chip.fastqs_rep1_R2\"" : [ \""/labs/dflev/siming/chipseq/raw_fastq/test_miseqnano/0425-3-cetch1-flag_subsample1_R2.fastq.gz\"" ],\n    \""chip.ctl_fastqs_rep1_R1\"" : [ \""/labs/dflev/siming/chipseq/raw_fastq/test_miseqnano/0425-3-cetch1-input_subsample1_R1.fastq.gz\"" ],\n    \""chip.ctl_fastqs_rep1_R2\"" : [ \""/labs/dflev/siming/chipseq/raw_fastq/test_miseqnano/0425-3-cetch1-input_subsample1_R2.fastq.gz\"" ],\n\n    \""chip.crop_length\"" : 0,\n\n    \""chip.mapq_thresh\"" : 30,\n    \""chip.dup_marker\"" : \""picard\"",\n    \""chip.no_dup_removal\"" : false,\n\n    \""chip.subsample_reads\"" : 0,\n    \""chip.ctl_subsample_reads\"" : 0,\n    \""chip.xcor_subsample_reads\"" : 15000000,\n\n    \""chip.xcor_trim_bp\"" : 50,\n    \""chip.use_filt_pe_ta_for_xcor\"" : false,\n\n    \""chip.always_use_pooled_ctl\"" : false,\n    \""chip.ctl_depth_ratio\"" : 1.2,\n\n    \""chip.peak_caller\"" : null,\n    \""chip.cap_num_peak_macs2\"" : 500000,\n    \""chip.pval_thresh\"" : 0.01,\n    \""chip.fdr_thresh\"" : 0.01,\n    \""chip.idr_thresh\"" : 0.05,\n    \""chip.cap_num_peak_spp\"" : 300000,\n\n    \""chip.enable_jsd\"" : true,\n    \""chip.enable_gc_bias\"" : true,\n    \""chip.enable_count_signal_track\"" : false,\n\n    \""chip.filter_chrs\"" : [],\n\n    \""chip.align_cpu\"" : 4,\n    \""chip.align_mem_mb\"" : 20000,\n    \""chip.align_time_hr\"" : 144,\n    \""chip.align_disks\"" : \""local-disk 400 HDD\"",\n\n    \""chip.filter_cpu\"" : 2,\n    \""chip.filter_mem_mb\"" : 20000,\n    \""chip.filter_time_hr\"" : 144,\n    \""chip.filter_disks\"" : \""local-disk 400 HDD\"",\n\n    \""chip.bam2ta_cpu\"" : 2,\n    \""chip.bam2ta_mem_mb\"" : 10000,\n    \""chip.bam2ta_time_hr\"" : 144,\n    \""chip.bam2ta_disks\"" : \""local-disk 100 HDD\"",\n\n    \""chip.spr_mem_mb\"" : 16000,\n\n    \""chip.jsd_cpu\"" : 2,\n    \""chip.jsd_mem_mb\"" : 12000,\n    \""chip.jsd_time_hr\"" : 144,\n    \""chip.jsd_disks\"" : \""local-disk 200 HDD\"",\n\n    \""chip.xcor_cpu\"" : 2,\n    \""chip.xcor_mem_mb\"" : 16000,\n    \""chip.xcor_time_hr\"" : 144,\n    \""chip.xcor_disks\"" : \""local-disk 100 HDD\"",\n\n    \""chip.call_peak_cpu\"" : 2,\n    \""chip.call_peak_mem_mb\"" : 16000,\n    \""chip.call_peak_time_hr\"" : 144,\n    \""chip.call_peak_disks\"" : \""local-disk 200 HDD\"",\n\n    \""chip.macs2_signal_track_mem_mb\"" : 16000,\n    \""chip.macs2_signal_track_time_hr\"" : 144,\n    \""chip.macs2_signal_track_disks\"" : \""local-disk 400 HDD\"",\n\n    \""chip.gc_bias_picard_java_heap\"" : \""10G\""\n}\n"",
        ""workflowUrl"": ""/labs/dflev/siming/software/chip-seq-pipeline2/chip.wdl"",
        ""labels"": ""{\n    \""caper-backend\"": \""slurm\"",\n    \""caper-str-label\"": \""chipseq_nano3_test1\"",\n    \""caper-user\"": \""simingz\""\n}""
    },
    ""calls"": {
        ""chip.overlap_pr"": [
            {
                ""retryableFailure"": true,
                ""executionStatus"": ""RetryableFailure"",
                ""stdout"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/execution/stdout"",
                ""backendStatus"": ""Done"",
                ""commandLine"": ""\ntouch null \npython3 $(which encode_task_overlap.py) \\\n\t/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/inputs/1836791510/0425-3-cetch1-flag_subsample1_R1.nodup.pr1_x_ctl_for_rep1.300K.regionPeak.gz /labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/inputs/-1827717161/0425-3-cetch1-flag_subsample1_R1.nodup.pr2_x_ctl_for_rep1.300K.regionPeak.gz /labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/inputs/1290460198/0425-3-cetch1-flag_subsample1_R1.nodup_x_ctl_for_rep1.300K.regionPeak.gz \\\n\t--prefix rep1-pr1_vs_rep1-pr2 \\\n\t--peak-type regionPeak \\\n\t--fraglen 200 \\\n\t--chrsz /labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/inputs/-723689832/hg38.chrom.sizes \\\n\t--blacklist /labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/inputs/-723689832/hg38.blacklist.bed.gz \\\n\t--nonamecheck \\\n\t--regex-bfilt-peak-chr-name 'chr[\\dXY]+' \\\n\t--ta /labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/inputs/-1113689129/0425-3-cetch1-flag_subsample1_R1.nodup.tagAlign.gz"",
                ""shardIndex"": 0,
                ""runtimeAttributes"": {
                    ""slurm_account"": ""aeurban"",
                    ""failOnStderr"": ""false"",
                    ""continueOnReturnCode"": ""0"",
                    ""maxRetries"": ""1"",
                    ""cpu"": ""1"",
                    ""time"": ""1"",
                    ""memory"": ""3.90625 GB""
                },
                ""callCaching"": {
                    ""allowResultReuse"": false,
                    ""hit"": false,
                    ""result"": ""Cache Miss"",
                    ""hashes"": {
                        ""output count"": ""1679091C5A880FAF6FB5E6087EB1B2DC"",
                        ""runtime attribute"": {
                            ""failOnStderr"": ""68934A3E9455FA72420237EB05902327"",
                            ""docker"": ""N/A"",
                            ""continueOnReturnCode"": ""CFCD208495D565EF66E7DFF9F98764DA""
                        },
                        ""output expression"": {
                            ""File overlap_peak"": ""5FE0ABD18E429C34B9371C7F78153E57"",
                            ""File frip_qc"": ""FFBDC0CF158D56A15AA0F87CB842D5C8"",
                            ""File bfilt_overlap_peak_hammock"": ""AAEDB2388B1A8885F60BDF99860308F2"",
                            ""File bfilt_overlap_peak_bb"": ""D2388B1E435478D195314A0DE2E9CEEB"",
                            ""File bfilt_overlap_peak_hammock_tbi"": ""F7AD80D930D3266E42DF62760BB4CA48"",
                            ""File bfilt_overlap_peak"": ""504E92495AEB2A7383BCE85ACF634E4A""
                        },
                        ""input count"": ""D3D9446802A44259755D38E6D163E820"",
                        ""backend name"": ""8C338F9EC0DF1BB3621803F2983039DA"",
                        ""command template"": ""B64FD519BA0800AF98DB11528D527648"",
                        ""input"": {
                            ""File peak2"": ""7e16b4ac12c4afe624c8ece83ff994a4"",
                            ""File blacklist"": ""4a58b07c400e8641dc3df79ad6fcf12c"",
                            ""Int fraglen"": ""3644A684F98EA8FE223C713B77189A77"",
                            ""File chrsz"": ""9b996e0d2eabf4f49ef31793c11d2f45"",
                            ""String regex_bfilt_peak_chr_name"": ""C742E46BA2D35AFA2B5C0BBCB7D31CE7"",
                            ""File peak_pooled"": ""44a9d024f599eaf7003cafd63a1a8574"",
                            ""File ta"": ""2db8b57a38e09aa03ad502953b1adc50"",
                            ""String prefix"": ""D3B9D7856D560D6435DB69A1320959A6"",
                            ""String peak_type"": ""CCC3DB10222D85D8F7B6CE07DD9D8E2F"",
                            ""File peak1"": ""b4ada56382dc83c1a00602df92c79ba5""
                        }
                    },
                    ""effectiveCallCachingMode"": ""ReadAndWriteCache""
                },
                ""inputs"": {
                    ""blacklist"": ""/reference/ENCODE/pipeline_genome_data/hg38/hg38.blacklist.bed.gz"",
                    ""peak_type"": ""regionPeak"",
                    ""ta"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-bam2ta/shard-0/execution/glob-199637d3015dccbe277f621a18be9eb4/0425-3-cetch1-flag_subsample1_R1.nodup.tagAlign.gz"",
                    ""prefix"": ""rep1-pr1_vs_rep1-pr2"",
                    ""peak2"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-call_peak_pr2/shard-0/execution/glob-3c17d82667de5da0b56a7c17d88175d2/0425-3-cetch1-flag_subsample1_R1.nodup.pr2_x_ctl_for_rep1.300K.regionPeak.gz"",
                    ""fraglen"": 200,
                    ""chrsz"": ""/reference/ENCODE/pipeline_genome_data/hg38/hg38.chrom.sizes"",
                    ""peak1"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-call_peak_pr1/shard-0/execution/glob-3c17d82667de5da0b56a7c17d88175d2/0425-3-cetch1-flag_subsample1_R1.nodup.pr1_x_ctl_for_rep1.300K.regionPeak.gz"",
                    ""regex_bfilt_peak_chr_name"": ""chr[\\dXY]+"",
                    ""peak_pooled"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-call_peak/shard-0/execution/glob-3c17d82667de5da0b56a7c17d88175d2/0425-3-cetch1-flag_subsample1_R1.nodup_x_ctl_for_rep1.300K.regionPeak.gz""
                },
                ""returnCode"": 1,
                ""failures"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Job chip.overlap_pr:0:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
                    }
                ],
                ""jobId"": ""14894969"",
                ""backend"": ""slurm"",
                ""end"": ""2020-04-07T21:30:05.053Z"",
                ""stderr"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/execution/stderr"",
                ""callRoot"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0"",
                ""attempt"": 1,
                ""executionEvents"": [
                    {
                        ""startTime"": ""2020-04-07T21:30:05.052Z"",
                        ""description"": ""UpdatingJobStore"",
                        ""endTime"": ""2020-04-07T21:30:05.052Z""
                    },
                    {
                        ""startTime"": ""2020-04-07T21:29:43.448Z"",
                        ""description"": ""Pending"",
                        ""endTime"": ""2020-04-07T21:29:43.449Z""
                    },
                    {
                        ""startTime"": ""2020-04-07T21:29:44.874Z"",
                        ""endTime"": ""2020-04-07T21:29:44.875Z"",
                        ""description"": ""WaitingForValueStore""
                    },
                    {
                        ""startTime"": ""2020-04-07T21:29:43.449Z"",
                        ""endTime"": ""2020-04-07T21:29:44.874Z"",
                        ""description"": ""RequestingExecutionToken""
                    },
                    {
                        ""description"": ""RunningJob"",
                        ""startTime"": ""2020-04-07T21:29:44.944Z"",
                        ""endTime"": ""2020-04-07T21:30:05.052Z""
                    },
                    {
                        ""endTime"": ""2020-04-07T21:29:44.944Z"",
                        ""startTime"": ""2020-04-07T21:29:44.885Z"",
                        ""description"": ""CallCacheReading""
                    },
                    {
                        ""startTime"": ""2020-04-07T21:29:44.875Z"",
                        ""description"": ""PreparingJob"",
                        ""endTime"": ""2020-04-07T21:29:44.885Z""
                    }
                ],
                ""start"": ""2020-04-07T21:29:43.448Z""
            },
            {
                ""retryableFailure"": false,
                ""executionStatus"": ""Failed"",
                ""stdout"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/attempt-2/execution/stdout"",
                ""backendStatus"": ""Done"",
                ""commandLine"": ""\ntouch null \npython3 $(which encode_task_overlap.py) \\\n\t/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/attempt-2/inputs/1836791510/0425-3-cetch1-flag_subsample1_R1.nodup.pr1_x_ctl_for_rep1.300K.regionPeak.gz /labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/attempt-2/inputs/-1827717161/0425-3-cetch1-flag_subsample1_R1.nodup.pr2_x_ctl_for_rep1.300K.regionPeak.gz /labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/attempt-2/inputs/1290460198/0425-3-cetch1-flag_subsample1_R1.nodup_x_ctl_for_rep1.300K.regionPeak.gz \\\n\t--prefix rep1-pr1_vs_rep1-pr2 \\\n\t--peak-type regionPeak \\\n\t--fraglen 200 \\\n\t--chrsz /labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/attempt-2/inputs/-723689832/hg38.chrom.sizes \\\n\t--blacklist /labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/attempt-2/inputs/-723689832/hg38.blacklist.bed.gz \\\n\t--nonamecheck \\\n\t--regex-bfilt-peak-chr-name 'chr[\\dXY]+' \\\n\t--ta /labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/attempt-2/inputs/-1113689129/0425-3-cetch1-flag_subsample1_R1.nodup.tagAlign.gz"",
                ""shardIndex"": 0,
                ""runtimeAttributes"": {
                    ""slurm_account"": ""aeurban"",
                    ""failOnStderr"": ""false"",
                    ""continueOnReturnCode"": ""0"",
                    ""maxRetries"": ""1"",
                    ""cpu"": ""1"",
                    ""time"": ""1"",
                    ""memory"": ""3.90625 GB""
                },
                ""callCaching"": {
                    ""allowResultReuse"": false,
                    ""effectiveCallCachingMode"": ""WriteCache"",
                    ""hashes"": {
                        ""output count"": ""1679091C5A880FAF6FB5E6087EB1B2DC"",
                        ""runtime attribute"": {
                            ""docker"": ""N/A"",
                            ""failOnStderr"": ""68934A3E9455FA72420237EB05902327"",
                            ""continueOnReturnCode"": ""CFCD208495D565EF66E7DFF9F98764DA""
                        },
                        ""output expression"": {
                            ""File overlap_peak"": ""5FE0ABD18E429C34B9371C7F78153E57"",
                            ""File frip_qc"": ""FFBDC0CF158D56A15AA0F87CB842D5C8"",
                            ""File bfilt_overlap_peak_hammock"": ""AAEDB2388B1A8885F60BDF99860308F2"",
                            ""File bfilt_overlap_peak_bb"": ""D2388B1E435478D195314A0DE2E9CEEB"",
                            ""File bfilt_overlap_peak_hammock_tbi"": ""F7AD80D930D3266E42DF62760BB4CA48"",
                            ""File bfilt_overlap_peak"": ""504E92495AEB2A7383BCE85ACF634E4A""
                        },
                        ""input count"": ""D3D9446802A44259755D38E6D163E820"",
                        ""backend name"": ""8C338F9EC0DF1BB3621803F2983039DA"",
                        ""command template"": ""B64FD519BA0800AF98DB11528D527648"",
                        ""input"": {
                            ""File peak2"": ""7e16b4ac12c4afe624c8ece83ff994a4"",
                            ""File blacklist"": ""4a58b07c400e8641dc3df79ad6fcf12c"",
                            ""Int fraglen"": ""3644A684F98EA8FE223C713B77189A77"",
                            ""File chrsz"": ""9b996e0d2eabf4f49ef31793c11d2f45"",
                            ""String regex_bfilt_peak_chr_name"": ""C742E46BA2D35AFA2B5C0BBCB7D31CE7"",
                            ""File peak_pooled"": ""44a9d024f599eaf7003cafd63a1a8574"",
                            ""File ta"": ""2db8b57a38e09aa03ad502953b1adc50"",
                            ""String prefix"": ""D3B9D7856D560D6435DB69A1320959A6"",
                            ""String peak_type"": ""CCC3DB10222D85D8F7B6CE07DD9D8E2F"",
                            ""File peak1"": ""b4ada56382dc83c1a00602df92c79ba5""
                        }
                    }
                },
                ""inputs"": {
                    ""blacklist"": ""/reference/ENCODE/pipeline_genome_data/hg38/hg38.blacklist.bed.gz"",
                    ""peak_type"": ""regionPeak"",
                    ""ta"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-bam2ta/shard-0/execution/glob-199637d3015dccbe277f621a18be9eb4/0425-3-cetch1-flag_subsample1_R1.nodup.tagAlign.gz"",
                    ""prefix"": ""rep1-pr1_vs_rep1-pr2"",
                    ""peak2"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-call_peak_pr2/shard-0/execution/glob-3c17d82667de5da0b56a7c17d88175d2/0425-3-cetch1-flag_subsample1_R1.nodup.pr2_x_ctl_for_rep1.300K.regionPeak.gz"",
                    ""fraglen"": 200,
                    ""chrsz"": ""/reference/ENCODE/pipeline_genome_data/hg38/hg38.chrom.sizes"",
                    ""peak1"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-call_peak_pr1/shard-0/execution/glob-3c17d82667de5da0b56a7c17d88175d2/0425-3-cetch1-flag_subsample1_R1.nodup.pr1_x_ctl_for_rep1.300K.regionPeak.gz"",
                    ""regex_bfilt_peak_chr_name"": ""chr[\\dXY]+"",
                    ""peak_pooled"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-call_peak/shard-0/execution/glob-3c17d82667de5da0b56a7c17d88175d2/0425-3-cetch1-flag_subsample1_R1.nodup_x_ctl_for_rep1.300K.regionPeak.gz""
                },
                ""returnCode"": 1,
                ""failures"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Job chip.overlap_pr:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
                    }
                ],
                ""jobId"": ""14894971"",
                ""backend"": ""slurm"",
                ""end"": ""2020-04-07T21:30:37.271Z"",
                ""stderr"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/attempt-2/execution/stderr"",
                ""callRoot"": ""/labs/dflev/siming/chipseq/encode_analysis_pipeline/chipseq_nano3_test5/chip/8b1e7e4e-e0a8-4328-9e2d-1b776b0b1b06/call-overlap_pr/shard-0/attempt-2"",
                ""attempt"": 2,
                ""executionEvents"": [
                    {
                        ""startTime"": ""2020-04-07T21:30:06.893Z"",
                        ""description"": ""RunningJob"",
                        ""endTime"": ""2020-04-07T21:30:37.271Z""
                    },
                    {
                        ""startTime"": ""2020-04-07T21:30:06.864Z"",
                        ""description"": ""WaitingForValueStore"",
                        ""endTime"": ""2020-04-07T21:30:06.876Z""
                    },
                    {
                        ""startTime"": ""2020-04-07T21:30:37.271Z"",
                        ""description"": ""UpdatingJobStore"",
                        ""endTime"": ""2020-04-07T21:30:37.271Z""
                    },
                    {
                        ""description"": ""RequestingExecutionToken"",
                        ""endTime"": ""2020-04-07T21:30:06.864Z"",
                        ""startTime"": ""2020-04-07T21:30:05.758Z""
                    },
                    {
                        ""startTime"": ""2020-04-07T21:30:05.758Z"",
                        ""endTime"": ""2020-04-07T21:30:05.758Z"",
                        ""description"": ""Pending""
                    },
                    {
                        ""startTime"": ""2020-04-07T21:30:06.876Z"",
                        ""description"": ""PreparingJob"",
                        ""endTime"": ""2020-04-07T21:30:06.893Z""
                    }
                ],
                ""start"": ""2020-04-07T21:30:05.757Z""
            }
        ],

",simingzhang,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/147
MDU6SXNzdWU1OTkzMzAyMzY=,sbatch: error: Batch job submission failed: Socket timed out on send/recv operation,CLOSED,2020-04-14T06:33:37Z,2020-05-29T15:46:27Z,2020-05-29T15:46:27Z,"Hi,

I am running this pipeline using slurm engine. However, when I try to submit more than one job, then some of the jobs fail with the error below. This could be because the job scheduler is getting swamped with jobs. Is there a way to control this in the pipeline?

_sbatch: error: Batch job submission failed: Socket timed out on send/recv operation._

Thanks,
Irtisha
",irtisha,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/150
MDU6SXNzdWU2MDQ2MDY4ODk=,Autouri module,CLOSED,2020-04-22T09:34:06Z,2020-05-07T08:23:35Z,2020-05-07T08:23:35Z,"I have installed the pipeline conda env on a new machine successfullly.

However I have run to this problem during the `caper init local` step

```
Traceback (most recent call last):
  File ""/home/fnyasimi/.conda/envs/encode-chip-seq-pipeline/bin/caper"", line 11, in <module>
    from caper.caper import main
  File ""/home/fnyasimi/.conda/envs/encode-chip-seq-pipeline/lib/python3.7/site-packages/caper/caper.py"", line 31, in <module>
    from autouri import AutoURI, AbsPath, GCSURI, S3URI, URIBase
ModuleNotFoundError: No module named 'autouri'
```
I figured out the module is missing I downloaded  it using `conda install autouri`

Ran again `caper init local` and it couldn't import logger, see error msg below;
```
Traceback (most recent call last):
  File ""/home/fnyasimi/.conda/envs/encode-chip-seq-pipeline/bin/caper"", line 11, in <module>
    from caper.caper import main
  File ""/home/fnyasimi/.conda/envs/encode-chip-seq-pipeline/lib/python3.7/site-packages/caper/caper.py"", line 32, in <module>
    from autouri import logger as autouri_logger
ImportError: cannot import name 'logger' from 'autouri' (/home/fnyasimi/.conda/envs/encode-chip-seq-pipeline/lib/python3.7/site-packages/autouri/__init__.py)
```
Kindly help out with the `Autouri` module",Fnyasimi,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/152
MDU6SXNzdWU2MTM4Njg0MDc=,Failure at xcor task,CLOSED,2020-05-07T08:22:56Z,2020-07-01T06:45:58Z,2020-05-29T15:48:49Z,"I am running the pipeline in parallel and I am getting a failure on `encode_task_xcor.py` with the error below. What might be the problem?
```
Traceback (most recent call last):
  File ""/home/ckibet/lustre/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/home/ckibet/lustre/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/home/ckibet/lustre/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/mnt/lustre/users/ckibet/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=149955, PGID=149955, RC=1
STDERR=/home/ckibet/lustre/miniconda3/envs/encode-chip-seq-pipeline/lib/R/bin/R: line 238: /home/ckibet/lustre/miniconda3/envs/encode-chip-seq-pipeline/lib/R/etc/ldpaths: No such file or directory
STDOUT=
```",Fnyasimi,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/156
MDU6SXNzdWU2MzAzOTc3NDI=,chip.align and chip.align_R1 tasks fail if input FASTQ(s) cannot be hard-linked,CLOSED,2020-06-03T23:27:10Z,2020-09-09T21:26:50Z,2020-09-09T21:26:40Z,"**Describe the bug**
I've included 2 JSON files below. The first is an example of a run that completed successfully, and the second is an example that failed. All my workflows matching the first succeeded, and all those matching the second failed. The pattern is that all (and only) the failing ones have `""chip.paired_end"": true` and a non-empty `""chip.fastqs_rep1_R2""`. 

**OS/Platform**
- OS/Platform: `SYS_TYPE=redhat_7_x86_64` `ARC=lx-amd64`
- Singularity version: 3.5.3-1.1.el7
- Pipeline version: v1.3.6
- Caper version: 0.7.0

**Caper configuration file**
```
backend=Local

tmp-dir=/path/to/tmpdir

cromwell=/path/to/software/caper-0.7.0/lib/cromwell-47.jar
womtool=/path/to/software/caper-0.7.0/lib/womtool-47.jar
```

**Input JSON file**
JSON for succeeding workflow:
```json
{
  ""chip.title"": ""H3K4me1_sample2"",
  ""chip.description"": ""H3K4me1 ChIP-Seq on sample2"",
  ""chip.pipeline_type"": ""histone"",
  ""chip.true_rep_only"": true,
  ""chip.aligner"": ""bwa"",
  ""chip.genome_tsv"": ""/path/to/hg19/encode-dcc/genome.tsv"",
  ""chip.paired_end"": false,
  ""chip.fastqs_rep1_R1"": [
    ""/path/to/data/ChIP-Seq/H3K4me1/sample2/reads.1.fastq.gz""
  ],
  ""chip.fastqs_rep1_R2"": [],
  ""chip.ctl_paired_end"": false,
  ""chip.ctl_fastqs_rep1_R1"": [
    ""/path/to/data/ChIP-Seq/H3K4me1/sample2/ctl.1.reads.1.fastq.gz""
  ],
  ""chip.ctl_fastqs_rep1_R2"": []
}
```

JSON for failing workflow:
```json
{
  ""chip.title"": ""H3K4me1_sample3"",
  ""chip.description"": ""H3K4me1 ChIP-Seq on sample3"",
  ""chip.pipeline_type"": ""histone"",
  ""chip.true_rep_only"": true,
  ""chip.aligner"": ""bwa"",
  ""chip.genome_tsv"": ""/path/to/hg19/encode-dcc/genome.tsv"",
  ""chip.paired_end"": true,
  ""chip.fastqs_rep1_R1"": [
    ""/path/to/data/ChIP-Seq/H3K4me1/sample3/mate1s.1.fastq.gz""
  ],
  ""chip.fastqs_rep1_R2"": [
    ""/path/to/data/ChIP-Seq/H3K4me1/sample3/mate2s.1.fastq.gz""
  ],
  ""chip.ctl_paired_end"": false,
  ""chip.ctl_fastqs_rep1_R1"": [
    ""/path/to/data/ChIP-Seq/H3K4me1/sample3/ctl.1.reads.1.fastq.gz""
  ],
  ""chip.ctl_fastqs_rep1_R2"": []
}
```

**Error log**
Output of `caper debug /path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip-1.3.6/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/metadata.json`:
```log
[Caper] troubleshooting 4b3f9fc8-4dbe-42d7-9332-a02f38e26084 ...
Found failures:
[
    {
        ""causedBy"": [
            {
                ""causedBy"": [],
                ""message"": ""Job chip.align_R1:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            },
            {
                ""causedBy"": [],
                ""message"": ""Job chip.align:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            }
        ],
        ""message"": ""Workflow failed""
    }
]

chip.align RetryableFailure. SHARD_IDX=0, RC=1, JOB_ID=5212, RUN_START=2020-06-02T16:33:06.275Z, RUN_END=2020-06-02T16:36:11.761Z, STDOUT=/path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/call-align/shard-0/execution/stdout, STDERR=/path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/call-align/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 105, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 93, in main
    merged_R1 = merge_fastqs(fastqs_R1, 'R1', args.out_dir)
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 72, in merge_fastqs
    run_shell_cmd(cmd)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=5572, PGID=5572, RC=1
STDERR=gzip: /path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/call-align/shard-0/inputs/-889636323/mate1s.1.fastq.gz: No such file or directory
STDOUT=


chip.align Failed. SHARD_IDX=0, RC=1, JOB_ID=9394, RUN_START=2020-06-02T16:36:12.257Z, RUN_END=2020-06-02T16:38:17.034Z, STDOUT=/path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/call-align/shard-0/attempt-2/execution/stdout, STDERR=/path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/call-align/shard-0/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 105, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 93, in main
    merged_R1 = merge_fastqs(fastqs_R1, 'R1', args.out_dir)
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 72, in merge_fastqs
    run_shell_cmd(cmd)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=10774, PGID=10774, RC=1
STDERR=gzip: /path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/call-align/shard-0/attempt-2/inputs/-889636323/mate1s.1.fastq.gz: No such file or directory
STDOUT=


chip.align_R1 RetryableFailure. SHARD_IDX=0, RC=1, JOB_ID=7312, RUN_START=2020-06-02T16:33:10.335Z, RUN_END=2020-06-02T16:35:41.037Z, STDOUT=/path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/call-align_R1/shard-0/execution/stdout, STDERR=/path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/call-align_R1/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 105, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 93, in main
    merged_R1 = merge_fastqs(fastqs_R1, 'R1', args.out_dir)
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 72, in merge_fastqs
    run_shell_cmd(cmd)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=8545, PGID=8545, RC=1
STDERR=gzip: /path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/call-align_R1/shard-0/inputs/-889636323/mate1s.1.fastq.gz: No such file or directory
STDOUT=


chip.align_R1 Failed. SHARD_IDX=0, RC=1, JOB_ID=24792, RUN_START=2020-06-02T16:35:42.261Z, RUN_END=2020-06-02T16:37:39.880Z, STDOUT=/path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/call-align_R1/shard-0/attempt-2/execution/stdout, STDERR=/path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/call-align_R1/shard-0/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 105, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 93, in main
    merged_R1 = merge_fastqs(fastqs_R1, 'R1', args.out_dir)
  File ""/software/chip-seq-pipeline/src/encode_task_merge_fastq.py"", line 72, in merge_fastqs
    run_shell_cmd(cmd)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=26087, PGID=26087, RC=1
STDERR=gzip: /path/to/data/ChIP-Seq/H3K4me1/sample3/tmp/chip/4b3f9fc8-4dbe-42d7-9332-a02f38e26084/call-align_R1/shard-0/attempt-2/inputs/-889636323/mate1s.1.fastq.gz: No such file or directory
STDOUT=


```
",rivison,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/159
MDU6SXNzdWU2MzE5MDQ4Nzg=,Chip.wdl has a limitation of 6 replicates ,CLOSED,2020-06-05T19:57:48Z,2020-09-09T21:27:23Z,2020-09-09T21:27:23Z,"Hi,

I am trying to run the ENCODE pipeline for 12 traits samples and 20 controls on HPC. The pipeline worked (I am using the piperunner.sh code and slurm-singularity as backend from IHEC /
integrative_analysis_chip), however I just have the outputs for 6 replicates (the 6 first described in the Input.json). I checked the chip.wdl file and in fact the pipeline has a ""restriction"" of 6 replicates:

fastqs
    Array[File] fastqs_rep1_R1 = [] # [merge_id]
    Array[File] fastqs_rep1_R2 = [] # do not define _R2 array if your sample is not paired end
    Array[File] fastqs_rep2_R1 = [] # do not define if you have a single replicate
    Array[File] fastqs_rep2_R2 = [] # do not define _R2 array if your sample is not paired end
    Array[File] fastqs_rep3_R1 = [] # do not define if you have <=2 replicates
    Array[File] fastqs_rep3_R2 = [] # do not define _R2 array if your sample is not paired end
    Array[File] fastqs_rep4_R1 = [] # do not define if you have <=3 replicates
    Array[File] fastqs_rep4_R2 = [] # do not define _R2 array if your sample is not paired end
    Array[File] fastqs_rep5_R1 = [] # do not define if you have <=4 replicates
    Array[File] fastqs_rep5_R2 = [] # do not define _R2 array if your sample is not paired end
    Array[File] fastqs_rep6_R1 = [] # do not define if you have <=5 replicates
    Array[File] fastqs_rep6_R2 = [] # do not define _R2 array if your sample is not paired end
    Array[File] ctl_fastqs_rep1_R1 = []     # [merge_id]
    Array[File] ctl_fastqs_rep1_R2 = [] # do not define _R2 array if your sample is not paired end
    Array[File] ctl_fastqs_rep2_R1 = [] # do not define if you have a single control
    Array[File] ctl_fastqs_rep2_R2 = []   # do not define _R2 array if your sample is not paired end
    Array[File] ctl_fastqs_rep3_R1 = [] # do not define if you have <=2 controls
    Array[File] ctl_fastqs_rep3_R2 = []   # do not define _R2 array if your sample is not paired end
    Array[File] ctl_fastqs_rep4_R1 = [] # do not define if you have <=3 controls
    Array[File] ctl_fastqs_rep4_R2 = []   # do not define _R2 array if your sample is not paired end
    Array[File] ctl_fastqs_rep5_R1 = [] # do not define if you have <=4 controls
    Array[File] ctl_fastqs_rep5_R2 = []   # do not define _R2 array if your sample is not paired end
    Array[File] ctl_fastqs_rep6_R1 = [] # do not define if you have <=5 controls
    Array[File] ctl_fastqs_rep6_R2 = []   # do not define _R2 array if your sample is not paired end

Is there any solution to run more than 6 replicates?

Thanks in advance for your help,
Gabriella Frosi",GFrosi,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/160
MDU6SXNzdWU2Mzg0NjYyOTE=,Deactivated link. ,CLOSED,2020-06-15T00:40:22Z,2020-07-07T21:13:34Z,2020-07-07T21:13:33Z,"[This page where you said](https://github.com/ENCODE-DCC/chip-seq-pipeline2/blob/master/docs/build_genome_database.md#how-to-build-genome-database-for-your-own-genome)
> Get a URL for a gzipped blacklist BED file for your genome. If you don't have one then skip this step. An example blacklist for hg38 is here.

the link is not working. ",abearab,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/161
MDU6SXNzdWU2Mzk5NjYyMzI=,Issue with install_conda_env.sh,CLOSED,2020-06-16T20:55:19Z,2020-06-17T00:52:03Z,2020-06-17T00:52:03Z,"**Describe the bug**
I'm trying to install the conda environment on Stanford Sherlock following the steps here (https://github.com/ENCODE-DCC/chip-seq-pipeline2/blob/e2a698d0dcc3d7b16ac8b9dc86d2f9097a35f0b8/docs/install_conda.md), and the script keeps failing at line 15 for some reason. I've followed the previous instructions correctly I think, so I'm not sure what to do. I have copied the error log below

**OS/Platform**
- OS/Platform: Stanford Sherlock
- Conda version: Conda 4.8.2
- Pipeline version: latest
- Caper version: [e.g. v0.6.0]

**Caper configuration file**
Paste contents of `~/.caper/default.conf`.

**Input JSON file**
Paste contents of your input JSON file.

**Error log**
conda 4.8.2
=== Installing pipeline's Conda environments ===
Collecting package metadata (current_repodata.json): done
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: | chip-seq-pipeline2/scripts/install_conda_env.sh: line 15: 60721 Killed                  conda create -n ${CONDA_ENV_PY3} --file ${REQ_TXT_PY3} -y -c defaults -c r -c bioconda -c conda-forge
```
$ caper debug [WORKFLOW_ID_OR_METADATA_JSON_FILE]
```
",mhayes8520,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/162
MDU6SXNzdWU2NDAwNjYxMzM=,Issue with build_genome_data.sh,CLOSED,2020-06-17T01:06:18Z,2020-09-09T21:41:34Z,2020-09-09T21:41:34Z,"**Describe the bug**
I'm stuck trying to build the genome data for sacCer3 since it's not supported already. The build_genome_data.sh script seems to be stuck here:

Entering Ebwt loop

and I think it is specifically stuck trying to build the .bt2 files of the bowtie2 index since they are not yet completed and haven't increased in file size in a long while. I'd say it's been stuck here for about and hour or so. Any ideas?

I also made sure to update the build_genome_data.sh script with the appropriate inputs (genome, chrM, and url to fa.gz file for saccer3)

Finally this was being run in an sdev node in sherlock with 8GB of memory and 2 hours of time

**OS/Platform**
- OS/Platform: Sherlock
- Conda version: 4.8.2
- Pipeline version: latest
- Caper version: [e.g. v0.6.0]

**Caper configuration file**
Paste contents of `~/.caper/default.conf`.

**Input JSON file**
Paste contents of your input JSON file.

**Error log**
Using parameters --bmax 1139729 --dcv 1024
  Doing ahead-of-time memory usage test
  Passed!  Constructing with these parameters: --bmax 1139729 --dcv 1024
Constructing suffix-array element generator
Building DifferenceCoverSample
  Building sPrime
  Building sPrimeOrder
  V-Sorting samples
  V-Sorting samples time: 00:00:01
  Allocating rank array
  Ranking v-sort output
  Ranking v-sort output time: 00:00:00
  Invoking Larsson-Sadakane on ranks
  Invoking Larsson-Sadakane on ranks time: 00:00:00
  Sanity-checking and returning
Building samples
Reserving space for 22 sample suffixes
Generating random suffixes
QSorting 22 sample offsets, eliminating duplicates
QSorting sample offsets, eliminating duplicates time: 00:00:00
Multikey QSorting 22 samples
  (Using difference cover)
  Multikey QSorting samples time: 00:00:00
Calculating bucket sizes
Splitting and merging
  Splitting and merging time: 00:00:00
Split 3, merged 9; iterating...
Splitting and merging
  Splitting and merging time: 00:00:00
Split 2, merged 3; iterating...
Splitting and merging
  Splitting and merging time: 00:00:00
Avg bucket size: 810473 (target: 1139728)
Converting suffix-array elements to index image
Allocating ftab, absorbFtab
Entering Ebwt loop
",mhayes8520,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/163
MDU6SXNzdWU2NDE4NDgyNDY=,error with install_conda_env.sh,CLOSED,2020-06-19T09:51:07Z,2020-06-23T09:36:20Z,2020-06-23T09:36:20Z,"Describe the bug
I'm essentially getting the same error as #162, except i'm on ubuntu 18:04. How should I fix this? It used to work fine before.

OS/Platform

OS/Platform: Ubuntu:18.04
Conda version: Conda 4.7.12
Pipeline version: latest
Caper version: [e.g. v0.6.0]
Caper configuration file
Paste contents of ~/.caper/default.conf.

Input JSON file
Paste contents of your input JSON file.

Error log
conda 4.7.12
=== Installing pipeline's Conda environments ===
Collecting package metadata (current_repodata.json): done
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
",ychsiao1,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/165
MDU6SXNzdWU2NDIxOTc3MTI=,pipeline gets stuck at filtering step,CLOSED,2020-06-19T20:15:26Z,2020-07-01T18:14:32Z,2020-07-01T17:58:51Z,"**Describe the bug**
The pipeline doesn't seem to be running to completion in sherlock using the command you've given here: https://github.com/ENCODE-DCC/caper. It stops at the call-filter step with the stderr.submit file saying: ""sbatch: error: Batch job submission failed: Requested node configuration is not available"". Attached are the command I ran, the slurm.out, and the stderr.submit files.
[caper_debug_error.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4806559/caper_debug_error.txt)

[sbatch_command.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4806551/sbatch_command.txt)
[slurm-2558098.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4806552/slurm-2558098.txt)
[stderr.submit.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4806553/stderr.submit.txt)



**OS/Platform**
- OS/Platform: Sherlock
- Conda version: Conda 4.8.2
- Pipeline version: latest
- Caper version: [e.g. v0.6.0]

**Caper configuration file**
backend=slurm
slurm-partition=normal

# DO NOT use /tmp here
# You can use $OAK or $SCRATCH storages here.
# Caper stores all important temp files and cached big data files here
# If not defined, Caper will make .caper_tmp/ on your local output directory
# which is defined by out-dir, --out-dir or $CWD
# Use a local absolute path here
tmp-dir=/scratch/users/mihayes

# IMPORTANT warning for Stanford Sherlock cluster
# ====================================================================
# DO NOT install any codes/executables
# (java, conda, python, caper, pipeline's WDL, pipeline's Conda env, ...) on $SCRATCH or $OAK.
# You will see Segmentation Fault errors.
# Install all executables on $HOME or $PI_HOME instead.
# It's STILL OKAY to read input data from and write outputs to $SCRATCH or $OAK.
# ====================================================================

cromwell=/home/users/mihayes/.caper/cromwell_jar/cromwell-47.jar
womtool=/home/users/mihayes/.caper/womtool_jar/womtool-47.jar

**Input JSON file**
{
    ""chip.title"" : ""Pho4_ChIP_NoPi"",
    ""chip.description"" : ""Zhou and O'Shea 2011 Pho4 ChIP-seq"",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""/oak/stanford/groups/pfordyce/data-workspace/repeats/genomes/saccer3/encode_chip_pipeline_genome/saccer3_flab.tsv"",

    ""chip.paired_end"" : false,
    ""chip.ctl_paired_end"" : false,

    ""chip.always_use_pooled_ctl"" : false,

    ""chip.fastqs_rep1_R1"" : [ ""/oak/stanford/groups/pfordyce/data-workspace/repeats/data/raw/Zhou_OShea_2011/Pho4_ChIP_NoPi_R1.fastq.gz"" ],
    ""chip.fastqs_rep2_R1"" : [ ""/oak/stanford/groups/pfordyce/data-workspace/repeats/data/raw/Zhou_OShea_2011/Pho4_ChIP_NoPi_R2.fastq.gz"" ],

    ""chip.ctl_fastqs_rep1_R1"" : [ ""/oak/stanford/groups/pfordyce/data-workspace/repeats/data/raw/Zhou_OShea_2011/Pho4_Input_NoPi.fastq.gz"" ],
    ""chip.ctl_fastqs_rep2_R1"" : [ ""/oak/stanford/groups/pfordyce/data-workspace/repeats/data/raw/Zhou_OShea_2011/Pho2_Input_NoPi.fastq.gz"" ],
    ""chip.ctl_fastqs_rep3_R1"" : [ ""/oak/stanford/groups/pfordyce/data-workspace/repeats/data/raw/Zhou_OShea_2011/Cbf1_Input_NoPi.fastq.gz"" ],

    ""chip.always_use_pooled_ctl"" : true,
    ""chip.ctl_depth_ratio"" : 1.2,

    ""chip.mapq_thresh"" : 255,
    ""chip.dup_marker"" : ""picard"",
    ""chip.no_dup_removal"" : false,

    ""chip.peak_caller"" : ""spp"",
    ""chip.cap_num_peak_macs2"" : 500000,
    ""chip.pval_thresh"" : 0.01,
    ""chip.fdr_thresh"" : 0.01,
    ""chip.idr_thresh"" : 0.05,
    ""chip.cap_num_peak_spp"" : 300000,

    ""chip.enable_jsd"" : true,
    ""chip.enable_gc_bias"" : true,
    ""chip.enable_count_signal_track"" : true
}

**Error log**
Caper automatically runs a troubleshooter for failed workflows. If it doesn't then get a `WORKFLOW_ID` of your failed workflow with `caper list` or directly use a `metadata.json` file on Caper's output directory.
```
$ caper debug [WORKFLOW_ID_OR_METADATA_JSON_FILE]
```
caper debug metadata.json didn't work and threw an error in the txt file attached. 

",mhayes8520,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/166
MDU6SXNzdWU2NDkyMDE1MTY=,Pipeline fails during gc_bias_calc,CLOSED,2020-07-01T18:38:36Z,2020-09-09T21:51:05Z,2020-09-09T21:51:04Z,"**Describe the bug**
During gc_bias calculation the pipeline fails because matplotlib can't be imported while running the python script for calculating gc bias. However, matplotlib is for sure installed in the encode-chip-seq-pipeline python environment, which is confusing.

Attached are the slurm.out and stderr files cd 
[stderr_200701.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4859701/stderr_200701.txt)
[slurm-3313658.out.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4859702/slurm-3313658.out.txt)

In a second test, the pipeline fails at a different point with the stderr saying:
FileNotFoundError: [Errno 2] File Pho4_ChIP_NoPi_R1.nodup.gc.txt does not exist: 'Pho4_ChIP_NoPi_R1.nodup.gc.txt'
Attached are the second slurm.out, stderr, and stdout files.

[slurm-3393083_2.out.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4859800/slurm-3393083_2.out.txt)
[stdout_2.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4859801/stdout_2.txt)
[stderr_2.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/4859802/stderr_2.txt)

It seems like the pipeline is somehow unstable, since it's reporting different errors?

**OS/Platform**
- OS/Platform: sherlock
- Conda version: latest
- Pipeline version: latest
- Caper version: latest

**Caper configuration file**
backend=slurm
slurm-partition=akundaje

# DO NOT use /tmp here
# You can use $OAK or $SCRATCH storages here.
# Caper stores all important temp files and cached big data files here
# If not defined, Caper will make .caper_tmp/ on your local output directory
# which is defined by out-dir, --out-dir or $CWD
# Use a local absolute path here
tmp-dir=/scratch/users/mihayes

# IMPORTANT warning for Stanford Sherlock cluster
# ====================================================================
# DO NOT install any codes/executables
# (java, conda, python, caper, pipeline's WDL, pipeline's Conda env, ...) on $SCRATCH or $OAK.
# You will see Segmentation Fault errors.
# Install all executables on $HOME or $PI_HOME instead.
# It's STILL OKAY to read input data from and write outputs to $SCRATCH or $OAK.
# ====================================================================

cromwell=/home/users/mihayes/.caper/cromwell_jar/cromwell-47.jar
womtool=/home/users/mihayes/.caper/womtool_jar/womtool-47.jar

**Input JSON file**
{
    ""chip.title"" : ""Pho4_ChIP_NoPi"",
    ""chip.description"" : ""Zhou and O'Shea 2011 Pho4 ChIP-seq"",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""/oak/stanford/groups/pfordyce/data-workspace/repeats/genomes/saccer3/encode_chip_pipeline_genome/saccer3_flab.tsv"",

    ""chip.paired_end"" : false,
    ""chip.ctl_paired_end"" : false,

    ""chip.fastqs_rep1_R1"" : [ ""/oak/stanford/groups/pfordyce/data-workspace/repeats/data/raw/Zhou_OShea_2011/Pho4_ChIP_NoPi_R1.fastq.gz"" ],
    ""chip.fastqs_rep2_R1"" : [ ""/oak/stanford/groups/pfordyce/data-workspace/repeats/data/raw/Zhou_OShea_2011/Pho4_ChIP_NoPi_R2.fastq.gz"" ],

    ""chip.ctl_fastqs_rep1_R1"" : [ ""/oak/stanford/groups/pfordyce/data-workspace/repeats/data/raw/Zhou_OShea_2011/Pho4_Input_NoPi.fastq.gz"" ],
    ""chip.ctl_fastqs_rep2_R1"" : [ ""/oak/stanford/groups/pfordyce/data-workspace/repeats/data/raw/Zhou_OShea_2011/Pho2_Input_NoPi.fastq.gz"" ],
    ""chip.ctl_fastqs_rep3_R1"" : [ ""/oak/stanford/groups/pfordyce/data-workspace/repeats/data/raw/Zhou_OShea_2011/Cbf1_Input_NoPi.fastq.gz"" ],

    ""chip.always_use_pooled_ctl"" : true,
    ""chip.ctl_depth_ratio"" : 1.2,

    ""chip.mapq_thresh"" : 30,
    ""chip.dup_marker"" : ""picard"",
    ""chip.no_dup_removal"" : false,

    ""chip.peak_caller"" : ""spp"",
    ""chip.cap_num_peak_macs2"" : 500000,
    ""chip.pval_thresh"" : 0.01,
    ""chip.fdr_thresh"" : 0.01,
    ""chip.idr_thresh"" : 0.05,
    ""chip.cap_num_peak_spp"" : 300000,
    
    ""chip.enable_jsd"" : true,
    ""chip.enable_gc_bias"" : true,
    ""chip.enable_count_signal_track"" : true,

    ""chip.xcor_trim_bp"" : 10
}


**Error log**
Caper automatically runs a troubleshooter for failed workflows. If it doesn't then get a `WORKFLOW_ID` of your failed workflow with `caper list` or directly use a `metadata.json` file on Caper's output directory.
```
$ caper debug [WORKFLOW_ID_OR_METADATA_JSON_FILE]
```",mhayes8520,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/168
MDU6SXNzdWU2NDk4OTQ0Nzg=,custom aligner option disappeared in v1.5.0,OPEN,2020-07-02T12:32:09Z,2020-07-28T08:47:33Z,,"Hi Jin,

it seems that the custom aligner/peak options have disappeared in the last two releases. May I ask, why this is the case?

We are investigating to which extend the pipeline can be used for other technologies as well (such as CUT&RUN). In this respect, we would like to try different bowtie parameters. Is there a chance to achieve this? 

Thank you very much
Best,
Florian",Flowdihow,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/170
MDU6SXNzdWU2NTQzMzI4Mjc=,Error: pipeline dependencies not found.,CLOSED,2020-07-09T20:37:31Z,2020-07-10T16:10:42Z,2020-07-10T16:08:40Z,"**Describe the bug**

This is when running the test json provided by the pipeline.
See result below:
```
 _**Error: pipeline dependencies not found.**
Conda users: Did you activate Conda environment (conda activate encode-chip-seq-pipeline)?
    Or did you install Conda and environment correctly (bash scripts/install_conda_env.sh)?
GCP/AWS/Docker users: Did you add --docker flag to Caper command line arg?
2020-07-09 16:16:07,120 cromwell-system-akka.dispatchers.engine-dispatcher-49 INFO  - WorkflowManagerActor WorkflowActor-d90ea650-f3f7-4b98-b041-f9534f23ea98 is in a terminal state: WorkflowFailedState
2020-07-09 16:16:16,422 cromwell-system-akka.dispatchers.engine-dispatcher-77 INFO  - SingleWorkflowRunnerActor workflow finished with status 'Failed'.
2020-07-09 16:16:17,604 cromwell-system-akka.dispatchers.engine-dispatcher-81 INFO  - SingleWorkflowRunnerActor writing metadata to /Users/christopherott/.caper_tmp/chip/20200709_161439_474499/metadata.json
2020-07-09 16:16:17,626  INFO  - Workflow polling stopped
2020-07-09 16:16:17,635  INFO  - 0 workflows released by cromid-7d896fb
2020-07-09 16:16:17,638  INFO  - Shutting down WorkflowStoreActor - Timeout = 5 seconds
2020-07-09 16:16:17,640  INFO  - Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds
2020-07-09 16:16:17,642  INFO  - Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds
2020-07-09 16:16:17,642  INFO  - JobExecutionTokenDispenser stopped
2020-07-09 16:16:17,642 cromwell-system-akka.dispatchers.engine-dispatcher-81 INFO  - Aborting all running workflows.
2020-07-09 16:16:17,643  INFO  - WorkflowStoreActor stopped
2020-07-09 16:16:17,645  INFO  - WorkflowLogCopyRouter stopped
2020-07-09 16:16:17,645  INFO  - Shutting down WorkflowManagerActor - Timeout = 3600 seconds
2020-07-09 16:16:17,646 cromwell-system-akka.dispatchers.engine-dispatcher-81 INFO  - WorkflowManagerActor All workflows finished
2020-07-09 16:16:17,646  INFO  - WorkflowManagerActor stopped
2020-07-09 16:16:17,899  INFO  - Connection pools shut down
2020-07-09 16:16:17,900  INFO  - Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds
2020-07-09 16:16:17,900  INFO  - Shutting down JobStoreActor - Timeout = 1800 seconds
2020-07-09 16:16:17,900  INFO  - Shutting down CallCacheWriteActor - Timeout = 1800 seconds
2020-07-09 16:16:17,900  INFO  - Shutting down ServiceRegistryActor - Timeout = 1800 seconds
2020-07-09 16:16:17,901  INFO  - Shutting down DockerHashActor - Timeout = 1800 seconds
2020-07-09 16:16:17,901  INFO  - Shutting down IoProxy - Timeout = 1800 seconds
2020-07-09 16:16:17,901  INFO  - SubWorkflowStoreActor stopped
2020-07-09 16:16:17,901  INFO  - CallCacheWriteActor Shutting down: 0 queued messages to process
2020-07-09 16:16:17,901  INFO  - JobStoreActor stopped
2020-07-09 16:16:17,901  INFO  - WriteMetadataActor Shutting down: 0 queued messages to process
2020-07-09 16:16:17,901  INFO  - CallCacheWriteActor stopped
2020-07-09 16:16:17,901  INFO  - KvWriteActor Shutting down: 0 queued messages to process
2020-07-09 16:16:17,902  INFO  - IoProxy stopped
2020-07-09 16:16:17,903  INFO  - ServiceRegistryActor stopped
2020-07-09 16:16:17,905  INFO  - DockerHashActor stopped
2020-07-09 16:16:17,928  INFO  - Database closed
2020-07-09 16:16:17,928  INFO  - Stream materializer shut down
2020-07-09 16:16:17,931  INFO  - WDL HTTP import resolver closed
**Workflow d90ea650-f3f7-4b98-b041-f9534f23ea98 transitioned to state Failed
2020-07-09 16:16:18,052|caper.caper|INFO| run: 1, d90ea650-f3f7-4b98-b041-f9534f23ea98, None**_
```

**OS/Platform**
- OS/Platform: [e.g. Ubuntu 16.04, Google Cloud, Stanford Sherlock/SCG cluster, ...]
- Conda version: 4.8.3
- Pipeline version: 
- Caper version: 0.8.2.1

**Caper configuration file**
Paste contents of `~/.caper/default.conf`.

```
# DO NOT use /tmp here
# Caper stores all important temp files and cached big data files here
# If not defined, Caper will make .caper_tmp/ on your local output directory
# which is defined by out-dir, --out-dir or $CWD
# Use a local absolute path here
tmp-dir=

cromwell=/Users/USERNAME/.caper/cromwell_jar/cromwell-47.jar
womtool=/Users/USERNAME/.caper/womtool_jar/womtool-47.jar
default.conf (END)
```

**Input JSON file**
The test JSON file provided by the pipeline

**Error log**
Caper automatically runs a troubleshooter for failed workflows. If it doesn't then get a `WORKFLOW_ID` of your failed workflow with `caper list` or directly use a `metadata.json` file on Caper's output directory.
```
$ caper debug [WORKFLOW_ID_OR_METADATA_JSON_FILE]

$ caper debug metadata.json
```
**Response:**

```
2020-07-09 16:33:41,207|caper.cromwell_rest_api|ERROR| Help: cannot connect to server. Check if server is dead or still spinning up.
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connection.py"", line 160, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File ""/usr/local/lib/python3.7/site-packages/urllib3/util/connection.py"", line 84, in create_connection
    raise err
  File ""/usr/local/lib/python3.7/site-packages/urllib3/util/connection.py"", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py"", line 677, in urlopen
    chunked=chunked,
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py"", line 392, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File ""/usr/local/Cellar/python/3.7.8/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py"", line 1262, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File ""/usr/local/Cellar/python/3.7.8/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py"", line 1308, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File ""/usr/local/Cellar/python/3.7.8/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py"", line 1257, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File ""/usr/local/Cellar/python/3.7.8/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py"", line 1028, in _send_output
    self.send(msg)
  File ""/usr/local/Cellar/python/3.7.8/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py"", line 968, in send
    self.connect()
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connection.py"", line 187, in connect
    conn = self._new_conn()
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connection.py"", line 172, in _new_conn
    self, ""Failed to establish a new connection: %s"" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x10c144450>: Failed to establish a new connection: [Errno 61] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/requests/adapters.py"", line 449, in send
    timeout=timeout
  File ""/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py"", line 725, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File ""/usr/local/lib/python3.7/site-packages/urllib3/util/retry.py"", line 439, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /api/workflows/v1/query?additionalQueryResultFields=labels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10c144450>: Failed to establish a new connection: [Errno 61] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/caper/cromwell_rest_api.py"", line 256, in __request_get
    headers={'accept': 'application/json'})
  File ""/usr/local/lib/python3.7/site-packages/requests/api.py"", line 76, in get
    return request('get', url, params=params, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/requests/api.py"", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/requests/sessions.py"", line 530, in request
    resp = self.send(prep, **send_kwargs)
  File ""/usr/local/lib/python3.7/site-packages/requests/sessions.py"", line 643, in send
    r = adapter.send(request, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/requests/adapters.py"", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /api/workflows/v1/query?additionalQueryResultFields=labels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10c144450>: 
```



",Barbarak17,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/172
MDU6SXNzdWU2NTY2MTU5MjM=,Workflow failure: Failed to evaluate input 'tmp_fastqs',CLOSED,2020-07-14T13:33:15Z,2020-07-22T14:29:47Z,2020-07-22T14:29:47Z,"**Describe the bug**
Not sure if the issue here was a runtime error. In the metadata.json says that reason is ""transpose requires all collections have the same size.""
Have you seen a similar error before?

**OS/Platform**
- OS/Platform: Linux: gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-16)
- Conda version: 4.8.3
- Pipeline version: the latest
- Caper version: 0.8.2.1

**Caper configuration file**
Paste contents of `~/.caper/default.conf`.

**Input JSON file**
```
{
    ""chip.pipeline_type"" : ""tf"",
    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v1/hg19_caper.tsv"",
    ""chip.fastqs_rep1_R1"" : [""/PHShome/bk724/chip-seq-pipeline2/example_input_json/data/JB0009_H3K27ac_R1.fastq.gz""
    ],
    ""chip.fastqs_rep1_R2"" : [""/PHShome/bk724/chip-seq-pipeline2/example_input_json/data/JB0009_H3K27ac_R2.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R1"" : [""/PHShome/bk724/chip-seq-pipeline2/example_input_json/data/JB0009_input_R1.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep2_R1"" : [""/PHShome/bk724/chip-seq-pipeline2/example_input_json/data/JB0009_input_R2.fastq.gz""
    ],
    ""chip.paired_end"" : true,
    ""chip.title"" : ""H3K27ac"",
    ""chip.description"" : ""CLLepigenome_for_dbGAP""
}
```
**Error log**
```
submission"": ""2020-07-13T20:12:33.594Z"",
    ""status"": ""Failed"",
    ""failures"": [
        {
            ""causedBy"": [
                {
                    ""causedBy"": [
                        {
                            ""causedBy"": [],
                            ""message"": ""Failed to evaluate input 'tmp_fastqs' (reason 1 of 1): transpose requires all collections have the same size""
                        }
                    ],
                    ""message"": ""Call input and runtime attributes evaluation failed for align_ctl""
                },
                {
                    ""causedBy"": [
                        {
                            ""causedBy"": [],
                            ""message"": ""Failed to evaluate input 'tmp_fastqs' (reason 1 of 1): transpose requires all collections have the same size""
                        }
                    ],
                    ""message"": ""Call input and runtime attributes evaluation failed for align_ctl""
                }
            ],
            ""message"": ""Workflow failed""
        }
    ],
    ""end"": ""2020-07-14T02:04:24.456Z"",
    ""start"": ""2020-07-13T20:12:33.727Z""
}
```
$ caper debug [WORKFLOW_ID_OR_METADATA_JSON_FILE]
```
020-07-14 09:09:15,933|caper.cromwell_rest_api|ERROR| Help: cannot connect to server. Check if server is dead or still spinning up.
Traceback (most recent call last):
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connection.py"", line 160, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/util/connection.py"", line 84, in create_connection
    raise err
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/util/connection.py"", line 74, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 677, in urlopen
    chunked=chunked,
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 392, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/http/client.py"", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/http/client.py"", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/http/client.py"", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/http/client.py"", line 1026, in _send_output
    self.send(msg)
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/http/client.py"", line 964, in send
    self.connect()
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connection.py"", line 187, in connect
    conn = self._new_conn()
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connection.py"", line 172, in _new_conn
    self, ""Failed to establish a new connection: %s"" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fa4ed18c7b8>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/requests/adapters.py"", line 449, in send
    timeout=timeout
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 725, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/util/retry.py"", line 439, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /api/workflows/v1/query?additionalQueryResultFields=labels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa4ed18c7b8>: Failed to establish a new connection: [Errno 111] Connection refused',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cromwell_rest_api.py"", line 256, in __request_get
    headers={'accept': 'application/json'})
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/requests/api.py"", line 76, in get
    return request('get', url, params=params, **kwargs)
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/requests/api.py"", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/requests/sessions.py"", line 530, in request
    resp = self.send(prep, **send_kwargs)
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/requests/sessions.py"", line 643, in send
    r = adapter.send(request, **kwargs)
  File ""/PHShome/bk724/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/requests/adapters.py"", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8000): Max retries exceeded with url: /api/workflows/v1/query?additionalQueryResultFields=labels (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa4ed18c7b8>: Failed to establish a new connection: [Errno 111] Connection refused',))
```",Barbarak17,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/173
MDU6SXNzdWU2NTY2Mjk4OTc=,Warning occurred when running the qc2tsv under python3.7,OPEN,2020-07-14T13:51:50Z,2020-07-20T22:33:08Z,,"**Describe the bug**
A clear and concise description of what the problem is.

**OS/Platform**
- OS/Platform: 14.04.5 LTS (GNU/Linux 4.4.0-75-generic x86_64).
- Conda version: conda 4.4.4.
- Pipeline version: newest.
- Caper version: 0.8.2.1.
- Python version: **3.7.6.**

When I run the command `qc2tsv  ./template.json > test.tsv` , the system returns the warning message,
/home/user/.conda/envs/user/lib/python3.7/site-packages/qc2tsv/qc2tsv.py:78: **FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead
  df = pandas.io.json.json_normalize(jsons, sep=sep)**

![image](https://user-images.githubusercontent.com/57667010/87433763-49565500-c61c-11ea-8649-e84d5fd9b7f5.png)


",rongxinzh,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/174
MDU6SXNzdWU2NjM5NTkxMzU=,"Pipeline issues with sed, split,  & libopenblas.dylib - mac users (solved)",CLOSED,2020-07-22T18:21:44Z,2020-09-09T22:47:26Z,2020-08-03T13:43:00Z,"**Describe the bug**
Pipeline fails at chip.spr & chip.xcor, potentially related to shuf command. Using a mac terminal.
Error logs:

chip.spr
```
Traceback (most recent call last):
  File ""/Users/barbarak/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_spr.py"", line 143, in <module>
    main()
  File ""/Users/barbarak/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_spr.py"", line 130, in main
    ta_pr1, ta_pr2 = spr_se(args.ta, args.out_dir)
  File ""/Users/barbarak/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_spr.py"", line 54, in spr_se
    run_shell_cmd(cmd1)
  File ""/Users/barbarak/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=82727, PGID=82727, RC=64
STDERR=split: illegal option -- d
usage: split [-a sufflen] [-b byte_count] [-l line_count] [-p pattern]
             [file [prefix]]
/bin/bash: line 1: shuf: command not found
STDOUT=
```

chip.xcor
```
Traceback (most recent call last):
  File ""/Users/barbarak/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/Users/barbarak/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_xcor.py"", line 138, in main
    args.mito_chr_name, args.out_dir)
  File ""/Users/barbarak/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_genomic.py"", line 254, in subsample_ta_se
    run_shell_cmd(cmd)
  File ""/Users/barbarak/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=82749, PGID=82749, RC=127
STDERR=/bin/bash: line 1: shuf: command not found
STDOUT=
```

**Caper configuration file**
```
backend=local

# DO NOT use /tmp here
# Caper stores all important temp files and cached big data files here
# If not defined, Caper will make .caper_tmp/ on your local output directory
# which is defined by out-dir, --out-dir or $CWD
# Use a local absolute path here
tmp-dir=chiptestlocal

cromwell=/Users/barbarak/.caper/cromwell_jar/cromwell-47.jar
womtool=/Users/barbarak/.caper/womtool_jar/womtool-47.jar
```

**Input JSON file**
```
{
    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"": ""bowtie2"",
    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v1/hg19_caper.tsv"",
    ""chip.fastqs_rep1_R1"" : [""/Users/barbarak/Desktop/Barbara/data1/JB0009_H3K27ac_R1.fastq.gz""
    ],
    ""chip.fastqs_rep1_R2"": [],
    ""chip.ctl_fastqs_rep1_R1"" : [""/Users/barbarak/Desktop/Barbara//data1/JB0009_input_R1.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R2"": [],
    ""chip.paired_end"" : false,
    ""chip.ctl_paired_end"": false,
    ""chip.title"" : ""H3K27ac"",
    ""chip.description"" : ""CLLepigenome_for_dbGAP by the Ott lab""
}

**Error log**
Caper automatically runs a troubleshooter for failed workflows. If it doesn't then get a `WORKFLOW_ID` of your failed workflow with `caper list` or directly use a `metadata.json` file on Caper's output directory.
```
$ caper debug [WORKFLOW_ID_OR_METADATA_JSON_FILE]
```
  ""submission"": ""2020-07-22T14:51:29.232Z"",
    ""status"": ""Failed"",
    ""failures"": [
        {
            ""message"": ""Workflow failed"",
            ""causedBy"": [
                {
                    ""causedBy"": [],
                    ""message"": ""Job chip.spr:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
                },
                {
                    ""message"": ""Job chip.xcor:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                    ""causedBy"": []
                }
            ]
        }
    ],
    ""end"": ""2020-07-22T17:59:23.701Z"",
    ""start"": ""2020-07-22T14:51:29.326Z""
```
",Barbarak17,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/177
MDU6SXNzdWU2NzM3NDUyMTA=,Gecode version?,CLOSED,2020-08-05T18:13:01Z,2020-08-11T13:29:35Z,2020-08-11T13:29:35Z,"https://github.com/ENCODE-DCC/chip-seq-pipeline2/blob/master/scripts/download_genome_data.sh#L79
TSS=""https://storage.googleapis.com/encode-pipeline-genome-data/hg38/ataqc/hg38_gencode_tss_unique.bed.gz""

https://github.com/ENCODE-DCC/chip-seq-pipeline2/blob/master/scripts/download_genome_data.sh#L116
TSS=""https://storage.googleapis.com/encode-pipeline-genome-data/mm10/ataqc/mm10_gencode_tss_unique.bed.gz""

I will analyze RNAseq and ChIPseq together. I prefer to use the same version of GTF file for RNAseq and ChIPseq. The TSS info was derived from the GNCODE GTF. Which versions were used for hg38 and mm10? Thank you!",dzhaobio,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/179
MDU6SXNzdWU2NzY5NjIxOTc=,Pipeline stalled at filter step for one replicate,CLOSED,2020-08-11T15:16:07Z,2022-02-09T00:22:17Z,2022-02-09T00:22:16Z,"**Describe the bug**
I have three replicates (with three input) to run chip-seq pipeline2. Only 2 replicates finished filter step and one replicate was stalled at filtered mark dups step (on nodup.bam were generated). One of two that finished filter step went forward for xcor. (please see [log file](https://www.dropbox.com/s/2lu325xgzrkf14g/workflow.72b37ba0-ce7a-45f0-9642-826bcec80519.log?dl=0)).

I tried the pipeline with the same config a few days ago. The pipeline stalled at the same step for days (before I killed it).  The `caper debug` report ""Found a heartbeat file but it has been expired"" which I don't know which step is time-out. 

Also, I am wondering whether there is a way to resume the pipeline by feeding workflow id? Re-running the pipeline from the scratch with error like this is very time-consuming.


**OS/Platform**
- OS/Platform: CentOS Linux 7 (Core) [SGE]
- Conda version: conda 4.6.14.
- Pipeline version: [v1.4.0.1]
- Caper version: 1.1.0

**Caper configuration file**
backend=sge
sge-pe=smp

# DO NOT use /tmp here
# Caper stores all important temp files and cached big data files here
# If not defined, Caper will make .caper_tmp/ on your local output directory
# which is defined by out-dir, --out-dir or $CWD
# Use a local absolute path here
tmp-dir=/mnt/isilon/sfgi/suc1/tmp

cromwell=/home/suc1/.caper/cromwell_jar/cromwell-47.jar
womtool=/home/suc1/.caper/womtool_jar/womtool-47.jar

**Input JSON file**
{
""chip.title"" : ""Treg"",
""chip.description"" : ""This is an input JSON for paired-end sample."",
""chip.pipeline_type"" : ""tf"",
""chip.aligner"" : ""bowtie2"",
""chip.align_only"" : false,
""chip.true_rep_only"" : true,
""chip.genome_tsv"" : ""/mnt/isilon/sfgi/programs/chip-seq-pipeline2/genome_db/mm9.v2/mm9.tsv"",
""chip.paired_end"" : true,

""chip.fastqs_rep1_R1"" : [ ""/mnt/isilon/sfgi/suc1/analyses/wells/chipSeq/Treg_Ikaros/encode/Treg/IK_WT_Treg_CHIP_1_R1.fastq.gz""],
""chip.fastqs_rep1_R2"" : [ ""/mnt/isilon/sfgi/suc1/analyses/wells/chipSeq/Treg_Ikaros/encode/Treg/IK_WT_Treg_CHIP_1_R2.fastq.gz""],
""chip.fastqs_rep2_R1"" : [ ""/mnt/isilon/sfgi/suc1/analyses/wells/chipSeq/Treg_Ikaros/encode/Treg/IK_WT_Treg_CHIP_2_R1.fastq.gz""],
""chip.fastqs_rep2_R2"" : [ ""/mnt/isilon/sfgi/suc1/analyses/wells/chipSeq/Treg_Ikaros/encode/Treg/IK_WT_Treg_CHIP_2_R2.fastq.gz""],
""chip.fastqs_rep3_R1"" : [ ""/mnt/isilon/sfgi/suc1/analyses/wells/chipSeq/Treg_Ikaros/encode/Treg/IK_WT_Treg_CHIP_3_R1.fastq.gz""],
""chip.fastqs_rep3_R2"" : [ ""/mnt/isilon/sfgi/suc1/analyses/wells/chipSeq/Treg_Ikaros/encode/Treg/IK_WT_Treg_CHIP_3_R2.fastq.gz""],
""chip.ctl_paired_end"" : true,
""chip.ctl_fastqs_rep1_R1"" : [ ""/mnt/isilon/sfgi/suc1/analyses/wells/chipSeq/Treg_Ikaros/encode/Treg/WT_Treg_input_1_R1.fastq.gz""],
""chip.ctl_fastqs_rep1_R2"" : [ ""/mnt/isilon/sfgi/suc1/analyses/wells/chipSeq/Treg_Ikaros/encode/Treg/WT_Treg_input_1_R2.fastq.gz""],
""chip.ctl_fastqs_rep2_R1"" : [ ""/mnt/isilon/sfgi/suc1/analyses/wells/chipSeq/Treg_Ikaros/encode/Treg/WT_Treg_input_2_R1.fastq.gz""],
""chip.ctl_fastqs_rep2_R2"" : [ ""/mnt/isilon/sfgi/suc1/analyses/wells/chipSeq/Treg_Ikaros/encode/Treg/WT_Treg_input_2_R2.fastq.gz""],
""chip.ctl_fastqs_rep3_R1"" : [ ""/mnt/isilon/sfgi/suc1/analyses/wells/chipSeq/Treg_Ikaros/encode/Treg/WT_Treg_input_3_R1.fastq.gz""],
""chip.ctl_fastqs_rep3_R2"" : [ ""/mnt/isilon/sfgi/suc1/analyses/wells/chipSeq/Treg_Ikaros/encode/Treg/WT_Treg_input_3_R2.fastq.gz""],
""chip.crop_length"" : 0,

""chip.mapq_thresh"" : 30,
""chip.dup_marker"" : ""picard"",
""chip.no_dup_removal"" : false,

""chip.subsample_reads"" : 0,
""chip.ctl_subsample_reads"" : 0,
""chip.xcor_subsample_reads"" : 15000000,

""chip.xcor_trim_bp"" : 50,
""chip.use_filt_pe_ta_for_xcor"" : false,

""chip.always_use_pooled_ctl"" : false,
""chip.ctl_depth_ratio"" : 1.2,

""chip.peak_caller"" : null,
""chip.cap_num_peak_macs2"" : 500000,
""chip.pval_thresh"" : 0.01,
""chip.fdr_thresh"" : 0.01,
""chip.idr_thresh"" : 0.05,
""chip.cap_num_peak_spp"" : 300000,

""chip.enable_jsd"" : true,
""chip.enable_gc_bias"" : true,
""chip.enable_count_signal_track"" : false,

""chip.filter_chrs"" : [],

""chip.align_cpu"" : 4,
""chip.align_mem_mb"" : 20000,
""chip.align_time_hr"" : 48,

""chip.filter_cpu"" : 2,
""chip.filter_mem_mb"" : 20000,
""chip.filter_time_hr"" : 24,

""chip.bam2ta_cpu"" : 2,
""chip.bam2ta_mem_mb"" : 10000,
""chip.bam2ta_time_hr"" : 6,

""chip.spr_mem_mb"" : 16000,

""chip.jsd_cpu"" : 2,
""chip.jsd_mem_mb"" : 12000,
""chip.jsd_time_hr"" : 6,

""chip.xcor_cpu"" : 2,
""chip.xcor_mem_mb"" : 16000,
""chip.xcor_time_hr"" : 24,

""chip.call_peak_cpu"" : 2,
""chip.call_peak_mem_mb"" : 16000,
""chip.call_peak_time_hr"" : 72,

""chip.macs2_signal_track_mem_mb"" : 16000,
""chip.macs2_signal_track_time_hr"" : 24,

""chip.gc_bias_picard_java_heap"" : ""10G""
}


**Error log**
Caper automatically runs a troubleshooter for failed workflows. If it doesn't then get a `WORKFLOW_ID` of your failed workflow with `caper list` or directly use a `metadata.json` file on Caper's output directory.
```
$ caper debug 72b37ba0

2020-08-11 11:01:38,897|caper.server_heartbeat|ERROR| Found a heartbeat file but it has been expired (> timeout). ~/.caper/default_server_heartbeat
Traceback (most recent call last):
  File ""/mnt/isilon/sfgi/programs/miniconda3/envs/encode-chip-seq-pipeline/bin/caper"", line 13, in <module>
    main()
  File ""/mnt/isilon/sfgi/programs/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cli.py"", line 504, in main
    client(parsed_args)
  File ""/mnt/isilon/sfgi/programs/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cli.py"", line 269, in client
    subcmd_troubleshoot(c, args)
  File ""/mnt/isilon/sfgi/programs/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cli.py"", line 454, in subcmd_troubleshoot
    wf_ids_or_labels=args.wf_id_or_label, embed_subworkflow=True
  File ""/mnt/isilon/sfgi/programs/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/caper_client.py"", line 129, in metadata
    embed_subworkflow=embed_subworkflow,
  File ""/mnt/isilon/sfgi/programs/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cromwell_rest_api.py"", line 144, in get_metadata
    workflows = self.find(workflow_ids, labels)
  File ""/mnt/isilon/sfgi/programs/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cromwell_rest_api.py"", line 226, in find
    CromwellRestAPI.ENDPOINT_WORKFLOWS, params=CromwellRestAPI.PARAMS_WORKFLOWS
  File ""/mnt/isilon/sfgi/programs/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cromwell_rest_api.py"", line 299, in __request_get
    ) from None
Exception: Failed to connect to Cromwell server. req=GET, url=http://localhost:8000/api/workflows/v1/query
```",sckinta,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/180
MDU6SXNzdWU2OTMwODgwOTE=,pipeline fails with example json,CLOSED,2020-09-04T11:53:44Z,2020-09-08T16:57:40Z,2020-09-04T19:11:28Z,"Hi, 
I have just cloned the pipeline and tried to run it with the sample data json https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI_subsampled_chr19_only.json
but I get the following error: 
```
2020-09-04 13:40:36,300|caper.cromwell|INFO| Validating WDL/inputs/imports with Womtool...
2020-09-04 13:40:41,938|caper.cromwell|INFO| Womtool validation passed.
2020-09-04 13:40:41,938|caper.caper_runner|INFO| launching run: wdl=/home/users/ngs/software/encode/chip-seq-pipeline2/chip.wdl, inputs=/home/users/ngs/software/encode/
tmp/home/users/ngs/DNAnalysis/Chip_test_ENCSR000DYI/ENCSR000DYI_subsampled_chr19_only_fromat.local.json, backend_conf=/home/users/ngs/software/encode/tmp/chip/20200904_
134032_625284/backend.conf
2020-09-04 13:40:54,960|caper.cromwell_workflow_monitor|INFO| Workflow: id=c031f880-6509-40ba-a7e4-65309ea3b7d5, status=Submitted
2020-09-04 13:40:55,032|caper.cromwell_workflow_monitor|INFO| Workflow: id=c031f880-6509-40ba-a7e4-65309ea3b7d5, status=Running
2020-09-04 13:40:58,956|caper.cromwell_workflow_monitor|INFO| Workflow: id=c031f880-6509-40ba-a7e4-65309ea3b7d5, status=Failed
2020-09-04 13:41:04,941|caper.cromwell_metadata|WARNING| Failed to write metadata file. workflowRoot not found. wf_id=c031f880-6509-40ba-a7e4-65309ea3b7d5
2020-09-04 13:41:04,941|caper.cromwell|INFO| Workflow failed. Auto-troubleshooting...
* Started troubleshooting workflow: id=c031f880-6509-40ba-a7e4-65309ea3b7d5, status=Failed
* Found failures JSON object.
[
    {
        ""causedBy"": [
            {
                ""causedBy"": [],
                ""message"": ""Task raise_exception has an invalid runtime attribute memory = !! NOT FOUND !!""
            },
            {
                ""causedBy"": [],
                ""message"": ""Task raise_exception has an invalid runtime attribute memory = !! NOT FOUND !!""
            },
            {
                ""message"": ""Task raise_exception has an invalid runtime attribute memory = !! NOT FOUND !!"",
                ""causedBy"": []
            },
            {
                ""message"": ""Task raise_exception has an invalid runtime attribute memory = !! NOT FOUND !!"",
                ""causedBy"": []
            },
            {
                ""causedBy"": [],
                ""message"": ""Task raise_exception has an invalid runtime attribute memory = !! NOT FOUND !!""
            },
            {
                ""causedBy"": [],
                ""message"": ""Task raise_exception has an invalid runtime attribute memory = !! NOT FOUND !!""
            },
            {
                ""causedBy"": [],
                ""message"": ""Task raise_exception has an invalid runtime attribute memory = !! NOT FOUND !!""
            },
            {
                ""causedBy"": [],
                ""message"": ""Task raise_exception has an invalid runtime attribute memory = !! NOT FOUND !!""
            }
        ],
        ""message"": ""Runtime validation failed""
    }
]
* Recursively finding failures in calls (tasks)...
2020-09-04 13:41:04,942|caper.nb_subproc_thread|ERROR| Subprocess failed. returncode=1
2020-09-04 13:41:04,942|caper.cli|ERROR| Check stdout/stderr in /home/ngstree/ngs/DNAnalysis/Chip_test_ENCSR000DYI/cromwell.out
```
can you please help? 
Best,

Margherita

",atreeneedsaforest,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/182
MDU6SXNzdWU2OTgzNDM0NTk=,TEST TICKET,CLOSED,2020-09-10T18:35:55Z,2020-09-10T20:19:05Z,2020-09-10T20:19:05Z,"**Describe the bug**
A clear and concise description of what the problem is.

**OS/Platform**
- OS/Platform: [e.g. Ubuntu 16.04, Google Cloud, Stanford Sherlock/SCG cluster, ...]
- Conda version: If you used Conda (`$ conda --version`).
- Pipeline version: [e.g. v1.3.3]
- Caper version: [e.g. v0.6.0]

**Caper configuration file**
Paste contents of `~/.caper/default.conf`.

**Input JSON file**
Paste contents of your input JSON file.

**Error log**
Caper automatically runs a troubleshooter for failed workflows. If it doesn't then get a `WORKFLOW_ID` of your failed workflow with `caper list` or directly use a `metadata.json` file on Caper's output directory.
```
$ caper debug [WORKFLOW_ID_OR_METADATA_JSON_FILE]
```
",leepc12,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/183
MDU6SXNzdWU2OTgzOTExMjc=,TEST_TICKET_2,CLOSED,2020-09-10T19:19:39Z,2020-09-10T20:19:15Z,2020-09-10T20:19:15Z,"## **Describe the bug**
A clear and concise description of what the problem is.

## **OS/Platform**
- OS/Platform: [e.g. Ubuntu 18.04, Google Cloud, Stanford Sherlock/SCG cluster, ...]
- Conda version: If you used Conda (`$ conda --version`).
- Pipeline version: [e.g. v1.6.0]
- Caper version: [e.g. v1.2.0]

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
PASTE CAPER CONF CONTENTS HERE
```

## **Input JSON file**
Paste contents of your input JSON file.
```json
PASTE INPUT JSON CONTENTS HERE
```

## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
```
PASTE TROUBLESHOOTING RESULT HERE
```
",leepc12,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/184
MDU6SXNzdWU2OTg0MzI2NTI=,TEST_CHIP,CLOSED,2020-09-10T20:02:37Z,2020-09-10T20:18:53Z,2020-09-10T20:18:53Z,"## **Describe the bug**
A clear and concise description of what the problem is.

## **OS/Platform**
- OS/Platform: [e.g. Ubuntu 18.04, Google Cloud, Stanford Sherlock/SCG cluster, ...]
- Conda version: If you used Conda (`$ conda --version`).
- Pipeline version: [e.g. v1.6.0]
- Caper version: [e.g. v1.2.0]

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
PASTE CAPER CONF CONTENTS HERE
```

## **Input JSON file**
Paste contents of your input JSON file.
```json
PASTE INPUT JSON CONTENTS HERE
```

## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
```
PASTE TROUBLESHOOTING RESULT HERE
```
",leepc12,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/185
MDU6SXNzdWU3MDIyMjE5Mjg=,Replicates can be combined to get the FDR and P-values ,CLOSED,2020-09-15T20:05:34Z,2020-09-17T13:10:57Z,2020-09-17T13:10:57Z,"Hello,

I am new to ChIPSeq analysis and hoping you could help guide me with the following question.

I wanted to combine replicates to get a ranking list of regions according to p values and FDR. I have 3 samples (with 3 biological replicates each) & 3 input samples. ChIPSeq pipeline was run in histone mode. I get a directory ""call-reproducibility_overlap"", is it valid to use overlap.conservative_peak.narrowPeak.gz OR overlap.optimal_peak.narrowPeak.gz as the final combined ranking list? 

I came across IDR but this runs only in TF mode and it seeks to compares a pair of ranked lists of regions/peaks and assigns values that reflect its reproducibility. Why is IDR run only in mode and not the other? I came across [this tutorial](https://hbctraining.github.io/Intro-to-ChIPseq/lessons/07_handling-replicates-idr.html) which uses MACS2 peaks and thereafter runs IDR on them. 

```
# following is the line i found in chip.wdl which restricts it to tf mode.
Boolean enable_idr = pipeline_type=='tf' # enable_idr
```

Is IDR run in TF mode similar to the reproducibility_overlap run in histone mode?

Thank you,
Asma",asmariyaz23,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/187
MDU6SXNzdWU3MDM1NzUzNTg=,IDR analysis in tf mode not running,CLOSED,2020-09-17T13:11:41Z,2020-09-18T13:35:08Z,2020-09-18T13:35:08Z,"Hello,

I am running the pipeline in tf mode. I don't get a directory called ""call-idr"" in the output directory. How do I know if the pipeline has set ""enable-idr"" to true? I am using the latest version of wdl provided. 

Thank you,
Asma",asmariyaz23,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/188
MDU6SXNzdWU3MDc0MDk1Mjk=,croo,CLOSED,2020-09-23T14:19:57Z,2022-02-09T00:29:18Z,2022-02-09T00:29:18Z,"There was no error in the previous operation. The error reported in today's operation is as follows. I think it is a croo problem, but I don't know how to solve it.
Traceback (most recent call last):
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connection.py"", line 157, in _new_conn
    (self._dns_host, self.port), self.timeout, **extra_kw
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/util/connection.py"", line 84, in create_connection
    raise err
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/util/connection.py"", line 74, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 672, in urlopen
    chunked=chunked,
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 376, in _make_request
    self._validate_conn(conn)
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 994, in _validate_conn
    conn.connect()
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connection.py"", line 300, in connect
    conn = self._new_conn()
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connection.py"", line 169, in _new_conn
    self, ""Failed to establish a new connection: %s"" % e
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x2b716b0ce828>: Failed to establish a new connection: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/requests/adapters.py"", line 449, in send
    timeout=timeout
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 720, in urlopen
    method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/urllib3/util/retry.py"", line 436, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /encode-pipeline-output-definition/chip.croo.json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2b716b0ce828>: Failed to establish a new connection: [Errno 110] Connection timed out',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/bin/croo"", line 14, in <module>
    main()
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/croo/cli.py"", line 218, in main
    no_checksum=args['no_checksum'])
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/croo/croo.py"", line 85, in __init__
    f = AutoURI(out_def_json).localize_on(self._tmp_dir)
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/autouri/autouri.py"", line 341, in localize_on
    loc_prefix=loc_prefix, return_flag=return_flag, depth=depth)
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/autouri/autouri.py"", line 541, in localize
    src_uri.cp(dest_uri=loc_uri, make_md5_file=make_md5_file)
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/autouri/autouri.py"", line 298, in cp
    if not self._cp(dest_uri=d):
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/autouri/httpurl.py"", line 133, in _cp
    headers=requests.utils.default_headers())
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/requests/api.py"", line 76, in get
    return request('get', url, params=params, **kwargs)
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/requests/api.py"", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/requests/sessions.py"", line 530, in request
    resp = self.send(prep, **send_kwargs)
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/requests/sessions.py"", line 643, in send
    r = adapter.send(request, **kwargs)
  File ""/software/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/requests/adapters.py"", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='storage.googleapis.com', port=443): Max retries exceeded with url: /encode-pipeline-output-definition/chip.croo.json (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x2b716b0ce828>: Failed to establish a new connection: [Errno 110] Connection timed out',))
",User-yx,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/189
MDU6SXNzdWU3MTMxNDgyNzE=,GCP Caper Server Failed & Stopped,CLOSED,2020-10-01T20:06:46Z,2022-02-09T00:31:24Z,2022-02-09T00:31:24Z,"Even though it was started in screen mode, the caper server I was using lost it's heartbeat and stopped running after about 20 hours with the following error message: Failed to retrieve metadata from Cromwell server

Is it possible to resume the failed GCP workflows that were affected by this?  

gcp-out-dir=gs://bucket
gcp-call-caching-dup-strat=reference
local-loc-dir=/home/user/.caper_tmp

",kirbyziegler,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/190
MDU6SXNzdWU3MTU4MTAxNzk=,read_genome_tsv function has fixed maxRetries parameter,CLOSED,2020-10-06T15:49:03Z,2022-02-09T21:07:04Z,2022-02-09T21:07:04Z,"## **Describe the bug**
The function read_genome_tsv occassionally runs into a time out when reading files, especially if the general cluster node IO load is heavy (sge cluster). 

Of course this is not a problem of the pipeline itself, however, in such a case it would be nice to leverage cromwell's retry function. Unfortunately the corresponding option is hardcoded and set to 0:

https://github.com/ENCODE-DCC/chip-seq-pipeline2/blob/f3ab828c7358ce36dcc6db51c4f1c8c3ae9c4927/chip.wdl#L2919

Is there a chance to change this to parameter which can be specified (or simply increase: ""maxRetries:2(or whatever))

Thank you very much!
Best,
Florian

",Flowdihow,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/191
MDU6SXNzdWU3MjA2OTUyOTA=,regionPeak files generated in tf mode,CLOSED,2020-10-13T19:05:41Z,2020-10-27T15:11:10Z,2020-10-27T15:11:10Z,"Hello,

I ran ChIP-Seq ENCODE pipeline in ""tf"" mode for paired end datasets (has 3 biological replicates and 1 Input sample). Here is the input JSON

```
{
    ""chip.title"" : ""BZW1 (paired-end)"",
    ""chip.description"" : ""BZW1"",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""/cluster/tools/data/commondata/ENCODE/chip-seq/hg38/hg38.tsv"",

    ""chip.paired_end"" : true,
    ""chip.ctl_paired_end"" : true,
    ""chip.always_use_pooled_ctl"" : true,

    ""chip.align_bowtie2_mem_factor"": 0.50,
    ""chip.align_cpu"": 10,
    ""chip.filter_cpu"": 6,
    ""chip.filter_mem_factor"": 0.6,
    ""chip.bam2ta_cpu"": 4,
    ""chip.bam2ta_mem_factor"": 0.5,
    ""chip.spr_mem_factor"":5.5,
    ""chip.jsd_cpu"":6,
    ""chip.jsd_mem_factor"":0.3,
    ""chip.xcor_cpu"":4,
    ""chip.xcor_mem_factor"":2.0,
    ""chip.call_peak_cpu"":14,
    ""chip.call_peak_spp_mem_factor"":30,

    ""chip.fastqs_rep1_R1"" : [ ""BZW1-1_S9_L001_R1_001.fastq.gz"" ],
    ""chip.fastqs_rep1_R2"" : [ ""BZW1-1_S9_L001_R2_001.fastq.gz"" ],
    ""chip.fastqs_rep2_R1"" : [ ""BZW1-2_S10_L001_R1_001.fastq.gz"" ],
    ""chip.fastqs_rep2_R2"" : [ ""BZW1-2_S10_L001_R2_001.fastq.gz"" ],
    ""chip.fastqs_rep3_R1"" : [ ""BZW1-3_S11_L001_R1_001.fastq.gz"" ],
    ""chip.fastqs_rep3_R2"" : [ ""BZW1-3_S11_L001_R2_001.fastq.gz"" ],

    ""chip.ctl_fastqs_rep1_R1"" : [ ""Input-BZW1_S12_L001_R1_001.fastq.gz""],
    ""chip.ctl_fastqs_rep1_R2"" : [ ""Input-BZW1_S12_L001_R2_001.fastq.gz""]
}
```

Could you please help me understand why did I get regionPeak files as opposed to narrowPeak files as generated in histone mode? According to the [format documentation ](https://genome.ucsc.edu/FAQ/FAQformat.html#format13)for regionPeak or broadPeak the resultant BED file is supposed to have 9 columns however the file I see in the ""call-reproducibility_idr"" directory, idr.conservative_peak.regionPeak.gz has 10 columns 
[idr.conservative_peak10.regionPeak.gz](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/5373548/idr.conservative_peak10.regionPeak.gz). I am confused as to what I have is a regionPeak or narrowPeak file currently? 

Thank you for you help!
Asma",asmariyaz23,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/192
MDU6SXNzdWU3MjgzODk4OTk=,Analysis of broad marks,CLOSED,2020-10-23T17:24:56Z,2020-10-23T17:50:05Z,2020-10-23T17:50:05Z,"Hi,
Is there a way to specify that the input histone mark is a broad mark and therefore get the broad peaks and gapped peaks bed files?

",emattei,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/193
MDU6SXNzdWU3MjkyNjIxMDQ=,Renaming output folder and files ,CLOSED,2020-10-26T05:53:19Z,2022-02-09T21:16:11Z,2022-02-09T21:16:11Z,"The current naming convention for the output folder and file is not very indicative. It is hard to identify which files for each runs, particularly when there are multiple runs. I can't find anything in the documentation regarding specifying the output name. I suggest to add a parameter to an input_json to allow changing the output name. It would make things easier. ",sfpacman,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/194
MDU6SXNzdWU3MzIzOTUyMTg=,Conda env installation on a custom folder,CLOSED,2020-10-29T15:04:11Z,2020-11-02T14:06:59Z,2020-11-02T14:06:59Z,"I am setting up a pipeline on a cluster but I have a challenge installing the environment on a custom path which is visible to all nodes on the hpc.
 
The reason I am doing this is because the environments in the base conda directory are not visible to all the nodes hence the need to install on a custom path which is visible to all computing nodes.

I have tried using `--prefix` but I didn't manage to set up the pipeline configurations.

Kindly help me set up tweak the installation scripts to set up the environments in a custom path and do all the necessary configurations.

Ps: I don't have sudo rights to the cluster",Fnyasimi,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/196
MDU6SXNzdWU3MzQ2MDQxNzA=,"lib/python3.6/configparser.py"", line 846, in items  d.update(self._sections[section]) KeyError: 'defaults'",CLOSED,2020-11-02T15:35:00Z,2022-02-09T21:17:46Z,2022-02-09T21:17:46Z,"I was trying to run IDR pipeline . I could run this pipeline one time successfully my second run is coming up with following error. 
i am  running this pipeline as 
caper run /lower_bay/home/bony.dekumar/chip-seq-pipeline2/chip.wdl -i mediator_6_json 
## **Describe the bug**
Traceback (most recent call last):
  File ""/lower_bay/home/bony.dekumar/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/configparser.py"", line 846, in items
    d.update(self._sections[section])
KeyError: 'defaults'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/lower_bay/home/bony.dekumar/miniconda3/envs/encode-chip-seq-pipeline/bin/caper"", line 13, in <module>
    main()
  File ""/lower_bay/home/bony.dekumar/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cli.py"", line 481, in main
    parser, _ = get_parser_and_defaults()
  File ""/lower_bay/home/bony.dekumar/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/caper_args.py"", line 699, in get_parser_and_defaults
    conf_key_map=CAPER_1_0_0_PARAM_KEY_NAME_CHANGE,
  File ""/lower_bay/home/bony.dekumar/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/arg_tool.py"", line 120, in update_parsers_defaults_with_conf
    no_strip_quote=no_strip_quote,
  File ""/lower_bay/home/bony.dekumar/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/arg_tool.py"", line 47, in read_from_conf
    d_ = dict(config.items(conf_section))
  File ""/lower_bay/home/bony.dekumar/miniconda3/envs/encode-chip-seq-pipeline/lib/python3.6/configparser.py"", line 849, in items
    raise NoSectionError(section)
configparser.NoSectionError: No section: 'defaults'

## **OS/Platform**
- OS/Platform: [e.g. Ubuntu 18.04, Google Cloud, Stanford Sherlock/SCG cluster, ...]
- Conda version: If you used Conda (`$ conda --version`).
- Pipeline version: [e.g. v1.6.0]
- Caper version: [e.g. v1.2.0]

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
PASTE CAPER CONF CONTENTS HERE
```

## **Input JSON file**
Paste contents of your input JSON file.
```json
{
    ""chip.title"" : ""Example (paired-end)"",
    ""chip.description"" : ""This is an template input JSON for paired-end sample."",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""/lower_bay/home/bony.dekumar/chip-seq-pipeline2/mm10.tsv"",

    ""chip.paired_end"" : false,
    ""chip.ctl_paired_end"" : false,

    ""chip.always_use_pooled_ctl"" : true,

    ""chip.fastqs_rep1_R1"" : [ ""s_1_1_CATTTT.fastq.gz"", ""s_2_1_CATTTT.fastq.gz"" ],
    ""chip.fastqs_rep2_R1"" : [ ""s_1_1_CCAACA.fastq.gz"", ""s_2_1_CCAACA.fastq.gz"" ],

    ""chip.ctl_fastqs_rep1_R1"" : [ ""s_1_1_CTATAC.fastq.gz"",""s_2_1_CTATAC.fastq.gz"" ],
    ""chip.ctl_fastqs_rep2_R1"" : [ ""s_1_1_CTCAGA.fastq.gz"",""s_2_1_CTCAGA.fastq.gz"" ]
}

```

## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
```
PASTE TROUBLESHOOTING RESULT HERE
```
",bony45,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/198
MDU6SXNzdWU3NDYwOTAxNzQ=,Failed to connect cromwell server.. unsupported backened: sge,OPEN,2020-11-18T22:46:25Z,2020-11-19T00:02:20Z,,"## **Describe the bug**
I am trying to run caper for chip-seq pipeline for Transcription factor. The dry run shows that caper run is fine. But when trying with the example file or my own input.json file it is giving me error failed to connect Cromwell server and in crowwell.out it shows unsupported backend. SGE mode starts a job properly, then fails, I guess there is certain issue with configuration with the age for Cromwell. May be we have to add some options in order to work correctly in our cluster. I tried it in mac and My colleague did try on window platform as well. and report the same error. i went through all the documentation and tried to fix with different ways but somehow it is not running. It has been since 3 weeks that we are stuck in this. 

## **OS/Platform**
- OS/Platform: [e.g. MacOS-catalina (10.15.7),she]. 
- module load anaconda2/4.3.1 
-$ conda --version = conda 4.6.7.
- Pipeline version: [e.g. v1.6.0]
- Caper version: [e.g. v1.1.0]

## **Caper configuration file**
Paste contents of `/home/ambey/.caper/default.conf`.
```
backend=sge
sge-pe=openmp

# Hashing strategy for call-caching (3 choices)
# This parameter is for local (local/slurm/sge/pbs) backend only.
# This is important for call-caching,
# which means re-using outputs from previous/failed workflows.
# Cache will miss if different strategy is used.
# ""file"" method has been default for all old versions of Caper<1.0.
# ""path+modtime"" is a new default for Caper>=1.0,
#   file: use md5sum hash (slow).
#   path: use path.
#   path+modtime: use path and modification time.
local-hash-strat=path+modtime

# Local directory for localized files and Cromwell's intermediate files
# If not defined, Caper will make .caper_tmp/ on local-out-dir or CWD.
# /tmp is not recommended here since Caper store all localized data files
# on this directory (e.g. input FASTQs defined as URLs in input JSON).
local-loc-dir=/home/ambey/mnt/Genoma/amedina/ambey/CAPER/.caper_tmp
local_out_dir=/home/ambey/mnt/Genoma/amedina/ambey/CAPER/caper_out

```
## **Input JSON file**
```
I am trying the example json file: chip-seq-pipeline2/example_input_json/ENCSR000DYI_subsampled_chr19_only.json
{
    ""chip.pipeline_type"" : ""tf"",
    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v3/hg38_chr19_chrM.tsv"",
    ""chip.fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep1.subsampled.25.fastq.gz""
    ],
    ""chip.fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep2.subsampled.20.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl1.subsampled.25.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl2.subsampled.25.fastq.gz""
    ],
    ""chip.paired_end"" : false,
    ""chip.title"" : ""ENCSR000DYI (subsampled 1/25, chr19_chrM only)"",
    ""chip.description"" : ""CEBPB ChIP-seq on human A549 produced by the Snyder lab""
}
```
## **Command used**
```
$ qlogin
$ module load anaconda2/4.3.1
$ source activate encode-chip-seq-pipeline
$ caper init sge
# modified `/home/ambey/.caper/default.conf`
$ caper run /mnt/Genoma/amedina/ambey/chip-seq-pipeline2/chip.wdl -i /mnt/Genoma/amedina/ambey/chip-seq-pipeline2/example_input_json/ENCSR000DYI_subsampled_chr19_only.json
```
## **Troubleshooting result**
```
$ caper troubleshoot

2020-11-18 15:05:33,428|caper.server_heartbeat|ERROR| Found a heartbeat file but it has been expired (> timeout). ~/.caper/default_server_heartbeat
Traceback (most recent call last):
  File ""/cm/shared/apps/anaconda2/4.3.1/envs/encode-chip-seq-pipeline/bin/caper"", line 13, in <module>
    main()
  File ""/cm/shared/apps/anaconda2/4.3.1/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cli.py"", line 504, in main
    client(parsed_args)
  File ""/cm/shared/apps/anaconda2/4.3.1/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cli.py"", line 269, in client
    subcmd_troubleshoot(c, args)
  File ""/cm/shared/apps/anaconda2/4.3.1/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cli.py"", line 454, in subcmd_troubleshoot
    wf_ids_or_labels=args.wf_id_or_label, embed_subworkflow=True
  File ""/cm/shared/apps/anaconda2/4.3.1/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/caper_client.py"", line 129, in metadata
    embed_subworkflow=embed_subworkflow,
  File ""/cm/shared/apps/anaconda2/4.3.1/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cromwell_rest_api.py"", line 144, in get_metadata
    workflows = self.find(workflow_ids, labels)
  File ""/cm/shared/apps/anaconda2/4.3.1/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cromwell_rest_api.py"", line 226, in find
    CromwellRestAPI.ENDPOINT_WORKFLOWS, params=CromwellRestAPI.PARAMS_WORKFLOWS
  File ""/cm/shared/apps/anaconda2/4.3.1/envs/encode-chip-seq-pipeline/lib/python3.6/site-packages/caper/cromwell_rest_api.py"", line 299, in __request_get
    ) from None
Exception: Failed to connect to Cromwell server. req=GET, url=http://localhost:8000/api/workflows/v1/query
```
[cromwell.out.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/5563126/cromwell.out.txt)
",ambeys,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/200
MDU6SXNzdWU3NTg2MjAzNjA=,MACS2 Peaks Cap,CLOSED,2020-12-07T15:40:39Z,2020-12-07T16:28:34Z,2020-12-07T16:28:34Z,"I had a question about the number of peaks taken from `MACS2`. 
Why is the number of peaks capped at 500,000 for this pipeline vs 300,000 for the `ENCODE-DCC ATAC-Seq Pipeline`?

It would be very useful for me to know since I plan to analyze ChIP-Seq and ATAC-Seq data from the same biological samples soon. 
Please let me know if this makes sense. ",YogiOnBioinformatics,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/202
MDU6SXNzdWU3NjE2MzE0NTI=,BUG: dim(X) must have a positive length,OPEN,2020-12-10T21:28:49Z,2021-03-11T23:26:00Z,,"## **Describe the bug**
Task `xcor` fails with specific issue: 
```
Error in apply(ac, 2, function(x) sum(x * avw)) :
  dim(X) must have a positive length
```

## **OS/Platform**
- OS/Platform: `Debian GNU/Linux 8 (jessie)`
- Pipeline version: `1.3.6`

## **Input JSON file**
```
{
    ""chip.title"": ""P2L7S6_H3K4me3_ChIP"",
    ""chip.description"": """",
    ""chip.pipeline_type"": ""histone"",
    ""chip.paired_end"": false,
    ""chip.ctl_paired_end"": false,
    ""chip.genome_tsv"": ""/some_path/hg38/hg38.tsv"",
    ""chip.fastqs_rep1_R1"": [
        ""/absolute_path/201007Fra_D20-3991_NA_1.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R1"": [
        ""/absolute_path/201007Fra_D20-3986_NA_1.fastq.gz""
    ]
}
```

## **Troubleshooting result**
Paste troubleshooting result.
```
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/software/chip-seq-pipeline/src/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 319, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=1926106, PGID=1926106, RC=1
STDERR=Loading required package: caTools
Error in apply(ac, 2, function(x) sum(x * avw)) :
  dim(X) must have a positive length
Calls: get.binding.characteristics -> lapply -> FUN -> apply
Execution halted
STDOUT=################
ChIP data: 201007Fra_D20-3991_NA_1.trim_50bp.filt.no_chrM.15M.tagAlign.gz
Control data: NA
strandshift(min): -500
strandshift(step): 5
strandshift(max) 1500
user-defined peak shift NA
exclusion(min): -500
exclusion(max): 100
num parallel nodes: 2
FDR threshold: 0.01
NumPeaks Threshold: NA
Output Directory: .
narrowPeak output file name: NA
regionPeak output file name: NA
Rdata filename: NA
plot pdf filename: 201007Fra_D20-3991_NA_1.trim_50bp.filt.no_chrM.15M.cc.plot.pdf
result filename: 201007Fra_D20-3991_NA_1.trim_50bp.filt.no_chrM.15M.cc.qc
Overwrite files?: TRUE

Decompressing ChIP file
Reading ChIP tagAlign/BAM file 201007Fra_D20-3991_NA_1.trim_50bp.filt.no_chrM.15M.tagAlign.gz
opened /pool/data/cromwell-aals/cromwell-executions/chip/b744d0a2-c764-40a4-a952-fc43d2d0a1ee/call-xcor/shard-0/tmp.2813919d/RtmpwmIuJ2/201007Fra_D20-3991_NA_1.trim_50bp.filt.no_chrM.15M.tagAlign1d63dc4f08563d
done. read 16 fragments
ChIP data read length 40
[1] TRUE
Calculating peak characteristics
ln: failed to access '*.cc.plot.pdf': No such file or directory
ln: failed to access '*.cc.plot.png': No such file or directory
ln: failed to access '*.cc.qc': No such file or directory
ln: failed to access '*.cc.fraglen.txt': No such file or directory

```
",YogiOnBioinformatics,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/203
MDU6SXNzdWU3NjI4MDAwMDU=,Peak calling parameter chip.fdr_thresh never changes from default 0.01,OPEN,2020-12-11T19:31:03Z,2023-10-17T19:58:38Z,,"## **Describe the bug**
I'm running the transcription factor chipseq pipeline. I have one sample out of 16 that failed the pipeline. I'm trying to determine whether the sample may be poor or whether I can recover some peaks by loosening the fdr threshold from the default 0.01 it was originally run at. The pipeline failed with the following error:
```Exception: File is empty (20200622_Chip_H1_S8_L001_R1_001.merged.nodup.pr2_x_20200622_Chip_G1_S7_L001_R1_001.merged.nodup.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?``` 

I went back into my input json and added a chip.fdr_thresh of 0.05 and re-ran the pipeline. I received the exact same results. I re-ran again with fdr of 0.2 in an attempt to sanity check and received the same results. For the other samples that successfully made it through the pipeline the html output at fdr of 0.05 and 0.2 never changes, the number of peaks and everything remains the same as what originally was called at the default fdr level. Along those same lines the number of raw peaks called (capped at 300000) says ""at an fdr of 0.01"" in the html in every case, even when I specifically changed the fdr parameter in the input json. I then went into the metadata.json and grepped for fdr_thresh and confirmed the fdr threshold was the value I passed in the input json but the results are always at a fdr of 0.01 regardless of what the input json and metadata.json has. Down below in the troubleshooting section is the output from grepping the metadata.json for ""fdr_thresh"".

## **OS/Platform**
- OS/Platform: Ubuntu 16.04 
- Conda version: conda 4.8.3
- Pipeline version: [e.g. v1.6.0]
- Caper version: [e.g. v1.2.0]

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
backend=local

# Hashing strategy for call-caching (3 choices)
# This parameter is for local (local/slurm/sge/pbs) backend only.
# This is important for call-caching,
# which means re-using outputs from previous/failed workflows.
# Cache will miss if different strategy is used.
# ""file"" method has been default for all old versions of Caper<1.0.
# ""path+modtime"" is a new default for Caper>=1.0,
#   file: use md5sum hash (slow).
#   path: use path.
#   path+modtime: use path and modification time.
local-hash-strat=path+modtime

# Local directory for localized files and Cromwell's intermediate files
# If not defined, Caper will make .caper_tmp/ on local-out-dir or CWD.
# /tmp is not recommended here since Caper store all localized data files
# on this directory (e.g. input FASTQs defined as URLs in input JSON).
local-loc-dir=/home/ubuntu/20200730_KRISTINA_CHIPSEQ/tmp-caper-cache

cromwell=/home/ubuntu/.caper/cromwell_jar/cromwell-52.jar
womtool=/home/ubuntu/.caper/womtool_jar/womtool-52.jar
```

## **Input JSON file**
Paste contents of your input JSON file.
```
{
    ""chip.title"" : ""Kristina CHIPSeq (paired-end) H1 vs G1"",
    ""chip.description"" : ""Chip H1 vs Chip G1 as control"",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/software/chip-seq-pipeline2/mm10.tsv"",

    ""chip.paired_end"" : true,
    ""chip.ctl_paired_end"" : true,

    ""chip.always_use_pooled_ctl"" : true,
    ""chip.fdr_thresh"" : 0.05,

    ""chip.fastqs_rep1_R1"" : [ ""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_H1/20200622_Chip_H1_S8_L001_R1_001.fastq.gz"", ""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_H1/20200622_Chip_H1_S8_L002_R1_001.fastq.gz"" ],
    ""chip.fastqs_rep1_R2"" : [ ""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_H1/20200622_Chip_H1_S8_L001_R2_001.fastq.gz"", ""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_H1/20200622_Chip_H1_S8_L002_R2_001.fastq.gz"" ],
    
    ""chip.ctl_fastqs_rep1_R1"" : [ ""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_G1/20200622_Chip_G1_S7_L001_R1_001.fastq.gz"", ""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_G1/20200622_Chip_G1_S7_L002_R1_001.fastq.gz"" ],
    ""chip.ctl_fastqs_rep1_R2"" : [ ""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_G1/20200622_Chip_G1_S7_L001_R2_001.fastq.gz"", ""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_G1/20200622_Chip_G1_S7_L002_R2_001.fastq.gz"" ]
        
}
```
## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result. 
```

```

Since the pipeline failing isn't exactly the problem right now, below are contents of metadata.json confirming changed fdr_thresh value.
```
""inputs"": ""{\n    \""chip.title\"" : \""Kristina CHIPSeq (paired-end) H1 vs G1\"",\n    \""chip.description\"" : \""Chip H1 vs Chip G1 as control\"",\n\n    \""chip.pipeline_type\"" : \""tf\"",\n    \""chip.aligner\"" : \""bowtie2\"",\n    \""chip.align_only\"" : false,\n    \""chip.true_rep_only\"" : false,\n\n    \""chip.genome_tsv\"" : \""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/software/chip-seq-pipeline2/mm10.tsv\"",\n\n    \""chip.paired_end\"" : true,\n    \""chip.ctl_paired_end\"" : true,\n\n    \""chip.always_use_pooled_ctl\"" : true,\n    \""chip.fdr_thresh\"" : 0.05,\n\n    \""chip.fastqs_rep1_R1\"" : [ \""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_H1/20200622_Chip_H1_S8_L001_R1_001.fastq.gz\"", \""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_H1/20200622_Chip_H1_S8_L002_R1_001.fastq.gz\"" ],\n    \""chip.fastqs_rep1_R2\"" : [ \""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_H1/20200622_Chip_H1_S8_L001_R2_001.fastq.gz\"", \""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_H1/20200622_Chip_H1_S8_L002_R2_001.fastq.gz\"" ],\n    \n    \""chip.ctl_fastqs_rep1_R1\"" : [ \""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_G1/20200622_Chip_G1_S7_L001_R1_001.fastq.gz\"", \""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_G1/20200622_Chip_G1_S7_L002_R1_001.fastq.gz\"" ],\n    \""chip.ctl_fastqs_rep1_R2\"" : [ \""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_G1/20200622_Chip_G1_S7_L001_R2_001.fastq.gz\"", \""/home/ubuntu/20200730_KRISTINA_CHIPSEQ/FastQs/Young-ChIP-Seq/Chip_G1/20200622_Chip_G1_S7_L002_R2_001.fastq.gz\"" ]\n    \n}\n"",
                            ""Float fdr_thresh"": ""B14399CBAAC6DA4B5B733B483106383F"",
                    ""fdr_thresh"": 0.05,
                            ""Float fdr_thresh"": ""B14399CBAAC6DA4B5B733B483106383F"",
                    ""fdr_thresh"": 0.05,
                            ""Float fdr_thresh"": ""B14399CBAAC6DA4B5B733B483106383F"",
                    ""fdr_thresh"": 0.05,
                            ""Float fdr_thresh"": ""B14399CBAAC6DA4B5B733B483106383F"",
                    ""fdr_thresh"": 0.05,
        ""fdr_thresh"": 0.05,

```
",alexadowdell,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/204
MDU6SXNzdWU3NzQ5NjEwMzI=,STDERR=zcat: can't stat: error on a MacOSX computer,OPEN,2020-12-27T01:55:41Z,2020-12-27T01:55:41Z,,"The chip-set-pipeline2 fails because the pipeline is unable to merge the fastq.gz files using cat.  I have run it several times - on my Mac desktop and the pipeline always fails at the same point.  I am a bit of a newbie at this type of analysis and am using

a Mac OS Big Sur
with conda 4.9.2
Pipeline version v1.6.1 (download da few days ago)
with caper 1.4.2

I tried adding coreutils to my path, /usr/local/opt/coreutils/libexec/gnubin but that didn't work either.

Is there a relatively simple workaround for the zcat function that I can utilise to allow me to use the pipeline?


Many thanks,

Debbie

",DebbieCG,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/205
MDU6SXNzdWU3Nzc1NzI2ODA=,macs2 q-value,OPEN,2021-01-03T04:45:24Z,2021-01-15T22:43:50Z,,"When I use macs2 call peak, can I set the q-value instead of the p-value in this pipeline?",User-yx,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/206
MDU6SXNzdWU3ODgxNTA1ODY=,broad peak,OPEN,2021-01-18T10:41:18Z,2021-01-20T21:07:06Z,,"When I use macs2 call peak, can I set ""--broad"" parameters in this pipeline?",User-yx,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/207
MDU6SXNzdWU4MDE4NTI0NTU=,Problem when installing pipeline's Conda environment,CLOSED,2021-02-05T05:16:41Z,2021-02-05T07:19:18Z,2021-02-05T07:18:48Z,"Hi, when I tried to run the code `$ bash scripts/install_conda_env.sh`, it showed the following output:
```
conda 4.7.10
=== Installing pipeline's Conda environments ===
Collecting package metadata (current_repodata.json): done
Solving environment: failed with current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: - 
```
However, the ""solving environment"" has already ran for a whole day and it's still running. How can i fix this?
thank you.

Fixed: it's actually this slow",Noel388,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/209
MDU6SXNzdWU4MDk4NzczNzk=,Call-qc failed due an error,OPEN,2021-02-17T05:50:23Z,2021-02-17T21:38:30Z,,"## **Describe the bug**
It seems the pipeline has an error on the qc step.
* Started troubleshooting workflow: id=65302236-00d0-4f5c-af80-47836f267413, status=Failed
* Found failures JSON object.
[
    {
        ""causedBy"": [
            {
                ""causedBy"": [],
                ""message"": ""Job chip.qc_report:NA:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            }
        ],
        ""message"": ""Workflow failed""
    }
]
* Recursively finding failures in calls (tasks)...

==== NAME=chip.qc_report, STATUS=RetryableFailure, PARENT=
SHARD_IDX=-1, RC=1, JOB_ID=55217
START=2021-02-16T10:19:34.569Z, END=2021-02-16T10:19:51.775Z
STDOUT=/gpfs/fs1/data/shenlab/lw/chip-seq-pipeline2/run_pipeline/OP/K36me3high/chip/65302236-00d0-4f5c-af80-47836f267413/call-qc_report/execution/stdout
STDERR=/gpfs/fs1/data/shenlab/lw/chip-seq-pipeline2/run_pipeline/OP/K36me3high/chip/65302236-00d0-4f5c-af80-47836f267413/call-qc_report/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/data/shenlab/lw/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_qc_report.py"", line 927, in <module>
    main()
  File ""/data/shenlab/lw/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_qc_report.py"", line 890, in main
    make_cat_align_enrich(args, cat_root)
  File ""/data/shenlab/lw/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_qc_report.py"", line 737, in make_cat_align_enrich
    cat_jsd.add_log(qc, key=str_rep(i))
  File ""/gpfs/fs1/data/shenlab/lw/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_qc_category.py"", line 159, in add_log
    parser=self._parser,
  File ""/gpfs/fs1/data/shenlab/lw/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_qc_category.py"", line 43, in __init__
    self.__parse()
  File ""/gpfs/fs1/data/shenlab/lw/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_qc_category.py"", line 90, in __parse
    self._dict = self._parser(self._log_file)
  File ""/gpfs/fs1/data/shenlab/lw/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_log_parser.py"", line 421, in parse_jsd_qc
    result['jsd'] = float(arr[6])
ValueError: could not convert string to float: 'NA'

## **OS/Platform**
- OS/Platform: slurm
- Conda version: conda 4.6.14
- Pipeline version: 1.7.0
- Caper version: 1.4.2

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
backend=slurm

# define one of the followings (or both) according to your
# cluster's SLURM configuration.
slurm-partition=
slurm-account=

# Hashing strategy for call-caching (3 choices)
# This parameter is for local (local/slurm/sge/pbs) backend only.
# This is important for call-caching,
# which means re-using outputs from previous/failed workflows.
# Cache will miss if different strategy is used.
# ""file"" method has been default for all old versions of Caper<1.0.
# ""path+modtime"" is a new default for Caper>=1.0,
#   file: use md5sum hash (slow).
#   path: use path.
#   path+modtime: use path and modification time.
local-hash-strat=path+modtime

# Local directory for localized files and Cromwell's intermediate files
# If not defined, Caper will make .caper_tmp/ on local-out-dir or CWD.
# /tmp is not recommended here since Caper store all localized data files
# on this directory (e.g. input FASTQs defined as URLs in input JSON).
local-loc-dir=

cromwell=/home/lw227/.caper/cromwell_jar/cromwell-52.jar
womtool=/home/lw227/.caper/womtool_jar/womtool-52.jar
```

## **Input JSON file**
Paste contents of your input JSON file.
```json
{
    ""chip.title"" : ""high_27ac"",
    ""chip.description"" : ""high_27ac"",

    ""chip.pipeline_type"" : ""histone"",
    ""chip.peak_caller"" : ""macs2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""/data/shenlab/lw/chip-seq-pipeline2/genome/hg19/hg19.tsv"",
    ""chip.paired_end"" : true,
    ""chip.ctl_paired_end"" : true,

    ""chip.fastqs_rep1_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib57-63/trimmed/Lib58_CKDL200150158-1a-AK4949_H7N2KBBXX_L6/OP27.R1.paired.fq.gz"" ],
    ""chip.fastqs_rep1_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib57-63/trimmed/Lib58_CKDL200150158-1a-AK4949_H7N2KBBXX_L6/OP27.R2.paired.fq.gz"" ],
    ""chip.fastqs_rep2_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib65_CKDL200150159-1a-AK4949_H7N2KBBXX_L7/OP17.R1.paired.fq.gz"" ],
    ""chip.fastqs_rep2_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib65_CKDL200150159-1a-AK4949_H7N2KBBXX_L7/OP17.R2.paired.fq.gz"" ],
    ""chip.fastqs_rep3_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib65_CKDL200150159-1a-AK4949_H7N2KBBXX_L7/OP34.R1.paired.fq.gz"" ],
    ""chip.fastqs_rep3_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib65_CKDL200150159-1a-AK4949_H7N2KBBXX_L7/OP34.R2.paired.fq.gz"" ],
    ""chip.fastqs_rep4_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib71-77/trimmed/Lib72_CKDL200150160-1a-AK4949_H7N2KBBXX_L8/OP18.R1.paired.fq.gz"" ],
    ""chip.fastqs_rep4_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib71-77/trimmed/Lib72_CKDL200150160-1a-AK4949_H7N2KBBXX_L8/OP18.R2.paired.fq.gz"" ],
    ""chip.fastqs_rep5_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib65_CKDL200150159-1a-AK4949_H7N2KBBXX_L7/OP33.R1.paired.fq.gz"" ],
    ""chip.fastqs_rep5_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib65_CKDL200150159-1a-AK4949_H7N2KBBXX_L7/OP33.R2.paired.fq.gz"" ],
    ""chip.fastqs_rep6_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib65_CKDL200150159-1a-AK4949_H7N2KBBXX_L7/OP12.R1.paired.fq.gz"" ],
    ""chip.fastqs_rep6_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib65_CKDL200150159-1a-AK4949_H7N2KBBXX_L7/OP12.R2.paired.fq.gz"" ],
    ""chip.fastqs_rep7_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib57-63/trimmed/Lib58_CKDL200150158-1a-AK4949_H7N2KBBXX_L6/OP9.R1.paired.fq.gz"" ],
    ""chip.fastqs_rep7_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib57-63/trimmed/Lib58_CKDL200150158-1a-AK4949_H7N2KBBXX_L6/OP9.R2.paired.fq.gz"" ],
    ""chip.fastqs_rep8_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib71-77/trimmed/Lib72_CKDL200150160-1a-AK4949_H7N2KBBXX_L8/OP30.R1.paired.fq.gz"" ],
    ""chip.fastqs_rep8_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib71-77/trimmed/Lib72_CKDL200150160-1a-AK4949_H7N2KBBXX_L8/OP30.R2.paired.fq.gz"" ],
    ""chip.fastqs_rep9_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib71-77/trimmed/Lib72_CKDL200150160-1a-AK4949_H7N2KBBXX_L8/OP3.R1.paired.fq.gz"" ],
    ""chip.fastqs_rep9_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib71-77/trimmed/Lib72_CKDL200150160-1a-AK4949_H7N2KBBXX_L8/OP3.R2.paired.fq.gz"" ],

    ""chip.ctl_fastqs_rep1_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib57-63/trimmed/Lib57_CKDL200150158-1a-AK2721_H7N2KBBXX_L6/OP27.R1.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep1_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib57-63/trimmed/Lib57_CKDL200150158-1a-AK2721_H7N2KBBXX_L6/OP27.R2.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep2_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib64_CKDL200150159-1a-AK2721_H7N2KBBXX_L7/OP17.R1.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep2_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib64_CKDL200150159-1a-AK2721_H7N2KBBXX_L7/OP17.R2.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep3_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib64_CKDL200150159-1a-AK2721_H7N2KBBXX_L7/OP34.R1.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep3_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib64_CKDL200150159-1a-AK2721_H7N2KBBXX_L7/OP34.R2.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep4_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib71-77/trimmed/Lib71_CKDL200150160-1a-AK2721_H7N2KBBXX_L8/OP18.R1.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep4_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib71-77/trimmed/Lib71_CKDL200150160-1a-AK2721_H7N2KBBXX_L8/OP18.R2.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep5_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib64_CKDL200150159-1a-AK2721_H7N2KBBXX_L7/OP33.R1.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep5_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib64_CKDL200150159-1a-AK2721_H7N2KBBXX_L7/OP33.R2.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep6_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib64_CKDL200150159-1a-AK2721_H7N2KBBXX_L7/OP12.R1.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep6_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib64-70/trimmed/Lib64_CKDL200150159-1a-AK2721_H7N2KBBXX_L7/OP12.R2.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep7_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib57-63/trimmed/Lib57_CKDL200150158-1a-AK2721_H7N2KBBXX_L6/OP9.R1.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep7_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib57-63/trimmed/Lib57_CKDL200150158-1a-AK2721_H7N2KBBXX_L6/OP9.R2.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep8_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib71-77/trimmed/Lib71_CKDL200150160-1a-AK2721_H7N2KBBXX_L8/OP30.R1.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep8_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib71-77/trimmed/Lib71_CKDL200150160-1a-AK2721_H7N2KBBXX_L8/OP30.R2.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep9_R1"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib71-77/trimmed/Lib71_CKDL200150160-1a-AK2721_H7N2KBBXX_L8/OP3.R1.paired.fq.gz"" ],
    ""chip.ctl_fastqs_rep9_R2"" : [ ""/data/shenlab/lw/OP/for-Ergang/mint-chip/lib71-77/trimmed/Lib71_CKDL200150160-1a-AK2721_H7N2KBBXX_L8/OP3.R2.paired.fq.gz"" ],

    ""chip.crop_length"" : 0,

    ""chip.mapq_thresh"" : 30,
    ""chip.dup_marker"" : ""picard"",
    ""chip.no_dup_removal"" : false,

    ""chip.subsample_reads"" : 0,
    ""chip.ctl_subsample_reads"" : 0,
    ""chip.xcor_subsample_reads"" : 15000000,

    ""chip.xcor_trim_bp"" : 50,
    ""chip.use_filt_pe_ta_for_xcor"" : false,

    ""chip.always_use_pooled_ctl"" : true,
    ""chip.ctl_depth_ratio"" : 1.2,

    ""chip.peak_caller"" : null,
    ""chip.cap_num_peak"" : 500000,
    ""chip.pval_thresh"" : 0.01,
    ""chip.fdr_thresh"" : 0.01,
    ""chip.idr_thresh"" : 0.05,

    ""chip.enable_jsd"" : true,
    ""chip.enable_gc_bias"" : true,
    ""chip.enable_count_signal_track"" : false,

    ""chip.filter_chrs"" : [],

    ""chip.align_cpu"" : 6,
    ""chip.align_bowtie2_mem_factor"" : 0.15,
    ""chip.align_bwa_mem_factor"" : 0.15,
    ""chip.align_time_hr"" : 48,
    ""chip.align_bowtie2_disk_factor"" : 8.0,
    ""chip.align_bwa_disk_factor"" : 8.0,

    ""chip.filter_cpu"" : 4,
    ""chip.filter_mem_factor"" : 0.4,
    ""chip.filter_time_hr"" : 24,
    ""chip.filter_disk_factor"" : 6.0,

    ""chip.bam2ta_cpu"" : 2,
    ""chip.bam2ta_mem_factor"" : 0.35,
    ""chip.bam2ta_time_hr"" : 6,
    ""chip.bam2ta_disk_factor"" : 4.0,

    ""chip.spr_mem_factor"" : 4.5,
    ""chip.spr_disk_factor"" : 6.0,

    ""chip.jsd_cpu"" : 4,
    ""chip.jsd_mem_factor"" : 0.1,
    ""chip.jsd_time_hr"" : 6,
    ""chip.jsd_disk_factor"" : 2.0,

    ""chip.xcor_cpu"" : 2,
    ""chip.xcor_mem_factor"" : 1.0,
    ""chip.xcor_time_hr"" : 24,
    ""chip.xcor_disk_factor"" : 4.5,

    ""chip.subsample_ctl_mem_factor"" : 7.0,
    ""chip.subsample_ctl_disk_factor"" : 7.5,

    ""chip.call_peak_cpu"" : 6,
    ""chip.call_peak_spp_mem_factor"" : 5.0,
    ""chip.call_peak_macs2_mem_factor"" : 2.5,
    ""chip.call_peak_time_hr"" : 72,
    ""chip.call_peak_spp_disk_factor"" : 5.0,
    ""chip.call_peak_macs2_disk_factor"" : 15.0,

    ""chip.macs2_signal_track_mem_factor"" : 6.0,
    ""chip.macs2_signal_track_time_hr"" : 24,
    ""chip.macs2_signal_track_disk_factor"" : 40.0
}
```

",andrewucla,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/212
MDU6SXNzdWU4MTk0MzExMDI=,Pipeline gets stuck on first stage (read_genome_tsv),CLOSED,2021-03-02T00:13:29Z,2021-03-03T04:37:35Z,2021-03-03T04:37:35Z,"I've run the pipeline successfully many times before (last time end of January), but now it keeps getting stuck for hours/days after reading in the genome data. Running on a SLURM system using the included Conda environment.

JSON:
```
{
    ""chip.genome_tsv"" : ""/net/bmc-pub14/data/boyer/users/kdemuren/chip-seq-pipeline2/genome/mm9/mm9.tsv"",
    ""chip.paired_end"" : false,
    ""chip.ctl_paired_end"" : false,
    
    ""chip.fastqs_rep1_R1"" : [""/net/bmc-pub15/data/bmc/public/Boyer/210105Boy/D21-160-4854L/210105Boy_D21-160_NA_sequence.fastq""],
    ""chip.fastqs_rep2_R1"" : [""/net/bmc-pub14/data/boyer/users/kdemuren/SeqFiles/201005Boy/D20-4957-4668G/201005Boy_D20-4957_NA_sequence.fastq""],
    
	""chip.ctl_fastqs_rep1_R1"" : [""/net/bmc-pub15/data/bmc/public/Boyer/210105Boy/D21-165-4854L/210105Boy_D21-165_NA_sequence.fastq""],

    ""chip.title"" : ""CP TEAD1-HA DMSO"",
    ""chip.description"" : ""CP TEAD1-HA DMSO - Tead1-FKBP"",

	""chip.pipeline_type"" : ""tf"",
	""chip.aligner"" : ""bowtie2"",

    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.always_use_pooled_ctl"" : true
}
```

Cromwell output:
```
2021-03-01 19:01:26,103  INFO  - Running with database db.url = jdbc:hsqldb:mem:7bb53a68-3842-4a84-bedc-25fb4107ab58;shutdown=false;hsqldb.tx=mvcc
2021-03-01 19:01:34,948  INFO  - Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000
2021-03-01 19:01:34,962  INFO  - [RenameWorkflowOptionsInMetadata] 100%
2021-03-01 19:01:35,056  INFO  - Running with database db.url = jdbc:hsqldb:mem:05d392ec-9efb-464a-9623-ff024eb6d175;shutdown=false;hsqldb.tx=mvcc
2021-03-01 19:01:35,482  INFO  - Slf4jLogger started
2021-03-01 19:01:35,651 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO  - Workflow heartbeat configuration:
{
  ""cromwellId"" : ""cromid-65201fc"",
  ""heartbeatInterval"" : ""2 minutes"",
  ""ttl"" : ""10 minutes"",
  ""failureShutdownDuration"" : ""5 minutes"",
  ""writeBatchSize"" : 10000,
  ""writeThreshold"" : 10000
}
2021-03-01 19:01:35,689 cromwell-system-akka.dispatchers.service-dispatcher-12 INFO  - Metadata summary refreshing every 1 second.
2021-03-01 19:01:35,705 cromwell-system-akka.dispatchers.service-dispatcher-8 INFO  - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.
2021-03-01 19:01:35,706 cromwell-system-akka.actor.default-dispatcher-3 INFO  - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.
2021-03-01 19:01:35,727 cromwell-system-akka.dispatchers.engine-dispatcher-56 INFO  - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.
2021-03-01 19:01:35,728  WARN  - 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf)
2021-03-01 19:01:36,022 cromwell-system-akka.dispatchers.engine-dispatcher-56 INFO  - JobExecutionTokenDispenser - Distribution rate: 1 per 2 seconds.
2021-03-01 19:01:36,048 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO  - SingleWorkflowRunnerActor: Version 52
2021-03-01 19:01:36,053 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO  - SingleWorkflowRunnerActor: Submitting workflow
2021-03-01 19:01:36,108 cromwell-system-akka.dispatchers.api-dispatcher-62 INFO  - Unspecified type (Unspecified version) workflow 1eba32a4-5bb0-431c-846b-297ab6bd676d submitted
2021-03-01 19:01:36,128 cromwell-system-akka.dispatchers.engine-dispatcher-60 INFO  - SingleWorkflowRunnerActor: Workflow submitted UUID(1eba32a4-5bb0-431c-846b-297ab6bd676d)
2021-03-01 19:01:36,132 cromwell-system-akka.dispatchers.engine-dispatcher-56 INFO  - 1 new workflows fetched by cromid-65201fc: 1eba32a4-5bb0-431c-846b-297ab6bd676d
2021-03-01 19:01:36,141 cromwell-system-akka.dispatchers.engine-dispatcher-60 INFO  - WorkflowManagerActor Starting workflow UUID(1eba32a4-5bb0-431c-846b-297ab6bd676d)
2021-03-01 19:01:36,148 cromwell-system-akka.dispatchers.engine-dispatcher-60 INFO  - WorkflowManagerActor Successfully started WorkflowActor-1eba32a4-5bb0-431c-846b-297ab6bd676d
2021-03-01 19:01:36,148 cromwell-system-akka.dispatchers.engine-dispatcher-60 INFO  - Retrieved 1 workflows from the WorkflowStoreActor
2021-03-01 19:01:36,166 cromwell-system-akka.dispatchers.engine-dispatcher-56 INFO  - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.
2021-03-01 19:01:36,251 cromwell-system-akka.dispatchers.engine-dispatcher-60 INFO  - MaterializeWorkflowDescriptorActor [UUID(1eba32a4)]: Parsing workflow as WDL 1.0
2021-03-01 19:01:38,452 cromwell-system-akka.dispatchers.engine-dispatcher-60 INFO  - MaterializeWorkflowDescriptorActor [UUID(1eba32a4)]: Call-to-Backend assignments: chip.jsd -> slurm, chip.spr -> slurm, chip.error_use_bwa_mem_for_non_bwa -> slurm, chip.error_input_data -> slurm, chip.filter_no_dedup -> slurm, chip.overlap_pr -> slurm, chip.filter_ctl -> slurm, chip.subsample_ctl -> slurm, chip.idr_ppr -> slurm, chip.pool_ta_pr1 -> slurm, chip.reproducibility_idr -> slurm, chip.xcor -> slurm, chip.pool_ta_ctl -> slurm, chip.overlap_ppr -> slurm, chip.call_peak_pooled -> slurm, chip.call_peak -> slurm, chip.filter -> slurm, chip.error_ctl_fastq_input_required_for_control_mode -> slurm, chip.pool_ta_pr2 -> slurm, chip.error_control_required -> slurm, chip.qc_report -> slurm, chip.filter_R1 -> slurm, chip.choose_ctl -> slurm, chip.idr_pr -> slurm, chip.call_peak_pr1 -> slurm, chip.macs2_signal_track_pooled -> slurm, chip.bam2ta_no_dedup_R1 -> slurm, chip.fraglen_mean -> slurm, chip.error_ctl_input_defined_in_control_mode -> slurm, chip.error_subsample_pooled_control_with_mixed_endedness -> slurm, chip.overlap -> slurm, chip.error_custom_aligner -> slurm, chip.bam2ta -> slurm, chip.align -> slurm, chip.idr -> slurm, chip.align_R1 -> slurm, chip.call_peak_ppr2 -> slurm, chip.subsample_ctl_pooled -> slurm, chip.pool_ta -> slurm, chip.reproducibility_overlap -> slurm, chip.read_genome_tsv -> slurm, chip.macs2_signal_track -> slurm, chip.align_ctl -> slurm, chip.error_wrong_aligner -> slurm, chip.gc_bias -> slurm, chip.call_peak_pr2 -> slurm, chip.count_signal_track_pooled -> slurm, chip.bam2ta_no_dedup -> slurm, chip.pool_blacklist -> slurm, chip.call_peak_ppr1 -> slurm, chip.bam2ta_ctl -> slurm, chip.count_signal_track -> slurm
2021-03-01 19:01:38,674 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,675 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,676 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,676 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,676 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,676 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,677 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,677 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,677 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,677 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,677 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,678 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,678 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,678 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,678 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,678 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,679 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,679 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,679 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,679 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,679 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,679 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,680 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,680 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,680 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,680 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,680 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,680 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,681 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,681 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,681 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,681 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,681 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,681 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,682 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,682 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,682 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,682 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,682 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,682 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,683 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,683 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,683 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,683 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,683 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,683 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,684 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,684 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,684 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,684 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [preemptible, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,685 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:38,685 cromwell-system-akka.dispatchers.backend-dispatcher-99 WARN  - slurm [UUID(1eba32a4)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-01 19:01:41,036 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO  - Not triggering log of token queue status. Effective log interval = None
2021-03-01 19:01:42,996 cromwell-system-akka.dispatchers.engine-dispatcher-43 INFO  - WorkflowExecutionActor-1eba32a4-5bb0-431c-846b-297ab6bd676d [UUID(1eba32a4)]: Starting chip.read_genome_tsv
2021-03-01 19:01:44,045 cromwell-system-akka.dispatchers.engine-dispatcher-43 INFO  - Assigned new job execution tokens to the following groups: 1eba32a4: 1
2021-03-01 19:01:44,204 cromwell-system-akka.dispatchers.engine-dispatcher-127 INFO  - 1eba32a4-5bb0-431c-846b-297ab6bd676d-EngineJobExecutionActor-chip.read_genome_tsv:NA:1 [UUID(1eba32a4)]: Could not copy a suitable cache hit for 1eba32a4:chip.read_genome_tsv:-1:1. No copy attempts were made.
2021-03-01 19:01:44,229 cromwell-system-akka.dispatchers.backend-dispatcher-138 WARN  - BackgroundConfigAsyncJobExecutionActor [UUID(1eba32a4)chip.read_genome_tsv:NA:1]: Unrecognized runtime attribute keys: disks
2021-03-01 19:01:44,317 cromwell-system-akka.dispatchers.backend-dispatcher-138 INFO  - BackgroundConfigAsyncJobExecutionActor [UUID(1eba32a4)chip.read_genome_tsv:NA:1]: `echo ""$(basename /net/bmc-pub14/data/boyer/users/kdemuren/output-chip/CP_TEAD1HA_DMSO/chip/1eba32a4-5bb0-431c-846b-297ab6bd676d/call-read_genome_tsv/inputs/-1769241308/mm9.tsv)"" > genome_name
# create empty files for all entries
touch ref_fa bowtie2_idx_tar bwa_idx_tar chrsz gensz blacklist blacklist2
touch mito_chr_name
touch regex_bfilt_peak_chr_name

python <<CODE
import os
with open('/net/bmc-pub14/data/boyer/users/kdemuren/output-chip/CP_TEAD1HA_DMSO/chip/1eba32a4-5bb0-431c-846b-297ab6bd676d/call-read_genome_tsv/inputs/-1769241308/mm9.tsv','r') as fp:
    for line in fp:
        arr = line.strip('\n').split('\t')
        if arr:
            key, val = arr
            with open(key,'w') as fp2:
                fp2.write(val)
CODE`
2021-03-01 19:01:44,518 cromwell-system-akka.dispatchers.backend-dispatcher-138 INFO  - BackgroundConfigAsyncJobExecutionActor [UUID(1eba32a4)chip.read_genome_tsv:NA:1]: executing: if [ -z \""$SINGULARITY_BINDPATH\"" ]; then export SINGULARITY_BINDPATH=; fi; \
if [ -z \""$SINGULARITY_CACHEDIR\"" ]; then export SINGULARITY_CACHEDIR=; fi;

ITER=0
until [ $ITER -ge 3 ]; do
    sbatch \
        --export=ALL \
        -J cromwell_1eba32a4_read_genome_tsv \
        -D /net/bmc-pub14/data/boyer/users/kdemuren/output-chip/CP_TEAD1HA_DMSO/chip/1eba32a4-5bb0-431c-846b-297ab6bd676d/call-read_genome_tsv \
        -o /net/bmc-pub14/data/boyer/users/kdemuren/output-chip/CP_TEAD1HA_DMSO/chip/1eba32a4-5bb0-431c-846b-297ab6bd676d/call-read_genome_tsv/execution/stdout \
        -e /net/bmc-pub14/data/boyer/users/kdemuren/output-chip/CP_TEAD1HA_DMSO/chip/1eba32a4-5bb0-431c-846b-297ab6bd676d/call-read_genome_tsv/execution/stderr \
        -t 60 \
        -n 1 \
        --ntasks-per-node=1 \
        --cpus-per-task=1 \
        --mem=2048 \
        -p normal \
         \
         \
         \
        --wrap ""/bin/bash /net/bmc-pub14/data/boyer/users/kdemuren/output-chip/CP_TEAD1HA_DMSO/chip/1eba32a4-5bb0-431c-846b-297ab6bd676d/call-read_genome_tsv/execution/script"" \
        && break
    ITER=$[$ITER+1]
    sleep 30
done
2021-03-01 19:01:45,732 cromwell-system-akka.dispatchers.backend-dispatcher-138 INFO  - BackgroundConfigAsyncJobExecutionActor [UUID(1eba32a4)chip.read_genome_tsv:NA:1]: job id: 21301
2021-03-01 19:01:45,737 cromwell-system-akka.dispatchers.backend-dispatcher-140 INFO  - BackgroundConfigAsyncJobExecutionActor [UUID(1eba32a4)chip.read_genome_tsv:NA:1]: Status change from - to WaitingForReturnCode

```
",kdemuren,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/215
MDU6SXNzdWU4MjA5MzIwNjg=,Output from the successfull run ,OPEN,2021-03-03T09:38:50Z,2021-03-04T19:24:48Z,,"Hello I have run the example file from the pipeline,  I can found the output generated but has so many folders is it I have to go through all the folder and see the result or is there any option to get one consolidated result.
 
command I have run in my local system with 64 GB ram 12 core 
 
caper run chip.wdl -i example_input_json/ENCSR936XTK_subsampled_chr19_only.json


2021-03-03 14:30:37,801|caper.cromwell_metadata|INFO| Wrote metadata file. /media/chip-seq-pipeline2/chip/be3cf77a-2a5f-4b85-b477-5a6f5fdcd8ca/metadata.json
2021-03-03 14:30:37,801|caper.nb_subproc_thread|INFO| Cromwell finished successfully.

please help me how to see the result file

Thank you
",Hemantcnaik,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/217
MDU6SXNzdWU4MzgxNjk5NjY=,"Redundant computation - unneccesary ""trimfastq.py"" step?",OPEN,2021-03-22T22:59:10Z,2021-05-19T19:56:53Z,,"## **Describe the bug**
I've been looking at how the pipeline runs, and I noticed something strange. I'm doing something pretty simple, just running chip-seq analysis of existing data on a new reference genome. In the ""call-align_R1"" folder, I noticed that the pipeline calls ""trimfastq.py"" to trim the fastq data with an default value of 50bp. This is strange because I didn't see any option to specify this value or step in the input.md file.

This is different than the trimming for trimmomatic. It looks like a script to just trim all reads to some fixed value. The weirdness is that the output file ""R1_trimmed/xxxx.trim_50bp.fastq.gz"" is not actually trimmed, it's an exact copy of the original fastq file ""R1/xxxx.fastq.gz"". The pipeline goes on to use the R1_trimmed file for alignment. 

It seems really unclear why there's a call to trimfastq with default 50bp, but it doesn't actually trim the file. Maybe it's a bug, or just a left over result of something not used anymore? I was initially surprised to see that file name containing ""trim_50bp.fastq.gz"" because I didn't specify such trimming. The result itself doesn't seem to be a problem, but this could be a source of other issues or undesired behavior. 

I see that there's a parameter: ""chip.xcor_trim_bp"" with default 50bp. I'm guessing the ""call-align_R1"" is the step before the cross-correlation? If that's the case, then there is indeed a bug because my reads don't get trimmed! 

Any clarification would be helpful! Thanks.  

## **OS/Platform**
- OS/Platform: Ubuntu 20.04
- Conda version: 4.9.2
- Pipeline version: v1.7.1
- Caper version: 1.4.2

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
backend=local

local-hash-strat=path+modtime
local-loc-dir=/media/matt/fast_data_storage/ngs_sandbox/caper/

cromwell=/home/matt/.caper/cromwell_jar/cromwell-52.jar
womtool=/home/matt/.caper/womtool_jar/womtool-52.jar


## **Input JSON file**
{
    ""chip.title"" : ""H1 hESC primed chip seq."",
    ""chip.description"" : ""h3k27ac chip-seq."",

    ""chip.pipeline_type"" : ""histone"",
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""/media/ngs/data/genomes/v13/v13.tsv"",

    ""chip.paired_end"" : true,
    ""chip.ctl_paired_end"" : true,

    ""chip.always_use_pooled_ctl"" : true,

    ""chip.fastqs_rep1_R1"" : [ ""SRR8983693/SRR8983693.1_1.fastq.gz""],
    ""chip.fastqs_rep1_R2"" : [ ""SRR8983693/SRR8983693.1_2.fastq.gz""],
    ""chip.fastqs_rep2_R1"" : [ ""SRR8983695/SRR8983695.1_1.fastq.gz""],
    ""chip.fastqs_rep2_R2"" : [ ""SRR8983695/SRR8983695.1_2.fastq.gz""],

    ""chip.ctl_fastqs_rep1_R1"" : [ ""SRR8983705/SRR8983705.1_1.fastq.gz""],
    ""chip.ctl_fastqs_rep1_R2"" : [ ""SRR8983705/SRR8983705.1_2.fastq.gz""]
}



",jmfrank,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/218
MDU6SXNzdWU4MzkyMzI4OTQ=,Fail at chip.call_peak_ppr1 step,OPEN,2021-03-24T00:31:35Z,2021-03-26T17:10:50Z,,"
[encode_chip_Med1_KD-1671587.log](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/6193524/encode_chip_Med1_KD-1671587.log)
## **Describe the bug**
I installed and run the test successfully (ENCSR000DYI (subsampled 1/25, chr19_chrM only)) but when I run the pipeline on my data it failed at the step call_peak_ppr1
## **OS/Platform**
- OS/Platform: CentOS 6.3
- Conda version: 4.9.2
- Pipeline version: 1.7.1
- Caper version: 1.4.2

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
backend=slurm

# define one of the followings (or both) according to your
# cluster's SLURM configuration.
slurm-partition=all
#slurm-account=

# Hashing strategy for call-caching (3 choices)
# This parameter is for local (local/slurm/sge/pbs) backend only.
# This is important for call-caching,
# which means re-using outputs from previous/failed workflows.
# Cache will miss if different strategy is used.
# ""file"" method has been default for all old versions of Caper<1.0.
# ""path+modtime"" is a new default for Caper>=1.0,
#   file: use md5sum hash (slow).
#   path: use path.
#   path+modtime: use path and modification time.
local-hash-strat=path+modtime

# Local directory for localized files and Cromwell's intermediate files
# If not defined, Caper will make .caper_tmp/ on local-out-dir or CWD.
# /tmp is not recommended here since Caper store all localized data files
# on this directory (e.g. input FASTQs defined as URLs in input JSON).
local-loc-dir=/mnt/work1/users/hoffmangroup/lhuynh/Tools/chip-seq-pipeline2/tmp

cromwell=/mnt/work1/users/home/linhh/.caper/cromwell_jar/cromwell-52.jar
womtool=/mnt/work1/users/home/linhh/.caper/womtool_jar/womtool-52.jar
```

## **Input JSON file**
Paste contents of your input JSON file.
```json
{
    ""chip.pipeline_type"" : ""histone"",
    ""chip.genome_tsv"" : ""/mnt/work1/users/hoffmangroup/lhuynh/ChromatinHub/data/2021_03_22_raw_ChIP_seq/mm9.tsv"",
    ""chip.fastqs_rep1_R1"" : [""/mnt/work1/users/hoffmangroup/lhuynh/ChromatinHub/data/2021_03_22_raw_ChIP_seq/Med1_ChIPseq_siCtrl_Rep1.fastq""],
    ""chip.fastqs_rep2_R1"" : [""/mnt/work1/users/hoffmangroup/lhuynh/ChromatinHub/data/2021_03_22_raw_ChIP_seq/Med1_ChIPseq_siCtrl_Rep2.fastq""],
    ""chip.ctl_fastqs_rep1_R1"" : [""/mnt/work1/users/hoffmangroup/lhuynh/ChromatinHub/data/2021_03_22_raw_ChIP_seq/Input_ChIPseq_siCtrl_Rep1.fastq""],
    ""chip.ctl_fastqs_rep2_R1"" : [""/mnt/work1/users/hoffmangroup/lhuynh/ChromatinHub/data/2021_03_22_raw_ChIP_seq/Input_ChIPseq_siCtrl_Rep2.fastq""],
    ""chip.paired_end"" : false,
    ""chip.title"" : ""Med1Ctrl_mm9"",
    ""chip.description"" : ""Med1 ChIP-seq of Ctrl mESC mm9""
}
```


And here is what I got from slurm log file (the full log file is attached)
```
==== NAME=chip.call_peak_ppr1, STATUS=RetryableFailure, PARENT=
SHARD_IDX=-1, RC=1, JOB_ID=32045
START=2021-03-23T04:29:16.227Z, END=2021-03-23T08:25:58.647Z
STDOUT=/mnt/work1/users/hoffmangroup/lhuynh/Tools/chip-seq-pipeline2/Linh_Output/chip/b83eb85b-c760-440b-84d5-3d7b5e4cf3ec/call-call_peak_ppr1/execution/stdout
STDERR=/mnt/work1/users/hoffmangroup/lhuynh/Tools/chip-seq-pipeline2/Linh_Output/chip/b83eb85b-c760-440b-84d5-3d7b5e4cf3ec/call-call_peak_ppr1/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/mnt/work1/users/hoffmangroup/lhuynh/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/mnt/work1/users/hoffmangroup/lhuynh/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_spp.py"", line 119, in main
    args.ctl_subsample, args.ctl_paired_end, args.nth, args.out_dir)
  File ""/mnt/work1/users/hoffmangroup/lhuynh/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_task_spp.py"", line 90, in spp
    run_shell_cmd(cmd0)
  File ""/mnt/work1/users/hoffmangroup/lhuynh/miniconda3/envs/encode-chip-seq-pipeline/bin/encode_lib_common.py"", line 331, in 
[encode_chip_Med1_KD-1671587.log](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/6193467/encode_chip_Med1_KD-1671587.log)
run_shell_cmd
    raise Exception(err_str)
Exception: PID=17945, PGID=17945, RC=137, DURATION_SEC=13967.0
STDERR=Loading required package: Rcpp
Warning: stack imbalance in 'lapply', 20 then 107
Warning: stack imbalance in 'lapply', 11 then 98
/bin/bash: line 1: 17948 Killed                  Rscript --max-ppsize=500000 $(which run_spp.R) -c=/mnt/work1/users/hoffmangroup/lhuynh/Tools/chip-seq-pipeline2/Linh_Output/chip/b83eb85b-c760-440b-84d5-3d7b5e4cf3ec/call-call_peak_ppr1/inputs/-1843169244/rep-pr1.pooled.tagAlign.gz -i=/mnt/work1/users/hoffmangroup/lhuynh/Tools/chip-seq-pipeline2/Linh_Output/chip/b83eb85b-c760-440b-84d5-3d7b5e4cf3ec/call-call_peak_ppr1/inputs/-333660208/ctl.pooled.tagAlign.gz -npeak=300000 -odir=/mnt/work1/users/hoffmangroup/lhuynh/Tools/chip-seq-pipeline2/Linh_Output/chip/b83eb85b-c760-440b-84d5-3d7b5e4cf3ec/call-call_peak_ppr1/execution -speak=145 -savr=rep-pr1.pooled_x_ctl.pooled.300K.regionPeak.gz.tmp -fdr=0.01 -rf
```",huynhvietlinh,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/219
MDU6SXNzdWU4NDM5NjQ5Mjc=,Compatible with NChIP?,OPEN,2021-03-30T01:15:06Z,2021-08-11T17:42:32Z,,"Hello @akundaje and @leepc12 , 

I wanted to use this pipeline to analyze ultra-low-input, native ChIP-Seq samples [ULI-NChIP](https://www.nature.com/articles/ncomms7033) looking at histone modifications. 
Unlike regular ChIP-Seq, ULI-NChIP uses MNase for digestion (instead of sonication) and avoids cross-linking protein-DNA interactions. 

Considering that the histone pipeline would expect the standard histone ChIP-Seq, would there be a problem using this pipeline?

Furthermore, MNase is known to have it's own biases and so I wonder....
Whether the normal ChIP-Seq [library complexity QC parameters](https://www.encodeproject.org/data-standards/terms/) are still valid to exclude samples?
",YogiOnBioinformatics,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/222
MDU6SXNzdWU4NTE4MTA5MjU=,"Pipeline on GCP fails with ""Error: pipeline dependencies not found""",OPEN,2021-04-06T21:06:49Z,2021-04-08T17:00:27Z,,"## **Describe the bug**
I've submitted a good number (25) of ChIP-seq jobs to Caper, and the jobs begin running, but somehow halfway through, the Caper server dies suddenly. Examining the logs and grepping for ""error"", I find that all of the job logs (in `cromwell-workflow-logs/`) contain ""Error: pipeline dependencies not found"".

I have consulted [Issue #172](https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/172), but I have verified that I have activated the `encode-chip-seq-pipeline` einvironment both when launching the Caper server and when submitting the jobs. I am also experiencing these issues on GCP, and not on MacOS, so I felt it was prudent to create a new issue for this.

## **OS/Platform**
- OS/Platform: Google Cloud
- Conda version: 4.7.12
- Pipeline version: I'm not sure how to check this, sorry
- Caper version: 1.4.2

## **Caper configuration file**
```ini
backend=gcp
gcp-prj=gbsc-gcp-lab-kundaje
tmp-dir=/data/tmp_amtseng
singularity-cachedir=/data/singularity_cachedir_amtseng
file-db=/data/caper_db/caper_file_db_amtseng
db-timeout=120000
max-concurrent-tasks=1000
max-concurrent-workflows=50
use-google-cloud-life-sciences=True
gcp-region=us-central1
```

## **Input JSON file**
Here, I'm showing one of the 25 jobs submitted.
```json
{
  ""chip.title"": ""A549_cJun_FLAG cells untreated"",
  ""chip.description"": ""A549_cJun_FLAG cells untreated"",

  ""chip.pipeline_type"": ""tf"",

  ""chip.aligner"": ""bowtie2"",
  ""chip.align_only"": false,
  ""chip.true_rep_only"": false,

  ""chip.genome_tsv"": ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v3/hg38.tsv"",

  ""chip.paired_end"": false,
  ""chip.ctl_paired_end"": false,

  ""chip.always_use_pooled_ctl"": true,

  ""chip.align_cpu"": 4,
  ""chip.call_peak_cpu"": 4,

  ""chip.fastqs_rep1_R1"": [
    ""gs://caper_in/amtseng/AP1/fastqs/SRR12090532.fastq.gz""
  ],
  ""chip.fastqs_rep2_R1"": [
    ""gs://caper_in/amtseng/AP1/fastqs/SRR12090533.fastq.gz""
  ],
  ""chip.fastqs_rep3_R1"": [
    ""gs://caper_in/amtseng/AP1/fastqs/SRR12090534.fastq.gz""
  ],

  ""chip.ctl_fastqs_rep1_R1"": [
    ""gs://caper_in/amtseng/AP1/fastqs/SRR12090601.fastq.gz""
  ],
  ""chip.ctl_fastqs_rep2_R1"": [
    ""gs://caper_in/amtseng/AP1/fastqs/SRR12090602.fastq.gz""
  ],
  ""chip.ctl_fastqs_rep3_R1"": [
    ""gs://caper_in/amtseng/AP1/fastqs/SRR12090603.fastq.gz""
  ]
}
```

## **Troubleshooting result**

Unfortunately, because the Caper server dies, I am unable to use `caper troubleshoot {jobID}` to diagnose.
Instead, I've attached the cromwell log for the job. The end of this log is:

I've also attached `cromwell.out`.
[workflow.3d1cb136-9b32-4514-9a33-3262d8303d6f.log](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/6267549/workflow.3d1cb136-9b32-4514-9a33-3262d8303d6f.log.txt)

[cromwell.out](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/6267548/cromwell.out.txt)

Thanks!
",amtseng,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/224
MDU6SXNzdWU4NTM2NDc5NDM=,"Pipeline hangs on: ""undefined symbol: JLI_InitArgProcessing"" and ""task=chip.read_genome_tsv:-1, retry=0, status=WaitingForReturnCode""",OPEN,2021-04-08T16:30:37Z,2021-04-16T18:32:30Z,,"## **Describe the bug**
When running the pipeline on SCG, it consistently hangs on the line that reads ""task=chip.read_genome_tsv:-1, retry=0, status=WaitingForReturnCode"". I have changed the JDK version to different suggested versions and tried running the pipeline with and without an active server, and I cannot overcome this error.

## **OS/Platform**
- OS/Platform: SCG
- Conda version: 4.8.2
- Pipeline version: 1.7.1
- Caper version: 1.4.2

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini

backend=slurm
slurm-account=default
# Hashing strategy for call-caching (3 choices)
# This parameter is for local (local/slurm/sge/pbs) backend only.
# This is important for call-caching,
# which means re-using outputs from previous/failed workflows.
# Cache will miss if different strategy is used.
# ""file"" method has been default for all old versions of Caper<1.0.
# ""path+modtime"" is a new default for Caper>=1.0,
#   file: use md5sum hash (slow).
#   path: use path.
#   path+modtime: use path and modification time.
local-hash-strat=path+modtime
# Local directory for localized files and Cromwell's intermediate files
# If not defined, Caper will make .caper_tmp/ on local-out-dir or CWD.
# /tmp is not recommended here since Caper store all localized data files
# on this directory (e.g. input FASTQs defined as URLs in input JSON).
local-loc-dir=/labs/mpsnyder/neekonsu/2021/workspace/abc/CAPER
cromwell=/home/neekonsu/.caper/cromwell_jar/cromwell-52.jar
womtool=/home/neekonsu/.caper/womtool_jar/womtool-52.jar
```

## **Input JSON file**
Paste contents of your input JSON file.
```json
{
    ""chip.title"" : ""Paired End Preprocessing"",
    ""chip.description"" : ""Pipeline based on template JSON"",
    ""chip.pipeline_type"" : ""histone"",
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,
    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v3/hg38.tsv"",
    ""chip.paired_end"" : true,
    ""chip.ctl_paired_end"" : false,
    ""chip.fastqs_rep1_R1"" : [ ""/labs/mpsnyder/neekonsu/2021/workspace/abc/SRR9736862.1.fastq"" ],
    ""chip.fastqs_rep1_R2"" : [ ""/labs/mpsnyder/neekonsu/2021/workspace/abc/SRR9736862.2.fastq"" ],
    ""chip.fastqs_rep2_R1"" : [ ""/labs/mpsnyder/neekonsu/2021/workspace/abc/SRR9736863.1.fastq"" ],
    ""chip.fastqs_rep2_R2"" : [ ""/labs/mpsnyder/neekonsu/2021/workspace/abc/SRR9736863.2.fastq"" ]
}

```

## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
### **Pipeline Output usual error**
```
2021-03-07 16:23:29,791|caper.cromwell|INFO| Validating WDL/inputs/imports with Womtool...
2021-03-07 16:23:33,845|caper.cromwell|INFO| Womtool validation passed.
2021-03-07 16:23:33,846|caper.caper_runner|INFO| launching run: wdl=/labs/mpsnyder/neekonsu/2021/workspace/abc/chip-seq-pipeline2/chip.wdl, inputs=/labs/mpsnyder/neekonsu/2021/workspace/abc/CAPER/oak/stanford/scg/lab_mpsnyder/neekonsu/2021/workspace/abc/CAPER/input.local.json, backend_conf=/labs/mpsnyder/neekonsu/2021/workspace/abc/CAPER/chip/20210307_162323_253155/backend.conf
2021-03-07 16:23:46,169|caper.cromwell_workflow_monitor|INFO| Workflow: id=44992c81-836e-4fab-8ce1-dd5a9f5801ec, status=Submitted
2021-03-07 16:23:46,232|caper.cromwell_workflow_monitor|INFO| Workflow: id=44992c81-836e-4fab-8ce1-dd5a9f5801ec, status=Running
2021-03-07 16:23:55,760|caper.cromwell_workflow_monitor|INFO| Task: id=44992c81-836e-4fab-8ce1-dd5a9f5801ec, task=chip.read_genome_tsv:-1, retry=0, status=Started, job_id=10452
2021-03-07 16:23:55,772|caper.cromwell_workflow_monitor|INFO| Task: id=44992c81-836e-4fab-8ce1-dd5a9f5801ec, task=chip.read_genome_tsv:-1, retry=0, status=WaitingForReturnCode
```
### **Pipeline Output java error**
```
2021-03-07 16:21:08,258|caper.cromwell|INFO| Validating WDL/inputs/imports with Womtool...
2021-03-07 16:21:08,282|caper.cromwell|ERROR| RC=127
STDERR=java: symbol lookup error: java: undefined symbol: JLI_InitArgProcessing

Womtool validation failed.
```
### **Cromwell log**
```
2021-03-07 15:58:52,392 cromwell-system-akka.dispatchers.backend-dispatcher-95 WARN  - slurm [UUID(116d9c9e)]: Key/s [disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.
2021-03-07 15:58:54,133 cromwell-system-akka.dispatchers.engine-dispatcher-48 INFO  - Not triggering log of token queue status. Effective log interval = None
2021-03-07 15:58:56,738 cromwell-system-akka.dispatchers.engine-dispatcher-119 INFO  - WorkflowExecutionActor-116d9c9e-2d0e-48ec-8d91-e017729e6bb7 [UUID(116d9c9e)]: Starting chip.read_genome_tsv
2021-03-07 15:58:57,142 cromwell-system-akka.dispatchers.engine-dispatcher-97 INFO  - Assigned new job execution tokens to the following groups: 116d9c9e: 1
2021-03-07 15:58:57,286 cromwell-system-akka.dispatchers.engine-dispatcher-97 INFO  - 116d9c9e-2d0e-48ec-8d91-e017729e6bb7-EngineJobExecutionActor-chip.read_genome_tsv:NA:1 [UUID(116d9c9e)]: Could not copy a suitable cache hit for 116d9c9e:chip.read_genome_tsv:-1:1. No copy attempts were made.
2021-03-07 15:58:57,313 cromwell-system-akka.dispatchers.backend-dispatcher-189 WARN  - BackgroundConfigAsyncJobExecutionActor [UUID(116d9c9e)chip.read_genome_tsv:NA:1]: Unrecognized runtime attribute keys: disks
2021-03-07 15:58:58,703 cromwell-system-akka.dispatchers.backend-dispatcher-189 INFO  - BackgroundConfigAsyncJobExecutionActor [UUID(116d9c9e)chip.read_genome_tsv:NA:1]: `echo ""$(basename /oak/stanford/scg/lab_mpsnyder/neekonsu/2021/workspace/abc/CAPER2/chip/116d9c9e-2d0e-48ec-8d91-e017729e6bb7/call-read_genome_tsv/inputs/-37529440/hg38.local.tsv)"" > genome_name

```
",neekonsu,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/225
MDU6SXNzdWU4NTY1MzE4OTM=,Error in chip.align tasks (Failed to evaluate job outputs),OPEN,2021-04-13T03:28:25Z,2021-10-25T20:20:21Z,,"Hi,
I tried to analyze the DAP-seq data using the chip-seq-pipeline2 workflow, but encountered an error (Failed to evaluate job outputs). The task has been completed, the file has been generated, but the file cannot be found by caper.

<pre>
-rw-r--r-- 1 wangdehe ias_admin         3  4æœˆ 12 22:28 MYB25_like.rep2.trim.R1.trim_50bp.read_length.txt
-rw-r--r-- 1 wangdehe ias_admin 784580536  4æœˆ 12 22:28 MYB25_like.rep2.trim.R1.trim_50bp.srt.bam
-rw-r--r-- 1 wangdehe ias_admin   1524248  4æœˆ 12 22:29 MYB25_like.rep2.trim.R1.trim_50bp.srt.bam.bai
-rw-r--r-- 1 wangdehe ias_admin       342  4æœˆ 12 22:32 MYB25_like.rep2.trim.R1.trim_50bp.srt.samstats.qc
drwxr-xr-x 2 wangdehe ias_admin         1  4æœˆ 12 21:51 R1
drwxr-xr-x 2 wangdehe ias_admin         1  4æœˆ 12 21:59 R1_trimmed
-rw-r--r-- 1 wangdehe ias_admin     15022  4æœˆ 12 21:51 script
-rw-r--r-- 1 wangdehe ias_admin       471  4æœˆ 12 21:51 script.background
-rw-r--r-- 1 wangdehe ias_admin       350  4æœˆ 12 21:51 script.submit
-rw-r--r-- 1 wangdehe ias_admin         0  4æœˆ 12 21:51 stderr
-rw-r--r-- 1 wangdehe ias_admin         0  4æœˆ 12 21:51 stderr.background
-rw-r--r-- 1 wangdehe ias_admin     10326  4æœˆ 12 22:32 stdout
-rw-r--r-- 1 wangdehe ias_admin     10333  4æœˆ 12 22:32 stdout.background
-rw-r--r-- 1 wangdehe ias_admin       207  4æœˆ 12 21:51 write_tsv_b9349cb0e3563b467dcaa20e89670ada.tmp
</pre>

<pre>
{
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does 
not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0
 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an ind
ex value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an ind
ex value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            }

</pre>

can you please help?
Best,

### Installation
<pre>
git clone https://github.com/ENCODE-DCC/chip-seq-pipeline2
cd chip-seq-pipeline2
scripts/install_conda_env.sh mamba
source activate encode-chip-seq-pipeline
pip install caper croo
caper init local
</pre>

### Caper file
<pre>
backend=local

# Hashing strategy for call-caching (3 choices)
# This parameter is for local (local/slurm/sge/pbs) backend only.
# This is important for call-caching,
# which means re-using outputs from previous/failed workflows.
# Cache will miss if different strategy is used.
# ""file"" method has been default for all old versions of Caper<1.0.
# ""path+modtime"" is a new default for Caper>=1.0,
#   file: use md5sum hash (slow).
#   path: use path.
#   path+modtime: use path and modification time.
local-hash-strat=path+modtime

# Local directory for localized files and Cromwell's intermediate files
# If not defined, Caper will make .caper_tmp/ on local-out-dir or CWD.
# /tmp is not recommended here since Caper store all localized data files
# on this directory (e.g. input FASTQs defined as URLs in input JSON).
local-loc-dir=/home/wangdehe/project/caper_loc_dir

cromwell=/home/wangdehe/.caper/cromwell_jar/cromwell-59.jar
womtool=/home/wangdehe/.caper/womtool_jar/womtool-59.jar
</pre>

### Input JSON file
<pre>Error in chip.align tasks (Failed to evaluate job outputs)
{
    ""chip.pipeline_type"" : ""tf"",
    ""chip.genome_tsv"" : ""/home/wangdehe/project/CottonSingleCell/data/encode_chip_indx/gosHir_HUA.tsv"",
    ""chip.fastqs_rep1_R1"" : [""/home/wangdehe/project/CottonSingleCell/analysis_v3/DAP_seq/trim/MYB25_like.rep1.trim.R1.fastq.gz""
    ],
    ""chip.fastqs_rep1_R2"" : [""/home/wangdehe/project/CottonSingleCell/analysis_v3/DAP_seq/trim/MYB25_like.rep1.trim.R2.fastq.gz""
    ],
    ""chip.fastqs_rep2_R1"" : [""/home/wangdehe/project/CottonSingleCell/analysis_v3/DAP_seq/trim/MYB25_like.rep2.trim.R1.fastq.gz""
    ],
    ""chip.fastqs_rep2_R2"" : [""/home/wangdehe/project/CottonSingleCell/analysis_v3/DAP_seq/trim/MYB25_like.rep2.trim.R2.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R1"" : [""/home/wangdehe/project/CottonSingleCell/analysis_v3/DAP_seq/trim/MYB25.Input.trim.R1.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R2"" : [""/home/wangdehe/project/CottonSingleCell/analysis_v3/DAP_seq/trim/MYB25.Input.trim.R2.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep2_R1"" : [""/home/wangdehe/project/CottonSingleCell/analysis_v3/DAP_seq/trim/MYB25_like.Input.trim.R1.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep2_R2"" : [""/home/wangdehe/project/CottonSingleCell/analysis_v3/DAP_seq/trim/MYB25_like.Input.trim.R2.fastq.gz""
    ],
    ""chip.paired_end"" : true,
    ""chip.ctl_paired_end"" : true,
    ""chip.title"" : ""MYB25-like DAP-seq"",
    ""chip.description"" : ""MYB25-like DAP-seq"",
    
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,
}
</pre>

### caper debug metadata.json
<pre>
* Started troubleshooting workflow: id=22177161-660e-4365-9d49-bded5aee4ebf, status=Failed
* Found failures JSON object.
[
    {
        ""causedBy"": [
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            },
            {
                ""causedBy"": [
                    {
                        ""message"": ""Bad output 'align_R1.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'"",
                        ""causedBy"": []
                    },
                    {
                        ""message"": ""Bad output 'align_R1.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'"",
                        ""causedBy"": []
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            },
            {
                ""message"": ""Failed to evaluate job outputs"",
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""Error in chip.align tasks (Failed to evaluate job outputs)
                    },
                    {
                        ""message"": ""Bad output 'align.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'"",
                        ""causedBy"": []
                    }
                ]
            },
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            },
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            },
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            },
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            }
        ],
        ""message"": ""Workflow failed""
    }
]
* Recursively finding failures in calls (tasks)...

==== NAME=chip.align, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=None, JOB_ID=280536
START=2021-04-12T13:51:13.920Z, END=2021-04-12T15:55:29.372Z
STDOUT=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align/shard-0/execution/stdout
STDERR=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align/shard-0/execution/stderr
STDERR_CONTENTS=


==== NAME=chip.align, STATUS=Failed, PARENT=
SHARD_IDX=1, RC=None, JOB_ID=280615
START=2021-04-12T13:51:15.912Z, END=2021-04-12T16:07:19.780Z
STDOUT=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align/shard-1/execution/stdout
STDERR=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align/shard-1/execution/stderr
STDERR_CONTENTS=


==== NAME=chip.align_ctl, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=None, JOB_ID=280465
START=2021-04-12T13:51:11.941Z, END=2021-04-12T15:52:12.966Z
STDOUT=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_ctl/shard-0/execution/stdout
STDERR=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_ctl/shard-0/execution/stderr
STDERR_CONTENTS=


==== NAME=chip.align_ctl, STATUS=Failed, PARENT=
SHARD_IDX=1, RC=None, JOB_ID=280758
START=2021-04-12T13:51:19.910Z, END=2021-04-12T15:34:12.712Z
STDOUT=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee* Started troubleshooting workflow: id=22177161-660e-4365-9d49-bded5aee4ebf, status=Failed
* Found failures JSON object.
[
    {
        ""causedBy"": [
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            },
            {
                ""causedBy"": [
                    {
                        ""message"": ""Bad output 'align_R1.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'"",
                        ""causedBy"": []
                    },
                    {
                        ""message"": ""Bad output 'align_R1.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'"",
                        ""causedBy"": []
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            },
            {
                ""message"": ""Failed to evaluate job outputs"",
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""message"": ""Bad output 'align.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'"",
                        ""causedBy"": []
                    }
                ]
            },
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            },
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            },
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            },
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.samstat_qc': Bad array access glob(\""*.samstats.qc\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.read_len_log': Bad array access glob(\""*.read_length.txt\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    },
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_R1.bam': Bad array access glob(\""*.bam\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            }
        ],
        ""message"": ""Workflow failed""
    }
]
* Recursively finding failures in calls (tasks)...

==== NAME=chip.align, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=None, JOB_ID=280536
START=2021-04-12T13:51:13.920Z, END=2021-04-12T15:55:29.372Z
STDOUT=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align/shard-0/execution/stdout
STDERR=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align/shard-0/execution/stderr
STDERR_CONTENTS=


==== NAME=chip.align, STATUS=Failed, PARENT=
SHARD_IDX=1, RC=None, JOB_ID=280615
START=2021-04-12T13:51:15.912Z, END=2021-04-12T16:07:19.780Z
STDOUT=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align/shard-1/execution/stdout
STDERR=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align/shard-1/execution/stderr
STDERR_CONTENTS=


==== NAME=chip.align_ctl, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=None, JOB_ID=280465
START=2021-04-12T13:51:11.941Z, END=2021-04-12T15:52:12.966Z
STDOUT=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_ctl/shard-0/execution/stdout
STDERR=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_ctl/shard-0/execution/stderr
STDERR_CONTENTS=


==== NAME=chip.align_ctl, STATUS=Failed, PARENT=
SHARD_IDX=1, RC=None, JOB_ID=280758
START=2021-04-12T13:51:19.910Z, END=2021-04-12T15:34:12.712Z
STDOUT=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_ctl/shard-1/execution/stdout
STDERR=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_ctl/shard-1/execution/stderr
STDERR_CONTENTS=


==== NAME=chip.align_R1, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=None, JOB_ID=280803
START=2021-04-12T13:51:21.912Z, END=2021-04-12T14:27:07.619Z
STDOUT=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_R1/shard-0/execution/stdout
STDERR=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_R1/shard-0/execution/stderr
STDERR_CONTENTS=


==== NAME=chip.align_R1, STATUS=Failed, PARENT=
SHARD_IDX=1, RC=None, JOB_ID=280689
START=2021-04-12T13:51:17.910Z, END=2021-04-12T14:34:40.620Z
STDOUT=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_R1/shard-1/execution/stdout
STDERR=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_R1/shard-1/execution/stderr
STDERR_CONTENTS=

4ebf/call-align_ctl/shard-1/execution/stdout
STDERR=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_ctl/shard-1/execution/stderr
STDERR_CONTENTS=


==== NAME=chip.align_R1, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=None, JOB_ID=280803
START=2021-04-12T13:51:21.912Z, END=2021-04-12T14:27:07.619Z
STDOUT=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_R1/shard-0/execution/stdout
STDERR=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_R1/shard-0/execution/stderr
STDERR_CONTENTS=


==== NAME=chip.align_R1, STATUS=Failed, PARENT=
SHARD_IDX=1, RC=None, JOB_ID=280689
START=2021-04-12T13:51:17.910Z, END=2021-04-12T14:34:40.620Z
STDOUT=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_R1/shard-1/execution/stdout
STDERR=/beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_R1/shard-1/execution/stderr
STDERR_CONTENTS=

</pre>

### STDOUT and STDERR  file (chip.align_R1)
<pre>
tail -n 20 /beegfs/zhoulab/dhwang/CottonSingleCell/analysis_v3/DAP_seq/encode_chip2_pipeline/MYB25_like/chip/22177161-660e-4365-9d49-bded5aee4ebf/call-align_R1/shard-1/execution/stdout 
[2021-04-12 22:32:02,007 INFO] List all files in output directory...
[2021-04-12 22:32:02,012 INFO] run_shell_cmd: PID=68066, PGID=68066, CMD=ls -l 
[2021-04-12 22:32:02,039 INFO] PID=68066, PGID=68066, RC=0, DURATION_SEC=0.0
STDERR=
STDOUT=total 767721
-rw-r--r-- 1 wangdehe ias_admin         3  4æœˆ 12 22:28 MYB25_like.rep2.trim.R1.trim_50bp.read_length.txt
-rw-r--r-- 1 wangdehe ias_admin 784580536  4æœˆ 12 22:28 MYB25_like.rep2.trim.R1.trim_50bp.srt.bam
-rw-r--r-- 1 wangdehe ias_admin   1524248  4æœˆ 12 22:29 MYB25_like.rep2.trim.R1.trim_50bp.srt.bam.bai
-rw-r--r-- 1 wangdehe ias_admin       342  4æœˆ 12 22:32 MYB25_like.rep2.trim.R1.trim_50bp.srt.samstats.qc
drwxr-xr-x 2 wangdehe ias_admin         1  4æœˆ 12 21:51 R1
drwxr-xr-x 2 wangdehe ias_admin         1  4æœˆ 12 21:59 R1_trimmed
-rw-r--r-- 1 wangdehe ias_admin     15022  4æœˆ 12 21:51 script
-rw-r--r-- 1 wangdehe ias_admin       471  4æœˆ 12 21:51 script.background
-rw-r--r-- 1 wangdehe ias_admin       350  4æœˆ 12 21:51 script.submit
-rw-r--r-- 1 wangdehe ias_admin         0  4æœˆ 12 21:51 stderr
-rw-r--r-- 1 wangdehe ias_admin         0  4æœˆ 12 21:51 stderr.background
-rw-r--r-- 1 wangdehe ias_admin     10326  4æœˆ 12 22:32 stdout
-rw-r--r-- 1 wangdehe ias_admin     10333  4æœˆ 12 22:32 stdout.background
-rw-r--r-- 1 wangdehe ias_admin       207  4æœˆ 12 21:51 write_tsv_b9349cb0e3563b467dcaa20e89670ada.tmp
[2021-04-12 22:32:02,039 INFO] All done.
</pre>

STDERR  file is empty.


",sqreb,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/226
MDU6SXNzdWU5ODM5MzUxOTk=,Example JSON not working,OPEN,2021-08-31T14:33:49Z,2021-09-06T23:32:33Z,,"## **Describe the bug**
I have just cloned and installed the pipeline using conda, and caper using pip. However, I cannot run the example JSON. Any help would be much appreciated!

## **OS/Platform**
- OS/Platform: Linux (Brown's CS cluster)
- Conda version: 4.10.3
- Pipeline version: 1.9.0
- Caper version: 1.6.3

## **Caper configuration file**
<img width=""741"" alt=""Screen Shot 2021-08-31 at 3 28 13 PM"" src=""https://user-images.githubusercontent.com/43190860/131520975-67c373e5-9fde-49c3-8357-b6474f3cbc5f.png"">

## **Input JSON file**
https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI_subsampled_chr19_only.json

## **Troubleshooting result**
<img width=""1423"" alt=""Screen Shot 2021-08-31 at 3 32 49 PM"" src=""https://user-images.githubusercontent.com/43190860/131521854-8142009b-cf5d-48ec-a4a3-2f17743186f9.png"">
<img width=""1423"" alt=""Screen Shot 2021-08-31 at 3 30 28 PM"" src=""https://user-images.githubusercontent.com/43190860/131521420-c4527bcd-77be-4534-9596-21744c45dabe.png"">
<img width=""1423"" alt=""Screen Shot 2021-08-31 at 3 31 21 PM"" src=""https://user-images.githubusercontent.com/43190860/131521568-e8799a7a-36fe-43d1-b9ec-8a75c5279973.png"">
<img width=""1423"" alt=""Screen Shot 2021-08-31 at 3 31 49 PM"" src=""https://user-images.githubusercontent.com/43190860/131521670-192d697d-fb1d-4f81-b72b-2afd97a734c8.png"">

And so on. 

",lcamillo,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/235
MDU6SXNzdWU5ODY4MDk4Mjc=,Can I run chip-seq-pipeline without input files?,OPEN,2021-09-02T14:30:17Z,2021-09-24T01:49:23Z,,"## **Describe the bug**
If I run without `chip.ctl*` set in `.json`, it will report:
```
* Error: SPP requires control inputs. Define control input files (chip.ctl_*) in an input JSON file.
```
I know `tf` mode runs with input files which is different from `histone` mode, but is there any possibility to run ChIP-seq-pipeline without input files? Because I don't have input datasets in my research.

## **OS/Platform**
- OS/Platform: Ubuntu
- Conda version: conda 4.10.3
- Pipeline version: [e.g. v1.6.0]
- Caper version: [e.g. v1.2.0]


## **Input JSON file**
```json
{
    ""chip.pipeline_type"" : ""tf"",
    ""chip.genome_tsv"" : ""./genome_ENCODE/hg38.tsv"",
    ""chip.fastqs_rep1_R1"" : [""./0_raw_data/TF1_rep1_R1.fastq.gz""
    ],
    ""chip.fastqs_rep1_R2"" : [""./0_raw_data/TF1_rep1_R2.fastq.gz""
    ],
    ""chip.paired_end"" : true,
    ""chip.title"" : ""TF1"",
    ""chip.description"" : ""TF1""
}
```

## **Troubleshooting result**

Paste troubleshooting result.
```
* Error: SPP requires control inputs. Define control input files (chip.ctl_*) in an input JSON file.
```
",Reemann,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/236
MDU6SXNzdWU5OTM4ODkwNjY=,inquiry about reproducibility results,OPEN,2021-09-11T17:23:58Z,2021-09-11T17:23:58Z,,"I got two output document (""overlap_ reproducibility"" and ""idr_ reproducibility"") for reproducibility analysis from SPP. But I don't know the difference between them. How should I go about choosing? Looking forward to your reply. ",monnneee,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/237
I_kwDOBrDQms48bd86,Failed to evaluate input error when running pipeline,OPEN,2021-10-01T23:17:32Z,2021-10-21T01:59:07Z,,"## **Describe the bug**
I can't seem to run the pipeline, it keeps saying Failed to evaluate input 'fastqs_rep1_R1' (reason 1 of 1): No coercion defined from '""/oak/stanford/groups/akundaje/kmualim/06062021_ChromModelling/fastq/ENCFF680HKS.fastq.gz""' of type 'spray.json.JsString' to 'Array[File]'. 

## **OS/Platform**
- OS/Platform: Stanford Sherlock
- Conda version: conda 4.10.3
- Pipeline version: v1.9.0
- Caper version: running caper --version takes forever for some reason. 

## **Input JSON file**
```json
{
    ""chip.ctl_fastqs_rep1_R1"": [ ""/oak/stanford/groups/akundaje/kmualim/06062021_ChromModelling/fastq/ENCFF884PXT.fastq.gz""],
    ""chip.ctl_fastqs_rep2_R1"": [ ""/oak/stanford/groups/akundaje/kmualim/06062021_ChromModelling/fastq/ENCFF884PXT.fastq.gz""],
    ""chip.enable_idr"": ""true"",
    ""chip.fastqs_rep1_R1"": [ ""/oak/stanford/groups/akundaje/kmualim/06062021_ChromModelling/fastq/ENCFF247YSO.fastq.gz""],
    ""chip.fastqs_rep2_R1"": [ ""/oak/stanford/groups/akundaje/kmualim/06062021_ChromModelling/fastq/ENCFF453TXD.fastq.gz""],
    ""chip.genome.tsv"": ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v3/hg38.tsv"",
    ""chip.idr_thresh"": 0.05,
    ""chip.paired_end"": ""false"",
    ""chip.peak_caller"": ""macs2"",
    ""chip.pipeline_type"": ""tf"",
    ""chip.title"": ""AKAP8-human_HepG2""
}
```

## **Troubleshooting result**

Unfortunately, because the Caper server dies, I am unable to use caper troubleshoot to diagnose. cromwell.out is empty since I'm assuming the workflow doesn't start due to the failure in evaluating the input above. 
```
",kmualim,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/238
I_kwDOBrDQms49SuZQ,Example Chip-seq JSON not working,CLOSED,2021-10-17T13:06:16Z,2021-10-21T01:55:46Z,2021-10-21T01:55:46Z,"## Describe the bug
I'm trying to set up the Encode CHIP-seq pipeline and have it run on my computer, but running into issues with the following errors coming up: ""Bad output 'align_ctl.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'"" as listed below, I've tried a number of things like using a more recent version of cromwell/womtools (v70). My directory doesn't have issues with soft-linking. It seems like the issue is specifically with indexing the bam files, the default from the workflow is to use samtools 1.9 and there are more recent versions like 1.13 not sure if that is contributing.  Of note I did have to downgrade the tbb library to 2020.2 version, the workflow wasn't able to find it. 

## OS/Platform
- OS/Platform: MacOS 11.6
- Conda version: 4.10.3.
- Pipeline version: 1.0
- Caper version: 1.6.3

## Caper configuration file
backend=local

Hashing strategy for call-caching (3 choices)
This parameter is for local (local/slurm/sge/pbs) backend only.
This is important for call-caching,
which means re-using outputs from previous/failed workflows.
Cache will miss if different strategy is used.
""file"" method has been default for all old versions of Caper<1.0.
""path+modtime"" is a new default for Caper>=1.0,
file: use md5sum hash (slow).
path: use path.
path+modtime: use path and modification time.
local-hash-strat=path+modtime

Local directory for localized files and Cromwell's intermediate files
If not defined, Caper will make .caper_tmp/ on local-out-dir or CWD.
/tmp is not recommended here since Caper store all localized data files
on this directory (e.g. input FASTQs defined as URLs in input JSON).
local-loc-dir=

cromwell=/Users/grevetjd/.caper/cromwell_jar/cromwell-59.jar
womtool=/Users/grevetjd/.caper/womtool_jar/womtool-59.jar

## Input JSON file
https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI_subsampled_chr19_only.json

## Troubleshooting result

[
    {
        ""message"": ""Workflow failed"",
        ""causedBy"": [
            {
                ""message"": ""Failed to evaluate job outputs"",
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ]
            },
            {
                ""message"": ""Failed to evaluate job outputs"",
                ""causedBy"": [
                    {
                        ""message"": ""Bad output 'align_R1.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'"",
                        ""causedBy"": []
                    }
                ]
            },
            {
                ""message"": ""Failed to evaluate job outputs"",
                ""causedBy"": [
                    {
                        ""message"": ""Bad output 'align_ctl.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'"",
                        ""causedBy"": []
                    }
                ]
            },
            {
                ""message"": ""Failed to evaluate job outputs"",
                ""causedBy"": [
                    {
                        ""message"": ""Bad output 'align_R1.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'"",
                        ""causedBy"": []
                    }
                ]
            },
            {
                ""message"": ""Failed to evaluate job outputs"",
                ""causedBy"": [
                    {
                        ""message"": ""Bad output 'align.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'"",
                        ""causedBy"": []
                    }
                ]
            },
            {
                ""causedBy"": [
                    {
                        ""causedBy"": [],
                        ""message"": ""Bad output 'align_ctl.bai': Bad array access glob(\""*.bai\"")[0]: Array size 0 does not have an index value '0'""
                    }
                ],
                ""message"": ""Failed to evaluate job outputs""
            }
        ]
    }
]

",grevetjd,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/240
I_kwDOBrDQms493b8c,chip-seq-pipeline2 run with conda on linux with ERROR,CLOSED,2021-10-27T23:28:00Z,2022-02-23T23:09:18Z,2022-02-23T23:09:18Z,"I used chip-seq-pipeline from ENCODE and wanted to switch to this new version. Unfortunately, I can not get it run on Linux. I tried to follow the instructions to install all required packages etc. Then I cd into chip-seq-pipeline2, where chip.croo.v5.json and chip.wdl located. I tried to run the test as below:

caper run chip.wdl 
[CaperURI] copying from url to local, src: https://github.com/broadinstitute/cromwell/releases/download/47/cromwell-47.jar
[CaperURI] copying skipped, target: /home/ysun/.caper/cromwell_jar/cromwell-47.jar
[CaperURI] copying from url to local, src: https://github.com/broadinstitute/cromwell/releases/download/47/womtool-47.jar
[CaperURI] copying skipped, target: /home/ysun/.caper/womtool_jar/womtool-47.jar
[Caper] Validating WDL/input JSON with womtool...
Required workflow input 'chip.pipeline_type' not specified
[Caper] Error (womtool): WDL or input JSON is invalid.


Do you know what is the problem here? I can not find the manual or document to run chip-seq-pipeline2 on local Linux. Would you mind pointing me to that if possible? I followed the instructions for the json input files but have no idea about how, if need, to generate the chip.wdl file. I am sorry if it's a very basic question. I just felt very lost here.",yingsun-ucsd,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/242
I_kwDOBrDQms4-7IJC,Job chip.spp_pooled:NA:1 exited with return code 1,OPEN,2021-11-17T04:17:11Z,2021-11-17T04:17:11Z,,"## **Describe the bug**
Have never had trouble using the chip-seq pipeline but with newly generated sequencing reads for a TF the pipeline fails. If I run this pipeline without input controls using histone pipeline type it works fine. Any help would be greatly appreciated and happy to fill in missing gaps of info to solve the issue.


## **OS/Platform**
- OS/Platform: [e.g. Ubuntu 18.04, Google Cloud, Stanford Sherlock/SCG cluster, ...]
- Conda version: If you used Conda (`$ conda --version`).
- Pipeline version: [e.g. v1.6.0]
- Caper version: [e.g. v1.2.0]

chip-seq-pipeline-v1.2.0
using the UCSD TSCC cluster - TSCC uses the TORQUE Resource Manager (also known by its historical name Portable Batch System, or PBS) with the Maui Cluster Scheduler to define and manage job queues

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
PASTE CAPER CONF CONTENTS HERE
```

## **Input JSON file**
Paste contents of your input JSON file.
```json

{
    ""chip.genome_tsv"" : ""../../genome_database/mm10.tsv"",
    ""chip.pipeline_type"" : ""tf"",

    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.paired_end"" : false,
    ""chip.ctl_paired_end"" : false,

    ""chip.fastqs_rep1_R1"" : [ ""/projects/ps-yeolab4/t_cell_p01/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/igm-storage2.ucsd.edu/211104_A00953_0441_BH25C5DSX3/A1_S29_L003_R1_001.fastq.gz"",
                              ""/projects/ps-yeolab4/t_cell_p01/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/igm-storage2.ucsd.edu/211104_A00953_0441_BH25C5DSX3/A1_S29_L003_R2_001.fastq.gz"" ],
    ""chip.fastqs_rep2_R1"" : [ ""/projects/ps-yeolab4/t_cell_p01/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/igm-storage2.ucsd.edu/211104_A00953_0441_BH25C5DSX3/A2_S30_L003_R1_001.fastq.gz"", 
                              ""/projects/ps-yeolab4/t_cell_p01/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/igm-storage2.ucsd.edu/211104_A00953_0441_BH25C5DSX3/A2_S30_L003_R2_001.fastq.gz"" ],
    ""chip.ctl_fastqs_rep1_R1"" : [ ""/projects/ps-yeolab4/t_cell_p01/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/igm-storage2.ucsd.edu/211104_A00953_0441_BH25C5DSX3/A12input_S33_L003_R1_001.fastq.gz"", 
                                  ""/projects/ps-yeolab4/t_cell_p01/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/igm-storage2.ucsd.edu/211104_A00953_0441_BH25C5DSX3/A12input_S33_L003_R2_001.fastq.gz"" ],
    ""chip.ctl_fastqs_rep2_R1"" : [ ""/projects/ps-yeolab4/t_cell_p01/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/igm-storage2.ucsd.edu/211104_A00953_0441_BH25C5DSX3/A12input_S33_L003_R1_001.fastq.gz"", 
                                  ""/projects/ps-yeolab4/t_cell_p01/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/igm-storage2.ucsd.edu/211104_A00953_0441_BH25C5DSX3/A12input_S33_L003_R2_001.fastq.gz"" ],

    ""chip.disable_fingerprint"" : false,
    ""chip.enable_count_signal_track"" : false,

    ""chip.dup_marker"" : ""picard"",

    ""chip.mapq_thresh"" : 30,
    ""chip.no_dup_removal"" : false,

    ""chip.mito_chr_name"" : ""chrM"",
    ""chip.regex_filter_reads"" : ""chrM"",
    ""chip.subsample_reads"" : 0,
    ""chip.ctl_subsample_reads"" : 0,
    ""chip.xcor_subsample_reads"" : 15000000,

    ""chip.keep_irregular_chr_in_bfilt_peak"" : false,
    
    ""chip.always_use_pooled_ctl"" : false,
    ""chip.ctl_depth_ratio"" : 1.2,

    ""chip.macs2_cap_num_peak"" : 500000,
    ""chip.pval_thresh"" : 0.01,
    ""chip.idr_thresh"" : 0.05,
    ""chip.spp_cap_num_peak"" : 300000

}


```



## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
```
[2021-11-15 20:46:44,13] [error] WorkflowManagerActor Workflow 3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd failed (during ExecutingWorkflowState): Job chip.spp_pooled:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.
Check the content of stderr for potential additional information: /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp_pooled/execution/stderr.
 Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_spp.py"", line 115, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_spp.py"", line 90, in main
    args.fraglen, args.cap_num_peak, args.nth, args.out_dir)
  File ""/software/chip-seq-pipeline/src/encode_spp.py"", line 67, in spp
    run_shell_cmd(cmd0)
  File ""/software/chip-seq-pipeline/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=55953, PGID=55953, RC=1
STDERR=Loading required package: caTools
Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf
Error in data.frame(..., check.names = FALSE) : 
  arguments imply differing number of rows: 1, 0
Calls: find.binding.positions ... calculate.enrichment.estimates -> lapply -> FUN -> cbind -> cbind -> data.frame
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Execution halted
STDOUT=################
ChIP data: /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp_pooled/inputs/1290795626/A1_S29_L003_R1_001.merged.nodup.pooled.tagAlign.gz 
Control data: /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp_pooled/inputs/-70684730/A12input_S33_L003_R1_001.merged.nodup.pooled.tagAlign.gz 
strandshift(min): -500 
strandshift(step): 5 
strandshift(max) 1500 
user-defined peak shift 278 
exclusion(min): 10 
exclusion(max): NaN 
num parallel nodes: NA 
FDR threshold: 0.01 
NumPeaks Threshold: 3e+05 
Output Directory: /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp_pooled/execution 
narrowPeak output file name: NA 
regionPeak output file name: A1_S29_L003_R1_001.merged.nodup.pooled_x_A12input_S33_L003_R1_001.merged.nodup.pooled.300K.regionPeak.gz.tmp 
Rdata filename: NA 
plot pdf filename: NA 
result filename: NA 
Overwrite files?: TRUE

Decompressing ChIP file
Decompressing control file
Reading ChIP tagAlign/BAM file /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp_pooled/inputs/1290795626/A1_S29_L003_R1_001.merged.nodup.pooled.tagAlign.gz 
opened /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp_pooled/tmp.b0c01532/RtmpjDCQfz/A1_S29_L003_R1_001.merged.nodup.pooled.tagAlignda9341e2f0e1
done. read 34521764 fragments
ChIP data read length 101 
[1] TRUE
Reading Control tagAlign/BAM file /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp_pooled/inputs/-70684730/A12input_S33_L003_R1_001.merged.nodup.pooled.tagAlign.gz 
opened /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp_pooled/tmp.b0c01532/RtmpjDCQfz/A12input_S33_L003_R1_001.merged.nodup.pooled.tagAlignda934c2e4208
done. read 3842312 fragments
Control data read length 101 
Calculating peak characteristics
Minimum cross-correlation value 0.3530526 
Minimum cross-correlation shift 1500 
Top 3 cross-correlation values 0.38962993307496 
Top 3 estimates for fragment length 278 
Window half size 585 
Phantom peak location 105 
Phantom peak Correlation 0.3735254 
Normalized Strand cross-correlation coefficient (NSC) 1.103603 
Relative Strand cross-correlation Coefficient (RSC) 1.786629 
Phantom Peak Quality Tag 2 
Removing read stacks
Finding peaks
finding background exclusion regions ... done
determining peaks on provided 1 control datasets:
using reversed signal for FDR calculations
bg.weight= 0.01381287  processing chr1 in 5 steps [.....] done ( 2254 positions)
processing chr10 in 4 steps [....] done ( 2062 positions)
processing chr11 in 3 steps [...] done ( 3013 positions)
processing chr12 in 3 steps [...] done ( 1651 positions)
processing chr13 in 3 steps [...] done ( 1418 positions)
processing chr14 in 4 steps [....] done ( 1393 positions)
processing chr15 in 3 steps [...] done ( 1715 positions)
processing chr16 in 3 steps [...] done ( 1190 positions)
processing chr17 in 3 steps [...] done ( 1868 positions)
processing chr18 in 3 steps [...] done ( 1124 positions)
processing chr19 in 2 steps [..] done ( 1217 positions)
processing chr1_GL456210_random in 1 steps [.] done (  positions)
processing chr1_GL456211_random in 1 steps [.] done ( 1 positions)
processing chr1_GL456212_random in 1 steps [.] done ( 0 positions)
processing chr1_GL456221_random in 1 steps [.] done ( 0 positions)
processing chr2 in 5 steps [.....] done ( 2931 positions)
processing chr3 in 4 steps [....] done ( 1707 positions)
processing chr4 in 4 steps [....] done ( 2771 positions)
processing chr4_GL456216_random in 1 steps [.] done ( 9 positions)
processing chr4_JH584295_random in 1 steps [.] done ( 1 positions)
processing chr5 in 4 steps [....] done ( 2749 positions)
processing chr5_GL456354_random in 1 steps [.] done ( 0 positions)
processing chr5_JH584299_random in 1 steps [.] done (  positions)
processing chr6 in 4 steps [....] done ( 1828 positions)
processing chr7 in 4 steps [....] done ( 2744 positions)
processing chr8 in 4 steps [....] done ( 2387 positions)
processing chr9 in 4 steps [....] done ( 2157 positions)
processing chrUn_GL456239 in 1 steps [.] done ( 6 positions)
processing chrUn_GL456360 in 1 steps [.] done (  positions)
processing chrUn_GL456366 in 1 steps [.] done (  positions)
processing chrUn_GL456367 in 1 steps [.] done ( 0 positions)
processing chrUn_GL456368 in 1 steps [.] done (  positions)
processing chrUn_GL456370 in 1 steps [.] done ( 5 positions)
processing chrUn_GL456378 in 1 steps [.] done ( 1 positions)
processing chrUn_GL456379 in 1 steps [.] done ( 0 positions)
processing chrUn_GL456383 in 1 steps [.] done ( 18 positions)
processing chrUn_GL456389 in 1 steps [.] done ( 25 positions)
processing chrUn_GL456390 in 1 steps [.] done ( 12 positions)
processing chrUn_GL456392 in 1 steps [.] done ( 17 positions)
processing chrUn_GL456393 in 1 steps [.] done ( 7 positions)
processing chrUn_GL456394 in 1 steps [.] done (  positions)
processing chrUn_GL456396 in 1 steps [.] done ( 8 positions)
processing chrUn_JH584304 in 1 steps [.] done ( 87 positions)
processing chrX in 5 steps [.....] done ( 1097 positions)
processing chrX_GL456233_random in 1 steps [.] done ( 1 positions)
processing chrY in 3 steps [...] done ( 14 positions)
excluding systematic background anomalies ... done
determining peaks on real data:
bg.weight= 72.39624  processing chr1 in 5 steps [.....] done ( 133720 positions)
processing chr10 in 4 steps [....] done ( 91669 positions)
processing chr11 in 3 steps [...] done ( 106641 positions)
processing chr12 in 3 steps [...] done ( 84280 positions)
processing chr13 in 3 steps [...] done ( 84632 positions)
processing chr14 in 4 steps [....] done ( 80282 positions)
processing chr15 in 3 steps [...] done ( 76517 positions)
processing chr16 in 3 steps [...] done ( 65592 positions)
processing chr17 in 3 steps [...] done ( 75258 positions)
processing chr18 in 3 steps [...] done ( 63538 positions)
processing chr19 in 2 steps [..] done ( 47433 positions)
processing chr1_GL456210_random in 1 steps [.] done ( 52 positions)
processing chr1_GL456211_random in 1 steps [.] done ( 89 positions)
processing chr1_GL456212_random in 1 steps [.] done ( 37 positions)
processing chr1_GL456221_random in 1 steps [.] done ( 52 positions)
processing chr2 in 5 steps [.....] done ( 136143 positions)
processing chr3 in 4 steps [....] done ( 102345 positions)
processing chr4 in 4 steps [....] done ( 116627 positions)
processing chr4_GL456216_random in 1 steps [.] done ( 33 positions)
processing chr4_JH584292_random in 1 steps [.] done ( 9 positions)
processing chr4_JH584295_random in 1 steps [.] done ( 2 positions)
processing chr5 in 4 steps [....] done ( 119629 positions)
processing chr5_GL456354_random in 1 steps [.] done ( 4 positions)
processing chr5_JH584296_random in 1 steps [.] done ( 1 positions)
processing chr5_JH584297_random in 1 steps [.] done ( 3 positions)
processing chr5_JH584299_random in 1 steps [.] done ( 61 positions)
processing chr6 in 4 steps [....] done ( 104701 positions)
processing chr7 in 4 steps [....] done ( 110894 positions)
processing chr8 in 4 steps [....] done ( 99332 positions)
processing chr9 in 4 steps [....] done ( 99253 positions)
processing chrUn_GL456239 in 1 steps [.] done ( 47 positions)
processing chrUn_GL456359 in 1 steps [.] done ( 14 positions)
processing chrUn_GL456360 in 1 steps [.] done ( 20 positions)
processing chrUn_GL456366 in 1 steps [.] done ( 20 positions)
processing chrUn_GL456367 in 1 steps [.] done ( 27 positions)
processing chrUn_GL456368 in 1 steps [.] done ( 6 positions)
processing chrUn_GL456370 in 1 steps [.] done ( 14 positions)
processing chrUn_GL456372 in 1 steps [.] done ( 16 positions)
processing chrUn_GL456378 in 1 steps [.] done ( 23 positions)
processing chrUn_GL456379 in 1 steps [.] done ( 36 positions)
processing chrUn_GL456381 in 1 steps [.] done ( 30 positions)
processing chrUn_GL456382 in 1 steps [.] done ( 10 positions)
processing chrUn_GL456383 in 1 steps [.] done ( 17 positions)
processing chrUn_GL456385 in 1 steps [.] done ( 16 positions)
processing chrUn_GL456387 in 1 steps [.] done ( 29 positions)
processing chrUn_GL456389 in 1 steps [.] done ( 15 positions)
processing chrUn_GL456390 in 1 steps [.] done ( 9 positions)
processing chrUn_GL456392 in 1 steps [.] done ( 15 positions)
processing chrUn_GL456393 in 1 steps [.] done ( 61 positions)
processing chrUn_GL456394 in 1 steps [.] done ( 14 positions)
processing chrUn_GL456396 in 1 steps [.] done ( 20 positions)
processing chrUn_JH584304 in 1 steps [.] done ( 31 positions)
processing chrX in 5 steps [.....] done ( 81422 positions)
processing chrX_GL456233_random in 1 steps [.] done ( 164 positions)
processing chrY in 3 steps [...] done ( 37 positions)
excluding systematic background anomalies ... done
calculating statistical thresholds
FDR 0.99 threshold= 2.000003

Job chip.spp:1:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.
Check the content of stderr for potential additional information: /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp/shard-1/execution/stderr.
 Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_spp.py"", line 115, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_spp.py"", line 90, in main
    args.fraglen, args.cap_num_peak, args.nth, args.out_dir)
  File ""/software/chip-seq-pipeline/src/encode_spp.py"", line 67, in spp
    run_shell_cmd(cmd0)
  File ""/software/chip-seq-pipeline/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=53985, PGID=53985, RC=1
STDERR=Loading required package: caTools
Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf
3: In min(x) : no non-missing arguments to min; returning Inf
4: In max(x) : no non-missing arguments to max; returning -Inf
Error in data.frame(..., check.names = FALSE) : 
  arguments imply differing number of rows: 1, 0
Calls: find.binding.positions ... calculate.enrichment.estimates -> lapply -> FUN -> cbind -> cbind -> data.frame
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Execution halted
STDOUT=################
ChIP data: /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp/shard-1/inputs/-955210546/A2_S30_L003_R1_001.merged.nodup.tagAlign.gz 
Control data: /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp/shard-1/inputs/-1497687848/ctl_for_rep2.tagAlign.gz 
strandshift(min): -500 
strandshift(step): 5 
strandshift(max) 1500 
user-defined peak shift 250 
exclusion(min): 10 
exclusion(max): NaN 
num parallel nodes: NA 
FDR threshold: 0.01 
NumPeaks Threshold: 3e+05 
Output Directory: /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp/shard-1/execution 
narrowPeak output file name: NA 
regionPeak output file name: A2_S30_L003_R1_001.merged.nodup_x_ctl_for_rep2.300K.regionPeak.gz.tmp 
Rdata filename: NA 
plot pdf filename: NA 
result filename: NA 
Overwrite files?: TRUE

Decompressing ChIP file
Decompressing control file
Reading ChIP tagAlign/BAM file /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp/shard-1/inputs/-955210546/A2_S30_L003_R1_001.merged.nodup.tagAlign.gz 
opened /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp/shard-1/tmp.fa0bca6f/RtmpYou8In/A2_S30_L003_R1_001.merged.nodup.tagAlignd2ee2fc15669
done. read 10737662 fragments
ChIP data read length 101 
[1] TRUE
Reading Control tagAlign/BAM file /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp/shard-1/inputs/-1497687848/ctl_for_rep2.tagAlign.gz 
opened /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp/shard-1/tmp.fa0bca6f/RtmpYou8In/ctl_for_rep2.tagAlignd2ee5221dea4
done. read 3842312 fragments
Control data read length 101 
Calculating peak characteristics
Minimum cross-correlation value 0.1539102 
Minimum cross-correlation shift 1500 
Top 3 cross-correlation values 0.18106679260315 
Top 3 estimates for fragment length 250 
Window half size 545 
Phantom peak location 105 
Phantom peak Correlation 0.1672511 
Normalized Strand cross-correlation coefficient (NSC) 1.176444 
Relative Strand cross-correlation Coefficient (RSC) 2.035596 
Phantom Peak Quality Tag 2 
Removing read stacks
Finding peaks
finding background exclusion regions ... done
determining peaks on provided 1 control datasets:
using reversed signal for FDR calculations
bg.weight= 0.04478349  processing chr1 in 5 steps [.....] done ( 2157 positions)
processing chr10 in 4 steps [....] done ( 1976 positions)
processing chr11 in 3 steps [...] done ( 2909 positions)
processing chr12 in 3 steps [...] done ( 1599 positions)
processing chr13 in 3 steps [...] done ( 1364 positions)
processing chr14 in 4 steps [....] done ( 1347 positions)
processing chr15 in 3 steps [...] done ( 1688 positions)
processing chr16 in 3 steps [...] done ( 1138 positions)
processing chr17 in 3 steps [...] done ( 1817 positions)
processing chr18 in 3 steps [...] done ( 1074 positions)
processing chr19 in 2 steps [..] done ( 1191 positions)
processing chr1_GL456210_random in 1 steps [.] done (  positions)
processing chr1_GL456211_random in 1 steps [.] done ( 1 positions)
processing chr1_GL456212_random in 1 steps [.] done ( 0 positions)
processing chr1_GL456221_random in 1 steps [.] done ( 0 positions)
processing chr2 in 5 steps [.....] done ( 2803 positions)
processing chr3 in 4 steps [....] done ( 1629 positions)
processing chr4 in 4 steps [....] done ( 2678 positions)
processing chr4_GL456216_random in 1 steps [.] done ( 9 positions)
processing chr4_JH584295_random in 1 steps [.] done ( 1 positions)
processing chr5 in 4 steps [....] done ( 2655 positions)
processing chr5_GL456354_random in 1 steps [.] done ( 0 positions)
processing chr5_JH584299_random in 1 steps [.] done (  positions)
processing chr6 in 4 steps [....] done ( 1759 positions)
processing chr7 in 4 steps [....] done ( 2680 positions)
processing chr8 in 4 steps [....] done ( 2290 positions)
processing chr9 in 4 steps [....] done ( 2075 positions)
processing chrUn_GL456239 in 1 steps [.] done ( 6 positions)
processing chrUn_GL456360 in 1 steps [.] done (  positions)
processing chrUn_GL456366 in 1 steps [.] done (  positions)
processing chrUn_GL456367 in 1 steps [.] done ( 0 positions)
processing chrUn_GL456368 in 1 steps [.] done (  positions)
processing chrUn_GL456370 in 1 steps [.] done ( 4 positions)
processing chrUn_GL456378 in 1 steps [.] done ( 1 positions)
processing chrUn_GL456379 in 1 steps [.] done ( 0 positions)
processing chrUn_GL456383 in 1 steps [.] done ( 16 positions)
processing chrUn_GL456389 in 1 steps [.] done ( 20 positions)
processing chrUn_GL456390 in 1 steps [.] done ( 12 positions)
processing chrUn_GL456392 in 1 steps [.] done ( 16 positions)
processing chrUn_GL456393 in 1 steps [.] done ( 8 positions)
processing chrUn_GL456394 in 1 steps [.] done (  positions)
processing chrUn_GL456396 in 1 steps [.] done ( 9 positions)
processing chrUn_JH584304 in 1 steps [.] done ( 83 positions)
processing chrX in 5 steps [.....] done ( 1057 positions)
processing chrX_GL456233_random in 1 steps [.] done ( 1 positions)
processing chrY in 3 steps [...] done ( 12 positions)
excluding systematic background anomalies ... done
determining peaks on real data:
bg.weight= 22.32966  processing chr1 in 5 steps [.....] done ( 65134 positions)
processing chr10 in 4 steps [....] done ( 45853 positions)
processing chr11 in 3 steps [...] done ( 62439 positions)
processing chr12 in 3 steps [...] done ( 43166 positions)
processing chr13 in 3 steps [...] done ( 42334 positions)
processing chr14 in 4 steps [....] done ( 39377 positions)
processing chr15 in 3 steps [...] done ( 41042 positions)
processing chr16 in 3 steps [...] done ( 32583 positions)
processing chr17 in 3 steps [...] done ( 41752 positions)
processing chr18 in 3 steps [...] done ( 31887 positions)
processing chr19 in 2 steps [..] done ( 26155 positions)
processing chr1_GL456210_random in 1 steps [.] done ( 19 positions)
processing chr1_GL456211_random in 1 steps [.] done ( 37 positions)
processing chr1_GL456212_random in 1 steps [.] done ( 19 positions)
processing chr1_GL456221_random in 1 steps [.] done ( 17 positions)
processing chr2 in 5 steps [.....] done ( 72896 positions)
processing chr3 in 4 steps [....] done ( 47152 positions)
processing chr4 in 4 steps [....] done ( 64085 positions)
processing chr4_GL456216_random in 1 steps [.] done ( 10 positions)
processing chr4_JH584292_random in 1 steps [.] done ( 3 positions)
processing chr4_JH584295_random in 1 steps [.] done ( 1 positions)
processing chr5 in 4 steps [....] done ( 67255 positions)
processing chr5_GL456354_random in 1 steps [.] done ( 1 positions)
processing chr5_JH584296_random in 1 steps [.] done ( 1 positions)
processing chr5_JH584297_random in 1 steps [.] done ( 0 positions)
processing chr5_JH584299_random in 1 steps [.] done ( 15 positions)
processing chr6 in 4 steps [....] done ( 52499 positions)
processing chr7 in 4 steps [....] done ( 62334 positions)
processing chr8 in 4 steps [....] done ( 53691 positions)
processing chr9 in 4 steps [....] done ( 54463 positions)
processing chrUn_GL456239 in 1 steps [.] done ( 31 positions)
processing chrUn_GL456359 in 1 steps [.] done ( 7 positions)
processing chrUn_GL456360 in 1 steps [.] done ( 7 positions)
processing chrUn_GL456366 in 1 steps [.] done ( 11 positions)
processing chrUn_GL456367 in 1 steps [.] done ( 11 positions)
processing chrUn_GL456368 in 1 steps [.] done ( 3 positions)
processing chrUn_GL456370 in 1 steps [.] done ( 4 positions)
processing chrUn_GL456372 in 1 steps [.] done ( 7 positions)
processing chrUn_GL456378 in 1 steps [.] done ( 7 positions)
processing chrUn_GL456379 in 1 steps [.] done ( 14 positions)
processing chrUn_GL456381 in 1 steps [.] done ( 19 positions)
processing chrUn_GL456382 in 1 steps [.] done ( 4 positions)
processing chrUn_GL456383 in 1 steps [.] done ( 6 positions)
processing chrUn_GL456385 in 1 steps [.] done ( 7 positions)
processing chrUn_GL456387 in 1 steps [.] done ( 26 positions)
processing chrUn_GL456389 in 1 steps [.] done ( 9 positions)
processing chrUn_GL456390 in 1 steps [.] done ( 7 positions)
processing chrUn_GL456392 in 1 steps [.] done ( 8 positions)
processing chrUn_GL456393 in 1 steps [.] done ( 35 positions)
processing chrUn_GL456394 in 1 steps [.] done ( 13 positions)
processing chrUn_GL456396 in 1 steps [.] done ( 9 positions)
processing chrUn_JH584304 in 1 steps [.] done ( 36 positions)
processing chrX in 5 steps [.....] done ( 29988 positions)
processing chrX_GL456233_random in 1 steps [.] done ( 57 positions)
processing chrY in 3 steps [...] done ( 10 positions)
excluding systematic background anomalies ... done
calculating statistical thresholds
FDR 0.99 threshold= 2.000105

Job chip.spp_pr1:1:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.
Check the content of stderr for potential additional information: /projects/ps-yeolab4/t_cell_p01_project/home/jkanbar/rawdata/chipseq/ezh2/malat1KD/cromwell-executions/chip/3a5fa5c7-1e1d-43b2-a9b1-a232ea7882fd/call-spp_pr1/shard-1/execution/stderr.
 Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_spp.py"", line 115, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_spp.py"", line 90, in main
    args.fraglen, args.cap_num_peak, args.nth, args.out_dir)
  File ""/software/chip-seq-pipeline/src/encode_spp.py"", line 67, in spp
    run_shell_cmd(cmd0)
  File ""/software/chip-seq-pipeline/src/encode_common.py"", line 252, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=53986, PGID=53986, RC=1
STDERR=Loading required package: caTools
Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf
3: In min(x) : no non-missing arguments to min; returning Inf
4: In max(x) : no non-missing arguments to max; returning -Inf
Error in data.frame(..., check.names = FALSE) : 
  arguments imply differing number of rows: 1, 0
Calls: find.binding.positions ... calculate.enrichment.estimates -> lapply -> FUN -> cbind -> cbind -> data.frame
In addition: There were 50 or more warnings (use warnings() to see the first 50)
Execution halted

```
",jkanbar,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/249
I_kwDOBrDQms4_9PCZ,"bedClip: command not found,Fail  to run  chip.call_peak workflow when test example ",CLOSED,2021-12-07T07:36:21Z,2021-12-16T03:18:28Z,2021-12-16T03:18:27Z,"## **Describe the bug**
I just installed this workflow following the steps in the documentation, when I tested the example 
`caper run chip.wdl -i https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI_subsampled_chr19_only.json --conda`,Prompt that the task execution failed

By looking at the log, I found that it may be caused by the bedClip package when the call_peak is executed. 

There are two related errors. One is that there is no bedClip command in the environment.`/bin/bash: line 1: bedClip: command not found`,

the other is that the parameter truncate is not available `STDERR=-truncate is not a valid option`


## **OS/Platform**
- OS/Platform: [centos 7.2.1511]
- Conda version: conda 4.7.12
- Pipeline version: [2.1.1]
- Caper version: [2.1]

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
backend=local
local-hash-strat=path+modtime
local-loc-dir=

cromwell=/home/kchen/.caper/cromwell_jar/cromwell-65.jar
womtool=/home/kchen/.caper/womtool_jar/womtool-65.jar

```

## **Input JSON file**
```json
{
    ""chip.pipeline_type"" : ""tf"",
    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v3/hg38_chr19_chrM.tsv"",
    ""chip.fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep1.subsampled.25.fastq.gz""
    ],
    ""chip.fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep2.subsampled.20.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl1.subsampled.25.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl2.subsampled.25.fastq.gz""
    ],
    ""chip.paired_end"" : false,
    ""chip.title"" : ""ENCSR000DYI (subsampled 1/25, chr19_chrM only)"",
    ""chip.description"" : ""CEBPB ChIP-seq on human A549 produced by the Snyder lab""
}
```

## **Troubleshooting result**

Part of cromwell.out file information
```
Job chip.call_peak_ppr1:NA:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.
Check the content of stderr for potential additional information: /home/kchen/project/others_project/otherLab/xudan/myanalysis/encode/example/chip/bc868ec3-792e-45c0-8067-ce8def4e67f5/call-call_peak_ppr1/attempt-2/execution/stderr.
 [First 3000 bytes]:Traceback (most recent call last):
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 119, in main
    args.ctl_subsample, args.ctl_paired_end, args.nth, args.out_dir)
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 103, in spp
    bed_clip(rpeak_tmp2, chrsz, rpeak)
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_genomic.py"", line 710, in bed_clip
    run_shell_cmd(cmd)
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=14811, PGID=14811, RC=127, DURATION_SEC=0.0
STDERR=/bin/bash: line 1: bedClip: command not found
STDOUT=


Job chip.call_peak:1:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more det
ails.
Check the content of stderr for potential additional information: /home/kchen/project/others_project/otherLab/xudan/myanalysis/encode/example/chip/bc868ec3-79
2e-45c0-8067-ce8def4e67f5/call-call_peak/shard-1/attempt-2/execution/stderr.
 [First 3000 bytes]:Traceback (most recent call last):
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 119, in main
    args.ctl_subsample, args.ctl_paired_end, args.nth, args.out_dir)
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 103, in spp
    bed_clip(rpeak_tmp2, chrsz, rpeak)
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_genomic.py"", line 710, in bed_clip
    run_shell_cmd(cmd)
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=14687, PGID=14687, RC=127, DURATION_SEC=0.0
STDERR=/bin/bash: line 1: bedClip: command not found
STDOUT=

```

```
$cat /home/kchen/xudan/myanalysis/encode/example/chip/95f9dcf2-e713-4966-86c9-39a74705c2e1/call-call_peak/shard-1/execution/stderr
Traceback (most recent call last):
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 119, in main
    args.ctl_subsample, args.ctl_paired_end, args.nth, args.out_dir)
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 103, in spp
    bed_clip(rpeak_tmp2, chrsz, rpeak)
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_genomic.py"", line 710, in bed_clip
    run_shell_cmd(cmd)
  File ""/home/kchen/anaconda2/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=6347, PGID=6347, RC=255, DURATION_SEC=0.0
STDERR=-truncate is not a valid option
STDOUT=


```
[cromwell.out.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/7666394/cromwell.out.txt)


",ckfromCN,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/250
I_kwDOBrDQms5AHD92,An error occurs when running the process with test data,CLOSED,2021-12-09T13:47:37Z,2021-12-11T05:57:41Z,2021-12-11T05:57:41Z,"Hello
When I used the encode chip-seq pipeline test data set to run the process today, the following error occurred and I don't know how to solve it.

2021-12-09 21:09:27,028|caper.cromwell_workflow_monitor|INFO| Workflow: id=8414c8ac-ac89-4579-95d0-9c6ae64b2fcb, status=Failed
2021-12-09 21:10:03,614|caper.cromwell_metadata|INFO| Wrote metadata file. /home/zhong/chip-seq-pipeline2-2.1.2/chip/8414c8ac-ac89-4579-95d0-9c6ae64b2fcb/metadata.json
2021-12-09 21:10:03,614|caper.cromwell|INFO| Workflow failed. Auto-troubleshooting...
* Started troubleshooting workflow: id=8414c8ac-ac89-4579-95d0-9c6ae64b2fcb, status=Failed
* Found failures JSON object.
[
    {
        ""message"": ""Workflow failed"",
        ""causedBy"": [
            {
                ""message"": ""Job chip.xcor:1:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            },
            {
                ""message"": ""Job chip.xcor:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            }
        ]
    **}
]
* Recursively finding failures in calls (tasks)...

==== NAME=chip.xcor, STATUS=RetryableFailure, PARENT=
SHARD_IDX=0, RC=1, JOB_ID=1142
START=2021-12-09T13:05:43.498Z, END=2021-12-09T13:05:52.396Z
STDOUT=/home/zhong/chip-seq-pipeline2-2.1.2/chip/8414c8ac-ac89-4579-95d0-9c6ae64b2fcb/call-xcor/shard-0/execution/stdout
STDERR=/home/zhong/chip-seq-pipeline2-2.1.2/chip/8414c8ac-ac89-4579-95d0-9c6ae64b2fcb/call-xcor/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/home/zhong/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/home/zhong/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/home/zhong/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/home/zhong/miniconda**


How can I solve this kind of problem?
Is it to delete the original conda environment and reinstall it?
But after trying it, I found that it did not solve the problem",tyewaichung,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/253
I_kwDOBrDQms5ALoYC,libreadline.so.6: cannot open shared object file: No such file or directory,CLOSED,2021-12-10T12:21:08Z,2021-12-11T05:57:29Z,2021-12-11T05:57:21Z,"Hello,
This time there is a new problem
Check the content of stderr for potential additional information: /home/zhong/chip-seq-pipeline2-2.1.2/chip/f39b9431-ba54-4d6e-9894-9e5f32a42e3b/call-xcor/shard-0/attempt-2/execution/stderr.
 [First 3000 bytes]:Traceback (most recent call last):
  File ""/home/zhong/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/home/zhong/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/home/zhong/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/home/zhong/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=18196, PGID=18196, RC=127, DURATION_SEC=0.0
STDERR=/home/zhong/miniconda3/envs/encode-chip-seq-pipeline-spp/lib/R/bin/exec/R: error while loading shared libraries: libreadline.so.6: cannot open shared object file: No such file or directory
STDOUT=
[](url)
my system is ubuntu 18.0 
[cromwell.out.1.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/7692622/cromwell.out.1.txt)
",tyewaichung,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/254
I_kwDOBrDQms5BeLxI,pipeline fails trying to connect to auth.docker.io,OPEN,2022-01-10T22:01:46Z,2024-08-01T00:57:40Z,,"## **Description of bug**
I've installed caper and the pipeline in a conda environment and I'm trying to run it with example config/data from the repo thusly:

```
$ git clone https://github.com/encode-dcc/chip-seq-pipeline2
$ cd chip-seq-pipeline2
$ git checkout v2.0.1
$ cd ..
$ rm -rf ~/.caper/
$ caper init local
$ caper run ./chip-seq-pipeline2/chip.wdl -i ./chip-seq-pipeline2/dev/example_input_json/caper/ENCSR000DYI_subsampled_chr19_only_caper.json --conda
$ less /lscratch/29930830/cromwell.out
```
The pipeline does stuff and produces informational messages for about 15 minutes and then produces an error:

```
2022-01-10 13:57:25,383|caper.nb_subproc_thread|ERROR| Cromwell failed. returncode=-7
2022-01-10 13:57:25,384|caper.cli|ERROR| Check stdout in /lscratch/123456/cromwell.out
```

Inspecting `cromwell.out` turns up the following error (which appears to be the relevant problem?)

```
2022-01-10 13:25:17,159  INFO  - Request threw an exception on attempt #1. Retrying after 883 milliseconds
org.http4s.client.ConnectionFailure: Error connecting to https://auth.docker.io using address auth.docker.io:443 (unresolved: true)
```
along with a java stack trace, yadda yadda.  

Why is this trying to contact docker.io when I'm using the `--conda` directive?  Is there a workaround?  Thanks! 

## **OS/Platform**
- OS/Platform: CentOS-7 (NIH HPC Biowulf cluster)
- Conda version: 4.10.3
- Pipeline version: 2.0.1
- Caper version: 2.1.2

## **Caper configuration file**
```ini
backend=local

# Hashing strategy for call-caching (3 choices)
# This parameter is for local (local/slurm/sge/pbs/lsf) backend only.
# This is important for call-caching,
# which means re-using outputs from previous/failed workflows.
# Cache will miss if different strategy is used.
# ""file"" method has been default for all old versions of Caper<1.0.
# ""path+modtime"" is a new default for Caper>=1.0,
#   file: use md5sum hash (slow).
#   path: use path.
#   path+modtime: use path and modification time.
local-hash-strat=path+modtime

# Metadata DB for call-caching (reusing previous outputs):
# Cromwell supports restarting workflows based on a metadata DB
# DB is in-memory by default
#db=in-memory

# If you use 'caper server' then you can use one unified '--file-db'
# for all submitted workflows. In such case, uncomment the following two lines
# and defined file-db as an absolute path to store metadata of all workflows
#db=file
#file-db=

# If you use 'caper run' and want to use call-caching:
# Make sure to define different 'caper run ... --db file --file-db DB_PATH'
# for each pipeline run.
# But if you want to restart then define the same '--db file --file-db DB_PATH'
# then Caper will collect/re-use previous outputs without running the same task again
# Previous outputs will be simply hard/soft-linked.


# Local directory for localized files and Cromwell's intermediate files
# If not defined, Caper will make .caper_tmp/ on local-out-dir or CWD.
# /tmp is not recommended here since Caper store all localized data files
# on this directory (e.g. input FASTQs defined as URLs in input JSON).
local-loc-dir=

cromwell=/home/user/.caper/cromwell_jar/cromwell-65.jar
womtool=/home/user/.caper/womtool_jar/womtool-65.jar```

## **Input JSON file**
```json
{
    ""chip.pipeline_type"" : ""tf"",
    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v1/hg38_chr19_chrM_caper.tsv"",
    ""chip.fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep1.subsampled.25.fastq.gz""
    ],
    ""chip.fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep2.subsampled.20.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl1.subsampled.25.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl2.subsampled.25.fastq.gz""
    ],
    ""chip.paired_end"" : false,
    ""chip.title"" : ""ENCSR000DYI (subsampled 1/25, chr19_chrM only)"",
    ""chip.description"" : ""CEBPB ChIP-seq on human A549 produced by the Snyder lab""
}
```

## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
```
2022-01-10 13:57:25,383|caper.nb_subproc_thread|ERROR| Cromwell failed. returncode=-7
2022-01-10 13:57:25,384|caper.cli|ERROR| Check stdout in /lscratch/123456/cromwell.out.1

```
",GodloveD,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/256
I_kwDOBrDQms5BmvXM,caper.caper_workflow_opts|INFO| Conda environment name not found in WDL metadata. wdl=/net/waterston/vol2/home/gevirl/chip-seq-pipeline2-2.1.2/chip.wdl,OPEN,2022-01-12T18:46:07Z,2022-01-24T20:27:13Z,,"## **Describe the bug**
When I start a run with this:

caper run /net/waterston/vol2/home/gevirl/chip-seq-pipeline2-2.1.2/chip.wdl -i /net/waterston/vol9/ChipSeqPipeline/arid-1_RW12194_L4larva_1/6/pipeline.json --conda

I get the following error:

2022-01-11 09:57:17,891|caper.cli|INFO| Cromwell stdout: /net/waterston/vol9/ChipSeqPipeline/arid-1_RW12194_L4larva_1/cromwell.out.1
2022-01-11 09:57:17,904|caper.caper_base|INFO| Creating a timestamped temporary directory. /net/waterston/vol9/capertmp/chip/20220111_095717_900159
2022-01-11 09:57:17,904|caper.caper_runner|INFO| Localizing files on work_dir. /net/waterston/vol9/capertmp/chip/20220111_095717_900159
2022-01-11 09:57:19,247|caper.caper_workflow_opts|INFO| Conda environment name not found in WDL metadata. wdl=/net/waterston/vol2/home/gevirl/chip-seq-pipeline2-2.1.2/chip.wdl
2022-01-11 09:57:19,254|caper.cromwell|INFO| Validating WDL/inputs/imports with Womtool...
Traceback (most recent call last):
  File ""/nfs/waterston/miniconda3/envs/py39/bin/caper"", line 13, in <module>
    main()
  File ""/nfs/waterston/miniconda3/envs/py39/lib/python3.9/site-packages/caper/cli.py"", line 705, in main
    return runner(parsed_args, nonblocking_server=nonblocking_server)
  File ""/nfs/waterston/miniconda3/envs/py39/lib/python3.9/site-packages/caper/cli.py"", line 249, in runner
    subcmd_run(c, args)
  File ""/nfs/waterston/miniconda3/envs/py39/lib/python3.9/site-packages/caper/cli.py"", line 379, in subcmd_run
    thread = caper_runner.run(
  File ""/nfs/waterston/miniconda3/envs/py39/lib/python3.9/site-packages/caper/caper_runner.py"", line 462, in run
    self._cromwell.validate(wdl=wdl, inputs=inputs, imports=imports)
  File ""/nfs/waterston/miniconda3/envs/py39/lib/python3.9/site-packages/caper/cromwell.py"", line 154, in validate
    raise WomtoolValidationFailed(
caper.cromwell.WomtoolValidationFailed: RC=1
STDERR=WARNING: Unexpected input provided: chip.align_mem_mb (expected inputs: [chip.fastqs_rep3_R2, chip.align_ctl.trim_bp, chip.filter_disk_factor, chip.gensz, chip.trimmomatic_phred_score_format, chip.peaks_pr1, chip.ctl_nodup_bams, chip.ctl_depth_limit, chip.use_filt_pe_ta_for_xcor, chip.xcor_subsample_reads, chip.call_peak_time_hr, chip.fastqs_rep1_R1, chip.paired_ends, chip.align_R1.multimapping, chip.align.multimapping, chip.gc_bias_picard_java_heap, chip.fdr_thresh, chip.align_trimmomatic_java_heap, chip.align_bwa_mem_factor, chip.fastqs_rep9_R1, chip.ctl_depth_ratio, chip.filter_cpu, chip.xcor_exclusion_range_max, chip.pval_thresh, chip.fastqs_rep6_R2, chip.ctl_fastqs_rep4_R1, chip.fastqs_rep5_R2, chip.peak_pooled, chip.read_genome_tsv.null_s, chip.description, chip.ctl_paired_ends, chip.fastqs_rep4_R1, chip.macs2_signal_track_mem_factor, chip.fastqs_rep5_R1, chip.mapq_thresh, chip.ctl_fastqs_rep6_R1, chip.filter_R1.ref_fa, chip.macs2_signal_track_time_hr, chip.xcor_disk_factor, chip.ctl_fastqs_rep1_R2, chip.fastqs_rep7_R2, chip.filter_chrs, chip.ref_fa, chip.fastqs_rep6_R1, chip.ctl_fastqs_rep5_R2, chip.enable_jsd, chip.dup_marker, chip.call_peak_spp_disk_factor, chip.pool_ta.col, chip.docker, chip.use_bwa_mem_for_pe, chip.ctl_fastqs_rep2_R2, chip.fastqs_rep8_R2, chip.macs2_signal_track_disk_factor, chip.filter_time_hr, chip.peaks, chip.filter_no_dedup.ref_fa, chip.xcor_cpu, chip.call_peak_macs2_mem_factor, chip.peak_ppr1, chip.align_bowtie2_disk_factor, chip.call_peak_cpu, chip.enable_gc_bias, chip.ctl_fastqs_rep3_R1, chip.conda_macs2, chip.nodup_bams, chip.ctl_fastqs_rep6_R2, chip.ctl_fastqs_rep1_R1, chip.use_bowtie2_local_mode, chip.fastqs_rep10_R2, chip.ctl_paired_end, chip.pool_blacklist.prefix, chip.true_rep_only, chip.ctl_subsample_reads, chip.ctl_fastqs_rep8_R2, chip.align_R1.trimmomatic_java_heap, chip.subsample_ctl_mem_factor, chip.ctl_fastqs_rep7_R1, chip.spr_mem_factor, chip.ctl_fastqs_rep5_R1, chip.bam2ta_time_hr, chip.fastqs_rep2_R1, chip.pool_ta_pr1.col, chip.ctl_bams, chip.subsample_reads, chip.align_bowtie2_mem_factor, chip.aligner, chip.blacklist, chip.title, chip.bowtie2_idx_tar, chip.ctl_fastqs_rep2_R1, chip.singularity, chip.align.trim_bp, chip.align_only, chip.align_time_hr, chip.exp_ctl_depth_ratio_limit, chip.bam2ta_cpu, chip.ctl_fastqs_rep9_R1, chip.enable_count_signal_track, chip.call_peak_spp_mem_factor, chip.no_dup_removal, chip.paired_end, chip.chrsz, chip.jsd_mem_factor, chip.ctl_fastqs_rep10_R2, chip.qc_report.qc_json_ref, chip.xcor_trim_bp, chip.bwa_idx_tar, chip.conda, chip.fastqs_rep4_R2, chip.peak_caller, chip.peak_ppr2, chip.fastqs_rep2_R2, chip.ctl_fastqs_rep7_R2, chip.fastqs_rep10_R1, chip.ctl_fastqs_rep3_R2, chip.jsd_disk_factor, chip.fastqs_rep8_R1, chip.align_ctl.multimapping, chip.call_peak_macs2_disk_factor, chip.fraglen, chip.jsd_time_hr, chip.crop_length, chip.conda_spp, chip.genome_name, chip.fastqs_rep7_R1, chip.mito_chr_name, chip.cap_num_peak, chip.always_use_pooled_ctl, chip.ctl_fastqs_rep9_R2, chip.ctl_tas, chip.blacklist2, chip.align_cpu, chip.bwa_mem_read_len_limit, chip.custom_aligner_idx_tar, chip.tas, chip.pseudoreplication_random_seed, chip.fastqs_rep1_R2, chip.fastqs_rep3_R1, chip.filter_picard_java_heap, chip.filter_mem_factor, chip.regex_bfilt_peak_chr_name, chip.spr_disk_factor, chip.crop_length_tol, chip.genome_tsv, chip.pool_ta_pr2.col, chip.bams, chip.xcor_mem_factor, chip.ctl_fastqs_rep10_R1, chip.ctl_fastqs_rep4_R2, chip.fastqs_rep9_R2, chip.pipeline_type, chip.peaks_pr2, chip.align_bwa_disk_factor, chip.jsd_cpu, chip.bam2ta_disk_factor, chip.subsample_ctl_disk_factor, chip.custom_align_py, chip.redact_nodup_bam, chip.xcor_time_hr, chip.bam2ta_mem_factor, chip.ctl_fastqs_rep8_R1, chip.pool_ta_ctl.col, chip.xcor_exclusion_range_min, chip.idr_thresh])
WARNING: Unexpected input provided: chip.cap_num_peak_spp (expected inputs: [chip.fastqs_rep3_R2, chip.align_ctl.trim_bp, chip.filter_disk_factor, chip.gensz, chip.trimmomatic_phred_score_format, chip.peaks_pr1, chip.ctl_nodup_bams, chip.ctl_depth_limit, chip.use_filt_pe_ta_for_xcor, chip.xcor_subsample_reads, chip.call_peak_time_hr, chip.fastqs_rep1_R1, chip.paired_ends, chip.align_R1.multimapping, chip.align.multimapping, chip.gc_bias_picard_java_heap, chip.fdr_thresh, chip.align_trimmomatic_java_heap, chip.align_bwa_mem_factor, chip.fastqs_rep9_R1, chip.ctl_depth_ratio, chip.filter_cpu, chip.xcor_exclusion_range_max, chip.pval_thresh, chip.fastqs_rep6_R2, chip.ctl_fastqs_rep4_R1, chip.fastqs_rep5_R2, chip.peak_pooled, chip.read_genome_tsv.null_s, chip.description, chip.ctl_paired_ends, chip.fastqs_rep4_R1, chip.macs2_signal_track_mem_factor, chip.fastqs_rep5_R1, chip.mapq_thresh, chip.ctl_fastqs_rep6_R1, chip.filter_R1.ref_fa, chip.macs2_signal_track_time_hr, chip.xcor_disk_factor, chip.ctl_fastqs_rep1_R2, chip.fastqs_rep7_R2, chip.filter_chrs, chip.ref_fa, chip.fastqs_rep6_R1, chip.ctl_fastqs_rep5_R2, chip.enable_jsd, chip.dup_marker, chip.call_peak_spp_disk_factor, chip.pool_ta.col, chip.docker, chip.use_bwa_mem_for_pe, chip.ctl_fastqs_rep2_R2, chip.fastqs_rep8_R2, chip.macs2_signal_track_disk_factor, chip.filter_time_hr, chip.peaks, chip.filter_no_dedup.ref_fa, chip.xcor_cpu, chip.call_peak_macs2_mem_factor, chip.peak_ppr1, chip.align_bowtie2_disk_factor, chip.call_peak_cpu, chip.enable_gc_bias, chip.ctl_fastqs_rep3_R1, chip.conda_macs2, chip.nodup_bams, chip.ctl_fastqs_rep6_R2, chip.ctl_fastqs_rep1_R1, chip.use_bowtie2_local_mode, chip.fastqs_rep10_R2, chip.ctl_paired_end, chip.pool_blacklist.prefix, chip.true_rep_only, chip.ctl_subsample_reads, chip.ctl_fastqs_rep8_R2, chip.align_R1.trimmomatic_java_heap, chip.subsample_ctl_mem_factor, chip.ctl_fastqs_rep7_R1, chip.spr_mem_factor, chip.ctl_fastqs_rep5_R1, chip.bam2ta_time_hr, chip.fastqs_rep2_R1, chip.pool_ta_pr1.col, chip.ctl_bams, chip.subsample_reads, chip.align_bowtie2_mem_factor, chip.aligner, chip.blacklist, chip.title, chip.bowtie2_idx_tar, chip.ctl_fastqs_rep2_R1, chip.singularity, chip.align.trim_bp, chip.align_only, chip.align_time_hr, chip.exp_ctl_depth_ratio_limit, chip.bam2ta_cpu, chip.ctl_fastqs_rep9_R1, chip.enable_count_signal_track, chip.call_peak_spp_mem_factor, chip.no_dup_removal, chip.paired_end, chip.chrsz, chip.jsd_mem_factor, chip.ctl_fastqs_rep10_R2, chip.qc_report.qc_json_ref, chip.xcor_trim_bp, chip.bwa_idx_tar, chip.conda, chip.fastqs_rep4_R2, chip.peak_caller, chip.peak_ppr2, chip.fastqs_rep2_R2, chip.ctl_fastqs_rep7_R2, chip.fastqs_rep10_R1, chip.ctl_fastqs_rep3_R2, chip.jsd_disk_factor, chip.fastqs_rep8_R1, chip.align_ctl.multimapping, chip.call_peak_macs2_disk_factor, chip.fraglen, chip.jsd_time_hr, chip.crop_length, chip.conda_spp, chip.genome_name, chip.fastqs_rep7_R1, chip.mito_chr_name, chip.cap_num_peak, chip.always_use_pooled_ctl, chip.ctl_fastqs_rep9_R2, chip.ctl_tas, chip.blacklist2, chip.align_cpu, chip.bwa_mem_read_len_limit, chip.custom_aligner_idx_tar, chip.tas, chip.pseudoreplication_random_seed, chip.fastqs_rep1_R2, chip.fastqs_rep3_R1, chip.filter_picard_java_heap, chip.filter_mem_factor, chip.regex_bfilt_peak_chr_name, chip.spr_disk_factor, chip.crop_length_tol, chip.genome_tsv, chip.pool_ta_pr2.col, chip.bams, chip.xcor_mem_factor, chip.ctl_fastqs_rep10_R1, chip.ctl_fastqs_rep4_R2, chip.fastqs_rep9_R2, chip.pipeline_type, chip.peaks_pr2, chip.align_bwa_disk_factor, chip.jsd_cpu, chip.bam2ta_disk_factor, chip.subsample_ctl_disk_factor, chip.custom_align_py, chip.redact_nodup_bam, chip.xcor_time_hr, chip.bam2ta_mem_factor, chip.ctl_fastqs_rep8_R1, chip.pool_ta_ctl.col, chip.xcor_exclusion_range_min, chip.idr_thresh])
WARNING: Unexpected input provided: chip.call_peak_mem_mb (expected inputs: [chip.fastqs_rep3_R2, chip.align_ctl.trim_bp, chip.filter_disk_factor, chip.gensz, chip.trimmomatic_phred_score_format, chip.peaks_pr1, chip.ctl_nodup_bams, chip.ctl_depth_limit, chip.use_filt_pe_ta_for_xcor, chip.xcor_subsample_reads, chip.call_peak_time_hr, chip.fastqs_rep1_R1, chip.paired_ends, chip.align_R1.multimapping, chip.align.multimapping, chip.gc_bias_picard_java_heap, chip.fdr_thresh, chip.align_trimmomatic_java_heap, chip.align_bwa_mem_factor, chip.fastqs_rep9_R1, chip.ctl_depth_ratio, chip.filter_cpu, chip.xcor_exclusion_range_max, chip.pval_thresh, chip.fastqs_rep6_R2, chip.ctl_fastqs_rep4_R1, chip.fastqs_rep5_R2, chip.peak_pooled, chip.read_genome_tsv.null_s, chip.description, chip.ctl_paired_ends, chip.fastqs_rep4_R1, chip.macs2_signal_track_mem_factor, chip.fastqs_rep5_R1, chip.mapq_thresh, chip.ctl_fastqs_rep6_R1, chip.filter_R1.ref_fa, chip.macs2_signal_track_time_hr, chip.xcor_disk_factor, chip.ctl_fastqs_rep1_R2, chip.fastqs_rep7_R2, chip.filter_chrs, chip.ref_fa, chip.fastqs_rep6_R1, chip.ctl_fastqs_rep5_R2, chip.enable_jsd, chip.dup_marker, chip.call_peak_spp_disk_factor, chip.pool_ta.col, chip.docker, chip.use_bwa_mem_for_pe, chip.ctl_fastqs_rep2_R2, chip.fastqs_rep8_R2, chip.macs2_signal_track_disk_factor, chip.filter_time_hr, chip.peaks, chip.filter_no_dedup.ref_fa, chip.xcor_cpu, chip.call_peak_macs2_mem_factor, chip.peak_ppr1, chip.align_bowtie2_disk_factor, chip.call_peak_cpu, chip.enable_gc_bias, chip.ctl_fastqs_rep3_R1, chip.conda_macs2, chip.nodup_bams, chip.ctl_fastqs_rep6_R2, chip.ctl_fastqs_rep1_R1, chip.use_bowtie2_local_mode, chip.fastqs_rep10_R2, chip.ctl_paired_end, chip.pool_blacklist.prefix, chip.true_rep_only, chip.ctl_subsample_reads, chip.ctl_fastqs_rep8_R2, chip.align_R1.trimmomatic_java_heap, chip.subsample_ctl_mem_factor, chip.ctl_fastqs_rep7_R1, chip.spr_mem_factor, chip.ctl_fastqs_rep5_R1, chip.bam2ta_time_hr, chip.fastqs_rep2_R1, chip.pool_ta_pr1.col, chip.ctl_bams, chip.subsample_reads, chip.align_bowtie2_mem_factor, chip.aligner, chip.blacklist, chip.title, chip.bowtie2_idx_tar, chip.ctl_fastqs_rep2_R1, chip.singularity, chip.align.trim_bp, chip.align_only, chip.align_time_hr, chip.exp_ctl_depth_ratio_limit, chip.bam2ta_cpu, chip.ctl_fastqs_rep9_R1, chip.enable_count_signal_track, chip.call_peak_spp_mem_factor, chip.no_dup_removal, chip.paired_end, chip.chrsz, chip.jsd_mem_factor, chip.ctl_fastqs_rep10_R2, chip.qc_report.qc_json_ref, chip.xcor_trim_bp, chip.bwa_idx_tar, chip.conda, chip.fastqs_rep4_R2, chip.peak_caller, chip.peak_ppr2, chip.fastqs_rep2_R2, chip.ctl_fastqs_rep7_R2, chip.fastqs_rep10_R1, chip.ctl_fastqs_rep3_R2, chip.jsd_disk_factor, chip.fastqs_rep8_R1, chip.align_ctl.multimapping, chip.call_peak_macs2_disk_factor, chip.fraglen, chip.jsd_time_hr, chip.crop_length, chip.conda_spp, chip.genome_name, chip.fastqs_rep7_R1, chip.mito_chr_name, chip.cap_num_peak, chip.always_use_pooled_ctl, chip.ctl_fastqs_rep9_R2, chip.ctl_tas, chip.blacklist2, chip.align_cpu, chip.bwa_mem_read_len_limit, chip.custom_aligner_idx_tar, chip.tas, chip.pseudoreplication_random_seed, chip.fastqs_rep1_R2, chip.fastqs_rep3_R1, chip.filter_picard_java_heap, chip.filter_mem_factor, chip.regex_bfilt_peak_chr_name, chip.spr_disk_factor, chip.crop_length_tol, chip.genome_tsv, chip.pool_ta_pr2.col, chip.bams, chip.xcor_mem_factor, chip.ctl_fastqs_rep10_R1, chip.ctl_fastqs_rep4_R2, chip.fastqs_rep9_R2, chip.pipeline_type, chip.peaks_pr2, chip.align_bwa_disk_factor, chip.jsd_cpu, chip.bam2ta_disk_factor, chip.subsample_ctl_disk_factor, chip.custom_align_py, chip.redact_nodup_bam, chip.xcor_time_hr, chip.bam2ta_mem_factor, chip.ctl_fastqs_rep8_R1, chip.pool_ta_ctl.col, chip.xcor_exclusion_range_min, chip.idr_thresh])

## **OS/Platform**
- OS/Platform: Centos 7
- Conda version: 4.8.3
- Pipeline version: [e.g. v1.6.0]
- Caper version: 2.1.2

## **Caper configuration file**

backend=sge

# Parallel environement is required, ask your administrator to create one
# If your cluster doesn't support PE then edit 'sge-resource-param'
# to fit your cluster's configuration.
sge-pe=serial


# This parameter is NOT for 'caper submit' BUT for 'caper run' and 'caper server' only.
# This resource parameter string will be passed to sbatch, qsub, bsub, ...
# You can customize it according to your cluster's configuration.

# Note that Cromwell's implicit type conversion (String to Integer)
# seems to be buggy for WomLong type memory variables (memory_mb and memory_gb).
# So be careful about using the + operator between WomLong and other types (String, even Int).
# For example, ${""--mem="" + memory_mb} will not work since memory_mb is WomLong.
# Use ${""if defined(memory_mb) then ""--mem="" else """"}{memory_mb}${""if defined(memory_mb) then ""mb "" else "" ""}
# See https://github.com/broadinstitute/cromwell/issues/4659 for details

# Cromwell's built-in variables (attributes defined in WDL task's runtime)
# Use them within ${} notation.
# - cpu: number of cores for a job (default = 1)
# - memory_mb, memory_gb: total memory for a job in MB, GB
#   * these are converted from 'memory' string attribute (including size unit)
#     defined in WDL task's runtime
# - time: time limit for a job in hour
# - gpu: specified gpu name or number of gpus (it's declared as String)

# Parallel environment of SGE:
# Find one with `$ qconf -spl` or ask you admin to add one if not exists.
# If your cluster works without PE then edit the below sge-resource-param
#sge-pe=serial
sge-resource-param=${if cpu > 1 then ""-pe "" + sge_pe + "" "" else """"} ${if cpu > 1 then cpu else """"} ${true=""-l h_vmem=$(expr "" false="""" defined(memory_mb)}${memory_mb}${true="" / "" false="""" 
defined(memory_mb)}${if defined(memory_mb) then cpu else """"}${true="")m"" false="""" defined(memory_mb)} ${true=""-l s_vmem=$(expr "" false="""" defined(memory_mb)}${memory_mb}$#{true="" / "" false="""" defined(memory_mb)}${if defined(memory_mb) then cpu else """"}${true="")m"" false="""" defined(memory_mb)} ${""-l h_rt="" + time + "":00:00""} ${""-l s_rt="" + time + "":00:00""} ${""-l gpu="" + gpu} 

# If needed uncomment and define any extra SGE qsub parameters here
# YOU CANNOT USE WDL SYNTAX AND CROMWELL BUILT-IN VARIABLES HERE
#sge-extra-param=

# Hashing strategy for call-caching (3 choices)
# This parameter is for local (local/slurm/sge/pbs/lsf) backend only.
# This is important for call-caching,
# which means re-using outputs from previous/failed workflows.
# Cache will miss if different strategy is used.
# ""file"" method has been default for all old versions of Caper<1.0.
# ""path+modtime"" is a new default for Caper>=1.0,
#   file: use md5sum hash (slow).
#   path: use path.
#   path+modtime: use path and modification time.
local-hash-strat=path+modtime

# Metadata DB for call-caching (reusing previous outputs):
# Cromwell supports restarting workflows based on a metadata DB
# DB is in-memory by default
#db=in-memory

# If you use 'caper server' then you can use one unified '--file-db'
# for all submitted workflows. In such case, uncomment the following two lines
# and defined file-db as an absolute path to store metadata of all workflows
#db=file
#file-db=

# If you use 'caper run' and want to use call-caching:
# Make sure to define different 'caper run ... --db file --file-db DB_PATH'
# for each pipeline run.
# But if you want to restart then define the same '--db file --file-db DB_PATH'
# then Caper will collect/re-use previous outputs without running the same task again
# Previous outputs will be simply hard/soft-linked.


# Local directory for localized files and Cromwell's intermediate files
# If not defined, Caper will make .caper_tmp/ on local-out-dir or CWD.
# /tmp is not recommended here since Caper store all localized data files
# on this directory (e.g. input FASTQs defined as URLs in input JSON).
local-loc-dir=/net/waterston/vol9/capertmp

cromwell=/net/waterston/vol2/home/gevirl/.caper/cromwell_jar/cromwell-65.jar
womtool=/net/waterston/vol2/home/gevirl/.caper/womtool_jar/womtool-65.jar


## **Input JSON file**
{""chip.title"":""arid-1_RW12194_L4larva_1_6"",""chip.description"":""gevirl"",""chip.always_use_pooled_ctl"":false,""chip.true_rep_only"":false,""chip.enable_count_signal_track"":true,""chip.aligner"":""bwa"",""chip.use_bwa_mem_for_pe"":true,""chip.align_only"":false,""chip.genome_tsv"":""/net/waterston/vol9/WS245chr/WS245chr.tsv"",""chip.peak_caller"":""spp"",""chip.pipeline_type"":""tf"",""chip.cap_num_peak_spp"":300000,""chip.idr_thresh"":0.01,""chip.call_peak_mem_mb"":16000,""chip.align_mem_mb"":20000,""chip.filter_picard_java_heap"":""4G"",""chip.fastqs_rep1_R1"":[""/net/waterston/vol9/ChipSeqPipeline/arid-1_RW12194_L4larva_1/ARDIP3_240_337_S33_L001_R1_001.fastq.gz""],""chip.fastqs_rep1_R2"":[""/net/waterston/vol9/ChipSeqPipeline/arid-1_RW12194_L4larva_1/ARDIP3_240_337_S33_L001_R2_001.fastq.gz""],""chip.fastqs_rep2_R1"":[""/net/waterston/vol9/ChipSeqPipeline/arid-1_RW12194_L4larva_1/ARDIP4_228_349_S34_L001_R1_001.fastq.gz""],""chip.fastqs_rep2_R2"":[""/net/waterston/vol9/ChipSeqPipeline/arid-1_RW12194_L4larva_1/ARDIP4_228_349_S34_L001_R2_001.fastq.gz""],""chip.paired_ends"":[true,true],""chip.ctl_fastqs_rep1_R1"":[""/net/waterston/vol9/ChipSeqPipeline/arid-1_RW12194_L4larva_1/ARDinp3_263_314_S39_L001_R1_001.fastq.gz""],""chip.ctl_fastqs_rep1_R2"":[""/net/waterston/vol9/ChipSeqPipeline/arid-1_RW12194_L4larva_1/ARDinp3_263_314_S39_L001_R2_001.fastq.gz""],""chip.ctl_paired_ends"":[true]}

## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
```
PASTE TROUBLESHOOTING RESULT HERE
```
",louisgevirtzman,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/257
I_kwDOBrDQms5CE19v,Unable to run caper on windows,CLOSED,2022-01-19T21:11:51Z,2022-03-01T08:33:40Z,2022-03-01T08:33:40Z,"hey team:

I have followed the steps mentioned in the README which involves pip3 install caper. When trying to do caper init on a windows 10 machine i get an error saying command not recognized. This is even after resetting my bashrc and tryin the export command mentioned. What can i do to solve this issue?

best",silentsilencee,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/258
I_kwDOBrDQms5CTSRh,"cc.plot.png, cc.fraglen, no such file or directory",CLOSED,2022-01-24T09:01:55Z,2022-02-03T03:21:26Z,2022-02-03T03:19:14Z,"When I run the command 

""caper run chip.wdl -i https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI_subsampled_chr19_only.json --conda"", 

it returns that 

""error while loading shared libraries: libreadline.so.6: cannot open shared object file: No such file or directory
STDOUT=
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/c38f96bf-ffcf-4f31-b063-3f901c0137ad/call-xcor/shard-1/attempt-2/execution/*.cc.plot.png': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/c38f96bf-ffcf-4f31-b063-3f901c0137ad/call-xcor/shard-1/attempt-2/execution/*.cc.fraglen.txt': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/c38f96bf-ffcf-4f31-b063-3f901c0137ad/call-xcor/shard-1/attempt-2/execution/*.cc.plot.pdf': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/c38f96bf-ffcf-4f31-b063-3f901c0137ad/call-xcor/shard-1/attempt-2/execution/*.cc.qc': No such file or directory


2022-01-24 00:55:43,410|caper.nb_subproc_thread|ERROR| Cromwell failed. returncode=1""

I am not too sure how to eliminate this error and get the json file to run.
",shirleytemples,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/259
I_kwDOBrDQms5CdRai,A question about the use of fragment length estimated from cross-correlation analysis.,CLOSED,2022-01-26T12:33:37Z,2022-01-26T13:41:00Z,2022-01-26T13:41:00Z,"## **Describe the bug**
Hello, I'm trying to run ENCODE ChIP-Seq pipeline by shell commands step-by-step picked up from your Python scripts instead of installing your pipeline. But I have a question about the use of fragment length estimated by cross-correlation analysis.

I don't know which replicate FASTQ file (I have two biological replicates) should be trimmed to 50bp, then run by cross-correlation analysis to get the estimated fragment length. And which estimated fragment length (At present, I estimate fragment length for both biological replicates) should be used for downstream peak calling. Because I have 9 tagAlign files (Rep1, Rep2, Pooled, and their pr1/2) to be called.

I'm really grateful for your help.

## **OS/Platform**
- OS/Platform: [e.g. Ubuntu 18.04, Google Cloud, Stanford Sherlock/SCG cluster, ...]
- Conda version: If you used Conda (`$ conda --version`).
- Pipeline version: [e.g. v1.6.0]
- Caper version: [e.g. v1.2.0]

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
PASTE CAPER CONF CONTENTS HERE
```

## **Input JSON file**
Paste contents of your input JSON file.
```json
PASTE INPUT JSON CONTENTS HERE
```

## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
```
PASTE TROUBLESHOOTING RESULT HERE
```
",yr-gh,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/260
I_kwDOBrDQms5DAq-S,call-xcor fails before peak calling,CLOSED,2022-02-04T14:13:17Z,2022-02-07T22:59:38Z,2022-02-07T22:59:38Z,"## **Describe the bug**
The pipeline fails when doing cross correlation analysis. Please see the errors below: 

* Found failures JSON object.
[
    {
        ""causedBy"": [
            {
                ""causedBy"": [],
                ""message"": ""Job chip.xcor:1:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            }
        ],
        ""message"": ""Workflow failed""
    }
]
* Recursively finding failures in calls (tasks)...

==== NAME=chip.xcor, STATUS=RetryableFailure, PARENT=
SHARD_IDX=1, RC=1, JOB_ID=402477
START=2022-02-04T03:58:57.092Z, END=2022-02-04T03:59:35.114Z
STDOUT=/work/wx74/chip-seq-pipeline2-results/OP_1/test/chip/15cee7a3-e687-47fb-aaf2-8e022481ee9a/call-xcor/shard-1/execution/stdout
STDERR=/work/wx74/chip-seq-pipeline2-results/OP_1/test/chip/15cee7a3-e687-47fb-aaf2-8e022481ee9a/call-xcor/shard-1/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/work/wx74/.conda/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/work/wx74/.conda/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/work/wx74/.conda/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/work/wx74/.conda/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=193447, PGID=193447, RC=1, DURATION_SEC=20.2
STDERR=Loading required package: caTools
Error in pdf(file = iparams$output.plot.file, width = 5, height = 5) : 
  invalid 'file' argument 'H3K4me1%OP9_TGCGCAAT_1.trim_50bp.srt.filt.no_chrM.15M.cc.plot.pdf'
Execution halted
 

## **OS/Platform**
- OS/Platform: [e.g. cluster]
- Conda version: If you used Conda (`conda 4.9.0`).
- Pipeline version: [e.g. v2.1.2]
- Caper version: [e.g. 2.1.2]

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
backend=slurm
slurm-partition=common
slurm-resource-param=-n 1 --ntasks-per-node=1 --cpus-per-task=${cpu} ${if defined(memory_mb) then ""--mem="" else """"}${memory_mb}${if defined(memory_mb) then ""M"" else """"} ${if defined(time) then ""--time="" else """"}${time*60} ${if defined(gpu) then ""--gres=gpu:"" else """"}${gpu} 

local-hash-strat=path+modtime
local-loc-dir=/work/wx74/chip-seq-pipeline2-results/OP_1/test2
cromwell=/hpc/home/wx74/.caper/cromwell_jar/cromwell-65.jar
womtool=/hpc/home/wx74/.caper/womtool_jar/womtool-65.jar
```

## **Input JSON file**
Paste contents of your input JSON file.
```json

{
    ""chip.title"" : ""H3K4me1_1_test"",
    ""chip.description"" : ""H3K4me1_1"",

    ""chip.pipeline_type"" : ""histone"",
    ""chip.peak_caller"" : ""macs2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""/chip-seq-pipeline2/genome/hg19.tsv"",
    ""chip.paired_end"" : true,
    ""chip.ctl_paired_end"" : true,

    ""chip.fastqs_rep1_R1"" : [ ""/originalSamples/fastq/OP25/H3K4me1%OP25_ATACTTGG_1.fq.gz""],
    ""chip.fastqs_rep1_R2"" : [ ""/originalSamples/fastq/OP25/H3K4me1%OP25_ATACTTGG_2.fq.gz""],
    ""chip.fastqs_rep2_R1"" : [ ""/originalSamples/fastq/OP9/H3K4me1%OP9_TGCGCAAT_1.fq.gz""],
    ""chip.fastqs_rep2_R2"" : [ ""/originalSamples/fastq/OP9/H3K4me1%OP9_TGCGCAAT_2.fq.gz""],

    ""chip.ctl_fastqs_rep1_R1"" : [ ""/originalSamples/fastq/OP25/H3%OP25_ATACTTGG_1.fq.gz""],
    ""chip.ctl_fastqs_rep1_R2"" : [ ""/originalSamples/fastq/OP25/H3%OP25_ATACTTGG_2.fq.gz""],
    ""chip.ctl_fastqs_rep2_R1"" : [ ""/originalSamples/fastq/OP9/H3%OP9_TGCGCAAT_1.fq.gz""],
    ""chip.ctl_fastqs_rep2_R2"" : [ ""/originalSamples/fastq/OP9/H3%OP9_TGCGCAAT_2.fq.gz""],


    ""chip.crop_length"" : 0,

    ""chip.mapq_thresh"" : 30,
    ""chip.dup_marker"" : ""picard"",
    ""chip.no_dup_removal"" : false,

    ""chip.subsample_reads"" : 0,
    ""chip.ctl_subsample_reads"" : 0,
    ""chip.xcor_subsample_reads"" : 15000000,

    ""chip.xcor_trim_bp"" : 50,
    ""chip.use_filt_pe_ta_for_xcor"" : false,

    ""chip.always_use_pooled_ctl"" : true,
    ""chip.ctl_depth_ratio"" : 1.2,

    ""chip.cap_num_peak"" : 500000,
    ""chip.pval_thresh"" : 0.01,
    ""chip.fdr_thresh"" : 0.01,
    ""chip.idr_thresh"" : 0.05,

    ""chip.enable_gc_bias"" : true,
    ""chip.enable_count_signal_track"" : false,

    ""chip.filter_chrs"" : [],

    ""chip.align_cpu"" : 6,
    ""chip.align_bowtie2_mem_factor"" : 0.15,
    ""chip.align_bwa_mem_factor"" : 1.0,
    ""chip.align_time_hr"" : 48,
    ""chip.align_bowtie2_disk_factor"" : 8.0,
    ""chip.align_bwa_disk_factor"" : 8.0,

    ""chip.filter_cpu"" : 4,
    ""chip.filter_mem_factor"" : 0.4,
    ""chip.filter_time_hr"" : 24,
    ""chip.filter_disk_factor"" : 8.0,

    ""chip.bam2ta_cpu"" : 2,
    ""chip.bam2ta_mem_factor"" : 0.35,
    ""chip.bam2ta_time_hr"" : 6,
    ""chip.bam2ta_disk_factor"" : 4.0,

    ""chip.spr_mem_factor"" : 13.5,
    ""chip.spr_disk_factor"" : 18.0,

    ""chip.enable_jsd"": false,
    ""chip.jsd_cpu"" : 4,
    ""chip.jsd_mem_factor"" : 0.1,
    ""chip.jsd_time_hr"" : 6,
    ""chip.jsd_disk_factor"" : 2.0,

    ""chip.xcor_cpu"" : 2,
    ""chip.xcor_mem_factor"" : 1.0,
:
```

## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
```
* Found failures JSON object.
[
    {
        ""causedBy"": [
            {
                ""causedBy"": [],
                ""message"": ""Job chip.xcor:1:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            }
        ],
        ""message"": ""Workflow failed""
    }
]
* Recursively finding failures in calls (tasks)...

==== NAME=chip.xcor, STATUS=RetryableFailure, PARENT=
SHARD_IDX=1, RC=1, JOB_ID=402477
START=2022-02-04T03:58:57.092Z, END=2022-02-04T03:59:35.114Z
STDOUT=/work/wx74/chip-seq-pipeline2-results/OP_1/test/chip/15cee7a3-e687-47fb-aaf2-8e022481ee9a/call-xcor/shard-1/execution/stdout
STDERR=/work/wx74/chip-seq-pipeline2-results/OP_1/test/chip/15cee7a3-e687-47fb-aaf2-8e022481ee9a/call-xcor/shard-1/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/work/wx74/.conda/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/work/wx74/.conda/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/work/wx74/.conda/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/work/wx74/.conda/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=193447, PGID=193447, RC=1, DURATION_SEC=20.2
STDERR=Loading required package: caTools
Error in pdf(file = iparams$output.plot.file, width = 5, height = 5) : 
  invalid 'file' argument 'H3K4me1%OP9_TGCGCAAT_1.trim_50bp.srt.filt.no_chrM.15M.cc.plot.pdf'
Execution halted
 
```
",wx2022,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/261
I_kwDOBrDQms5EdUi8,TEST run gave an error. Please help!,CLOSED,2022-02-23T20:21:29Z,2022-02-24T19:20:35Z,2022-02-24T19:20:34Z,"$ pip install pip --upgrade
$ export PATH=""/home/ysun/.local/bin:$PATH""
$ pip install caper
$ pip install caper --upgrade
$ caper init local
$ git clone https://github.com/ENCODE-DCC/chip-seq-pipeline2
$ wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
$ bash Miniconda3-latest-Linux-x86_64.sh
$ bash Miniconda3-latest-Linux-x86_64.sh -u
$ cd chip-seq-pipeline2/
$ conda --version
conda 4.11.0
$ caper --version
2.1.3
$ java --version
openjdk 11.0.13 2021-10-19
OpenJDK Runtime Environment (build 11.0.13+8-Ubuntu-0ubuntu1.20.04)
OpenJDK 64-Bit Server VM (build 11.0.13+8-Ubuntu-0ubuntu1.20.04, mixed mode, sharing)
$ python3 --version
Python 3.9.7
$ bash scripts/uninstall_conda_env.sh
$ bash scripts/install_conda_env.sh
$ mkidr /home/ysun/chip-seq-pipeline2-genome/hg38|hg19|mm10|mm9
$ bash scripts/download_genome_data.sh hg38|hg19|mm10|mm9 /home/ysun/chip-seq-pipeline2-genome/hg38|hg19|mm10|mm9

Until this point, everything works fine. Then I tried the example as:
**THE ERROR HAPPENED AT THIS POINT** Debug file attached. Thanks.
_____________________________________________________________________________
$ caper run chip.wdl -i https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI_subsampled_chr19_only.json --conda
2022-02-23 11:57:55,044|caper.cli|INFO| Cromwell stdout: /home/ysun/pipelineTest/cromwell.out
2022-02-23 11:57:55,045|caper.caper_base|INFO| Creating a timestamped temporary directory. /home/ysun/pipelineTest/.caper_tmp/chip/20220223_115755_045003
2022-02-23 11:57:55,045|caper.caper_runner|INFO| Localizing files on work_dir. /home/ysun/pipelineTest/.caper_tmp/chip/20220223_115755_045003
2022-02-23 11:57:55,234|autouri.autouri|INFO| cp: (bb9e1351) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.fasta.gz, dest=/home/ysun/pipelineTest/.caper_tmp/dcc664bb3e886aa9127f3bd8522bff3c/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.fasta.gz
2022-02-23 11:57:55,350|autouri.autouri|INFO| cp: (bb9e1351) skipped due to md5_match. md5=fbd798407e251364cf52712b461de7bd
2022-02-23 11:57:55,352|autouri.autouri|INFO| cp: (49b1efdb) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.chrM.fa.gz, dest=/home/ysun/pipelineTest/.caper_tmp/be275eb60876cf28f4600fb8589afe42/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.chrM.fa.gz
2022-02-23 11:57:55,481|autouri.autouri|INFO| cp: (49b1efdb) skipped due to md5_match. md5=05297d96dd1f7cfb45a7b637d6dd7036
2022-02-23 11:57:55,483|autouri.autouri|INFO| cp: (bf4404e0) started. src=https://www.encodeproject.org/files/ENCFF547MET/@@download/ENCFF547MET.bed.gz, dest=/home/ysun/pipelineTest/.caper_tmp/da42a1c4b0f9d3225600da56b2c9571d/ENCFF547MET.bed.gz
2022-02-23 11:57:55,937|autouri.autouri|INFO| cp: (bf4404e0) skipped due to md5_match. md5=5d19eeb4197ae10540252c61399f3131
2022-02-23 11:57:55,939|autouri.autouri|INFO| cp: (1a966ac4) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/hg38_chr19_chrM.chrom.sizes, dest=/home/ysun/pipelineTest/.caper_tmp/f0e538218d74ce7a3850c9605caf2e23/hg38_chr19_chrM.chrom.sizes
2022-02-23 11:57:56,084|autouri.autouri|INFO| cp: (1a966ac4) skipped due to md5_match. md5=a068b95e53225dfb124590e10697d692
2022-02-23 11:57:56,085|autouri.autouri|INFO| cp: (70c34d06) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/bowtie2_index/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.fasta.tar, dest=/home/ysun/pipelineTest/.caper_tmp/7b07a4b54cf5f715b174d8e9164d7d9c/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.fasta.tar
2022-02-23 11:57:56,191|autouri.autouri|INFO| cp: (70c34d06) skipped due to md5_match. md5=22f0a7a6c0496b39f329f414fb192f75
2022-02-23 11:57:56,193|autouri.autouri|INFO| cp: (027e571a) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/bowtie2_index/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.chrM.fa.tar, dest=/home/ysun/pipelineTest/.caper_tmp/b44489aed009d7741fd44131dcc6b7c8/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.chrM.fa.tar
2022-02-23 11:57:56,295|autouri.autouri|INFO| cp: (027e571a) skipped due to md5_match. md5=c1b0155acebcd0f4d81ca79e8ec8bc79
2022-02-23 11:57:56,296|autouri.autouri|INFO| cp: (5ab45ce5) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/bwa_index/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.fasta.tar, dest=/home/ysun/pipelineTest/.caper_tmp/542354fad05fedb3cae8c97381031035/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.fasta.tar
2022-02-23 11:57:56,406|autouri.autouri|INFO| cp: (5ab45ce5) skipped due to md5_match. md5=d13bc228457d7b5347383658d1c2c4e8
2022-02-23 11:57:56,408|autouri.autouri|INFO| cp: (c409bf1a) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/bwa_index/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.chrM.fa.tar, dest=/home/ysun/pipelineTest/.caper_tmp/9b649793fb593506a76c3141180ea657/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.chrM.fa.tar
2022-02-23 11:57:56,520|autouri.autouri|INFO| cp: (c409bf1a) skipped due to md5_match. md5=d7a5706a25bcd14874cac8e24b006e22
2022-02-23 11:57:56,521|autouri.autouri|INFO| cp: (27437b3a) started. src=https://www.encodeproject.org/files/ENCFF493CCB/@@download/ENCFF493CCB.bed.gz, dest=/home/ysun/pipelineTest/.caper_tmp/0fa7d04b32e66fa02fb2c1ae39e41447/ENCFF493CCB.bed.gz
2022-02-23 11:57:56,912|autouri.autouri|INFO| cp: (27437b3a) skipped due to md5_match. md5=aca8cf959206aa3ad257fc46dc783266
2022-02-23 11:57:56,913|autouri.autouri|INFO| cp: (db11863a) started. src=https://www.encodeproject.org/files/ENCFF304XEX/@@download/ENCFF304XEX.bed.gz, dest=/home/ysun/pipelineTest/.caper_tmp/805e179275a9c0fb7a37def40c4312d1/ENCFF304XEX.bed.gz
2022-02-23 11:57:57,532|autouri.autouri|INFO| cp: (db11863a) skipped due to name_size_match. size=14377496, mt=1592463730.0
2022-02-23 11:57:57,534|autouri.autouri|INFO| cp: (614823a1) started. src=https://www.encodeproject.org/files/ENCFF140XLU/@@download/ENCFF140XLU.bed.gz, dest=/home/ysun/pipelineTest/.caper_tmp/0cbd2c602ddad252bc39729fc8a29286/ENCFF140XLU.bed.gz
2022-02-23 11:57:57,941|autouri.autouri|INFO| cp: (614823a1) skipped due to md5_match. md5=91047588129069ff91ec1b0664179f8e
2022-02-23 11:57:57,943|autouri.autouri|INFO| cp: (1902bc93) started. src=https://www.encodeproject.org/files/ENCFF212UAV/@@download/ENCFF212UAV.bed.gz, dest=/home/ysun/pipelineTest/.caper_tmp/1d3aa436b05f16a509edb94789c061d3/ENCFF212UAV.bed.gz
2022-02-23 11:57:58,646|autouri.autouri|INFO| cp: (1902bc93) skipped due to name_size_match. size=18381891, mt=1592463727.0
2022-02-23 11:57:58,648|autouri.autouri|INFO| cp: (783bb7e1) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38/ataqc/hg38_dnase_avg_fseq_signal_formatted.txt.gz, dest=/home/ysun/pipelineTest/.caper_tmp/3b39284516e676ea52238f0636c0bbbf/hg38_dnase_avg_fseq_signal_formatted.txt.gz
2022-02-23 11:57:58,751|autouri.autouri|INFO| cp: (783bb7e1) skipped due to md5_match. md5=df624401f76fbd4d651e736068c43a1a
2022-02-23 11:57:58,752|autouri.autouri|INFO| cp: (2aaeccad) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38/ataqc/hg38_celltype_compare_subsample.bed.gz, dest=/home/ysun/pipelineTest/.caper_tmp/c73f434c3fa4f3f54bc2ecad09c065c2/hg38_celltype_compare_subsample.bed.gz
2022-02-23 11:57:58,937|autouri.autouri|INFO| cp: (2aaeccad) skipped due to md5_match. md5=ced0c653d28628654288f7a8ab052590
2022-02-23 11:57:58,938|autouri.autouri|INFO| cp: (36c97462) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38/ataqc/hg38_dnase_avg_fseq_signal_metadata.txt, dest=/home/ysun/pipelineTest/.caper_tmp/a9745b33b4ffdd83d7d2c5a7d3c8036a/hg38_dnase_avg_fseq_signal_metadata.txt
2022-02-23 11:57:59,048|autouri.autouri|INFO| cp: (36c97462) skipped due to md5_match. md5=3f7fd85ab9a4c6274f28c3e82a79c10d
2022-02-23 11:57:59,050|autouri.autouri|INFO| cp: (c180d00a) started. src=https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep1.subsampled.25.fastq.gz, dest=/home/ysun/pipelineTest/.caper_tmp/41d3a8658bf4f565c08290e386fddccf/rep1.subsampled.25.fastq.gz
2022-02-23 11:57:59,161|autouri.autouri|INFO| cp: (c180d00a) skipped due to md5_match. md5=212ac7a69357df3df077177b44c8cdf0
2022-02-23 11:57:59,162|autouri.autouri|INFO| cp: (fe7084ff) started. src=https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep2.subsampled.20.fastq.gz, dest=/home/ysun/pipelineTest/.caper_tmp/0d5b102d7f21dd009798ae9b2c318b65/rep2.subsampled.20.fastq.gz
2022-02-23 11:57:59,272|autouri.autouri|INFO| cp: (fe7084ff) skipped due to md5_match. md5=4df1a7e6a3a299f6a2355d93b54db48a
2022-02-23 11:57:59,273|autouri.autouri|INFO| cp: (b041e76e) started. src=https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl1.subsampled.25.fastq.gz, dest=/home/ysun/pipelineTest/.caper_tmp/f4dba75d4430f4702a75554c44265119/ctl1.subsampled.25.fastq.gz
2022-02-23 11:57:59,382|autouri.autouri|INFO| cp: (b041e76e) skipped due to md5_match. md5=3ad89622e0b1269606575d305c5350ef
2022-02-23 11:57:59,383|autouri.autouri|INFO| cp: (78a17723) started. src=https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl2.subsampled.25.fastq.gz, dest=/home/ysun/pipelineTest/.caper_tmp/7a610dd5397c45a806678efaad824abf/ctl2.subsampled.25.fastq.gz
2022-02-23 11:57:59,487|autouri.autouri|INFO| cp: (78a17723) skipped due to md5_match. md5=b2a184523015df11edf3c670f07e1ed4
2022-02-23 11:58:00,316|caper.caper_workflow_opts|INFO| Conda environment name not found in WDL metadata. wdl=/home/ysun/pipelineTest/chip.wdl
2022-02-23 11:58:00,320|caper.cromwell|INFO| Validating WDL/inputs/imports with Womtool...
2022-02-23 11:58:03,566|caper.cromwell|INFO| Passed Womtool validation.
2022-02-23 11:58:03,567|caper.caper_runner|INFO| launching run: wdl=/home/ysun/pipelineTest/chip.wdl, inputs=/home/ysun/pipelineTest/.caper_tmp/15b4ff439de58d859f4c3ee4482c3bd2/ENCSR000DYI_subsampled_chr19_only.local.json, backend_conf=/home/ysun/pipelineTest/.caper_tmp/chip/20220223_115755_045003/backend.conf
2022-02-23 11:58:12,112|caper.cromwell_workflow_monitor|INFO| Workflow: id=71cc675c-d6a9-493a-b9af-0170726153a3, status=Submitted
2022-02-23 11:58:12,194|caper.cromwell_workflow_monitor|INFO| Workflow: id=71cc675c-d6a9-493a-b9af-0170726153a3, status=Running
2022-02-23 11:58:26,977|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.read_genome_tsv:-1, retry=0, status=Started, job_id=3576061
2022-02-23 11:58:26,983|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.read_genome_tsv:-1, retry=0, status=WaitingForReturnCode
2022-02-23 11:58:28,966|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.read_genome_tsv:-1, retry=0, status=Done
2022-02-23 11:58:36,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align:1, retry=0, status=Started, job_id=3576208
2022-02-23 11:58:36,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align:0, retry=0, status=Started, job_id=3576162
2022-02-23 11:58:36,961|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align:1, retry=0, status=WaitingForReturnCode
2022-02-23 11:58:36,961|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align:0, retry=0, status=WaitingForReturnCode
2022-02-23 11:58:41,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align_R1:1, retry=0, status=Started, job_id=3576315
2022-02-23 11:58:41,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align_R1:0, retry=0, status=Started, job_id=3576270
2022-02-23 11:58:41,961|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align_R1:0, retry=0, status=WaitingForReturnCode
2022-02-23 11:58:41,961|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align_R1:1, retry=0, status=WaitingForReturnCode
2022-02-23 11:58:46,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align_ctl:0, retry=0, status=Started, job_id=3576362
2022-02-23 11:58:46,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align_ctl:1, retry=0, status=Started, job_id=3576412
2022-02-23 11:58:46,961|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align_ctl:1, retry=0, status=WaitingForReturnCode
2022-02-23 11:58:46,961|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align_ctl:0, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:13,415|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align:1, retry=0, status=Done
2022-02-23 11:59:15,695|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align_ctl:0, retry=0, status=Done
2022-02-23 11:59:16,645|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align:0, retry=0, status=Done
2022-02-23 11:59:24,544|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align_R1:1, retry=0, status=Done
2022-02-23 11:59:26,215|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align_ctl:1, retry=0, status=Done
2022-02-23 11:59:26,957|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter_ctl:0, retry=0, status=Started, job_id=3577264
2022-02-23 11:59:26,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter:1, retry=0, status=Started, job_id=3577152
2022-02-23 11:59:26,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter:0, retry=0, status=Started, job_id=3577375
2022-02-23 11:59:26,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter:0, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:26,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter_ctl:0, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:26,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter:1, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:28,604|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.align_R1:0, retry=0, status=Done
2022-02-23 11:59:31,957|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter_R1:1, retry=0, status=Started, job_id=3577645
2022-02-23 11:59:31,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter_R1:1, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:33,995|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter:1, retry=0, status=Done
2022-02-23 11:59:34,094|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter_ctl:0, retry=0, status=Done
2022-02-23 11:59:36,956|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter_ctl:1, retry=0, status=Started, job_id=3577949
2022-02-23 11:59:36,956|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter_R1:0, retry=0, status=Started, job_id=3577786
2022-02-23 11:59:36,957|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter_R1:0, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:36,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter_ctl:1, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:37,534|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter:0, retry=0, status=Done
2022-02-23 11:59:42,864|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter_R1:1, retry=0, status=Done
2022-02-23 11:59:43,285|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter_R1:0, retry=0, status=Done
2022-02-23 11:59:44,795|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.filter_ctl:1, retry=0, status=Done
2022-02-23 11:59:46,957|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta_ctl:0, retry=0, status=Started, job_id=3578311
2022-02-23 11:59:46,957|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.gc_bias:1, retry=0, status=Started, job_id=3578365
2022-02-23 11:59:46,957|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta:1, retry=0, status=Started, job_id=3578563
2022-02-23 11:59:46,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta_ctl:0, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:46,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta:1, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:46,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.gc_bias:1, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:48,455|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta_ctl:0, retry=0, status=Done
2022-02-23 11:59:51,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta:0, retry=0, status=Started, job_id=3578627
2022-02-23 11:59:51,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.gc_bias:0, retry=0, status=Started, job_id=3578702
2022-02-23 11:59:51,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta:0, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:51,960|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.gc_bias:0, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:53,144|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta:1, retry=0, status=Done
2022-02-23 11:59:54,964|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta:0, retry=0, status=Done
2022-02-23 11:59:56,957|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta_no_dedup_R1:1, retry=0, status=Started, job_id=3578949
2022-02-23 11:59:56,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.jsd:-1, retry=0, status=Started, job_id=3579034
2022-02-23 11:59:56,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta_no_dedup_R1:0, retry=0, status=Started, job_id=3578887
2022-02-23 11:59:56,963|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta_no_dedup_R1:1, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:56,963|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta_no_dedup_R1:0, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:56,963|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.jsd:-1, retry=0, status=WaitingForReturnCode
2022-02-23 11:59:57,735|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.gc_bias:1, retry=0, status=Done
2022-02-23 11:59:58,944|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta_no_dedup_R1:0, retry=0, status=Done
2022-02-23 12:00:01,194|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta_no_dedup_R1:1, retry=0, status=Done
2022-02-23 12:00:01,957|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.spr:1, retry=0, status=Started, job_id=3579209
2022-02-23 12:00:01,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta_ctl:1, retry=0, status=Started, job_id=3579136
2022-02-23 12:00:01,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.spr:1, retry=0, status=WaitingForReturnCode
2022-02-23 12:00:01,960|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta_ctl:1, retry=0, status=WaitingForReturnCode
2022-02-23 12:00:03,061|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.gc_bias:0, retry=0, status=Done
2022-02-23 12:00:05,085|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.bam2ta_ctl:1, retry=0, status=Done
2022-02-23 12:00:06,674|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.spr:1, retry=0, status=Done
2022-02-23 12:00:06,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.pool_ta:-1, retry=0, status=Started, job_id=3579381
2022-02-23 12:00:06,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.spr:0, retry=0, status=Started, job_id=3579299
2022-02-23 12:00:06,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.pool_ta:-1, retry=0, status=WaitingForReturnCode
2022-02-23 12:00:06,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.spr:0, retry=0, status=WaitingForReturnCode
2022-02-23 12:00:10,935|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.spr:0, retry=0, status=Done
2022-02-23 12:00:11,956|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.xcor:0, retry=0, status=Started, job_id=3579442
2022-02-23 12:00:11,957|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.xcor:0, retry=0, status=WaitingForReturnCode
2022-02-23 12:00:13,904|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.pool_ta:-1, retry=0, status=Done
2022-02-23 12:00:16,957|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.xcor:1, retry=0, status=Started, job_id=3579521
2022-02-23 12:00:16,957|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.pool_ta_ctl:-1, retry=0, status=Started, job_id=3579612
2022-02-23 12:00:16,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.pool_ta_ctl:-1, retry=0, status=WaitingForReturnCode
2022-02-23 12:00:16,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.xcor:1, retry=0, status=WaitingForReturnCode
2022-02-23 12:00:17,754|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.xcor:0, retry=0, status=Done
2022-02-23 12:00:20,354|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.xcor:1, retry=0, status=Done
2022-02-23 12:00:21,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.pool_ta_pr2:-1, retry=0, status=Started, job_id=3579686
2022-02-23 12:00:21,960|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.pool_ta_pr2:-1, retry=0, status=WaitingForReturnCode
2022-02-23 12:00:22,314|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.pool_ta_ctl:-1, retry=0, status=Done
2022-02-23 12:00:26,504|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.pool_ta_pr2:-1, retry=0, status=Done
2022-02-23 12:00:26,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.pool_ta_pr1:-1, retry=0, status=Started, job_id=3579747
2022-02-23 12:00:26,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.xcor:1, retry=1, status=Started, job_id=3579800
2022-02-23 12:00:26,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.xcor:0, retry=1, status=Started, job_id=3579874
2022-02-23 12:00:26,959|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.xcor:0, retry=1, status=WaitingForReturnCode
2022-02-23 12:00:26,960|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.xcor:1, retry=1, status=WaitingForReturnCode
2022-02-23 12:00:26,960|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.pool_ta_pr1:-1, retry=0, status=WaitingForReturnCode
2022-02-23 12:00:28,074|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.pool_ta_pr1:-1, retry=0, status=Done
2022-02-23 12:00:31,524|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.xcor:1, retry=1, status=Done
2022-02-23 12:00:31,956|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.choose_ctl:-1, retry=0, status=Started, job_id=3579953
2022-02-23 12:00:31,958|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.choose_ctl:-1, retry=0, status=WaitingForReturnCode
2022-02-23 12:00:32,155|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.xcor:0, retry=1, status=Done
2022-02-23 12:00:35,137|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.choose_ctl:-1, retry=0, status=Done
2022-02-23 12:02:44,105|caper.cromwell_workflow_monitor|INFO| Task: id=71cc675c-d6a9-493a-b9af-0170726153a3, task=chip.jsd:-1, retry=0, status=Done
2022-02-23 12:02:45,423|caper.cromwell_workflow_monitor|INFO| Workflow: id=71cc675c-d6a9-493a-b9af-0170726153a3, status=Failed
2022-02-23 12:03:13,157|caper.cromwell_metadata|INFO| Wrote metadata file. /home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/metadata.json
2022-02-23 12:03:13,157|caper.cromwell|INFO| Workflow failed. Auto-troubleshooting...
* Started troubleshooting workflow: id=71cc675c-d6a9-493a-b9af-0170726153a3, status=Failed
* Found failures JSON object.
[
    {
        ""causedBy"": [
            {
                ""message"": ""Job chip.xcor:1:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details."",
                ""causedBy"": []
            },
            {
                ""causedBy"": [],
                ""message"": ""Job chip.xcor:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            }
        ],
        ""message"": ""Workflow failed""
    }
]
* Recursively finding failures in calls (tasks)...

==== NAME=chip.xcor, STATUS=RetryableFailure, PARENT=
SHARD_IDX=0, RC=1, JOB_ID=3579442
START=2022-02-23T20:00:10.027Z, END=2022-02-23T20:00:21.965Z
STDOUT=/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-0/execution/stdout
STDERR=/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=3579494, PGID=3579494, RC=127, DURATION_SEC=0.0
STDERR=/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/lib/R/bin/exec/R: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory
STDOUT=

STDERR_BACKGROUND_CONTENTS=
Traceback (most recent call last):
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=3579494, PGID=3579494, RC=127, DURATION_SEC=0.0
STDERR=/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/lib/R/bin/exec/R: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory
STDOUT=
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-0/execution/*.cc.plot.png': No such file or directory
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-0/execution/*.cc.fraglen.txt': No such file or directory
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-0/execution/*.cc.plot.pdf': No such file or directory
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-0/execution/*.cc.qc': No such file or directory



==== NAME=chip.xcor, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=1, JOB_ID=3579874
START=2022-02-23T20:00:26.013Z, END=2022-02-23T20:00:32.159Z
STDOUT=/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-0/attempt-2/execution/stdout
STDERR=/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-0/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=3579930, PGID=3579930, RC=127, DURATION_SEC=0.0
STDERR=/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/lib/R/bin/exec/R: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory
STDOUT=

STDERR_BACKGROUND_CONTENTS=
Traceback (most recent call last):
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=3579930, PGID=3579930, RC=127, DURATION_SEC=0.0
STDERR=/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/lib/R/bin/exec/R: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory
STDOUT=
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-0/attempt-2/execution/*.cc.plot.png': No such file or directory
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-0/attempt-2/execution/*.cc.fraglen.txt': No such file or directory
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-0/attempt-2/execution/*.cc.plot.pdf': No such file or directory
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-0/attempt-2/execution/*.cc.qc': No such file or directory



==== NAME=chip.xcor, STATUS=RetryableFailure, PARENT=
SHARD_IDX=1, RC=1, JOB_ID=3579521
START=2022-02-23T20:00:14.019Z, END=2022-02-23T20:00:21.965Z
STDOUT=/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-1/execution/stdout
STDERR=/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-1/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=3579574, PGID=3579574, RC=127, DURATION_SEC=0.0
STDERR=/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/lib/R/bin/exec/R: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory
STDOUT=

STDERR_BACKGROUND_CONTENTS=
Traceback (most recent call last):
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=3579574, PGID=3579574, RC=127, DURATION_SEC=0.0
STDERR=/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/lib/R/bin/exec/R: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory
STDOUT=
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-1/execution/*.cc.plot.png': No such file or directory
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-1/execution/*.cc.fraglen.txt': No such file or directory
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-1/execution/*.cc.plot.pdf': No such file or directory
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-1/execution/*.cc.qc': No such file or directory



==== NAME=chip.xcor, STATUS=Failed, PARENT=
SHARD_IDX=1, RC=1, JOB_ID=3579800
START=2022-02-23T20:00:24.012Z, END=2022-02-23T20:00:31.528Z
STDOUT=/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-1/attempt-2/execution/stdout
STDERR=/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-1/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=3579852, PGID=3579852, RC=127, DURATION_SEC=0.0
STDERR=/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/lib/R/bin/exec/R: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory
STDOUT=

STDERR_BACKGROUND_CONTENTS=
Traceback (most recent call last):
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=3579852, PGID=3579852, RC=127, DURATION_SEC=0.0
STDERR=/home/ysun/miniconda3/envs/encode-chip-seq-pipeline-spp/lib/R/bin/exec/R: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory
STDOUT=
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-1/attempt-2/execution/*.cc.plot.png': No such file or directory
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-1/attempt-2/execution/*.cc.fraglen.txt': No such file or directory
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-1/attempt-2/execution/*.cc.plot.pdf': No such file or directory
ln: failed to access '/home/ysun/pipelineTest/chip/71cc675c-d6a9-493a-b9af-0170726153a3/call-xcor/shard-1/attempt-2/execution/*.cc.qc': No such file or directory
_____________________________________________________________________________

[cromwell.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/8127554/cromwell.txt)",yingsun-ucsd,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/265
I_kwDOBrDQms5Ee0_I,Run gives error,CLOSED,2022-02-24T07:01:03Z,2022-03-03T01:42:59Z,2022-03-03T01:42:59Z,"## **Describe the bug**
I have been able to successfully run the chip-seq pipeline for the example json with a variety of different parameters. While passing in a custom .bam file I running into errors that I am not too sure how to debug.
## **Caper configuration file**
Locally run

## **Input JSON file**
Paste contents of your input JSON file.
```json
{
    ""chip.title"" : ""Running all-H3K4me3.bam through ENCODE"",
    ""chip.description"" : ""This is an template input JSON for all-POLR2A."",

    ""chip.pipeline_type"" : ""histone"",
    ""chip.nodup_bams"" : [""/mnt/c/Users/shirl/Desktop/guttman_lab/all-H3K4me3.bam""],
    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v4/hg38_chr19_chrM.tsv"",
    ""chip.enable_gc_bias"" : false,
    ""chip.paired_end"" : true
}
```

## **Troubleshooting result**

Paste troubleshooting result.
```
`ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/6b12d05b-3e09-49dd-82c2-0edd3964b413/call-xcor/shard-0/attempt-2/execution/*.cc.plot.png': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/6b12d05b-3e09-49dd-82c2-0edd3964b413/call-xcor/shard-0/attempt-2/execution/*.cc.fraglen.txt': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/6b12d05b-3e09-49dd-82c2-0edd3964b413/call-xcor/shard-0/attempt-2/execution/*.cc.plot.pdf': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/6b12d05b-3e09-49dd-82c2-0edd3964b413/call-xcor/shard-0/attempt-2/execution/*.cc.qc': No such file or directory
````
",shirleytemples,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/266
I_kwDOBrDQms5EqxrV,parrallel proccessing with spp,CLOSED,2022-02-26T17:53:59Z,2022-03-01T00:24:41Z,2022-03-01T00:24:41Z,"I am confused with this line of code from encode_task_spp.py
nth_param = '-p={}'.format(nth) if nth < 2 else ''
should it be:
nth_param = '-p={}'.format(nth) if nth >= 2 else ''
when I run the pipeline with spp it does not seem to use multiple threads",louisgevirtzman,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/268
I_kwDOBrDQms5FKPMI,"|ERROR| Failed to parse WDL with miniwdl, |ERROR| Conda environment name not found in WDL metadata",CLOSED,2022-03-05T10:37:18Z,2022-03-05T23:26:53Z,2022-03-05T23:26:53Z,"Hi, when I ran the command `caper run chip.wdl -i https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI_subsampled_chr19_only.json --conda`

I get the error message` |ERROR| Failed to parse WDL with miniwdl, Conda environment name not found in WDL metadata. `

Any suggestions would be much appreciated! 

I included the entire error message below for reference.

```
2022-03-05 00:44:55,190|caper.cli|INFO| Cromwell stdout: /home/shirleytemples/chip-seq-pipeline2/cromwell.out.59
2022-03-05 00:44:55,195|caper.caper_base|INFO| Creating a timestamped temporary directory. /home/shirleytemples/chip-seq-pipeline2/.caper_tmp/chip/20220305_004455_192720
2022-03-05 00:44:55,196|caper.caper_runner|INFO| Localizing files on work_dir. /home/shirleytemples/chip-seq-pipeline2/.caper_tmp/chip/20220305_004455_192720
2022-03-05 00:44:55,706|autouri.autouri|INFO| cp: (6dbd4d75) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.fasta.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/dcc664bb3e886aa9127f3bd8522bff3c/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.fasta.gz
2022-03-05 00:44:56,167|autouri.autouri|INFO| cp: (6dbd4d75) skipped due to md5_match. md5=fbd798407e251364cf52712b461de7bd
2022-03-05 00:44:56,172|autouri.autouri|INFO| cp: (4353037b) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.chrM.fa.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/be275eb60876cf28f4600fb8589afe42/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.chrM.fa.gz
2022-03-05 00:44:56,474|autouri.autouri|INFO| cp: (4353037b) skipped due to md5_match. md5=05297d96dd1f7cfb45a7b637d6dd7036
2022-03-05 00:44:56,481|autouri.autouri|INFO| cp: (01804529) started. src=https://www.encodeproject.org/files/ENCFF547MET/@@download/ENCFF547MET.bed.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/da42a1c4b0f9d3225600da56b2c9571d/ENCFF547MET.bed.gz
2022-03-05 00:44:57,110|autouri.autouri|INFO| cp: (01804529) skipped due to md5_match. md5=5d19eeb4197ae10540252c61399f3131
2022-03-05 00:44:57,116|autouri.autouri|INFO| cp: (a3339ce6) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/hg38_chr19_chrM.chrom.sizes, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/f0e538218d74ce7a3850c9605caf2e23/hg38_chr19_chrM.chrom.sizes
2022-03-05 00:44:57,367|autouri.autouri|INFO| cp: (a3339ce6) skipped due to md5_match. md5=a068b95e53225dfb124590e10697d692
2022-03-05 00:44:57,377|autouri.autouri|INFO| cp: (6bd317b1) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/bowtie2_index/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.fasta.tar, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/7b07a4b54cf5f715b174d8e9164d7d9c/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.fasta.tar
2022-03-05 00:44:57,858|autouri.autouri|INFO| cp: (6bd317b1) skipped due to md5_match. md5=22f0a7a6c0496b39f329f414fb192f75
2022-03-05 00:44:57,865|autouri.autouri|INFO| cp: (279ccd0a) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/bowtie2_index/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.chrM.fa.tar, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/b44489aed009d7741fd44131dcc6b7c8/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.chrM.fa.tar
2022-03-05 00:44:58,196|autouri.autouri|INFO| cp: (279ccd0a) skipped due to md5_match. md5=c1b0155acebcd0f4d81ca79e8ec8bc79
2022-03-05 00:44:58,201|autouri.autouri|INFO| cp: (a5951eee) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/bwa_index/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.fasta.tar, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/542354fad05fedb3cae8c97381031035/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.fasta.tar
2022-03-05 00:44:58,670|autouri.autouri|INFO| cp: (a5951eee) skipped due to md5_match. md5=d13bc228457d7b5347383658d1c2c4e8
2022-03-05 00:44:58,677|autouri.autouri|INFO| cp: (93f61117) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38_chr19_chrM/bwa_index/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.chrM.fa.tar, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/9b649793fb593506a76c3141180ea657/GRCh38_no_alt_analysis_set_GCA_000001405.15.chr19_chrM.chrM.fa.tar
2022-03-05 00:44:59,035|autouri.autouri|INFO| cp: (93f61117) skipped due to md5_match. md5=d7a5706a25bcd14874cac8e24b006e22
2022-03-05 00:44:59,041|autouri.autouri|INFO| cp: (68fc1758) started. src=https://www.encodeproject.org/files/ENCFF493CCB/@@download/ENCFF493CCB.bed.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/0fa7d04b32e66fa02fb2c1ae39e41447/ENCFF493CCB.bed.gz
2022-03-05 00:44:59,818|autouri.autouri|INFO| cp: (68fc1758) skipped due to md5_match. md5=aca8cf959206aa3ad257fc46dc783266
2022-03-05 00:44:59,824|autouri.autouri|INFO| cp: (2a5a74c5) started. src=https://www.encodeproject.org/files/ENCFF304XEX/@@download/ENCFF304XEX.bed.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/805e179275a9c0fb7a37def40c4312d1/ENCFF304XEX.bed.gz
2022-03-05 00:45:01,172|autouri.autouri|INFO| cp: (2a5a74c5) skipped due to name_size_match. size=14377496, mt=1592463730.0
2022-03-05 00:45:01,179|autouri.autouri|INFO| cp: (4c760c4d) started. src=https://www.encodeproject.org/files/ENCFF140XLU/@@download/ENCFF140XLU.bed.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/0cbd2c602ddad252bc39729fc8a29286/ENCFF140XLU.bed.gz
2022-03-05 00:45:01,960|autouri.autouri|INFO| cp: (4c760c4d) skipped due to md5_match. md5=91047588129069ff91ec1b0664179f8e
2022-03-05 00:45:01,966|autouri.autouri|INFO| cp: (aa339028) started. src=https://www.encodeproject.org/files/ENCFF212UAV/@@download/ENCFF212UAV.bed.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/1d3aa436b05f16a509edb94789c061d3/ENCFF212UAV.bed.gz
2022-03-05 00:45:03,095|autouri.autouri|INFO| cp: (aa339028) skipped due to name_size_match. size=18381891, mt=1592463727.0
2022-03-05 00:45:03,101|autouri.autouri|INFO| cp: (dd0b535a) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38/ataqc/hg38_dnase_avg_fseq_signal_formatted.txt.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/3b39284516e676ea52238f0636c0bbbf/hg38_dnase_avg_fseq_signal_formatted.txt.gz
2022-03-05 00:45:03,454|autouri.autouri|INFO| cp: (dd0b535a) skipped due to md5_match. md5=df624401f76fbd4d651e736068c43a1a
2022-03-05 00:45:03,458|autouri.autouri|INFO| cp: (7de7b933) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38/ataqc/hg38_celltype_compare_subsample.bed.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/c73f434c3fa4f3f54bc2ecad09c065c2/hg38_celltype_compare_subsample.bed.gz
2022-03-05 00:45:03,763|autouri.autouri|INFO| cp: (7de7b933) skipped due to md5_match. md5=ced0c653d28628654288f7a8ab052590
2022-03-05 00:45:03,766|autouri.autouri|INFO| cp: (4b14c116) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38/ataqc/hg38_dnase_avg_fseq_signal_metadata.txt, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/a9745b33b4ffdd83d7d2c5a7d3c8036a/hg38_dnase_avg_fseq_signal_metadata.txt
2022-03-05 00:45:03,994|autouri.autouri|INFO| cp: (4b14c116) skipped due to md5_match. md5=3f7fd85ab9a4c6274f28c3e82a79c10d
2022-03-05 00:45:04,045|autouri.autouri|INFO| cp: (9e879801) started. src=https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep1.subsampled.25.fastq.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/41d3a8658bf4f565c08290e386fddccf/rep1.subsampled.25.fastq.gz
2022-03-05 00:45:04,487|autouri.autouri|INFO| cp: (9e879801) skipped due to md5_match. md5=212ac7a69357df3df077177b44c8cdf0
2022-03-05 00:45:04,492|autouri.autouri|INFO| cp: (1f07eb6a) started. src=https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep2.subsampled.20.fastq.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/0d5b102d7f21dd009798ae9b2c318b65/rep2.subsampled.20.fastq.gz
2022-03-05 00:45:04,930|autouri.autouri|INFO| cp: (1f07eb6a) skipped due to md5_match. md5=4df1a7e6a3a299f6a2355d93b54db48a
2022-03-05 00:45:04,936|autouri.autouri|INFO| cp: (402c5ce4) started. src=https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl1.subsampled.25.fastq.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/f4dba75d4430f4702a75554c44265119/ctl1.subsampled.25.fastq.gz
2022-03-05 00:45:05,365|autouri.autouri|INFO| cp: (402c5ce4) skipped due to md5_match. md5=3ad89622e0b1269606575d305c5350ef
2022-03-05 00:45:05,370|autouri.autouri|INFO| cp: (0004b518) started. src=https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl2.subsampled.25.fastq.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/7a610dd5397c45a806678efaad824abf/ctl2.subsampled.25.fastq.gz
2022-03-05 00:45:05,785|autouri.autouri|INFO| cp: (0004b518) skipped due to md5_match. md5=b2a184523015df11edf3c670f07e1ed4
2022-03-05 00:45:07,153|caper.wdl_parser|ERROR| Failed to parse WDL with miniwdl.
2022-03-05 00:45:07,154|caper.caper_workflow_opts|INFO| Conda environment name not found in WDL metadata. wdl=/home/shirleytemples/chip-seq-pipeline2/chip.wdl
2022-03-05 00:45:07,179|caper.cromwell|INFO| Validating WDL/inputs/imports with Womtool...
2022-03-05 00:45:13,080|caper.cromwell|INFO| Passed Womtool validation.
2022-03-05 00:45:13,082|caper.caper_runner|INFO| launching run: wdl=/home/shirleytemples/chip-seq-pipeline2/chip.wdl, inputs=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/15b4ff439de58d859f4c3ee4482c3bd2/ENCSR000DYI_subsampled_chr19_only.local.json, backend_conf=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/chip/20220305_004455_192720/backend.conf
2022-03-05 00:45:27,348|caper.cromwell_workflow_monitor|INFO| Workflow: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, status=Submitted
2022-03-05 00:45:27,364|caper.cromwell_workflow_monitor|INFO| Workflow: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, status=Running
2022-03-05 00:45:42,010|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.read_genome_tsv:-1, retry=0, status=Started, job_id=13366
2022-03-05 00:45:42,015|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.read_genome_tsv:-1, retry=0, status=WaitingForReturnCode
2022-03-05 00:45:49,945|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.read_genome_tsv:-1, retry=0, status=Done
2022-03-05 00:46:01,988|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_ctl:1, retry=0, status=Started, job_id=13431
2022-03-05 00:46:01,990|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align:0, retry=0, status=Started, job_id=13520
2022-03-05 00:46:01,992|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_ctl:1, retry=0, status=WaitingForReturnCode
2022-03-05 00:46:01,993|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_R1:0, retry=0, status=Started, job_id=13476
2022-03-05 00:46:01,995|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align:0, retry=0, status=WaitingForReturnCode
2022-03-05 00:46:01,996|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_R1:0, retry=0, status=WaitingForReturnCode
2022-03-05 00:46:04,870|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_ctl:1, retry=0, status=Done
2022-03-05 00:46:06,983|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align:1, retry=0, status=Started, job_id=13573
2022-03-05 00:46:06,983|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_ctl:0, retry=0, status=Started, job_id=13640
2022-03-05 00:46:06,989|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_ctl:0, retry=0, status=WaitingForReturnCode
2022-03-05 00:46:06,999|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align:1, retry=0, status=WaitingForReturnCode
2022-03-05 00:46:07,319|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_R1:0, retry=0, status=Done
2022-03-05 00:46:08,495|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align:0, retry=0, status=Done
2022-03-05 00:46:11,033|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align:1, retry=0, status=Done
2022-03-05 00:46:11,997|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_R1:1, retry=0, status=Started, job_id=13709
2022-03-05 00:46:12,001|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_ctl:1, retry=1, status=Started, job_id=13776
2022-03-05 00:46:12,013|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_ctl:1, retry=1, status=WaitingForReturnCode
2022-03-05 00:46:12,016|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_R1:1, retry=0, status=WaitingForReturnCode
2022-03-05 00:46:12,629|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_ctl:0, retry=0, status=Done
2022-03-05 00:46:15,300|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_R1:1, retry=0, status=Done
2022-03-05 00:46:16,856|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_ctl:1, retry=1, status=Done
2022-03-05 00:46:16,988|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_R1:0, retry=1, status=Started, job_id=13878
2022-03-05 00:46:16,988|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align:0, retry=1, status=Started, job_id=13945
2022-03-05 00:46:16,993|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_R1:0, retry=1, status=WaitingForReturnCode
2022-03-05 00:46:16,994|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align:0, retry=1, status=WaitingForReturnCode
2022-03-05 00:46:21,026|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align_R1:0, retry=1, status=Done
2022-03-05 00:46:21,990|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align:1, retry=1, status=Started, job_id=14018
2022-03-05 00:46:21,993|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align:1, retry=1, status=WaitingForReturnCode
2022-03-05 00:46:24,279|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align:1, retry=1, status=Done
2022-03-05 00:46:25,133|caper.cromwell_workflow_monitor|INFO| Task: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, task=chip.align:0, retry=1, status=Done
2022-03-05 00:46:26,133|caper.cromwell_workflow_monitor|INFO| Workflow: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, status=Failed
2022-03-05 00:46:38,336|caper.cromwell_metadata|INFO| Wrote metadata file. /home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/metadata.json
2022-03-05 00:46:38,336|caper.cromwell|INFO| Workflow failed. Auto-troubleshooting...
* Started troubleshooting workflow: id=e77e6cbd-4515-47b2-9fd5-f27506f041c2, status=Failed
* Found failures JSON object.
[
    {
        ""message"": ""Workflow failed"",
        ""causedBy"": [
            {
                ""causedBy"": [],
                ""message"": ""Job chip.align_ctl:1:2 exited with return code 3 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            },
            {
                ""causedBy"": [],
                ""message"": ""Job chip.align_R1:0:2 exited with return code 3 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            },
            {
                ""causedBy"": [],
                ""message"": ""Job chip.align:1:2 exited with return code 3 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            },
            {
                ""causedBy"": [],
                ""message"": ""Job chip.align:0:2 exited with return code 3 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            }
        ]
    }
]
* Recursively finding failures in calls (tasks)...

==== NAME=chip.align, STATUS=RetryableFailure, PARENT=
SHARD_IDX=0, RC=3, JOB_ID=13520
START=2022-03-05T08:46:01.194Z, END=2022-03-05T08:46:11.997Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-0/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-0/execution/stderr
STDERR_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.

STDERR_BACKGROUND_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-0/execution/*.samstats.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-0/execution/*.read_length.txt': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-0/execution/*.bai': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-0/execution/*.bam': No such file or directory



==== NAME=chip.align, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=3, JOB_ID=13945
START=2022-03-05T08:46:15.195Z, END=2022-03-05T08:46:25.139Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-0/attempt-2/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-0/attempt-2/execution/stderr
STDERR_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.

STDERR_BACKGROUND_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-0/attempt-2/execution/*.samstats.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-0/attempt-2/execution/*.read_length.txt': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-0/attempt-2/execution/*.bai': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-0/attempt-2/execution/*.bam': No such file or directory



==== NAME=chip.align, STATUS=RetryableFailure, PARENT=
SHARD_IDX=1, RC=3, JOB_ID=13573
START=2022-03-05T08:46:03.197Z, END=2022-03-05T08:46:12.020Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-1/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-1/execution/stderr
STDERR_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.

STDERR_BACKGROUND_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-1/execution/*.samstats.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-1/execution/*.read_length.txt': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-1/execution/*.bai': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-1/execution/*.bam': No such file or directory



==== NAME=chip.align, STATUS=Failed, PARENT=
SHARD_IDX=1, RC=3, JOB_ID=14018
START=2022-03-05T08:46:17.191Z, END=2022-03-05T08:46:24.284Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-1/attempt-2/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-1/attempt-2/execution/stderr
STDERR_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.

STDERR_BACKGROUND_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-1/attempt-2/execution/*.samstats.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-1/attempt-2/execution/*.read_length.txt': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-1/attempt-2/execution/*.bai': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align/shard-1/attempt-2/execution/*.bam': No such file or directory



==== NAME=chip.align_ctl, STATUS=RetryableFailure, PARENT=
SHARD_IDX=0, RC=3, JOB_ID=13640
START=2022-03-05T08:46:05.195Z, END=2022-03-05T08:46:16.991Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-0/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-0/execution/stderr
STDERR_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.

STDERR_BACKGROUND_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-0/execution/*.samstats.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-0/execution/*.read_length.txt': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-0/execution/*.bai': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-0/execution/*.bam': No such file or directory



==== NAME=chip.align_ctl, STATUS=RetryableFailure, PARENT=
SHARD_IDX=1, RC=3, JOB_ID=13431
START=2022-03-05T08:45:57.246Z, END=2022-03-05T08:46:06.993Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-1/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-1/execution/stderr
STDERR_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.

STDERR_BACKGROUND_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-1/execution/*.samstats.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-1/execution/*.read_length.txt': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-1/execution/*.bai': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-1/execution/*.bam': No such file or directory



==== NAME=chip.align_ctl, STATUS=Failed, PARENT=
SHARD_IDX=1, RC=3, JOB_ID=13776
START=2022-03-05T08:46:09.194Z, END=2022-03-05T08:46:16.860Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-1/attempt-2/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-1/attempt-2/execution/stderr
STDERR_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.

STDERR_BACKGROUND_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-1/attempt-2/execution/*.samstats.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-1/attempt-2/execution/*.read_length.txt': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-1/attempt-2/execution/*.bai': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_ctl/shard-1/attempt-2/execution/*.bam': No such file or directory



==== NAME=chip.align_R1, STATUS=RetryableFailure, PARENT=
SHARD_IDX=0, RC=3, JOB_ID=13476
START=2022-03-05T08:45:59.202Z, END=2022-03-05T08:46:11.997Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-0/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-0/execution/stderr
STDERR_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.

STDERR_BACKGROUND_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-0/execution/*.samstats.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-0/execution/*.read_length.txt': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-0/execution/*.bai': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-0/execution/*.bam': No such file or directory



==== NAME=chip.align_R1, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=3, JOB_ID=13878
START=2022-03-05T08:46:13.184Z, END=2022-03-05T08:46:21.031Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-0/attempt-2/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-0/attempt-2/execution/stderr
STDERR_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.

STDERR_BACKGROUND_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-0/attempt-2/execution/*.samstats.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-0/attempt-2/execution/*.read_length.txt': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-0/attempt-2/execution/*.bai': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-0/attempt-2/execution/*.bam': No such file or directory



==== NAME=chip.align_R1, STATUS=RetryableFailure, PARENT=
SHARD_IDX=1, RC=3, JOB_ID=13709
START=2022-03-05T08:46:07.210Z, END=2022-03-05T08:46:16.990Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-1/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-1/execution/stderr
STDERR_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.

STDERR_BACKGROUND_CONTENTS=

* Error: pipeline environment (docker, singularity or conda) not found.
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-1/execution/*.samstats.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-1/execution/*.read_length.txt': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-1/execution/*.bai': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/e77e6cbd-4515-47b2-9fd5-f27506f041c2/call-align_R1/shard-1/execution/*.bam': No such file or directory


2022-03-05 00:46:38,486|caper.nb_subproc_thread|ERROR| Cromwell failed. returncode=1
2022-03-05 00:46:38,486|caper.cli|ERROR| Check stdout in /home/shirleytemples/chip-seq-pipeline2/cromwell.out.59
```",shirleytemples,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/271
I_kwDOBrDQms5FLRbo,Issue with running tf file,OPEN,2022-03-06T11:13:02Z,2022-03-14T22:35:02Z,,"I have been able to successfully run the chip-seq pipeline for the example json and my own histone bam files. However, while passing in a custom **tf** .bam file, I am running into errors that I am not too sure how to debug. Any suggestions are much appreciated!

Here are more info about the issue:

I ran `caper run chip.wdl -i /mnt/c/users/shirl/Desktop/guttman_lab/CTCF.json --conda`

**Caper configuration file**
Locally run

**Input JSON file**


```
{
    
    ""chip.title"" : ""Running all-CTCF.bam through ENCODE"",
    ""chip.description"" : ""This is an template input JSON for CTCF."",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.nodup_bams"" : [""/mnt/c/Users/shirl/Desktop/guttman_lab/all-CTCF.bam""],
    ""chip.ctl_nodup_bams"" : [""/mnt/c/Users/shirl/Desktop/guttman_lab/Control_ChIP-seq_hg38_K562.bam""],
    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v4/hg38.tsv"",
    ""chip.enable_gc_bias"" : false,
    ""chip.paired_end"" : false,
    ""chip.ctl_paired_ends"" : [true]
}
```

**Error message:**

```
2022-03-06 00:07:20,574|caper.cli|INFO| Cromwell stdout: /home/shirleytemples/chip-seq-pipeline2/cromwell.out.69
2022-03-06 00:07:20,577|caper.caper_base|INFO| Creating a timestamped temporary directory. /home/shirleytemples/chip-seq-pipeline2/.caper_tmp/chip/20220306_000720_576058
2022-03-06 00:07:20,578|caper.caper_runner|INFO| Localizing files on work_dir. /home/shirleytemples/chip-seq-pipeline2/.caper_tmp/chip/20220306_000720_576058
2022-03-06 00:07:20,877|autouri.autouri|INFO| cp: (3596ce88) started. src=https://www.encodeproject.org/files/GRCh38_no_alt_analysis_set_GCA_000001405.15/@@download/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/caf534ed3cf684406e731d19be272b4a/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta.gz2022-03-06 00:07:22,661|autouri.autouri|INFO| cp: (3596ce88) skipped due to name_size_match. size=872949833, mt=1549739698.0
2022-03-06 00:07:22,664|autouri.autouri|INFO| cp: (9756f6dd) started. src=https://www.encodeproject.org/files/GRCh38_no_alt_analysis_set_GCA_000001405.15_mito_only/@@download/GRCh38_no_alt_analysis_set_GCA_000001405.15_mito_only.fasta.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/f43b63a83784d3ec8055f1a22168ed89/GRCh38_no_alt_analysis_set_GCA_000001405.15_mito_only.fasta.gz
2022-03-06 00:07:23,689|autouri.autouri|INFO| cp: (9756f6dd) skipped due to md5_match. md5=05297d96dd1f7cfb45a7b637d6dd7036
2022-03-06 00:07:23,788|autouri.autouri|INFO| cp: (16a445a9) started. src=https://www.encodeproject.org/files/ENCFF356LFX/@@download/ENCFF356LFX.bed.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/f183dcba5d34f959d8b55ed438ee2e22/ENCFF356LFX.bed.gz
2022-03-06 00:07:25,099|autouri.autouri|INFO| cp: (16a445a9) skipped due to md5_match. md5=393688b4f06c9ce26165d47433dd8c37
2022-03-06 00:07:26,624|autouri.autouri|INFO| cp: (32d95d6d) started. src=https://www.encodeproject.org/files/GRCh38_EBV.chrom.sizes/@@download/GRCh38_EBV.chrom.sizes.tsv, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/c52f52c7bfa357f55a39b1de7e4d0b0c/GRCh38_EBV.chrom.sizes.tsv
2022-03-06 00:07:27,861|autouri.autouri|INFO| cp: (32d95d6d) skipped due to md5_match. md5=c95303fb77cc3e11d50e3c3a4b93b3fb
2022-03-06 00:07:27,960|autouri.autouri|INFO| cp: (d2b2384c) started. src=https://www.encodeproject.org/files/ENCFF110MCL/@@download/ENCFF110MCL.tar.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/3ff4ac4c3f59d096b1a3842a182072ae/ENCFF110MCL.tar.gz
2022-03-06 00:07:29,889|autouri.autouri|INFO| cp: (d2b2384c) skipped due to name_size_match. size=3749246230, mt=1571469011.0
2022-03-06 00:07:29,969|autouri.autouri|INFO| cp: (c874ed2c) started. src=https://www.encodeproject.org/files/GRCh38_no_alt_analysis_set_GCA_000001405.15_mito_only_bowtie2_index/@@download/GRCh38_no_alt_analysis_set_GCA_000001405.15_mito_only_bowtie2_index.tar.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/df5193e07055d13c48be59bacd0f56b8/GRCh38_no_alt_analysis_set_GCA_000001405.15_mito_only_bowtie2_index.tar.gz
2022-03-06 00:07:31,217|autouri.autouri|INFO| cp: (c874ed2c) skipped due to md5_match. md5=80b263f6ea6ff65d547eef07102535db
2022-03-06 00:07:31,353|autouri.autouri|INFO| cp: (b4264198) started. src=https://www.encodeproject.org/files/ENCFF643CGH/@@download/ENCFF643CGH.tar.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/8c692fba4640609720272154ab0faa30/ENCFF643CGH.tar.gz
2022-03-06 00:07:33,241|autouri.autouri|INFO| cp: (b4264198) skipped due to name_size_match. size=4318261891, mt=1549723866.0
2022-03-06 00:07:33,313|autouri.autouri|INFO| cp: (81deb398) started. src=https://www.encodeproject.org/files/GRCh38_no_alt_analysis_set_GCA_000001405.15_mito_only_bwa_index/@@download/GRCh38_no_alt_analysis_set_GCA_000001405.15_mito_only_bwa_index.tar.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/d3dff25534e93d893902540d81e4f475/GRCh38_no_alt_analysis_set_GCA_000001405.15_mito_only_bwa_index.tar.gz
2022-03-06 00:07:34,528|autouri.autouri|INFO| cp: (81deb398) skipped due to md5_match. md5=7e088c24a017a43b1db5e8f50060eec1
2022-03-06 00:07:34,627|autouri.autouri|INFO| cp: (7b90f336) started. src=https://www.encodeproject.org/files/ENCFF766FGL/@@download/ENCFF766FGL.bed.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/f16cc7892540d7a9bc3207cc44eb8288/ENCFF766FGL.bed.gz
2022-03-06 00:07:35,725|autouri.autouri|INFO| cp: (7b90f336) skipped due to md5_match. md5=d108aa2a392ce5dd207fb8769a6e8240
2022-03-06 00:07:35,825|autouri.autouri|INFO| cp: (2f87a11e) started. src=https://www.encodeproject.org/files/ENCFF304XEX/@@download/ENCFF304XEX.bed.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/805e179275a9c0fb7a37def40c4312d1/ENCFF304XEX.bed.gz
2022-03-06 00:07:37,766|autouri.autouri|INFO| cp: (2f87a11e) skipped due to name_size_match. size=14377496, mt=1592463730.0
2022-03-06 00:07:37,867|autouri.autouri|INFO| cp: (a7a00986) started. src=https://www.encodeproject.org/files/ENCFF140XLU/@@download/ENCFF140XLU.bed.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/0cbd2c602ddad252bc39729fc8a29286/ENCFF140XLU.bed.gz
2022-03-06 00:07:39,122|autouri.autouri|INFO| cp: (a7a00986) skipped due to md5_match. md5=91047588129069ff91ec1b0664179f8e
2022-03-06 00:07:39,215|autouri.autouri|INFO| cp: (db9320cd) started. src=https://www.encodeproject.org/files/ENCFF212UAV/@@download/ENCFF212UAV.bed.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/1d3aa436b05f16a509edb94789c061d3/ENCFF212UAV.bed.gz
2022-03-06 00:07:40,931|autouri.autouri|INFO| cp: (db9320cd) skipped due to name_size_match. size=18381891, mt=1592463727.0
2022-03-06 00:07:41,032|autouri.autouri|INFO| cp: (c192ef15) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38/ataqc/hg38_dnase_avg_fseq_signal_formatted.txt.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/3b39284516e676ea52238f0636c0bbbf/hg38_dnase_avg_fseq_signal_formatted.txt.gz
2022-03-06 00:07:41,485|autouri.autouri|INFO| cp: (c192ef15) skipped due to md5_match. md5=df624401f76fbd4d651e736068c43a1a
2022-03-06 00:07:41,584|autouri.autouri|INFO| cp: (0aa7e5d2) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38/ataqc/hg38_celltype_compare_subsample.bed.gz, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/c73f434c3fa4f3f54bc2ecad09c065c2/hg38_celltype_compare_subsample.bed.gz
2022-03-06 00:07:42,008|autouri.autouri|INFO| cp: (0aa7e5d2) skipped due to md5_match. md5=ced0c653d28628654288f7a8ab052590
2022-03-06 00:07:42,108|autouri.autouri|INFO| cp: (dfbf40b5) started. src=https://storage.googleapis.com/encode-pipeline-genome-data/hg38/ataqc/hg38_dnase_avg_fseq_signal_metadata.txt, dest=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/a9745b33b4ffdd83d7d2c5a7d3c8036a/hg38_dnase_avg_fseq_signal_metadata.txt
2022-03-06 00:07:42,408|autouri.autouri|INFO| cp: (dfbf40b5) skipped due to md5_match. md5=3f7fd85ab9a4c6274f28c3e82a79c10d
2022-03-06 00:07:44,996|caper.wdl_parser|ERROR| Failed to parse WDL with miniwdl.
2022-03-06 00:07:45,098|caper.caper_workflow_opts|INFO| Conda environment name not found in WDL metadata. wdl=/home/shirleytemples/chip-seq-pipeline2/chip.wdl
2022-03-06 00:07:45,246|caper.cromwell|INFO| Validating WDL/inputs/imports with Womtool...
2022-03-06 00:08:55,449|caper.cromwell|INFO| Passed Womtool validation.
2022-03-06 00:08:55,641|caper.caper_runner|INFO| launching run: wdl=/home/shirleytemples/chip-seq-pipeline2/chip.wdl, inputs=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/mnt/c/users/shirl/Desktop/guttman_lab/CTCF.local.json, backend_conf=/home/shirleytemples/chip-seq-pipeline2/.caper_tmp/chip/20220306_000720_576058/backend.conf
2022-03-06 00:10:54,066|caper.cromwell_workflow_monitor|INFO| Workflow: id=f7347247-01cf-446d-8ab2-263fc28712e8, status=Running
2022-03-06 00:10:55,496|caper.cromwell_workflow_monitor|INFO| Workflow: id=f7347247-01cf-446d-8ab2-263fc28712e8, status=Submitted
2022-03-06 00:13:34,964|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.read_genome_tsv:-1, retry=0, status=Started, job_id=4143
2022-03-06 00:13:35,314|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.read_genome_tsv:-1, retry=0, status=WaitingForReturnCode
2022-03-06 00:13:48,125|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.read_genome_tsv:-1, retry=0, status=Done
2022-03-06 00:14:39,011|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.bam2ta_ctl:0, retry=0, status=Started, job_id=4207
2022-03-06 00:14:39,183|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.bam2ta_ctl:0, retry=0, status=WaitingForReturnCode
2022-03-06 00:15:04,638|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.bam2ta:0, retry=0, status=Started, job_id=4246
2022-03-06 00:15:05,027|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.bam2ta:0, retry=0, status=WaitingForReturnCode
2022-03-06 00:15:54,765|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.jsd:-1, retry=0, status=Started, job_id=4295
2022-03-06 00:15:54,777|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.jsd:-1, retry=0, status=WaitingForReturnCode
2022-03-06 00:36:03,460|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.bam2ta_ctl:0, retry=0, status=Done


2022-03-06 01:25:58,884|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.bam2ta:0, retry=0, status=Done
2022-03-06 01:26:08,571|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.spr:0, retry=0, status=Started, job_id=5201
2022-03-06 01:26:08,627|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.spr:0, retry=0, status=WaitingForReturnCode
2022-03-06 01:26:13,690|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.choose_ctl:-1, retry=0, status=Started, job_id=5304
2022-03-06 01:26:13,713|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.xcor:0, retry=0, status=Started, job_id=5248
2022-03-06 01:26:13,714|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.choose_ctl:-1, retry=0, status=WaitingForReturnCode
2022-03-06 01:26:13,715|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.xcor:0, retry=0, status=WaitingForReturnCode
2022-03-06 01:26:34,516|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.choose_ctl:-1, retry=0, status=Done
2022-03-06 01:28:30,335|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.jsd:-1, retry=0, status=Done
2022-03-06 01:29:38,842|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.spr:0, retry=0, status=Done
2022-03-06 01:39:08,928|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.xcor:0, retry=0, status=Done
2022-03-06 01:39:18,570|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.fraglen_mean:-1, retry=0, status=Started, job_id=5652
2022-03-06 01:39:18,570|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak:0, retry=0, status=Started, job_id=5605
2022-03-06 01:39:18,571|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.fraglen_mean:-1, retry=0, status=WaitingForReturnCode
2022-03-06 01:39:18,571|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak:0, retry=0, status=WaitingForReturnCode
2022-03-06 01:39:23,563|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.macs2_signal_track:0, retry=0, status=Started, job_id=5745
2022-03-06 01:39:23,566|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak_pr1:0, retry=0, status=Started, job_id=5793
2022-03-06 01:39:23,570|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak_pr2:0, retry=0, status=Started, job_id=5697
2022-03-06 01:39:23,575|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.macs2_signal_track:0, retry=0, status=WaitingForReturnCode
2022-03-06 01:39:23,576|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak_pr1:0, retry=0, status=WaitingForReturnCode
2022-03-06 01:39:23,578|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak_pr2:0, retry=0, status=WaitingForReturnCode
2022-03-06 01:39:25,216|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.fraglen_mean:-1, retry=0, status=Done
2022-03-06 01:41:12,368|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.macs2_signal_track:0, retry=0, status=Done
2022-03-06 02:06:23,162|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak_pr2:0, retry=0, status=Done
2022-03-06 02:06:28,547|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak_pr2:0, retry=1, status=Started, job_id=7669
2022-03-06 02:06:28,549|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak_pr2:0, retry=1, status=WaitingForReturnCode
2022-03-06 02:07:29,211|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak_pr1:0, retry=0, status=Done
2022-03-06 02:07:38,561|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak_pr1:0, retry=1, status=Started, job_id=7775
2022-03-06 02:07:38,562|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak_pr1:0, retry=1, status=WaitingForReturnCode
2022-03-06 02:18:56,769|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak:0, retry=0, status=Done
2022-03-06 02:19:03,559|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak:0, retry=1, status=Started, job_id=8135
2022-03-06 02:19:03,560|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak:0, retry=1, status=WaitingForReturnCode
2022-03-06 02:26:35,273|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak_pr2:0, retry=1, status=Done
2022-03-06 02:30:32,518|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak_pr1:0, retry=1, status=Done
2022-03-06 02:48:37,810|caper.cromwell_workflow_monitor|INFO| Task: id=f7347247-01cf-446d-8ab2-263fc28712e8, task=chip.call_peak:0, retry=1, status=Done
2022-03-06 02:48:38,347|caper.cromwell_workflow_monitor|INFO| Workflow: id=f7347247-01cf-446d-8ab2-263fc28712e8, status=Failed
2022-03-06 02:48:58,507|caper.cromwell_metadata|INFO| Wrote metadata file. /home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/metadata.json
2022-03-06 02:48:58,509|caper.cromwell|INFO| Workflow failed. Auto-troubleshooting...
* Started troubleshooting workflow: id=f7347247-01cf-446d-8ab2-263fc28712e8, status=Failed
* Found failures JSON object.
[
    {
        ""message"": ""Workflow failed"",
        ""causedBy"": [
            {
                ""causedBy"": [],
                ""message"": ""Job chip.call_peak_pr2:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            },
            {
                ""causedBy"": [],
                ""message"": ""Job chip.call_peak_pr1:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            },
            {
                ""causedBy"": [],
                ""message"": ""Job chip.call_peak:0:2 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.""
            }
        ]
    }
]
* Recursively finding failures in calls (tasks)...

==== NAME=chip.call_peak, STATUS=RetryableFailure, PARENT=
SHARD_IDX=0, RC=1, JOB_ID=5605
START=2022-03-06T09:39:15.370Z, END=2022-03-06T10:18:58.555Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 123, in main
    'No peaks found. FDR threshold (fdr_thresh in your input JSON) '
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 218, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (all-CTCF_x_Control_ChIP-seq_hg38_K562.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?

STDERR_BACKGROUND_CONTENTS=
Traceback (most recent call last):
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 123, in main
    'No peaks found. FDR threshold (fdr_thresh in your input JSON) '
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 218, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (all-CTCF_x_Control_ChIP-seq_hg38_K562.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/execution/*.num_peak.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/execution/*.peak_region_size.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/execution/*.peak_region_size.png': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/execution/*.frip.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/execution/*.bfilt.regionPeak.gz': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/execution/*.bfilt.regionPeak.bb': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/execution/*.bfilt.regionPeak.starch': No such file or directory
mkdir: cannot create directory â€˜/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/execution/glob-c71d4cca8627aab27dc3503b7db7a39dâ€™: File exists
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory



==== NAME=chip.call_peak, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=1, JOB_ID=8135
START=2022-03-06T10:18:59.364Z, END=2022-03-06T10:48:37.827Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/attempt-2/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 123, in main
    'No peaks found. FDR threshold (fdr_thresh in your input JSON) '
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 218, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (all-CTCF_x_Control_ChIP-seq_hg38_K562.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?

STDERR_BACKGROUND_CONTENTS=
Traceback (most recent call last):
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 123, in main
    'No peaks found. FDR threshold (fdr_thresh in your input JSON) '
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 218, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (all-CTCF_x_Control_ChIP-seq_hg38_K562.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/attempt-2/execution/*.num_peak.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/attempt-2/execution/*.peak_region_size.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/attempt-2/execution/*.peak_region_size.png': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/attempt-2/execution/*.frip.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/attempt-2/execution/*.bfilt.regionPeak.gz': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/attempt-2/execution/*.bfilt.regionPeak.bb': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/attempt-2/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/attempt-2/execution/*.bfilt.regionPeak.starch': No such file or directory
mkdir: cannot create directory â€˜/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/attempt-2/execution/glob-c71d4cca8627aab27dc3503b7db7a39dâ€™: File exists
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak/shard-0/attempt-2/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory



==== NAME=chip.call_peak_pr1, STATUS=RetryableFailure, PARENT=
SHARD_IDX=0, RC=1, JOB_ID=5793
START=2022-03-06T09:39:23.366Z, END=2022-03-06T10:07:33.559Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 123, in main
    'No peaks found. FDR threshold (fdr_thresh in your input JSON) '
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 218, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (all-CTCF.pr1_x_Control_ChIP-seq_hg38_K562.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?

STDERR_BACKGROUND_CONTENTS=
Traceback (most recent call last):
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 123, in main
    'No peaks found. FDR threshold (fdr_thresh in your input JSON) '
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 218, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (all-CTCF.pr1_x_Control_ChIP-seq_hg38_K562.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/execution/*.num_peak.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/execution/*.peak_region_size.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/execution/*.peak_region_size.png': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/execution/*.frip.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/execution/*.bfilt.regionPeak.gz': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/execution/*.bfilt.regionPeak.bb': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/execution/*.bfilt.regionPeak.starch': No such file or directory
mkdir: cannot create directory â€˜/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/execution/glob-c71d4cca8627aab27dc3503b7db7a39dâ€™: File exists
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory



==== NAME=chip.call_peak_pr1, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=1, JOB_ID=7775
START=2022-03-06T10:07:35.892Z, END=2022-03-06T10:30:32.521Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/attempt-2/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 123, in main
    'No peaks found. FDR threshold (fdr_thresh in your input JSON) '
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 218, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (all-CTCF.pr1_x_Control_ChIP-seq_hg38_K562.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?

STDERR_BACKGROUND_CONTENTS=
Traceback (most recent call last):
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 123, in main
    'No peaks found. FDR threshold (fdr_thresh in your input JSON) '
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 218, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (all-CTCF.pr1_x_Control_ChIP-seq_hg38_K562.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/attempt-2/execution/*.num_peak.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/attempt-2/execution/*.peak_region_size.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/attempt-2/execution/*.peak_region_size.png': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/attempt-2/execution/*.frip.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/attempt-2/execution/*.bfilt.regionPeak.gz': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/attempt-2/execution/*.bfilt.regionPeak.bb': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/attempt-2/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/attempt-2/execution/*.bfilt.regionPeak.starch': No such file or directory
mkdir: cannot create directory â€˜/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/attempt-2/execution/glob-c71d4cca8627aab27dc3503b7db7a39dâ€™: File exists
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr1/shard-0/attempt-2/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory



==== NAME=chip.call_peak_pr2, STATUS=RetryableFailure, PARENT=
SHARD_IDX=0, RC=1, JOB_ID=5697
START=2022-03-06T09:39:19.347Z, END=2022-03-06T10:06:23.592Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 123, in main
    'No peaks found. FDR threshold (fdr_thresh in your input JSON) '
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 218, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (all-CTCF.pr2_x_Control_ChIP-seq_hg38_K562.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?

STDERR_BACKGROUND_CONTENTS=
Traceback (most recent call last):
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 123, in main
    'No peaks found. FDR threshold (fdr_thresh in your input JSON) '
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 218, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (all-CTCF.pr2_x_Control_ChIP-seq_hg38_K562.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/execution/*.num_peak.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/execution/*.peak_region_size.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/execution/*.peak_region_size.png': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/execution/*.frip.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/execution/*.bfilt.regionPeak.gz': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/execution/*.bfilt.regionPeak.bb': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/execution/*.bfilt.regionPeak.starch': No such file or directory
mkdir: cannot create directory â€˜/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/execution/glob-c71d4cca8627aab27dc3503b7db7a39dâ€™: File exists
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory



==== NAME=chip.call_peak_pr2, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=1, JOB_ID=7669
START=2022-03-06T10:06:25.414Z, END=2022-03-06T10:26:35.301Z
STDOUT=/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/attempt-2/execution/stdout
STDERR=/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 123, in main
    'No peaks found. FDR threshold (fdr_thresh in your input JSON) '
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 218, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (all-CTCF.pr2_x_Control_ChIP-seq_hg38_K562.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?

STDERR_BACKGROUND_CONTENTS=
Traceback (most recent call last):
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 133, in <module>
    main()
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_task_spp.py"", line 123, in main
    'No peaks found. FDR threshold (fdr_thresh in your input JSON) '
  File ""/home/shirleytemples/miniconda3/envs/encode-chip-seq-pipeline-spp/bin/encode_lib_common.py"", line 218, in assert_file_not_empty
    raise Exception('File is empty ({}). Help: {}'.format(f, help))
Exception: File is empty (all-CTCF.pr2_x_Control_ChIP-seq_hg38_K562.300K.regionPeak.gz). Help: No peaks found. FDR threshold (fdr_thresh in your input JSON) might be too stringent or poor quality sample?
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/attempt-2/execution/*.num_peak.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/attempt-2/execution/*.peak_region_size.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/attempt-2/execution/*.peak_region_size.png': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/attempt-2/execution/*.frip.qc': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/attempt-2/execution/*.bfilt.regionPeak.gz': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/attempt-2/execution/*.bfilt.regionPeak.bb': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/attempt-2/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/attempt-2/execution/*.bfilt.regionPeak.starch': No such file or directory
mkdir: cannot create directory â€˜/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/attempt-2/execution/glob-c71d4cca8627aab27dc3503b7db7a39dâ€™: File exists
ln: failed to access '/home/shirleytemples/chip-seq-pipeline2/chip/f7347247-01cf-446d-8ab2-263fc28712e8/call-call_peak_pr2/shard-0/attempt-2/execution/*.bfilt.regionPeak.hammock.gz*': No such file or directory


2022-03-06 02:48:58,707|caper.nb_subproc_thread|ERROR| Cromwell failed. returncode=1
2022-03-06 02:48:58,709|caper.cli|ERROR| Check stdout in /home/shirleytemples/chip-seq-pipeline2/cromwell.out.69
```",shirleytemples,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/272
I_kwDOBrDQms5Fu4VK,Advice on output folders/files,CLOSED,2022-03-15T16:36:52Z,2022-04-05T20:38:10Z,2022-04-05T20:38:10Z,"I've successfully ran the ChIP-seq pipeline and need advice interpreting the folders/files. The size of my output folder is 176 GB and I'm trying to determine which files to use for downstream analyses (peak, motif analysis, etc.). 

There are dozens of folders containing many more subfolders and files so I'm not sure which of these I should keep and which I can trash. 
<img width=""364"" alt=""idr output"" src=""https://user-images.githubusercontent.com/61433004/158424873-4ea272bf-bd2d-4e0a-8927-b9b9f092bd63.png"">
 
I was able to successfully find the qc.html file but I believe I will at minimum need the conservative and optimal peakset bed files and bigwig files.  ",gene-drive,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/273
I_kwDOBrDQms5HJk6T,Pipeline stalls before IDR steps,OPEN,2022-04-05T20:37:19Z,2022-05-12T20:43:12Z,,"## **Describe the bug**
The pipeline stalls or ends prematurely before the IDR steps. 
I have successfully run the pipeline on datasets using the mm10 genome, but it stalls when I use custom genomes.

## **OS/Platform**
- OS/Platform: UGA Sapelo2 cluster
- Conda version: If you used Conda (`$ conda --version`).
- Pipeline version: 2.1.4
- Caper version: 2.1.3

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
backend=slurm

# define one of the followings (or both) according to your
# cluster's SLURM configuration.

# SLURM partition. Define only if required by a cluster. You must define it for Stanford Sherlock.
slurm-partition=batch
# SLURM account. Define only if required by a cluster. You must define it for Stanford SCG.
slurm-account=usr1lab


# This parameter is NOT for 'caper submit' BUT for 'caper run' and 'caper server' only.
# This resource parameter string will be passed to sbatch, qsub, bsub, ...
# You can customize it according to your cluster's configuration.

# Note that Cromwell's implicit type conversion (String to Integer)
# seems to be buggy for WomLong type memory variables (memory_mb and memory_gb).
# So be careful about using the + operator between WomLong and other types (String, even Int).
# For example, ${""--mem="" + memory_mb} will not work since memory_mb is WomLong.
# Use ${""if defined(memory_mb) then ""--mem="" else """"}{memory_mb}${""if defined(memory_mb) then ""mb "" else "" ""}
# See https://github.com/broadinstitute/cromwell/issues/4659 for details

# Cromwell's built-in variables (attributes defined in WDL task's runtime)
# Use them within ${} notation.
# - cpu: number of cores for a job (default = 1)
# - memory_mb, memory_gb: total memory for a job in MB, GB
#   * these are converted from 'memory' string attribute (including size unit)
#     defined in WDL task's runtime
# - time: time limit for a job in hour
# - gpu: specified gpu name or number of gpus (it's declared as String)

slurm-resource-param=-n 1 --ntasks-per-node=1 --cpus-per-task=${cpu} ${if defined(memory_mb) then ""--mem="" else """"}${memory_mb}${if defined(memory_mb) then ""M"" else """"} ${if defined(time) then ""--time="" else """"}${time*60} ${if defined(gpu) then ""--gres=gpu:"" else """"}${gpu} 

# If needed uncomment and define any extra SLURM sbatch parameters here
# YOU CANNOT USE WDL SYNTAX AND CROMWELL BUILT-IN VARIABLES HERE
#slurm-extra-param=

# Hashing strategy for call-caching (3 choices)
# This parameter is for local (local/slurm/sge/pbs/lsf) backend only.
# This is important for call-caching,
# which means re-using outputs from previous/failed workflows.
# Cache will miss if different strategy is used.
# ""file"" method has been default for all old versions of Caper<1.0.
# ""path+modtime"" is a new default for Caper>=1.0,
#   file: use md5sum hash (slow).
#   path: use path.
#   path+modtime: use path and modification time.
local-hash-strat=path+modtime

# Metadata DB for call-caching (reusing previous outputs):
# Cromwell supports restarting workflows based on a metadata DB
# DB is in-memory by default
#db=in-memory

# If you use 'caper server' then you can use one unified '--file-db'
# for all submitted workflows. In such case, uncomment the following two lines
# and defined file-db as an absolute path to store metadata of all workflows
#db=file
#file-db=

# If you use 'caper run' and want to use call-caching:
# Make sure to define different 'caper run ... --db file --file-db DB_PATH'
# for each pipeline run.
# But if you want to restart then define the same '--db file --file-db DB_PATH'
# then Caper will collect/re-use previous outputs without running the same task again
# Previous outputs will be simply hard/soft-linked.


# Local directory for localized files and Cromwell's intermediate files
# If not defined, Caper will make .caper_tmp/ on local-out-dir or CWD.
# /tmp is not recommended here since Caper store all localized data files
# on this directory (e.g. input FASTQs defined as URLs in input JSON).
local-loc-dir=

cromwell=/home/usr1/.caper/cromwell_jar/cromwell-65.jar
womtool=/home/usr1/.caper/womtool_jar/womtool-65.jar

```

## **Input JSON file**
Paste contents of your input JSON file.
```json
{
	""chip.pipeline_type"" : ""tf"",
	""chip.genome_tsv"" : ""/scratch/usr1/chrPicGB_IDR_v2/build_genome_output_10k/chrPic_GB_10k.tsv"",
	""chip.fastqs_rep1_R1"" : [""/scratch/usr1/chrPic1_IDR/ts_ChIP_R1.fastq.gz"" ],
	""chip.fastqs_rep2_R1"" : [""/scratch/usr1/chrPic1_IDR/ts_ChIP_R3.fastq.gz"" ],
	""chip.ctl_fastqs_rep1_R1"" : [""/scratch/usr1/chrPic1_IDR/input_R1.fastq.gz"" ],
	""chip.ctl_fastqs_rep2_R1"" : [""/scratch/usr1/chrPic1_IDR/nput_R3.fastq.gz"" ],
	""chip.paired_end"" : false,
	""chip.peak_caller"" : ""macs2"", 
	""chip.title"" : ""chrPic_GB_10k_macs2"",
	""chip.description"" : ""ChIP-Seq""
}
```

## **Troubleshooting result**

Below are some of the output logs from a run that ended prematurely. 

[cromwell.out.log](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/8420842/cromwell.out.log)
[output.err.log](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/8420939/output.err.log)
[output.out.log](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/8420940/output.out.log)

",gene-drive,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/276
I_kwDOBrDQms5HLw_q,can this wdl pipeline be run with cromwell engine?,OPEN,2022-04-06T08:34:50Z,2022-04-06T08:34:50Z,,"Hi, 
I am wondering if this wdl pipeline can be run by cromwell engine.

Best regards!",gudeqing,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/277
I_kwDOBrDQms5HNUT5,Terra output missing metadata.json,OPEN,2022-04-06T14:09:22Z,2022-08-04T16:56:05Z,,"Hello, I am wondering if it is possible to get the Terra workflow to generate the metadata.json file with paths to all relevant results. Would significantly improve the usability of the pipeline in Terra. Thanks in advance.",elisadonnard,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/278
I_kwDOBrDQms5JTGBC,Problem about build_genome_data.sh,CLOSED,2022-05-09T13:48:22Z,2023-01-24T23:43:45Z,2023-01-24T23:43:44Z,"I'm trying to use this script to build my own genome data. I found that if I set `REF_FA=somegenome.fa`, this script will remove '.fa' file as a tmp file in line 292~294 and set the corresponding '.gz' file as ref_fa in the final TSV file. But I failed to find lines to compress the original fa file. So when I carry on analyses with the built genome TSV, I will encounter an error that the '.fa.gz' file cannot be found. I suggest adding a line like `gzip -nc ${REF_FA_PREFIX} > ${REF_FA_PREFIX}.gz` after line 212. Thank you for this pipeline.",Mozillian1,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/279
I_kwDOBrDQms5LUXJR,Where are the peak files from MACS2 output stored?,OPEN,2022-06-07T17:20:18Z,2022-06-07T17:20:18Z,,"In an older version of the pipeline, the narrowPeak outputs from MACS2 were stored in ./peak/macs2/ 

<img width=""847"" alt=""Screenshot 2022-06-07 131503"" src=""https://user-images.githubusercontent.com/61433004/172443863-842ed077-d983-4723-8573-c00a07657120.png"">

Where are these stored in the current pipeline's output?",gene-drive,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/280
I_kwDOBrDQms5LtHSa,Are adapter-trimmed FASTQs required?,OPEN,2022-06-14T00:50:07Z,2023-03-10T06:48:50Z,,I was wondering why the ChIP-Seq pipeline doesn't include an adapter trimming step like in the ATAC-Seq pipeline. Are adapter-trimmed FASTQs required for this pipeline?,benayang,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/283
I_kwDOBrDQms5MJTms,HELP: call-xcor fails with TEST command,OPEN,2022-06-20T23:52:05Z,2022-06-23T06:05:27Z,,"## **Describe the bug**
When running the newest pipeline (v2.2.0) with TEST command `caper run chip.wdl -i https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI_subsampled_chr19_only.json --conda`, it returns errors due to `could not find function ""startsWith""` at `xcor` steps. 

I noticed that many issues related to `xcor` reported can be fixed by re-installing and -installing. But I tried several times, it still can not fix this issue.
In addition, when running the newest encode-atac-seq-pipeline with TEST command, I obtained the same error. 
Note `python=3.8.13`, `java=17.0.3.1` and `pip=22.1.2` are installed **locally**, and `caper` is installed based these.

## **OS/Platform**
- OS/Platform: Red Hat Enterprise Linux Server 7.7 (Maipo)
- Conda version: v4.12.0
- Pipeline version: v2.2.0
- Caper version: v2.2.0

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```
backend=local

# Local directory for localized files and Cromwell's intermediate files.
# If not defined then Caper will make .caper_tmp/ on CWD or `local-out-dir`.
# /tmp is not recommended since Caper store localized data files here.
local-loc-dir=

cromwell=/storage/taowu/home/u237039/.caper/cromwell_jar/cromwell-65.jar
womtool=/storage/taowu/home/u237039/.caper/womtool_jar/womtool-65.jar
```

## **Input JSON file**
Paste contents of your input JSON file.
```json
{
    ""chip.pipeline_type"" : ""tf"",
    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v3/hg38_chr19_chrM.tsv"",
    ""chip.fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep1.subsampled.25.fastq.gz""
    ],
    ""chip.fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep2.subsampled.20.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl1.subsampled.25.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl2.subsampled.25.fastq.gz""
    ],
    ""chip.paired_end"" : false,
    ""chip.title"" : ""ENCSR000DYI (subsampled 1/25, chr19_chrM only)"",
    ""chip.description"" : ""CEBPB ChIP-seq on human A549 produced by the Snyder lab""
}
```

## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
```
* Recursively finding failures in calls (tasks)...

==== NAME=atac.xcor, STATUS=RetryableFailure, PARENT=
SHARD_IDX=0, RC=1, JOB_ID=242459
START=2022-06-20T23:33:11.689Z, END=2022-06-20T23:33:27.424Z
STDOUT=/storage/taowu/home/u237039/test/atac/atac/f4f1ee8d-81d6-47af-a1fb-3121489010cd/call-xcor/shard-0/execution/stdout
STDERR=/storage/taowu/home/u237039/test/atac/atac/f4f1ee8d-81d6-47af-a1fb-3121489010cd/call-xcor/shard-0/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=242723, PGID=242723, RC=1, DURATION_SEC=0.3
STDERR=Error in eval(expr, envir, enclos) : could not find function ""startsWith""
Calls: local -> eval.parent -> eval -> eval -> eval -> eval
Execution halted
STDOUT=

STDERR_BACKGROUND_CONTENTS=
Traceback (most recent call last):
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=242723, PGID=242723, RC=1, DURATION_SEC=0.3
STDERR=Error in eval(expr, envir, enclos) : could not find function ""startsWith""
Calls: local -> eval.parent -> eval -> eval -> eval -> eval
Execution halted
STDOUT=
ln: failed to access â€˜/storage/taowu/home/u237039/test/atac/atac/f4f1ee8d-81d6-47af-a1fb-3121489010cd/call-xcor/shard-0/execution/*.cc.plot.pngâ€™: No such file or directory
ln: failed to access â€˜/storage/taowu/home/u237039/test/atac/atac/f4f1ee8d-81d6-47af-a1fb-3121489010cd/call-xcor/shard-0/execution/*.cc.plot.pdfâ€™: No such file or directory
ln: failed to access â€˜/storage/taowu/home/u237039/test/atac/atac/f4f1ee8d-81d6-47af-a1fb-3121489010cd/call-xcor/shard-0/execution/*.cc.qcâ€™: No such file or directory



==== NAME=atac.xcor, STATUS=Failed, PARENT=
SHARD_IDX=0, RC=1, JOB_ID=243126
START=2022-06-20T23:33:29.799Z, END=2022-06-20T23:33:39.861Z
STDOUT=/storage/taowu/home/u237039/test/atac/atac/f4f1ee8d-81d6-47af-a1fb-3121489010cd/call-xcor/shard-0/attempt-2/execution/stdout
STDERR=/storage/taowu/home/u237039/test/atac/atac/f4f1ee8d-81d6-47af-a1fb-3121489010cd/call-xcor/shard-0/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=243307, PGID=243307, RC=1, DURATION_SEC=0.1
STDERR=Error in eval(expr, envir, enclos) : could not find function ""startsWith""
Calls: local -> eval.parent -> eval -> eval -> eval -> eval
Execution halted
STDOUT=

STDERR_BACKGROUND_CONTENTS=
Traceback (most recent call last):
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_task_xcor.py"", line 156, in <module>
    main()
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_task_xcor.py"", line 144, in main
    args.chip_seq_type, args.exclusion_range_min, args.exclusion_range_max)
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_task_xcor.py"", line 105, in xcor
    run_shell_cmd(cmd1)
  File ""/storage/taowu/home/u237039/install/miniconda3/envs/encd-atac-spp/bin/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=243307, PGID=243307, RC=1, DURATION_SEC=0.1
STDERR=Error in eval(expr, envir, enclos) : could not find function ""startsWith""
Calls: local -> eval.parent -> eval -> eval -> eval -> eval
Execution halted
STDOUT=
ln: failed to access â€˜/storage/taowu/home/u237039/test/atac/atac/f4f1ee8d-81d6-47af-a1fb-3121489010cd/call-xcor/shard-0/attempt-2/execution/*.cc.plot.pngâ€™: No such file or directory
ln: failed to access â€˜/storage/taowu/home/u237039/test/atac/atac/f4f1ee8d-81d6-47af-a1fb-3121489010cd/call-xcor/shard-0/attempt-2/execution/*.cc.plot.pdfâ€™: No such file or directory
ln: failed to access â€˜/storage/taowu/home/u237039/test/atac/atac/f4f1ee8d-81d6-47af-a1fb-3121489010cd/call-xcor/shard-0/attempt-2/execution/*.cc.qcâ€™: No such file or directory

```
",yinyeya,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/284
I_kwDOBrDQms5P_Rha,Conflicts while running scripts/install_conda_env.sh,OPEN,2022-08-17T16:02:44Z,2022-09-08T16:53:26Z,,"## **Describe the bug**
When running the install_conda_env.sh script to setup the conda environments, there are many conflicts that are found, causing the install to fail.

It seems to be the encd-chip and encd-chip-spp failing. The encd-chip-macs2 environment installs fine.
```
conda create -n encd-chip --file ${SH_SCRIPT_DIR}/requirements.txt \
  --override-channels -c bioconda -c defaults -y

...

conda create -n encd-chip-spp --file ${SH_SCRIPT_DIR}/requirements.spp.txt \
  --override-channels -c r -c bioconda -c defaults -y

```

## **OS/Platform**
- OS/Platform: Ubuntu 20.04
- Conda version: 4.13.0
- Pipeline version: v2.2.0
- Caper version: 2.2.2

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
backend=local

# Local directory for localized files and Cromwell's intermediate files.
# If not defined then Caper will make .caper_tmp/ on CWD or `local-out-dir`.
# /tmp is not recommended since Caper store localized data files here.
local-loc-dir=

cromwell=/home/andrew/.caper/cromwell_jar/cromwell-82.jar
womtool=/home/andrew/.caper/womtool_jar/womtool-82.jar
```


## **Troubleshooting result**
Here is the beginning output from trying to install encd-chip-spp
```
Wed 17 Aug 2022 11:50:30 AM EDT: Installing pipeline's Conda environments...
Collecting package metadata (current_repodata.json): done
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: / 
Found conflicts! Looking for incompatible packages.
This can take several minutes.  Press CTRL-C to abort.
...
```

Here is the full output for trying to install encd-chip-spp
[failed.chip.pipeline.install.conda.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/9364462/failed.chip.pipeline.install.conda.txt)
",agduncan94,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/285
I_kwDOBrDQms5VmUYP,caper.wdl_parser|ERROR| Failed to parse WDL with miniwdl.,CLOSED,2022-11-04T13:52:57Z,2022-11-07T06:29:37Z,2022-11-07T06:29:37Z,"Hi,
I am trying to use this pipeline for the first time. And I meet this error.
when i follow the [README.md](https://github.com/ENCODE-DCC/chip-seq-pipeline2#readme). the command like this :
$ caper run chip.wdl -i ""${INPUT_JSON}"" --singularity  docker://ubuntu:latest
```
2022-11-04 21:47:02,661|caper.cli|INFO| Cromwell stdout: /public/home/luzhang/tmp/test/cromwell.out.3
2022-11-04 21:47:02,663|caper.caper_base|INFO| Creating a timestamped temporary directory. /public/home/luzhang/caper_tmp/chip/20221104_214702_663539
2022-11-04 21:47:02,664|caper.caper_runner|INFO| Localizing files on work_dir. /public/home/luzhang/caper_tmp/chip/20221104_214702_663539
2022-11-04 21:47:03,922|caper.wdl_parser|ERROR| Failed to parse WDL with miniwdl.
2022-11-04 21:47:03,931|caper.cromwell|INFO| Validating WDL/inputs/imports with Womtool...
2022-11-04 21:47:05,600|caper.nb_subproc_thread|ERROR| Subprocess failed. returncode=1
Traceback (most recent call last):
  File ""/public/home/luzhang/miniconda3/bin/caper"", line 13, in <module>
    main()
  File ""/public/home/luzhang/miniconda3/lib/python3.8/site-packages/caper/cli.py"", line 713, in main
    return runner(parsed_args, nonblocking_server=nonblocking_server)
  File ""/public/home/luzhang/miniconda3/lib/python3.8/site-packages/caper/cli.py"", line 255, in runner
    subcmd_run(c, args)
  File ""/public/home/luzhang/miniconda3/lib/python3.8/site-packages/caper/cli.py"", line 386, in subcmd_run
    thread = caper_runner.run(
  File ""/public/home/luzhang/miniconda3/lib/python3.8/site-packages/caper/caper_runner.py"", line 462, in run
    self._cromwell.validate(wdl=wdl, inputs=inputs, imports=imports)
  File ""/public/home/luzhang/miniconda3/lib/python3.8/site-packages/caper/cromwell.py"", line 160, in validate
    raise WomtoolValidationFailed(
caper.cromwell.WomtoolValidationFailed: RC=1
STDERR=Unrecognized token on line 28, column 46:

    <meta name=""optimizely-datafile"" content=""{&quot;groups&quot;: [], &quot;environmentKey&quot;: &quot;production&quot;, &quot;rollouts&quot;: [], &quot;typedAudiences&quot;: [], &quot;projectId&quot;: &quot;16737760170&quot;, &quot;variables&quot;: [], &quot;featureFlags&quot;: [], &quot;experiments&quot;: [], &quot;version&quot;: &quot;4&quot;, &quot;audiences&quot;: [{&quot;conditions&quot;: &quot;[\&quot;or\&quot;, {\&quot;match\&quot;: \&quot;exact\&quot;, \&quot;name\&quot;: \&quot;$opt_dummy_attribute\&quot;, \&quot;type\&quot;: \&quot;custom_attribute\&quot;, \&quot;value\&quot;: \&quot;$opt_dummy_value\&quot;}]&quot;, &quot;id&quot;: &quot;$opt_dummy_audience&quot;, &quot;name&quot;: &quot;Optimizely-Generated Audience for Backwards Compatibility&quot;}], &quot;anonymizeIP&quot;: true, &quot;sdkKey&quot;: &quot;WTc6awnGuYDdG98CYRban&quot;, &quot;attributes&quot;: [{&quot;id&quot;: &quot;16822470375&quot;, &quot;key&quot;: &quot;user_id&quot;}, {&quot;id&quot;: &quot;17143601254&quot;, &quot;key&quot;: &quot;spammy&quot;}, {&quot;id&quot;: &quot;18175660309&quot;, &quot;key&quot;: &quot;organization_plan&quot;}, {&quot;id&quot;: &quot;18813001570&quot;, &quot;key&quot;: &quot;is_logged_in&quot;}, {&quot;id&quot;: &quot;19073851829&quot;, &quot;key&quot;: &quot;geo&quot;}, {&quot;id&quot;: &quot;20175462351&quot;, &quot;key&quot;: &quot;requestedCurrency&quot;}, {&quot;id&quot;: &quot;20785470195&quot;, &quot;key&quot;: &quot;country_code&quot;}, {&quot;id&quot;: &quot;21656311196&quot;, &quot;key&quot;: &quot;opened_downgrade_dialog&quot;}], &quot;botFiltering&quot;: false, &quot;accountId&quot;: &quot;16737760170&quot;, &quot;events&quot;: [{&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;17911811441&quot;, &quot;key&quot;: &quot;hydro_click.dashboard.teacher_toolbox_cta&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18124116703&quot;, &quot;key&quot;: &quot;submit.organizations.complete_sign_up&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18145892387&quot;, &quot;key&quot;: &quot;no_metric.tracked_outside_of_optimizely&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18178755568&quot;, &quot;key&quot;: &quot;click.org_onboarding_checklist.add_repo&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18180553241&quot;, &quot;key&quot;: &quot;submit.repository_imports.create&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18186103728&quot;, &quot;key&quot;: &quot;click.help.learn_more_about_repository_creation&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18188530140&quot;, &quot;key&quot;: &quot;test_event&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18191963644&quot;, &quot;key&quot;: &quot;click.empty_org_repo_cta.transfer_repository&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18195612788&quot;, &quot;key&quot;: &quot;click.empty_org_repo_cta.import_repository&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18210945499&quot;, &quot;key&quot;: &quot;click.org_onboarding_checklist.invite_members&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18211063248&quot;, &quot;key&quot;: &quot;click.empty_org_repo_cta.create_repository&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18215721889&quot;, &quot;key&quot;: &quot;click.org_onboarding_checklist.update_profile&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18224360785&quot;, &quot;key&quot;: &quot;click.org_onboarding_checklist.dismiss&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18234832286&quot;, &quot;key&quot;: &quot;submit.organization_activation.complete&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18252392383&quot;, &quot;key&quot;: &quot;submit.org_repository.create&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18257551537&quot;, &quot;key&quot;: &quot;submit.org_member_invitation.create&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18259522260&quot;, &quot;key&quot;: &quot;submit.organization_profile.update&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18564603625&quot;, &quot;key&quot;: &quot;view.classroom_select_organization&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18568612016&quot;, &quot;key&quot;: &quot;click.classroom_sign_in_click&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18572592540&quot;, &quot;key&quot;: &quot;view.classroom_name&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18574203855&quot;, &quot;key&quot;: &quot;click.classroom_create_organization&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18582053415&quot;, &quot;key&quot;: &quot;click.classroom_select_organization&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18589463420&quot;, &quot;key&quot;: &quot;click.classroom_create_classroom&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18591323364&quot;, &quot;key&quot;: &quot;click.classroom_create_first_classroom&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18591652321&quot;, &quot;key&quot;: &quot;click.classroom_grant_access&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18607131425&quot;, &quot;key&quot;: &quot;view.classroom_creation&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;18831680583&quot;, &quot;key&quot;: &quot;upgrade_account_plan&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;19064064515&quot;, &quot;key&quot;: &quot;click.signup&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;19075373687&quot;, &quot;key&quot;: &quot;click.view_account_billing_page&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;19077355841&quot;, &quot;key&quot;: &quot;click.dismiss_signup_prompt&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;19079713938&quot;, &quot;key&quot;: &quot;click.contact_sales&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;19120963070&quot;, &quot;key&quot;: &quot;click.compare_account_plans&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;19151690317&quot;, &quot;key&quot;: &quot;click.upgrade_account_cta&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;19424193129&quot;, &quot;key&quot;: &quot;click.open_account_switcher&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;19520330825&quot;, &quot;key&quot;: &quot;click.visit_account_profile&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;19540970635&quot;, &quot;key&quot;: &quot;click.switch_account_context&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;19730198868&quot;, &quot;key&quot;: &quot;submit.homepage_signup&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;19820830627&quot;, &quot;key&quot;: &quot;click.homepage_signup&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;19988571001&quot;, &quot;key&quot;: &quot;click.create_enterprise_trial&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20036538294&quot;, &quot;key&quot;: &quot;click.create_organization_team&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20040653299&quot;, &quot;key&quot;: &quot;click.input_enterprise_trial_form&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20062030003&quot;, &quot;key&quot;: &quot;click.continue_with_team&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20068947153&quot;, &quot;key&quot;: &quot;click.create_organization_free&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20086636658&quot;, &quot;key&quot;: &quot;click.signup_continue.username&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20091648988&quot;, &quot;key&quot;: &quot;click.signup_continue.create_account&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20103637615&quot;, &quot;key&quot;: &quot;click.signup_continue.email&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20111574253&quot;, &quot;key&quot;: &quot;click.signup_continue.password&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20120044111&quot;, &quot;key&quot;: &quot;view.pricing_page&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20152062109&quot;, &quot;key&quot;: &quot;submit.create_account&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20165800992&quot;, &quot;key&quot;: &quot;submit.upgrade_payment_form&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20171520319&quot;, &quot;key&quot;: &quot;submit.create_organization&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20222645674&quot;, &quot;key&quot;: &quot;click.recommended_plan_in_signup.discuss_your_needs&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20227443657&quot;, &quot;key&quot;: &quot;submit.verify_primary_user_email&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20234607160&quot;, &quot;key&quot;: &quot;click.recommended_plan_in_signup.try_enterprise&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20238175784&quot;, &quot;key&quot;: &quot;click.recommended_plan_in_signup.team&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20239847212&quot;, &quot;key&quot;: &quot;click.recommended_plan_in_signup.continue_free&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20251097193&quot;, &quot;key&quot;: &quot;recommended_plan&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20438619534&quot;, &quot;key&quot;: &quot;click.pricing_calculator.1_member&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20456699683&quot;, &quot;key&quot;: &quot;click.pricing_calculator.15_members&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20467868331&quot;, &quot;key&quot;: &quot;click.pricing_calculator.10_members&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20476267432&quot;, &quot;key&quot;: &quot;click.trial_days_remaining&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20476357660&quot;, &quot;key&quot;: &quot;click.discover_feature&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20479287901&quot;, &quot;key&quot;: &quot;click.pricing_calculator.custom_members&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20481107083&quot;, &quot;key&quot;: &quot;click.recommended_plan_in_signup.apply_teacher_benefits&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20483089392&quot;, &quot;key&quot;: &quot;click.pricing_calculator.5_members&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20484283944&quot;, &quot;key&quot;: &quot;click.onboarding_task&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20484996281&quot;, &quot;key&quot;: &quot;click.recommended_plan_in_signup.apply_student_benefits&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20486713726&quot;, &quot;key&quot;: &quot;click.onboarding_task_breadcrumb&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20490791319&quot;, &quot;key&quot;: &quot;click.upgrade_to_enterprise&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20491786766&quot;, &quot;key&quot;: &quot;click.talk_to_us&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20494144087&quot;, &quot;key&quot;: &quot;click.dismiss_enterprise_trial&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20499722759&quot;, &quot;key&quot;: &quot;completed_all_tasks&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20500710104&quot;, &quot;key&quot;: &quot;completed_onboarding_tasks&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20513160672&quot;, &quot;key&quot;: &quot;click.read_doc&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20516196762&quot;, &quot;key&quot;: &quot;actions_enabled&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20518980986&quot;, &quot;key&quot;: &quot;click.dismiss_trial_banner&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20535446721&quot;, &quot;key&quot;: &quot;click.issue_actions_prompt.dismiss_prompt&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20557002247&quot;, &quot;key&quot;: &quot;click.issue_actions_prompt.setup_workflow&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20595070227&quot;, &quot;key&quot;: &quot;click.pull_request_setup_workflow&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20626600314&quot;, &quot;key&quot;: &quot;click.seats_input&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20642310305&quot;, &quot;key&quot;: &quot;click.decrease_seats_number&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20662990045&quot;, &quot;key&quot;: &quot;click.increase_seats_number&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20679620969&quot;, &quot;key&quot;: &quot;click.public_product_roadmap&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20761240940&quot;, &quot;key&quot;: &quot;click.dismiss_survey_banner&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20767210721&quot;, &quot;key&quot;: &quot;click.take_survey&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20795281201&quot;, &quot;key&quot;: &quot;click.archive_list&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20966790249&quot;, &quot;key&quot;: &quot;contact_sales.submit&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20996500333&quot;, &quot;key&quot;: &quot;contact_sales.existing_customer&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;20996890162&quot;, &quot;key&quot;: &quot;contact_sales.blank_message_field&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21000470317&quot;, &quot;key&quot;: &quot;contact_sales.personal_email&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21002790172&quot;, &quot;key&quot;: &quot;contact_sales.blank_phone_field&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21354412592&quot;, &quot;key&quot;: &quot;click.dismiss_create_readme&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21366102546&quot;, &quot;key&quot;: &quot;click.dismiss_zero_user_content&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21370252505&quot;, &quot;key&quot;: &quot;account_did_downgrade&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21370840408&quot;, &quot;key&quot;: &quot;click.cta_create_readme&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21375451068&quot;, &quot;key&quot;: &quot;click.cta_create_new_repository&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21385390948&quot;, &quot;key&quot;: &quot;click.zero_user_content&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21467712175&quot;, &quot;key&quot;: &quot;click.downgrade_keep&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21484112202&quot;, &quot;key&quot;: &quot;click.downgrade&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21495292213&quot;, &quot;key&quot;: &quot;click.downgrade_survey_exit&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21508241468&quot;, &quot;key&quot;: &quot;click.downgrade_survey_submit&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21512030356&quot;, &quot;key&quot;: &quot;click.downgrade_support&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21539090022&quot;, &quot;key&quot;: &quot;click.downgrade_exit&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21543640644&quot;, &quot;key&quot;: &quot;click_fetch_upstream&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21646510300&quot;, &quot;key&quot;: &quot;click.move_your_work&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21656151116&quot;, &quot;key&quot;: &quot;click.add_branch_protection_rule&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21663860599&quot;, &quot;key&quot;: &quot;click.downgrade_dialog_open&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21687860483&quot;, &quot;key&quot;: &quot;click.learn_about_protected_branches&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21689050333&quot;, &quot;key&quot;: &quot;click.dismiss_protect_this_branch&quot;}, {&quot;experimentIds&quot;: [], &quot;id&quot;: &quot;21864370109&quot;, &quot;key&quot;: &quot;click.sign_in&quot;}], &quot;revision&quot;: &quot;1367&quot;}"" />
                                             ^
```

~/.caper/default.conf
```
backend=lsf

# Local directory for localized files and Cromwell's intermediate files.
# If not defined then Caper will make .caper_tmp/ on CWD or `local-out-dir`.
# /tmp is not recommended since Caper store localized data files here.
local-loc-dir=/public/home/luzhang/caper_tmp

cromwell=/public/home/luzhang/.caper/cromwell_jar/cromwell-82.jar
womtool=/public/home/luzhang/.caper/womtool_jar/womtool-82.jar
```
Hope you can help me. many thanks.",wbszhu,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/288
I_kwDOBrDQms5V3p1f,"No peak call output from ""TF"" pipeline",CLOSED,2022-11-08T17:55:08Z,2022-11-13T10:11:31Z,2022-11-13T10:11:30Z,"## **Describe the bug**
I am running caper on a slurm cluster with the --singularity option, and the histone pipeline works fine, but the TF pipeline produces only signal tracks but no peak calls. 

Looking at the task-graph files i see there is no peak calling in the TF one:
![croo task_graph b8c9f35e-4f0b-4277-a384-6eef58480425](https://user-images.githubusercontent.com/8479067/200637882-5dd70792-50fb-45dc-af4c-e287ac798240.svg)


whereas the histone one does:
![croo task_graph da2bf31e-e3e0-47ce-ad4a-1e2afc7b79b4](https://user-images.githubusercontent.com/8479067/200631581-91bf55f9-2b4e-4743-914c-b96e65f4a8e1.svg)

Does the absence of peak calling on the task graph mean that it is not part of the TF pipeline? The google doc description of the pipeline would suggest otherwise. Or should i be looking for a bug causing it to fail?


## **OS/Platform**
- SLURM cluster running CentOS unix
- Using --singularity
- Pipeline version: v2.2.1 
- Caper version:  v2.1.0

Caper command:
```
caper run chip.wdl -i ${jsonFile} --singularity --slurm-partition pall --slurm-account $USER --local-out-dir results/${grp} --str-label ${grp}
```


## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
# Use them within ${} notation.
# - cpu: number of cores for a job (default = 1)
# - memory_mb, memory_gb: total memory for a job in MB, GB
#   * these are converted from 'memory' string attribute (including size unit)
#     defined in WDL task's runtime
# - time: time limit for a job in hour
# - gpu: specified gpu name or number of gpus (it's declared as String)

slurm-resource-param=-n 1 --ntasks-per-node=1 --cpus-per-task=${cpu} ${if defined(memory_mb) then ""--mem="" else """"}${memory_mb}${if defined(memory_mb) then ""M"" else """"} ${if defined(time) then ""--time="" else """"}${time*60} ${if defined(gpu) then ""--gres=gpu:"" else """"}${gpu}

# If needed uncomment and define any extra SLURM sbatch parameters here
# YOU CANNOT USE WDL SYNTAX AND CROMWELL BUILT-IN VARIABLES HERE
#slurm-extra-param=

# Hashing strategy for call-caching (3 choices)
# This parameter is for local (local/slurm/sge/pbs/lsf) backend only.
# This is important for call-caching,
# which means re-using outputs from previous/failed workflows.
# Cache will miss if different strategy is used.
# ""file"" method has been default for all old versions of Caper<1.0.
# ""path+modtime"" is a new default for Caper>=1.0,
#   file: use md5sum hash (slow).
#   path: use path.
#   path+modtime: use path and modification time.
local-hash-strat=path+modtime

# Metadata DB for call-caching (reusing previous outputs):
# Cromwell supports restarting workflows based on a metadata DB
# DB is in-memory by default
db=in-memory

# If you use 'caper run' and want to use call-caching:
# Make sure to define different 'caper run ... --db file --file-db DB_PATH'
# for each pipeline run.
# But if you want to restart then define the same '--db file --file-db DB_PATH'
# then Caper will collect/re-use previous outputs without running the same task again
# Previous outputs will be simply hard/soft-linked.

# If you use 'caper server' then you can use one unified '--file-db'
# for all submitted workflows. In such case, uncomment the following two lines
# and defined file-db as an absolute path to store metadata of all workflows
#db=file
#file-db=

# Local directory for localized files and Cromwell's intermediate files
# If not defined, Caper will make .caper_tmp/ on local-out-dir or CWD.```
# /tmp is not recommended here since Caper store all localized data files
# on this directory (e.g. input FASTQs defined as URLs in input JSON).
local-loc-dir=

cromwell=/home/jsemple/.caper/cromwell_jar/cromwell-65.jar
womtool=/home/jsemple/.caper/womtool_jar/womtool-65.jar
```

## **Input JSON file**
Paste contents of your input JSON file.
```json
{""chip.title"":""LET418_YA"",
""chip.description"":""Ahringer ChIP: LET-418_YA"",
""chip.pipeline_type"":""tf"",
""chip.aligner"":""bowtie2"",
""chip.align_only"":false,
""chip.true_rep_only"":false,
""chip.genome_tsv"":""/data/projects/p025/jenny/genome/ce11/ce11.tsv"",
""chip.paired_end"":false,
""chip.ctl_paired_end"":false,
""chip.always_use_pooled_ctl"":false,
""chip.fastqs_rep1_R1"":[""/data/projects/p025/jenny/shweta/tmpRun/SRR_download/LET-418_YA_rep1_IP.fq.gz""],
""chip.fastqs_rep2_R1"":[""/data/projects/p025/jenny/shweta/tmpRun/SRR_download/LET-418_YA_rep2_IP.fq.gz""],
""chip.ctl_fastqs_rep1_R1"":[""/data/projects/p025/jenny/shweta/tmpRun/SRR_download/LET-418_YA_rep1_input.fq.gz""],
""chip.ctl_fastqs_rep2_R1"":[""/data/projects/p025/jenny/shweta/tmpRun/SRR_download/LET-418_YA_rep2_input.fq.gz""]
}
```

## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
[cromwell.out.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/9963877/cromwell.out.txt)
```
```
",jsemple19,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/289
I_kwDOBrDQms5aDrK2,Error in Alignment process : Call input and runtime attributes evaluation failed for align: Failed to evaluate input 'tmp_fastqs' (reason 1 of 1): transpose requires all collections have the same size,CLOSED,2022-12-26T12:27:58Z,2023-11-09T22:48:58Z,2022-12-27T05:27:10Z,"## **Describe the bug**

Hi,

Thanks to you, I've been using the chip-seq-pipeline2 workflow since last year until earlier this year which was very helpful.

However, a few days ago, when I ran the new data on the same command as earlier this year, the following error appeared repeatedly.

```cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor$$anonfun$1$$anon$1: Call input and runtime attributes evaluation failed for align_ctl:
Failed to evaluate input 'tmp_fastqs' (reason 1 of 1): transpose requires all collections have the same size

cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor$$anonfun$1$$anon$1: Call input and runtime attributes evaluation failed for align:
Failed to evaluate input 'tmp_fastqs' (reason 1 of 1): transpose requires all collections have the same size

cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor$$anonfun$1$$anon$1: Call input and runtime attributes evaluation failed for align_ctl:
Failed to evaluate input 'tmp_fastqs' (reason 1 of 1): transpose requires all collections have the same size

cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor$$anonfun$1$$anon$1: Call input and runtime attributes evaluation failed for align:
Failed to evaluate input 'tmp_fastqs' (reason 1 of 1): transpose requires all collections have the same size

```

The same alignment process error continues to occur despite updating the caper and chip-seq-pipeline2 to the latest version by referring to the previous issue.
https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/226#issue-856531893 

I checked my fastq file , but there was no problem.

I wonder what caused this error.
can you please help?

Thanks!

## **OS/Platform**
- OS/Platform: Ubuntu 21.04
- Pipeline version: v2.2.1
- Caper version: v2.2.3

## **Caper configuration file**
```
caper run chip.wdl -i lmna_test.json --singularity --leader-job-name ChIP_TEST
```
Paste contents of `~/.caper/default.conf`.
```ini
backend=local

# Local directory for localized files and Cromwell's intermediate files.
# If not defined then Caper will make .caper_tmp/ on CWD or `local-out-dir`.
# /tmp is not recommended since Caper store localized data files here.
local-loc-dir=

cromwell=/home/hj/.caper/cromwell_jar/cromwell-82.jar
womtool=/home/hj/.caper/womtool_jar/womtool-82.jar
```

## **Input JSON file**

```json
{
    ""chip.title"" : ""LMNA ab TEST"",
    ""chip.description"" : ""LMNA AB TEST chip data"",

    ""chip.pipeline_type"" : ""histone"",
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""/mnt/NAS2/home/hj/chip-seq-pipeline2/hg19.tsv"",

    ""chip.paired_end"" : true,
    ""chip.ctl_paired_end"" : true,
    ""chip.always_use_pooled_ctl"" : true,
    ""chip.peak_caller"" : ""macs2"",
    ""chip.pval_thresh"" : 0.01,
    ""chip.fdr_thresh"" : 0.01,
    ""chip.idr_thresh"" : 0.05,
    ""chip.enable_jsd"" : true,
    ""chip.enable_gc_bias"" : true,
    ""chip.enable_count_signal_track"" : true,

    ""chip.fastqs_rep1_R1"" : [""/mnt/NAS2/home/hj/LMNA_ChIP_TEST/CM_LAab_1.fastq.gz""],
    ""chip.fastqs_rep1_R2"" : [""/mnt/NAS2/home/hj/LMNA_ChIP_TEST/CM_LAab_2.fastq.gz""],

    ""chip.ctl_fastqs_rep1_R1"" : [""/mnt/NAS2/home/hj/LMNA_ChIP_TEST/CM_input_1.fastq.gz""],
    ""chip.ctl_fastqs_rep1_R2"" : [""/mnt/NAS2/home/hj/LMNA_ChIP_TEST/CM_input_2.fastq.gz""]
}

```

## **Troubleshooting result**

```
2022-12-26 18:37:28,554  IoFO o- Running with database db.url = jdbc:hsqldb:mem:2332d49b-cffe-4946-9356-ad5653ee3016;shutdown=false;hsqldb.tx=mvcc
ut"" 640L, 65209B                                                                                                      640,64        Bot
2022-12-26 20:32:23,077 cromwell-system-akka.dispatchers.backend-dispatcher-1526 INFO  - BackgroundConfigAsyncJobExecutionActor [UUID(faf8a76e)chip.align_R1:1:1]: Status change from WaitingForReturnCode to Done
2022-12-26 20:32:51,042 cromwell-system-akka.dispatchers.backend-dispatcher-1526 INFO  - BackgroundConfigAsyncJobExecutionActor [UUID(faf8a76e)chip.align_R1:0:1]: Status change from WaitingForReturnCode to Done
2022-12-26 20:32:55,845 cromwell-system-akka.dispatchers.engine-dispatcher-31 INFO  - WorkflowManagerActor: Workflow faf8a76e-54b4-45ec-87a5-972b2408e03c failed (during ExecutingWorkflowState): cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor$$anonfun$1$$anon$1: Call input and runtime attributes evaluation failed for align_ctl:
Failed to evaluate input 'tmp_fastqs' (reason 1 of 1): transpose requires all collections have the same size

cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor$$anonfun$1$$anon$1: Call input and runtime attributes evaluation failed for align:
Failed to evaluate input 'tmp_fastqs' (reason 1 of 1): transpose requires all collections have the same size

cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor$$anonfun$1$$anon$1: Call input and runtime attributes evaluation failed for align_ctl:
Failed to evaluate input 'tmp_fastqs' (reason 1 of 1): transpose requires all collections have the same size

cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor$$anonfun$1$$anon$1: Call input and runtime attributes evaluation failed for align:
Failed to evaluate input 'tmp_fastqs' (reason 1 of 1): transpose requires all collections have the same size

2022-12-26 20:34:13,871 cromwell-system-akka.dispatchers.engine-dispatcher-20 INFO  - WorkflowManagerActor: Workflow actor for faf8a76e-54b4-45ec-87a5-972b2408e03c completed with status 'Failed'. The workflow will be removed from the workflow store.
2022-12-26 20:34:14,538 cromwell-system-akka.dispatchers.engine-dispatcher-9 INFO  - SingleWorkflowRunnerActor workflow finished with status 'Failed'.
2022-12-26 20:34:19,195 cromwell-system-akka.dispatchers.engine-dispatcher-9 INFO  - SingleWorkflowRunnerActor writing metadata to /mnt/NAS2/home/hj/chip-seq-pipeline2/.caper_tmp/chip/20221226_183721_969493/metadata.json
2022-12-26 20:34:19,417  INFO  - Workflow polling stopped
2022-12-26 20:34:19,422  INFO  - 0 workflows released by cromid-497e9e3
2022-12-26 20:34:19,424  INFO  - Shutting down WorkflowStoreActor - Timeout = 5 seconds
2022-12-26 20:34:19,427  INFO  - Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds
2022-12-26 20:34:19,429  INFO  - Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds
2022-12-26 20:34:19,431  INFO  - WorkflowLogCopyRouter stopped
2022-12-26 20:34:19,431  INFO  - JobExecutionTokenDispenser stopped
2022-12-26 20:34:19,432 cromwell-system-akka.dispatchers.engine-dispatcher-9 INFO  - Aborting all running workflows.
2022-12-26 20:34:19,434  INFO  - WorkflowStoreActor stopped
2022-12-26 20:34:19,434  INFO  - Shutting down WorkflowManagerActor - Timeout = 3600 seconds
2022-12-26 20:34:19,434 cromwell-system-akka.dispatchers.engine-dispatcher-21 INFO  - WorkflowManagerActor: All workflows finished
2022-12-26 20:34:19,434  INFO  - WorkflowManagerActor stopped
2022-12-26 20:34:19,561  INFO  - Connection pools shut down
2022-12-26 20:34:19,562  INFO  - Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds
2022-12-26 20:34:19,562  INFO  - Shutting down JobStoreActor - Timeout = 1800 seconds
2022-12-26 20:34:19,562  INFO  - Shutting down CallCacheWriteActor - Timeout = 1800 seconds
2022-12-26 20:34:19,562  INFO  - Shutting down ServiceRegistryActor - Timeout = 1800 seconds
2022-12-26 20:34:19,562  INFO  - Shutting down DockerHashActor - Timeout = 1800 seconds
2022-12-26 20:34:19,562  INFO  - Shutting down IoProxy - Timeout = 1800 seconds
2022-12-26 20:34:19,564  INFO  - CallCacheWriteActor Shutting down: 0 queued messages to process
2022-12-26 20:34:19,568  INFO  - SubWorkflowStoreActor stopped
2022-12-26 20:34:19,568  INFO  - JobStoreActor stopped
2022-12-26 20:34:19,568  INFO  - CallCacheWriteActor stopped
2022-12-26 20:34:19,568  INFO  - IoProxy stopped
2022-12-26 20:34:19,574  INFO  - DockerHashActor stopped
2022-12-26 20:34:19,575  INFO  - Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false
2022-12-26 20:34:19,576  INFO  - Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false
2022-12-26 20:34:19,576  INFO  - Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false
2022-12-26 20:34:19,577  INFO  - WriteMetadataActor Shutting down: 0 queued messages to process
2022-12-26 20:34:19,577  INFO  - KvWriteActor Shutting down: 0 queued messages to process
2022-12-26 20:34:19,582  INFO  - ServiceRegistryActor stopped
2022-12-26 20:34:19,585  INFO  - Database closed
2022-12-26 20:34:19,585  INFO  - Stream materializer shut down
2022-12-26 20:34:19,587  INFO  - WDL HTTP import resolver closed

```

",cafri1105,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/290
I_kwDOBrDQms5cvWl2,Changing MACS2 output from earlier pipeline version,OPEN,2023-01-25T01:23:09Z,2023-01-31T00:05:31Z,,"I am currently updating an adaptation of this pipeline from a version forked from v1.1.2 to v2.1.6. Very minor changes were made in both adaptations for the sake of metadata/display, without modifying the analyses performed. Given that, however, my question is a bit more general.

The phenomenon I am observing is that the optimal and conservative peaks generated by MACS2 are often identical for pipeline version 2.1.6. I read in the documentation that the optimal peaks are selected as the set with the most peaks, while the conservative set is selected as the set of true replicate consistent peaks, and can see that these are the same set. However, I was not expecting that the true replicate peaks would be the largest set.

To give a concrete example, running the old and new pipeline on the same set (from fastq files), the choice of conservative peaks changes from the ppr to rep1-rep2 set from v1.1.1 to v2.1.6. The full QC metrics are available here ([v1.1.1](https://s3.amazonaws.com/elasticbeanstalk-fourfront-webprod-wfoutput/4DNFINRI6WOLqc_report.html) and [v2.1.6](https://s3.amazonaws.com/elasticbeanstalk-fourfront-webdev-wfoutput/4DNFICZJUA7S/qc_report.html)) and the dataset is available at https://data.4dnucleome.org/experiment-set-replicates/4DNESSNWXHXK/. The control experiment was similarly processed starting from fastq files with old and new pipeline versions, respectively.

All this is to ask if there is some change (perhaps in the method of generating/number of pseudoreplicates) that might explain this difference in output, or if it is more likely there is a flaw in the new implementation. I know v1.1.1 is quite old at this point, which I apologize for. I would be grateful for any insight you might have and happy to provide more information should it be helpful.

- Docker image: encodedcc/chip-seq-pipeline:v2.1.6 (with slight modification to qc metrics)
- Pipeline version: 2.1.6",clarabakker,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/291
I_kwDOBrDQms5fIyxV,caper.nb_subproc_thread|ERROR| Cromwell failed. returncode=1,OPEN,2023-02-23T03:10:01Z,2023-02-26T03:13:32Z,,"## **Describe the bug**
While running `nohup caper run chip.wdl -i https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI_subsampled_chr19_only.json --conda &`
 I got error as: `Conda environment name not found in WDL metadata.` and `caper.nb_subproc_thread|ERROR| Cromwell failed. returncode=1` and a cromwell.out with nothing in it.
```shell
2023-02-23 10:45:50,046|autouri.autouri|INFO| cp: (468c5614) started. src=https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep1.subsampled.25.fastq.gz, dest=/home/encode-dcc/41d3a8658bf4f565c08290e386fddccf/rep1.subsampled.25.fastq.gz
2023-02-23 10:45:53,986|autouri.autouri|INFO| cp: (468c5614) done.
2023-02-23 10:45:53,987|autouri.autouri|INFO| cp: (1e490fb8) started. src=https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep2.subsampled.20.fastq.gz, dest=/home/encode-dcc/0d5b102d7f21dd009798ae9b2c318b65/rep2.subsampled.20.fastq.gz
2023-02-23 10:45:57,226|autouri.autouri|INFO| cp: (1e490fb8) done.
2023-02-23 10:45:57,227|autouri.autouri|INFO| cp: (7176279f) started. src=https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl1.subsampled.25.fastq.gz, dest=/home/encode-dcc/f4dba75d4430f4702a75554c44265119/ctl1.subsampled.25.fastq.gz
2023-02-23 10:45:59,741|autouri.autouri|INFO| cp: (7176279f) done.
2023-02-23 10:45:59,742|autouri.autouri|INFO| cp: (89ae1f80) started. src=https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl2.subsampled.25.fastq.gz, dest=/home/encode-dcc/7a610dd5397c45a806678efaad824abf/ctl2.subsampled.25.fastq.gz
2023-02-23 10:46:02,442|autouri.autouri|INFO| cp: (89ae1f80) done.
2023-02-23 10:46:03,271|caper.caper_workflow_opts|INFO| Conda environment name not found in WDL metadata. wdl=/home/lvwei/chipseq/encode/chip.wdl
2023-02-23 10:46:03,289|caper.cromwell|INFO| Validating WDL/inputs/imports with Womtool...
2023-02-23 10:46:06,100|caper.nb_subproc_thread|INFO| Subprocess finished successfully.
2023-02-23 10:46:06,100|caper.cromwell|INFO| Passed Womtool validation.
2023-02-23 10:46:06,101|caper.caper_runner|INFO| launching run: wdl=/home/lvwei/chipseq/encode/chip.wdl, inputs=/home/encode-dcc/15b4ff439de58d859f4c3ee4482c3bd2/ENCSR000DYI_subsampled_chr19_only.local.json, backend_conf=/home/encode-dcc/chip/20230223_104456_225709/backend.conf
2023-02-23 10:46:06,129|caper.nb_subproc_thread|ERROR| Cromwell failed. returncode=1
2023-02-23 10:46:06,130|caper.cli|ERROR| Check stdout in /home/lvwei/chipseq/encode/cromwell.out.1
```

I tried to follow issue #271 to remove and re-install caper and conda_env, but still get the same output.

## **OS/Platform**
- OS/Platform: CentOS 7.5.1804
- Conda version: conda 23.1.0
- Pipeline version: v2.2.1
- Caper version: v2.2.3

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
backend=local

# Local directory for localized files and Cromwell's intermediate files.
# If not defined then Caper will make .caper_tmp/ on CWD or `local-out-dir`.
# /tmp is not recommended since Caper store localized data files here.
local-loc-dir=/home/encode-dcc

cromwell=/home/.caper/cromwell_jar/cromwell-82.jar
womtool=/home/.caper/womtool_jar/womtool-82.jar
```

## **Input JSON file**
Paste contents of your input JSON file.
```json
{
    ""chip.pipeline_type"" : ""tf"",
    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v3/hg38_chr19_chrM.tsv"",
    ""chip.fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep1.subsampled.25.fastq.gz""
    ],
    ""chip.fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/rep2.subsampled.20.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep1_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl1.subsampled.25.fastq.gz""
    ],
    ""chip.ctl_fastqs_rep2_R1"" : [""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI/fastq_subsampled/ctl2.subsampled.25.fastq.gz""
    ],
    ""chip.paired_end"" : false,
    ""chip.title"" : ""ENCSR000DYI (subsampled 1/25, chr19_chrM only)"",
    ""chip.description"" : ""CEBPB ChIP-seq on human A549 produced by the Snyder lab""
}

```

## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
```
2023-02-23 11:02:03,383|caper.cli|INFO| Cromwell stdout: /home/lvwei/chipseq/encode/cromwell.out.3
2023-02-23 11:02:03,387|caper.caper_base|INFO| Creating a timestamped temporary directory. /home/encode-dcc/chip/20230223_110203_384959
2023-02-23 11:02:03,387|caper.caper_runner|INFO| Localizing files on work_dir. /home/encode-dcc/chip/20230223_110203_384959
2023-02-23 11:02:04,211|caper.cromwell|INFO| Validating WDL/inputs/imports with Womtool...
2023-02-23 11:02:06,884|caper.nb_subproc_thread|INFO| Subprocess finished successfully.
2023-02-23 11:02:06,885|caper.cromwell|INFO| Passed Womtool validation.
2023-02-23 11:02:06,885|caper.caper_runner|INFO| launching run: wdl=/home/lvwei/chipseq/encode/chip.wdl, inputs=None, backend_conf=/home/encode-dcc/chip/20230223_110203_384959/backend.conf
2023-02-23 11:02:06,911|caper.nb_subproc_thread|ERROR| Cromwell failed. returncode=1
2023-02-23 11:02:06,912|caper.cli|ERROR| Check stdout in /home/lvwei/chipseq/encode/cromwell.out.3

```
",ritetsu,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/292
I_kwDOBrDQms5isLUq,â€caper init localâ€œ error,OPEN,2023-04-05T14:33:08Z,2023-04-05T18:56:44Z,,"**When I run caper init local, I get the following error, how can I solve it?**
```

2023-04-05 22:02:14,771|caper.cromwell|INFO| Installing Cromwell JAR... https://github.com/broadinstitute/cromwell/releases/download/82/cromwell-82.jar
2023-04-05 22:02:14,771|autouri.autouri|INFO| cp: (b8f59ec7) started. src=https://github.com/broadinstitute/cromwell/releases/download/82/cromwell-82.jar, dest=/home/songxh/.caper/cromwell_jar/cromwell-82.jar
Traceback (most recent call last):
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/urllib3/connection.py"", line 174, in _new_conn
    conn = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/urllib3/util/connection.py"", line 95, in create_connection
    raise err
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/urllib3/util/connection.py"", line 85, in create_connection
    sock.connect(sa)
TimeoutError: [Errno 110] Connection timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/urllib3/connectionpool.py"", line 703, in urlopen
    httplib_response = self._make_request(
                       ^^^^^^^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/urllib3/connectionpool.py"", line 386, in _make_request
    self._validate_conn(conn)
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/urllib3/connectionpool.py"", line 1042, in _validate_conn
    conn.connect()
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/urllib3/connection.py"", line 363, in connect
    self.sock = conn = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/urllib3/connection.py"", line 179, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x7f94be7aafd0>, 'Connection to github.com timed out. (connect timeout=None)')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/requests/adapters.py"", line 489, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/urllib3/connectionpool.py"", line 787, in urlopen
    retries = retries.increment(
              ^^^^^^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/urllib3/util/retry.py"", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='github.com', port=443): Max retries exceeded with url: /broadinstitute/cromwell/releases/download/82/cromwell-82.jar (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f94be7aafd0>, 'Connection to github.com timed out. (connect timeout=None)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/songxh/miniconda3/envs/chipseq_caper/bin/caper"", line 13, in <module>
    main()
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/caper/cli.py"", line 709, in main
    init_caper_conf(parsed_args.conf, parsed_args.platform)
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/caper/caper_init.py"", line 181, in init_caper_conf
    '{key}={val}\n'.format(key='cromwell', val=cromwell.install_cromwell())
                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/caper/cromwell.py"", line 480, in install_cromwell
    self._cromwell = install_file(
                     ^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/caper/cromwell.py"", line 33, in install_file
    return AutoURI(f).cp(path)
           ^^^^^^^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/autouri/autouri.py"", line 338, in cp
    if not self._cp(dest_uri=d):
           ^^^^^^^^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/autouri/httpurl.py"", line 142, in _cp
    r = requests.get(
        ^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/requests/api.py"", line 73, in get
    return request(""get"", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/requests/api.py"", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/requests/sessions.py"", line 587, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/requests/sessions.py"", line 701, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/songxh/miniconda3/envs/chipseq_caper/lib/python3.11/site-packages/requests/adapters.py"", line 553, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='github.com', port=443): Max retries exceeded with url: /broadinstitute/cromwell/releases/download/82/cromwell-82.jar (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f94be7aafd0>, 'Connection to github.com timed out. (connect timeout=None)'))
```
",songxh1996,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/293
I_kwDOBrDQms5jkri7,Fixed peak size,OPEN,2023-04-17T07:10:38Z,2023-04-18T01:19:59Z,,"## **Describe the bug**
Peak size appears to be fixed with a few exceptions.
Of the 15598 idr.optimal peaks, all but 13 have the size 740bp.
I would like to know if this is expected or if there is some mistake I am making in the settings.

## **OS/Platform**
- OS/Platform: Cent OS 7
- Conda version: 4.12.0
- Pipeline version: 2.2.1
- Caper version: 2.2.3

## **Caper configuration file**
```ini
backend=local

# Hashing strategy for call-caching (3 choices)
# This parameter is for local (local/slurm/sge/pbs) backend only.
# This is important for call-caching,
# which means re-using outputs from previous/failed workflows.
# Cache will miss if different strategy is used.
# ""file"" method has been default for all old versions of Caper<1.0.
# ""path+modtime"" is a new default for Caper>=1.0,
#   file: use md5sum hash (slow).
#   path: use path.
#   path+modtime: use path and modification time.
local-hash-strat=path+modtime

# Local directory for localized files and Cromwell's intermediate files
# If not defined, Caper will make .caper_tmp/ on local-out-dir or CWD.
# /tmp is not recommended here since Caper store all localized data files
# on this directory (e.g. input FASTQs defined as URLs in input JSON).
local-loc-dir=

cromwell=/home/plantsymbiosis/.caper/cromwell_jar/cromwell-52.jar
womtool=/home/plantsymbiosis/.caper/womtool_jar/womtool-52.jar
```

## **Input JSON file**
```json
{
    ""chip.title"" : ""NIN"",
    ""chip.description"" : ""Run on station."",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""/home/plantsymbiosis/Desktop/TOOLS/GenomeReferences/LotusJaponicusGifuv12_NucMitoChloro/atac_gifu12/LotusJaponicusGifuv12.tsv"",

    ""chip.paired_end"" : false,
    ""chip.ctl_paired_end"" : false,

    ""chip.fastqs_rep1_R1"" : [""03_No_Mito_Chloro/chip.fastqs_sample.rep1_R1_NoMtCh.fq.gz""],
    ""chip.fastqs_rep1_R2"" : [],
    ""chip.fastqs_rep2_R1"" : [],
    ""chip.fastqs_rep2_R2"" : [],
    ""chip.fastqs_rep3_R1"" : [],
    ""chip.fastqs_rep3_R2"" : [],
    ""chip.fastqs_rep4_R1"" : [],
    ""chip.fastqs_rep4_R2"" : [],
    ""chip.fastqs_rep5_R1"" : [],
    ""chip.fastqs_rep5_R2"" : [],
    ""chip.fastqs_rep6_R1"" : [],
    ""chip.fastqs_rep6_R2"" : [],
    ""chip.fastqs_rep7_R1"" : [],
    ""chip.fastqs_rep7_R2"" : [],
    ""chip.fastqs_rep8_R1"" : [],
    ""chip.fastqs_rep8_R2"" : [],
    ""chip.fastqs_rep9_R1"" : [],
    ""chip.fastqs_rep9_R2"" : [],

    ""chip.ctl_fastqs_rep1_R1"" : [""03_No_Mito_Chloro/chip.fastqs_background.rep1_R1_NoMtCh.fq.gz""],
    ""chip.ctl_fastqs_rep1_R2"" : [],
    ""chip.ctl_fastqs_rep2_R1"" : [],
    ""chip.ctl_fastqs_rep2_R2"" : [],
    ""chip.ctl_fastqs_rep3_R1"" : [],
    ""chip.ctl_fastqs_rep3_R2"" : [],
    ""chip.ctl_fastqs_rep4_R1"" : [],
    ""chip.ctl_fastqs_rep4_R2"" : [],
    ""chip.ctl_fastqs_rep5_R1"" : [],
    ""chip.ctl_fastqs_rep5_R2"" : [],
    ""chip.ctl_fastqs_rep6_R1"" : [],
    ""chip.ctl_fastqs_rep6_R2"" : [],
    ""chip.ctl_fastqs_rep7_R1"" : [],
    ""chip.ctl_fastqs_rep7_R2"" : [],
    ""chip.ctl_fastqs_rep8_R1"" : [],
    ""chip.ctl_fastqs_rep8_R2"" : [],
    ""chip.ctl_fastqs_rep9_R1"" : [],
    ""chip.ctl_fastqs_rep9_R2"" : [],

    ""chip.always_use_pooled_ctl"" : true
}
```

## **Troubleshooting result**
```
The pipeline runs without errors.
```
",kbattenb,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/294
I_kwDOBrDQms5mXNlI,The pipeline stops at Job chip.read_genome_tsv,OPEN,2023-05-19T14:36:42Z,2023-09-14T15:44:43Z,,"### **Describe the bug**
I am trying to run the pipeline locally using ""caper run chip.wdl -i ""${INPUT_JSON}"" --docker"", but it fails on the line that reads:

>  Job chip.read_genome_tsv:NA:1 exited with return code -1 which has not been declared as a valid return code
STDERR_BACKGROUND_CONTENTS=
/bin/bash: /cromwell-executions/chip/ce23b07e-d49f-4338-9a62-55923e9a2ac3/call-read_genome_tsv/execution/script: No such file or directory
2023-05-18 16:01:10,748|caper.nb_subproc_thread|ERROR| Cromwell failed. returncode=1
2023-05-18 16:01:10,748|caper.cli|ERROR| Check stdout in /shared_home/encode-chip/chip-seq-pipeline2/cromwell.out


### **OS/Platform**
OS/Platform: Ubuntu 22.04.2 LTS
Pipeline version: 2.2.1
Java version: openjdk 17.0.6 2023-01-17 LTS
OpenJDK Runtime Environment Corretto-17.0.6.10.1 (build 17.0.6+10-LTS)
OpenJDK 64-Bit Server VM Corretto-17.0.6.10.1 (build 17.0.6+10-LTS, mixed mode, sharing)


### **Caper configuration file**
`backend=local

local-loc-dir=/shared_home/caper_mah/

cromwell=/nvme/mahdi/.caper/cromwell_jar/cromwell-82.jar
womtool=/nvme/mahdi/.caper/womtool_jar/womtool-82.jar
`
### **Input JSON file**

`{
    ""chip.title"" : ""STAT1"",
    ""chip.description"" : ""STAT family"",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v4/mm10.tsv"",

    ""chip.paired_end"" : false,
    ""chip.ctl_paired_end"" : false,

    ""chip.always_use_pooled_ctl"" : true,

    ""chip.fastqs_rep1_R1"" : [ ""/DATA/Meta_project/chip_MQ_decker/SRR7275159_GSM3178206_WT_STAT1_90_min_IFNg_rep1_Mus_musculus_ChIP-Seq.fastq.gz""],
    ""chip.fastqs_rep2_R1"" : [ ""/DATA/Meta_project/chip_MQ_decker/SRR7275160_GSM3178207_WT_STAT1_90_min_IFNg_rep2_Mus_musculus_ChIP-Seq.fastq.gz""],
    
    

    ""chip.ctl_fastqs_rep1_R1"" : [ ""/DATA/Meta_project/chip_MQ_decker/SRR7275147_GSM3178194_WT_STAT1_rep1_Mus_musculus_ChIP-Seq.fastq.gz"" ],
    ""chip.ctl_fastqs_rep2_R1"" : [ ""/DATA/Meta_project/chip_MQ_decker/SRR7275148_GSM3178195_WT_STAT1_rep2_Mus_musculus_ChIP-Seq.fastq.gz"" ]
}`


Any help would be much appreciated.",peculiar97,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/295
I_kwDOBrDQms5mao6S,no motif output,OPEN,2023-05-20T19:08:15Z,2023-05-20T19:08:15Z,,"1-Im using the hg38 from your link:
bash scripts/download_genome_data.sh hg38

My input BAM files are have names like chr1 chrX chr1_KI270706v1_random
as far as i know they resemble the downloaded hg38

The pipeline says if a genome is downloaded and have similar chromosome names as the bams, motif analysis is automatic.

2-macs peaks were called, i thought the default for tf was spp? i do have input controls
",jamesaliba,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/296
I_kwDOBrDQms5mauKG,signal track height is higher for input control,OPEN,2023-05-20T20:26:50Z,2024-03-27T03:11:22Z,,signal track height is higher for input control both using pval and fc. though the called peaks are significant for that region. what files should i use for peak visualization and scaling by height.,jamesaliba,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/297
I_kwDOBrDQms5v4TYO,Does the calculation of sval in encode_task_macs2_signal_track_chip.py take into account the difference between single-end and paired-end data?,OPEN,2023-09-01T08:57:27Z,2023-09-04T09:58:05Z,,"I am in the process of using your innovative scripts for ChIP-seq data processing (many datasets containing both single-end and paired-end). While going through the pipeline, I noticed that there doesn't appear to be a clear distinction made between single-end ChIP-seq data and paired-end ChIP-seq data during sval calculation (encode_task_macs2_signal_track_chip.py, line 145). In my understanding, the tagAlign files generated by this pipeline might differ between single-end and paired-end data.

For single-end tagAlign files, the read count should be equal to the total number of lines in the file, while for paired-end tagAlign files, the read count should be half of the total number of lines in the file. However, I'm not entirely certain if my interpretation is correct. I would greatly appreciate your assistance in clarifying this matter. Thank you once again for creating such valuable tools.",ezioljj,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/298
I_kwDOBrDQms5xxivJ,how to create pseudo-replicate files,OPEN,2023-09-22T12:25:32Z,2023-11-06T21:16:17Z,,">python encode_task_reproducibility.py \
> liver1_peaks.narrowPeak.gz,liver2_peaks.narrowPeak.gz \
> --peak-type narrowPeak \
> --prefix liver_rep \
> --chrsz genome_nomt.size --out-dir ./
ENCODE DCC reproducibility QC.: error: the following arguments are required: --peaks-pr

Thank you for your resources, I encountered such an error when running the code, I need pseudo-replicate, but in my previous analysis, I did not get it. If I miss important information, any tips from you will help me. In addition, they are necessary in the analysis, right?

",songxh1996,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/299
I_kwDOBrDQms5zxdho,missing slurm qos parameter,OPEN,2023-10-13T17:23:42Z,2023-11-06T23:10:00Z,,"First I am able to run the pipeline in the open queue, so I know that everything is installed properly.  In case it makes a difference, this is a conda install, with Slurm.  But I would like to be able to run this under an allocation to avoid long queues.  In our system we need to not only define the account and partition but also the qos.  This fails with the ENCODE pipelines.  In the slurm*.out files I see that the qos is not being used.
In default.conf:
slurm-partition=burst
slurm-qos=burst3x 

In slurm*.out:
2023-10-13 12:37:15,399|caper.hpc|INFO| Running shell command: sbatch -t 48:00:00 --mem 4G -p burst -A xxxx --export=ALL -J CAPER_62 /storage/home/bmg137/miaq8ut7.sh
sbatch: error: Batch job submission failed: Invalid qos specification

Belinda
",giardine,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/300
I_kwDOBrDQms51LANT,How do you resume ?,OPEN,2023-10-27T16:11:32Z,2023-10-27T16:11:32Z,,"Hi, 

I ran the pipeline as follows:

`caper hpc submit /home/opt/chip-seq-pipeline2/chip.wdl -i chip_cntl.json --singularity --leader-job-name cntl --file-db /gpfs0/home1/lab/analyses
`

making sure that I have the `--file-db`. Now, I wanted to resume the processes using the same command but it seemed to restart from the beginning. I see `task=chip.align:0` when the last task previously done was `task=chip.idr:1`

Is this not the correct way to resume the chipseq pipeline?

Thanks!",olechnwin,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/301
I_kwDOBrDQms57ujdB,pipeline stuck in call-macs2_signal_track_pooled,OPEN,2024-01-11T05:44:25Z,2024-01-11T05:48:18Z,,"hello there:
wonderful pipeline for all encode project.
I was using chip-seq-pipeline recently
after testing ""https://storage.googleapis.com/encode-pipeline-test-samples/encode-chip-seq-pipeline/ENCSR000DYI_subsampled_chr19_only.json"" as input, the result is completed.

but I was stuck in call-macs2_signal_track_pooled when using bam as input

there is my input.json and cromwell.out and std.out


[template-hg19.json](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/13897766/template-hg19.json)
[29909179.err.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/13897767/29909179.err.txt)
[cromwell.out.txt](https://github.com/ENCODE-DCC/chip-seq-pipeline2/files/13897768/cromwell.out.txt)

any suggestion would be much appreciated!",cmf1997,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/302
I_kwDOBrDQms6C30dx,Datasets for TF-target genes,OPEN,2024-03-19T18:18:00Z,2024-03-19T18:18:00Z,,"Hi there! 

I appreciate your excellent work!

I am interested in obtaining all TF-target gene links for human and mouse from ENCODE. Could you please provide the datasets categorized by cell types and tissues? Thank you in advance for your time and kind help!

Best regards,
Yiqi",yiqisu,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/305
I_kwDOBrDQms6NjEfk,Can chip-seq-pipeline2 run locally without internet?,OPEN,2024-06-26T09:03:36Z,2024-07-02T18:42:03Z,,"I tried to run pipeline on cluster without internet connection, with local docker. But this error:
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='github.com', port=443): Max retries exceeded with url: /broadinstitute/cromwell/releases/download/82/womtool-82.jar

I run by:
 caper run /data/home/cheyizhuo/opt/encode/chip-seq-pipeline2/chip.wdl -i /data/home/cheyizhuo/MeCP2_HuangChen/mycode/data_process/chip/jsons/chip_MeCP2-IPS.json --singularity encodedcc/chip-seq-pipeline:v2.2.1 -b ""local"" -m ./chip_MeCP2-IPS.json --max-concurrent-tasks 2 --local-out-dir /data/home/cheyizhuo/opt/encode/chip-seq-pipeline2/local_for_caper/",cyz0315,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/306
I_kwDOBrDQms6W81v1,Insufficient peaks in pseudoreplicates resulting in chip.idr_ppr failure,OPEN,2024-09-18T02:07:39Z,2024-09-18T02:08:42Z,,"## **Describe the bug**
The pipeline fails at the peak merging step at chip.idr_ppr due to insufficient peaks. Upon checking the respective pseudoreplicate files, there are only 20 and 6 peaks respectively. To my understanding the pseudoreplicates are supposed to be a subsample of the true replicates, so I am unclear why there are so little peaks even before merging. I have tried to set a seed for the pseudoreplicates but still no luck. No such error encountered for other samples. 

## **OS/Platform**
- OS/Platform: Linux 4.18.0-372.9.1.el8.x86_64
- Pipeline version: v2.2.2
- Caper version: v2.3.2

## **Caper configuration file**
Paste contents of `~/.caper/default.conf`.
```ini
backend=local

# Local directory for localized files and Cromwell's intermediate files.
# If not defined then Caper will make .caper_tmp/ on CWD or `local-out-dir`.
# /tmp is not recommended since Caper store localized data files here.
local-loc-dir=/home/cbi/grn_inference/database/raw/as_tf/ctcf/chipseq/chip-seq_encode_pipeline/pipeline_data

cromwell=/home/nursyahi001/.caper/cromwell_jar/cromwell-82.jar
womtool=/home/nursyahi001/.caper/womtool_jar/womtool-82.jar
```

## **Input JSON file**
Paste contents of your input JSON file.
```json
{
    ""chip.title"" : ""2024-08-20 FFF Control"",
    ""chip.description"" : ""Samples: WHC2180-2; FFF-C1,C2,C3"",

    ""chip.pipeline_type"" : ""tf"",
    ""chip.aligner"" : ""bowtie2"",
    ""chip.align_only"" : false,
    ""chip.true_rep_only"" : false,

    ""chip.genome_tsv"" : ""https://storage.googleapis.com/encode-pipeline-genome-data/genome_tsv/v4/hg38.tsv"",
    ""chip.genome_name"" : ""hg38"",

    ""chip.paired_end"" : true,
    ""chip.ctl_paired_end"" : true,

    ""chip.always_use_pooled_ctl"" : true,

    ""chip.fastqs_rep1_R1"" : [ ""/home/cbi/projects/20240725_CHIPseq_data/fastq/trimmed/WHC2180_1_val_1.fq.gz""],
    ""chip.fastqs_rep2_R1"" : [ ""/home/cbi/projects/20240725_CHIPseq_data/fastq/trimmed/WHC2181_1_val_1.fq.gz""],
    ""chip.fastqs_rep3_R1"" : [ ""/home/cbi/projects/20240725_CHIPseq_data/fastq/trimmed/WHC2182_1_val_1.fq.gz""],

    ""chip.fastqs_rep1_R2"" : [ ""/home/cbi/projects/20240725_CHIPseq_data/fastq/trimmed/WHC2180_2_val_2.fq.gz""],
    ""chip.fastqs_rep2_R2"" : [ ""/home/cbi/projects/20240725_CHIPseq_data/fastq/trimmed/WHC2181_2_val_2.fq.gz""],
    ""chip.fastqs_rep3_R2"" : [ ""/home/cbi/projects/20240725_CHIPseq_data/fastq/trimmed/WHC2182_2_val_2.fq.gz""],

    ""chip.ctl_fastqs_rep1_R1"" : [ ""/home/cbi/projects/20240725_CHIPseq_data/fastq/trimmed/WHC2192_1_val_1.fq.gz""],
    ""chip.ctl_fastqs_rep1_R2"" : [ ""/home/cbi/projects/20240725_CHIPseq_data/fastq/trimmed/WHC2192_2_val_2.fq.gz""]
    
}

```

## **Troubleshooting result**

If you ran `caper run` without Caper server then Caper automatically runs a troubleshooter for failed workflows. Find troubleshooting result in the bottom of Caper's screen log.

If you ran `caper submit` with a running Caper server then first find your workflow ID (1st column) with `caper list` and run `caper debug [WORKFLOW_ID]`.

Paste troubleshooting result.
```


==== NAME=chip.idr_ppr, STATUS=Failed, PARENT=
SHARD_IDX=-1, RC=1, JOB_ID=2331552
START=2024-09-12T11:51:25.550Z, END=2024-09-12T11:51:39.781Z
STDOUT=/home/cbi/projects/20240725_PheckKhee_CHIPseq_data/croo_output/outputs/trimmed/chip/10977366-4d12-4516-b858-b2ecec8ef1d0/call-idr_ppr/attempt-2/execution/stdout
STDERR=/home/cbi/projects/20240725_PheckKhee_CHIPseq_data/croo_output/outputs/trimmed/chip/10977366-4d12-4516-b858-b2ecec8ef1d0/call-idr_ppr/attempt-2/execution/stderr
STDERR_CONTENTS=
Traceback (most recent call last):
  File ""/software/chip-seq-pipeline/src/encode_task_idr.py"", line 213, in <module>
    main()
  File ""/software/chip-seq-pipeline/src/encode_task_idr.py"", line 175, in main
    args.idr_thresh, args.idr_rank, args.mem_gb, args.out_dir,
  File ""/software/chip-seq-pipeline/src/encode_task_idr.py"", line 118, in idr
    idr_stdout=idr_stdout,
  File ""/software/chip-seq-pipeline/src/encode_lib_common.py"", line 359, in run_shell_cmd
    raise Exception(err_str)
Exception: PID=2331702, PGID=2331702, RC=1, DURATION_SEC=5.2
STDERR=Traceback (most recent call last):
  File ""/usr/local/bin/idr"", line 4, in <module>
    __import__('pkg_resources').run_script('idr==2.0.3', 'idr')
  File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 658, in run_script
    self.require(requires)[0].run_script(script_name, ns)
  File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 1438, in run_script
    exec(code, namespace, namespace)
  File ""/usr/local/lib/python3.6/dist-packages/idr-2.0.3-py3.6-linux-x86_64.egg/EGG-INFO/scripts/idr"", line 10, in <module>
    idr.idr.main()
  File ""/usr/local/lib/python3.6/dist-packages/idr-2.0.3-py3.6-linux-x86_64.egg/idr/idr.py"", line 857, in main
    raise ValueError(error_msg)
ValueError: Peak files must contain at least 20 peaks post-merge
Hint: Merged peaks were written to the output file
STDOUT=/usr/local/bin/idr --samples /cromwell-executions/chip/10977366-4d12-4516-b858-b2ecec8ef1d0/call-idr_ppr/attempt-2/inputs/313145862/rep-pr1.pooled_x_WHC2192_1_val_1.srt.nodup.300K.regionPea
k.gz /cromwell-executions/chip/10977366-4d12-4516-b858-b2ecec8ef1d0/call-idr_ppr/attempt-2/inputs/305386503/rep-pr2.pooled_x_WHC2192_1_val_1.srt.nodup.300K.regionPeak.gz --peak-list /cromwell-exec
utions/chip/10977366-4d12-4516-b858-b2ecec8ef1d0/call-idr_ppr/attempt-2/inputs/1977487234/rep.pooled_x_WHC2192_1_val_1.srt.nodup.300K.regionPeak.gz --input-file-type narrowPeak --output-file poole
d-pr1_vs_pooled-pr2.idr0.05.unthresholded-peaks.txt --rank signal.value --soft-idr-threshold 0.05 --plot --use-best-multisummit-IDR --log-output-file pooled-pr1_vs_pooled-pr2.idr0.05.log

```
",nursyahr,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/307
I_kwDOBrDQms6Y2pO0,conda list ucsc-twobittofa,CLOSED,2024-10-03T16:23:31Z,2024-10-07T18:59:44Z,2024-10-07T18:59:44Z,"hello,
I tried to install `ucsc-twobittofa` in conda environment and all things seems like good but when I type the package name it response the command not found. I can see the name in my conda list and when I  utilize conda list ucsc-twobittofa I can see all information of it .",YasaminRaziee,https://github.com/ENCODE-DCC/chip-seq-pipeline2/issues/308
