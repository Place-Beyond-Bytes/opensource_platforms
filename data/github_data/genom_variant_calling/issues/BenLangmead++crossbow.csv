id,title,state,created_at,updated_at,closed_at,body,user,url
MDU6SXNzdWUyMTc2MTk1NQ==,cb_script shall use $RealBin instead of $Bin to resolve libraries ,OPEN,2013-10-29T14:53:23Z,2013-10-29T17:51:34Z,,"One of the ways to use cb_\* scripts can be putting symbolic links to them in /usr/local/bin or similar paths (instead of polluting ever growing PATH). Unfortunately the Perl scripts find their libraries by checking executable file path and its directory without following any symbolic links. I suggest using $RealBin instead of $Bin to resolve this situation the easiest way. 

one can patch the cb_hadoop script, for example, with

sudo sed -i 's/$Bin/$RealBin/g' /biotools/crossbow/cb_hadoop

Best regards,
Vlad
",vlad-belogrudov,https://github.com/BenLangmead/crossbow/issues/3
MDU6SXNzdWUyMTc2MjM4Mw==,"make stops with error on building bowtie, etc, etc",OPEN,2013-10-29T14:59:18Z,2013-10-29T17:52:32Z,,"make cannot proceed due to problems with downloaded archives - wget gets them in form archive.tar.gz.download but the script tries to unpack archive.tar.gz

The makefile also needs some  cleanup to build only what is necessary - now it tries linux, mac, .. failing in the middle. 

The doc mentioned everything for linux comes within a zip but  it is not true anylonger

Best regards,
Vlad
",vlad-belogrudov,https://github.com/BenLangmead/crossbow/issues/4
MDU6SXNzdWUyMjQ0MTY3NQ==,referenced sra are not found on FTP server,OPEN,2013-11-11T11:11:48Z,2013-12-11T14:58:27Z,,"Sample invocation of the tool with e.coli does not work because sra files mentioned in manifest don't exist any longer 
",vlad-belogrudov,https://github.com/BenLangmead/crossbow/issues/5
MDU6SXNzdWUyMjgwNjQzMA==,EMR seems to fail always at the last step,OPEN,2013-11-17T22:02:42Z,2013-12-20T03:04:14Z,,"I am getting results similar to http://www.biostars.org/p/83060/
",vlad-belogrudov,https://github.com/BenLangmead/crossbow/issues/6
MDU6SXNzdWUzNjcwNjI5Nw==,hadoop map failure,OPEN,2014-06-27T21:41:34Z,2021-02-11T12:29:38Z,,"I'm using Crossbow with Hadoop 2.4 on a cluster of 3, and get this error:
## Crossbow job

Hadoop streaming commands in: /tmp/crossbow-9ZzYhbmcKc/invoke.scripts/cb.7742.hadoop.sh
# Running...
# Stage 1 of 4. Preprocess

Fri Jun 27 13:31:44 CDT 2014
14/06/27 13:31:45 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
OpenJDK 64-Bit Server VM warning: You have loaded library /usr/local/hadoop/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.
It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.
14/06/27 13:31:46 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
packageJobJar: [/home/hadoop/crossbow-1.2.0/Get.pm, /home/hadoop/crossbow-1.2.0/Counters.pm, /home/hadoop/crossbow-1.2.0/Util.pm, /home/hadoop/crossbow-1.2.0/Tools.pm, /home/hadoop/crossbow-1.2.0/AWS.pm, /tmp/hadoop-hadoop/hadoop-unjar8648399505312935021/] [] /tmp/streamjob8287394335394764183.jar tmpDir=null
14/06/27 13:31:47 INFO client.RMProxy: Connecting to ResourceManager at hadoopmaster/10.53.14.117:8032
14/06/27 13:31:47 INFO client.RMProxy: Connecting to ResourceManager at hadoopmaster/10.53.14.117:8032
14/06/27 13:31:48 INFO mapred.FileInputFormat: Total input paths to process : 1
14/06/27 13:31:48 INFO mapreduce.JobSubmitter: number of splits:11
14/06/27 13:31:48 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
14/06/27 13:31:48 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/27 13:31:48 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1403714184227_0009
14/06/27 13:31:49 INFO impl.YarnClientImpl: Submitted application application_1403714184227_0009
14/06/27 13:31:49 INFO mapreduce.Job: The url to track the job: http://50.23.84.174-static.reverse.softlayer.com:8088/proxy/application_1403714184227_0009/
14/06/27 13:31:49 INFO mapreduce.Job: Running job: job_1403714184227_0009
14/06/27 13:31:55 INFO mapreduce.Job: Job job_1403714184227_0009 running in uber mode : false
14/06/27 13:31:55 INFO mapreduce.Job:  map 0% reduce 0%
14/06/27 13:32:08 INFO mapreduce.Job:  map 9% reduce 0%
14/06/27 13:32:09 INFO mapreduce.Job:  map 18% reduce 0%
14/06/27 13:32:11 INFO mapreduce.Job:  map 27% reduce 0%
14/06/27 13:32:12 INFO mapreduce.Job:  map 36% reduce 0%
14/06/27 13:32:13 INFO mapreduce.Job:  map 55% reduce 0%
14/06/27 13:32:15 INFO mapreduce.Job:  map 73% reduce 0%
14/06/27 13:32:16 INFO mapreduce.Job:  map 82% reduce 0%
14/06/27 13:32:17 INFO mapreduce.Job:  map 100% reduce 0%
14/06/27 13:34:23 INFO mapreduce.Job: Task Id : attempt_1403714184227_0009_m_000001_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 2
    at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
    at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
    at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
    at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
    at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
    at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
    at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
    at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:415)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

14/06/27 13:34:24 INFO mapreduce.Job:  map 91% reduce 0%
14/06/27 13:34:55 INFO mapreduce.Job:  map 100% reduce 0%
14/06/27 13:34:58 INFO mapreduce.Job: Task Id : attempt_1403714184227_0009_m_000004_0, Status : FAILED
Error: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 2
    at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:320)
    at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:533)
    at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:130)
    at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)
    at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
    at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:430)
    at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342)
    at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
    at java.security.AccessController.doPrivileged(Native Method)
    at javax.security.auth.Subject.doAs(Subject.java:415)
    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

...

14/06/27 13:41:24 INFO mapreduce.Job:  map 91% reduce 0%
14/06/27 13:41:31 INFO mapreduce.Job:  map 100% reduce 0%
14/06/27 13:41:35 INFO mapreduce.Job: Job job_1403714184227_0009 failed with state FAILED due to: Task failed task_1403714184227_0009_m_000009
Job failed as tasks failed. failedMaps:1 failedReduces:0

14/06/27 13:41:38 INFO mapreduce.Job: Counters: 34
    File System Counters
        FILE: Number of bytes read=0
        FILE: Number of bytes written=96812
        FILE: Number of read operations=0
        FILE: Number of large read operations=0
        FILE: Number of write operations=0
        HDFS: Number of bytes read=1629
        HDFS: Number of bytes written=6
        HDFS: Number of read operations=5
        HDFS: Number of large read operations=0
        HDFS: Number of write operations=2
    Job Counters 
        Failed map tasks=24
        Killed map tasks=14
        Launched map tasks=39
        Other local map tasks=39
        Total time spent by all maps in occupied slots (ms)=7474134
        Total time spent by all reduces in occupied slots (ms)=0
        Total time spent by all map tasks (ms)=7474134
        Total vcore-seconds taken by all map tasks=7474134
        Total megabyte-seconds taken by all map tasks=7653513216
    Map-Reduce Framework
        Map input records=1
        Map output records=1
        Input split bytes=127
        Spilled Records=0
        Failed Shuffles=0
        Merged Map outputs=0
        GC time elapsed (ms)=26
        CPU time spent (ms)=800
        Physical memory (bytes) snapshot=136933376
        Virtual memory (bytes) snapshot=1168240640
        Total committed heap usage (bytes)=85458944
    Short read preprocessor
        Comment lines=1
        Warnings=0
    File Input Format Counters 
        Bytes Read=1502
    File Output Format Counters 
        Bytes Written=6
14/06/27 13:41:38 ERROR streaming.StreamJob: Job not Successful!
Streaming Command Failed!
Non-zero exitlevel from Preprocess stage
",soaphee,https://github.com/BenLangmead/crossbow/issues/7
MDU6SXNzdWUyODYzMTQ3NDA=,Errors in sorting ,OPEN,2018-01-05T15:10:33Z,2018-01-05T15:10:33Z,,"Hello,
I'm getting the following error when run **soapsnp**:
```
...
Processing TRINITY_DN154966_c175_g1_i1
Processing TRINITY_DN268204_c0_g1_i1
Processing TRINITY_DN171129_c3_g1_i1
Processing TRINITY_DN167603_c3052_g26_i1
Processing TRINITY_DN172399_c1264_g1_i2
Processing TRINITY_DN154966_c440_g2_i1
Processing TRINITY_DN143030_c98_g1_i1
Processing TRINITY_DN170398_c2_g3_i1
Processing TRINITY_DN166585_c2299_g1_i2
Errors in sorting:1183<1220
```
My command line is the following:
`./soapsnp -i '/home/me/SNP/Programs/soap2.21release/alinhamento chrN/teste4' -d '/home/me/SNP/Programs/soap2.21release/Reference genome/todos_um_e_dois.fasta' -o /home/me/SNP/Programs/soap2.21release/teste4consensus -r 0.05 -t -u -L 400 -M /home/me/SNP/Programs/soap2.21release/teste4matrix -m`

**How do I solve this issue?**",patrick-douglas,https://github.com/BenLangmead/crossbow/issues/8
