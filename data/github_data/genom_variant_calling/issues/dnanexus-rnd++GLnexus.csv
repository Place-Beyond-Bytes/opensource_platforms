id,title,state,created_at,updated_at,closed_at,body,user,url
MDU6SXNzdWUxMTk3OTY1MDI=,Ordering of emitted unphased genotype calls,CLOSED,2015-12-01T20:05:38Z,2015-12-15T00:33:59Z,2015-12-15T00:33:59Z,"Context: when we emit an unphased heterozygous genotype, by convention we should write the two alleles indices in increasing order, e.g. ""2/3"" instead of ""3/2"".

In general, the total order of alleles in the unified site may not be consistent with the partial order in each input gVCF, so we'll need to go out of our way to swap the order when necessary.

We should construct some test that elicits this behavior and enforce increasing order in genotyping.
",yifei-men,https://github.com/dnanexus-rnd/GLnexus/issues/50
MDU6SXNzdWUxMTk3OTczMzY=,Testing of genotyping against known set of unified_sites,OPEN,2015-12-01T20:09:39Z,2015-12-01T20:10:36Z,,"Previously existing test for this use case was dropped in #49 

The ability to genotype a set of samples against unified sites derived from a different set of samples (such as, but not limited to, a superset) will be useful in the future.

As an example, you might do this to get a quick-and-not-too-dirty projection of a new N+1'th sample onto the unified sites for which you already have the N-sample genotype matrix -- for large representative N, the new sample will have few novel alleles, so you'd lose little by doing so. 
",yifei-men,https://github.com/dnanexus-rnd/GLnexus/issues/51
MDU6SXNzdWUxODEyNDUwMjk=,needed to apt-get install catch,CLOSED,2016-10-05T19:33:30Z,2016-11-16T17:21:20Z,2016-11-16T17:21:20Z,"I found I needed to
`apt-get install catch`
after that build worked and tests passed 
",jpdna,https://github.com/dnanexus-rnd/GLnexus/issues/101
MDU6SXNzdWUxODM3MzMxNjQ=,cli discover_alleles tests for incorrect num cli arguments,CLOSED,2016-10-18T16:10:23Z,2016-11-16T17:20:22Z,2016-11-16T17:20:22Z,"With current code, running cli

```
./glnexus_cli discover_alleles ~/glnexus_data1/ chr1:1-50000000 | capnp decode --packed capnp/serialize/defs.capnp DiscoveredAlleles > out.capnp.DiscoveredAlleles.txt
```

I get bounced to usage help always

It looks to me that:
https://github.com/dnanexus-rnd/GLnexus/blob/master/cli/glnexus_cli.cc#L625
should be:

```
if (optind != argc-2) {
```

rather than current `if (optind != argc-1)`   At least it seems to work for me after that code change

Or do I misunderstand the command usage?

One other nit - 
https://github.com/dnanexus-rnd/GLnexus/blob/master/cli/glnexus_cli.cc#L566
should say `discover_alleles` in examples usage, not the current `discover`
and it would be useful to list chr with prefix ""chr1""  of a real chr in example `chrom:1234-2345` in usage so user knows we need th ""chr"" text prefix 
",jpdna,https://github.com/dnanexus-rnd/GLnexus/issues/103
MDU6SXNzdWUzMzQ0MzQ2ODY=,Please add a command line option to specify the number of threads GLnexus is using,CLOSED,2018-06-21T10:35:22Z,2018-07-17T19:18:03Z,2018-07-17T19:18:03Z,"If you consider that some users of your software are running it in a shared environment, like a HPC cluster, then using std::thread::hardware_concurrency() to set the number of threads used might not be the best idea.

I just observed one case, where a user on our HPC cluster submitted 3 single core GLnexus jobs that were all dispatched to the same large compute node.

```
[sfux@lo-a6-001-11 threads]$ cat test.cpp 
#include <iostream>
#include <thread>
 
int main() {
    unsigned int n = std::thread::hardware_concurrency();
    std::cout << n << "" concurrent threads are supported.\n"";
}
[sfux@lo-a6-001-11 threads]$ ./test 
72 concurrent threads are supported.
```

These jobs can only use the 3 cores that are reserved by the batch system (the other 33 cores are reserved for other jobs). The 3 jobs started a total of more than 800 threads (even though only 3*72=216 can be attributed to the threads setting, but there might be other things going wrong), all fighting for the 3 available cores (we limit the cores that a job can use with cgroups, i.e. all the threads started by these processes will be bound to the cores requested from the batch system). This slows down all 3 jobs and makes them very inefficient.

Therefore I would like to kindly ask you to implement an option that users can specify the number of threads on the command line, when running the glnexus_cli command.",samfux84,https://github.com/dnanexus-rnd/GLnexus/issues/133
MDU6SXNzdWUzODQ4OTIyNDI=,"Flag for using different directory path/name for ""GLnexus.DB""",CLOSED,2018-11-27T16:56:22Z,2019-12-30T22:41:43Z,2019-12-28T03:50:16Z,"`glnexus_cli` currently leaves behind a subdirectory `GLnexus.DB`. Since the directory name is fixed and we have no way of modifying it, we cannot run two instances of GLnexus in the same directory. I'd appreciate if you can add a flag for specifying the path to this temporary directory.

Thank you,
Ted",tedyun,https://github.com/dnanexus-rnd/GLnexus/issues/142
MDU6SXNzdWUzOTI3NDIwODc=,FILTER (FT) liftover for Strelka2,CLOSED,2018-12-19T19:18:26Z,2018-12-19T19:29:27Z,2018-12-19T19:29:27Z,,mlin,https://github.com/dnanexus-rnd/GLnexus/issues/143
MDU6SXNzdWUzOTUyNTA3OTE=,Genotyping GVCFs from other vendors,OPEN,2019-01-02T13:38:18Z,2019-01-02T20:57:20Z,,"Hi there,

I have a question regarding genotyping GVCFs that were generated from other vendors. 

For example, can I use GVCFs from Sentieon to jointly genotype variants using GLNexus?

What impact this should have in the variant discovery process?

Thank you for your attention!",raonyguimaraes,https://github.com/dnanexus-rnd/GLnexus/issues/145
MDU6SXNzdWUzOTUyNjU3Njc=,Sentieon GVCFs,CLOSED,2019-01-02T14:32:18Z,2019-04-15T17:58:07Z,2019-04-15T17:58:07Z,"Hi there,

How can I build/define a config preset for Sentieon style GVCFs?",raonyguimaraes,https://github.com/dnanexus-rnd/GLnexus/issues/146
MDU6SXNzdWUzOTYwMjY1Nzg=,Question on use of SyncWAL during bulk load.,CLOSED,2019-01-04T18:43:43Z,2019-01-08T01:39:45Z,2019-01-08T01:39:45Z,"In `RocksKeyValue::DB::flush()`, should `SyncWAL` be conditioned on `!= OpenMode::BULK_LOAD` ?
The write options has WAL disabled when BULK_LOAD.

https://github.com/dnanexus-rnd/GLnexus/blob/master/src/RocksKeyValue.cc#L557
```
    Status flush() override {
        if (mode_ != OpenMode::READ_ONLY) {
            Status s;
            S(convertStatus(db_->SyncWAL()));  // Should this be conditioned on != BULK_LOAD?
            for (const auto& p : coll2handle_) {
                S(convertStatus(db_->Flush(rocksdb::FlushOptions(), p.second)));
            }
        }
        return Status::OK();
    }
```

WAL is disabled here for BULK_LOAD.
```
            // prepare write options
            if (mode_ == OpenMode::BULK_LOAD) {
                write_options_.disableWAL = true;
                batch_write_options_.disableWAL = true;
            } else {
                batch_write_options_.sync = true;
            }
```",xunjieli,https://github.com/dnanexus-rnd/GLnexus/issues/147
MDU6SXNzdWUzOTY2NDE4Nzc=,parallelize allele unifier across chromosomes,CLOSED,2019-01-07T20:42:11Z,2019-12-24T03:04:03Z,2019-12-24T03:04:03Z,"Here the `glnexus_cli` driver runs the allele unifier by looping over the chromosomes serially: https://github.com/dnanexus-rnd/GLnexus/blob/74f427950c325ef58a283dc8ce2008c8b46458c6/cli/glnexus_cli.cc#L112-L125

This causes an embarrassing single-threaded stage which is quite noticeable on WGS datasets (less an issue for WES). It should be easy to parallelize.",mlin,https://github.com/dnanexus-rnd/GLnexus/issues/148
MDU6SXNzdWUzOTY3MTA1ODE=,travis build doesn't work on pull requests,CLOSED,2019-01-08T01:04:26Z,2019-09-24T01:06:22Z,2019-09-24T01:06:22Z,"We build inside a docker container (running inside Travis) which has some advantages, but it checks out the specified revision from dnanexus-rnd/GLnexus, which won't work on a PR originating from someone else's fork. We would like to somehow use Travis' checkout of the source revision in that case, but still have the Dockerfile able to stand alone in other cases.

https://github.com/dnanexus-rnd/GLnexus/blob/0d3974ee6e538936215baf862be23be7eb67b221/Dockerfile#L22",mlin,https://github.com/dnanexus-rnd/GLnexus/issues/149
MDU6SXNzdWU0MDIyNTI1NTg=,--bed ranges and gvcf merging,CLOSED,2019-01-23T13:59:47Z,2019-09-24T05:21:57Z,2019-09-24T05:21:57Z,"Hi, 

Thank you for creating GLnexus.
I have a few question regarding merging of gvcf files from deepvariant. 
1. Does GLnexus change/recalibrate GTs in anyway? I want to use GLnexus for merging gvcf files - not joint-genotyping. 
2. Is it possible to add multiple ranges to the --bed file - or all contigs in the gvcfs? 

Thank you,
/Hagen
 ",HagenC,https://github.com/dnanexus-rnd/GLnexus/issues/150
MDU6SXNzdWU0MDI2NzI1Njk=,VQSR,OPEN,2019-01-24T11:54:31Z,2019-01-24T18:44:02Z,,"Hi there,

My question is if I should perform VQSR after running GLNexus and what is the recommended tool for doing this from a GLNexus output. Should I run Sentieon or GATK4 VQSR?

Thank you!",raonyguimaraes,https://github.com/dnanexus-rnd/GLnexus/issues/151
MDU6SXNzdWU0MDM3MzA0MTY=,Resume GLNexus for an existing GLnexus.DB database,OPEN,2019-01-28T09:56:44Z,2020-11-30T20:52:05Z,,"Is there a way to reuse the created GLnexus.DB database after an unsuccessful run?

My bed file was empty and because of that, it didn't call any variants although it created the database for calling the variants. Is there a way to rerun glnexus using the same database? Right now if I try to run it again it complains about the existing folder instead of trying to use the database that it already has created.

Is there a way to bypass this check and use the existing database?

Thanks for all the help!",raonyguimaraes,https://github.com/dnanexus-rnd/GLnexus/issues/152
MDU6SXNzdWU0MDU3MDE0MzU=,Using GLnexus to merge gVCFs produced by isaac/starling,OPEN,2019-02-01T13:27:09Z,2019-02-04T13:18:46Z,,"I'm trialing using GLnexus to merge gVCFs produced by the isaac/starling workflow from Illumina, as an alternative to using gvcfgenotyper (as gvcfgenotyper is extremely memory heavy).

I know it's not a supported configuration, but I have had some success using the yaml for Strelka (with some minor modifications, changing the allele_dp_format field from min_dp to dp).

This does work, and produce a merged gVCF, but I've noticed the following issues:
Output format fields for AD,GQ can have . as an entry, instead of an int value.
If the value for min_GQ is set higher than min_AQ1 and min_AQ2 then every variant is filtered out.

The second issue is easy to work around, but the first is presenting problems when trying to use the produced gVCF downstream, for example importing it into Hail throws an error, since it expects ints.

Is this something that you would be able to help / advise with?

Below is the full config file that I am using:
`unifier_config:`
`drop_filtered: false`
`min_allele_copy_number: 1`
`min_AQ1: 0`
`min_AQ2: 0`
`min_GQ: 0`
`max_alleles_per_site: 0`
`monoallelic_sites_for_lost_alleles: false`
`preference: common`
`genotyper_config:`
`revise_genotypes: false`
`min_assumed_allele_frequency: 0.0001`
`required_dp: 0`
`allow_partial_data: false`
`allele_dp_format: AD`
`ref_dp_format: DP`
`output_residuals: false`
`squeeze: false`
`output_format: BCF`
`liftover_fields:`
`- {orig_names: [MIN_DP, DP, DPI], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}`
`- {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=.,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: true}`
`- {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: float, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}`
`- {orig_names: [FILTER], name: FT, description: ""##FORMAT=<ID=FT,Number=1,Type=String,Description=\""FILTER field from sample gVCF\"">"", type: string, number: basic, default_type: missing, count: 1, combi_method: missing, ignore_non_variants: true}`",Alexander-Stuckey,https://github.com/dnanexus-rnd/GLnexus/issues/153
MDU6SXNzdWU0MDY1NDM5OTg=,De Novo Mutation QC / Filtering,OPEN,2019-02-04T22:15:20Z,2019-02-06T20:51:55Z,,"Many existing pipelines implement features from GATK/VQSR to distinguish between true and false de novo mutations. Given GLnexus variant calling, these pipelines cannot be adapted. 

Do you have recommendations for de novo mutation calling for SNVs and INDELs? I was wondering if you could please expand on this

>The  pVCF  output  from  joint-calling  would  typically undergo    further    QC    filtering suited    to specific downstream analyses, such  as identifying candidate de novo mutations... ",dantaki,https://github.com/dnanexus-rnd/GLnexus/issues/154
MDU6SXNzdWU0MDY3MjEwNDQ=,Option to create one file per region specified in regions file,OPEN,2019-02-05T10:40:11Z,2019-02-05T12:00:29Z,,"Currently with GLnexus (as I understand it), it creates one output file that contains the regions that are specified in the regions BED file. It would be nice if there was an option for creating one file per region in the BED file instead.

Due to the large number of gVCF files that I would need to merge, the merged file would end up somewhere in the range of 200+TB, so being able to split them would be best.",Alexander-Stuckey,https://github.com/dnanexus-rnd/GLnexus/issues/155
MDU6SXNzdWU0MDY4NDY4MzM=,gVCF reference depth FORMAT field is missing or malformed,CLOSED,2019-02-05T15:49:18Z,2019-02-06T15:53:02Z,2019-02-06T15:53:02Z,"Hi,

When I try to run GLnexus, sometimes I got the below error, but not always:
```
Failed to Genotyping: Invalid: genotyper: gVCF reference depth FORMAT field is missing or malformed (BPD22-Fam6_snp <0>:69091-70009 (MIN_DP))
```
My gvcf is generated using xAtlas, and does not have the MIN_DP field. But sometimes the merging works even my files does not have the MIN_DP field. 

Do you have any idea why this happens?

Thanks,
Hurley
",hurleyLi,https://github.com/dnanexus-rnd/GLnexus/issues/156
MDU6SXNzdWU0MDk4ODk2MDM=,Implementing BCFData directly instead of relying on RocksDB,CLOSED,2019-02-13T16:26:50Z,2019-02-20T20:42:04Z,2019-02-20T19:59:57Z,"@mlin, you mentioned that in https://github.com/dnanexus-rnd/GLnexus/issues/147#issuecomment-452139168 we can directly implement KeyValueData using a cloud-based storage system. However, I've tried that and it doesn't work better than having an embeddable database like RocksDB. 

Now I want to get rid of RocksDB entirely by implementing **BCFData** directly. 
All our gVCFs reside in the cloud already (accessible via file-like APIs). If they are also tabix indexed, we can query ranges of the gVCFs and retrieve subset of records that fit in RAM.

Do you think this approach (overriding BCFData directly) will work? GLnexus uses 30kbp bins of records and stores them in KeyValueData. That also means we need to pay for serialization and deserialization cost (bcf1_t from/to capnproto). I am wondering if we can avoid relying on KeyValueData and query records on demand from a cloud source. There are probably subtleties that I am missing.  Thank you.
",xunjieli,https://github.com/dnanexus-rnd/GLnexus/issues/158
MDU6SXNzdWU0MTEwOTYxOTg=,QC of variant genotypes,CLOSED,2019-02-16T17:56:58Z,2019-04-15T17:54:04Z,2019-04-15T17:54:04Z,"GLnexus as output genotypes have mostly 4 options:
0/0 - reference hom
0/1
1/1 - alt hom
./. - no reads
Although if the specific locus is sequenced by only 1 read , sample have genotype as 0/0 or 1/1 . 
Is it somehow possible to specify a minimal quality / depth to call as ./. genotype (e.g. all locuses with DP<10) ?",bopohdr,https://github.com/dnanexus-rnd/GLnexus/issues/159
MDU6SXNzdWU0MTg2Njk4NjY=,idea: cache the last-seen reference record,OPEN,2019-03-08T07:41:20Z,2019-04-19T17:04:58Z,,"When loci are sufficiently dense, most of the time the genotyper gets back from the database the same reference records pertinent to the other recent loci it looked at. Maybe we can come up with 'safe' rules for regurgitating it from some cache, saving the bucket scan and `bcf_unpack` each time. The new query has to be contained within the reference record range, and there have to be no other records (in the same sample) overlapping that reference record. 

Thread contention on this cache might become a problem, though.",mlin,https://github.com/dnanexus-rnd/GLnexus/issues/160
MDU6SXNzdWU0MjA3MjY3MzA=,AF calculation from DeepVariant,OPEN,2019-03-13T21:25:32Z,2019-04-12T19:04:16Z,,"I am trying to use GLnexus on DNAnexus platform for gvcfs produced by DeepVariant. For positions that was not covered (or by some reads only), the genotype is 0/0 - which assumes it is homozygous and is used for AF calculation. 
Example:
`
#CHROM | POS | ID | REF | ALT | QUAL | FILTER | INFO | FORMAT | ZL556| ZL553
-- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --
chr1 | 1020217 | chr1_1020217_G_T | G | T | 0 | . | AF=0.25 | GT:DP:AD:GQ:PL:RNC | 0/0:0:0,0:1:.:.. | 0/1:3:1,2:3:0,0,26:..
chr1 | 1041134 | chr1_1041134_C_A | C | A | 33 | . | AF=0.5;AQ=33 | GT:DP:AD:GQ:PL:RNC | 0/1:4:0,4:28:33,0,29:.. | 0/1:8:1,7:16:17,0,21:..
`
First case has AF=0.25 while sample ZL556 do not have any reads at this positions.

For sentieon it was at least ./. or similar. 

Is it possible to add/change/improve something in DNAnexus version to take low DP or 0 DP in account, when calculating AF and assigning genotypes ? ",bopohdr,https://github.com/dnanexus-rnd/GLnexus/issues/161
MDU6SXNzdWU0MjY1NjI3NDk=,Dragen JgVCF merging,OPEN,2019-03-28T15:36:43Z,2020-07-29T04:13:26Z,,"Hi there,
We trying to merge joint Edico-Dragen called gVCFs (one VCF file per family) and noticed two issues:

Error 1:  ""Invalid: allele is not a DNA sequence""  - that seems to happen if an asterix is part of the VCF file allele notation. 
Error2: ""invalid GT entry in gVCF record"" happened for haploid genotypes.

Thank you!",MatthiasWielscher,https://github.com/dnanexus-rnd/GLnexus/issues/162
MDU6SXNzdWU0MzI5NzQ1MTg=,Trio pipeline,OPEN,2019-04-14T13:11:54Z,2020-01-08T22:42:26Z,,"Hello, I want to analyse trios data (father,mother,child). Should I create the vcf files for each member with deepvariant and then combine then with GLnexus? ",kokyriakidis,https://github.com/dnanexus-rnd/GLnexus/issues/163
MDU6SXNzdWU0MzQ0MzM5NTQ=,min_AQ1 has no effect when min_AQ2 is zero,CLOSED,2019-04-17T18:51:32Z,2019-04-23T14:46:57Z,2019-04-23T05:19:26Z,"My name is Ted Yun and I'm in Genomics team at Google. My coworkers and I have found that when GLnexus is run with the two different set of parameters: `min_AQ1 = 30, min_AQ2 = 0` and `min_AQ1 = 0, min_AQ2 = 0`, it produces identical results.

I believe I've found the cause of the issue and have created a pull request containing a fix - https://github.com/dnanexus-rnd/GLnexus/pull/164 Please take a look. Thank you!

Regards,
Ted",tedyun,https://github.com/dnanexus-rnd/GLnexus/issues/165
MDU6SXNzdWU0MzUyNDI0ODU=,investigate benefits of cgranges,CLOSED,2019-04-19T17:04:30Z,2019-07-20T16:41:21Z,2019-07-20T16:41:21Z,"https://github.com/lh3/cgranges

What's the feasibility of using this in place of the current ['skip index' scheme](https://github.com/dnanexus-rnd/GLnexus/blob/e25a6be613fbd1879477d62c7258a2dcfe8dd896/src/BCFKeyValueData_utils.h#L152)? Would it be practically advantageous given that gVCF records tend to be non-overlapping?",mlin,https://github.com/dnanexus-rnd/GLnexus/issues/166
MDU6SXNzdWU0Mzc3NjczNTY=,Bug in AF calculation when exome capture is used as --bed,CLOSED,2019-04-26T17:14:45Z,2019-05-16T00:38:35Z,2019-05-13T11:09:36Z,"When exome capture regions is used as --bed, there are issues with AF calculation at the edges of these regions.

Here's one example where GLnexus will calculate the AF as 1.33333 when it should be 0.666667

HG002
```
19	13317490	.	GTTA	G,<*>	59	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:58:76:0,76,0:1,0:59,65,0,990,990,990
```

HG003
```
19	13317490	.	GTTA	G,<*>	69.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:66:76:34,42,0:0.552632,0:69,0,68,990,990,990
```

HG004
```
19	13317490	.	GTTA	G,<*>	70.7	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:69:78:37,41,0:0.525641,0:70,0,74,990,990,990
```

Bed file used (taken from agilent_sureselect_human_all_exon_v5_b37_targets.bed)
```
19	13317371	13317491
19	13317492	13317612
```

```
./glnexus_cli --config DeepVariant --bed chr19.bed HG00*.vcf.gz > merged.bcf
```

This merged.bcf will have `AF=1.33333`:
```
19	13317490	19_13317490_GTTA_G	GTTA	G	70	.	AF=1.33333;AQ=70	GT:DP:AD:GQ:PL:RNC	1/1:76:0,76:58:59,65,0:..	0/1:76:34,42:66:69,0,68:..	0/1:78:37,41:69:70,0,74:..
```

If repeat the above, but supply `19 0 10000000` as --bed, GLnexus is correct in the AF calculation. `AF=0.666667`:
```
19	13317490	19_13317490_GTTA_G	GTTA	G	70	.	AF=0.666667;AQ=70	GT:DP:AD:GQ:PL:RNC	1/1:76:0,76:58:59,65,0:..	0/1:76:34,42:66:69,0,68:..	0/1:78:37,41:69:70,0,74:..
```",xunjieli,https://github.com/dnanexus-rnd/GLnexus/issues/168
MDU6SXNzdWU0Mzg1OTg4ODY=,"install failure, how can I solve this problem?",CLOSED,2019-04-30T04:24:08Z,2019-12-24T03:27:26Z,2019-12-24T03:27:26Z,"tao@ubuntu:~/GLnexus⟫ sudo make -j$(nproc)
[  8%] Built target catch
[ 16%] Built target capnp
[ 32%] Built target spdlog
[ 32%] Built target yaml-cpp
[ 40%] Built target fcmm
[ 48%] Built target htslib
[ 56%] Built target CTPL
[ 64%] Built target rocksdb
[ 82%] Built target glnexus
[ 83%] Linking CXX executable glnexus_cli
[ 84%] Linking CXX executable unit_tests
/usr/bin/ld: cannot find -lsnappy
/usr/bin/ld: cannot find -lzstd
collect2: error: ld returned 1 exit status
CMakeFiles/glnexus_cli.dir/build.make:98: recipe for target 'glnexus_cli' failed
make[2]: *** [glnexus_cli] Error 1
CMakeFiles/Makefile2:387: recipe for target 'CMakeFiles/glnexus_cli.dir/all' failed
make[1]: *** [CMakeFiles/glnexus_cli.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
/usr/bin/ld: cannot find -lsnappy
/usr/bin/ld: cannot find -lzstd
collect2: error: ld returned 1 exit status
CMakeFiles/unit_tests.dir/build.make:436: recipe for target 'unit_tests' failed
make[2]: *** [unit_tests] Error 1
CMakeFiles/Makefile2:983: recipe for target 'CMakeFiles/unit_tests.dir/all' failed
make[1]: *** [CMakeFiles/unit_tests.dir/all] Error 2
Makefile:138: recipe for target 'all' failed
make: *** [all] Error 2


---------------please see above errors------
how can I install successfully?",scotty323,https://github.com/dnanexus-rnd/GLnexus/issues/169
MDU6SXNzdWU0NDQ3MDg4NDI=,Performance issue with std::set used as a range filter when exome bed targets are used,CLOSED,2019-05-16T01:08:48Z,2019-05-31T00:05:46Z,2019-05-31T00:05:46Z,"Exome bed file can contain close to 300k records. `std::set<range>` of this size will slow the import stage to a crawl.

Local profiling shows that most of the time  (~86% in this case) is spent in iterating the rb tree that backs the `std::set<range>`.
![T5YxPcDTfZW](https://user-images.githubusercontent.com/1412855/57818649-c81edc00-7752-11e9-9627-063c915f86fe.png)

Can we improve this part? Maybe `std::vector` instead of `std::set`, and do a binary search of overlapping ranges? Or a better solution as you suggested in the comment below, it will be great if you can consider implementing the tabix build (if an index doesn't already exist) and query using htslib/tbx.h, and so we can do without the `std::set` here and use a flat container.

https://github.com/dnanexus-rnd/GLnexus/blob/master/src/BCFKeyValueData.cc#L933
```
static Status bulk_insert_gvcf_key_values(BCFBucketRange& rangeHelper,
                                          MetadataCache& metadata,
                                          KeyValue::DB* db,
                                          const string& dataset,
                                          const string& filename,
                                          const set<range>& range_filter,
                                          const bcf_hdr_t *hdr,
                                          vcfFile *vcf,
                                          BCFKeyValueData::import_result& rslt) {
...
    for(c = bcf_read(vcf, hdr, vt.get());
        c == 0 && vt->errcode == 0;
        c = bcf_read(vcf, hdr, vt.get())) {
        range vt_rng(vt.get());
        last_range = vt_rng;
        if (!range_filter.empty()) {
            // Test range filter if applicable. It would be nice to use a
            // tabix index instead.
            if (all_of(range_filter.begin(), range_filter.end(),
                       [&vt_rng](const range& r) { return !r.overlaps(vt_rng); })) {
                continue;
            }
        }
```",xunjieli,https://github.com/dnanexus-rnd/GLnexus/issues/171
MDU6SXNzdWU0NDk0MjA0ODc=,Ability to specify a user provided configuration yaml file or ability to change presets,CLOSED,2019-05-28T18:43:50Z,2019-05-29T13:11:41Z,2019-05-29T13:11:40Z,"We are experimenting with different GLnexus parameters. It will be very helpful if the standalone GLnexus program (glnexus_cli) can accept a flag to parse a user-supplied yaml config file instead of using one of the presets.

This feature request might be equivalent to what you wrote in the code here:

https://github.com/dnanexus-rnd/GLnexus/blob/master/src/cli_utils.cc#L463
```
// hard-coded configuration presets for unifier & genotyper. TODO: these
// should reside in some user-modifiable yml file
static const char* config_presets_yml = R""eof(
...
```

Either solution will work for us, so we can use the released binaries with different params.  Thank you.",xunjieli,https://github.com/dnanexus-rnd/GLnexus/issues/172
MDU6SXNzdWU0NjY1NDgwMzY=,Missing PL fields for 0/0 calls ,CLOSED,2019-07-10T22:11:28Z,2019-10-30T21:14:48Z,2019-10-30T21:14:48Z,"We noticed that GLnexus omits PL fields for `0/0` calls while GATK's GenotypeGVCFs retains PL fields from the original gVCF.

An example:
HG002 has no variant at loc 61083.
gVCF content:
```
chr20	61001	.	C	<*>	0	.	END=61130	GT:GQ:MIN_DP:PL	0/0:50:94:0,300,2999
```

Merged VCF with GATK 4.0.6.0 GenotypeGVCFs:
```
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  HG002   HG003   HG004
chr20	61083	.	C	T	31.18	.	AC=2;AF=0.333;AN=6;DP=94;ExcessHet=3.9794;MLEAC=2;MLEAF=0.333;QD=0.3	GT:AD:DP:GQ:PL:VAF	0/0:94,0:94:99:0,300,2999:.	0/1:29,23:.:27:27,0,49:0.442,0	0/1:35,17:.:36:36,0,59:0.321,0
```
Notice that HG002 is 0/0 with PL is `0,300,2999`.

Merged VCF with GLnexus:
```
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  HG002   HG003   HG004
chr20	61083	chr20_61083_C_T	C	T	36	.	AF=0.333333;AQ=36	GT:DP:AD:GQ:PL:RNC	0/0:94:94,0:50:.:..	0/1:52:29,23:27:27,0,49:..	0/1:53:35,17:37:36,0,59:..
```

Notice that HG002 is 0/0 but PL is `.`. 

Can GLnexus retain the PL fields? 

The VCF spec (https://samtools.github.io/hts-specs/VCFv4.3.pdf) seems underspecified in this regard, and PL for `ref/<*>` is interpreted as `ref/any alt allele` in GATK. If GLnexus can match this behavior, that will greatly facilitate our downstream analysis. I am somewhat lost in the code and not sure how this can be fixed. Or is GLnexus's treatment better?

@mlin ",xunjieli,https://github.com/dnanexus-rnd/GLnexus/issues/173
MDU6SXNzdWU0Njg4MzMwNzk=,glnexus_cli should have -o to write out a file instead of stdout,OPEN,2019-07-16T19:49:39Z,2019-07-18T07:43:12Z,,"Hi,

First of all, Great Job.

(Issue) I am trying to use GLnexus, not sure why, but when I run the command under the screen command, the output does not generate. 
Is there any -out option to define the output file rather than "">""


(Suggestion) Imagin that I run GLnexus on 50 samples, after a week I have 10 new samples, it will be a nice option if GLnexus only go over the new samples and new positions. As I learned currently I need to call all samples again.

Kind regards
Amin",aardes,https://github.com/dnanexus-rnd/GLnexus/issues/175
MDU6SXNzdWU0NzA2MjkxMTM=,"nondeterministic sorting of ""usable half-calls""",CLOSED,2019-07-20T03:21:50Z,2019-12-28T03:18:58Z,2019-12-28T03:18:58Z,"Obscure corner case where GLnexus generates nondeterministic results:

https://github.com/dnanexus-rnd/GLnexus/blob/237e9bcbcd685445ab0aa65ecbc6c29cefe1b26e/src/genotyper.cc#L441-L448

https://github.com/dnanexus-rnd/GLnexus/blob/237e9bcbcd685445ab0aa65ecbc6c29cefe1b26e/src/genotyper.cc#L471

This sorts the ""usable half-calls"" by decreasing QUAL value, but it's possible that multiple such records share the same QUAL value. Then the order we get depends on the arbitrary/uncontrollable memory address pointers. ",mlin,https://github.com/dnanexus-rnd/GLnexus/issues/176
MDU6SXNzdWU0ODQwOTgxNDU=,docker image,CLOSED,2019-08-22T16:33:10Z,2019-10-30T22:57:07Z,2019-10-30T22:57:07Z,"hi, thanks for providing the software and the Dockerfile. Would it be possible to have an image on dockerhub? this makes it simpler to create a singularity image to run on a cluster (I'm not able to get the static binary to work on our cluster regardless of the GCC futzing).",brentp,https://github.com/dnanexus-rnd/GLnexus/issues/177
MDU6SXNzdWU0ODcwMDQ2Mjg=,Truncated bcf file,CLOSED,2019-08-29T14:47:04Z,2019-09-27T13:18:29Z,2019-09-27T13:18:29Z,"I've been using GLNexus 1.1.3 and about 27,000 WES gVCFs from DeepVariant to create a single cohort bcf. It's been working well for months. I decided to try GLNexus 1.1.10 and when writing the bcf file it seems to consume all the memory on the server (500GB or 750GB depending on the server I use) and the process is killed. The bcf file is not completed and I have to start over. I tried upgrading to GLNexus 1.1.11 and I have the same problem. So I've gone back to using the older version (1.1.3).

Is there something that changed in the new version that I should be aware of? Or is there some more info that I could provide that would help diagnose the problem.",chrisfleisch,https://github.com/dnanexus-rnd/GLnexus/issues/178
MDU6SXNzdWU0OTgxMzIyNTY=,error in make step,CLOSED,2019-09-25T08:32:03Z,2019-12-24T03:05:01Z,2019-12-24T03:05:01Z,"![makeError](https://user-images.githubusercontent.com/6711870/65583192-5896e400-dfb1-11e9-99c8-93da990250db.png)

CZ docker are not available in our server, GLnexus was installed with cmake. Some errors present in the make step:
PASS: capnp-evolution-test
PASS: src/capnp/compiler/capnp-test.sh
FAIL: capnp-test
============================================================================
Testsuite summary for Capn Proto 0.7.0
============================================================================
# TOTAL: 3
# PASS:  2
# SKIP:  0
# XFAIL: 0
# FAIL:  1
# XPASS: 0
# ERROR: 0
============================================================================
See ./test-suite.log
Please report to capnproto@googlegroups.com
============================================================================
make[6]: *** [Makefile:3475：test-suite.log] 错误 1
make[5]: *** [Makefile:3583：check-TESTS] 错误 2
make[4]: *** [Makefile:3805：check-am] 错误 2
make[3]: *** [Makefile:3807：check] 错误 2
make[2]: *** [CMakeFiles/capnp.dir/build.make:113：external/src/capnp-stamp/capnp-build] 错误 2
make[1]: *** [CMakeFiles/Makefile2:482：CMakeFiles/capnp.dir/all] 错误 2
make: *** [Makefile:141：all] 错误 2",berry08,https://github.com/dnanexus-rnd/GLnexus/issues/182
MDU6SXNzdWU1MDA0Mjg1NTc=,Remove const qualifier on BCFData::dataset_header,CLOSED,2019-09-30T17:57:11Z,2019-09-30T20:13:31Z,2019-09-30T20:13:31Z,"Hi Mike, `BCFKeyValueData::dataset_header` modifies the cache state, and it's not a const method in the strict sense. Do you think it's a good idea to remove the `const` qualifier on the parent method `BCFData::dataset_header` ?

I am currently trying to implement BCFData interface with my own cache backend. The const method signature makes it difficult to override `dataset_header` in a cache aware manner.
",xunjieli,https://github.com/dnanexus-rnd/GLnexus/issues/185
MDU6SXNzdWU1MDE1NzAzMjU=,Number=R for AD,CLOSED,2019-10-02T15:40:41Z,2019-10-02T22:14:49Z,2019-10-02T22:14:48Z,"Currently, glnexus writes the AD file with Number=. this means that decomposing, or subsetting the VCF by samples does not work correctly.

VCF4.2 supports Number=R for this.",brentp,https://github.com/dnanexus-rnd/GLnexus/issues/187
MDU6SXNzdWU1MTIxMTMyODI=,option to bcf_trim_alleles after regenotyping,CLOSED,2019-10-24T18:38:56Z,2019-10-29T12:13:44Z,2019-10-29T12:13:43Z,It's possible for the genotype revision to leave allele in the pVCF without any (hard) calls. htslib has a convenient subroutine we can use to drop them before writing out the final row: https://github.com/samtools/htslib/blob/123bd90394e6bc49ebc869b5cc43a31076d9523c/htslib/vcfutils.h#L47,mlin,https://github.com/dnanexus-rnd/GLnexus/issues/191
MDU6SXNzdWU1MTI4OTk0ODc=,RocksDB build issues with gcc 9,CLOSED,2019-10-26T23:49:35Z,2019-12-23T00:34:13Z,2019-12-23T00:34:13Z,"RocksDB hits compile errors with gcc 9, which can be worked around by adding `-Wno-error=deprecated-copy -Wno-error=pessimizing-move` to the RocksDB build flags in CMakeLists.txt. However, this then breaks earlier versions of gcc which don't understand those flags.

we're waiting for RocksDB to cut a release including https://github.com/facebook/rocksdb/commit/61876614dce8c9155e28d40b5d95ec1bf1cbfa47",mlin,https://github.com/dnanexus-rnd/GLnexus/issues/192
MDU6SXNzdWU1MTQ5Mzc5Mjg=,"The ""Performance"" wiki page has moved/removed",CLOSED,2019-10-30T19:48:07Z,2019-10-30T20:47:13Z,2019-10-30T20:47:13Z,"Hi Mike,

I just noticed that the ""Performance"" wiki page link is dead so wanted to let you know in case you didn't know already :) https://github.com/dnanexus-rnd/GLnexus#performance-profiling

The link address is: https://github.com/dnanexus-rnd/GLnexus/wiki/Performance

Thanks,
Ted",tedyun,https://github.com/dnanexus-rnd/GLnexus/issues/194
MDU6SXNzdWU1MTc5OTc3MzM=,Dockerfile multi-stage build,CLOSED,2019-11-05T20:05:25Z,2019-11-26T02:34:01Z,2019-11-26T02:34:01Z,"https://docs.docker.com/develop/develop-images/multistage-build/

would clean up the ad hoc way we build the runtime docker image right now (scripted in .travis.yml)",mlin,https://github.com/dnanexus-rnd/GLnexus/issues/198
MDU6SXNzdWU1MjgzNzg1NTY=,account for discovered_alleles data structures in memory budget,CLOSED,2019-11-25T22:38:28Z,2024-03-12T01:21:42Z,2019-12-24T03:03:41Z,"When the allele discovery stage runs on large WGS/WES cohorts, the discovered_alleles data structures use a considerable amount of memory not currently accounted for in the `--mem-gbytes` budget. This can cause an OOM problem trying to run everything in one shot (as opposed to splitting up chromosomes or such into separate runs).",mlin,https://github.com/dnanexus-rnd/GLnexus/issues/199
MDU6SXNzdWU1NDcyMTQ0Njc=,out of memory for large dataset,CLOSED,2020-01-09T02:41:27Z,2022-11-15T12:19:15Z,2020-09-10T00:52:10Z,"Hi,
I'm trying to run GLnexus on a large dataset with 9,000 exome gvcfs, and I always has the issues of running out of memory. I run them on a 190G machine, and specified the exon bed file. 

Any suggestions on how I should deal with this issue?
Thanks!
Hurley
",hurleyLi,https://github.com/dnanexus-rnd/GLnexus/issues/206
MDU6SXNzdWU1NDk5MjI3OTE=,an error appear when use glnexus_cli,CLOSED,2020-01-15T02:09:44Z,2020-12-22T20:56:19Z,2020-02-16T19:34:58Z,"version:v1.1.5-1-gd7b4307
command:glnexus_cli --bed test2.bed --squeeze  sample*.g.vcf.gz >chr1.bcf
test2.bed:chr1	1	3000000
sample*.g.vcf.gz: there are two files in total, some lines in file are pasted as follow:
chr1    1000281 .       C       <NON_REF>       .       .       END=1000284     GT:DP:GQ:MIN_DP:PL      0/0:36:99:34:0,99,1120
chr1    1000285 .       C       <NON_REF>       .       .       END=1000290     GT:DP:GQ:MIN_DP:PL      0/0:30:81:29:0,81,1215
chr1    1000291 rs116904365     C       G,<NON_REF>     100.77  .       BaseQRankSum=-0.555;ClippingRankSum=0.000;DB;DP=17;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.500,0.00;MQRankSum=0.000;RAW_MQ=61200.00;ReadPosRankSum=1.236     GT:AD:DP:GQ:PL:SB       0/1:11,6,0:17:99:129,0,283,161,301,463:4,7,4,2
chr1    1000292 .       C       <NON_REF>       .       .       END=1000292     GT:DP:GQ:MIN_DP:PL      0/0:19:54:19:0,54,810

running errors:
[001957] [2020-01-14 21:02:50.887] [GLnexus] [error] sample1000000.g.vcf.gz IOError: reading from gVCF file (sample1000000.g.vcf.gz bcf1_t::errcode = 2; after chr1:1000285-1000290)
[001957] [2020-01-14 21:02:50.887] [GLnexus] [error] sample999001.g.vcf.gz IOError: reading from gVCF file (sample999001.g.vcf.gz bcf1_t::errcode = 2; after chr1:1000075-1000078)
[001957] [2020-01-14 21:02:50.897] [GLnexus] [error] Failed to bulk load into DB: Failure: One or more gVCF inputs failed validation or database loading; check log for details.",berry08,https://github.com/dnanexus-rnd/GLnexus/issues/207
MDU6SXNzdWU1NTQ1NTA1MDc=,tech debt: htslib 1.10+ breaking ABI changes,OPEN,2020-01-24T05:21:26Z,2024-09-23T08:41:28Z,,"htslib 1.10 widens a couple of fields in `bcf1_t` from 32-bit to 64-bit. We'll need to update [BCFSerialize.cc](https://github.com/dnanexus-rnd/GLnexus/blob/master/src/BCFSerialize.cc) & tests to match, and invalidate/upgrade existing databases.

Info: https://github.com/samtools/htslib/blob/develop/README.large_positions.md

wip: https://github.com/dnanexus-rnd/GLnexus/tree/mlin-htslib-1.10
",mlin,https://github.com/dnanexus-rnd/GLnexus/issues/208
MDU6SXNzdWU1NjU3OTA2NDM=,Any recommended parser?,CLOSED,2020-02-15T18:31:23Z,2020-02-26T21:48:52Z,2020-02-26T21:48:52Z,"Hello,

I was just wondering if there was any recommended tool for parsing the pVCF? Of course it is always possible to write on to extract the relevant fields. 
If I am interested into de novo variants that exist in  1 sample, and is not shared with any other sample, what would be the genotype assigned by GLnexus? Am I right to assume I should look for rows where the genotypes is ./. everywhere but in a single sample?

thanks a lot",N/A,https://github.com/dnanexus-rnd/GLnexus/issues/209
MDU6SXNzdWU1NjY3MTk5ODQ=,pVCF representation rework,OPEN,2020-02-18T08:15:06Z,2024-11-12T21:03:37Z,,"We're considering a significant rework of GLnexus' output [pVCF representation](https://github.com/dnanexus-rnd/GLnexus/wiki/Reading-GLnexus-pVCFs). This issue is here for early show-and-tell and feedback. We have not yet decided to execute on it.

**Pros and cons of [current representation](https://github.com/dnanexus-rnd/GLnexus/wiki/Reading-GLnexus-pVCFs)**

To review briefly, given a set of overlapping alleles discovered in the population, GLnexus currently unifies as many of them as possible into non-overlapping multiallelic sites of mutually exclusive alleles; and for the few remaining alleles (typically <1%) that don't unify cleanly, emits a secondary tier of ""monoallelic"" records to indicate their copy number, without duplicating reference and other calls in the overlapping sites.

Contrived example:

```
                         Alice  Bob    Carol
chr17  1000  A    T,C    ./.    1/2    0/0
chr17  1000  ACG  A      1/1    ./.    ./.   *MONOALLELIC
chr17  1001  CGA  C,GGA  ./.    0/1    1/2
```

Pro:

* overlapping records are minimized
* pVCF records are ~independent with no duplication between them
* multi-ALT records model all possible ""het-ALT"" genotypes (heterozygotes carrying two different non-reference alleles) at a site/locus & their full joint PL

Con:

* allele padding (to unify with lengthier, overlapping alleles) is common & inconvenient
* PL field grows quadratically in # of alleles at a site
* large expenditure of representation effort/space to accommodate all possible het-ALT genotypes, few if any of which are usually observed. (In 1KGP chr17 data, there are only 196K distinct het-ALT genotypes observed with 3.6M ALT alleles.)
* situations that give rise to ""monoallelic"" records seem arbitrary to users
* downstream programs may badly overestimate AF=AC/AN in monoallelic records


**Proposed alternative**

A pending [VCF spec proposal](https://github.com/samtools/hts-specs/pull/464) endorses the splitting of het-ALT genotypes across two overlapping VCF records, thereby relieving pressure to unify all overlapping alleles into a single, multi-ALT pVCF site. GLnexus historically avoided such split/overlapping genotypes, but the field has generally grown more comfortable with this kind of representation since we started in 2015. The key is the use of the ""star allele"" to symbolize some allele not specified in the current record, but that should be found in another overlapping record.

Several variant callers now use the star allele or something like it, albeit -- of course -- [without consensus on important details](https://github.com/samtools/hts-specs/issues/437) of its interpretation (especially how to describe reference bases in the vicinity of het-ALT genotypes). We'll therefore still have to make some ""artistic"" choices about when to use multi-ALT sites versus a series of overlapping records involving star alleles. The most uniform & predictable approach, [following bgt](https://github.com/samtools/hts-specs/issues/437#issuecomment-528064189), seems to move toward one pVCF record per ALT allele:

1. Generate one pVCF record for every discovered alternate allele passing quality thresholds.
2. The record's alleles are 0=REF, 1=ALT, 2=* and are never padded.
3. het-ALT genotypes are *always* split across two overlapping records with GT=1/2.

The concept of ""site"" or ""locus"" is demoted. The main drawback is making it harder to analyze het-ALT genotypes; even if the reader knows to reconstruct the genotype by examining overlapping records, they're only shown marginals of the joint PL distribution. 

Applied to our example:

```
                         Alice    Bob  Carol
chr17  1000  A    T,*      2/2    1/2    0/0
chr17  1000  A    C,*      2/2    1/2    0/0
chr17  1000  ACG  A,*      1/1    2/2    0/0
chr17  1001  C    G,*      2/2    0/2    1/2
chr17  1001  CGA  C,*      2/2    0/1    1/2
```

**Optional: idea to furthermore keep het-ALT genotypes & PLs**

4. Furthermore generate a multi-ALT pVCF record *for each distinct het-ALT genotype actually observed in the cohort* above a quality threshold: 0=REF, 1=ALT1, 2=ALT2, 3=*. 

```
                         Alice    Bob  Carol
chr17  1000  A    T,*      2/2    1/2    0/0
chr17  1000  A    C,*      2/2    1/2    0/0
chr17  1000  A    T,C,*    3/3    1/2    0/0 *HET-ALT
chr17  1000  ACG  A,*      1/1    2/2    0/0
chr17  1001  C    G,*      2/2    0/2    1/2
chr17  1001  CGA  C,*      2/2    0/1    1/2
chr17  1001  CGA  C,GGA,*  3/3    0/1    1/2 *HET-ALT
```

We can thus include the joint PL for het-ALTs, while avoiding PL quadratic blowup since no one record has more than three ALTs. Duplication of information between the regular and het-ALT record is a concern, as it invites naive double-counting of copy numbers. That's further exacerbated by potential padding of the alleles in het-ALT records, making the redundancy non-trivial to recognize. Possibly we could segregate the het-ALT record in a separate file?

At least the cause of the second class of sites is more intuitive and predictable compared to the monoallelic sites...",mlin,https://github.com/dnanexus-rnd/GLnexus/issues/210
MDU6SXNzdWU1NjkzMTY5NTk=,How to filter out unknown variants?,CLOSED,2020-02-22T10:46:26Z,2020-02-22T16:58:46Z,2020-02-22T16:58:33Z,"Hello, is there a built-in ability to filter out unkown genotypes?

thank you

EDIT: more precisely, for instance 

`chromosome_6	3581170	chromosome_6_3581170_G_A	G	A	33	.	AF=0.041667;AQ=33;AC=1;AN=2	GT:DP:AD:GQ:PL:RNC	./.:.:.:.:0,0,0:MM	./.:.:.:.:0,0,0:MM	./.:.:.:.:0,0,0:MM	./.:.:.:.:0,0,0:MM	./.:.:.:.:0,0,0:MM	./.:.:.:.:0,0,0:MM	./.:.:.:.:0,0,0:MM	./.:.:.:.:0,0,0:MM	./.:.:.:.:0,0,0:MM	./.:.:.:.:0,0,0:MM	./.:.:.:.:0,0,0:MM	0/1:201:104,97:34:33,0,53:..
`

This looks like the variant only exist in the last individual. However, as others have just the ""missing information"", I would regard this as a false positive. Is there a way to get rid of those false positive or it must be dealt with by the user on a per case basis? (I understand that making it automatic would be a challenge, for example what to do if the variant is genotyped in half of the individuals and is ""unknown"" in the other half, etc ...)",N/A,https://github.com/dnanexus-rnd/GLnexus/issues/211
MDU6SXNzdWU1NzIwMzAyOTI=,GLnexus assigns a non existant SNP,CLOSED,2020-02-27T11:51:27Z,2020-02-29T16:08:07Z,2020-02-29T16:08:07Z,"Hello, I performed Joint calling from DeepVariant output, so far so good. But I noticed a line where one sample is supposed to be 0/1 for a C:T. Eyeballing the bam file, however ... 
![imT](https://user-images.githubusercontent.com/23341393/75442276-689b6100-595f-11ea-9193-440f13a8d7a6.png)
There is simply no T (it's the column just adjacent to the left T). I checked in other samples and in some of them there are a few T where yo would expect for a SNP call but their original gvcf from DeepVariant classifies them as 0/0 (rightly so on my opinion there are very few of them). 

So not only has GLnexus decided that there was a real variant there, but it assigned it to the samples where there is no C:T variation at all.

Do you have any idea of why this happens?",N/A,https://github.com/dnanexus-rnd/GLnexus/issues/212
MDU6SXNzdWU1ODAwNjMwMjI=,Outputting homozygous reference,OPEN,2020-03-12T16:32:48Z,2023-07-07T20:56:16Z,,"Hello,

Is there any way to output the homozygous reference bases in the pVCF? Can I have a pVGCF, with one line per base in my reference genome?  

thanks",N/A,https://github.com/dnanexus-rnd/GLnexus/issues/213
MDU6SXNzdWU1ODIyMDQwMjI=,Docker build failed,OPEN,2020-03-16T11:08:59Z,2020-03-18T09:24:27Z,,"Hello, with the last version from github

```
FAIL: capnp-test
PASS: capnp-evolution-test
PASS: src/capnp/compiler/capnp-test.sh
============================================================================
Testsuite summary for Capn Proto 0.7.0
============================================================================
# TOTAL: 3
# PASS:  2
# SKIP:  0
# XFAIL: 0
# FAIL:  1
# XPASS: 0
# ERROR: 0
============================================================================
See ./test-suite.log
Please report to capnproto@googlegroups.com
============================================================================
Makefile:3474: recipe for target 'test-suite.log' failed
make[6]: *** [test-suite.log] Error 1
Makefile:3580: recipe for target 'check-TESTS' failed
make[5]: *** [check-TESTS] Error 2
Makefile:3804: recipe for target 'check-am' failed
make[4]: *** [check-am] Error 2
make[3]: *** [check] Error 2
Makefile:3807: recipe for target 'check' failed
make[2]: *** [external/src/capnp-stamp/capnp-build] Error 2
CMakeFiles/capnp.dir/build.make:111: recipe for target 'external/src/capnp-stamp/capnp-build' failed
make[1]: *** [CMakeFiles/capnp.dir/all] Error 2
CMakeFiles/Makefile2:515: recipe for target 'CMakeFiles/capnp.dir/all' failed
make: *** [all] Error 2
Makefile:140: recipe for target 'all' failed
The command '/bin/sh -c cmake -DCMAKE_BUILD_TYPE=$build_type . && make -j4' returned a non-zero code: 2

```",N/A,https://github.com/dnanexus-rnd/GLnexus/issues/214
MDU6SXNzdWU1ODc1Nzg2MjI=,Het site 0/1 becoming ./. in the pVCF,CLOSED,2020-03-25T10:02:37Z,2020-03-26T12:28:12Z,2020-03-26T12:28:12Z,"Hello, 

I have a case where at  some position a reference sample has the GT 0/1 

```
Chrom_3	11583331	.	G	T,<*>	35.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:281:134,140,0:0.498221,0:35,0,55,990,990,990
```

And 1/1 in another sample 

```
Chrom_3	11583331	.	G	T,<*>	33.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:20:44:0,44,0:1,0:33,19,0,990,990,990
```

However, in the pVCF 
```
Chrom_3	11583331	Chrom_3_11583331_G_T	G	T	33	.	AF=0.5;AQ=33	GT:DP:AD:GQ:PL:RNC	./.:.:.:.:0,0,0:MM	1/1:44:0,44:16:33,19,0:..
```

The genotype of the first sample has moved from 0/1 to ./.

Is it an intended feature? 

Thank you",N/A,https://github.com/dnanexus-rnd/GLnexus/issues/215
MDU6SXNzdWU1OTAxMDQwMTI=,Using GLNexus to merge GATK gVCFs,OPEN,2020-03-30T08:44:33Z,2021-12-26T12:11:40Z,,"Hi,
I'm trying to use GLnexus v.1.2.6 to merge g.vcf files generated by the GATK HaplotypeCaller, using the gatk configuration pre-set. For my project, I'm merging WGS calls from ~300 individuals sequenced at 30-50X mean coverage. I have a couple of questions about the merging process:
1. What exactly is the difference between gatk and gatk_unfiltered configuration pre-sets and when do you advise to use on or the other?
2. The VCF files produced by GLNexus using gatk preset only contain AF and AQ variant annotations, with AQ equal to QUAL value. Is there a way to output part of the statistics usually contained in the VCF file merged using the standard GATK workflow?
3. Doing QC I've noted that the GLNexus merged VCF and the one produced by GATK genotypeGVCFs are quite different. Specifically, it seems that the GLNexus one contains more variants, but with quite low ts/tv ratio (~1.8) and much more multi-allelic variants and indels. So I suspect that there is more false-positive calls in the GL nexus merged VCF. Any advice on post-merging filters for the GLNexus cohort VCF?

Thanks!",edg1983,https://github.com/dnanexus-rnd/GLnexus/issues/216
MDU6SXNzdWU2MDQzNTA4MTY=,missing recorder from GLnexus result,CLOSED,2020-04-21T23:38:43Z,2020-04-22T13:46:10Z,2020-04-22T13:46:10Z,"Hi,

I came across an issue where an INDEL variant is present in an individual gvcf file (GT = 0/1), but is missing from the GLNexus call. The job finished successfully, and most of the variants are fine. 

I am using an older version of the tool (v1.1.3-0-g74f4279) because I don't have permission to upgrade the tool on our cluster. Also my gvcf files are generated using xAtlas. 

I'll try to upgrade the tool and see whether it can fix the problem. But I'm wondering if you've seen this problem before or know any version of the tool specifically fixed this problem.

Thanks in advance!
Hurley
",hurleyLi,https://github.com/dnanexus-rnd/GLnexus/issues/217
MDU6SXNzdWU2MDUxNzg2MDM=,`GLIBC_2.18' not found,OPEN,2020-04-23T01:44:24Z,2023-10-13T17:03:35Z,,"I got this error when running the executable file:
`/glnexus_cli: /lib64/libc.so.6: version GLIBC_2.18 not found (required by ./glnexus_cli)`

Since I ran it on cluster so the upgrade of glibc looks impossible. Is there other way to solve this problem? Docker was not installed in our cluster, so docker installation is also not available.",szhang0112,https://github.com/dnanexus-rnd/GLnexus/issues/218
MDU6SXNzdWU2MjI3NDk2NzQ=,tech debt: upgrade testOutputVcf.py to python3,CLOSED,2020-05-21T20:06:24Z,2020-05-27T06:52:38Z,2020-05-27T06:52:38Z,,mlin,https://github.com/dnanexus-rnd/GLnexus/issues/219
MDU6SXNzdWU2MjMxNDMyMDg=,Error vcf exists check log,OPEN,2020-05-22T11:27:14Z,2020-05-22T20:06:02Z,,"Hello, I am getting this error

```
[12907] [2020-05-22 13:22:59.879] [GLnexus] [error] ARC_D30.g.vcf.gz Exists: sample is currently being added (default (ARC_D30.g.vcf.gz))
[12907] [2020-05-22 13:23:04.756] [GLnexus] [error] Failed to bulk load into DB: Failure: One or more gVCF inputs failed validation or database loading; check log for details.
Failed to read from standard input: unknown file type

```

I have  no idea of what might be wrong, the vcf file looks all right to me. 
here is the vcf header

```
##fileformat=VCFv4.2
##FILTER=<ID=PASS,Description=""All filters passed"">
##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">
##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">
##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">
##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">
##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">
##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">
##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">
##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">
##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">
##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">
##contig=<ID=Chrom_3,length=20354777>
##contig=<ID=Chrom_1,length=18146847>
##contig=<ID=Chrom_5,length=16930519>
##contig=<ID=Chrom_2,length=16274841>
##contig=<ID=Chrom_4,length=15224634>
##contig=<ID=Chrom_6,length=13893210>
##bcftools_viewVersion=1.10.2-27-g9d66868+htslib-1.10.2-32-g84f0a86
##bcftools_viewCommand=view ARC_D30.g.vcf.gz; Date=Fri May 22 13:26:43 2020
#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	default
```

thank you

PS: here is the log

```
2020/05/22-13:22:50.554608 7f33fc5e8f00 RocksDB version: 6.6.4
2020/05/22-13:22:50.554641 7f33fc5e8f00 Git sha rocksdb_build_git_sha:4d057dcf24b68b33de7a9759ae65ca2b144a3d47
2020/05/22-13:22:50.554643 7f33fc5e8f00 Compile date Mar 19 2020
2020/05/22-13:22:50.554644 7f33fc5e8f00 DB SUMMARY
2020/05/22-13:22:50.554668 7f33fc5e8f00 CURRENT file:  CURRENT
2020/05/22-13:22:50.554669 7f33fc5e8f00 IDENTITY file:  IDENTITY
2020/05/22-13:22:50.554672 7f33fc5e8f00 MANIFEST file:  MANIFEST-000006 size: 452 Bytes
2020/05/22-13:22:50.554674 7f33fc5e8f00 SST files in GLnexus.DB dir, Total Num: 2, files: 000018.sst 000019.sst 
2020/05/22-13:22:50.554675 7f33fc5e8f00 Write Ahead Log file in GLnexus.DB: 000017.log size: 0 ; 
2020/05/22-13:22:50.554676 7f33fc5e8f00                         Options.error_if_exists: 0
2020/05/22-13:22:50.554677 7f33fc5e8f00                       Options.create_if_missing: 0
2020/05/22-13:22:50.554678 7f33fc5e8f00                         Options.paranoid_checks: 1
2020/05/22-13:22:50.554679 7f33fc5e8f00                                     Options.env: 0x5638c74ce580
2020/05/22-13:22:50.554680 7f33fc5e8f00                                Options.info_log: 0x5638c8d7f090
2020/05/22-13:22:50.554680 7f33fc5e8f00                Options.max_file_opening_threads: 16
2020/05/22-13:22:50.554681 7f33fc5e8f00                              Options.statistics: (nil)
2020/05/22-13:22:50.554682 7f33fc5e8f00                               Options.use_fsync: 0
2020/05/22-13:22:50.554683 7f33fc5e8f00                       Options.max_log_file_size: 0
2020/05/22-13:22:50.554684 7f33fc5e8f00                  Options.max_manifest_file_size: 1073741824
2020/05/22-13:22:50.554685 7f33fc5e8f00                   Options.log_file_time_to_roll: 0
2020/05/22-13:22:50.554686 7f33fc5e8f00                       Options.keep_log_file_num: 1000
2020/05/22-13:22:50.554686 7f33fc5e8f00                    Options.recycle_log_file_num: 0
2020/05/22-13:22:50.554687 7f33fc5e8f00                         Options.allow_fallocate: 1
2020/05/22-13:22:50.554688 7f33fc5e8f00                        Options.allow_mmap_reads: 0
2020/05/22-13:22:50.554689 7f33fc5e8f00                       Options.allow_mmap_writes: 0
2020/05/22-13:22:50.554690 7f33fc5e8f00                        Options.use_direct_reads: 0
2020/05/22-13:22:50.554690 7f33fc5e8f00                        Options.use_direct_io_for_flush_and_compaction: 0
2020/05/22-13:22:50.554691 7f33fc5e8f00          Options.create_missing_column_families: 0
2020/05/22-13:22:50.554692 7f33fc5e8f00                              Options.db_log_dir: 
2020/05/22-13:22:50.554693 7f33fc5e8f00                                 Options.wal_dir: GLnexus.DB
2020/05/22-13:22:50.554694 7f33fc5e8f00                Options.table_cache_numshardbits: 6
2020/05/22-13:22:50.554694 7f33fc5e8f00                      Options.max_subcompactions: 8
2020/05/22-13:22:50.554695 7f33fc5e8f00                  Options.max_background_flushes: -1
2020/05/22-13:22:50.554696 7f33fc5e8f00                         Options.WAL_ttl_seconds: 0
2020/05/22-13:22:50.554697 7f33fc5e8f00                       Options.WAL_size_limit_MB: 0
2020/05/22-13:22:50.554698 7f33fc5e8f00                        Options.max_write_batch_group_size_bytes: 1048576
2020/05/22-13:22:50.554698 7f33fc5e8f00             Options.manifest_preallocation_size: 4194304
2020/05/22-13:22:50.554699 7f33fc5e8f00                     Options.is_fd_close_on_exec: 1
2020/05/22-13:22:50.554700 7f33fc5e8f00                   Options.advise_random_on_open: 1
2020/05/22-13:22:50.554701 7f33fc5e8f00                    Options.db_write_buffer_size: 0
2020/05/22-13:22:50.554702 7f33fc5e8f00                    Options.write_buffer_manager: 0x5638c8e080e0
2020/05/22-13:22:50.554703 7f33fc5e8f00         Options.access_hint_on_compaction_start: 2
2020/05/22-13:22:50.554703 7f33fc5e8f00  Options.new_table_reader_for_compaction_inputs: 1
2020/05/22-13:22:50.554704 7f33fc5e8f00           Options.random_access_max_buffer_size: 1048576
2020/05/22-13:22:50.554705 7f33fc5e8f00                      Options.use_adaptive_mutex: 0
2020/05/22-13:22:50.554706 7f33fc5e8f00                            Options.rate_limiter: (nil)
2020/05/22-13:22:50.554715 7f33fc5e8f00     Options.sst_file_manager.rate_bytes_per_sec: 0
2020/05/22-13:22:50.554716 7f33fc5e8f00                       Options.wal_recovery_mode: 2
2020/05/22-13:22:50.554717 7f33fc5e8f00                  Options.enable_thread_tracking: 0
2020/05/22-13:22:50.554717 7f33fc5e8f00                  Options.enable_pipelined_write: 0
2020/05/22-13:22:50.554718 7f33fc5e8f00                  Options.unordered_write: 0
2020/05/22-13:22:50.554719 7f33fc5e8f00         Options.allow_concurrent_memtable_write: 0
2020/05/22-13:22:50.554720 7f33fc5e8f00      Options.enable_write_thread_adaptive_yield: 1
2020/05/22-13:22:50.554721 7f33fc5e8f00             Options.write_thread_max_yield_usec: 100
2020/05/22-13:22:50.554721 7f33fc5e8f00            Options.write_thread_slow_yield_usec: 3
2020/05/22-13:22:50.554722 7f33fc5e8f00                               Options.row_cache: None
2020/05/22-13:22:50.554723 7f33fc5e8f00                              Options.wal_filter: None
2020/05/22-13:22:50.554724 7f33fc5e8f00             Options.avoid_flush_during_recovery: 0
2020/05/22-13:22:50.554725 7f33fc5e8f00             Options.allow_ingest_behind: 0
2020/05/22-13:22:50.554725 7f33fc5e8f00             Options.preserve_deletes: 0
2020/05/22-13:22:50.554726 7f33fc5e8f00             Options.two_write_queues: 0
2020/05/22-13:22:50.554727 7f33fc5e8f00             Options.manual_wal_flush: 0
2020/05/22-13:22:50.554728 7f33fc5e8f00             Options.atomic_flush: 0
2020/05/22-13:22:50.554728 7f33fc5e8f00             Options.avoid_unnecessary_blocking_io: 0
2020/05/22-13:22:50.554729 7f33fc5e8f00                 Options.persist_stats_to_disk: 0
2020/05/22-13:22:50.554730 7f33fc5e8f00                 Options.write_dbid_to_manifest: 0
2020/05/22-13:22:50.554731 7f33fc5e8f00                 Options.log_readahead_size: 0
2020/05/22-13:22:50.554731 7f33fc5e8f00             Options.max_background_jobs: 8
2020/05/22-13:22:50.554732 7f33fc5e8f00             Options.max_background_compactions: -1
2020/05/22-13:22:50.554733 7f33fc5e8f00             Options.avoid_flush_during_shutdown: 0
2020/05/22-13:22:50.554734 7f33fc5e8f00           Options.writable_file_max_buffer_size: 1048576
2020/05/22-13:22:50.554735 7f33fc5e8f00             Options.delayed_write_rate : 10737418240
2020/05/22-13:22:50.554735 7f33fc5e8f00             Options.max_total_wal_size: 0
2020/05/22-13:22:50.554736 7f33fc5e8f00             Options.delete_obsolete_files_period_micros: 900000000
2020/05/22-13:22:50.554737 7f33fc5e8f00                   Options.stats_dump_period_sec: 600
2020/05/22-13:22:50.554738 7f33fc5e8f00                 Options.stats_persist_period_sec: 600
2020/05/22-13:22:50.554739 7f33fc5e8f00                 Options.stats_history_buffer_size: 1048576
2020/05/22-13:22:50.554740 7f33fc5e8f00                          Options.max_open_files: -1
2020/05/22-13:22:50.554740 7f33fc5e8f00                          Options.bytes_per_sync: 0
2020/05/22-13:22:50.554741 7f33fc5e8f00                      Options.wal_bytes_per_sync: 0
2020/05/22-13:22:50.554742 7f33fc5e8f00                   Options.strict_bytes_per_sync: 0
2020/05/22-13:22:50.554743 7f33fc5e8f00       Options.compaction_readahead_size: 16777216
2020/05/22-13:22:50.554743 7f33fc5e8f00 Compression algorithms supported:
2020/05/22-13:22:50.554745 7f33fc5e8f00 	kZSTDNotFinalCompression supported: 1
2020/05/22-13:22:50.554746 7f33fc5e8f00 	kZSTD supported: 1
2020/05/22-13:22:50.554747 7f33fc5e8f00 	kXpressCompression supported: 0
2020/05/22-13:22:50.554748 7f33fc5e8f00 	kLZ4HCCompression supported: 0
2020/05/22-13:22:50.554749 7f33fc5e8f00 	kLZ4Compression supported: 0
2020/05/22-13:22:50.554750 7f33fc5e8f00 	kBZip2Compression supported: 1
2020/05/22-13:22:50.554751 7f33fc5e8f00 	kZlibCompression supported: 1
2020/05/22-13:22:50.554751 7f33fc5e8f00 	kSnappyCompression supported: 1
2020/05/22-13:22:50.554753 7f33fc5e8f00 Fast CRC32 supported: Supported on x86
2020/05/22-13:22:50.554879 7f33fc5e8f00 [rsion_set.cc:4377] Recovering from manifest file: GLnexus.DB/MANIFEST-000006
2020/05/22-13:22:50.554944 7f33fc5e8f00 [lumn_family.cc:550] --------------- Options for column family [default]:
2020/05/22-13:22:50.554946 7f33fc5e8f00               Options.comparator: leveldb.BytewiseComparator
2020/05/22-13:22:50.554947 7f33fc5e8f00           Options.merge_operator: None
2020/05/22-13:22:50.554948 7f33fc5e8f00        Options.compaction_filter: None
2020/05/22-13:22:50.554949 7f33fc5e8f00        Options.compaction_filter_factory: None
2020/05/22-13:22:50.554949 7f33fc5e8f00         Options.memtable_factory: VectorRepFactory
2020/05/22-13:22:50.554950 7f33fc5e8f00            Options.table_factory: BlockBasedTable
2020/05/22-13:22:50.554968 7f33fc5e8f00            table_factory options:   flush_block_policy_factory: FlushBlockBySizePolicyFactory (0x5638c8db05a0)
  cache_index_and_filter_blocks: 1
  cache_index_and_filter_blocks_with_high_priority: 1
  pin_l0_filter_and_index_blocks_in_cache: 0
  pin_top_level_index_and_filter: 1
  index_type: 0
  data_block_index_type: 0
  index_shortening: 1
  data_block_hash_table_util_ratio: 0.750000
  hash_index_allow_collision: 1
  checksum: 1
  no_block_cache: 0
  block_cache: 0x5638c8dea9d0
  block_cache_name: LRUCache
  block_cache_options:
    capacity : 13473801830
    num_shard_bits : 6
    strict_capacity_limit : 0
    memory_allocator : None
    high_pri_pool_ratio: 0.500
  block_cache_compressed: (nil)
  persistent_cache: (nil)
  block_size: 1048576
  block_size_deviation: 10
  block_restart_interval: 16
  index_block_restart_interval: 1
  metadata_block_size: 4096
  partition_filters: 0
  use_delta_encoding: 1
  filter_policy: nullptr
  whole_key_filtering: 1
  verify_compression: 0
  read_amp_bytes_per_bit: 0
  format_version: 4
  enable_index_compression: 1
  block_align: 0
2020/05/22-13:22:50.554969 7f33fc5e8f00        Options.write_buffer_size: 8982534553
2020/05/22-13:22:50.554970 7f33fc5e8f00  Options.max_write_buffer_number: 4
2020/05/22-13:22:50.554971 7f33fc5e8f00          Options.compression: ZSTD
2020/05/22-13:22:50.554972 7f33fc5e8f00                  Options.bottommost_compression: Disabled
2020/05/22-13:22:50.554973 7f33fc5e8f00       Options.prefix_extractor: nullptr
2020/05/22-13:22:50.554974 7f33fc5e8f00   Options.memtable_insert_with_hint_prefix_extractor: nullptr
2020/05/22-13:22:50.554975 7f33fc5e8f00             Options.num_levels: 4
2020/05/22-13:22:50.554976 7f33fc5e8f00        Options.min_write_buffer_number_to_merge: 1
2020/05/22-13:22:50.554977 7f33fc5e8f00     Options.max_write_buffer_number_to_maintain: 0
2020/05/22-13:22:50.554977 7f33fc5e8f00     Options.max_write_buffer_size_to_maintain: 0
2020/05/22-13:22:50.554978 7f33fc5e8f00            Options.bottommost_compression_opts.window_bits: -14
2020/05/22-13:22:50.554979 7f33fc5e8f00                  Options.bottommost_compression_opts.level: 32767
2020/05/22-13:22:50.554980 7f33fc5e8f00               Options.bottommost_compression_opts.strategy: 0
2020/05/22-13:22:50.554981 7f33fc5e8f00         Options.bottommost_compression_opts.max_dict_bytes: 0
2020/05/22-13:22:50.554982 7f33fc5e8f00         Options.bottommost_compression_opts.zstd_max_train_bytes: 0
2020/05/22-13:22:50.554982 7f33fc5e8f00                  Options.bottommost_compression_opts.enabled: false
2020/05/22-13:22:50.554983 7f33fc5e8f00            Options.compression_opts.window_bits: -14
2020/05/22-13:22:50.554984 7f33fc5e8f00                  Options.compression_opts.level: 2
2020/05/22-13:22:50.554985 7f33fc5e8f00               Options.compression_opts.strategy: 0
2020/05/22-13:22:50.554986 7f33fc5e8f00         Options.compression_opts.max_dict_bytes: 0
2020/05/22-13:22:50.554986 7f33fc5e8f00         Options.compression_opts.zstd_max_train_bytes: 0
2020/05/22-13:22:50.554987 7f33fc5e8f00                  Options.compression_opts.enabled: false
2020/05/22-13:22:50.554988 7f33fc5e8f00      Options.level0_file_num_compaction_trigger: 4
2020/05/22-13:22:50.554989 7f33fc5e8f00          Options.level0_slowdown_writes_trigger: 1073741824
2020/05/22-13:22:50.554990 7f33fc5e8f00              Options.level0_stop_writes_trigger: 1073741824
2020/05/22-13:22:50.554997 7f33fc5e8f00                   Options.target_file_size_base: 4294967296
2020/05/22-13:22:50.554998 7f33fc5e8f00             Options.target_file_size_multiplier: 1
2020/05/22-13:22:50.554999 7f33fc5e8f00                Options.max_bytes_for_level_base: 268435456
2020/05/22-13:22:50.555000 7f33fc5e8f00 Options.level_compaction_dynamic_level_bytes: 0
2020/05/22-13:22:50.555000 7f33fc5e8f00          Options.max_bytes_for_level_multiplier: 10.000000
2020/05/22-13:22:50.555002 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[0]: 1
2020/05/22-13:22:50.555003 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[1]: 1
2020/05/22-13:22:50.555004 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[2]: 1
2020/05/22-13:22:50.555005 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[3]: 1
2020/05/22-13:22:50.555006 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[4]: 1
2020/05/22-13:22:50.555007 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[5]: 1
2020/05/22-13:22:50.555007 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[6]: 1
2020/05/22-13:22:50.555008 7f33fc5e8f00       Options.max_sequential_skip_in_iterations: 8
2020/05/22-13:22:50.555009 7f33fc5e8f00                    Options.max_compaction_bytes: 107374182400
2020/05/22-13:22:50.555010 7f33fc5e8f00                        Options.arena_block_size: 1122820096
2020/05/22-13:22:50.555011 7f33fc5e8f00   Options.soft_pending_compaction_bytes_limit: 0
2020/05/22-13:22:50.555012 7f33fc5e8f00   Options.hard_pending_compaction_bytes_limit: 0
2020/05/22-13:22:50.555012 7f33fc5e8f00       Options.rate_limit_delay_max_milliseconds: 100
2020/05/22-13:22:50.555013 7f33fc5e8f00                Options.disable_auto_compactions: 0
2020/05/22-13:22:50.555014 7f33fc5e8f00                        Options.compaction_style: kCompactionStyleUniversal
2020/05/22-13:22:50.555015 7f33fc5e8f00                          Options.compaction_pri: kMinOverlappingRatio
2020/05/22-13:22:50.555016 7f33fc5e8f00 Options.compaction_options_universal.size_ratio: 10
2020/05/22-13:22:50.555017 7f33fc5e8f00 Options.compaction_options_universal.min_merge_width: 2
2020/05/22-13:22:50.555018 7f33fc5e8f00 Options.compaction_options_universal.max_merge_width: 6
2020/05/22-13:22:50.555019 7f33fc5e8f00 Options.compaction_options_universal.max_size_amplification_percent: 1073741824
2020/05/22-13:22:50.555020 7f33fc5e8f00 Options.compaction_options_universal.compression_size_percent: -1
2020/05/22-13:22:50.555021 7f33fc5e8f00 Options.compaction_options_universal.stop_style: kCompactionStopStyleTotalSize
2020/05/22-13:22:50.555022 7f33fc5e8f00 Options.compaction_options_fifo.max_table_files_size: 1073741824
2020/05/22-13:22:50.555022 7f33fc5e8f00 Options.compaction_options_fifo.allow_compaction: 0
2020/05/22-13:22:50.555023 7f33fc5e8f00                   Options.table_properties_collectors: 
2020/05/22-13:22:50.555024 7f33fc5e8f00                   Options.inplace_update_support: 0
2020/05/22-13:22:50.555025 7f33fc5e8f00                 Options.inplace_update_num_locks: 10000
2020/05/22-13:22:50.555026 7f33fc5e8f00               Options.memtable_prefix_bloom_size_ratio: 0.000000
2020/05/22-13:22:50.555027 7f33fc5e8f00               Options.memtable_whole_key_filtering: 0
2020/05/22-13:22:50.555028 7f33fc5e8f00   Options.memtable_huge_page_size: 0
2020/05/22-13:22:50.555029 7f33fc5e8f00                           Options.bloom_locality: 0
2020/05/22-13:22:50.555029 7f33fc5e8f00                    Options.max_successive_merges: 0
2020/05/22-13:22:50.555030 7f33fc5e8f00                Options.optimize_filters_for_hits: 0
2020/05/22-13:22:50.555031 7f33fc5e8f00                Options.paranoid_file_checks: 0
2020/05/22-13:22:50.555032 7f33fc5e8f00                Options.force_consistency_checks: 0
2020/05/22-13:22:50.555033 7f33fc5e8f00                Options.report_bg_io_stats: 0
2020/05/22-13:22:50.555033 7f33fc5e8f00                               Options.ttl: 2592000
2020/05/22-13:22:50.555034 7f33fc5e8f00          Options.periodic_compaction_seconds: 2592000
2020/05/22-13:22:50.555064 7f33fc5e8f00 [lumn_family.cc:550] --------------- Options for column family [config]:
2020/05/22-13:22:50.555065 7f33fc5e8f00               Options.comparator: leveldb.BytewiseComparator
2020/05/22-13:22:50.555066 7f33fc5e8f00           Options.merge_operator: None
2020/05/22-13:22:50.555067 7f33fc5e8f00        Options.compaction_filter: None
2020/05/22-13:22:50.555068 7f33fc5e8f00        Options.compaction_filter_factory: None
2020/05/22-13:22:50.555069 7f33fc5e8f00         Options.memtable_factory: VectorRepFactory
2020/05/22-13:22:50.555069 7f33fc5e8f00            Options.table_factory: BlockBasedTable
2020/05/22-13:22:50.555082 7f33fc5e8f00            table_factory options:   flush_block_policy_factory: FlushBlockBySizePolicyFactory (0x5638c8d81d40)
  cache_index_and_filter_blocks: 1
  cache_index_and_filter_blocks_with_high_priority: 1
  pin_l0_filter_and_index_blocks_in_cache: 0
  pin_top_level_index_and_filter: 1
  index_type: 0
  data_block_index_type: 0
  index_shortening: 1
  data_block_hash_table_util_ratio: 0.750000
  hash_index_allow_collision: 1
  checksum: 1
  no_block_cache: 0
  block_cache: 0x5638c8dea9d0
  block_cache_name: LRUCache
  block_cache_options:
    capacity : 13473801830
    num_shard_bits : 6
    strict_capacity_limit : 0
    memory_allocator : None
    high_pri_pool_ratio: 0.500
  block_cache_compressed: (nil)
  persistent_cache: (nil)
  block_size: 1048576
  block_size_deviation: 10
  block_restart_interval: 16
  index_block_restart_interval: 1
  metadata_block_size: 4096
  partition_filters: 0
  use_delta_encoding: 1
  filter_policy: nullptr
  whole_key_filtering: 1
  verify_compression: 0
  read_amp_bytes_per_bit: 0
  format_version: 4
  enable_index_compression: 1
  block_align: 0
2020/05/22-13:22:50.555083 7f33fc5e8f00        Options.write_buffer_size: 8982534553
2020/05/22-13:22:50.555084 7f33fc5e8f00  Options.max_write_buffer_number: 4
2020/05/22-13:22:50.555085 7f33fc5e8f00          Options.compression: ZSTD
2020/05/22-13:22:50.555085 7f33fc5e8f00                  Options.bottommost_compression: Disabled
2020/05/22-13:22:50.555086 7f33fc5e8f00       Options.prefix_extractor: nullptr
2020/05/22-13:22:50.555087 7f33fc5e8f00   Options.memtable_insert_with_hint_prefix_extractor: nullptr
2020/05/22-13:22:50.555088 7f33fc5e8f00             Options.num_levels: 4
2020/05/22-13:22:50.555088 7f33fc5e8f00        Options.min_write_buffer_number_to_merge: 1
2020/05/22-13:22:50.555089 7f33fc5e8f00     Options.max_write_buffer_number_to_maintain: 0
2020/05/22-13:22:50.555090 7f33fc5e8f00     Options.max_write_buffer_size_to_maintain: 0
2020/05/22-13:22:50.555091 7f33fc5e8f00            Options.bottommost_compression_opts.window_bits: -14
2020/05/22-13:22:50.555092 7f33fc5e8f00                  Options.bottommost_compression_opts.level: 32767
2020/05/22-13:22:50.555092 7f33fc5e8f00               Options.bottommost_compression_opts.strategy: 0
2020/05/22-13:22:50.555093 7f33fc5e8f00         Options.bottommost_compression_opts.max_dict_bytes: 0
2020/05/22-13:22:50.555094 7f33fc5e8f00         Options.bottommost_compression_opts.zstd_max_train_bytes: 0
2020/05/22-13:22:50.555095 7f33fc5e8f00                  Options.bottommost_compression_opts.enabled: false
2020/05/22-13:22:50.555096 7f33fc5e8f00            Options.compression_opts.window_bits: -14
2020/05/22-13:22:50.555096 7f33fc5e8f00                  Options.compression_opts.level: 2
2020/05/22-13:22:50.555097 7f33fc5e8f00               Options.compression_opts.strategy: 0
2020/05/22-13:22:50.555098 7f33fc5e8f00         Options.compression_opts.max_dict_bytes: 0
2020/05/22-13:22:50.555099 7f33fc5e8f00         Options.compression_opts.zstd_max_train_bytes: 0
2020/05/22-13:22:50.555100 7f33fc5e8f00                  Options.compression_opts.enabled: false
2020/05/22-13:22:50.555100 7f33fc5e8f00      Options.level0_file_num_compaction_trigger: 4
2020/05/22-13:22:50.555101 7f33fc5e8f00          Options.level0_slowdown_writes_trigger: 1073741824
2020/05/22-13:22:50.555102 7f33fc5e8f00              Options.level0_stop_writes_trigger: 1073741824
2020/05/22-13:22:50.555109 7f33fc5e8f00                   Options.target_file_size_base: 4294967296
2020/05/22-13:22:50.555110 7f33fc5e8f00             Options.target_file_size_multiplier: 1
2020/05/22-13:22:50.555110 7f33fc5e8f00                Options.max_bytes_for_level_base: 268435456
2020/05/22-13:22:50.555111 7f33fc5e8f00 Options.level_compaction_dynamic_level_bytes: 0
2020/05/22-13:22:50.555112 7f33fc5e8f00          Options.max_bytes_for_level_multiplier: 10.000000
2020/05/22-13:22:50.555113 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[0]: 1
2020/05/22-13:22:50.555114 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[1]: 1
2020/05/22-13:22:50.555115 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[2]: 1
2020/05/22-13:22:50.555116 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[3]: 1
2020/05/22-13:22:50.555117 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[4]: 1
2020/05/22-13:22:50.555117 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[5]: 1
2020/05/22-13:22:50.555118 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[6]: 1
2020/05/22-13:22:50.555119 7f33fc5e8f00       Options.max_sequential_skip_in_iterations: 8
2020/05/22-13:22:50.555120 7f33fc5e8f00                    Options.max_compaction_bytes: 107374182400
2020/05/22-13:22:50.555121 7f33fc5e8f00                        Options.arena_block_size: 1122820096
2020/05/22-13:22:50.555121 7f33fc5e8f00   Options.soft_pending_compaction_bytes_limit: 0
2020/05/22-13:22:50.555122 7f33fc5e8f00   Options.hard_pending_compaction_bytes_limit: 0
2020/05/22-13:22:50.555123 7f33fc5e8f00       Options.rate_limit_delay_max_milliseconds: 100
2020/05/22-13:22:50.555124 7f33fc5e8f00                Options.disable_auto_compactions: 0
2020/05/22-13:22:50.555125 7f33fc5e8f00                        Options.compaction_style: kCompactionStyleUniversal
2020/05/22-13:22:50.555126 7f33fc5e8f00                          Options.compaction_pri: kMinOverlappingRatio
2020/05/22-13:22:50.555127 7f33fc5e8f00 Options.compaction_options_universal.size_ratio: 10
2020/05/22-13:22:50.555127 7f33fc5e8f00 Options.compaction_options_universal.min_merge_width: 2
2020/05/22-13:22:50.555128 7f33fc5e8f00 Options.compaction_options_universal.max_merge_width: 6
2020/05/22-13:22:50.555129 7f33fc5e8f00 Options.compaction_options_universal.max_size_amplification_percent: 1073741824
2020/05/22-13:22:50.555130 7f33fc5e8f00 Options.compaction_options_universal.compression_size_percent: -1
2020/05/22-13:22:50.555131 7f33fc5e8f00 Options.compaction_options_universal.stop_style: kCompactionStopStyleTotalSize
2020/05/22-13:22:50.555132 7f33fc5e8f00 Options.compaction_options_fifo.max_table_files_size: 1073741824
2020/05/22-13:22:50.555132 7f33fc5e8f00 Options.compaction_options_fifo.allow_compaction: 0
2020/05/22-13:22:50.555133 7f33fc5e8f00                   Options.table_properties_collectors: 
2020/05/22-13:22:50.555134 7f33fc5e8f00                   Options.inplace_update_support: 0
2020/05/22-13:22:50.555135 7f33fc5e8f00                 Options.inplace_update_num_locks: 10000
2020/05/22-13:22:50.555136 7f33fc5e8f00               Options.memtable_prefix_bloom_size_ratio: 0.000000
2020/05/22-13:22:50.555137 7f33fc5e8f00               Options.memtable_whole_key_filtering: 0
2020/05/22-13:22:50.555137 7f33fc5e8f00   Options.memtable_huge_page_size: 0
2020/05/22-13:22:50.555138 7f33fc5e8f00                           Options.bloom_locality: 0
2020/05/22-13:22:50.555139 7f33fc5e8f00                    Options.max_successive_merges: 0
2020/05/22-13:22:50.555140 7f33fc5e8f00                Options.optimize_filters_for_hits: 0
2020/05/22-13:22:50.555141 7f33fc5e8f00                Options.paranoid_file_checks: 0
2020/05/22-13:22:50.555141 7f33fc5e8f00                Options.force_consistency_checks: 0
2020/05/22-13:22:50.555142 7f33fc5e8f00                Options.report_bg_io_stats: 0
2020/05/22-13:22:50.555143 7f33fc5e8f00                               Options.ttl: 2592000
2020/05/22-13:22:50.555144 7f33fc5e8f00          Options.periodic_compaction_seconds: 2592000
2020/05/22-13:22:50.555161 7f33fc5e8f00 [lumn_family.cc:550] --------------- Options for column family [sampleset]:
2020/05/22-13:22:50.555163 7f33fc5e8f00               Options.comparator: leveldb.BytewiseComparator
2020/05/22-13:22:50.555164 7f33fc5e8f00           Options.merge_operator: None
2020/05/22-13:22:50.555164 7f33fc5e8f00        Options.compaction_filter: None
2020/05/22-13:22:50.555165 7f33fc5e8f00        Options.compaction_filter_factory: None
2020/05/22-13:22:50.555166 7f33fc5e8f00         Options.memtable_factory: VectorRepFactory
2020/05/22-13:22:50.555167 7f33fc5e8f00            Options.table_factory: BlockBasedTable
2020/05/22-13:22:50.555177 7f33fc5e8f00            table_factory options:   flush_block_policy_factory: FlushBlockBySizePolicyFactory (0x5638c8d7f3e0)
  cache_index_and_filter_blocks: 1
  cache_index_and_filter_blocks_with_high_priority: 1
  pin_l0_filter_and_index_blocks_in_cache: 0
  pin_top_level_index_and_filter: 1
  index_type: 0
  data_block_index_type: 0
  index_shortening: 1
  data_block_hash_table_util_ratio: 0.750000
  hash_index_allow_collision: 1
  checksum: 1
  no_block_cache: 0
  block_cache: 0x5638c8dea9d0
  block_cache_name: LRUCache
  block_cache_options:
    capacity : 13473801830
    num_shard_bits : 6
    strict_capacity_limit : 0
    memory_allocator : None
    high_pri_pool_ratio: 0.500
  block_cache_compressed: (nil)
  persistent_cache: (nil)
  block_size: 1048576
  block_size_deviation: 10
  block_restart_interval: 16
  index_block_restart_interval: 1
  metadata_block_size: 4096
  partition_filters: 0
  use_delta_encoding: 1
  filter_policy: nullptr
  whole_key_filtering: 1
  verify_compression: 0
  read_amp_bytes_per_bit: 0
  format_version: 4
  enable_index_compression: 1
  block_align: 0
2020/05/22-13:22:50.555178 7f33fc5e8f00        Options.write_buffer_size: 8982534553
2020/05/22-13:22:50.555179 7f33fc5e8f00  Options.max_write_buffer_number: 4
2020/05/22-13:22:50.555180 7f33fc5e8f00          Options.compression: ZSTD
2020/05/22-13:22:50.555181 7f33fc5e8f00                  Options.bottommost_compression: Disabled
2020/05/22-13:22:50.555182 7f33fc5e8f00       Options.prefix_extractor: nullptr
2020/05/22-13:22:50.555183 7f33fc5e8f00   Options.memtable_insert_with_hint_prefix_extractor: nullptr
2020/05/22-13:22:50.555183 7f33fc5e8f00             Options.num_levels: 4
2020/05/22-13:22:50.555184 7f33fc5e8f00        Options.min_write_buffer_number_to_merge: 1
2020/05/22-13:22:50.555185 7f33fc5e8f00     Options.max_write_buffer_number_to_maintain: 0
2020/05/22-13:22:50.555186 7f33fc5e8f00     Options.max_write_buffer_size_to_maintain: 0
2020/05/22-13:22:50.555186 7f33fc5e8f00            Options.bottommost_compression_opts.window_bits: -14
2020/05/22-13:22:50.555187 7f33fc5e8f00                  Options.bottommost_compression_opts.level: 32767
2020/05/22-13:22:50.555188 7f33fc5e8f00               Options.bottommost_compression_opts.strategy: 0
2020/05/22-13:22:50.555189 7f33fc5e8f00         Options.bottommost_compression_opts.max_dict_bytes: 0
2020/05/22-13:22:50.555190 7f33fc5e8f00         Options.bottommost_compression_opts.zstd_max_train_bytes: 0
2020/05/22-13:22:50.555190 7f33fc5e8f00                  Options.bottommost_compression_opts.enabled: false
2020/05/22-13:22:50.555191 7f33fc5e8f00            Options.compression_opts.window_bits: -14
2020/05/22-13:22:50.555192 7f33fc5e8f00                  Options.compression_opts.level: 2
2020/05/22-13:22:50.555193 7f33fc5e8f00               Options.compression_opts.strategy: 0
2020/05/22-13:22:50.555193 7f33fc5e8f00         Options.compression_opts.max_dict_bytes: 0
2020/05/22-13:22:50.555194 7f33fc5e8f00         Options.compression_opts.zstd_max_train_bytes: 0
2020/05/22-13:22:50.555195 7f33fc5e8f00                  Options.compression_opts.enabled: false
2020/05/22-13:22:50.555196 7f33fc5e8f00      Options.level0_file_num_compaction_trigger: 4
2020/05/22-13:22:50.555197 7f33fc5e8f00          Options.level0_slowdown_writes_trigger: 1073741824
2020/05/22-13:22:50.555204 7f33fc5e8f00              Options.level0_stop_writes_trigger: 1073741824
2020/05/22-13:22:50.555205 7f33fc5e8f00                   Options.target_file_size_base: 4294967296
2020/05/22-13:22:50.555205 7f33fc5e8f00             Options.target_file_size_multiplier: 1
2020/05/22-13:22:50.555206 7f33fc5e8f00                Options.max_bytes_for_level_base: 268435456
2020/05/22-13:22:50.555207 7f33fc5e8f00 Options.level_compaction_dynamic_level_bytes: 0
2020/05/22-13:22:50.555208 7f33fc5e8f00          Options.max_bytes_for_level_multiplier: 10.000000
2020/05/22-13:22:50.555209 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[0]: 1
2020/05/22-13:22:50.555210 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[1]: 1
2020/05/22-13:22:50.555211 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[2]: 1
2020/05/22-13:22:50.555212 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[3]: 1
2020/05/22-13:22:50.555212 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[4]: 1
2020/05/22-13:22:50.555213 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[5]: 1
2020/05/22-13:22:50.555214 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[6]: 1
2020/05/22-13:22:50.555215 7f33fc5e8f00       Options.max_sequential_skip_in_iterations: 8
2020/05/22-13:22:50.555216 7f33fc5e8f00                    Options.max_compaction_bytes: 107374182400
2020/05/22-13:22:50.555216 7f33fc5e8f00                        Options.arena_block_size: 1122820096
2020/05/22-13:22:50.555217 7f33fc5e8f00   Options.soft_pending_compaction_bytes_limit: 0
2020/05/22-13:22:50.555218 7f33fc5e8f00   Options.hard_pending_compaction_bytes_limit: 0
2020/05/22-13:22:50.555219 7f33fc5e8f00       Options.rate_limit_delay_max_milliseconds: 100
2020/05/22-13:22:50.555219 7f33fc5e8f00                Options.disable_auto_compactions: 0
2020/05/22-13:22:50.555221 7f33fc5e8f00                        Options.compaction_style: kCompactionStyleUniversal
2020/05/22-13:22:50.555221 7f33fc5e8f00                          Options.compaction_pri: kMinOverlappingRatio
2020/05/22-13:22:50.555222 7f33fc5e8f00 Options.compaction_options_universal.size_ratio: 10
2020/05/22-13:22:50.555223 7f33fc5e8f00 Options.compaction_options_universal.min_merge_width: 2
2020/05/22-13:22:50.555224 7f33fc5e8f00 Options.compaction_options_universal.max_merge_width: 6
2020/05/22-13:22:50.555225 7f33fc5e8f00 Options.compaction_options_universal.max_size_amplification_percent: 1073741824
2020/05/22-13:22:50.555225 7f33fc5e8f00 Options.compaction_options_universal.compression_size_percent: -1
2020/05/22-13:22:50.555226 7f33fc5e8f00 Options.compaction_options_universal.stop_style: kCompactionStopStyleTotalSize
2020/05/22-13:22:50.555227 7f33fc5e8f00 Options.compaction_options_fifo.max_table_files_size: 1073741824
2020/05/22-13:22:50.555228 7f33fc5e8f00 Options.compaction_options_fifo.allow_compaction: 0
2020/05/22-13:22:50.555229 7f33fc5e8f00                   Options.table_properties_collectors: 
2020/05/22-13:22:50.555229 7f33fc5e8f00                   Options.inplace_update_support: 0
2020/05/22-13:22:50.555230 7f33fc5e8f00                 Options.inplace_update_num_locks: 10000
2020/05/22-13:22:50.555231 7f33fc5e8f00               Options.memtable_prefix_bloom_size_ratio: 0.000000
2020/05/22-13:22:50.555232 7f33fc5e8f00               Options.memtable_whole_key_filtering: 0
2020/05/22-13:22:50.555233 7f33fc5e8f00   Options.memtable_huge_page_size: 0
2020/05/22-13:22:50.555234 7f33fc5e8f00                           Options.bloom_locality: 0
2020/05/22-13:22:50.555234 7f33fc5e8f00                    Options.max_successive_merges: 0
2020/05/22-13:22:50.555235 7f33fc5e8f00                Options.optimize_filters_for_hits: 0
2020/05/22-13:22:50.555236 7f33fc5e8f00                Options.paranoid_file_checks: 0
2020/05/22-13:22:50.555237 7f33fc5e8f00                Options.force_consistency_checks: 0
2020/05/22-13:22:50.555237 7f33fc5e8f00                Options.report_bg_io_stats: 0
2020/05/22-13:22:50.555238 7f33fc5e8f00                               Options.ttl: 2592000
2020/05/22-13:22:50.555244 7f33fc5e8f00          Options.periodic_compaction_seconds: 2592000
2020/05/22-13:22:50.555257 7f33fc5e8f00 [lumn_family.cc:550] --------------- Options for column family [sample_dataset]:
2020/05/22-13:22:50.555258 7f33fc5e8f00               Options.comparator: leveldb.BytewiseComparator
2020/05/22-13:22:50.555259 7f33fc5e8f00           Options.merge_operator: None
2020/05/22-13:22:50.555260 7f33fc5e8f00        Options.compaction_filter: None
2020/05/22-13:22:50.555261 7f33fc5e8f00        Options.compaction_filter_factory: None
2020/05/22-13:22:50.555261 7f33fc5e8f00         Options.memtable_factory: VectorRepFactory
2020/05/22-13:22:50.555262 7f33fc5e8f00            Options.table_factory: BlockBasedTable
2020/05/22-13:22:50.555272 7f33fc5e8f00            table_factory options:   flush_block_policy_factory: FlushBlockBySizePolicyFactory (0x5638c8dd6e30)
  cache_index_and_filter_blocks: 1
  cache_index_and_filter_blocks_with_high_priority: 1
  pin_l0_filter_and_index_blocks_in_cache: 0
  pin_top_level_index_and_filter: 1
  index_type: 0
  data_block_index_type: 0
  index_shortening: 1
  data_block_hash_table_util_ratio: 0.750000
  hash_index_allow_collision: 1
  checksum: 1
  no_block_cache: 0
  block_cache: 0x5638c8dea9d0
  block_cache_name: LRUCache
  block_cache_options:
    capacity : 13473801830
    num_shard_bits : 6
    strict_capacity_limit : 0
    memory_allocator : None
    high_pri_pool_ratio: 0.500
  block_cache_compressed: (nil)
  persistent_cache: (nil)
  block_size: 1048576
  block_size_deviation: 10
  block_restart_interval: 16
  index_block_restart_interval: 1
  metadata_block_size: 4096
  partition_filters: 0
  use_delta_encoding: 1
  filter_policy: nullptr
  whole_key_filtering: 1
  verify_compression: 0
  read_amp_bytes_per_bit: 0
  format_version: 4
  enable_index_compression: 1
  block_align: 0
2020/05/22-13:22:50.555273 7f33fc5e8f00        Options.write_buffer_size: 8982534553
2020/05/22-13:22:50.555274 7f33fc5e8f00  Options.max_write_buffer_number: 4
2020/05/22-13:22:50.555275 7f33fc5e8f00          Options.compression: ZSTD
2020/05/22-13:22:50.555276 7f33fc5e8f00                  Options.bottommost_compression: Disabled
2020/05/22-13:22:50.555276 7f33fc5e8f00       Options.prefix_extractor: nullptr
2020/05/22-13:22:50.555277 7f33fc5e8f00   Options.memtable_insert_with_hint_prefix_extractor: nullptr
2020/05/22-13:22:50.555278 7f33fc5e8f00             Options.num_levels: 4
2020/05/22-13:22:50.555279 7f33fc5e8f00        Options.min_write_buffer_number_to_merge: 1
2020/05/22-13:22:50.555279 7f33fc5e8f00     Options.max_write_buffer_number_to_maintain: 0
2020/05/22-13:22:50.555280 7f33fc5e8f00     Options.max_write_buffer_size_to_maintain: 0
2020/05/22-13:22:50.555281 7f33fc5e8f00            Options.bottommost_compression_opts.window_bits: -14
2020/05/22-13:22:50.555282 7f33fc5e8f00                  Options.bottommost_compression_opts.level: 32767
2020/05/22-13:22:50.555283 7f33fc5e8f00               Options.bottommost_compression_opts.strategy: 0
2020/05/22-13:22:50.555283 7f33fc5e8f00         Options.bottommost_compression_opts.max_dict_bytes: 0
2020/05/22-13:22:50.555284 7f33fc5e8f00         Options.bottommost_compression_opts.zstd_max_train_bytes: 0
2020/05/22-13:22:50.555285 7f33fc5e8f00                  Options.bottommost_compression_opts.enabled: false
2020/05/22-13:22:50.555286 7f33fc5e8f00            Options.compression_opts.window_bits: -14
2020/05/22-13:22:50.555287 7f33fc5e8f00                  Options.compression_opts.level: 2
2020/05/22-13:22:50.555287 7f33fc5e8f00               Options.compression_opts.strategy: 0
2020/05/22-13:22:50.555288 7f33fc5e8f00         Options.compression_opts.max_dict_bytes: 0
2020/05/22-13:22:50.555289 7f33fc5e8f00         Options.compression_opts.zstd_max_train_bytes: 0
2020/05/22-13:22:50.555290 7f33fc5e8f00                  Options.compression_opts.enabled: false
2020/05/22-13:22:50.555290 7f33fc5e8f00      Options.level0_file_num_compaction_trigger: 4
2020/05/22-13:22:50.555291 7f33fc5e8f00          Options.level0_slowdown_writes_trigger: 1073741824
2020/05/22-13:22:50.555298 7f33fc5e8f00              Options.level0_stop_writes_trigger: 1073741824
2020/05/22-13:22:50.555299 7f33fc5e8f00                   Options.target_file_size_base: 4294967296
2020/05/22-13:22:50.555299 7f33fc5e8f00             Options.target_file_size_multiplier: 1
2020/05/22-13:22:50.555300 7f33fc5e8f00                Options.max_bytes_for_level_base: 268435456
2020/05/22-13:22:50.555301 7f33fc5e8f00 Options.level_compaction_dynamic_level_bytes: 0
2020/05/22-13:22:50.555302 7f33fc5e8f00          Options.max_bytes_for_level_multiplier: 10.000000
2020/05/22-13:22:50.555303 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[0]: 1
2020/05/22-13:22:50.555304 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[1]: 1
2020/05/22-13:22:50.555305 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[2]: 1
2020/05/22-13:22:50.555306 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[3]: 1
2020/05/22-13:22:50.555306 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[4]: 1
2020/05/22-13:22:50.555307 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[5]: 1
2020/05/22-13:22:50.555308 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[6]: 1
2020/05/22-13:22:50.555309 7f33fc5e8f00       Options.max_sequential_skip_in_iterations: 8
2020/05/22-13:22:50.555309 7f33fc5e8f00                    Options.max_compaction_bytes: 107374182400
2020/05/22-13:22:50.555310 7f33fc5e8f00                        Options.arena_block_size: 1122820096
2020/05/22-13:22:50.555311 7f33fc5e8f00   Options.soft_pending_compaction_bytes_limit: 0
2020/05/22-13:22:50.555312 7f33fc5e8f00   Options.hard_pending_compaction_bytes_limit: 0
2020/05/22-13:22:50.555313 7f33fc5e8f00       Options.rate_limit_delay_max_milliseconds: 100
2020/05/22-13:22:50.555313 7f33fc5e8f00                Options.disable_auto_compactions: 0
2020/05/22-13:22:50.555314 7f33fc5e8f00                        Options.compaction_style: kCompactionStyleUniversal
2020/05/22-13:22:50.555315 7f33fc5e8f00                          Options.compaction_pri: kMinOverlappingRatio
2020/05/22-13:22:50.555316 7f33fc5e8f00 Options.compaction_options_universal.size_ratio: 10
2020/05/22-13:22:50.555317 7f33fc5e8f00 Options.compaction_options_universal.min_merge_width: 2
2020/05/22-13:22:50.555317 7f33fc5e8f00 Options.compaction_options_universal.max_merge_width: 6
2020/05/22-13:22:50.555318 7f33fc5e8f00 Options.compaction_options_universal.max_size_amplification_percent: 1073741824
2020/05/22-13:22:50.555319 7f33fc5e8f00 Options.compaction_options_universal.compression_size_percent: -1
2020/05/22-13:22:50.555320 7f33fc5e8f00 Options.compaction_options_universal.stop_style: kCompactionStopStyleTotalSize
2020/05/22-13:22:50.555321 7f33fc5e8f00 Options.compaction_options_fifo.max_table_files_size: 1073741824
2020/05/22-13:22:50.555322 7f33fc5e8f00 Options.compaction_options_fifo.allow_compaction: 0
2020/05/22-13:22:50.555322 7f33fc5e8f00                   Options.table_properties_collectors: 
2020/05/22-13:22:50.555323 7f33fc5e8f00                   Options.inplace_update_support: 0
2020/05/22-13:22:50.555324 7f33fc5e8f00                 Options.inplace_update_num_locks: 10000
2020/05/22-13:22:50.555325 7f33fc5e8f00               Options.memtable_prefix_bloom_size_ratio: 0.000000
2020/05/22-13:22:50.555326 7f33fc5e8f00               Options.memtable_whole_key_filtering: 0
2020/05/22-13:22:50.555326 7f33fc5e8f00   Options.memtable_huge_page_size: 0
2020/05/22-13:22:50.555327 7f33fc5e8f00                           Options.bloom_locality: 0
2020/05/22-13:22:50.555328 7f33fc5e8f00                    Options.max_successive_merges: 0
2020/05/22-13:22:50.555329 7f33fc5e8f00                Options.optimize_filters_for_hits: 0
2020/05/22-13:22:50.555329 7f33fc5e8f00                Options.paranoid_file_checks: 0
2020/05/22-13:22:50.555330 7f33fc5e8f00                Options.force_consistency_checks: 0
2020/05/22-13:22:50.555331 7f33fc5e8f00                Options.report_bg_io_stats: 0
2020/05/22-13:22:50.555332 7f33fc5e8f00                               Options.ttl: 2592000
2020/05/22-13:22:50.555337 7f33fc5e8f00          Options.periodic_compaction_seconds: 2592000
2020/05/22-13:22:50.555349 7f33fc5e8f00 [lumn_family.cc:550] --------------- Options for column family [header]:
2020/05/22-13:22:50.555351 7f33fc5e8f00               Options.comparator: leveldb.BytewiseComparator
2020/05/22-13:22:50.555351 7f33fc5e8f00           Options.merge_operator: None
2020/05/22-13:22:50.555352 7f33fc5e8f00        Options.compaction_filter: None
2020/05/22-13:22:50.555353 7f33fc5e8f00        Options.compaction_filter_factory: None
2020/05/22-13:22:50.555354 7f33fc5e8f00         Options.memtable_factory: VectorRepFactory
2020/05/22-13:22:50.555355 7f33fc5e8f00            Options.table_factory: BlockBasedTable
2020/05/22-13:22:50.555365 7f33fc5e8f00            table_factory options:   flush_block_policy_factory: FlushBlockBySizePolicyFactory (0x5638c8dda6d0)
  cache_index_and_filter_blocks: 1
  cache_index_and_filter_blocks_with_high_priority: 1
  pin_l0_filter_and_index_blocks_in_cache: 0
  pin_top_level_index_and_filter: 1
  index_type: 0
  data_block_index_type: 0
  index_shortening: 1
  data_block_hash_table_util_ratio: 0.750000
  hash_index_allow_collision: 1
  checksum: 1
  no_block_cache: 0
  block_cache: 0x5638c8dea9d0
  block_cache_name: LRUCache
  block_cache_options:
    capacity : 13473801830
    num_shard_bits : 6
    strict_capacity_limit : 0
    memory_allocator : None
    high_pri_pool_ratio: 0.500
  block_cache_compressed: (nil)
  persistent_cache: (nil)
  block_size: 1048576
  block_size_deviation: 10
  block_restart_interval: 16
  index_block_restart_interval: 1
  metadata_block_size: 4096
  partition_filters: 0
  use_delta_encoding: 1
  filter_policy: nullptr
  whole_key_filtering: 1
  verify_compression: 0
  read_amp_bytes_per_bit: 0
  format_version: 4
  enable_index_compression: 1
  block_align: 0
2020/05/22-13:22:50.555366 7f33fc5e8f00        Options.write_buffer_size: 8982534553
2020/05/22-13:22:50.555366 7f33fc5e8f00  Options.max_write_buffer_number: 4
2020/05/22-13:22:50.555367 7f33fc5e8f00          Options.compression: ZSTD
2020/05/22-13:22:50.555368 7f33fc5e8f00                  Options.bottommost_compression: Disabled
2020/05/22-13:22:50.555369 7f33fc5e8f00       Options.prefix_extractor: nullptr
2020/05/22-13:22:50.555370 7f33fc5e8f00   Options.memtable_insert_with_hint_prefix_extractor: nullptr
2020/05/22-13:22:50.555370 7f33fc5e8f00             Options.num_levels: 4
2020/05/22-13:22:50.555371 7f33fc5e8f00        Options.min_write_buffer_number_to_merge: 1
2020/05/22-13:22:50.555372 7f33fc5e8f00     Options.max_write_buffer_number_to_maintain: 0
2020/05/22-13:22:50.555373 7f33fc5e8f00     Options.max_write_buffer_size_to_maintain: 0
2020/05/22-13:22:50.555373 7f33fc5e8f00            Options.bottommost_compression_opts.window_bits: -14
2020/05/22-13:22:50.555374 7f33fc5e8f00                  Options.bottommost_compression_opts.level: 32767
2020/05/22-13:22:50.555375 7f33fc5e8f00               Options.bottommost_compression_opts.strategy: 0
2020/05/22-13:22:50.555376 7f33fc5e8f00         Options.bottommost_compression_opts.max_dict_bytes: 0
2020/05/22-13:22:50.555377 7f33fc5e8f00         Options.bottommost_compression_opts.zstd_max_train_bytes: 0
2020/05/22-13:22:50.555377 7f33fc5e8f00                  Options.bottommost_compression_opts.enabled: false
2020/05/22-13:22:50.555378 7f33fc5e8f00            Options.compression_opts.window_bits: -14
2020/05/22-13:22:50.555379 7f33fc5e8f00                  Options.compression_opts.level: 2
2020/05/22-13:22:50.555380 7f33fc5e8f00               Options.compression_opts.strategy: 0
2020/05/22-13:22:50.555380 7f33fc5e8f00         Options.compression_opts.max_dict_bytes: 0
2020/05/22-13:22:50.555381 7f33fc5e8f00         Options.compression_opts.zstd_max_train_bytes: 0
2020/05/22-13:22:50.555382 7f33fc5e8f00                  Options.compression_opts.enabled: false
2020/05/22-13:22:50.555383 7f33fc5e8f00      Options.level0_file_num_compaction_trigger: 4
2020/05/22-13:22:50.555384 7f33fc5e8f00          Options.level0_slowdown_writes_trigger: 1073741824
2020/05/22-13:22:50.555390 7f33fc5e8f00              Options.level0_stop_writes_trigger: 1073741824
2020/05/22-13:22:50.555391 7f33fc5e8f00                   Options.target_file_size_base: 4294967296
2020/05/22-13:22:50.555391 7f33fc5e8f00             Options.target_file_size_multiplier: 1
2020/05/22-13:22:50.555392 7f33fc5e8f00                Options.max_bytes_for_level_base: 268435456
2020/05/22-13:22:50.555393 7f33fc5e8f00 Options.level_compaction_dynamic_level_bytes: 0
2020/05/22-13:22:50.555394 7f33fc5e8f00          Options.max_bytes_for_level_multiplier: 10.000000
2020/05/22-13:22:50.555395 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[0]: 1
2020/05/22-13:22:50.555396 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[1]: 1
2020/05/22-13:22:50.555397 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[2]: 1
2020/05/22-13:22:50.555398 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[3]: 1
2020/05/22-13:22:50.555398 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[4]: 1
2020/05/22-13:22:50.555399 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[5]: 1
2020/05/22-13:22:50.555400 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[6]: 1
2020/05/22-13:22:50.555401 7f33fc5e8f00       Options.max_sequential_skip_in_iterations: 8
2020/05/22-13:22:50.555401 7f33fc5e8f00                    Options.max_compaction_bytes: 107374182400
2020/05/22-13:22:50.555402 7f33fc5e8f00                        Options.arena_block_size: 1122820096
2020/05/22-13:22:50.555403 7f33fc5e8f00   Options.soft_pending_compaction_bytes_limit: 0
2020/05/22-13:22:50.555404 7f33fc5e8f00   Options.hard_pending_compaction_bytes_limit: 0
2020/05/22-13:22:50.555405 7f33fc5e8f00       Options.rate_limit_delay_max_milliseconds: 100
2020/05/22-13:22:50.555405 7f33fc5e8f00                Options.disable_auto_compactions: 0
2020/05/22-13:22:50.555406 7f33fc5e8f00                        Options.compaction_style: kCompactionStyleUniversal
2020/05/22-13:22:50.555407 7f33fc5e8f00                          Options.compaction_pri: kMinOverlappingRatio
2020/05/22-13:22:50.555408 7f33fc5e8f00 Options.compaction_options_universal.size_ratio: 10
2020/05/22-13:22:50.555409 7f33fc5e8f00 Options.compaction_options_universal.min_merge_width: 2
2020/05/22-13:22:50.555410 7f33fc5e8f00 Options.compaction_options_universal.max_merge_width: 6
2020/05/22-13:22:50.555411 7f33fc5e8f00 Options.compaction_options_universal.max_size_amplification_percent: 1073741824
2020/05/22-13:22:50.555411 7f33fc5e8f00 Options.compaction_options_universal.compression_size_percent: -1
2020/05/22-13:22:50.555412 7f33fc5e8f00 Options.compaction_options_universal.stop_style: kCompactionStopStyleTotalSize
2020/05/22-13:22:50.555413 7f33fc5e8f00 Options.compaction_options_fifo.max_table_files_size: 1073741824
2020/05/22-13:22:50.555414 7f33fc5e8f00 Options.compaction_options_fifo.allow_compaction: 0
2020/05/22-13:22:50.555415 7f33fc5e8f00                   Options.table_properties_collectors: 
2020/05/22-13:22:50.555415 7f33fc5e8f00                   Options.inplace_update_support: 0
2020/05/22-13:22:50.555416 7f33fc5e8f00                 Options.inplace_update_num_locks: 10000
2020/05/22-13:22:50.555417 7f33fc5e8f00               Options.memtable_prefix_bloom_size_ratio: 0.000000
2020/05/22-13:22:50.555418 7f33fc5e8f00               Options.memtable_whole_key_filtering: 0
2020/05/22-13:22:50.555419 7f33fc5e8f00   Options.memtable_huge_page_size: 0
2020/05/22-13:22:50.555419 7f33fc5e8f00                           Options.bloom_locality: 0
2020/05/22-13:22:50.555420 7f33fc5e8f00                    Options.max_successive_merges: 0
2020/05/22-13:22:50.555421 7f33fc5e8f00                Options.optimize_filters_for_hits: 0
2020/05/22-13:22:50.555422 7f33fc5e8f00                Options.paranoid_file_checks: 0
2020/05/22-13:22:50.555422 7f33fc5e8f00                Options.force_consistency_checks: 0
2020/05/22-13:22:50.555423 7f33fc5e8f00                Options.report_bg_io_stats: 0
2020/05/22-13:22:50.555424 7f33fc5e8f00                               Options.ttl: 2592000
2020/05/22-13:22:50.555429 7f33fc5e8f00          Options.periodic_compaction_seconds: 2592000
2020/05/22-13:22:50.555442 7f33fc5e8f00 [lumn_family.cc:550] --------------- Options for column family [bcf]:
2020/05/22-13:22:50.555443 7f33fc5e8f00               Options.comparator: leveldb.BytewiseComparator
2020/05/22-13:22:50.555443 7f33fc5e8f00           Options.merge_operator: None
2020/05/22-13:22:50.555444 7f33fc5e8f00        Options.compaction_filter: None
2020/05/22-13:22:50.555445 7f33fc5e8f00        Options.compaction_filter_factory: None
2020/05/22-13:22:50.555446 7f33fc5e8f00         Options.memtable_factory: VectorRepFactory
2020/05/22-13:22:50.555447 7f33fc5e8f00            Options.table_factory: BlockBasedTable
2020/05/22-13:22:50.555456 7f33fc5e8f00            table_factory options:   flush_block_policy_factory: FlushBlockBySizePolicyFactory (0x5638c8e02af0)
  cache_index_and_filter_blocks: 1
  cache_index_and_filter_blocks_with_high_priority: 1
  pin_l0_filter_and_index_blocks_in_cache: 0
  pin_top_level_index_and_filter: 1
  index_type: 1
  data_block_index_type: 0
  index_shortening: 1
  data_block_hash_table_util_ratio: 0.750000
  hash_index_allow_collision: 1
  checksum: 1
  no_block_cache: 0
  block_cache: 0x5638c8dea9d0
  block_cache_name: LRUCache
  block_cache_options:
    capacity : 13473801830
    num_shard_bits : 6
    strict_capacity_limit : 0
    memory_allocator : None
    high_pri_pool_ratio: 0.500
  block_cache_compressed: (nil)
  persistent_cache: (nil)
  block_size: 1048576
  block_size_deviation: 10
  block_restart_interval: 16
  index_block_restart_interval: 1
  metadata_block_size: 4096
  partition_filters: 0
  use_delta_encoding: 1
  filter_policy: nullptr
  whole_key_filtering: 1
  verify_compression: 0
  read_amp_bytes_per_bit: 0
  format_version: 4
  enable_index_compression: 1
  block_align: 0
2020/05/22-13:22:50.555457 7f33fc5e8f00        Options.write_buffer_size: 8982534553
2020/05/22-13:22:50.555458 7f33fc5e8f00  Options.max_write_buffer_number: 4
2020/05/22-13:22:50.555459 7f33fc5e8f00          Options.compression: ZSTD
2020/05/22-13:22:50.555460 7f33fc5e8f00                  Options.bottommost_compression: Disabled
2020/05/22-13:22:50.555461 7f33fc5e8f00       Options.prefix_extractor: rocksdb.FixedPrefix.8
2020/05/22-13:22:50.555462 7f33fc5e8f00   Options.memtable_insert_with_hint_prefix_extractor: nullptr
2020/05/22-13:22:50.555462 7f33fc5e8f00             Options.num_levels: 4
2020/05/22-13:22:50.555463 7f33fc5e8f00        Options.min_write_buffer_number_to_merge: 1
2020/05/22-13:22:50.555464 7f33fc5e8f00     Options.max_write_buffer_number_to_maintain: 0
2020/05/22-13:22:50.555465 7f33fc5e8f00     Options.max_write_buffer_size_to_maintain: 0
2020/05/22-13:22:50.555465 7f33fc5e8f00            Options.bottommost_compression_opts.window_bits: -14
2020/05/22-13:22:50.555466 7f33fc5e8f00                  Options.bottommost_compression_opts.level: 32767
2020/05/22-13:22:50.555467 7f33fc5e8f00               Options.bottommost_compression_opts.strategy: 0
2020/05/22-13:22:50.555468 7f33fc5e8f00         Options.bottommost_compression_opts.max_dict_bytes: 0
2020/05/22-13:22:50.555469 7f33fc5e8f00         Options.bottommost_compression_opts.zstd_max_train_bytes: 0
2020/05/22-13:22:50.555469 7f33fc5e8f00                  Options.bottommost_compression_opts.enabled: false
2020/05/22-13:22:50.555470 7f33fc5e8f00            Options.compression_opts.window_bits: -14
2020/05/22-13:22:50.555471 7f33fc5e8f00                  Options.compression_opts.level: 2
2020/05/22-13:22:50.555472 7f33fc5e8f00               Options.compression_opts.strategy: 0
2020/05/22-13:22:50.555472 7f33fc5e8f00         Options.compression_opts.max_dict_bytes: 0
2020/05/22-13:22:50.555473 7f33fc5e8f00         Options.compression_opts.zstd_max_train_bytes: 0
2020/05/22-13:22:50.555474 7f33fc5e8f00                  Options.compression_opts.enabled: false
2020/05/22-13:22:50.555475 7f33fc5e8f00      Options.level0_file_num_compaction_trigger: 4
2020/05/22-13:22:50.555482 7f33fc5e8f00          Options.level0_slowdown_writes_trigger: 1073741824
2020/05/22-13:22:50.555483 7f33fc5e8f00              Options.level0_stop_writes_trigger: 1073741824
2020/05/22-13:22:50.555484 7f33fc5e8f00                   Options.target_file_size_base: 4294967296
2020/05/22-13:22:50.555485 7f33fc5e8f00             Options.target_file_size_multiplier: 1
2020/05/22-13:22:50.555486 7f33fc5e8f00                Options.max_bytes_for_level_base: 268435456
2020/05/22-13:22:50.555486 7f33fc5e8f00 Options.level_compaction_dynamic_level_bytes: 0
2020/05/22-13:22:50.555487 7f33fc5e8f00          Options.max_bytes_for_level_multiplier: 10.000000
2020/05/22-13:22:50.555488 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[0]: 1
2020/05/22-13:22:50.555489 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[1]: 1
2020/05/22-13:22:50.555490 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[2]: 1
2020/05/22-13:22:50.555491 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[3]: 1
2020/05/22-13:22:50.555492 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[4]: 1
2020/05/22-13:22:50.555492 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[5]: 1
2020/05/22-13:22:50.555493 7f33fc5e8f00 Options.max_bytes_for_level_multiplier_addtl[6]: 1
2020/05/22-13:22:50.555494 7f33fc5e8f00       Options.max_sequential_skip_in_iterations: 8
2020/05/22-13:22:50.555495 7f33fc5e8f00                    Options.max_compaction_bytes: 107374182400
2020/05/22-13:22:50.555496 7f33fc5e8f00                        Options.arena_block_size: 1122820096
2020/05/22-13:22:50.555496 7f33fc5e8f00   Options.soft_pending_compaction_bytes_limit: 0
2020/05/22-13:22:50.555497 7f33fc5e8f00   Options.hard_pending_compaction_bytes_limit: 0
2020/05/22-13:22:50.555498 7f33fc5e8f00       Options.rate_limit_delay_max_milliseconds: 100
2020/05/22-13:22:50.555499 7f33fc5e8f00                Options.disable_auto_compactions: 0
2020/05/22-13:22:50.555500 7f33fc5e8f00                        Options.compaction_style: kCompactionStyleUniversal
2020/05/22-13:22:50.555501 7f33fc5e8f00                          Options.compaction_pri: kMinOverlappingRatio
2020/05/22-13:22:50.555501 7f33fc5e8f00 Options.compaction_options_universal.size_ratio: 10
2020/05/22-13:22:50.555502 7f33fc5e8f00 Options.compaction_options_universal.min_merge_width: 2
2020/05/22-13:22:50.555503 7f33fc5e8f00 Options.compaction_options_universal.max_merge_width: 6
2020/05/22-13:22:50.555504 7f33fc5e8f00 Options.compaction_options_universal.max_size_amplification_percent: 1073741824
2020/05/22-13:22:50.555505 7f33fc5e8f00 Options.compaction_options_universal.compression_size_percent: -1
2020/05/22-13:22:50.555506 7f33fc5e8f00 Options.compaction_options_universal.stop_style: kCompactionStopStyleTotalSize
2020/05/22-13:22:50.555506 7f33fc5e8f00 Options.compaction_options_fifo.max_table_files_size: 1073741824
2020/05/22-13:22:50.555507 7f33fc5e8f00 Options.compaction_options_fifo.allow_compaction: 0
2020/05/22-13:22:50.555508 7f33fc5e8f00                   Options.table_properties_collectors: 
2020/05/22-13:22:50.555509 7f33fc5e8f00                   Options.inplace_update_support: 0
2020/05/22-13:22:50.555509 7f33fc5e8f00                 Options.inplace_update_num_locks: 10000
2020/05/22-13:22:50.555510 7f33fc5e8f00               Options.memtable_prefix_bloom_size_ratio: 0.000000
2020/05/22-13:22:50.555511 7f33fc5e8f00               Options.memtable_whole_key_filtering: 0
2020/05/22-13:22:50.555512 7f33fc5e8f00   Options.memtable_huge_page_size: 0
2020/05/22-13:22:50.555513 7f33fc5e8f00                           Options.bloom_locality: 0
2020/05/22-13:22:50.555514 7f33fc5e8f00                    Options.max_successive_merges: 0
2020/05/22-13:22:50.555514 7f33fc5e8f00                Options.optimize_filters_for_hits: 0
2020/05/22-13:22:50.555515 7f33fc5e8f00                Options.paranoid_file_checks: 0
2020/05/22-13:22:50.555516 7f33fc5e8f00                Options.force_consistency_checks: 0
2020/05/22-13:22:50.555517 7f33fc5e8f00                Options.report_bg_io_stats: 0
2020/05/22-13:22:50.555522 7f33fc5e8f00                               Options.ttl: 2592000
2020/05/22-13:22:50.555523 7f33fc5e8f00          Options.periodic_compaction_seconds: 2592000
2020/05/22-13:22:50.558155 7f33fc5e8f00 [rsion_set.cc:4527] Recovered from manifest file:GLnexus.DB/MANIFEST-000006 succeeded,manifest_file_number is 6, next_file_number is 21, last_sequence is 4, log_number is 17,prev_log_number is 0,max_column_family is 5,min_log_number_to_keep is 0
2020/05/22-13:22:50.558160 7f33fc5e8f00 [rsion_set.cc:4536] Column family [default] (ID 0), log number is 0
2020/05/22-13:22:50.558161 7f33fc5e8f00 [rsion_set.cc:4536] Column family [config] (ID 1), log number is 17
2020/05/22-13:22:50.558163 7f33fc5e8f00 [rsion_set.cc:4536] Column family [sampleset] (ID 2), log number is 17
2020/05/22-13:22:50.558164 7f33fc5e8f00 [rsion_set.cc:4536] Column family [sample_dataset] (ID 3), log number is 3
2020/05/22-13:22:50.558165 7f33fc5e8f00 [rsion_set.cc:4536] Column family [header] (ID 4), log number is 3
2020/05/22-13:22:50.558166 7f33fc5e8f00 [rsion_set.cc:4536] Column family [bcf] (ID 5), log number is 3
2020/05/22-13:22:50.558300 7f33fc5e8f00 EVENT_LOG_v1 {""time_micros"": 1590146570558298, ""job"": 1, ""event"": ""recovery_started"", ""log_files"": [17]}
2020/05/22-13:22:50.558303 7f33fc5e8f00 [_impl/db_impl_open.cc:735] Recovering log #17 mode 2
2020/05/22-13:22:50.558369 7f33fc5e8f00 [rsion_set.cc:3788] Creating manifest 21
2020/05/22-13:22:50.662608 7f33fc5e8f00 EVENT_LOG_v1 {""time_micros"": 1590146570662599, ""job"": 1, ""event"": ""recovery_finished""}
2020/05/22-13:22:50.715975 7f33fc5e8f00 DB pointer 0x5638c8dcde70
2020/05/22-13:22:50.717220 7f33a27fc700 [_impl/db_impl.cc:858] ------- DUMPING STATS -------
2020/05/22-13:22:50.717562 7f33a27fc700 [_impl/db_impl.cc:859] 
** DB Stats **
Uptime(secs): 0.2 total, 0.2 interval
Cumulative writes: 0 writes, 0 keys, 0 commit groups, 0.0 writes per commit group, ingest: 0.00 GB, 0.00 MB/s
Cumulative WAL: 0 writes, 0 syncs, 0.00 writes per sync, written: 0.00 GB, 0.00 MB/s
Cumulative stall: 00:00:0.000 H:M:S, 0.0 percent
Interval writes: 0 writes, 0 keys, 0 commit groups, 0.0 writes per commit group, ingest: 0.00 MB, 0.00 MB/s
Interval WAL: 0 writes, 0 syncs, 0.00 writes per sync, written: 0.00 MB, 0.00 MB/s
Interval stall: 00:00:0.000 H:M:S, 0.0 percent

** Compaction Stats [default] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sum      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [default] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 0.2 total, 0.2 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level [default] **

** Compaction Stats [config] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  L0      1/0    0.89 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Sum      1/0    0.89 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [config] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 0.2 total, 0.2 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level [config] **

** Compaction Stats [sampleset] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  L0      1/0    0.78 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Sum      1/0    0.78 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [sampleset] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 0.2 total, 0.2 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level [sampleset] **

** Compaction Stats [sample_dataset] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sum      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [sample_dataset] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 0.2 total, 0.2 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level [sample_dataset] **

** Compaction Stats [header] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sum      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [header] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 0.2 total, 0.2 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level [header] **

** Compaction Stats [bcf] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sum      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [bcf] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 0.2 total, 0.2 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level [bcf] **

** Compaction Stats [default] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sum      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [default] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 0.2 total, 0.0 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level [default] **

** Compaction Stats [config] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  L0      1/0    0.89 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Sum      1/0    0.89 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [config] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 0.2 total, 0.0 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level [config] **

** Compaction Stats [sampleset] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  L0      1/0    0.78 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Sum      1/0    0.78 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [sampleset] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 0.2 total, 0.0 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level [sampleset] **

** Compaction Stats [sample_dataset] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sum      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [sample_dataset] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 0.2 total, 0.0 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level [sample_dataset] **

** Compaction Stats [header] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sum      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [header] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 0.2 total, 0.0 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level [header] **

** Compaction Stats [bcf] **
Level    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Sum      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0
 Int      0/0    0.00 KB   0.0      0.0     0.0      0.0       0.0      0.0       0.0   0.0      0.0      0.0      0.00              0.00         0    0.000       0      0

** Compaction Stats [bcf] **
Priority    Files   Size     Score Read(GB)  Rn(GB) Rnp1(GB) Write(GB) Wnew(GB) Moved(GB) W-Amp Rd(MB/s) Wr(MB/s) Comp(sec) CompMergeCPU(sec) Comp(cnt) Avg(sec) KeyIn KeyDrop
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Uptime(secs): 0.2 total, 0.0 interval
Flush(GB): cumulative 0.000, interval 0.000
AddFile(GB): cumulative 0.000, interval 0.000
AddFile(Total Files): cumulative 0, interval 0
AddFile(L0 Files): cumulative 0, interval 0
AddFile(Keys): cumulative 0, interval 0
Cumulative compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Interval compaction: 0.00 GB write, 0.00 MB/s write, 0.00 GB read, 0.00 MB/s read, 0.0 seconds
Stalls(count): 0 level0_slowdown, 0 level0_slowdown_with_compaction, 0 level0_numfiles, 0 level0_numfiles_with_compaction, 0 stop for pending_compaction_bytes, 0 slowdown for pending_compaction_bytes, 0 memtable_compaction, 0 memtable_slowdown, interval 0 total count

** File Read Latency Histogram By Level [bcf] **
2020/05/22-13:22:59.881740 7f33fc5e8f00 [_impl/db_impl_compaction_flush.cc:1307] [bcf] Manual flush start.
2020/05/22-13:22:59.881806 7f33fc5e8f00 [_impl/db_impl_write.cc:1669] [bcf] New memtable created with log file: #22. Immutable memtables: 0.
2020/05/22-13:22:59.881929 7f33f17fa700 (Original Log Time 2020/05/22-13:22:59.881901) [_impl/db_impl_compaction_flush.cc:2197] Calling FlushMemTableToOutputFile with column family [bcf], flush slots available 2, compaction slots available 6, flush slots scheduled 2, compaction slots scheduled 0
2020/05/22-13:22:59.881931 7f33f17fa700 [ush_job.cc:320] [bcf] [JOB 3] Flushing memtable with next log file: 22
2020/05/22-13:22:59.881939 7f33f17fa700 EVENT_LOG_v1 {""time_micros"": 1590146579881936, ""job"": 3, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 6728, ""num_deletes"": 0, ""total_data_size"": 887359956, ""memory_usage"": 887420020, ""flush_reason"": ""Manual Flush""}
2020/05/22-13:22:59.881940 7f33f17fa700 [ush_job.cc:349] [bcf] [JOB 3] Level-0 flush table #25: started
2020/05/22-13:23:04.323421 7f33f17fa700 EVENT_LOG_v1 {""time_micros"": 1590146584323361, ""cf_name"": ""bcf"", ""job"": 3, ""event"": ""table_file_creation"", ""file_number"": 25, ""file_size"": 162156078, ""table_properties"": {""data_size"": 162136566, ""index_size"": 59481, ""index_partitions"": 0, ""top_level_index_size"": 0, ""index_key_is_user_key"": 1, ""index_value_is_delta_encoded"": 1, ""filter_size"": 0, ""raw_key_size"": 158108, ""raw_average_key_size"": 23, ""raw_value_size"": 887175336, ""raw_average_value_size"": 131863, ""num_data_blocks"": 867, ""num_entries"": 6728, ""num_deletions"": 0, ""num_merge_operands"": 0, ""num_range_deletions"": 0, ""format_version"": 0, ""fixed_key_len"": 0, ""filter_policy"": """", ""column_family_name"": ""bcf"", ""column_family_id"": 5, ""comparator"": ""leveldb.BytewiseComparator"", ""merge_operator"": ""nullptr"", ""prefix_extractor_name"": ""rocksdb.FixedPrefix.8"", ""property_collectors"": ""[]"", ""compression"": ""ZSTD"", ""compression_options"": ""window_bits=-14; level=2; strategy=0; max_dict_bytes=0; zstd_max_train_bytes=0; enabled=0; "", ""creation_time"": 1590146579, ""oldest_key_time"": 1590146571, ""file_creation_time"": 1590146579}}
2020/05/22-13:23:04.323459 7f33f17fa700 [ush_job.cc:395] [bcf] [JOB 3] Level-0 flush table #25: 162156078 bytes OK
2020/05/22-13:23:04.413170 7f33f17fa700 (Original Log Time 2020/05/22-13:23:04.371338) [mtable_list.cc:447] [bcf] Level-0 commit table #25 started
2020/05/22-13:23:04.413182 7f33f17fa700 (Original Log Time 2020/05/22-13:23:04.413040) [mtable_list.cc:503] [bcf] Level-0 commit table #25: memtable #1 done
2020/05/22-13:23:04.413187 7f33f17fa700 (Original Log Time 2020/05/22-13:23:04.413078) EVENT_LOG_v1 {""time_micros"": 1590146584413067, ""job"": 3, ""event"": ""flush_finished"", ""output_compression"": ""ZSTD"", ""lsm_state"": [1, 0, 0, 0], ""immutable_memtables"": 0}
2020/05/22-13:23:04.413192 7f33f17fa700 (Original Log Time 2020/05/22-13:23:04.413113) [_impl/db_impl_compaction_flush.cc:205] [bcf] Level summary: files[1 0 0 0] max score 0.25
2020/05/22-13:23:04.458368 7f33fc5e8f00 [_impl/db_impl_compaction_flush.cc:1318] [bcf] Manual flush finished, status: OK
2020/05/22-13:23:04.458390 7f33fc5e8f00 [_impl/db_impl_compaction_flush.cc:1307] [config] Manual flush start.
2020/05/22-13:23:04.458394 7f33fc5e8f00 [_impl/db_impl_compaction_flush.cc:1318] [config] Manual flush finished, status: OK
2020/05/22-13:23:04.458395 7f33fc5e8f00 [_impl/db_impl_compaction_flush.cc:1307] [default] Manual flush start.
2020/05/22-13:23:04.458397 7f33fc5e8f00 [_impl/db_impl_compaction_flush.cc:1318] [default] Manual flush finished, status: OK
2020/05/22-13:23:04.458398 7f33fc5e8f00 [_impl/db_impl_compaction_flush.cc:1307] [header] Manual flush start.
2020/05/22-13:23:04.458433 7f33fc5e8f00 [_impl/db_impl_write.cc:1669] [header] New memtable created with log file: #22. Immutable memtables: 0.
2020/05/22-13:23:04.458534 7f33bbfff700 (Original Log Time 2020/05/22-13:23:04.458513) [_impl/db_impl_compaction_flush.cc:2197] Calling FlushMemTableToOutputFile with column family [header], flush slots available 2, compaction slots available 6, flush slots scheduled 2, compaction slots scheduled 0
2020/05/22-13:23:04.458539 7f33bbfff700 [ush_job.cc:320] [header] [JOB 6] Flushing memtable with next log file: 22
2020/05/22-13:23:04.458565 7f33bbfff700 EVENT_LOG_v1 {""time_micros"": 1590146584458561, ""job"": 6, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 2, ""num_deletes"": 0, ""total_data_size"": 2701, ""memory_usage"": 7604, ""flush_reason"": ""Manual Flush""}
2020/05/22-13:23:04.458568 7f33bbfff700 [ush_job.cc:349] [header] [JOB 6] Level-0 flush table #26: started
2020/05/22-13:23:04.504969 7f33bbfff700 EVENT_LOG_v1 {""time_micros"": 1590146584504938, ""cf_name"": ""header"", ""job"": 6, ""event"": ""table_file_creation"", ""file_number"": 26, ""file_size"": 1448, ""table_properties"": {""data_size"": 678, ""index_size"": 26, ""index_partitions"": 0, ""top_level_index_size"": 0, ""index_key_is_user_key"": 1, ""index_value_is_delta_encoded"": 1, ""filter_size"": 0, ""raw_key_size"": 31, ""raw_average_key_size"": 15, ""raw_value_size"": 2664, ""raw_average_value_size"": 1332, ""num_data_blocks"": 1, ""num_entries"": 2, ""num_deletions"": 0, ""num_merge_operands"": 0, ""num_range_deletions"": 0, ""format_version"": 0, ""fixed_key_len"": 0, ""filter_policy"": """", ""column_family_name"": ""header"", ""column_family_id"": 4, ""comparator"": ""leveldb.BytewiseComparator"", ""merge_operator"": ""nullptr"", ""prefix_extractor_name"": ""nullptr"", ""property_collectors"": ""[]"", ""compression"": ""ZSTD"", ""compression_options"": ""window_bits=-14; level=2; strategy=0; max_dict_bytes=0; zstd_max_train_bytes=0; enabled=0; "", ""creation_time"": 1590146584, ""oldest_key_time"": 1590146579, ""file_creation_time"": 1590146584}}
2020/05/22-13:23:04.504999 7f33bbfff700 [ush_job.cc:395] [header] [JOB 6] Level-0 flush table #26: 1448 bytes OK
2020/05/22-13:23:04.563189 7f33bbfff700 (Original Log Time 2020/05/22-13:23:04.521382) [mtable_list.cc:447] [header] Level-0 commit table #26 started
2020/05/22-13:23:04.563198 7f33bbfff700 (Original Log Time 2020/05/22-13:23:04.563057) [mtable_list.cc:503] [header] Level-0 commit table #26: memtable #1 done
2020/05/22-13:23:04.563204 7f33bbfff700 (Original Log Time 2020/05/22-13:23:04.563091) EVENT_LOG_v1 {""time_micros"": 1590146584563080, ""job"": 6, ""event"": ""flush_finished"", ""output_compression"": ""ZSTD"", ""lsm_state"": [1, 0, 0, 0], ""immutable_memtables"": 0}
2020/05/22-13:23:04.563209 7f33bbfff700 (Original Log Time 2020/05/22-13:23:04.563124) [_impl/db_impl_compaction_flush.cc:205] [header] Level summary: files[1 0 0 0] max score 0.25
2020/05/22-13:23:04.563352 7f33fc5e8f00 [_impl/db_impl_compaction_flush.cc:1318] [header] Manual flush finished, status: OK
2020/05/22-13:23:04.563368 7f33fc5e8f00 [_impl/db_impl_compaction_flush.cc:1307] [sample_dataset] Manual flush start.
2020/05/22-13:23:04.563390 7f33fc5e8f00 [_impl/db_impl_write.cc:1669] [sample_dataset] New memtable created with log file: #22. Immutable memtables: 0.
2020/05/22-13:23:04.563487 7f33f37fe700 (Original Log Time 2020/05/22-13:23:04.563463) [_impl/db_impl_compaction_flush.cc:2197] Calling FlushMemTableToOutputFile with column family [sample_dataset], flush slots available 2, compaction slots available 6, flush slots scheduled 2, compaction slots scheduled 0
2020/05/22-13:23:04.563495 7f33f37fe700 [ush_job.cc:320] [sample_dataset] [JOB 7] Flushing memtable with next log file: 22
2020/05/22-13:23:04.563529 7f33f37fe700 EVENT_LOG_v1 {""time_micros"": 1590146584563513, ""job"": 7, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 2, ""num_deletes"": 0, ""total_data_size"": 45, ""memory_usage"": 493, ""flush_reason"": ""Manual Flush""}
2020/05/22-13:23:04.563537 7f33f37fe700 [ush_job.cc:349] [sample_dataset] [JOB 7] Level-0 flush table #27: started
2020/05/22-13:23:04.597061 7f33f37fe700 EVENT_LOG_v1 {""time_micros"": 1590146584597000, ""cf_name"": ""sample_dataset"", ""job"": 7, ""event"": ""table_file_creation"", ""file_number"": 27, ""file_size"": 833, ""table_properties"": {""data_size"": 60, ""index_size"": 24, ""index_partitions"": 0, ""top_level_index_size"": 0, ""index_key_is_user_key"": 1, ""index_value_is_delta_encoded"": 1, ""filter_size"": 0, ""raw_key_size"": 26, ""raw_average_key_size"": 13, ""raw_value_size"": 15, ""raw_average_value_size"": 7, ""num_data_blocks"": 1, ""num_entries"": 2, ""num_deletions"": 0, ""num_merge_operands"": 0, ""num_range_deletions"": 0, ""format_version"": 0, ""fixed_key_len"": 0, ""filter_policy"": """", ""column_family_name"": ""sample_dataset"", ""column_family_id"": 3, ""comparator"": ""leveldb.BytewiseComparator"", ""merge_operator"": ""nullptr"", ""prefix_extractor_name"": ""nullptr"", ""property_collectors"": ""[]"", ""compression"": ""ZSTD"", ""compression_options"": ""window_bits=-14; level=2; strategy=0; max_dict_bytes=0; zstd_max_train_bytes=0; enabled=0; "", ""creation_time"": 1590146584, ""oldest_key_time"": 1590146579, ""file_creation_time"": 1590146584}}
2020/05/22-13:23:04.597119 7f33f37fe700 [ush_job.cc:395] [sample_dataset] [JOB 7] Level-0 flush table #27: 833 bytes OK
2020/05/22-13:23:04.663442 7f33f37fe700 (Original Log Time 2020/05/22-13:23:04.613287) [mtable_list.cc:447] [sample_dataset] Level-0 commit table #27 started
2020/05/22-13:23:04.663452 7f33f37fe700 (Original Log Time 2020/05/22-13:23:04.663307) [mtable_list.cc:503] [sample_dataset] Level-0 commit table #27: memtable #1 done
2020/05/22-13:23:04.663457 7f33f37fe700 (Original Log Time 2020/05/22-13:23:04.663343) EVENT_LOG_v1 {""time_micros"": 1590146584663332, ""job"": 7, ""event"": ""flush_finished"", ""output_compression"": ""ZSTD"", ""lsm_state"": [1, 0, 0, 0], ""immutable_memtables"": 0}
2020/05/22-13:23:04.663462 7f33f37fe700 (Original Log Time 2020/05/22-13:23:04.663392) [_impl/db_impl_compaction_flush.cc:205] [sample_dataset] Level summary: files[1 0 0 0] max score 0.25
2020/05/22-13:23:04.663551 7f33fc5e8f00 [_impl/db_impl_compaction_flush.cc:1318] [sample_dataset] Manual flush finished, status: OK
2020/05/22-13:23:04.663567 7f33fc5e8f00 [_impl/db_impl_compaction_flush.cc:1307] [sampleset] Manual flush start.
2020/05/22-13:23:04.663588 7f33fc5e8f00 [_impl/db_impl_write.cc:1669] [sampleset] New memtable created with log file: #22. Immutable memtables: 0.
2020/05/22-13:23:04.663740 7f33f27fc700 (Original Log Time 2020/05/22-13:23:04.663683) [_impl/db_impl_compaction_flush.cc:2197] Calling FlushMemTableToOutputFile with column family [sampleset], flush slots available 2, compaction slots available 6, flush slots scheduled 2, compaction slots scheduled 0
2020/05/22-13:23:04.663751 7f33f27fc700 [ush_job.cc:320] [sampleset] [JOB 9] Flushing memtable with next log file: 22
2020/05/22-13:23:04.663780 7f33f27fc700 EVENT_LOG_v1 {""time_micros"": 1590146584663769, ""job"": 9, ""event"": ""flush_started"", ""num_memtables"": 1, ""num_entries"": 7, ""num_deletes"": 0, ""total_data_size"": 109, ""memory_usage"": 597, ""flush_reason"": ""Manual Flush""}
2020/05/22-13:23:04.663786 7f33f27fc700 [ush_job.cc:349] [sampleset] [JOB 9] Level-0 flush table #28: started
2020/05/22-13:23:04.705399 7f33f27fc700 EVENT_LOG_v1 {""time_micros"": 1590146584705340, ""cf_name"": ""sampleset"", ""job"": 9, ""event"": ""table_file_creation"", ""file_number"": 28, ""file_size"": 858, ""table_properties"": {""data_size"": 86, ""index_size"": 28, ""index_partitions"": 0, ""top_level_index_size"": 0, ""index_key_is_user_key"": 1, ""index_value_is_delta_encoded"": 1, ""filter_size"": 0, ""raw_key_size"": 84, ""raw_average_key_size"": 14, ""raw_value_size"": 1, ""raw_average_value_size"": 0, ""num_data_blocks"": 1, ""num_entries"": 6, ""num_deletions"": 0, ""num_merge_operands"": 0, ""num_range_deletions"": 0, ""format_version"": 0, ""fixed_key_len"": 0, ""filter_policy"": """", ""column_family_name"": ""sampleset"", ""column_family_id"": 2, ""comparator"": ""leveldb.BytewiseComparator"", ""merge_operator"": ""nullptr"", ""prefix_extractor_name"": ""nullptr"", ""property_collectors"": ""[]"", ""compression"": ""ZSTD"", ""compression_options"": ""window_bits=-14; level=2; strategy=0; max_dict_bytes=0; zstd_max_train_bytes=0; enabled=0; "", ""creation_time"": 1590146584, ""oldest_key_time"": 1590146579, ""file_creation_time"": 1590146584}}
2020/05/22-13:23:04.705455 7f33f27fc700 [ush_job.cc:395] [sampleset] [JOB 9] Level-0 flush table #28: 858 bytes OK
2020/05/22-13:23:04.755335 7f33f27fc700 (Original Log Time 2020/05/22-13:23:04.721839) [mtable_list.cc:447] [sampleset] Level-0 commit table #28 started
2020/05/22-13:23:04.755345 7f33f27fc700 (Original Log Time 2020/05/22-13:23:04.755201) [mtable_list.cc:503] [sampleset] Level-0 commit table #28: memtable #1 done
2020/05/22-13:23:04.755350 7f33f27fc700 (Original Log Time 2020/05/22-13:23:04.755251) EVENT_LOG_v1 {""time_micros"": 1590146584755226, ""job"": 9, ""event"": ""flush_finished"", ""output_compression"": ""ZSTD"", ""lsm_state"": [2, 0, 0, 0], ""immutable_memtables"": 0}
2020/05/22-13:23:04.755355 7f33f27fc700 (Original Log Time 2020/05/22-13:23:04.755286) [_impl/db_impl_compaction_flush.cc:205] [sampleset] Level summary: files[2 0 0 0] max score 0.50
2020/05/22-13:23:04.755443 7f33fc5e8f00 [_impl/db_impl_compaction_flush.cc:1318] [sampleset] Manual flush finished, status: OK
2020/05/22-13:23:04.755483 7f33fc5e8f00 [_impl/db_impl.cc:401] Shutdown: canceling all background work
2020/05/22-13:23:04.756386 7f33fc5e8f00 [_impl/db_impl.cc:582] Shutdown complete
```",N/A,https://github.com/dnanexus-rnd/GLnexus/issues/220
MDU6SXNzdWU2MjUzNjU2MjY=,tech debt: unaligned capnproto messages from rocksdb,OPEN,2020-05-27T04:25:01Z,2020-05-27T04:25:01Z,,"BCFKeyValueData works with capnp messages stored in RocksDB table blocks, which don't provide word alignment for the tightly packed values. Non-aligned reads have been disabled in capnp 0.8.0 (https://github.com/capnproto/capnproto/pull/977) for what sound like good reasons. Reinvestigate how much to worry about this from the links below and concerns described in the capnp diff. If necessary, memcpy the RocksDB values into an aligned buffer before opening the capnp reader on them; which would be a bummer, but probably not really a large cost compared to the binary search and parsing we then undertake within.

https://github.com/dnanexus-rnd/GLnexus/blob/4d057dcf24b68b33de7a9759ae65ca2b144a3d47/src/BCFKeyValueData.cc#L459-L474",mlin,https://github.com/dnanexus-rnd/GLnexus/issues/221
MDU6SXNzdWU2MzEyNDAxNDE=,Genotype column name,OPEN,2020-06-05T01:09:47Z,2020-06-06T16:19:06Z,,"Hey guys,

Probably a stupid question but is there a way (or a simple to add feature?) to choose the name of the genotype fields when creating a merged pVCF?  For example, I am trying to create a pVCF using UK Biobank data, and there are ~50,000 gVCFs, and I need to use the filename of the .gz files because they have a specific encrypted ID that is specific to my project.  The IDs inside the file have been extracted in your command, which I am guessing is the correct use in most cases, but in my case those IDs are wrong and specific to whomever made the gVCFs in the first place.  

e.g. for file NEWNUMBER_23176_0_0.gz

```
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  UKB_SOME_NUMBER
```
replace with

```
#CHROM  POS     ID      REF     ALT     QUAL    FILTER  INFO    FORMAT  NEWNUMBER
```

Is there a simple fix for this?

Best regards,

Jim",jimhavrilla,https://github.com/dnanexus-rnd/GLnexus/issues/223
MDU6SXNzdWU2MzE4MDI0MDI=,QUAL score correlating to number of variant samples?,OPEN,2020-06-05T17:56:01Z,2020-06-07T09:49:56Z,,"Hello, we have an inlab discussion about that, basically, that QUAL value is somehow directly related to the number of samples having variant sites. 

In practice though, it doesn't seem to be the case, as I have many instances of an allele shared by many sample but with a poor QUAL score. 

Could you elaborate a bit on how exactly QUAL is computed? if I understand well, if among 10 samples, 9 homozygote reference, if one has a SNP well supported from it's original vcf, that whole line will get a relatively high QUAL score, right? 

In other words, let's say I am interested in SNP occurring in only 1 of my 11 samples, should I then not filter on QUAL? 

I made a quick plot of the QUAL per number of shared variants (1 means variant is private to a single sample, 2 means the variants is shared by 2 samples, etc ) 

![QUAL_shared_Variant](https://user-images.githubusercontent.com/23341393/83914334-56f10300-a771-11ea-8bec-28ec18c97079.png)

It seems to me not filtering on QUAL would enrich drastically in poor quality calls, while not really increasing the number of private variants.",N/A,https://github.com/dnanexus-rnd/GLnexus/issues/224
MDU6SXNzdWU2MzMyNDA2MTk=,No space on device error,CLOSED,2020-06-07T09:35:08Z,2020-07-07T23:41:03Z,2020-07-07T22:24:58Z,"So, when I try to merge 49,953 gVCFs into a pVCF for just chromosome 22 using the command (passed into docker image via `bash -c`) :

`glnexus_cli --config weCall_unfiltered --bed in/chroms/chr22.bed in/fixedgvcfs/*.gz > in/ukbchr22.bcf`

I get the following error at about 28k samples loaded:

```
[2020-06-06 20:14:31.449] [GLnexus] [info] Loaded 28399 datasets with 28399 samples; 12751105984064 bytes in 123428107856 BCF records (74432681 duplicate) in 1065073421 buckets. Bucket max 213584 bytes, 1865 records. 0 BCF records skipped due to caller-specific exceptions
[7] [2020-06-06 21:45:14.525] [GLnexus] [error] Failed to bulk load into DB: IOError: RocksDB kIOError (IO error: No space left on deviceWhile appending to file: GLnexus.DB/000995.sst: No space left on device)
```

Now I understand this is a large file, but I should have ~10TB left on my device and all of the full gVCFs combined and their tabix files only add up to 3.4TB, so why is it taking up `12751105984064 ` bytes (12.7 TB!) just for chromosome 22?  I'm hoping I'm just being dumb and the command is wrong but this seems pretty crazy to me.

Thanks in advance,

Jim",jimhavrilla,https://github.com/dnanexus-rnd/GLnexus/issues/225
MDU6SXNzdWU2MzY5Mjg0Nzk=,Why was this site rejected,OPEN,2020-06-11T11:12:14Z,2020-06-11T19:36:12Z,,"Hello,

from Deepvariant, in one gVCF I have the following

```
Chrom_3	7768199	.	C	T,<*>	6.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:7:81:55,24,0:0.296296,0:5,0,48,990,990,990
```

However, it doesn't seem to have been kept in the final pVCF. I suppose it comes from the ratio of AQ (computed from PL, right)? 

In that case, for DeepVariant WGS, would setting

min_AQ1: 0
min_AQ2: 0

Have the effect of keeping all variants? If I understand well, the preset for Deepvariant WGS are just to filter on AQ. Therefore I tried a custom yaml 


```
cat config_custom.yml
 unifier_config:
        min_AQ1: 0
        min_AQ2: 0
        min_GQ: 0
        monoallelic_sites_for_lost_alleles: true
        max_alleles_per_site: 32
    genotyper_config:
        required_dp: 0
        revise_genotypes: true
        allow_partial_data: true
        more_PL: true
        trim_uncalled_alleles: true
        liftover_fields:
            - orig_names: [MIN_DP, DP]
              name: DP
              description: '##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">'
              type: int
              combi_method: min
              number: basic
              count: 1
              ignore_non_variants: true
            - orig_names: [AD]
              name: AD
              description: '##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">'
              type: int
              number: alleles
              combi_method: min
              default_type: zero
              count: 0
            - orig_names: [GQ]
              name: GQ
              description: '##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">'
              type: int
              number: basic
              combi_method: min
              count: 1
              ignore_non_variants: true
            - orig_names: [PL]
              name: PL
              description: '##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">'
              type: int
              number: genotype
              combi_method: missing
              count: 0
              ignore_non_variants: true

```

but then I get

```
./GLnexus/glnexus_cli --config config_custom.yml  *.g.vcf.gz|bcftools view|bgzip -@ 8 -c > joint_noAQfilter.vcf.gz
[17095] [2020-06-11 13:18:04.730] [GLnexus] [info] glnexus_cli release v1.2.6-0-g4d057dc Thu Mar 19 09:26:57 2020
[17095] [2020-06-11 13:18:04.730] [GLnexus] [warning] jemalloc absent, which will impede performance with high thread counts. See https://github.com/dnanexus-rnd/GLnexus/wiki/Performance
[17095] [2020-06-11 13:18:04.730] [GLnexus] [info] Loading config YAML file config_custom.yml
[17095] [2020-06-11 13:18:04.730] [GLnexus] [error] Failed to load unifier/genotyper configuration: IOError: loading configuration YAML file (config_custom.yml)
Failed to read from standard input: unknown file type

```",N/A,https://github.com/dnanexus-rnd/GLnexus/issues/226
MDU6SXNzdWU2NDQ0ODI5MzI=,IOError: reading gVCF header,CLOSED,2020-06-24T09:56:18Z,2020-06-25T07:27:57Z,2020-06-25T07:27:57Z,"Hello,

I was trying to merge gvcf files using the following command,
glnexus_cli --config DeepVariantWGS -a --threads 24 vcfs/*gvcf -m 32 1>vcfs/merged.gvcf 2>err.log

(version: glnexus_v1.2.3)

And here is the error message I got.

```
[E::bcf_hdr_read] Input is not detected as bcf or vcf format
[190977] [2020-06-24 09:03:04.774] [GLnexus] [info] 100 (Ox.sub1)...
[190392] [2020-06-24 09:16:57.945] [GLnexus] [info] Loaded 169 datasets with 169 samples; 417362543352 bytes in 4662497125 BCF records (313 duplicate) in 6440421 buckets. Bucket max 1162624 bytes, 12613 records. 0 BCF records skipped due to caller-specific exceptions
[190392] [2020-06-24 09:16:57.946] [GLnexus] [info] Created sample set *@169
[190392] [2020-06-24 09:16:57.946] [GLnexus] [error] vcfs/merged.gvcf IOError: reading gVCF header (vcfs/merged.gvcf)
[190392] [2020-06-24 09:29:05.037] [GLnexus] [error] Failed to bulk load into DB: Failure: One or more gVCF inputs failed validation or database loading; check log for details.

```

Any help would be greatly appreciated!

Zoe",zoeluo15,https://github.com/dnanexus-rnd/GLnexus/issues/227
MDU6SXNzdWU2NDkzMDI3ODI=,container error,OPEN,2020-07-01T20:36:07Z,2020-07-02T19:04:44Z,,"When I try to run glnexus_cli the container errors out with the same error when passing the data to the container and also when trying to run from within the container.
Error: Illegal instruction (core dumped)
root@c5e334faee93:/# glnexus_cli --config DeepVariant /in/*.g.vcf.gz
Illegal instruction (core dumped)
docker run --rm -i -v $(pwd)/dv_1000G_ALDH2_gvcf:/in quay.io/mlin/glnexus:vX.Y.Z \
    bash -c 'glnexus_cli --config DeepVariant /in/*.g.vcf.gz' > dv_1000G_ALDH2.bcf
I have also tried versions 1.26---1.1.12 and all resulted in the same error.
 
Please let me know if you have any thoughts on this error.",paniscusJr,https://github.com/dnanexus-rnd/GLnexus/issues/228
MDU6SXNzdWU2Njc4OTgwNTU=,What assumptions remain if one deactivate the specific filters,OPEN,2020-07-29T14:39:00Z,2020-08-13T07:20:28Z,,"Hello,

let us say we are using GLNexus for joint-calling of variants. If we specify a yaml that has no criteria (so, no minimal AQ, etc ...) how does the joint-calling still differ from, for example, bcftools merge ? 

thank you",N/A,https://github.com/dnanexus-rnd/GLnexus/issues/231
MDU6SXNzdWU2NzczNDA2OTc=,Deepvariant gvcfs merge error,OPEN,2020-08-12T02:50:39Z,2020-11-04T01:08:23Z,,"I tried to merge the trios' gvcf files which generate by DeepVariant and the command and error message show like below:

`./glnexus_cli --config DeepVariantWES --bed exon.bed HY20080095.gvcf HY20080096.gvcf HY20080097.gvcf`

> [6563] [2020-08-12 10:18:15.554] [GLnexus] [info] glnexus_cli release v1.2.6-2-gca0e9b7 Aug 10 2020
> [6563] [2020-08-12 10:18:15.554] [GLnexus] [warning] jemalloc absent, which will impede performance with high thread counts. See https://github.com/dnanexus-rnd/GLnexus/wiki/Performance
> [6563] [2020-08-12 10:18:15.554] [GLnexus] [info] Loading config preset DeepVariantWES
> [6563] [2020-08-12 10:18:15.566] [GLnexus] [info] config:
> unifier_config:
>   drop_filtered: false
>   min_allele_copy_number: 1
>   min_AQ1: 35
>   min_AQ2: 20
>   min_GQ: 20
>   max_alleles_per_site: 32
>   monoallelic_sites_for_lost_alleles: true
>   preference: common
> genotyper_config:
>   revise_genotypes: true
>   min_assumed_allele_frequency: 9.99999975e-05
>   required_dp: 0
>   allow_partial_data: true
>   allele_dp_format: AD
>   ref_dp_format: MIN_DP
>   output_residuals: false
>   more_PL: true
>   squeeze: false
>   trim_uncalled_alleles: true
>   output_format: BCF
>   liftover_fields:
>     - {orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
>     - {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}
>     - {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
>     - {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}
> [6563] [2020-08-12 10:18:15.567] [GLnexus] [info] config CRC32C = 4105299981
> [6563] [2020-08-12 10:18:15.567] [GLnexus] [info] init database, exemplar_vcf=HY20080095.gvcf
> [6563] [2020-08-12 10:18:15.570] [GLnexus] [error] Failed to initialize database: Invalid: RocksDB kInvalidArgument (Invalid argument: Compression type ZSTD is not linked with the binary.)

How to fix that? thanks for your time.",Johnnywang92,https://github.com/dnanexus-rnd/GLnexus/issues/232
MDU6SXNzdWU2Nzc0NzI5MzU=,N+1 calling,OPEN,2020-08-12T07:43:30Z,2022-12-21T01:20:15Z,,"Hi,

We're attempting to use GLnexus to joint call the UKbiobank gvcfs alongside batches of in-house exomes. We will be regularly adding to this calling set. From the GLnexus paper it looks like the rocksDB can be updated with new samples for subsequent  joint calling but i can't figure out how to do this using the docker container. I can get a single joint call working, but if I use the same DB with additional samples, I get a DB already present error. Is there a way to get this working? Or is it reserved for the DNAnexus version?

Thanks for your time,

Dan",danchubb,https://github.com/dnanexus-rnd/GLnexus/issues/233
MDU6SXNzdWU2OTk2MTI0ODU=,Octopus joint genotyping config,OPEN,2020-09-11T18:22:18Z,2022-06-15T07:36:22Z,,"Hello, I am trying to do joint genotyping with gvcfs produced by the [Octopus](https://github.com/luntergroup/octopus) variant caller. There isn't a preset (yet?) so I am trying to roll my own but glnexus wont read what I have written.

`[error] Failed to load unifier/genotyper configuration: IOError: loading configuration YAML file (octopus.yml)`

This is a rather cryptic error message so I was hoping you could help.

Here is my config file:

[octopus.zip](https://github.com/dnanexus-rnd/GLnexus/files/5210897/octopus.zip)

I am assuming I don't need to add the GT or DP format fields.

Cheers,

Max H.",DiDeoxy,https://github.com/dnanexus-rnd/GLnexus/issues/234
MDU6SXNzdWU2OTk2ODYwNDM=,Support for Octopus VCF files,OPEN,2020-09-11T19:47:46Z,2020-09-16T15:12:03Z,,"Octopus has a unique way of reporting alleles when the start at the same position on the reference but end at different positions. They indicate this with a * character. You can read more about it here: https://github.com/luntergroup/octopus/wiki/VCF-format

Would it be possible to support this?",DiDeoxy,https://github.com/dnanexus-rnd/GLnexus/issues/235
MDU6SXNzdWU3MDQwOTQ4NjM=,GLnexus.DB,OPEN,2020-09-18T05:24:09Z,2020-09-18T20:19:46Z,,Does glnexus only load variants contained in the bed file into the db? or all of the variants?,xshah,https://github.com/dnanexus-rnd/GLnexus/issues/236
MDU6SXNzdWU3MDk3NzkzNDI=,combine gvcf files with different contigs,OPEN,2020-09-27T17:19:56Z,2024-04-11T19:57:53Z,,"Hi @mlin 
I want to merge two big sets of gvcf files, one set has the contig of `hs37d5`, the other don't. When I tried to run glnexus_cli, I got the following error:

```
[7451] [2020-09-24 17:19:06.680] [GLnexus] [error] /users/hl7/SB969883.SNP.gvcf.gz Invalid: Incompatible gVCF. The reference contigs must match the database configuration exactly. (/users/hl7/SB969883.SNP.gvcf.gz)
``` 
The loading runs fine until the program sees a samples with different contigs.  
I'm wondering if there is any easy way to specify the contigs that needs to be loaded, or somehow bypass this validation procedure. Previously I just add / remove the different contig names from the gvcf file, but this project is kind of big with ~10k samples from each set...  
Any suggestions would be appreciated!  

This might be related to #236 

Thanks!
Hurley
",hurleyLi,https://github.com/dnanexus-rnd/GLnexus/issues/238
MDU6SXNzdWU3MTYxMDEzNDk=,Merge Error with Octopus GVCFs,OPEN,2020-10-07T00:09:32Z,2020-10-07T00:09:32Z,,"Getting error:

[248444] [2020-10-06 19:13:24.830] [GLnexus] [error] Failed to genotype: NotImplemented: genotyper StringFormatFieldHelper::add_record_data

Config file:
```
unifier_config:
    min_AQ1: 0
    min_AQ2: 0
    min_GQ: 0
    monoallelic_sites_for_lost_alleles: true
genotyper_config:
    required_dp: 0
    revise_genotypes: false
    liftover_fields:
        - orig_names: [DP]
          name: DP
          description: '##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth at this position for this sample"">'
          type: int
          number: basic
          combi_method: min
          count: 1
          ignore_non_variants: true
        - orig_names: [FT]
          name: FT
          description: '##FORMAT=<ID=FT,Number=1,Type=String,Description=""Sample genotype filter indicating if this genotype was called"">'
          type: string
          number: basic
          combi_method: semicolon
          count: 1
          ignore_non_variants: true
        - orig_names: [PS]
          name: PS
          description: '##FORMAT=<ID=PS,Number=1,Type=String,Description=""Phase set"">'
          type: string
          number: basic
          combi_method: missing
          count: 0
          ignore_non_variants: true
        - orig_names: [PQ]
          name: PQ
          description: '##FORMAT=<ID=PQ,Number=1,Type=Integer,Description=""Phasing quality"">'
          type: int
          number: basic
          combi_method: missing
          count: 1
          ignore_non_variants: true
        - orig_names: [MQ]
          name: MQ
          description: '##FORMAT=<ID=MQ,Number=1,Type=Integer,Description=""RMS mapping quality"">'
          type: int
          number: genotype
          combi_method: missing
          count: 1
          ignore_non_variants: true
```

Just looking to merge, not joint genotype.",DiDeoxy,https://github.com/dnanexus-rnd/GLnexus/issues/239
MDU6SXNzdWU3MjAyMjgyNDE=,Working without SSD,CLOSED,2020-10-13T13:08:17Z,2020-10-14T07:56:55Z,2020-10-14T07:56:55Z,"Your performance consideration article states that due to a large number of intensive sorting operations one should use local SSD.

Can you clarify this further, preferably in the official documentation:
1. Is using a regular local HDD bad because it would slow down the operation somewhat, or would it cause wear of the HDD head, or would it affect it in some other way?
2. Does that mean that network mounted input files are OK as long as the output files are on local SSD?

Thanks!",OgnjenMilicevic,https://github.com/dnanexus-rnd/GLnexus/issues/240
MDU6SXNzdWU3MjIxNTU5MDc=,Deepvariant vfc merge fail with docker,CLOSED,2020-10-15T09:19:42Z,2022-03-09T07:03:38Z,2020-10-15T11:48:12Z,"hi,

similar to #232 , I get the same error, but while I am using the latest docker image. 
the .vcf files are created with Deepvariant 1.0.0 and I am using the image `quay.io/mlin/glnexus:v1.2.7`
the ""getting started"" example works perfectly in the image. the only difference is I am reading the files from separate folders but this should not matter.

the 3 small example vcf files used (on MT chrom): [error_vcf.zip](https://github.com/dnanexus-rnd/GLnexus/files/5383649/error_vcf.zip)

the (default) command used:
```
docker run --rm -i  \
	-v /path/error_vcf:""/in""  \
	quay.io/mlin/glnexus:v1.2.7  \
    bash -c ""glnexus_cli --config DeepVariant /in/*/*.g.vcf.gz"" # > glnexus_out.bcf
```

please ask if you need additional information,
thank you  for your help 



the error:
```
[1] [2020-10-15 09:08:30.374] [GLnexus] [info] glnexus_cli release v1.2.7-0-g0e74fc4 Aug 13 2020
[1] [2020-10-15 09:08:30.374] [GLnexus] [info] detected jemalloc 5.2.1-0-gea6b3e973b477b8061e0076bb257dbd7f3faa756
[1] [2020-10-15 09:08:30.374] [GLnexus] [info] Loading config preset DeepVariant
[1] [2020-10-15 09:08:30.379] [GLnexus] [info] config:
unifier_config:
  drop_filtered: false
  min_allele_copy_number: 1
  min_AQ1: 10
  min_AQ2: 10
  min_GQ: 0
  max_alleles_per_site: 32
  monoallelic_sites_for_lost_alleles: true
  preference: common
genotyper_config:
  revise_genotypes: true
  min_assumed_allele_frequency: 9.99999975e-05
  required_dp: 0
  allow_partial_data: true
  allele_dp_format: AD
  ref_dp_format: MIN_DP
  output_residuals: false
  more_PL: true
  squeeze: false
  trim_uncalled_alleles: true
  output_format: BCF
  liftover_fields:
    - {orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
    - {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}
    - {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
    - {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}
[1] [2020-10-15 09:08:30.379] [GLnexus] [info] config CRC32C = 2857227159
[1] [2020-10-15 09:08:30.379] [GLnexus] [info] init database, exemplar_vcf=/in/DRR023395/DRR023395.g.vcf.gz
[1] [2020-10-15 09:08:30.485] [GLnexus] [info] Initialized GLnexus database in GLnexus.DB
[1] [2020-10-15 09:08:30.485] [GLnexus] [info] bucket size: 30000
[1] [2020-10-15 09:08:30.485] [GLnexus] [info] contigs: MT
[1] [2020-10-15 09:08:30.525] [GLnexus] [info] db_get_contigs GLnexus.DB
[1] [2020-10-15 09:08:30.600] [GLnexus] [info] Beginning bulk load with no range filter.
[1] [2020-10-15 09:08:30.609] [GLnexus] [info] Loaded 2 datasets with 1 samples; 126952 bytes in 1431 BCF records (0 duplicate) in 2 buckets. Bucket max 99648 bytes, 1121 records. 0 BCF records skipped due to caller-specific exceptions
[1] [2020-10-15 09:08:30.609] [GLnexus] [info] Created sample set *@2
[1] [2020-10-15 09:08:30.609] [GLnexus] [error] /in/ERR1275204/ERR1275204.g.vcf.gz Exists: sample is currently being added (default (/in/ERR1275204/ERR1275204.g.vcf.gz))
[1] [2020-10-15 09:08:30.672] [GLnexus] [error] Failed to bulk load into DB: Failure: One or more gVCF inputs failed validation or database loading; check log for details.
```




",loipf,https://github.com/dnanexus-rnd/GLnexus/issues/241
MDU6SXNzdWU3MzU3NTE5NTk=,Running out space,OPEN,2020-11-04T01:54:53Z,2021-04-02T21:56:45Z,,"Hi,

The GLnexus team have an estimation of how much space in HD is required, compared to the sizes of the .gvcfs?


Cheers. ",leorippel,https://github.com/dnanexus-rnd/GLnexus/issues/242
MDU6SXNzdWU3NDIxMTQ4NDA=,Assertion `end_offset >= start_offset' failed,OPEN,2020-11-13T03:57:42Z,2020-11-13T03:57:42Z,,"Hi,
I got this error when I run GLnexus
```
[19454] [2020-11-11 22:00:15.485] [GLnexus] [info] Loaded 10409 datasets with 10409 samples; 2336168480176 bytes in 15722891405 BCF records (83322179 duplicate) in 429273641 buckets. Bucket max 736880 bytes, 4797 records. 23199252 BCF records skipped due to caller-specific exceptions
[19454] [2020-11-11 22:00:15.678] [GLnexus] [info] Created sample set *@10409
[19454] [2020-11-11 22:00:15.678] [GLnexus] [info] Flushing database...
[19454] [2020-11-11 22:00:29.146] [GLnexus] [info] Bulk load complete!
[19454] [2020-11-11 22:00:29.154] [GLnexus] [warning] Processing full length of 86 contigs, as no --bed was provided. Providing a BED file with regions of interest, if applicable, can speed this up.
[19454] [2020-11-11 22:00:29.190] [GLnexus] [info] found sample set *@10409
[19454] [2020-11-11 22:00:29.190] [GLnexus] [info] discovering alleles in 86 range(s) on 2 threads
glnexus_cli: /hgsc_software/7.x/glnexus/src/GLnexus-1.2.6/external/src/rocksdb/table/block_based/block_based_table_reader.cc:4041: virtual uint64_t rocksdb::BlockBasedTable::ApproximateSize(const rocksdb::Slice&, const rocksdb::Slice&, rocksdb::TableReaderCaller): Assertion `end_offset >= start_offset' failed.
/var/spool/torque/mom_priv/jobs/2817137.sug-moab.SC: line 1: 19454 Aborted                 /hgsc_software/software/GLnexus/1.2.6/bin/glnexus_cli --config xAtlas --list filelist -m 40 -t 4 > merged.INDEL.bcf
```
This only occur when I tried to merge INDELs, and all the individual gvcf files (from exome sequencing) are sorted and indexed.  

Just wondering what might cause this issue.

Thanks!
Hurley
",hurleyLi,https://github.com/dnanexus-rnd/GLnexus/issues/243
MDU6SXNzdWU3NzY3MDc0OTU=,Bulk load error ,OPEN,2020-12-31T01:33:50Z,2020-12-31T01:33:50Z,,"Hello

I have an error, During the glnexus program.

![image](https://user-images.githubusercontent.com/27615279/103389618-4e1fae80-4b53-11eb-8dd1-44195c2a6b19.PNG)

server has enough capacity.

This error occurs when more than 10 samples are analyzed.

Is there a solution? thanks.",mellowo,https://github.com/dnanexus-rnd/GLnexus/issues/245
MDU6SXNzdWU3ODE2OTIzNDY=,gvcf_manifest issues,OPEN,2021-01-07T23:11:17Z,2021-02-17T21:41:09Z,,"Hi.

I have been trying to use GLnexus with a list of gvcfs. I have tried all different ways to point to the vcfs with a vcf on each line and I keep getting the following error when running via DNAnexusy.

2021-01-07 18:08:50 GLnexus STDERR ResolutionError: Unable to resolve ""DRR132536.cancer.vcf"" to a data object or folder name in '/'
2021-01-07 18:08:50 GLnexus STDERR ResolutionError: Unable to resolve ""DRR131656.cancer.vcf"" to a data object or folder name in '/'
* GLnexus (failed) job-Fzqk8jj06F16vzZgFXzygy7b
  mpagadala 2021-01-07 18:08:19 (runtime 0:00:25)
  AppInternalError: Please consult the job log; the job's reported error could not be parsed from
  the file job_error.json

This is the command:
dx run ../tools/GLnexus -i gvcf_manifest=cancer.list.txt -i output_name=PRJDB6952.cancer -i bed_ranges_to_genotype=../hg38.chromsizes

Thanks!",meghatron21,https://github.com/dnanexus-rnd/GLnexus/issues/246
MDU6SXNzdWU3OTk1MjkyODQ=,allele fequency calculation,OPEN,2021-02-02T18:00:00Z,2023-10-10T17:40:31Z,,"I am using Deepvariant to obtain vcf files for single individuals and merge these files with GLnexus. I am having 2 issues.

1) I observed that a 0/0 is coded if an individual is homozygous reference at a certain position but also if no data was available for the individual at this position. So missing data gets treated as homozygous reference (while it should be ./.).  

2) Regarding the allele frequency calculation it appears that both ./. and 0/0 are treated as homozygous reference resulting in allele frequencies which are off (too low with regard to the alt allele).

Could you tell me how to fix this?
Thank you very much Laura",lahage,https://github.com/dnanexus-rnd/GLnexus/issues/247
MDU6SXNzdWU4MDE0MDY1NTk=,Copying applet to target directory,OPEN,2021-02-04T15:48:05Z,2021-02-04T20:43:31Z,,"Hi.

I have tried to copy GLnexus to my directory using the DNanexus platform, but am unable to do so, because my project is in a different area. I tried downloading the source code and and building using dx build, however, I'm getting the following error. 

Error: ('make -j8 in target directory failed with exit code 2',)

Not quite sure what is going on. Any help would be appreciated.",meghatron21,https://github.com/dnanexus-rnd/GLnexus/issues/248
MDU6SXNzdWU4MTAwNDk1MTg=,AVX Instructions and jemalloc,OPEN,2021-02-17T10:21:02Z,2021-03-08T14:06:26Z,,"Hi there,

thanks for providing this great tool. Unfortunately I have run into issues executing the default Docker container on (very) old hardware (`march=(amdfam10|westmere)`), on those I get `Illegal Instruction (core dumped)` errors. While the tool runs fine on contemporary hardware, given that we still run a sizeable amount of these legacy systems I would like to get the tool to work on these systems as well.

To do so, I create a singularity image following the same steps from the Dockerfile provided in the repository, with some changes to the `CMakeLists.txt`:

```bash
# Modify march and mtune to set SIMD Preferences
MARCH=$(gcc -march=native -Q --help=target | grep march | cut -f3)
sed -ie ""s/ivybridge/$MARCH/g"" CMakeLists.txt
sed -ie ""s/-msse4.2//g"" CMakeLists.txt
sed -ie ""s/-DHAVE_SSE42//g"" CMakeLists.txt
sed -ie ""s#USE_SSE=1#UKNOWN_VARIABLE=1#g"" CMakeLists.txt
```

This builds fine, however when running the resulting executable or invoking `ctest -v` it throws the `false-positive jemalloc warning` error of `test/jemalloc_linkig.sh`. This is a result of the executable not being able to detect jemalloc support (i think). However jemalloc is installed and linked (`LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libjemalloc.so.2`).

Are there some further steps I need to do to enable jemalloc support for the executable? Is it possible that the glnexus_cli will issue the warning despite jemalloc being loaded and subsequently used? Is there any way for me to tell whether jemalloc is actually used by glnexus_cli?",brand-fabian,https://github.com/dnanexus-rnd/GLnexus/issues/250
MDU6SXNzdWU4Mjk3OTUyMjM=,gVCF ordering,OPEN,2021-03-12T06:16:34Z,2021-03-19T03:05:13Z,,"Hi.

I'm trying to merge ~500 gvcf files, but they are failing at the validation step:

[88309] [2021-03-10 04:32:58.726] [GLnexus] [info] Created sample set *@555
[88309] [2021-03-10 04:32:58.727] [GLnexus] [error] SKLJKDS.WholeGenome.g.vcf.gz Invalid: gVCF records are out-of-order  (SKLJKDS..WholeGenome.g.vcf.gz 21202249 >= chr17:0--1)
[88309] [2021-03-10 04:32:58.728] [GLnexus] [error] LSJDAKSD.WholeGenome.g.vcf.gz Invalid: gVCF records are out-of-order  (LSJDAKSD.WholeGenome.g.vcf.gz 41352891 >= chr19:413-412)
[88309] [2021-03-10 12:22:14.099] [GLnexus] [error] Failed to bulk load into DB: Failure: One or more gVCF inputs failed validation or database loading; check log for details.

This seems like an issue with the creation of the gVCFs, but I don't have access to the original BAM files to recreate the gVCFs. Is there a way to work around his error without completely excluding the files?",meghatron21,https://github.com/dnanexus-rnd/GLnexus/issues/251
MDU6SXNzdWU4NzIxNTQ4ODc=,question about --bed,CLOSED,2021-04-30T08:24:12Z,2021-05-04T05:05:05Z,2021-05-04T05:05:05Z,"Hi Mike, thanks for the great software.
If I have a setup so I am calling glnexus with a single chromosome (* $n samples), do I need to specify the `--bed` argument with the extent of that chromosome for maximum efficiency? or will glnexus split the work correctly on just the chromosome contained in the set of gvcfs?
thanks,
-Brent",brentp,https://github.com/dnanexus-rnd/GLnexus/issues/252
MDU6SXNzdWU4NzYyNTIyNDM=,"bucket size should be in (1,1e9]",CLOSED,2021-05-05T09:23:59Z,2021-05-05T09:56:21Z,2021-05-05T09:56:21Z,"Hi, 

 I get the following error when running GLnexus . ( without docker, compiled on  Ubuntu 20.04.2 LTS )

```
glnexus_cli -x DeepVariantWES -sequeeze -bed /mnt/R60/bioinformatique/hg38/bed/S33266340_Padded_hg38.noheader.bed OneSegHumanFemale1.deepvariant.gvcf OneSegHumanFemale2.deepvariant.gvcf OneSegHumanFemale3.deepvariant.gvcf OneSegHumanFemale4.deepvariant.gvcf SGT152803pur1.deepvariant.gvcf SGT152803pur2.deepvariant.gvcf SGT153103nonpur1.deepvariant.gvcf SGT153103nonpur2.deepvariant.gvcf > merge.deepvariant.bcf
```

```
[460290] [2021-05-05 09:34:30.760] [GLnexus] [info] glnexus_cli release v1.3.1-0-g0e1c9c9 May  5 2021
[460290] [2021-05-05 09:34:30.760] [GLnexus] [warning] jemalloc absent, which will impede performance with high thread counts. See https://github.com/dnanexus-rnd/GLnexus/wiki/Performance
bucket size should be in (1,1e9]
```
",dridk,https://github.com/dnanexus-rnd/GLnexus/issues/253
MDU6SXNzdWU4ODM5NzUyNDg=,Incorrect variant call,CLOSED,2021-05-10T11:02:57Z,2021-05-11T06:14:51Z,2021-05-11T06:14:51Z,"We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0

Happy to provide a BAM file, gVCFs etc. But maybe this is easy enough to explain; I just cannot figure out why the joint call for this locus comes out as follows:

``` 
chr19   15174241        rs1044006       T       C       66      .       AF=0.75;AQ=66   GT:DP:AD:GQ:PL:RNC      1/1:112:0,112:62:65,63,0:..     1/1:169:0,169:59:61,60,0:..     ./1:78:.,78:.:0,0,0:O.  1/1:208:0,208:62:66,63,0:..     1/1:94:0,94:57:58,60,0:..    0/1:196:96,99:53:52,0,68:..      1/1:156:0,156:58:59,60,0:..     0/1:202:105,97:53:53,0,63:..
chr19   15174242        chr19_15174242_G_C      G       C       58      .       AF=0.0625;AQ=58 GT:DP:AD:GQ:PL:RNC      0/0:112:112,0:50:0,300,2999:..  0/0:170:170,0:50:0,300,2999:..  0/1:177:77,100:56:58,0,60:..    0/0:207:207,0:50:0,300,2999:..  0/0:93:93,0:50:0,282,2819:..  0/0:198:198,0:50:0,300,2999:..  0/0:155:155,0:50:0,300,2999:..  0/0:204:204,0:50:0,300,2999:..

``` 

The corresponding gVCF block from the sample carrying the complex mutation:

```
chr19   15174058        .       G       <*>     0       .       END=15174239    GT:GQ:MIN_DP:PL 0/0:50:97:0,291,2909
chr19   15174240        .       CT      C,<*>   28.1    PASS    .       GT:GQ:DP:AD:VAF:PL      0/1:25:177:78,99,0:0.559322,0:20,0,42,990,990,990
chr19   15174241        .       T       C,<*>   21.3    PASS    .       GT:GQ:DP:AD:VAF:PL      0/1:8:78:0,78,0:1,0:13,0,21,990,990,990
chr19   15174242        .       G       C,<*>   58.5    PASS    .       GT:GQ:DP:AD:VAF:PL      0/1:56:177:77,100,0:0.564972,0:58,0,60,990,990,990
chr19   15174243        .       G       <*>     0       .       END=15174410    GT:GQ:MIN_DP:PL 0/0:50:177:0,300,2999

```
The gVCFs were called with DeepVariant 1.0 - and the per-sample VCFs from that same process show the variant correctly. 

``` 
chr19   15174240        .       CT      C       28.1    PASS    .       GT:GQ:DP:AD:VAF:PL      0/1:25:177:78,99:0.559322:20,0,42
chr19   15174241        .       T       C       21.3    PASS    .       GT:GQ:DP:AD:VAF:PL      0/1:8:78:0,78:1:13,0,21
chr19   15174242        .       G       C       58.5    PASS    .       GT:GQ:DP:AD:VAF:PL      0/1:56:177:77,100:0.564972:58,0,60

``` 

GLNexus version: 1.3.1 (docker)
DeepVariant version: 1.0 (docker)

GLNexus call:

```
/usr/local/bin/glnexus_cli \
                        --config DeepVariantWES \
                        --bed $bed \
                        $gvcfs | bcftools view - | bgzip -c > $merged_vcf
```
",marchoeppner,https://github.com/dnanexus-rnd/GLnexus/issues/254
MDU6SXNzdWU4OTIxNDU3NzY=,VAF liftover_field to pVCF,OPEN,2021-05-14T18:32:14Z,2021-05-18T05:44:59Z,,"We need to have a VAF field present from DeepVariant in a pVCF generated by GLnexus. Is it possible to adjust .yaml file to also include the original VAF field into the pVCF ? 

Thanks!",bopohdr,https://github.com/dnanexus-rnd/GLnexus/issues/255
MDU6SXNzdWU4OTM1NDY1ODU=,Resuming Merging of GVCFs,CLOSED,2021-05-17T17:27:25Z,2021-05-17T20:21:51Z,2021-05-17T20:21:51Z,"Hi.

I am trying to merge ~800 GVCFs that are WGS. It takes some time with GLNexus (14 days). Unfortunately, the job failed after this time; however, the GLnexusDB is still present and I was curious if there was a way to resume progress with the database so progress is not lost.

Thanks,
Meghana
",meghatron21,https://github.com/dnanexus-rnd/GLnexus/issues/256
MDU6SXNzdWU4OTU0NjMzNjI=,GLnexus output,OPEN,2021-05-19T13:42:53Z,2023-03-20T13:53:37Z,,"Hello,
Using GLnexus in a singularity container is not convenient because stdout cannot be redirected.
It would be more efficient to have an --output option in GLnexus than relying on stdout.
Thanks",Fred-07,https://github.com/dnanexus-rnd/GLnexus/issues/257
MDU6SXNzdWU5MTM4MjQ5NjI=,The model underlying GLnexus calling,OPEN,2021-06-07T18:19:30Z,2021-06-07T20:24:27Z,,"Hello,

is it possible to have some infos on the underlying model which decides to keep or reject a variant? If I understood well it's a Bayesian model, right? I would be interested to see the formula and its priors. It's pure curiosity.

Thanks a lot",N/A,https://github.com/dnanexus-rnd/GLnexus/issues/258
MDU6SXNzdWU5MjE4NDMwODY=,"Error message: PL vector length 2, expected 3 - did the job failed?",OPEN,2021-06-15T22:08:30Z,2022-11-08T06:49:44Z,,"I tested the GLnexus Docker image, and tried to combine just two of my WGS gVCF samples to familiarize myselft with the program. I got the error message:

Failed to genotype: Invalid: genotyper: unexpected result when fetching record FORMAT field ([FILE-NAME] <22>:2781480-2781529 PL vector length 2, expected 3)

However, I could convert the BCF to a VCF as instructed in the Get Started page. I see that chrX variants were present in the VCF, but no chrY or alt contigs. Does it mean that the job failed completely or this specific variant was just skipped/filtered and everything is OK? The same for the alt contigs?

Thanks",antoniocampos13,https://github.com/dnanexus-rnd/GLnexus/issues/259
MDU6SXNzdWU5MjUwNTc4OTQ=, Failed to initialize database,OPEN,2021-06-18T16:37:48Z,2021-11-12T10:04:13Z,,"I am running GLnexus on singularity using the command below for the example dataset. Everything is find with the first run, but for the second run I get the following error. Does anyone know how to resolve the issues?  what parameter I have to set in singularity so that it cleans let over files from previous run?
 
singularity run -B $(pwd)/deep_vcf:/in glnexus_v1.3.1.sif bash -c 'glnexus_cli --config DeepVariant /in/*.g.vcf.gz' > ppmi_6samples.bcf
[16130] [2021-06-17 14:03:02.965] [GLnexus] [info] glnexus_cli release v1.3.1-0-g0e1c9c9 Feb 17 2021
[16130] [2021-06-17 14:03:02.965] [GLnexus] [info] detected jemalloc 5.2.1-0-gea6b3e973b477b8061e0076bb257dbd7f3faa756
[16130] [2021-06-17 14:03:02.965] [GLnexus] [info] Loading config preset DeepVariant
[16130] [2021-06-17 14:03:02.971] [GLnexus] [info] config:
unifier_config:
  drop_filtered: false
  min_allele_copy_number: 1
  min_AQ1: 10
  min_AQ2: 10
  min_GQ: 0
  max_alleles_per_site: 32
  monoallelic_sites_for_lost_alleles: true
  preference: common
genotyper_config:
  revise_genotypes: true
  min_assumed_allele_frequency: 9.99999975e-05
  required_dp: 0
  allow_partial_data: true
  allele_dp_format: AD
  ref_dp_format: MIN_DP
  output_residuals: false
  more_PL: true
  squeeze: false
  trim_uncalled_alleles: true
  top_two_half_calls: false
  output_format: BCF
  liftover_fields:
    - {orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
    - {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}
    - {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
    - {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}
[16130] [2021-06-17 14:03:02.971] [GLnexus] [info] config CRC32C = 706912162
[16130] [2021-06-17 14:03:02.971] [GLnexus] [info] init database, exemplar_vcf=/in/PM17-01350-A.g.vcf.gz
[16130] [2021-06-17 14:03:02.972] [GLnexus] [error] Failed to initialize database: IOError: Database directory already exists (GLnexus.DB)",Asppagh,https://github.com/dnanexus-rnd/GLnexus/issues/260
MDU6SXNzdWU5MzIzNzkzMzU=,"The inconsistent output of GLnexus, labeling no call to '0/0'",CLOSED,2021-06-29T08:47:51Z,2021-06-29T10:25:45Z,2021-06-29T10:25:45Z,"Hi,

I found there are inconsistent cases of GLnexus output. I run GLnexus to merge the DeepVariant outputs, but I found a portion of genotypes not called in a single sample is mislabeled as '0/0' in GLnuex output. And the results of GLnexus seem inconsistent when I try to merge VCFs that only contain a single position. 
For example, for the 3 VCFs of DeepVariants called, when I tried to merge all three original gVCFs, the results shown in chr20 position 1258820, the genotype of HG004 is 0/0, and the Approximate read depth is 0, which is wrong.
But then I tried to extract variants at chr20 position 1258820 from each gVCFs to three single records gVCFs in the first place and then feed to GLnexus. GLnexus output the genotype of HG004 as ""./."", which is right.

I attached the command I used and files ([GLnexus_results.zip](https://github.com/dnanexus-rnd/GLnexus/files/6731880/GLnexus_results.zip)) for your reference:

Thanks,
JH
",sujunhao,https://github.com/dnanexus-rnd/GLnexus/issues/263
MDU6SXNzdWU5MzYwODU3MDg=,cannot join g.vcf files using glnexus,CLOSED,2021-07-02T21:57:06Z,2021-07-05T10:27:26Z,2021-07-05T10:27:25Z,"Hi,

When I try to merge gvcf files generated with deepvariant, using glnexus, I get the following error:

`[W::bgzf_read_block] EOF marker is absent. The input is probably truncated Error: BCF read error`

Below is the command that I am using:

`./glnexus_cli \`
`--config DeepVariantWGS \`
`SQU1.sort.pcr_rem.RG.kept.g.vcf.gz SQU3.sort.pcr_rem.RG.kept.g.vcf.gz | \`
`bcftools view - | \`
`bgzip -c > SQU13.vcf.gz`

My gvcf files look normal and the log file for gvcf generation did not give any errors.

Any help will be appreciated.

Thanks",kostasgalexiou,https://github.com/dnanexus-rnd/GLnexus/issues/264
MDU6SXNzdWU5NDcwOTQ3Njc=,Incorrect variant calls,CLOSED,2021-07-18T18:41:02Z,2021-07-18T18:42:59Z,2021-07-18T18:42:58Z,"Hi,
For GLnexus version:
##GLnexusVersion=v1.3.1-0-g0e1c9c9
##GLnexusConfigName=gatk
##GLnexusConfigCRC32C=1263441421

I'm getting missing variant calls in the jointly called file, even though the original gVCF of the input sample had a variant call.

Joint called VCF for locus -> Sample cmh003679-02 has ./. as the genotype with 'II' as the reason for the missing call, which means the input gVCF was not genotyped.
```
#CHROM    POS  ID   REF  ALT  QUAL FILTER    INFO FORMAT    cmh003679-01     cmh003679-02   cmh003679-03   cmh003679-04
chr5 77298807  chr5_77298807_CT_C  CT   C    61   .    AF=0.25;AQ=61     GT:DP:AD:SB:GQ:PL:RNC    0/1:19:6,13:.,.,.,.:61:61,0,72:..     ./.:5:5,0:.,.,.,.:0:.:II 0/0:30:30,0:.,.,.,.:50:.:..     0/1:13:6,7:.,.,.,.:59:58,0,99:..
```

However, that sample did have a genotype call at that locus...
```
#CHROM    POS  ID   REF  ALT  QUAL FILTER    INFO FORMAT    cmh003679-02
chr5 77298808  .    T    <*>  0    .    END=77298808   GT:GQ:MIN_DP:PL     0/0:15:5:0,15,149
```

This is probably a bug in GLnexus.",gevro,https://github.com/dnanexus-rnd/GLnexus/issues/265
MDU6SXNzdWU5NDc5NDk3MDM=,problems merging variants with DeepVariant_WES,CLOSED,2021-07-19T19:15:09Z,2021-07-19T19:55:09Z,2021-07-19T19:55:09Z,"Hi,

I am trying to merge and backfill variant calls from 4 different gVCF files produced by DeepVariant WES.  Only 1 out of 4 samples have this variant called:

chr19	33302293	.	T	G,<*>	32.5	PASS	.	GT:GQ:DP:AD:VAF:PL

When I try to backfill, it continously just ignores this variant and removes it.  I have tried to use the DeepVariant_unfiltered config as well, and it produces the same results.  If I try to use bcftools norm -m -both to split the multiallelic calls I get a formatting error.  I checked the bam files of this variant for all 4 samples and it is deeply covered so not sure why it can't merge this call.  Any suggestions?

I have tried the following (and changing DeepVariantWES to DeepVaraint_unfiltered):

```
sudo docker run -v ""/input"":""/input"" quay.io/mlin/glnexus:v1.2.2 /usr/local/bin/glnexus_cli --config DeepVariantWES /input/sample_4_S20.g.vcf.gz /input/sample_5_S21.g.vcf.gz /input/sample_6_S22.g.vcf.gz /input/sample_7_S23.g.vcf.gz  | bcftools view - | bgzip -c >all_variants_backfilled.vcf.gz
```
Thanks!",tbrunetti,https://github.com/dnanexus-rnd/GLnexus/issues/266
MDU6SXNzdWU5NDk4NzI4NTI=,Build on CentOS7,OPEN,2021-07-21T16:01:53Z,2023-07-10T19:58:50Z,,"Has anyone successfully built for CentOS7 with glibc 2.17?

We are unable to build manually or extract a 2.17 glibc based exe from the docker build. 
",james-vincent,https://github.com/dnanexus-rnd/GLnexus/issues/267
MDU6SXNzdWU5NTkzODgwODE=,Test failures on ARM,OPEN,2021-08-03T18:41:29Z,2021-08-03T22:49:30Z,,"I am trying to get GLnexus working on AWS Graviton2. Attached is a Dockerfile that works, except that there are some unit test failures. The ctest log is also attached. Hopefully these are easy fixes.

I build this image on a `t4g.large` with the Amazon Linux AMI. It may be necessary to adjust `-j4` to a smaller number of jobs if you get out-of-memory errors. Also, it seems that `docker build` doesn't fail when there are ctest errors, so I had to build the image first, then run it interactively to run the tests.

[Dockerfile.txt](https://github.com/dnanexus-rnd/GLnexus/files/6927326/Dockerfile.txt)
[ctest.log](https://github.com/dnanexus-rnd/GLnexus/files/6927465/ctest.log)
",jdidion,https://github.com/dnanexus-rnd/GLnexus/issues/268
MDU6SXNzdWU5NjQ0NTI1NjA=,Failed to genotype: Invalid: genotyper,OPEN,2021-08-09T22:59:28Z,2021-08-20T19:51:56Z,,"Hi, I'm getting the following error when trying to combine GVCF files:

[1779450] [2021-08-04 13:25:45.041] [GLnexus] [error] Failed to genotype: Invalid: genotyper: unexpected result when fetching record FORMAT field (file.WholeGenome <12>:89333621-89333621 SB vector length 1, expected 4)

I can see that it is because of the inconsistency of the file at this row (see attached). However, I don't know if there is a way to still complete the genotyping and ignore this line. Or do I have to manually change the individual gvcf.

Thanks,
Meghana

<img width=""1097"" alt=""Screen Shot 2021-08-09 at 3 53 23 PM"" src=""https://user-images.githubusercontent.com/45370974/128784669-58e0a3a0-0141-4a1e-b8e2-883cd0588b75.png"">

",meghatron21,https://github.com/dnanexus-rnd/GLnexus/issues/269
MDU6SXNzdWU5NzY0MDM2NTI=,Any configuration preset for paftools caller?,OPEN,2021-08-22T15:29:26Z,2021-08-22T21:45:27Z,,"I would like to merge VCFs generated with `paftools.js` from [minimap](https://github.com/lh3/minimap2). Is there any recommended preset for this among the currently available?

I am using now `--config DeepVariant` on the basis that to my understanding the VCFs generated are whole genome sequencing VCFs, but not 100% confident about the differences of that with the preset for other callers (e.g. gatk), or if paftools would require its own preset.

Thanks",elcortegano,https://github.com/dnanexus-rnd/GLnexus/issues/270
MDU6SXNzdWU5Nzc4OTIwMDA=,adding glnexus to bioconda,OPEN,2021-08-24T09:21:25Z,2023-09-22T08:44:48Z,,"Hi all! 

I'd like to be able to install glnexus through bioconda, and I was wondering if any of the developers could let me know if its okay for me to add glnexus to bioconda? 

Thanks!",ramprasadn,https://github.com/dnanexus-rnd/GLnexus/issues/271
I_kwDOAgB6-M4-2Li6,Invalid: BCFKeyValueData::import_gvcf:invalid data set name ,OPEN,2021-11-16T03:08:21Z,2021-11-16T03:32:35Z,,"I am running into an error whet trying to merge my .g.vcf.gz files outpiut from PEPPER for long read data. 
I am running the command as follows but get the resulting error for my run. Just wondering if you have any advice.

singularity exec --bind /usr/lib/locale/ glnexus_v1.4.1.sif glnexus_cli \
--config DeepVariant \
--threads 10 \
--bed  contig_81883.coord.bed \
*.g.vcf.gz > Test.contig81883.PEPPER.joint.bcf


[8781] [2021-11-15 21:58:40.154] [GLnexus] [error] Samplix.678_03_01.R2R3Myb.Guppyv.5.0.1.NF_L500_Q10.minimap2.mapont.noMD.phlox_flye.curated.medaka.v1.sorted.pepper_contig_81883.rename.g.vcf.gz Invalid: BCFKeyValueData::import_gvcf: invalid data set name (Samplix.678_03_01.R2R3Myb.Guppyv.5.0.1.NF_L500_Q10.minimap2.mapont.noMD.phlox_flye.curated.medaka.v1.sorted.pepper_contig_81883.rename)
[8781] [2021-11-15 21:58:40.154] [GLnexus] [error] Samplix.678_08_07.R2R3Myb.Guppyv.5.0.1.NF_L500_Q10.minimap2.mapont.noMD.phlox_flye.curated.medaka.v1.sorted.pepper_contig_81883.rename.g.vcf.gz Invalid: BCFKeyValueData::import_gvcf: invalid data set name (Samplix.678_08_07.R2R3Myb.Guppyv.5.0.1.NF_L500_Q10.minimap2.mapont.noMD.phlox_flye.curated.medaka.v1.sorted.pepper_contig_81883.rename)
",aguygarner,https://github.com/dnanexus-rnd/GLnexus/issues/272
I_kwDOAgB6-M5E4fV3,can't compile GLnexus on RHEL 7.9 (LZ4 errors),OPEN,2022-03-01T18:16:16Z,2022-04-20T19:30:41Z,,"```
» cmake -Dtest=ON . && make -j8 && ctest -V
...
[100%] Linking CXX executable unit_tests
./util/compression.h:1149: error: undefined reference to 'LZ4_createStreamDecode'
./util/compression.h:1155: error: undefined reference to 'LZ4_decompress_safe_continue'
./util/compression.h:1158: error: undefined reference to 'LZ4_freeStreamDecode'
./util/compression.h:1152: error: undefined reference to 'LZ4_setStreamDecode'
./util/compression.h:1149: error: undefined reference to 'LZ4_createStreamDecode'
./util/compression.h:1152: error: undefined reference to 'LZ4_setStreamDecode'
./util/compression.h:1155: error: undefined reference to 'LZ4_decompress_safe_continue'
./util/compression.h:1158: error: undefined reference to 'LZ4_freeStreamDecode'
./util/compression.h:1210: error: undefined reference to 'LZ4_compressBound'
./util/compression.h:1221: error: undefined reference to 'LZ4_createStreamHC'
./util/compression.h:1222: error: undefined reference to 'LZ4_resetStreamHC'
./util/compression.h:1227: error: undefined reference to 'LZ4_loadDictHC'
./util/compression.h:1232: error: undefined reference to 'LZ4_compress_HC_continue'
./util/compression.h:1239: error: undefined reference to 'LZ4_freeStreamHC'
./util/compression.h:1072: error: undefined reference to 'LZ4_compressBound'
./util/compression.h:1077: error: undefined reference to 'LZ4_createStream'
./util/compression.h:1085: error: undefined reference to 'LZ4_compress_fast_continue'
./util/compression.h:1092: error: undefined reference to 'LZ4_freeStream'
./util/compression.h:1080: error: undefined reference to 'LZ4_loadDict'
./util/compression.h:1072: error: undefined reference to 'LZ4_compressBound'
./util/compression.h:1077: error: undefined reference to 'LZ4_createStream'
./util/compression.h:1085: error: undefined reference to 'LZ4_compress_fast_continue'
./util/compression.h:1092: error: undefined reference to 'LZ4_freeStream'
./util/compression.h:1210: error: undefined reference to 'LZ4_compressBound'
./util/compression.h:1221: error: undefined reference to 'LZ4_createStreamHC'
./util/compression.h:1222: error: undefined reference to 'LZ4_resetStreamHC'
./util/compression.h:1227: error: undefined reference to 'LZ4_loadDictHC'
./util/compression.h:1232: error: undefined reference to 'LZ4_compress_HC_continue'
./util/compression.h:1239: error: undefined reference to 'LZ4_freeStreamHC'
./util/compression.h:1080: error: undefined reference to 'LZ4_loadDict'
collect2: error: ld returned 1 exit status
make[2]: *** [unit_tests] Error 1
make[1]: *** [CMakeFiles/unit_tests.dir/all] Error 2
make: *** [all] Error 2

» module list                                                          
Currently Loaded Modulefiles:
  1) EasyBuild/4.4.2                  6) cmake/3.14.3                    11) lz4/1.9.3-GCCcore-10.3.0
  2) uge/8.6.15                       7) bzip2/1.0.8-GCCcore-10.3.0      12) zstd/1.4.9-GCCcore-10.3.0
  3) GCCcore/10.3.0                   8) xz/5.2.5-GCCcore-10.3.0         13) snappy/1.1.8-GCCcore-10.3.0
  4) zlib/1.2.11-GCCcore-10.3.0       9) gzip/1.10-GCCcore-10.3.0
  5) binutils/2.36.1-GCCcore-10.3.0  10) XZ/5.2.5-GCCcore-10.3.0

» ls /path/software/lz4/1.9.3-GCCcore-10.3.0/lib 
liblz4.a  liblz4.so  liblz4.so.1  liblz4.so.1.9.3  pkgconfig
```
So the library is there but it is not seen by the linker. Please help!",ponomarevsy,https://github.com/dnanexus-rnd/GLnexus/issues/273
I_kwDOAgB6-M5HwmBl,Long reads sequencing data,OPEN,2022-04-14T00:54:10Z,2022-04-14T00:54:10Z,,"Hi, I have some gVCF files based on ONT sequencing data. Is GLnexus suitable for joint calling of gVCF files based on long reads sequencing data, such as Pacbio Hifi or ONT? Thanks!",LiShuhang-gif,https://github.com/dnanexus-rnd/GLnexus/issues/274
I_kwDOAgB6-M5IaxDQ,GLnexus CLI generates VCFs missing GATK-compatible INFO fields,OPEN,2022-04-25T19:57:44Z,2023-06-17T07:43:40Z,,"In an attempt to joint-call a small cohort of 55 WGS samples, I used 

glnexus_cli --config gatk --mem-gbytes 900 /samples/*.g.vcf.gz > out.bcf

The output VCF (in following ""bcftools view"" and ""bgzip"") was successfully created in a short time. Comparing to parallel outcomes from other joint-calling processes using GATK pipelines, however, I found that many key-value pairs are missing from the GLnexus results, e.g.

GLnexus  - 

#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	...
1	10146	1_10146_AC_A	AC	A	181	.	AF=0.009091;AQ=181	GT:DP:AD:SB:GQ:PL:RNC	...


GATK - 

#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	
chr1	10140	.	ACCCTAAC	A	189.78	.	AC=1;AF=0.022;AN=46;AS_BaseQRankSum=0.900;AS_FS=2.632;AS_InbreedingCoeff=-0.0305;AS_MQ=47.10;AS_MQRankSum=3.000;AS_QD=15.83;AS_ReadPosRankSum=2.200;AS_SOR=0.916;BaseQRankSum=1.17;DP=1908;ExcessHet=3.0103;FS=5.756;InbreedingCoeff=-0.0305;MLEAC=1;MLEAF=0.022;MQ=39.19;MQRankSum=2.24;QD=15.82;ReadPosRankSum=1.80;SOR=1.198	GT:AD:DP:GQ:PL


I went though the CLI options and found none would permit extra meta-data to be added in the calling process. Is this GATK-incompatibility a feature in design? If not, would it be possible to sort of ""turn on"" such extra output in VCF generation?

Thanks.",bh007,https://github.com/dnanexus-rnd/GLnexus/issues/275
I_kwDOAgB6-M5M_Mx8,Glnexus failed to joint the g.vcf file generated from GATK Haplotypecaller with BP_resolution,OPEN,2022-07-01T17:04:02Z,2022-07-01T17:04:02Z,,"Hi,

I want to use glnexus after gatk haplotype caller with BP_resolution. However, it failed by giving this error message. 

Message
```
[GLnexus] [error] Failed to genotype: Invalid: genotyper: gVCF reference depth FORMAT field is missing or malformed (CP-F0823-001U_BP_germline <0>:69270-69270 (MIN_DP))
```

It works well if I run the glnexus with the g.vcf derived from the halotypecaller default setting. 

May I know if I should change some settings specifically for BP_resolution?

Thanks,

David",Drdreammaerd,https://github.com/dnanexus-rnd/GLnexus/issues/276
I_kwDOAgB6-M5O_Z2U,out of memory in genotyping stage,OPEN,2022-08-02T03:45:28Z,2022-08-02T03:45:28Z,,"Hi,
I'm trying to run GLnexus(v1.4.1) on a large dataset with 100,000 small gvcfs((1Mbp-2Mbp of chr1), the small gvcfs was simuted from 2504 gvcfs of the 1000 Genomes Project by randomly selecting gvcfs with replication and rename gvcf sample names.
I run GLnexus on a server with 184G memory, 72 threads, nvme SSD , CentOS7

here is my commond to run GLnexus
/path/to/glnexus_cli \
    --dir result-glnexus/GLnexus.DB \
    --bed target.bed --list vcfs.list \
    --threads 10 --mem-gbytes 60 | bcftools view --threads 12 -O z -o result-glnexus/result.vcf.gz

and here is tail of log file
[23109] [2022-08-02 00:36:23.650] [GLnexus] [info] Bulk load complete!
[23109] [2022-08-02 00:36:24.345] [GLnexus] [info] found sample set *@100000
[23109] [2022-08-02 00:36:24.346] [GLnexus] [info] discovering alleles in 1 range(s) on 8 threads
[23109] [2022-08-02 01:10:23.176] [GLnexus] [info] discovered 167420 alleles
[23109] [2022-08-02 01:12:22.491] [GLnexus] [info] unified to 63450 sites cleanly with 71734 ALT alleles. 1937 ALT alleles were additionally included in monoallelic sites and 12215 were filtered out on quality thresholds.
[23109] [2022-08-02 01:12:22.491] [GLnexus] [info] Finishing database compaction...
[23109] [2022-08-02 01:12:24.363] [GLnexus] [info] genotyping 63450 sites; sample set = *@100000 mem_budget = 64424509440 threads = 10
ClockTime:4:24:38       ClockTimeSeconds:15878.10       CPU_Time:127822.03      CPU_percent:875%        ResidentMemory:180420124
[W::bgzf_read_block] EOF marker is absent. The input is probably truncated
Error: BCF read error

I have jemalloc installed and GLnexus is linked to jemalloc dynamic library(NOT by using LD_PRELOAD), here is the head lines of log file
[23109] [2022-08-01 21:07:43.920] [GLnexus] [info] glnexus_cli release v1.4.1-0-g68e25e5-dirty Aug  1 2022
[23109] [2022-08-01 21:07:43.923] [GLnexus] [info] detected jemalloc 5.3.0-0-g54eaed1d8b56b1aa528be3bdd1877e59c56fa90c

Any suggestions on how I should deal with this issue?
Thanks!
Archie


",Archieyoung,https://github.com/dnanexus-rnd/GLnexus/issues/277
I_kwDOAgB6-M5PBvxh,Resume GLNexus for an existing GLnexus.DB database,CLOSED,2022-08-02T13:26:38Z,2023-04-04T06:54:12Z,2023-04-04T06:54:12Z,"i had built GLnexus.DB, but i forget to put my chr1_part2.bed file to current directory
this code:
```
$glnexus_cli --config gatk --list ${chr[$line0]}.list --dir ${chr[$line0]}.GLnexus.DB --mem-gbytes 40 --bed chr1_part2.bed
```
this error :
```
2767723] [2022-08-02 17:43:23.845] [GLnexus] [info] 100/444 (20D004909.chr1)...
[2767753] [2022-08-02 18:11:53.733] [GLnexus] [info] 200/444 (20D008382.chr1)...
[2767764] [2022-08-02 18:42:08.396] [GLnexus] [info] 300/444 (20D008553.chr1)...
[2767685] [2022-08-02 19:09:53.664] [GLnexus] [info] 400/444 (20D008656.chr1)...
[2767241] [2022-08-02 19:17:27.776] [GLnexus] [info] Loaded 444 datasets with 444 samples; 2711335351984 bytes in 27359645837 BCF records (33653>
[2767241] [2022-08-02 19:17:27.778] [GLnexus] [info] Created sample set *@444
[2767241] [2022-08-02 19:17:27.778] [GLnexus] [info] Flushing database...
[2767241] [2022-08-02 19:18:09.501] [GLnexus] [info] Bulk load complete!
[2767241] [2022-08-02 19:18:14.327] [GLnexus] [error] Failed to parse the bed file: IOError: bed file does not exist (chr1_part2.bed)
```
Is there a way to bypass this check and use the existing database?

",zhoudreames,https://github.com/dnanexus-rnd/GLnexus/issues/278
I_kwDOAgB6-M5QVgsy,BED file not taken into account,OPEN,2022-08-23T11:45:38Z,2023-11-28T03:47:00Z,,"Hi
Passing a BED file using `--bed` results in:
`[info] Beginning bulk load with no range filter`.
This also happened with the tutorial's ALDH2 dataset, and the `echo -e ""chr12\t111760000\t111820000"" > ALDH2.bed` bed file.
What causes this issue?

Thank you.
",ThatMatin,https://github.com/dnanexus-rnd/GLnexus/issues/279
I_kwDOAgB6-M5ZvRcO,N+1 calling as way to enhance small dataset accuracy,OPEN,2022-12-21T01:21:13Z,2022-12-21T01:21:13Z,,"Hi there,

I was wondering - is this a valid way to improve variant calling? In theory, can you take a large cohort dataset such as 1000G or even UK Biobank and merge it with your own a private dataset called on a functionally equivalent pipeline? 

Thanks!

_Originally posted by @JosephLalli in https://github.com/dnanexus-rnd/GLnexus/issues/233#issuecomment-1360640383_
      ",JosephLalli,https://github.com/dnanexus-rnd/GLnexus/issues/280
I_kwDOAgB6-M5amdfP,glibc error when using conda version,OPEN,2023-01-05T04:13:48Z,2023-01-05T04:13:48Z,,"Hi,

I got glibc errors when using conda to install GLnexus, would you please fix this problem.

my issue maybe duplicated because I found this issue(https://github.com/dnanexus-rnd/GLnexus/issues/271)

source ./bin/activate glnexus
glnexus_cli 
glnexus_cli: /Bio/lib64/libc.so.6: version `GLIBC_2.15' not found (required by glnexus_cli)
glnexus_cli: /Bio/lib64/libc.so.6: version `GLIBC_2.17' not found (required by glnexus_cli)
glnexus_cli: /Bio/lib64/libc.so.6: version `GLIBC_2.14' not found (required by glnexus_cli)
glnexus_cli: /Bio/lib64/libc.so.6: version `GLIBC_2.16' not found (required by glnexus_cli)
glnexus_cli: /Bio/lib64/libc.so.6: version `GLIBC_2.18' not found (required by glnexus_cli)

Best,
Kun",xiekunwhy,https://github.com/dnanexus-rnd/GLnexus/issues/281
I_kwDOAgB6-M5eCGJO,No filter info after merging deepvariant gvcfs.,OPEN,2023-02-09T10:15:24Z,2024-12-05T23:23:11Z,,"I'm wondering why there are no any filters after merged, especially the PASSed variants.",JieHe233,https://github.com/dnanexus-rnd/GLnexus/issues/282
I_kwDOAgB6-M5e6yDT,Please provide instructions on how to use singularity to run GLnexus,OPEN,2023-02-20T21:31:36Z,2023-03-31T13:31:45Z,,"I would appreciate instructions on how to run GLnexus using singularity - the format used by the likes of Deepvariant would be really welcome - see link https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md (see section: Notes on Singularity) 

Thank you very much for your help!",hoyonh,https://github.com/dnanexus-rnd/GLnexus/issues/283
I_kwDOAgB6-M5e7Hao,N+1 calling code,OPEN,2023-02-20T23:16:06Z,2023-02-20T23:16:06Z,,"Hi there,
I have been working with deepvariants to create GVCF files. I want to joint-call them. I wanted to use GLnexus as the paper suggests it can perform incremental (N+1) calling. But I can't figure out how to add more samples to my existing database. Can you please help? thanks    ",Yask-Gupta,https://github.com/dnanexus-rnd/GLnexus/issues/284
I_kwDOAgB6-M5e_BVl,More details needed on configuration options for custom config,OPEN,2023-02-21T14:26:21Z,2023-02-21T14:26:21Z,,"On the configuration doc page the section under liftover fields is TODO. 
While most of the fields are self-explanatory, it would be helpful to have confirm some details on a couple of the fields. In lieu of completing the whole doc section, I've posed a couple questions here  that might help to fill out some of the details for us and others and would be quicker and easier to answer than updating the configuration page ;-) We could  try to read the code but it is not always clear.

1.  number: basic
does this mean just single entry for all variants ? (alleles and genotype are clear enough)

2.  default_type:
does this mean that all variants will have this value unless the specific variant type has this format field ?

3. count: 0 (or 1)
we can guess but good to confirm this.

4.  Any other options not listed in the example  ?
https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration

5.  Separate unifier_config: question 
We noticed that with a custom config the unifier_config:  has a default which we did not explicitly specify in the custom yaml.

drop_filtered: false

We are wondering - what is the downstream effect of drop_filtered: false.  If the FILTER is non-PASS, does glnexus consider them to be true called variants ?

Thanks very much.
 ",jcm6t,https://github.com/dnanexus-rnd/GLnexus/issues/285
I_kwDOAgB6-M5gkoTw,(DP) Depth value being incorrectly set to 0 for calls ,OPEN,2023-03-12T02:59:11Z,2023-06-05T20:26:50Z,,"When joint calling gVCF files generated by DeepVariant, GLnexus will assign a genotype of 0/0 and a depth (DP) of 0. However without any supporting reads, the genotype should be './.' or nocall?",carsonhh,https://github.com/dnanexus-rnd/GLnexus/issues/286
I_kwDOAgB6-M5hMrRz,error,OPEN,2023-03-19T00:21:45Z,2023-11-28T18:26:03Z,,"I got this error

[912] [2023-03-18 17:00:50.893] [GLnexus] [error] Failed to genotype: Invalid: genotyper: unexpected result when fetching record FORMAT field (W149 <0>:180392281-180392281 PL vector length 5, expected 6)

chr1    180392281       .       G       A,<*>   0.4     NoCall  .       GT:GQ:DP:AD:VAF:PL      ./.:0:19:0,0,0:0,0:0,0,990,990,990

I can see why it expects 6 values, but all NoCall positions from DeepVariant look this, I believe.",shinlin77,https://github.com/dnanexus-rnd/GLnexus/issues/287
I_kwDOAgB6-M5ifHjV,Exception deserializing BCF bucket,OPEN,2023-04-03T15:45:45Z,2023-04-03T15:45:45Z,,"I am running GLnexus using Singularity from the official Docker image like so:

```
singularity exec ~/singularity/glnexus_v1.4.1.sif \
glnexus_cli \
    -t 16 \
    --config gatk \
    --dir ./GLnexus.DB.chr13test \
    combined_name_short_c*s_ALL_chr13test_gvcf.vcf.gz > cohort_Lindsay_chr13test_glnexus.bcf
```

But getting this error relating to capnp:

```
[12693] [2023-04-03 08:05:01.834] [GLnexus] [info] glnexus_cli release v1.4.1-0-g68e25e5 Aug 13 2021
[12693] [2023-04-03 08:05:01.834] [GLnexus] [info] detected jemalloc 5.2.1-0-gea6b3e973b477b8061e0076bb257dbd7f3faa756
[12693] [2023-04-03 08:05:01.834] [GLnexus] [info] Loading config preset gatk
[12693] [2023-04-03 08:05:01.840] [GLnexus] [info] config:
unifier_config:
  drop_filtered: false
  min_allele_copy_number: 1
  min_AQ1: 70
  min_AQ2: 40
  min_GQ: 40
  max_alleles_per_site: 32
  monoallelic_sites_for_lost_alleles: true
  preference: common
genotyper_config:
  revise_genotypes: true
  min_assumed_allele_frequency: 9.99999975e-05
  snv_prior_calibration: 1
  indel_prior_calibration: 1
  required_dp: 1
  allow_partial_data: false
  allele_dp_format: AD
  ref_dp_format: MIN_DP
  output_residuals: false
  more_PL: false
  squeeze: false
  trim_uncalled_alleles: false
  top_two_half_calls: false
  output_format: BCF
  liftover_fields:
    - {orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
    - {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}
    - {orig_names: [SB], name: SB, description: ""##FORMAT=<ID=SB,Number=4,Type=Integer,Description=\""Per-sample component statistics which comprise the Fishers Exact Test to detect strand bias.\"">"", type: int, number: basic, default_type: missing, count: 4, combi_method: missing, ignore_non_variants: false}
    - {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
    - {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}
[12693] [2023-04-03 08:05:01.840] [GLnexus] [info] config CRC32C = 1926883223
[12693] [2023-04-03 08:05:01.841] [GLnexus] [info] init database, exemplar_vcf=combined_name_short_cases_ALL_chr13test_gvcf.vcf.gz
[12693] [2023-04-03 08:05:02.137] [GLnexus] [info] Initialized GLnexus database in ./GLnexus.DB.chr13test
[12693] [2023-04-03 08:05:02.137] [GLnexus] [info] bucket size: 30000
[12693] [2023-04-03 08:05:02.137] [GLnexus] [info] contigs: chrM chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chr1_gl000191_random chr1_gl000192_random chr4_ctg9_hap1 chr4_gl000193_random chr4_gl000194_random chr6_apd_hap1 chr6_cox_hap2 chr6_dbb_hap3 chr6_mann_hap4 chr6_mcf_hap5 chr6_qbl_hap6 chr6_ssto_hap7 chr7_gl000195_random chr8_gl000196_random chr8_gl000197_random chr9_gl000198_random chr9_gl000199_random chr9_gl000200_random chr9_gl000201_random chr11_gl000202_random chr17_ctg5_hap1 chr17_gl000203_random chr17_gl000204_random chr17_gl000205_random chr17_gl000206_random chr18_gl000207_random chr19_gl000208_random chr19_gl000209_random chr21_gl000210_random chrUn_gl000211 chrUn_gl000212 chrUn_gl000213 chrUn_gl000214 chrUn_gl000215 chrUn_gl000216 chrUn_gl000217 chrUn_gl000218 chrUn_gl000219 chrUn_gl000220 chrUn_gl000221 chrUn_gl000222 chrUn_gl000223 chrUn_gl000224 chrUn_gl000225 chrUn_gl000226 chrUn_gl000227 chrUn_gl000228 chrUn_gl000229 chrUn_gl000230 chrUn_gl000231 chrUn_gl000232 chrUn_gl000233 chrUn_gl000234 chrUn_gl000235 chrUn_gl000236 chrUn_gl000237 chrUn_gl000238 chrUn_gl000239 chrUn_gl000240 chrUn_gl000241 chrUn_gl000242 chrUn_gl000243 chrUn_gl000244 chrUn_gl000245 chrUn_gl000246 chrUn_gl000247 chrUn_gl000248 chrUn_gl000249
[12693] [2023-04-03 08:05:02.160] [GLnexus] [info] db_get_contigs ./GLnexus.DB.chr13test
[12693] [2023-04-03 08:05:02.215] [GLnexus] [info] Beginning bulk load with no range filter.
[12693] [2023-04-03 08:27:55.854] [GLnexus] [info] Loaded 2 datasets with 721 samples; 115906987368 bytes in 21423078 BCF records (335 duplicate) in 1402 buckets. Bucket max 297427480 bytes, 25887 records. 0 BCF records skipped due to caller-specific exceptions
[12693] [2023-04-03 08:27:55.856] [GLnexus] [info] Created sample set *@2
[12693] [2023-04-03 08:27:55.856] [GLnexus] [info] Flushing database...
[12693] [2023-04-03 08:29:54.332] [GLnexus] [info] Bulk load complete!
[12693] [2023-04-03 08:29:54.358] [GLnexus] [warning] Processing full length of 93 contigs, as no --bed was provided. Providing a BED file with regions of interest, if applicable, can speed this up.
[12693] [2023-04-03 08:29:54.399] [GLnexus] [info] found sample set *@2
[12693] [2023-04-03 08:29:54.399] [GLnexus] [info] discovering alleles in 93 range(s) on 14 threads
[12693] [2023-04-03 08:29:55.542] [GLnexus] [error] Failed to discover alleles: IOError: exception deserializing BCF bucket (capnp/arena.c++:127: failed: Exceeded message traversal limit.  See capnp::ReaderOptions.
stack: 5648996158d8 5648990ba8f7 5648990c61e5 5648990c6349 56489908ba38 564899083508 564899009248 2abc52d6947e 56489907fbaa 56489907fd02 56489901316c 56489968b47e 2abc52d60608 2abc52e9c292)
```

I had also tried to provide a BED as shown in the tutorial, but it didn't seem to be recognized so I subsetted my gVCFs with `bcftools view` first instead.",lvclark,https://github.com/dnanexus-rnd/GLnexus/issues/288
I_kwDOAgB6-M5n4oRB,The configuration presents for DeepVariant whole genome sequencing,OPEN,2023-06-06T01:27:56Z,2023-06-14T08:49:16Z,,"Hello,
There are two choices in the configuration presents, ""DeepVariant"" and ""DeepVariantWGS"", for glnexus_cli (v1.4.1). They have the same description ""Joint call DeepVariant whole genome sequencing gVCFs"". I wonder if they are the same. Do the presets work for different sequencing data, like NGS (Illumina) data and PacBio data, since both of them can be treated with DeepVariant?

Thank you very much!",xunzhizhang,https://github.com/dnanexus-rnd/GLnexus/issues/289
I_kwDOAgB6-M5or8Vn,Is capnp-test failure a cause of worry?,OPEN,2023-06-14T08:31:12Z,2023-06-14T08:38:10Z,,"Hello, 

I am trying to install GLnexus, and I have this error. Note that the compilation doesn't stop. Is it a benign error? 

Thank you

EDIT: here is the complete failure

Testsuite summary for Capn Proto 0.7.0
============================================================================
# TOTAL: 3
# PASS:  2
# SKIP:  0
# XFAIL: 0
# FAIL:  1
# XPASS: 0
# ERROR: 0
============================================================================
See ./test-suite.log
Please report to capnproto@googlegroups.com
============================================================================
Makefile:3474: recipe for target 'test-suite.log' failed
make[6]: *** [test-suite.log] Error 1
make[5]: *** [check-TESTS] Error 2
Makefile:3580: recipe for target 'check-TESTS' failed
make[4]: *** [check-am] Error 2
Makefile:3804: recipe for target 'check-am' failed
Makefile:3807: recipe for target 'check' failed
make[3]: *** [check] Error 2
CMakeFiles/capnp.dir/build.make:111: recipe for target 'external/src/capnp-stamp/capnp-build' failed
make[2]: *** [external/src/capnp-stamp/capnp-build] Error 2
make[1]: *** [CMakeFiles/capnp.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
CMakeFiles/Makefile2:515: recipe for target 'CMakeFiles/capnp.dir/all' failed
-- rocksdb build command succeeded.  See also /GLnexus/external/src/rocksdb-stamp/rocksdb-build-*.log
[ 61%] No install step for 'rocksdb'
[ 62%] Completed 'rocksdb'
[ 62%] Built target rocksdb
Makefile:140: recipe for target 'all' failed
make: *** [all] Error 2
The command '/bin/sh -c cmake -DCMAKE_BUILD_TYPE=$build_type . && make -j4' returned a non-zero code: 2",N/A,https://github.com/dnanexus-rnd/GLnexus/issues/290
I_kwDOAgB6-M5qpAhe,X and Y-chromosome calling,OPEN,2023-07-05T09:19:15Z,2023-07-05T09:19:15Z,,"When doing joint calling is it desirable to call the X-chromosome separately for males and females and then merge?

Many thanks

Scott
",shaze,https://github.com/dnanexus-rnd/GLnexus/issues/291
I_kwDOAgB6-M5wx-j2,Merging and variant loss,OPEN,2023-09-12T10:05:39Z,2023-09-12T10:05:39Z,,"Hello,

Using Deepvariant v1.5 + GLnexus v1.4.3 on WES data, the variant G>C is not kept from the gvcf file.
It is the same result if GLnexus model is set to ""DeepVariant"" or ""DeepVariant_unfiltered"".
Twelve files are merged. The variant is found in 3 of them.
The genomic region looks clean (no low mapping qual).
It is not clear to me. Could you please comment about this variant?

Thanks


```
S4.deepvariant.wes.gvcf.gz:19       39971432        .       G       C,<*>   54.4    PASS    .  GT:GQ:DP:AD:VAF:PL       0/1:49:118:61,57,0:0.483051,0:54,0,51,990,990,990
S0.deepvariant.wes.gvcf.gz:19       39971432        .       G       C,<*>   54.7    PASS    .  GT:GQ:DP:AD:VAF:PL       0/1:47:101:37,64,0:0.633663,0:54,0,47,990,990,990
S6.deepvariant.wes.gvcf.gz:19       39971432        .       G       C,<*>   49.9    PASS    .  GT:GQ:DP:AD:VAF:PL       0/1:48:82:48,34,0:0.414634,0:49,0,54,990,990,990
```

Genome=hg19",Fred-07,https://github.com/dnanexus-rnd/GLnexus/issues/292
I_kwDOAgB6-M5xIfW2,deepvarinat,OPEN,2023-09-15T09:25:40Z,2023-09-15T09:25:40Z,,"Sorry to bother you, I have a question, if we use Deepvarinat for SNP calling on pacbio or ONT sequencing data, can we also use glnexus for joint variant calling? Because the options for the config parameter I found are DeepVariantWGS and DeepVariantWES. ",Tonitsk8264,https://github.com/dnanexus-rnd/GLnexus/issues/293
I_kwDOAgB6-M50xF_U,"glnexus_cli with Singularity - GLnexus.DB ""directory already exists""",CLOSED,2023-10-24T11:16:16Z,2023-11-30T18:09:29Z,2023-11-30T18:08:38Z,"Hi DNAnexus team,

I'm currently trying to use a Singularity image of GLnexus 1.4.1 to merge a few single-called Google deepvariant genome.vcf.gz files, using the following command:

```{bash}
singularity exec --bind /path/to/script/dir:/mnt /separate/path/to/glnexus_1.4.1.sif glnexus_cli --config DeepVariantWGS --bed /mnt/input/regions.bed --mem-gbytes 16 --threads 8 /mnt/input/sample1.genome.vcf.gz /mnt/input/sample2.genome.vcf.gz /mnt/input/sample3.genome.vcf.gz /mnt/input/sample4.genome.vcf.gz > /path/to/script/dir/output/merged.bcf
```

Note that I've used the bind directory paths for the input gVCFs & the BED file, but used the standard path for the redirected output BCF, though they're technically point to the same thing (I couldn't get the command to work otherwise).

However, I keep getting the follwing error:

```{bash}
[GLnexus] [info] glnexus_cli release v1.4.1-0-g68e25e5 Aug 13 2021
[GLnexus] [info] detected jemalloc 5.2.1-0-<long hash>
[GLnexus] [info] Loading config preset DeepVariantWGS
[GLnexus] [info] config:
<config values key-value pairs>
[GLnexus] [info] config CRC32C = <long number>
[GLnexus] [info] init database, exemplar_vcf=/mnt/input/sample1.genome.vcf.gz
[GLnexus] [error] Failed to initialize database: IOError: Database directory already exists (GLnexus.DB)
```

The documentation says that the database directory is created at `$(pwd)/GLnexus.DB`, but using `find . -name ""*GLnexus.DB"" -type d` returns nothing. I'm not sure where this directory is actually being created at this point, so that I can delete it & re-run my command.

Could you kindly help me figure this out?

P.S. This is an isolated remote environment so I don't have admin access to anything here.

Regards",ama249,https://github.com/dnanexus-rnd/GLnexus/issues/294
I_kwDOAgB6-M505z6b,./runglnexus.sh: line 2: 20506 Terminated,OPEN,2023-10-25T12:30:44Z,2023-10-25T12:30:44Z,,"I used parabricks to combine GVCF

[33mWARNING:[0m destination /home/u220220932211/data/yxj_g_vcf already in mount list: destination is already in the mount point list
[33mWARNING:[0m destination /home/u220220932211/pika already in mount list: destination is already in the mount point list
[33mWARNING:[0m destination /home/u220220932211/pika/pika3 already in mount list: destination is already in the mount point list
[33mWARNING:[0m destination /home/u220220932211/pika/pika2 already in mount list: destination is already in the mount point list
[33mWARNING:[0m destination /home/u220220932211/pika/pika5 already in mount list: destination is already in the mount point list
[33mWARNING:[0m destination /home/u220220932211/pika/pika4 already in mount list: destination is already in the mount point list
[20506] [2023-10-25 10:59:17.005] [GLnexus] [info] glnexus_cli release v1.2.7-0-g0e74fc4 Aug 13 2020
[20506] [2023-10-25 10:59:17.005] [GLnexus] [warning] jemalloc absent, which will impede performance with high thread counts. See https://github.com/dnanexus-rnd/GLnexus/wiki/Performance
[20506] [2023-10-25 10:59:17.005] [GLnexus] [info] Loading config preset gatk
[20506] [2023-10-25 10:59:17.013] [GLnexus] [info] config:
unifier_config:
  drop_filtered: false
  min_allele_copy_number: 1
  min_AQ1: 70
  min_AQ2: 40
  min_GQ: 40
  max_alleles_per_site: 32
  monoallelic_sites_for_lost_alleles: true
  preference: common
genotyper_config:
  revise_genotypes: true
  min_assumed_allele_frequency: 9.99999975e-05
  required_dp: 1
  allow_partial_data: false
  allele_dp_format: AD
  ref_dp_format: MIN_DP
  output_residuals: false
  more_PL: false
  squeeze: false
  trim_uncalled_alleles: false
  output_format: BCF
  liftover_fields:
    - {orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
    - {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}
    - {orig_names: [SB], name: SB, description: ""##FORMAT=<ID=SB,Number=4,Type=Integer,Description=\""Per-sample component statistics which comprise the Fishers Exact Test to detect strand bias.\"">"", type: int, number: basic, default_type: missing, count: 4, combi_method: missing, ignore_non_variants: false}
    - {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
    - {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}
[20506] [2023-10-25 10:59:17.014] [GLnexus] [info] config CRC32C = 268790301
[20506] [2023-10-25 10:59:17.014] [GLnexus] [info] init database, exemplar_vcf=/home/u220220932211/data/yxj_g_vcf/BBZ.g.vcf.gz
[20506] [2023-10-25 10:59:17.961] [GLnexus] [info] Initialized GLnexus database in GLnexus.DB
[20506] [2023-10-25 10:59:17.962] [GLnexus] [info] bucket size: 30000
[20506] [2023-10-25 10:59:17.962] [GLnexus] [info] contigs: Chr1 Chr2 Chr3 Chr4 Chr5 Chr6 Chr7 Chr8 Chr9 Chr10 Chr11 Chr12 Chr13 Chr14 Chr15 Chr16 Chr17 Chr18 Chr19 Chr20 Chr21 Chr22 Chr23 Chr24 Chr25 Chr26 scaffold1 scaffold2 scaffold3 scaffold4 scaffold5 scaffold6 scaffold7 scaffold8 scaffold9 scaffold10 scaffold11 scaffold12 scaffold13 scaffold14 scaffold15 scaffold16 scaffold17 scaffold18 scaffold19 scaffold20 scaffold21 scaffold22 scaffold23 scaffold24 scaffold25 scaffold26 scaffold27 scaffold28 scaffold29 scaffold30 scaffold31 scaffold32 scaffold33 scaffold34 scaffold35 scaffold36 scaffold37 scaffold38 scaffold39 scaffold40 scaffold41 scaffold42 scaffold43 scaffold44 scaffold45 scaffold46 scaffold47 scaffold48 scaffold49 scaffold50 scaffold51 scaffold52 scaffold53 scaffold54 scaffold55 scaffold56 scaffold57 scaffold58 scaffold59 scaffold60 scaffold61 scaffold62 scaffold63 scaffold64 scaffold65 scaffold66 scaffold67 scaffold68 scaffold69 scaffold70 scaffold71 scaffold72 scaffold73 scaffold74 scaffold75 scaffold76 scaffold77 scaffold78 scaffold79 scaffold80 scaffold81 scaffold82 scaffold83 scaffold84 scaffold85 scaffold86 scaffold87 scaffold88 scaffold89 scaffold90 scaffold91 scaffold92 scaffold93 scaffold94 scaffold95 scaffold96 scaffold97 scaffold98 scaffold99 scaffold100 scaffold101 scaffold102 scaffold103 scaffold104 scaffold105 scaffold106 scaffold107 scaffold108 scaffold109 scaffold110 scaffold111 scaffold112 scaffold113 scaffold114 scaffold115 scaffold116 scaffold117 scaffold118 scaffold119 scaffold120 scaffold121 scaffold122 scaffold123 scaffold124 scaffold125 scaffold126 scaffold127 scaffold128 scaffold129 scaffold130 scaffold131 scaffold132 scaffold133 scaffold134 scaffold135 scaffold136 scaffold137 scaffold138 scaffold139 scaffold140 scaffold141 scaffold142 scaffold143 scaffold144 scaffold145 scaffold146 scaffold147 scaffold148 scaffold149 scaffold150 scaffold151 scaffold152 scaffold153 scaffold154 scaffold155 scaffold156 scaffold157 scaffold158 scaffold159 scaffold160 scaffold161 scaffold162 scaffold163 scaffold164 scaffold165 scaffold166 scaffold167 scaffold168 scaffold169 scaffold170 scaffold171 scaffold172 scaffold173 scaffold174 scaffold175 scaffold176 scaffold177 scaffold178 scaffold179 scaffold180 scaffold181 scaffold182 scaffold183 scaffold184 scaffold185 scaffold186 scaffold187 scaffold188 scaffold189 scaffold190 scaffold191 scaffold192 scaffold193 scaffold194 scaffold195 scaffold196 scaffold197 scaffold198 scaffold199 scaffold200 scaffold201 scaffold202 scaffold203 scaffold204 scaffold205 scaffold206 scaffold207 scaffold208 scaffold209 scaffold210 scaffold211 scaffold212 scaffold213 scaffold214 scaffold215 scaffold216 scaffold217 scaffold218 scaffold219 scaffold220 scaffold221 scaffold222 scaffold223 scaffold224 scaffold225 scaffold226 scaffold227 scaffold228 scaffold229 scaffold230 scaffold231 scaffold232 scaffold233 scaffold234 scaffold235 scaffold236 scaffold237 scaffold238 scaffold239 scaffold240 scaffold241 scaffold242 scaffold243 scaffold244 scaffold245 scaffold246 scaffold247 scaffold248 scaffold249 scaffold250 scaffold251 scaffold252 scaffold253 scaffold254 scaffold255 scaffold256 scaffold257 scaffold258 scaffold259 scaffold260 scaffold261 scaffold262 scaffold263 scaffold264 scaffold265 scaffold266 scaffold267 scaffold268 scaffold269 scaffold270 scaffold271 scaffold272 scaffold273 scaffold274 scaffold275 scaffold276 scaffold277 scaffold278 scaffold279 scaffold280 scaffold281 scaffold282 scaffold283 scaffold284 scaffold285 scaffold286 scaffold287 scaffold288 scaffold289 scaffold290 scaffold291 scaffold292 scaffold293 scaffold294 scaffold295 scaffold296 scaffold297 scaffold298 scaffold299 scaffold300 scaffold301 scaffold302 scaffold303 scaffold304 scaffold305 scaffold306 scaffold307 scaffold308 scaffold309 scaffold310 scaffold311 scaffold312 scaffold313 scaffold314 scaffold315 scaffold316 scaffold317 scaffold318 scaffold319 scaffold320 scaffold321 scaffold322 scaffold323 scaffold324 scaffold325 scaffold326 scaffold327 scaffold328 scaffold329 scaffold330 scaffold331 scaffold332 scaffold333 scaffold334 scaffold335 scaffold336 scaffold337 scaffold338 scaffold339 scaffold340 scaffold341 scaffold342 scaffold343 scaffold344 scaffold345 scaffold346 scaffold347 scaffold348 scaffold349 scaffold350 scaffold351 scaffold352 scaffold353 scaffold354 scaffold355 scaffold356 scaffold357 scaffold358 scaffold359 scaffold360 scaffold361 scaffold362 scaffold363 scaffold364 scaffold365 scaffold366 scaffold367 scaffold368 scaffold369 scaffold370 scaffold371 scaffold372 scaffold373 scaffold374 scaffold375 scaffold376 scaffold377 scaffold378 scaffold379 scaffold380 scaffold381 scaffold382 scaffold383 scaffold384 scaffold385 scaffold386 scaffold387 scaffold388 scaffold389 scaffold390 scaffold391 scaffold392 scaffold393 scaffold394 scaffold395 scaffold396 scaffold397 scaffold398 scaffold399 scaffold400 scaffold401 scaffold402 scaffold403 scaffold404 scaffold405 scaffold406 scaffold407 scaffold408 scaffold409 scaffold410 scaffold411 scaffold412 scaffold413 scaffold414 scaffold415 scaffold416 scaffold417 scaffold418 scaffold419 scaffold420 scaffold421 scaffold422 scaffold423 scaffold424 scaffold425 scaffold426 scaffold427 scaffold428 scaffold429 scaffold430 scaffold431 scaffold432 scaffold433 scaffold434 scaffold435 scaffold436 scaffold437 scaffold438 scaffold439 scaffold440 scaffold441 scaffold442 scaffold443 scaffold444 scaffold445 scaffold446 scaffold447 scaffold448 scaffold449 scaffold450 scaffold451 scaffold452 scaffold453 scaffold454 scaffold455 scaffold456 scaffold457 scaffold458 scaffold459 scaffold460 scaffold461 scaffold462 scaffold463 scaffold464 scaffold465 scaffold466 scaffold467 scaffold468 scaffold469 scaffold470 scaffold471 scaffold472 scaffold473 scaffold474 scaffold475 scaffold476 scaffold477 scaffold478 scaffold479 scaffold480 scaffold481 scaffold482 scaffold483 scaffold484 scaffold485 scaffold486 scaffold487 scaffold488 scaffold489 scaffold490 scaffold491 scaffold492 scaffold493 scaffold494 scaffold495 scaffold496 scaffold497 scaffold498 scaffold499 scaffold500 scaffold501 scaffold502 scaffold503 scaffold504 scaffold505 scaffold506 scaffold507 scaffold508 scaffold509 scaffold510 scaffold511 scaffold512 scaffold513 scaffold514 scaffold515 scaffold516 scaffold517 scaffold518 scaffold519 scaffold520 scaffold521 scaffold522 scaffold523 scaffold524 scaffold525 scaffold526 scaffold527 scaffold528 scaffold529 scaffold530 scaffold531 scaffold532 scaffold533 scaffold534 scaffold535 scaffold536 scaffold537 scaffold538 scaffold539 scaffold540 scaffold541 scaffold542 scaffold543 scaffold544 scaffold545 scaffold546 scaffold547 scaffold548 scaffold549 scaffold550 scaffold551 scaffold552 scaffold553 scaffold554 scaffold555 scaffold556 scaffold557 scaffold558 scaffold559 scaffold560 scaffold561 scaffold562 scaffold563 scaffold564 scaffold565 scaffold566 scaffold567 scaffold568 scaffold569 scaffold570 scaffold571 scaffold572 scaffold573 scaffold574 scaffold575 scaffold576 scaffold577 scaffold578 scaffold579
[20506] [2023-10-25 10:59:18.032] [GLnexus] [info] db_get_contigs GLnexus.DB
[20506] [2023-10-25 10:59:18.172] [GLnexus] [info] Beginning bulk load with no range filter.
[W::hts_idx_load2] The index file is older than the data file: /home/u220220932211/data/yxj_g_vcf/DWR17.g.vcf.gz.tbi
[W::hts_idx_load2] The index file is older than the data file: /home/u220220932211/data/yxj_g_vcf/DWR25.g.vcf.gz.tbi
[W::hts_idx_load2] The index file is older than the data file: /home/u220220932211/data/yxj_g_vcf/DWR26.g.vcf.gz.tbi
[W::hts_idx_load2] The index file is older than the data file: /home/u220220932211/data/yxj_g_vcf/CCZ.g.vcf.gz.tbi
[W::hts_idx_load2] The index file is older than the data file: /home/u220220932211/data/yxj_g_vcf/DWR27.g.vcf.gz.tbi
[20506] [2023-10-25 12:02:24.903] [GLnexus] [info] Loaded 58 datasets with 58 samples; 2478962947064 bytes in 24132545089 BCF records (4923152 duplicate) in 5767867 buckets. Bucket max 1456928 bytes, 14021 records. 8872 BCF records skipped due to caller-specific exceptions
[20506] [2023-10-25 12:02:24.905] [GLnexus] [info] Created sample set *@58
[20506] [2023-10-25 12:02:24.905] [GLnexus] [info] Flushing database...
[20506] [2023-10-25 12:04:31.288] [GLnexus] [info] Bulk load complete!
[20506] [2023-10-25 12:04:31.340] [GLnexus] [warning] Processing full length of 605 contigs, as no --bed was provided. Providing a BED file with regions of interest, if applicable, can speed this up.
[20506] [2023-10-25 12:04:31.354] [GLnexus] [info] found sample set *@58
[20506] [2023-10-25 12:04:31.354] [GLnexus] [info] discovering alleles in 605 range(s) on 38 threads
./runglnexus.sh: line 2: 20506 Terminated              /usr/local/cuda/.pb/binaries//bin/glnexus /home/u220220932211/data/yxj_g_vcf/BBZ.g.vcf.gz /home/u220220932211/data/yxj_g_vcf/CCZ.g.vcf.gz /home/u220220932211/pika/DCB085_L2_306306..g.vcf /home/u220220932211/data/yxj_g_vcf/DWR15.g.vcf.gz /home/u220220932211/data/yxj_g_vcf/DWR17.g.vcf.gz /home/u220220932211/pika/pika3/DWR18.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/DWR19.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika2/DWR20.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika2/DWR21.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/DWR22.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika2/DWR23.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/DWR24.sort.markdup.bam.g.vcf /home/u220220932211/data/yxj_g_vcf/DWR25.g.vcf.gz /home/u220220932211/data/yxj_g_vcf/DWR26.g.vcf.gz /home/u220220932211/data/yxj_g_vcf/DWR27.g.vcf.gz /home/u220220932211/data/yxj_g_vcf/DWR28.g.vcf.gz /home/u220220932211/pika/DWR_LS.g.vcf.gz /home/u220220932211/pika/pika3/DWRpika1.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/DWRpika2.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika2/DWRpika3.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika2/DWRpika4.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/DWRpika5.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/DWRpika6.sort.markdup.bam.g.vcf /home/u220220932211/pika/DWR_XLGL.g.vcf.gz /home/u220220932211/pika/pika3/GYpika10.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/GYpika1.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/GYpika2.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/GYpika3.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika2/GYpika4.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/GYpika5.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/GYpika6.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/GYpika7.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/GYpika8.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika2/GYpika9.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/nubrica_pika1.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/nubrica_pika2.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika2/nubrica_pika3.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/nubrica_pika4.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/nubrica_pika5.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/nubrica_pika6.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/nubrica_pika7.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika2/OCH206.markdup.bam.g.vcf /home/u220220932211/pika/pika3/OCH240.markdup.bam.g.vcf /home/u220220932211/pika/pika3/OCH241.markdup.bam.g.vcf /home/u220220932211/pika/pika2/OCH242.markdup.bam.g.vcf /home/u220220932211/pika/pika2/plateau10.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/plateau11.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika3/plateau12.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika5/plateau13.sort.markdup.g.vcf /home/u220220932211/pika/pika5/plateau1.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika5/plateau2.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika2/plateau3.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika2/plateau4.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika4/plateau5.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika4/plateau6.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika4/plateau7.sort.markdup.bam.g.vcf /home/u220220932211/pika/pika4/WL15490_L4_307307.markdup.bam.g.vcf /home/u220220932211/pika/pika5/plateau8.sort.markdup.g.vcf.gz > /home/u220220932211/pika/GVCF/pika.bcf
For technical support visit https://docs.nvidia.com/clara/parabricks/3.7.0/index.html#how-to-get-help
Exiting...
Please visit https://docs.nvidia.com/clara/#parabricks for detailed documentation


Could not run glnexus
Exiting pbrun ...
.

why did it occur, is it memory not enough?",gotouerina,https://github.com/dnanexus-rnd/GLnexus/issues/295
I_kwDOAgB6-M51hF2J,Merging GVCF or VCF?,OPEN,2023-11-01T03:03:30Z,2023-11-01T03:03:30Z,,"I have dozens of GVCF files generated by DeepVariant from WGS data to be merged but I don't seem to have enough memory for GLnexus to complete the job. Is it the only solution to bin the entire genome properly and split the job into different genomic bins?

On the other hand, if I used VCF files instead of GVCF files, GLnexus was done succcessfully. Is this a proper way to merge the genotypes from different samples?",alanlamsiu,https://github.com/dnanexus-rnd/GLnexus/issues/296
I_kwDOAgB6-M51_MOH,GVCFs : std::bad_alloc,CLOSED,2023-11-06T15:59:22Z,2023-11-09T01:15:18Z,2023-11-09T01:15:18Z,"Hi All,

I have 40 gvcfs file generated from deepvariant and was combining them using GLnexus and here is my sbatch file 

#SBATCH -J GLnexus
#SBATCH -p normal
#SBATCH -N 5
#SBATCH -n 1
#SBATCH -o GLnexus.o%j
#SBATCH -e GLnexus.e%j
#SBATCH -t 00:08:00
#SBATCH --mail-type=ALL
#SBATCH --qos=maxjobs100


#          <------ Account String ----->
# <--- (Use this ONLY if you have MULTIPLE accounts) --->
#SBATCH -A MCB21061
#------------------------------------------------------

module load tacc-apptainer
module load parallel-netcdf/4.6.2

cd /scratch/09505/s223885/deepvariant_test/test/gl_test/

apptainer exec /home1/09505/s223885/GLnexus/glnexus_v1.4.1.sif glnexus_cli --config DeepVariantWES /scratch/09505/s223885/deepvariant_test/test/gl_vcf_small/*.g*.vcf.gz > /scratch/09505/s223885/deepvariant_test/test/gl_test/ALL_40.bcf



ERROR

[3252169] [2023-11-05 15:49:18.682] [GLnexus] [info] contigs: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y MT GL000207.1 GL000226.1 GL000229.1 GL000231.1 GL000210.1 GL000239.1 GL000235.1 GL000201.1 GL000247.1 GL000245.1 GL000197.1 GL000203.1 GL000246.1 GL000249.1 GL000196.1 GL000248.1 GL000244.1 GL000238.1 GL000202.1 GL000234.1 GL000232.1 GL000206.1 GL000240.1 GL000236.1 GL000241.1 GL000243.1 GL000242.1 GL000230.1 GL000237.1 GL000233.1 GL000204.1 GL000198.1 GL000208.1 GL000191.1 GL000227.1 GL000228.1 GL000214.1 GL000221.1 GL000209.1 GL000218.1 GL000220.1 GL000213.1 GL000211.1 GL000199.1 GL000217.1 GL000216.1 GL000215.1 GL000205.1 GL000219.1 GL000224.1 GL000223.1 GL000195.1 GL000212.1 GL000222.1 GL000200.1 GL000193.1 GL000194.1 GL000225.1 GL000192.1 NC_007605 hs37d5
[3252169] [2023-11-05 15:49:19.066] [GLnexus] [info] db_get_contigs GLnexus.DB
[3252169] [2023-11-05 15:49:19.590] [GLnexus] [info] Beginning bulk load with no range filter.
[3252169] [2023-11-05 15:50:54.588] [GLnexus] [info] Loaded 40 datasets with 40 samples; 116674418800 bytes in 1318363541 BCF records (310 duplicate) in 3821600 buckets. Bucket max 357928 bytes, 3920 records. 0 BCF records skipped due to caller-specific exceptions
[3252169] [2023-11-05 15:50:54.589] [GLnexus] [info] Created sample set *@40
[3252169] [2023-11-05 15:50:54.590] [GLnexus] [info] Flushing database...
[3252169] [2023-11-05 15:52:43.895] [GLnexus] [info] Bulk load complete!
[3252169] [2023-11-05 15:52:44.589] [GLnexus] [warning] Processing full length of 86 contigs, as no --bed was provided. Providing a BED file with regions of interest, if applicable, can speed this up.
[3252169] [2023-11-05 15:52:44.600] [GLnexus] [info] found sample set *@40
[3252169] [2023-11-05 15:52:44.601] [GLnexus] [info] discovering alleles in 86 range(s) on 126 threads
[3252169] [2023-11-05 15:54:23.937] [GLnexus] [info] discovered 11655338 alleles

terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc

/var/spool/slurmd/job1297083/slurm_script: line 38: 3252143 Aborted                 (core dumped) apptainer exec 
/home1/09505/s223885/GLnexus/glnexus_v1.4.1.sif glnexus_cli --config DeepVariantWES /scratch/09505/s223885/deepvariant_test/test/gl_vcf_small/*.g*.vcf.gz > /scratch/09505/s223885/deepvariant_test/test/gl_test/ALL_24.bcf

",DineshRavindraRaju,https://github.com/dnanexus-rnd/GLnexus/issues/297
I_kwDOAgB6-M52S1qv,"GLnexus , error while combining gvcf files",OPEN,2023-11-09T01:17:09Z,2023-11-09T21:35:29Z,,"Hi All,

I have 40 gvcfs file generated from deepvariant and was combining them using GLnexus 

here is my sbatch file

#SBATCH -J GLnexus
#SBATCH -p normal
#SBATCH -N 5
#SBATCH -n 11
#SBATCH -o GLnexus.o%j
#SBATCH -e GLnexus.e%j
#SBATCH -t 00:08:00
#SBATCH --mail-type=ALL
#SBATCH --qos=maxjobs100

<------ Account String ----->
<--- (Use this ONLY if you have MULTIPLE accounts) --->
#SBATCH -A MCB21061
#------------------------------------------------------

module load tacc-apptainer
module load parallel-netcdf/4.6.2

cd /scratch/09505/s223885/deepvariant_test/test/gl_test/

apptainer exec /home1/09505/s223885/GLnexus/glnexus_v1.4.1.sif glnexus_cli --config DeepVariantWES /scratch/09505/s223885/deepvariant_test/test/gl_vcf_small/*.g.vcf.gz > /scratch/09505/s223885/deepvariant_test/test/gl_test/ALL_40.bcf

ERROR

[3252169] [2023-11-05 15:49:18.682] [GLnexus] [info] contigs: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y MT GL000207.1 GL000226.1 GL000229.1 GL000231.1 GL000210.1 GL000239.1 GL000235.1 GL000201.1 GL000247.1 GL000245.1 GL000197.1 GL000203.1 GL000246.1 GL000249.1 GL000196.1 GL000248.1 GL000244.1 GL000238.1 GL000202.1 GL000234.1 GL000232.1 GL000206.1 GL000240.1 GL000236.1 GL000241.1 GL000243.1 GL000242.1 GL000230.1 GL000237.1 GL000233.1 GL000204.1 GL000198.1 GL000208.1 GL000191.1 GL000227.1 GL000228.1 GL000214.1 GL000221.1 GL000209.1 GL000218.1 GL000220.1 GL000213.1 GL000211.1 GL000199.1 GL000217.1 GL000216.1 GL000215.1 GL000205.1 GL000219.1 GL000224.1 GL000223.1 GL000195.1 GL000212.1 GL000222.1 GL000200.1 GL000193.1 GL000194.1 GL000225.1 GL000192.1 NC_007605 hs37d5
[3252169] [2023-11-05 15:49:19.066] [GLnexus] [info] db_get_contigs GLnexus.DB
[3252169] [2023-11-05 15:49:19.590] [GLnexus] [info] Beginning bulk load with no range filter.
[3252169] [2023-11-05 15:50:54.588] [GLnexus] [info] Loaded 40 datasets with 40 samples; 116674418800 bytes in 1318363541 BCF records (310 duplicate) in 3821600 buckets. Bucket max 357928 bytes, 3920 records. 0 BCF records skipped due to caller-specific exceptions
[3252169] [2023-11-05 15:50:54.589] [GLnexus] [info] Created sample set *@40
[3252169] [2023-11-05 15:50:54.590] [GLnexus] [info] Flushing database...
[3252169] [2023-11-05 15:52:43.895] [GLnexus] [info] Bulk load complete!
[3252169] [2023-11-05 15:52:44.589] [GLnexus] [warning] Processing full length of 86 contigs, as no --bed was provided. Providing a BED file with regions of interest, if applicable, can speed this up.
[3252169] [2023-11-05 15:52:44.600] [GLnexus] [info] found sample set *@40
[3252169] [2023-11-05 15:52:44.601] [GLnexus] [info] discovering alleles in 86 range(s) on 126 threads
[3252169] [2023-11-05 15:54:23.937] [GLnexus] [info] discovered 11655338 alleles

terminate called after throwing an instance of 'std::bad_alloc'
what(): std::bad_alloc

/var/spool/slurmd/job1297083/slurm_script: line 38: 3252143 Aborted (core dumped) apptainer exec
/home1/09505/s223885/GLnexus/glnexus_v1.4.1.sif glnexus_cli --config DeepVariantWES /scratch/09505/s223885/deepvariant_test/test/gl_vcf_small/*.g.vcf.gz > /scratch/09505/s223885/deepvariant_test/test/gl_test/ALL_24.bcf",DineshRavindraRaju,https://github.com/dnanexus-rnd/GLnexus/issues/298
I_kwDOAgB6-M52b-Po,Invalid: allele is not a DNA sequence,OPEN,2023-11-10T07:03:19Z,2024-09-10T14:51:16Z,,"Hi,

I'm getting the following error when trying to joint call some gVCF files:
```
[14707] [2023-11-09 18:40:20.654] [GLnexus] [error] mother_snv.g.vcf.gz Invalid: allele is not a DNA sequence  (mother_snv.g.vcf.gz <*> chr1:16532574-16532574)
[14707] [2023-11-09 18:40:21.165] [GLnexus] [error] Failed to bulk load into DB: Failure: One or more gVCF inputs failed validation or database loading; check log for details.
```

variants on this position:
```
chr1    16532574 .       TA      TAA,<*> 1.5     RefCall AN=0;AC=0,0     GT:GQ:DP:AD:VAF:PL      ./.:5:21:6,2,0:0.0952381,0:0,3,35,990,990,990
chr1    16532574 .       TA      TAAA,<*>,T      8       PASS    AN=2;AC=1,0,0   GT:GQ:DP:AD:VAF:PL      0/1:3:21:6,5,0,4:0.238095,0,0.190476:4,0,38,990,990,990,1,13,990,35
chr1    16532574 .       T       TAA,<*> 14.7    PASS    AN=2;AC=1,0     GT:GQ:DP:AD:VAF:PL      0/1:15:21:6,5,0:0.238095,0:14,0,43,990,990,990
```

I have some trouble finding out what is wrong with these variants, the <*> should not be the problem I assume since it is ""standard"" for DeepVariant",bartcharbon,https://github.com/dnanexus-rnd/GLnexus/issues/299
I_kwDOAgB6-M53Dhld,Genotyping specific sites from GVCF,OPEN,2023-11-16T17:38:19Z,2023-11-16T17:38:19Z,,"Greetings,

  I have GVCF files generated from deepvariant and I have a set of sites (in simplified vcf format) for which I want to extract genotypes for those sites. Is there an argument I can pass to GLNexus to genotype those vcf sites specifically? 

Passing Intervals usually wont give the 0/0 genotypes I want to see if thats what the likelihoods indicate.

Otherwise my guess is I will have to go back to the bams. Thanks.",bwubb,https://github.com/dnanexus-rnd/GLnexus/issues/300
I_kwDOAgB6-M53taDn,Failed to open exemplar gVCF file,CLOSED,2023-11-23T14:59:01Z,2024-02-15T15:35:48Z,2024-02-15T15:35:48Z,"Hi

I'm currently trying to use a Singularity image of GLnexus 1.4.1 to merge the deepvariant genome.vcf.gz files by chromosome, 1-19 chromosome.
I using the following command:

singularity run --bind /exports/cmvm/eddie/eb/groups/ogden_grp/nat/dv3/chromosome/chrom1:/io /exports/cmvm/eddie/eb/groups/ogden_grp/nat/glnexus/glnexus.sif glnexus_cli --config DeepVariantWGS *_1.g.vcf.gz > chromosome1.bcf


On April, I ran that command with 18 samples, it was work  and I got the result.
However, I got the new sample set (19 samples) so it will be 18+19 samples. I use the same command also deleted ""GLnexus.DB"" folder  just incase for conflict.


But I got the error

[33871] [2023-11-22 18:50:12.614] [GLnexus] [info] config CRC32C = 2932316105
[33871] [2023-11-22 18:50:12.614] [GLnexus] [info] init database, exemplar_vcf=A7_1.g.vcf.gz
[E::hts_open_format] Failed to open file A7_1.g.vcf.gz
[33871] [2023-11-22 18:50:12.615] [GLnexus] [error] Failed to initialize database: IOError: Failed to open exemplar gVCF file at  (A7_1.g.vcf.gz)
INFO:    Cleaning up image...

I try  not deleted GLnexus.DB but the error still the same, it look like can not open the gVCF file.

Could you kindly help me figure this out?

Thank you



",nat6an,https://github.com/dnanexus-rnd/GLnexus/issues/301
I_kwDOAgB6-M56FUzA,IOError: RocksDB kIOError,OPEN,2023-12-19T09:00:46Z,2023-12-19T09:00:46Z,,"Hi
I'm currently trying to use a Singularity image of GLnexus to merge the GATK sample.chr4.vcf.gz files for chromosome 4 only.
I using the following command and get error:

$ singularity run --bind /work/WFS/09.tmp:/home/wufusheng/04.tmp_bamfile /home/Singusoft/glnexus.sif glnexus_cli --config gatk --list chr4.list --dir chr4.GLnexus.DB --mem-gbytes 170 >chr4.bcf
[204941] [2023-12-19 15:46:35.312] [GLnexus] [info] glnexus_cli release v1.4.3-0-gcecf42e Sep 20 2021
[204941] [2023-12-19 15:46:35.314] [GLnexus] [info] detected jemalloc 5.2.1-0-gea6b3e973b477b8061e0076bb257dbd7f3faa756
[204941] [2023-12-19 15:46:35.317] [GLnexus] [info] Loading config preset gatk
[204941] [2023-12-19 15:46:35.325] [GLnexus] [info] config:
unifier_config:
  drop_filtered: false
  min_allele_copy_number: 1
  min_AQ1: 70
  min_AQ2: 40
  min_GQ: 40
  max_alleles_per_site: 32
  monoallelic_sites_for_lost_alleles: true
  preference: common
genotyper_config:
  revise_genotypes: true
  min_assumed_allele_frequency: 9.99999975e-05
  snv_prior_calibration: 1
  indel_prior_calibration: 1
  required_dp: 1
  allow_partial_data: false
  allele_dp_format: AD
  ref_dp_format: MIN_DP
  output_residuals: false
  more_PL: false
  squeeze: false
  trim_uncalled_alleles: false
  top_two_half_calls: false
  output_format: BCF
  liftover_fields:
    - {orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
    - {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}
    - {orig_names: [SB], name: SB, description: ""##FORMAT=<ID=SB,Number=4,Type=Integer,Description=\""Per-sample component statistics which comprise the Fishers Exact Test to detect strand bias.\"">"", type: int, number: basic, default_type: missing, count: 4, combi_method: missing, ignore_non_variants: false}
    - {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
    - {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}
[204941] [2023-12-19 15:46:35.325] [GLnexus] [info] config CRC32C = 1926883223
[204941] [2023-12-19 15:46:35.326] [GLnexus] [info] init database, exemplar_vcf=20D004183.chr4.g.vcf.gz
[204941] [2023-12-19 15:46:35.388] [GLnexus] [error] Failed to initialize database: IOError: RocksDB kIOError (IO error: While lock file: chr4.GLnexus.DB/LOCK: Function not implemented)


Does anyone know how to resolve the issues? ",fsw10,https://github.com/dnanexus-rnd/GLnexus/issues/302
I_kwDOAgB6-M58BIbf,malformed merged gVCF from DV config,CLOSED,2024-01-14T10:31:14Z,2024-01-14T15:33:02Z,2024-01-14T15:32:06Z,"Hi there,

I'm doing some analyses with the SGDP panel and need to create a joint VCF from the Giraffe-DV pipeline. Everything up to variant calling went smoothly, and even upon connecting/contacting the Google staff they confirmed there are not many options to do so as per GATK.

Then looking up the DV Git page I found `GLnexux` and tried to merge the 279 gVCF from the SGDP. Apparently, there are no evident errors (_see_ [merge.log](https://github.com/dnanexus-rnd/GLnexus/files/13931092/merge.log) file); however, for some reason, the output VCF is malformed (_see_ screenshot). In particular, the header and samples' names seem to be fine but the actual body is corrupted. For clarity I share the script I run:
```
#!/bin/bash
#
#SBATCH --nodes=1 --ntasks=1 --cpus-per-task=32
#SBATCH --time=24:00:00
#SBATCH --mem=450gb
#
#SBATCH --job-name=merge
#SBATCH --output=merge.out
#
#SBATCH --partition=<partition>
#
#SBATCH --account=<account_name>

cd /path/to/folder

singularity run -B /path/to/folder glnexus_v1.4.1.sif \
  glnexus_cli \
  --config DeepVariantWGS \
  --dir temp_merge \
  --list to_merge.list \
  --threads 32 > SGDP_panel.vcf
```
**Screenshot**
![Screenshot 2024-01-14 at 11 26 44 AM](https://github.com/dnanexus-rnd/GLnexus/assets/98895614/d5e65706-be03-4614-8e98-75382a0bc9f5)",Overcraft90,https://github.com/dnanexus-rnd/GLnexus/issues/303
I_kwDOAgB6-M59q_Zl,Failed Install when using Non-Docker file Install,OPEN,2024-01-30T17:45:18Z,2024-01-30T17:45:18Z,,"I am not in the docker group so I am forced to proceed with the install that does not use docker. When I copy and paste the steps provided I get the following error.

![image](https://github.com/dnanexus-rnd/GLnexus/assets/131883197/0616af7e-4bc8-4a75-a550-8d133cbac7a3)
",cantlap,https://github.com/dnanexus-rnd/GLnexus/issues/304
I_kwDOAgB6-M59rCYk,std::logic_error when running Basic Command,OPEN,2024-01-30T17:52:34Z,2024-08-07T07:18:29Z,,"I am getting the following error message when I try to run this command:

singularity run docker://ghcr.io/dnanexus-rnd/glnexus:v1.4.1 glnexus_cli -d {outdir} -c DeepVariant_unfiltered --list {bam file list}

INFO:    Using cached SIF image
INFO:    underlay of /etc/localtime required more than 50 (77) bind mounts
[339884] [2024-01-30 12:49:16.486] [GLnexus] [info] glnexus_cli release v1.4.1-0-g68e25e5 Aug 13 2021
[339884] [2024-01-30 12:49:16.488] [GLnexus] [info] detected jemalloc 5.2.1-0-gea6b3e973b477b8061e0076bb257dbd7f3faa756
terminate called after throwing an instance of 'std::logic_error'
  what():  basic_string::_M_construct null not valid
Aborted (core dumped)",cantlap,https://github.com/dnanexus-rnd/GLnexus/issues/305
I_kwDOAgB6-M5_7TF7,RNC field not comma-separated,OPEN,2024-02-21T09:33:23Z,2024-10-22T00:09:56Z,,"The `FORMAT/RNC` field is encoded as a string of length two rather than a list of two caracters.

IOW, it is:

```
GT:RNC      ./.:II     1/1:15:1,14:1:16,4,0:..
```

But (arguably?) should be:

```
GT:RNC      ./.:I,I     1/1:15:1,14:1:16,4,0:.,.
```

What are your thoughts?

Also see

- https://github.com/zaeleus/noodles/issues/235
- https://github.com/samtools/hts-specs/issues/631",holtgrewe,https://github.com/dnanexus-rnd/GLnexus/issues/306
I_kwDOAgB6-M6BTO6b,Optimizing memory usage,OPEN,2024-03-05T13:57:40Z,2024-03-05T13:57:40Z,,"Is it possible to save some intermediate results to reduce memory usage?
I'm using GLnexus for a big project (around 5k WES on test, expecting around 30-35k in total). 
We divided genome in 100 +/- equal pieces and run each piece separately from joint step. So we have 5k full gVCFs and 100 multi-sample VCF.
And temporary files for each genome part require a LOT OF storage. Is it possible to optimize these storage usage?",georgiiprovisor,https://github.com/dnanexus-rnd/GLnexus/issues/308
I_kwDOAgB6-M6BouKZ,bad_alloc,OPEN,2024-03-07T22:31:19Z,2024-08-04T19:50:28Z,,"Hello -

I am trying to run GLNExus to combine gVCFs produced by DeepVariant. The input is 16 single-sample gVCFs, aligned to the rhesus macaque genome. I split the job to run one contig at a time, and I find that chromosome 1 consistently gives a std::bad_alloc error. Below is the command and output. Can you suggest any debugging steps I could try?

```
docker run --rm=true \
-v /SequenceO.work:/work \
-w /work \
-v /mnt/scratch/prime-seq/tmp.lwcDaskfexRun_GLNexus_2024-02-12_12-17-24:/tmp \
--memory=120g \
ghcr.io/dnanexus-rnd/glnexus:v1.4.3 \
glnexus_cli --config DeepVariant \
--bed /work/contig.bed \
--trim-uncalled-alleles \
--mem-gbytes 120 \
--threads 8 \
/work/TNPRC-GR91.g.vcf.gz /work/TNPRC-HF97.g.vcf.gz /work/TNPRC-IJ90.g.vcf.gz /work/TNPRC-IP72.g.vcf.gz /work/TNPRC-GH30.g.vcf.gz /work/TNPRC-HR17.g.vcf.gz /work/TNPRC-FP85.g.vcf.gz /work/TNPRC-FP05.g.vcf.gz /work/TNPRC-EP96.g.vcf.gz /work/TNPRC-DN75.g.vcf.gz /work/TNPRC-II86.g.vcf.gz /work/TNPRC-IB18.g.vcf.gz /work/TNPRC-II50.g.vcf.gz /work/TNPRC-HR27.g.vcf.gz /work/TNPRC-HP89.g.vcf.gz /work/TNPRC-GB29.g.vcf.gz | bcftools view | bgzip -c > myFile.vcf.gz

```
In the command, contig.bed is a one-line bed file specifying chromosome 1. 

The output is the following:

```
07 Mar 2024 13:43:06,239 DEBUG: 	[1] [2024-03-07 21:43:06.239] [GLnexus] [info] glnexus_cli release v1.4.3-0-gcecf42e Sep 20 2021
07 Mar 2024 13:43:06,241 DEBUG: 	[1] [2024-03-07 21:43:06.239] [GLnexus] [info] detected jemalloc 5.2.1-0-gea6b3e973b477b8061e0076bb257dbd7f3faa756
07 Mar 2024 13:43:06,243 DEBUG: 	[1] [2024-03-07 21:43:06.239] [GLnexus] [info] Loading config preset DeepVariant
07 Mar 2024 13:43:06,247 DEBUG: 	[1] [2024-03-07 21:43:06.247] [GLnexus] [info] config:
07 Mar 2024 13:43:06,249 DEBUG: 	unifier_config:
07 Mar 2024 13:43:06,250 DEBUG: 	  drop_filtered: false
07 Mar 2024 13:43:06,252 DEBUG: 	  min_allele_copy_number: 1
07 Mar 2024 13:43:06,253 DEBUG: 	  min_AQ1: 10
07 Mar 2024 13:43:06,255 DEBUG: 	  min_AQ2: 10
07 Mar 2024 13:43:06,256 DEBUG: 	  min_GQ: 0
07 Mar 2024 13:43:06,258 DEBUG: 	  max_alleles_per_site: 32
07 Mar 2024 13:43:06,259 DEBUG: 	  monoallelic_sites_for_lost_alleles: true
07 Mar 2024 13:43:06,260 DEBUG: 	  preference: common
07 Mar 2024 13:43:06,262 DEBUG: 	genotyper_config:
07 Mar 2024 13:43:06,263 DEBUG: 	  revise_genotypes: true
07 Mar 2024 13:43:06,265 DEBUG: 	  min_assumed_allele_frequency: 9.99999975e-05
07 Mar 2024 13:43:06,266 DEBUG: 	  snv_prior_calibration: 0.600000024
07 Mar 2024 13:43:06,268 DEBUG: 	  indel_prior_calibration: 0.449999988
07 Mar 2024 13:43:06,269 DEBUG: 	  required_dp: 0
07 Mar 2024 13:43:06,270 DEBUG: 	  allow_partial_data: true
07 Mar 2024 13:43:06,271 DEBUG: 	  allele_dp_format: AD
07 Mar 2024 13:43:06,273 DEBUG: 	  ref_dp_format: MIN_DP
07 Mar 2024 13:43:06,274 DEBUG: 	  output_residuals: false
07 Mar 2024 13:43:06,275 DEBUG: 	  more_PL: true
07 Mar 2024 13:43:06,276 DEBUG: 	  squeeze: false
07 Mar 2024 13:43:06,277 DEBUG: 	  trim_uncalled_alleles: true
07 Mar 2024 13:43:06,279 DEBUG: 	  top_two_half_calls: false
07 Mar 2024 13:43:06,280 DEBUG: 	  output_format: BCF
07 Mar 2024 13:43:06,281 DEBUG: 	  liftover_fields:
07 Mar 2024 13:43:06,282 DEBUG: 	    - {orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are filtered)\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
07 Mar 2024 13:43:06,284 DEBUG: 	    - {orig_names: [AD], name: AD, description: ""##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\""Allelic depths for the ref and alt alleles in the order listed\"">"", type: int, number: alleles, default_type: zero, count: 0, combi_method: min, ignore_non_variants: false}
07 Mar 2024 13:43:06,285 DEBUG: 	    - {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}
07 Mar 2024 13:43:06,286 DEBUG: 	    - {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}
07 Mar 2024 13:43:06,287 DEBUG: 	[1] [2024-03-07 21:43:06.247] [GLnexus] [info] config CRC32C = 2932316105
07 Mar 2024 13:43:06,289 DEBUG: 	[1] [2024-03-07 21:43:06.248] [GLnexus] [info] init database, exemplar_vcf=/work/TNPRC-GR91.g.vcf.gz
07 Mar 2024 13:43:06,620 DEBUG: 	[1] [2024-03-07 21:43:06.620] [GLnexus] [info] Initialized GLnexus database in GLnexus.DB
07 Mar 2024 13:43:06,621 DEBUG: 	[1] [2024-03-07 21:43:06.620] [GLnexus] [info] bucket size: 30000
07 Mar 2024 13:43:06,623 DEBUG: 	[1] [2024-03-07 21:43:06.620] [GLnexus] [info] contigs: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ML143117.1 ML143118.1 ML143119.1 ML143120.1 ML143121.1 ML143122.1 ML143123.1 ML143124.1 MT QNVO02000039.1 QNVO02000040.1 QNVO02000041.1 QNVO02000042.1 QNVO02000043.1 QNVO02000044.1 QNVO02000045.1 QNVO02000046.1 QNVO02000047.1 QNVO02000048.1 QNVO02000049.1 QNVO02000050.1 QNVO02000051.1 QNVO02000052.1 QNVO02000061.1 QNVO02000062.1 QNVO02000063.1 QNVO02000064.1 QNVO02000065.1 QNVO02000066.1 QNVO02000067.1 QNVO02000068.1 QNVO02000069.1 QNVO02000070.1 QNVO02000071.1 QNVO02000072.1 QNVO02000073.1 QNVO02000074.1 QNVO02000082.1 QNVO02000083.1 QNVO02000084.1 QNVO02000085.1 QNVO02000086.1 QNVO02000087.1 QNVO02000088.1 QNVO02000096.1 QNVO02000097.1 QNVO02000098.1 QNVO02000099.1 QNVO02000100.1 QNVO02000101.1 QNVO02000102.1 QNVO02000113.1 QNVO02000114.1 QNVO02000115.1 QNVO02000116.1 QNVO02000117.1 QNVO02000118.1 QNVO02000119.1 QNVO02000120.1 QNVO02000121.1 QNVO02000122.1 QNVO02000123.1 QNVO02000124.1 QNVO02000125.1 QNVO02000126.1 QNVO02000127.1 QNVO02000128.1 QNVO02000129.1 QNVO02000130.1 QNVO02000141.1 QNVO02000142.1 QNVO02000143.1 QNVO02000144.1 QNVO02000145.1 QNVO02000146.1 QNVO02000147.1 QNVO02000148.1 QNVO02000149.1 QNVO02000150.1 QNVO02000151.1 QNVO02000152.1 QNVO02000153.1 QNVO02000154.1 QNVO02000166.1 QNVO02000167.1 QNVO02000168.1 QNVO02000169.1 QNVO02000170.1 QNVO02000171.1 QNVO02000172.1 QNVO02000173.1 QNVO02000174.1 QNVO02000175.1 QNVO02000176.1 QNVO02000177.1 QNVO02000178.1 QNVO02000179.1 QNVO02000180.1 QNVO02000181.1 QNVO02000194.1 QNVO02000195.1 QNVO02000196.1 QNVO02000197.1 QNVO02000198.1 QNVO02000199.1 QNVO02000200.1 QNVO02000201.1 QNVO02000202.1 QNVO02000203.1 QNVO02000204.1 QNVO02000205.1 QNVO02000206.1 QNVO02000207.1 QNVO02000208.1 QNVO02000209.1 QNVO02000210.1 QNVO02000211.1 QNVO02000212.1 QNVO02000216.1 QNVO02000217.1 QNVO02000218.1 QNVO02000219.1 QNVO02000220.1 QNVO02000221.1 QNVO02000222.1 QNVO02000237.1 QNVO02000238.1 QNVO02000239.1 QNVO02000240.1 QNVO02000241.1 QNVO02000242.1 QNVO02000243.1 QNVO02000244.1 QNVO02000245.1 QNVO02000246.1 QNVO02000247.1 QNVO02000248.1 QNVO02000249.1 QNVO02000250.1 QNVO02000251.1 QNVO02000252.1 QNVO02000253.1 QNVO02000254.1 QNVO02000255.1 QNVO02000259.1 QNVO02000260.1 QNVO02000261.1 QNVO02000262.1 QNVO02000263.1 QNVO02000264.1 QNVO02000265.1 QNVO02000266.1 QNVO02000267.1 QNVO02000268.1 QNVO02000269.1 QNVO02000270.1 QNVO02000271.1 QNVO02000272.1 QNVO02000273.1 QNVO02000274.1 QNVO02000275.1 QNVO02000276.1 QNVO02000277.1 QNVO02000278.1 QNVO02000279.1 QNVO02000293.1 QNVO02000294.1 QNVO02000295.1 QNVO02000296.1 QNVO02000297.1 QNVO02000298.1 QNVO02000299.1 QNVO02000300.1 QNVO02000301.1 QNVO02000302.1 QNVO02000303.1 QNVO02000304.1 QNVO02000305.1 QNVO02000306.1 QNVO02000315.1 QNVO02000316.1 QNVO02000317.1 QNVO02000318.1 QNVO02000319.1 QNVO02000320.1 QNVO02000321.1 QNVO02000322.1 QNVO02000323.1 QNVO02000324.1 QNVO02000325.1 QNVO02000326.1 QNVO02000327.1 QNVO02000328.1 QNVO02000329.1 QNVO02000330.1 QNVO02000331.1 QNVO02000332.1 QNVO02000333.1 QNVO02000334.1 QNVO02000347.1 QNVO02000348.1 QNVO02000349.1 QNVO02000350.1 QNVO02000351.1 QNVO02000352.1 QNVO02000353.1 QNVO02000354.1 QNVO02000355.1 QNVO02000356.1 QNVO02000357.1 QNVO02000358.1 QNVO02000359.1 QNVO02000360.1 QNVO02000361.1 QNVO02000362.1 QNVO02000371.1 QNVO02000372.1 QNVO02000373.1 QNVO02000374.1 QNVO02000375.1 QNVO02000376.1 QNVO02000377.1 QNVO02000378.1 QNVO02000379.1 QNVO02000380.1 QNVO02000381.1 QNVO02000382.1 QNVO02000383.1 QNVO02000384.1 QNVO02000385.1 QNVO02000393.1 QNVO02000394.1 QNVO02000395.1 QNVO02000396.1 QNVO02000397.1 QNVO02000398.1 QNVO02000399.1 QNVO02000400.1 QNVO02000401.1 QNVO02000402.1 QNVO02000403.1 QNVO02000404.1 QNVO02000405.1 QNVO02000406.1 QNVO02000424.1 QNVO02000425.1 QNVO02000426.1 QNVO02000427.1 QNVO02000428.1 QNVO02000429.1 QNVO02000430.1 QNVO02000431.1 QNVO02000432.1 QNVO02000433.1 QNVO02000434.1 QNVO02000435.1 QNVO02000436.1 QNVO02000437.1 QNVO02000438.1 QNVO02000439.1 QNVO02000440.1 QNVO02000441.1 QNVO02000458.1 QNVO02000459.1 QNVO02000460.1 QNVO02000461.1 QNVO02000462.1 QNVO02000463.1 QNVO02000464.1 QNVO02000465.1 QNVO02000466.1 QNVO02000467.1 QNVO02000468.1 QNVO02000469.1 QNVO02000470.1 QNVO02000471.1 QNVO02000472.1 QNVO02000473.1 QNVO02000504.1 QNVO02000505.1 QNVO02000506.1 QNVO02000507.1 QNVO02000508.1 QNVO02000509.1 QNVO02000510.1 QNVO02000511.1 QNVO02000512.1 QNVO02000513.1 QNVO02000514.1 QNVO02000515.1 QNVO02000516.1 QNVO02000517.1 QNVO02000518.1 QNVO02000519.1 QNVO02000520.1 QNVO02000521.1 QNVO02000522.1 QNVO02000523.1 QNVO02000524.1 QNVO02000525.1 QNVO02000526.1 QNVO02000527.1 QNVO02000528.1 QNVO02000529.1 QNVO02000530.1 QNVO02000531.1 QNVO02000532.1 QNVO02000533.1 QNVO02000534.1 QNVO02000535.1 QNVO02000536.1 QNVO02000537.1 QNVO02000538.1 QNVO02000539.1 QNVO02000540.1 QNVO02000541.1 QNVO02000542.1 QNVO02000543.1 QNVO02000544.1 QNVO02000545.1 QNVO02000546.1 QNVO02000547.1 QNVO02000548.1 QNVO02000549.1 QNVO02000550.1 QNVO02000551.1 QNVO02000552.1 QNVO02000553.1 QNVO02000554.1 QNVO02000555.1 QNVO02000556.1 QNVO02000557.1 QNVO02000558.1 QNVO02000559.1 QNVO02000560.1 QNVO02000561.1 QNVO02000562.1 QNVO02000563.1 QNVO02000564.1 QNVO02000565.1 QNVO02000566.1 QNVO02000567.1 QNVO02000568.1 QNVO02000569.1 QNVO02000570.1 QNVO02000571.1 QNVO02000572.1 QNVO02000573.1 QNVO02000574.1 QNVO02000575.1 QNVO02000576.1 QNVO02000577.1 QNVO02000578.1 QNVO02000579.1 QNVO02000580.1 QNVO02000581.1 QNVO02000582.1 QNVO02000583.1 QNVO02000584.1 QNVO02000585.1 QNVO02000586.1 QNVO02000587.1 QNVO02000588.1 QNVO02000589.1 QNVO02000590.1 QNVO02000591.1 QNVO02000592.1 QNVO02000593.1 QNVO02000594.1 QNVO02000595.1 QNVO02000596.1 QNVO02000597.1 QNVO02000598.1 QNVO02000599.1 QNVO02000600.1 QNVO02000601.1 QNVO02000602.1 QNVO02000603.1 QNVO02000604.1 QNVO02000605.1 QNVO02000606.1 QNVO02000607.1 QNVO02000608.1 QNVO02000609.1 QNVO02000610.1 QNVO02000611.1 QNVO02000612.1 QNVO02000613.1 QNVO02000614.1 QNVO02000615.1 QNVO02000616.1 QNVO02000617.1 QNVO02000618.1 QNVO02000619.1 QNVO02000620.1 QNVO02000621.1 QNVO02000622.1 QNVO02000623.1 QNVO02000624.1 QNVO02000625.1 QNVO02000626.1 QNVO02000627.1 QNVO02000628.1 QNVO02000632.1 QNVO02000633.1 QNVO02000634.1 QNVO02000635.1 QNVO02000636.1 QNVO02000637.1 QNVO02000638.1 QNVO02000639.1 QNVO02000640.1 QNVO02000641.1 QNVO02000642.1 QNVO02000643.1 QNVO02000644.1 QNVO02000645.1 QNVO02000646.1 QNVO02000647.1 QNVO02000648.1 QNVO02000649.1 QNVO02000650.1 QNVO02000651.1 QNVO02000652.1 QNVO02000653.1 QNVO02000654.1 QNVO02000655.1 QNVO02000656.1 QNVO02000657.1 QNVO02000658.1 QNVO02000659.1 QNVO02000660.1 QNVO02000661.1 QNVO02000662.1 QNVO02000663.1 QNVO02000664.1 QNVO02000665.1 QNVO02000666.1 QNVO02000667.1 QNVO02000668.1 QNVO02000669.1 QNVO02000670.1 QNVO02000671.1 QNVO02000672.1 QNVO02000673.1 QNVO02000674.1 QNVO02000675.1 QNVO02000676.1 QNVO02000677.1 QNVO02000678.1 QNVO02000679.1 QNVO02000680.1 QNVO02000681.1 QNVO02000682.1 QNVO02000683.1 QNVO02000684.1 QNVO02000685.1 QNVO02000686.1 QNVO02000687.1 QNVO02000688.1 QNVO02000689.1 QNVO02000690.1 QNVO02000691.1 QNVO02000692.1 QNVO02000693.1 QNVO02000694.1 QNVO02000695.1 QNVO02000696.1 QNVO02000697.1 QNVO02000698.1 QNVO02000699.1 QNVO02000700.1 QNVO02000701.1 QNVO02000702.1 QNVO02000703.1 QNVO02000704.1 QNVO02000705.1 QNVO02000706.1 QNVO02000707.1 QNVO02000708.1 QNVO02000709.1 QNVO02000710.1 QNVO02000711.1 QNVO02000712.1 QNVO02000713.1 QNVO02000714.1 QNVO02000715.1 QNVO02000716.1 QNVO02000717.1 QNVO02000718.1 QNVO02000719.1 QNVO02000720.1 QNVO02000721.1 QNVO02000722.1 QNVO02000723.1 QNVO02000724.1 QNVO02000725.1 QNVO02000726.1 QNVO02000727.1 QNVO02000728.1 QNVO02000729.1 QNVO02000730.1 QNVO02000731.1 QNVO02000732.1 QNVO02000733.1 QNVO02000734.1 QNVO02000735.1 QNVO02000736.1 QNVO02000737.1 QNVO02000738.1 QNVO02000739.1 QNVO02000740.1 QNVO02000741.1 QNVO02000746.1 QNVO02000747.1 QNVO02000748.1 QNVO02000749.1 QNVO02000750.1 QNVO02000751.1 QNVO02000752.1 QNVO02000753.1 QNVO02000754.1 QNVO02000755.1 QNVO02000756.1 QNVO02000757.1 QNVO02000758.1 QNVO02000759.1 QNVO02000760.1 QNVO02000761.1 QNVO02000762.1 QNVO02000763.1 QNVO02000764.1 QNVO02000765.1 QNVO02000766.1 QNVO02000767.1 QNVO02000768.1 QNVO02000769.1 QNVO02000770.1 QNVO02000771.1 QNVO02000772.1 QNVO02000773.1 QNVO02000774.1 QNVO02000775.1 QNVO02000776.1 QNVO02000777.1 QNVO02000778.1 QNVO02000779.1 QNVO02000780.1 QNVO02000781.1 QNVO02000782.1 QNVO02000783.1 QNVO02000784.1 QNVO02000785.1 QNVO02000786.1 QNVO02000787.1 QNVO02000788.1 QNVO02000789.1 QNVO02000790.1 QNVO02000791.1 QNVO02000792.1 QNVO02000793.1 QNVO02000794.1 QNVO02000795.1 QNVO02000796.1 QNVO02000797.1 QNVO02000798.1 QNVO02000799.1 QNVO02000800.1 QNVO02000801.1 QNVO02000802.1 QNVO02000803.1 QNVO02000804.1 QNVO02000805.1 QNVO02000806.1 QNVO02000807.1 QNVO02000808.1 QNVO02000809.1 QNVO02000810.1 QNVO02000811.1 QNVO02000812.1 QNVO02000813.1 QNVO02000814.1 QNVO02000815.1 QNVO02000816.1 QNVO02000817.1 QNVO02000818.1 QNVO02000819.1 QNVO02000820.1 QNVO02000821.1 QNVO02000822.1 QNVO02000823.1 QNVO02000824.1 QNVO02000825.1 QNVO02000826.1 QNVO02000827.1 QNVO02000828.1 QNVO02000829.1 QNVO02000830.1 QNVO02000831.1 QNVO02000832.1 QNVO02000833.1 QNVO02000834.1 QNVO02000835.1 QNVO02000836.1 QNVO02000837.1 QNVO02000838.1 QNVO02000839.1 QNVO02000840.1 QNVO02000841.1 QNVO02000842.1 QNVO02000843.1 QNVO02000844.1 QNVO02000845.1 QNVO02000846.1 QNVO02000847.1 QNVO02000848.1 QNVO02000849.1 QNVO02000850.1 QNVO02000851.1 QNVO02000852.1 QNVO02000853.1 QNVO02000854.1 QNVO02000855.1 QNVO02000856.1 QNVO02000857.1 QNVO02000858.1 QNVO02000859.1 QNVO02000860.1 QNVO02000861.1 QNVO02000862.1 QNVO02000863.1 QNVO02000864.1 QNVO02000865.1 QNVO02000866.1 QNVO02000867.1 QNVO02000868.1 QNVO02000869.1 QNVO02000870.1 QNVO02000871.1 QNVO02000872.1 QNVO02000873.1 QNVO02000874.1 QNVO02000875.1 QNVO02000876.1 QNVO02000877.1 QNVO02000878.1 QNVO02000879.1 QNVO02000880.1 QNVO02000881.1 QNVO02000882.1 QNVO02000883.1 QNVO02000884.1 QNVO02000885.1 QNVO02000886.1 QNVO02000887.1 QNVO02000888.1 QNVO02000889.1 QNVO02000890.1 QNVO02000891.1 QNVO02000892.1 QNVO02000893.1 QNVO02000894.1 QNVO02000895.1 QNVO02000896.1 QNVO02000897.1 QNVO02000898.1 QNVO02000899.1 QNVO02000900.1 QNVO02000901.1 QNVO02000902.1 QNVO02000903.1 QNVO02000904.1 QNVO02000905.1 QNVO02000906.1 QNVO02000907.1 QNVO02000908.1 QNVO02000909.1 QNVO02000910.1 QNVO02000911.1 QNVO02000912.1 QNVO02000913.1 QNVO02000914.1 QNVO02000915.1 QNVO02000916.1 QNVO02000917.1 QNVO02000918.1 QNVO02000919.1 QNVO02000920.1 QNVO02000921.1 QNVO02000922.1 QNVO02000923.1 QNVO02000924.1 QNVO02000925.1 QNVO02000926.1 QNVO02000927.1 QNVO02000928.1 QNVO02000929.1 QNVO02000930.1 QNVO02000931.1 QNVO02000932.1 QNVO02000933.1 QNVO02000934.1 QNVO02000935.1 QNVO02000936.1 QNVO02000937.1 QNVO02000938.1 QNVO02000939.1 QNVO02000940.1 QNVO02000941.1 QNVO02000942.1 QNVO02000943.1 QNVO02000944.1 QNVO02000945.1 QNVO02000946.1 QNVO02000947.1 QNVO02000948.1 QNVO02000949.1 QNVO02000950.1 QNVO02000951.1 QNVO02000952.1 QNVO02000953.1 QNVO02000954.1 QNVO02000955.1 QNVO02000956.1 QNVO02000957.1 QNVO02000958.1 QNVO02000959.1 QNVO02000960.1 QNVO02000961.1 QNVO02000962.1 QNVO02000963.1 QNVO02000964.1 QNVO02000965.1 QNVO02000969.1 QNVO02000970.1 QNVO02000971.1 QNVO02000972.1 QNVO02000973.1 QNVO02000974.1 QNVO02000975.1 QNVO02000976.1 QNVO02000977.1 QNVO02000978.1 QNVO02000979.1 QNVO02000980.1 QNVO02000981.1 QNVO02000982.1 QNVO02000983.1 QNVO02000984.1 QNVO02000985.1 QNVO02000986.1 QNVO02000987.1 QNVO02000988.1 QNVO02000989.1 QNVO02000990.1 QNVO02000991.1 QNVO02000992.1 QNVO02000993.1 QNVO02000994.1 QNVO02000995.1 QNVO02000996.1 QNVO02000997.1 QNVO02000998.1 QNVO02000999.1 QNVO02001000.1 QNVO02001001.1 QNVO02001002.1 QNVO02001003.1 QNVO02001004.1 QNVO02001005.1 QNVO02001006.1 QNVO02001007.1 QNVO02001008.1 QNVO02001009.1 QNVO02001010.1 QNVO02001011.1 QNVO02001012.1 QNVO02001013.1 QNVO02001014.1 QNVO02001015.1 QNVO02001016.1 QNVO02001017.1 QNVO02001018.1 QNVO02001019.1 QNVO02001020.1 QNVO02001021.1 QNVO02001022.1 QNVO02001023.1 QNVO02001024.1 QNVO02001025.1 QNVO02001026.1 QNVO02001027.1 QNVO02001028.1 QNVO02001029.1 QNVO02001030.1 QNVO02001031.1 QNVO02001032.1 QNVO02001033.1 QNVO02001034.1 QNVO02001035.1 QNVO02001036.1 QNVO02001037.1 QNVO02001038.1 QNVO02001039.1 QNVO02001040.1 QNVO02001041.1 QNVO02001042.1 QNVO02001043.1 QNVO02001044.1 QNVO02001045.1 QNVO02001046.1 QNVO02001047.1 QNVO02001048.1 QNVO02001049.1 QNVO02001050.1 QNVO02001051.1 QNVO02001052.1 QNVO02001053.1 QNVO02001054.1 QNVO02001055.1 QNVO02001056.1 QNVO02001057.1 QNVO02001058.1 QNVO02001059.1 QNVO02001060.1 QNVO02001061.1 QNVO02001062.1 QNVO02001063.1 QNVO02001064.1 QNVO02001065.1 QNVO02001066.1 QNVO02001067.1 QNVO02001068.1 QNVO02001069.1 QNVO02001070.1 QNVO02001071.1 QNVO02001072.1 QNVO02001073.1 QNVO02001074.1 QNVO02001075.1 QNVO02001076.1 QNVO02001077.1 QNVO02001078.1 QNVO02001079.1 QNVO02001080.1 QNVO02001081.1 QNVO02001082.1 QNVO02001083.1 QNVO02001084.1 QNVO02001085.1 QNVO02001086.1 QNVO02001087.1 QNVO02001088.1 QNVO02001089.1 QNVO02001090.1 QNVO02001091.1 QNVO02001092.1 QNVO02001093.1 QNVO02001094.1 QNVO02001095.1 QNVO02001096.1 QNVO02001097.1 QNVO02001098.1 QNVO02001099.1 QNVO02001100.1 QNVO02001101.1 QNVO02001102.1 QNVO02001103.1 QNVO02001104.1 QNVO02001105.1 QNVO02001106.1 QNVO02001107.1 QNVO02001108.1 QNVO02001109.1 QNVO02001110.1 QNVO02001111.1 QNVO02001112.1 QNVO02001113.1 QNVO02001114.1 QNVO02001115.1 QNVO02001116.1 QNVO02001117.1 QNVO02001118.1 QNVO02001119.1 QNVO02001120.1 QNVO02001121.1 QNVO02001122.1 QNVO02001123.1 QNVO02001124.1 QNVO02001125.1 QNVO02001126.1 QNVO02001127.1 QNVO02001128.1 QNVO02001129.1 QNVO02001130.1 QNVO02001131.1 QNVO02001132.1 QNVO02001133.1 QNVO02001134.1 QNVO02001135.1 QNVO02001136.1 QNVO02001137.1 QNVO02001138.1 QNVO02001139.1 QNVO02001140.1 QNVO02001141.1 QNVO02001142.1 QNVO02001143.1 QNVO02001144.1 QNVO02001145.1 QNVO02001146.1 QNVO02001147.1 QNVO02001148.1 QNVO02001149.1 QNVO02001150.1 QNVO02001151.1 QNVO02001152.1 QNVO02001153.1 QNVO02001154.1 QNVO02001155.1 QNVO02001156.1 QNVO02001157.1 QNVO02001158.1 QNVO02001159.1 QNVO02001160.1 QNVO02001161.1 QNVO02001162.1 QNVO02001163.1 QNVO02001164.1 QNVO02001165.1 QNVO02001166.1 QNVO02001167.1 QNVO02001168.1 QNVO02001169.1 QNVO02001170.1 QNVO02001171.1 QNVO02001172.1 QNVO02001173.1 QNVO02001174.1 QNVO02001175.1 QNVO02001176.1 QNVO02001177.1 QNVO02001178.1 QNVO02001179.1 QNVO02001180.1 QNVO02001181.1 QNVO02001182.1 QNVO02001183.1 QNVO02001184.1 QNVO02001185.1 QNVO02001186.1 QNVO02001187.1 QNVO02001188.1 QNVO02001189.1 QNVO02001190.1 QNVO02001191.1 QNVO02001192.1 QNVO02001193.1 QNVO02001194.1 QNVO02001195.1 QNVO02001196.1 QNVO02001197.1 QNVO02001198.1 QNVO02001199.1 QNVO02001200.1 QNVO02001201.1 QNVO02001202.1 QNVO02001203.1 QNVO02001204.1 QNVO02001205.1 QNVO02001206.1 QNVO02001207.1 QNVO02001208.1 QNVO02001209.1 QNVO02001210.1 QNVO02001211.1 QNVO02001212.1 QNVO02001213.1 QNVO02001214.1 QNVO02001215.1 QNVO02001216.1 QNVO02001217.1 QNVO02001218.1 QNVO02001219.1 QNVO02001220.1 QNVO02001221.1 QNVO02001222.1 QNVO02001223.1 QNVO02001224.1 QNVO02001225.1 QNVO02001226.1 QNVO02001227.1 QNVO02001228.1 QNVO02001229.1 QNVO02001230.1 QNVO02001231.1 QNVO02001232.1 QNVO02001233.1 QNVO02001234.1 QNVO02001235.1 QNVO02001236.1 QNVO02001237.1 QNVO02001238.1 QNVO02001239.1 QNVO02001240.1 QNVO02001241.1 QNVO02001242.1 QNVO02001243.1 QNVO02001244.1 QNVO02001245.1 QNVO02001246.1 QNVO02001247.1 QNVO02001248.1 QNVO02001249.1 QNVO02001250.1 QNVO02001251.1 QNVO02001252.1 QNVO02001253.1 QNVO02001254.1 QNVO02001255.1 QNVO02001256.1 QNVO02001257.1 QNVO02001258.1 QNVO02001259.1 QNVO02001260.1 QNVO02001261.1 QNVO02001262.1 QNVO02001263.1 QNVO02001264.1 QNVO02001265.1 QNVO02001266.1 QNVO02001267.1 QNVO02001268.1 QNVO02001269.1 QNVO02001270.1 QNVO02001271.1 QNVO02001272.1 QNVO02001273.1 QNVO02001274.1 QNVO02001275.1 QNVO02001276.1 QNVO02001277.1 QNVO02001278.1 QNVO02001279.1 QNVO02001280.1 QNVO02001281.1 QNVO02001282.1 QNVO02001283.1 QNVO02001284.1 QNVO02001285.1 QNVO02001286.1 QNVO02001287.1 QNVO02001288.1 QNVO02001289.1 QNVO02001290.1 QNVO02001291.1 QNVO02001292.1 QNVO02001293.1 QNVO02001294.1 QNVO02001295.1 QNVO02001296.1 QNVO02001297.1 QNVO02001298.1 QNVO02001299.1 QNVO02001300.1 QNVO02001301.1 QNVO02001302.1 QNVO02001303.1 QNVO02001304.1 QNVO02001305.1 QNVO02001306.1 QNVO02001307.1 QNVO02001308.1 QNVO02001309.1 QNVO02001310.1 QNVO02001311.1 QNVO02001312.1 QNVO02001313.1 QNVO02001314.1 QNVO02001315.1 QNVO02001316.1 QNVO02001317.1 QNVO02001318.1 QNVO02001319.1 QNVO02001320.1 QNVO02001321.1 QNVO02001322.1 QNVO02001323.1 QNVO02001324.1 QNVO02001325.1 QNVO02001326.1 QNVO02001327.1 QNVO02001328.1 QNVO02001329.1 QNVO02001330.1 QNVO02001331.1 QNVO02001332.1 QNVO02001333.1 QNVO02001334.1 QNVO02001335.1 QNVO02001336.1 QNVO02001337.1 QNVO02001338.1 QNVO02001339.1 QNVO02001340.1 QNVO02001341.1 QNVO02001342.1 QNVO02001343.1 QNVO02001344.1 QNVO02001345.1 QNVO02001346.1 QNVO02001347.1 QNVO02001348.1 QNVO02001349.1 QNVO02001350.1 QNVO02001351.1 QNVO02001352.1 QNVO02001353.1 QNVO02001354.1 QNVO02001355.1 QNVO02001356.1 QNVO02001357.1 QNVO02001358.1 QNVO02001359.1 QNVO02001360.1 QNVO02001361.1 QNVO02001362.1 QNVO02001363.1 QNVO02001364.1 QNVO02001365.1 QNVO02001366.1 QNVO02001367.1 QNVO02001368.1 QNVO02001369.1 QNVO02001370.1 QNVO02001371.1 QNVO02001372.1 QNVO02001373.1 QNVO02001374.1 QNVO02001375.1 QNVO02001376.1 QNVO02001377.1 QNVO02001378.1 QNVO02001379.1 QNVO02001380.1 QNVO02001381.1 QNVO02001382.1 QNVO02001383.1 QNVO02001384.1 QNVO02001385.1 QNVO02001386.1 QNVO02001387.1 QNVO02001388.1 QNVO02001389.1 QNVO02001390.1 QNVO02001391.1 QNVO02001392.1 QNVO02001393.1 QNVO02001394.1 QNVO02001395.1 QNVO02001396.1 QNVO02001397.1 QNVO02001398.1 QNVO02001399.1 QNVO02001400.1 QNVO02001401.1 QNVO02001402.1 QNVO02001403.1 QNVO02001404.1 QNVO02001405.1 QNVO02001406.1 QNVO02001407.1 QNVO02001408.1 QNVO02001409.1 QNVO02001410.1 QNVO02001411.1 QNVO02001412.1 QNVO02001413.1 QNVO02001414.1 QNVO02001415.1 QNVO02001416.1 QNVO02001417.1 QNVO02001418.1 QNVO02001419.1 QNVO02001420.1 QNVO02001421.1 QNVO02001422.1 QNVO02001423.1 QNVO02001424.1 QNVO02001425.1 QNVO02001426.1 QNVO02001427.1 QNVO02001428.1 QNVO02001429.1 QNVO02001430.1 QNVO02001431.1 QNVO02001432.1 QNVO02001433.1 QNVO02001434.1 QNVO02001435.1 QNVO02001436.1 QNVO02001437.1 QNVO02001438.1 QNVO02001439.1 QNVO02001440.1 QNVO02001441.1 QNVO02001442.1 QNVO02001443.1 QNVO02001444.1 QNVO02001445.1 QNVO02001446.1 QNVO02001447.1 QNVO02001448.1 QNVO02001449.1 QNVO02001450.1 QNVO02001451.1 QNVO02001452.1 QNVO02001453.1 QNVO02001454.1 QNVO02001455.1 QNVO02001456.1 QNVO02001457.1 QNVO02001458.1 QNVO02001459.1 QNVO02001460.1 QNVO02001461.1 QNVO02001462.1 QNVO02001463.1 QNVO02001464.1 QNVO02001465.1 QNVO02001466.1 QNVO02001467.1 QNVO02001468.1 QNVO02001469.1 QNVO02001470.1 QNVO02001471.1 QNVO02001472.1 QNVO02001473.1 QNVO02001474.1 QNVO02001475.1 QNVO02001476.1 QNVO02001477.1 QNVO02001478.1 QNVO02001479.1 QNVO02001480.1 QNVO02001481.1 QNVO02001482.1 QNVO02001483.1 QNVO02001484.1 QNVO02001485.1 QNVO02001486.1 QNVO02001487.1 QNVO02001488.1 QNVO02001489.1 QNVO02001490.1 QNVO02001491.1 QNVO02001492.1 QNVO02001493.1 QNVO02001494.1 QNVO02001495.1 QNVO02001496.1 QNVO02001497.1 QNVO02001498.1 QNVO02001499.1 QNVO02001500.1 QNVO02001501.1 QNVO02001502.1 QNVO02001503.1 QNVO02001504.1 QNVO02001505.1 QNVO02001506.1 QNVO02001507.1 QNVO02001508.1 QNVO02001509.1 QNVO02001510.1 QNVO02001511.1 QNVO02001512.1 QNVO02001513.1 QNVO02001514.1 QNVO02001515.1 QNVO02001516.1 QNVO02001517.1 QNVO02001518.1 QNVO02001519.1 QNVO02001520.1 QNVO02001521.1 QNVO02001522.1 QNVO02001523.1 QNVO02001524.1 QNVO02001525.1 QNVO02001526.1 QNVO02001527.1 QNVO02001528.1 QNVO02001529.1 QNVO02001530.1 QNVO02001531.1 QNVO02001532.1 QNVO02001533.1 QNVO02001534.1 QNVO02001535.1 QNVO02001536.1 QNVO02001537.1 QNVO02001538.1 QNVO02001539.1 QNVO02001540.1 QNVO02001541.1 QNVO02001542.1 QNVO02001543.1 QNVO02001544.1 QNVO02001545.1 QNVO02001546.1 QNVO02001547.1 QNVO02001548.1 QNVO02001549.1 QNVO02001550.1 QNVO02001551.1 QNVO02001552.1 QNVO02001553.1 QNVO02001554.1 QNVO02001555.1 QNVO02001556.1 QNVO02001557.1 QNVO02001558.1 QNVO02001559.1 QNVO02001560.1 QNVO02001561.1 QNVO02001562.1 QNVO02001563.1 QNVO02001564.1 QNVO02001565.1 QNVO02001566.1 QNVO02001567.1 QNVO02001568.1 QNVO02001569.1 QNVO02001570.1 QNVO02001571.1 QNVO02001572.1 QNVO02001573.1 QNVO02001574.1 QNVO02001575.1 QNVO02001576.1 QNVO02001577.1 QNVO02001578.1 QNVO02001579.1 QNVO02001580.1 QNVO02001581.1 QNVO02001582.1 QNVO02001583.1 QNVO02001584.1 QNVO02001585.1 QNVO02001586.1 QNVO02001587.1 QNVO02001588.1 QNVO02001589.1 QNVO02001590.1 QNVO02001591.1 QNVO02001592.1 QNVO02001593.1 QNVO02001594.1 QNVO02001595.1 QNVO02001596.1 QNVO02001597.1 QNVO02001598.1 QNVO02001599.1 QNVO02001600.1 QNVO02001601.1 QNVO02001602.1 QNVO02001603.1 QNVO02001604.1 QNVO02001605.1 QNVO02001606.1 QNVO02001607.1 QNVO02001608.1 QNVO02001609.1 QNVO02001610.1 QNVO02001611.1 QNVO02001612.1 QNVO02001613.1 QNVO02001614.1 QNVO02001615.1 QNVO02001616.1 QNVO02001617.1 QNVO02001618.1 QNVO02001619.1 QNVO02001620.1 QNVO02001621.1 QNVO02001622.1 QNVO02001623.1 QNVO02001624.1 QNVO02001625.1 QNVO02001626.1 QNVO02001627.1 QNVO02001628.1 QNVO02001629.1 QNVO02001630.1 QNVO02001631.1 QNVO02001632.1 QNVO02001633.1 QNVO02001634.1 QNVO02001635.1 QNVO02001636.1 QNVO02001637.1 QNVO02001638.1 QNVO02001639.1 QNVO02001640.1 QNVO02001641.1 QNVO02001642.1 QNVO02001643.1 QNVO02001644.1 QNVO02001645.1 QNVO02001646.1 QNVO02001647.1 QNVO02001648.1 QNVO02001649.1 QNVO02001650.1 QNVO02001651.1 QNVO02001652.1 QNVO02001653.1 QNVO02001654.1 QNVO02001655.1 QNVO02001656.1 QNVO02001657.1 QNVO02001658.1 QNVO02001659.1 QNVO02001660.1 QNVO02001661.1 QNVO02001662.1 QNVO02001663.1 QNVO02001664.1 QNVO02001665.1 QNVO02001666.1 QNVO02001667.1 QNVO02001668.1 QNVO02001669.1 QNVO02001670.1 QNVO02001671.1 QNVO02001672.1 QNVO02001673.1 QNVO02001674.1 QNVO02001675.1 QNVO02001676.1 QNVO02001677.1 QNVO02001678.1 QNVO02001679.1 QNVO02001680.1 QNVO02001681.1 QNVO02001682.1 QNVO02001683.1 QNVO02001684.1 QNVO02001685.1 QNVO02001686.1 QNVO02001687.1 QNVO02001688.1 QNVO02001689.1 QNVO02001690.1 QNVO02001691.1 QNVO02001692.1 QNVO02001693.1 QNVO02001694.1 QNVO02001695.1 QNVO02001696.1 QNVO02001697.1 QNVO02001698.1 QNVO02001699.1 QNVO02001700.1 QNVO02001701.1 QNVO02001702.1 QNVO02001703.1 QNVO02001704.1 QNVO02001705.1 QNVO02001706.1 QNVO02001707.1 QNVO02001708.1 QNVO02001709.1 QNVO02001710.1 QNVO02001711.1 QNVO02001712.1 QNVO02001713.1 QNVO02001714.1 QNVO02001715.1 QNVO02001716.1 QNVO02001717.1 QNVO02001718.1 QNVO02001719.1 QNVO02001720.1 QNVO02001721.1 QNVO02001722.1 QNVO02001723.1 QNVO02001724.1 QNVO02001725.1 QNVO02001726.1 QNVO02001727.1 QNVO02001728.1 QNVO02001729.1 QNVO02001730.1 QNVO02001731.1 QNVO02001732.1 QNVO02001733.1 QNVO02001734.1 QNVO02001735.1 QNVO02001736.1 QNVO02001741.1 QNVO02001742.1 QNVO02001743.1 QNVO02001744.1 QNVO02001745.1 QNVO02001746.1 QNVO02001747.1 QNVO02001748.1 QNVO02001749.1 QNVO02001750.1 QNVO02001751.1 QNVO02001752.1 QNVO02001753.1 QNVO02001754.1 QNVO02001755.1 QNVO02001756.1 QNVO02001757.1 QNVO02001758.1 QNVO02001759.1 QNVO02001760.1 QNVO02001761.1 QNVO02001762.1 QNVO02001763.1 QNVO02001764.1 QNVO02001765.1 QNVO02001766.1 QNVO02001767.1 QNVO02001768.1 QNVO02001769.1 QNVO02001770.1 QNVO02001771.1 QNVO02001772.1 QNVO02001773.1 QNVO02001774.1 QNVO02001775.1 QNVO02001776.1 QNVO02001777.1 QNVO02001778.1 QNVO02001779.1 QNVO02001780.1 QNVO02001781.1 QNVO02001782.1 QNVO02001783.1 QNVO02001784.1 QNVO02001785.1 QNVO02001786.1 QNVO02001787.1 QNVO02001788.1 QNVO02001789.1 QNVO02001790.1 QNVO02001791.1 QNVO02001792.1 QNVO02001793.1 QNVO02001794.1 QNVO02001795.1 QNVO02001796.1 QNVO02001797.1 QNVO02001798.1 QNVO02001799.1 QNVO02001800.1 QNVO02001801.1 QNVO02001802.1 QNVO02001803.1 QNVO02001804.1 QNVO02001805.1 QNVO02001806.1 QNVO02001807.1 QNVO02001808.1 QNVO02001809.1 QNVO02001810.1 QNVO02001811.1 QNVO02001812.1 QNVO02001813.1 QNVO02001814.1 QNVO02001815.1 QNVO02001816.1 QNVO02001817.1 QNVO02001818.1 QNVO02001819.1 QNVO02001820.1 QNVO02001821.1 QNVO02001822.1 QNVO02001823.1 QNVO02001824.1 QNVO02001825.1 QNVO02001826.1 QNVO02001827.1 QNVO02001828.1 QNVO02001829.1 QNVO02001830.1 QNVO02001831.1 QNVO02001832.1 QNVO02001833.1 QNVO02001834.1 QNVO02001835.1 QNVO02001836.1 QNVO02001837.1 QNVO02001838.1 QNVO02001839.1 QNVO02001840.1 QNVO02001841.1 QNVO02001842.1 QNVO02001843.1 QNVO02001844.1 QNVO02001845.1 QNVO02001846.1 QNVO02001847.1 QNVO02001848.1 QNVO02001849.1 QNVO02001850.1 QNVO02001851.1 QNVO02001852.1 QNVO02001853.1 QNVO02001854.1 QNVO02001855.1 QNVO02001856.1 QNVO02001857.1 QNVO02001858.1 QNVO02001859.1 QNVO02001860.1 QNVO02001861.1 QNVO02001862.1 QNVO02001863.1 QNVO02001864.1 QNVO02001865.1 QNVO02001866.1 QNVO02001867.1 QNVO02001868.1 QNVO02001869.1 QNVO02001870.1 QNVO02001871.1 QNVO02001872.1 QNVO02001873.1 QNVO02001874.1 QNVO02001875.1 QNVO02001876.1 QNVO02001877.1 QNVO02001878.1 QNVO02001879.1 QNVO02001880.1 QNVO02001881.1 QNVO02001882.1 QNVO02001883.1 QNVO02001884.1 QNVO02001885.1 QNVO02001886.1 QNVO02001887.1 QNVO02001888.1 QNVO02001889.1 QNVO02001890.1 QNVO02001891.1 QNVO02001892.1 QNVO02001893.1 QNVO02001894.1 QNVO02001895.1 QNVO02001896.1 QNVO02001897.1 QNVO02001898.1 QNVO02001899.1 QNVO02001900.1 QNVO02001901.1 QNVO02001902.1 QNVO02001903.1 QNVO02001904.1 QNVO02001905.1 QNVO02001906.1 QNVO02001907.1 QNVO02001908.1 QNVO02001909.1 QNVO02001910.1 QNVO02001911.1 QNVO02001912.1 QNVO02001913.1 QNVO02001914.1 QNVO02001915.1 QNVO02001916.1 QNVO02001917.1 QNVO02001918.1 QNVO02001919.1 QNVO02001920.1 QNVO02001921.1 QNVO02001922.1 QNVO02001923.1 QNVO02001924.1 QNVO02001925.1 QNVO02001926.1 QNVO02001927.1 QNVO02001928.1 QNVO02001929.1 QNVO02001930.1 QNVO02001931.1 QNVO02001932.1 QNVO02001933.1 QNVO02001934.1 QNVO02001935.1 QNVO02001936.1 QNVO02001937.1 QNVO02001938.1 QNVO02001939.1 QNVO02001940.1 QNVO02001941.1 QNVO02001942.1 QNVO02001943.1 QNVO02001944.1 QNVO02001945.1 QNVO02001946.1 QNVO02001947.1 QNVO02001948.1 QNVO02001949.1 QNVO02001950.1 QNVO02001951.1 QNVO02001952.1 QNVO02001953.1 QNVO02001954.1 QNVO02001955.1 QNVO02001956.1 QNVO02001957.1 QNVO02001958.1 QNVO02001959.1 QNVO02001960.1 QNVO02001961.1 QNVO02001962.1 QNVO02001963.1 QNVO02001964.1 QNVO02001965.1 QNVO02001966.1 QNVO02001967.1 QNVO02001968.1 QNVO02001969.1 QNVO02001970.1 QNVO02001971.1 QNVO02001972.1 QNVO02001973.1 QNVO02001974.1 QNVO02001975.1 QNVO02001976.1 QNVO02001977.1 QNVO02001978.1 QNVO02001979.1 QNVO02001980.1 QNVO02001981.1 QNVO02001982.1 QNVO02001983.1 QNVO02001984.1 QNVO02001985.1 QNVO02001986.1 QNVO02001987.1 QNVO02001988.1 QNVO02001989.1 QNVO02001990.1 QNVO02001991.1 QNVO02001992.1 QNVO02001993.1 QNVO02001997.1 QNVO02001998.1 QNVO02001999.1 QNVO02002000.1 QNVO02002001.1 QNVO02002002.1 QNVO02002003.1 QNVO02002004.1 QNVO02002005.1 QNVO02002006.1 QNVO02002007.1 QNVO02002008.1 QNVO02002009.1 QNVO02002010.1 QNVO02002011.1 QNVO02002012.1 QNVO02002013.1 QNVO02002014.1 QNVO02002015.1 QNVO02002016.1 QNVO02002017.1 QNVO02002018.1 QNVO02002019.1 QNVO02002020.1 QNVO02002021.1 QNVO02002022.1 QNVO02002023.1 QNVO02002024.1 QNVO02002025.1 QNVO02002026.1 QNVO02002027.1 QNVO02002028.1 QNVO02002029.1 QNVO02002030.1 QNVO02002031.1 QNVO02002032.1 QNVO02002033.1 QNVO02002034.1 QNVO02002035.1 QNVO02002036.1 QNVO02002037.1 QNVO02002038.1 QNVO02002039.1 QNVO02002040.1 QNVO02002041.1 QNVO02002042.1 QNVO02002043.1 QNVO02002044.1 QNVO02002045.1 QNVO02002046.1 QNVO02002047.1 QNVO02002048.1 QNVO02002049.1 QNVO02002050.1 QNVO02002051.1 QNVO02002052.1 QNVO02002053.1 QNVO02002054.1 QNVO02002055.1 QNVO02002056.1 QNVO02002057.1 QNVO02002058.1 QNVO02002059.1 QNVO02002060.1 QNVO02002061.1 QNVO02002062.1 QNVO02002063.1 QNVO02002064.1 QNVO02002065.1 QNVO02002066.1 QNVO02002067.1 QNVO02002068.1 QNVO02002069.1 QNVO02002070.1 QNVO02002071.1 QNVO02002072.1 QNVO02002073.1 QNVO02002074.1 QNVO02002075.1 QNVO02002076.1 QNVO02002077.1 QNVO02002078.1 QNVO02002079.1 QNVO02002080.1 QNVO02002081.1 QNVO02002082.1 QNVO02002083.1 QNVO02002084.1 QNVO02002085.1 QNVO02002086.1 QNVO02002087.1 QNVO02002088.1 QNVO02002089.1 QNVO02002090.1 QNVO02002091.1 QNVO02002092.1 QNVO02002093.1 QNVO02002094.1 QNVO02002095.1 QNVO02002096.1 QNVO02002097.1 QNVO02002098.1 QNVO02002099.1 QNVO02002100.1 QNVO02002101.1 QNVO02002102.1 QNVO02002103.1 QNVO02002104.1 QNVO02002105.1 QNVO02002106.1 QNVO02002107.1 QNVO02002108.1 QNVO02002109.1 QNVO02002110.1 QNVO02002111.1 QNVO02002112.1 QNVO02002113.1 QNVO02002114.1 QNVO02002115.1 QNVO02002116.1 QNVO02002117.1 QNVO02002118.1 QNVO02002119.1 QNVO02002120.1 QNVO02002121.1 QNVO02002122.1 QNVO02002123.1 QNVO02002124.1 QNVO02002125.1 QNVO02002126.1 QNVO02002127.1 QNVO02002128.1 QNVO02002129.1 QNVO02002130.1 QNVO02002131.1 QNVO02002132.1 QNVO02002133.1 QNVO02002134.1 QNVO02002135.1 QNVO02002136.1 QNVO02002137.1 QNVO02002138.1 QNVO02002139.1 QNVO02002140.1 QNVO02002141.1 QNVO02002142.1 QNVO02002143.1 QNVO02002144.1 QNVO02002145.1 QNVO02002146.1 QNVO02002147.1 QNVO02002148.1 QNVO02002149.1 QNVO02002150.1 QNVO02002151.1 QNVO02002152.1 QNVO02002153.1 QNVO02002154.1 QNVO02002155.1 QNVO02002156.1 QNVO02002157.1 QNVO02002158.1 QNVO02002159.1 QNVO02002160.1 QNVO02002161.1 QNVO02002162.1 QNVO02002163.1 QNVO02002164.1 QNVO02002165.1 QNVO02002166.1 QNVO02002167.1 QNVO02002168.1 QNVO02002169.1 QNVO02002170.1 QNVO02002171.1 QNVO02002172.1 QNVO02002173.1 QNVO02002174.1 QNVO02002175.1 QNVO02002176.1 QNVO02002177.1 QNVO02002178.1 QNVO02002179.1 QNVO02002180.1 QNVO02002181.1 QNVO02002182.1 QNVO02002183.1 QNVO02002184.1 QNVO02002185.1 QNVO02002186.1 QNVO02002187.1 QNVO02002188.1 QNVO02002189.1 QNVO02002190.1 QNVO02002191.1 QNVO02002192.1 QNVO02002193.1 QNVO02002194.1 QNVO02002195.1 QNVO02002196.1 QNVO02002197.1 QNVO02002198.1 QNVO02002199.1 QNVO02002200.1 QNVO02002201.1 QNVO02002202.1 QNVO02002203.1 QNVO02002204.1 QNVO02002205.1 QNVO02002206.1 QNVO02002207.1 QNVO02002208.1 QNVO02002209.1 QNVO02002210.1 QNVO02002211.1 QNVO02002212.1 QNVO02002213.1 QNVO02002214.1 QNVO02002215.1 QNVO02002216.1 QNVO02002217.1 QNVO02002218.1 QNVO02002219.1 QNVO02002220.1 QNVO02002221.1 QNVO02002222.1 QNVO02002223.1 QNVO02002224.1 QNVO02002225.1 QNVO02002226.1 QNVO02002227.1 QNVO02002228.1 QNVO02002229.1 QNVO02002230.1 QNVO02002231.1 QNVO02002232.1 QNVO02002233.1 QNVO02002234.1 QNVO02002235.1 QNVO02002236.1 QNVO02002237.1 QNVO02002238.1 QNVO02002239.1 QNVO02002240.1 QNVO02002241.1 QNVO02002242.1 QNVO02002243.1 QNVO02002244.1 QNVO02002245.1 QNVO02002246.1 QNVO02002247.1 QNVO02002248.1 QNVO02002249.1 QNVO02002250.1 QNVO02002251.1 QNVO02002252.1 QNVO02002253.1 QNVO02002254.1 QNVO02002255.1 QNVO02002256.1 QNVO02002257.1 QNVO02002258.1 QNVO02002259.1 QNVO02002260.1 QNVO02002261.1 QNVO02002262.1 QNVO02002263.1 QNVO02002264.1 QNVO02002265.1 QNVO02002266.1 QNVO02002267.1 QNVO02002268.1 QNVO02002269.1 QNVO02002270.1 QNVO02002271.1 QNVO02002272.1 QNVO02002273.1 QNVO02002274.1 QNVO02002275.1 QNVO02002276.1 QNVO02002277.1 QNVO02002278.1 QNVO02002279.1 QNVO02002280.1 QNVO02002281.1 QNVO02002282.1 QNVO02002283.1 QNVO02002284.1 QNVO02002285.1 QNVO02002286.1 QNVO02002287.1 QNVO02002288.1 QNVO02002289.1 QNVO02002290.1 QNVO02002291.1 QNVO02002292.1 QNVO02002293.1 QNVO02002294.1 QNVO02002295.1 QNVO02002296.1 QNVO02002297.1 QNVO02002298.1 QNVO02002299.1 QNVO02002300.1 QNVO02002301.1 QNVO02002302.1 QNVO02002303.1 QNVO02002304.1 QNVO02002305.1 QNVO02002306.1 QNVO02002307.1 QNVO02002308.1 QNVO02002309.1 QNVO02002310.1 QNVO02002311.1 QNVO02002312.1 QNVO02002313.1 QNVO02002314.1 QNVO02002315.1 QNVO02002316.1 QNVO02002317.1 QNVO02002318.1 QNVO02002319.1 QNVO02002320.1 QNVO02002321.1 QNVO02002322.1 QNVO02002323.1 QNVO02002324.1 QNVO02002325.1 QNVO02002326.1 QNVO02002327.1 QNVO02002328.1 QNVO02002329.1 QNVO02002330.1 QNVO02002331.1 QNVO02002332.1 QNVO02002333.1 QNVO02002334.1 QNVO02002335.1 QNVO02002336.1 QNVO02002337.1 QNVO02002338.1 QNVO02002339.1 QNVO02002340.1 QNVO02002341.1 QNVO02002342.1 QNVO02002343.1 QNVO02002344.1 QNVO02002345.1 QNVO02002346.1 QNVO02002347.1 QNVO02002348.1 QNVO02002349.1 QNVO02002350.1 QNVO02002351.1 QNVO02002352.1 QNVO02002353.1 QNVO02002354.1 QNVO02002355.1 QNVO02002356.1 QNVO02002357.1 QNVO02002358.1 QNVO02002359.1 QNVO02002360.1 QNVO02002361.1 QNVO02002362.1 QNVO02002363.1 QNVO02002364.1 QNVO02002365.1 QNVO02002366.1 QNVO02002367.1 QNVO02002368.1 QNVO02002369.1 QNVO02002370.1 QNVO02002371.1 QNVO02002372.1 QNVO02002373.1 QNVO02002374.1 QNVO02002375.1 QNVO02002376.1 QNVO02002377.1 QNVO02002378.1 QNVO02002379.1 QNVO02002380.1 QNVO02002381.1 QNVO02002382.1 QNVO02002383.1 QNVO02002384.1 QNVO02002385.1 QNVO02002386.1 QNVO02002387.1 QNVO02002388.1 QNVO02002389.1 QNVO02002390.1 QNVO02002391.1 QNVO02002392.1 QNVO02002393.1 QNVO02002394.1 QNVO02002395.1 QNVO02002396.1 QNVO02002397.1 QNVO02002398.1 QNVO02002399.1 QNVO02002400.1 QNVO02002401.1 QNVO02002402.1 QNVO02002403.1 QNVO02002404.1 QNVO02002405.1 QNVO02002406.1 QNVO02002407.1 QNVO02002408.1 QNVO02002409.1 QNVO02002410.1 QNVO02002411.1 QNVO02002412.1 QNVO02002413.1 QNVO02002414.1 QNVO02002415.1 QNVO02002416.1 QNVO02002417.1 QNVO02002418.1 QNVO02002419.1 QNVO02002420.1 QNVO02002421.1 QNVO02002422.1 QNVO02002423.1 QNVO02002424.1 QNVO02002425.1 QNVO02002426.1 QNVO02002427.1 QNVO02002428.1 QNVO02002429.1 QNVO02002430.1 QNVO02002431.1 QNVO02002432.1 QNVO02002433.1 QNVO02002434.1 QNVO02002435.1 QNVO02002436.1 QNVO02002437.1 QNVO02002438.1 QNVO02002439.1 QNVO02002440.1 QNVO02002441.1 QNVO02002442.1 QNVO02002443.1 QNVO02002444.1 QNVO02002445.1 QNVO02002446.1 QNVO02002447.1 QNVO02002448.1 QNVO02002449.1 QNVO02002450.1 QNVO02002451.1 QNVO02002452.1 QNVO02002453.1 QNVO02002454.1 QNVO02002455.1 QNVO02002456.1 QNVO02002457.1 QNVO02002458.1 QNVO02002459.1 QNVO02002460.1 QNVO02002461.1 QNVO02002462.1 QNVO02002463.1 QNVO02002464.1 QNVO02002465.1 QNVO02002466.1 QNVO02002467.1 QNVO02002468.1 QNVO02002469.1 QNVO02002470.1 QNVO02002471.1 QNVO02002472.1 QNVO02002473.1 QNVO02002474.1 QNVO02002475.1 QNVO02002476.1 QNVO02002477.1 QNVO02002478.1 QNVO02002479.1 QNVO02002480.1 QNVO02002481.1 QNVO02002482.1 QNVO02002483.1 QNVO02002484.1 QNVO02002485.1 QNVO02002486.1 QNVO02002487.1 QNVO02002488.1 QNVO02002489.1 QNVO02002490.1 QNVO02002491.1 QNVO02002492.1 QNVO02002493.1 QNVO02002494.1 QNVO02002495.1 QNVO02002496.1 QNVO02002497.1 QNVO02002498.1 QNVO02002499.1 QNVO02002500.1 QNVO02002501.1 QNVO02002502.1 QNVO02002503.1 QNVO02002504.1 QNVO02002505.1 QNVO02002506.1 QNVO02002507.1 QNVO02002508.1 QNVO02002509.1 QNVO02002510.1 QNVO02002511.1 QNVO02002512.1 QNVO02002513.1 QNVO02002514.1 QNVO02002515.1 QNVO02002516.1 QNVO02002517.1 QNVO02002518.1 QNVO02002519.1 QNVO02002520.1 QNVO02002521.1 QNVO02002522.1 QNVO02002523.1 QNVO02002524.1 QNVO02002525.1 QNVO02002526.1 QNVO02002527.1 QNVO02002528.1 QNVO02002529.1 QNVO02002530.1 QNVO02002531.1 QNVO02002532.1 QNVO02002533.1 QNVO02002534.1 QNVO02002535.1 QNVO02002536.1 QNVO02002537.1 QNVO02002538.1 QNVO02002539.1 QNVO02002540.1 QNVO02002541.1 QNVO02002542.1 QNVO02002543.1 QNVO02002544.1 QNVO02002545.1 QNVO02002546.1 QNVO02002547.1 QNVO02002548.1 QNVO02002549.1 QNVO02002550.1 QNVO02002551.1 QNVO02002552.1 QNVO02002553.1 QNVO02002554.1 QNVO02002555.1 QNVO02002556.1 QNVO02002557.1 QNVO02002558.1 QNVO02002559.1 QNVO02002560.1 QNVO02002561.1 QNVO02002562.1 QNVO02002563.1 QNVO02002564.1 QNVO02002565.1 QNVO02002566.1 QNVO02002567.1 QNVO02002568.1 QNVO02002569.1 QNVO02002570.1 QNVO02002571.1 QNVO02002572.1 QNVO02002573.1 QNVO02002574.1 QNVO02002575.1 QNVO02002576.1 QNVO02002577.1 QNVO02002578.1 QNVO02002579.1 QNVO02002580.1 QNVO02002581.1 QNVO02002582.1 QNVO02002583.1 QNVO02002584.1 QNVO02002585.1 QNVO02002586.1 QNVO02002587.1 QNVO02002588.1 QNVO02002589.1 QNVO02002590.1 QNVO02002591.1 QNVO02002592.1 QNVO02002593.1 QNVO02002594.1 QNVO02002595.1 QNVO02002596.1 QNVO02002597.1 QNVO02002598.1 QNVO02002599.1 QNVO02002600.1 QNVO02002601.1 QNVO02002602.1 QNVO02002603.1 QNVO02002604.1 QNVO02002605.1 QNVO02002606.1 QNVO02002607.1 QNVO02002608.1 QNVO02002609.1 QNVO02002610.1 QNVO02002611.1 QNVO02002612.1 QNVO02002613.1 QNVO02002614.1 QNVO02002615.1 QNVO02002616.1 QNVO02002617.1 QNVO02002618.1 QNVO02002619.1 QNVO02002620.1 QNVO02002621.1 QNVO02002622.1 QNVO02002623.1 QNVO02002624.1 QNVO02002625.1 QNVO02002626.1 QNVO02002627.1 QNVO02002628.1 QNVO02002629.1 QNVO02002630.1 QNVO02002631.1 QNVO02002632.1 QNVO02002633.1 QNVO02002634.1 QNVO02002635.1 QNVO02002636.1 QNVO02002637.1 QNVO02002638.1 QNVO02002639.1 QNVO02002640.1 QNVO02002641.1 QNVO02002642.1 QNVO02002643.1 QNVO02002644.1 QNVO02002645.1 QNVO02002646.1 QNVO02002647.1 QNVO02002648.1 QNVO02002649.1 QNVO02002650.1 QNVO02002651.1 QNVO02002652.1 QNVO02002653.1 QNVO02002654.1 QNVO02002655.1 QNVO02002656.1 QNVO02002657.1 QNVO02002658.1 QNVO02002659.1 QNVO02002660.1 QNVO02002661.1 QNVO02002662.1 QNVO02002663.1 QNVO02002664.1 QNVO02002665.1 QNVO02002666.1 QNVO02002667.1 QNVO02002668.1 QNVO02002669.1 QNVO02002670.1 QNVO02002671.1 QNVO02002672.1 QNVO02002673.1 QNVO02002674.1 QNVO02002675.1 QNVO02002676.1 QNVO02002677.1 QNVO02002678.1 QNVO02002679.1 QNVO02002680.1 QNVO02002681.1 QNVO02002682.1 QNVO02002683.1 QNVO02002684.1 QNVO02002685.1 QNVO02002686.1 QNVO02002687.1 QNVO02002688.1 QNVO02002689.1 QNVO02002690.1 QNVO02002691.1 QNVO02002692.1 QNVO02002693.1 QNVO02002694.1 QNVO02002695.1 QNVO02002696.1 QNVO02002697.1 QNVO02002698.1 QNVO02002699.1 QNVO02002700.1 QNVO02002701.1 QNVO02002702.1 QNVO02002703.1 QNVO02002704.1 QNVO02002705.1 QNVO02002706.1 QNVO02002707.1 QNVO02002708.1 QNVO02002709.1 QNVO02002710.1 QNVO02002711.1 QNVO02002712.1 QNVO02002713.1 QNVO02002714.1 QNVO02002715.1 QNVO02002716.1 QNVO02002717.1 QNVO02002718.1 QNVO02002719.1 QNVO02002720.1 QNVO02002721.1 QNVO02002722.1 QNVO02002723.1 QNVO02002724.1 QNVO02002725.1 QNVO02002726.1 QNVO02002727.1 QNVO02002728.1 QNVO02002729.1 QNVO02002730.1 QNVO02002731.1 QNVO02002732.1 QNVO02002733.1 QNVO02002734.1 QNVO02002735.1 QNVO02002736.1 QNVO02002737.1 QNVO02002738.1 QNVO02002739.1 QNVO02002740.1 QNVO02002741.1 QNVO02002742.1 QNVO02002743.1 QNVO02002744.1 QNVO02002745.1 QNVO02002746.1 QNVO02002747.1 QNVO02002748.1 QNVO02002749.1 QNVO02002750.1 QNVO02002751.1 QNVO02002752.1 QNVO02002753.1 QNVO02002754.1 QNVO02002755.1 QNVO02002756.1 QNVO02002757.1 QNVO02002758.1 QNVO02002759.1 QNVO02002760.1 QNVO02002761.1 QNVO02002762.1 QNVO02002763.1 QNVO02002764.1 QNVO02002765.1 QNVO02002766.1 QNVO02002767.1 QNVO02002768.1 QNVO02002769.1 QNVO02002770.1 QNVO02002771.1 QNVO02002772.1 QNVO02002773.1 QNVO02002774.1 QNVO02002775.1 QNVO02002776.1 QNVO02002777.1 QNVO02002778.1 QNVO02002779.1 QNVO02002780.1 QNVO02002781.1 QNVO02002782.1 QNVO02002783.1 QNVO02002784.1 QNVO02002785.1 QNVO02002786.1 QNVO02002787.1 QNVO02002788.1 QNVO02002789.1 QNVO02002790.1 QNVO02002791.1 QNVO02002792.1 QNVO02002793.1 QNVO02002794.1 QNVO02002795.1 QNVO02002796.1 QNVO02002797.1 QNVO02002798.1 QNVO02002799.1 QNVO02002800.1 QNVO02002801.1 QNVO02002802.1 QNVO02002803.1 QNVO02002804.1 QNVO02002805.1 QNVO02002806.1 QNVO02002807.1 QNVO02002808.1 QNVO02002809.1 QNVO02002810.1 QNVO02002811.1 QNVO02002812.1 QNVO02002813.1 QNVO02002814.1 QNVO02002815.1 QNVO02002816.1 QNVO02002817.1 QNVO02002818.1 QNVO02002819.1 QNVO02002820.1 QNVO02002821.1 QNVO02002822.1 QNVO02002823.1 QNVO02002824.1 QNVO02002825.1 QNVO02002826.1 QNVO02002827.1 QNVO02002828.1 QNVO02002829.1 QNVO02002830.1 QNVO02002831.1 QNVO02002832.1 QNVO02002833.1 QNVO02002834.1 QNVO02002835.1 QNVO02002836.1 QNVO02002837.1 QNVO02002838.1 QNVO02002839.1 QNVO02002840.1 QNVO02002841.1 QNVO02002842.1 QNVO02002843.1 QNVO02002844.1 QNVO02002845.1 QNVO02002846.1 QNVO02002847.1 QNVO02002848.1 QNVO02002849.1 QNVO02002850.1 QNVO02002851.1 QNVO02002852.1 QNVO02002853.1 QNVO02002854.1 QNVO02002855.1 QNVO02002856.1 QNVO02002857.1 QNVO02002858.1 QNVO02002859.1 QNVO02002860.1 QNVO02002861.1 QNVO02002862.1 QNVO02002863.1 QNVO02002864.1 QNVO02002865.1 QNVO02002866.1 QNVO02002867.1 QNVO02002868.1 QNVO02002869.1 QNVO02002870.1 QNVO02002871.1 QNVO02002872.1 QNVO02002873.1 QNVO02002874.1 QNVO02002875.1 QNVO02002876.1 QNVO02002877.1 QNVO02002878.1 QNVO02002879.1 QNVO02002880.1 QNVO02002881.1 QNVO02002882.1 QNVO02002883.1 QNVO02002884.1 QNVO02002885.1 QNVO02002886.1 QNVO02002887.1 QNVO02002888.1 QNVO02002889.1 QNVO02002890.1 QNVO02002891.1 QNVO02002892.1 QNVO02002893.1 QNVO02002894.1 QNVO02002895.1 QNVO02002896.1 QNVO02002897.1 QNVO02002898.1 QNVO02002899.1 QNVO02002900.1 QNVO02002901.1 QNVO02002902.1 QNVO02002903.1 QNVO02002904.1 QNVO02002905.1 QNVO02002906.1 QNVO02002907.1 QNVO02002908.1 QNVO02002909.1 QNVO02002910.1 QNVO02002911.1 QNVO02002912.1 QNVO02002913.1 QNVO02002914.1 QNVO02002915.1 QNVO02002916.1 QNVO02002917.1 QNVO02002918.1 QNVO02002919.1 QNVO02002920.1 QNVO02002921.1 QNVO02002922.1 QNVO02002923.1 QNVO02002924.1 QNVO02002925.1 QNVO02002926.1 QNVO02002927.1 QNVO02002928.1 QNVO02002929.1 QNVO02002930.1 QNVO02002931.1 QNVO02002932.1 QNVO02002933.1 QNVO02002934.1 QNVO02002935.1 QNVO02002936.1 QNVO02002937.1 QNVO02002938.1 QNVO02002939.1 QNVO02002940.1 QNVO02002941.1 QNVO02002942.1 QNVO02002943.1 QNVO02002944.1 QNVO02002945.1 QNVO02002946.1 QNVO02002947.1 QNVO02002948.1 QNVO02002949.1 QNVO02002950.1 QNVO02002951.1 QNVO02002952.1 QNVO02002953.1 QNVO02002954.1 QNVO02002955.1 QNVO02002956.1 QNVO02002957.1 QNVO02002958.1 QNVO02002959.1 QNVO02002960.1 QNVO02002961.1 QNVO02002962.1 QNVO02002963.1 QNVO02002964.1 QNVO02002965.1 QNVO02002966.1 QNVO02002967.1 QNVO02002968.1 QNVO02002969.1 QNVO02002970.1 QNVO02002971.1 QNVO02002972.1 QNVO02002973.1 QNVO02002974.1 QNVO02002975.1 QNVO02002976.1 QNVO02002977.1 QNVO02002978.1 QNVO02002979.1 QNVO02002980.1 QNVO02002981.1 QNVO02002982.1 QNVO02002983.1 QNVO02002984.1 QNVO02002985.1 QNVO02002986.1 QNVO02002987.1 QNVO02002988.1 QNVO02002989.1 QNVO02002990.1 QNVO02002991.1 QNVO02002992.1 QNVO02002993.1 QNVO02002994.1 QNVO02002995.1 QNVO02002996.1 QNVO02002997.1 QNVO02002998.1 QNVO02002999.1 QNVO02003000.1 QNVO02003001.1 QNVO02003002.1 QNVO02003003.1 QNVO02003004.1 QNVO02003005.1 QNVO02003006.1 QNVO02003007.1 QNVO02003008.1 QNVO02003009.1 QNVO02003010.1 QNVO02003011.1 QNVO02003012.1 QNVO02003013.1 QNVO02003014.1 QNVO02003015.1 QNVO02003016.1 QNVO02003017.1 QNVO02003018.1 QNVO02003019.1 QNVO02003020.1 QNVO02003021.1 QNVO02003022.1 QNVO02003023.1 QNVO02003024.1 QNVO02003025.1 QNVO02003026.1 QNVO02003027.1 QNVO02003028.1 QNVO02003029.1 QNVO02003030.1 QNVO02003031.1 QNVO02003032.1 QNVO02003033.1 QNVO02003034.1 QNVO02003035.1 QNVO02003036.1 QNVO02003037.1 QNVO02003038.1 QNVO02003039.1 QNVO02003040.1 QNVO02003041.1 QNVO02003042.1 QNVO02003043.1 QNVO02003044.1 QNVO02003045.1 QNVO02003046.1 QNVO02003047.1 QNVO02003048.1 QNVO02003049.1 QNVO02003050.1 QNVO02003051.1 QNVO02003052.1 QNVO02003053.1 QNVO02003054.1 QNVO02003055.1 QNVO02003056.1 QNVO02003057.1 QNVO02003058.1 QNVO02003059.1 QNVO02003060.1 QNVO02003061.1 QNVO02003062.1 QNVO02003063.1 QNVO02003064.1 QNVO02003065.1 QNVO02003066.1 QNVO02003067.1 QNVO02003068.1 QNVO02003069.1 QNVO02003070.1 QNVO02003071.1 QNVO02003072.1 QNVO02003073.1 QNVO02003074.1 QNVO02003075.1 QNVO02003076.1 QNVO02003077.1 QNVO02003078.1 QNVO02003079.1 QNVO02003080.1 QNVO02003081.1 QNVO02003082.1 QNVO02003083.1 QNVO02003084.1 QNVO02003085.1 QNVO02003086.1 QNVO02003087.1 QNVO02003088.1 QNVO02003089.1 QNVO02003090.1 QNVO02003091.1 QNVO02003092.1 QNVO02003093.1 QNVO02003094.1 QNVO02003095.1 QNVO02003096.1 QNVO02003097.1 QNVO02003098.1 QNVO02003099.1 QNVO02003100.1 QNVO02003101.1 QNVO02003102.1 QNVO02003103.1 QNVO02003104.1 QNVO02003105.1 QNVO02003106.1 QNVO02003107.1 QNVO02003108.1 QNVO02003109.1 QNVO02003110.1 QNVO02003111.1 QNVO02003112.1 QNVO02003113.1 QNVO02003114.1 QNVO02003115.1 QNVO02003116.1 QNVO02003117.1 QNVO02003118.1 QNVO02003119.1 QNVO02003120.1 QNVO02003121.1 QNVO02003122.1 QNVO02003123.1 QNVO02003124.1 QNVO02003125.1 QNVO02003126.1 QNVO02003127.1 QNVO02003128.1 QNVO02003129.1 QNVO02003130.1 QNVO02003131.1 QNVO02003132.1 QNVO02003133.1 QNVO02003134.1 QNVO02003135.1 QNVO02003136.1 QNVO02003137.1 QNVO02003138.1 QNVO02003139.1 QNVO02003140.1 QNVO02003141.1 QNVO02003142.1 QNVO02003143.1 QNVO02003144.1 QNVO02003145.1 QNVO02003146.1 QNVO02003147.1 QNVO02003148.1 QNVO02003149.1 QNVO02003150.1 QNVO02003151.1 QNVO02003152.1 QNVO02003153.1 QNVO02003154.1 QNVO02003155.1 QNVO02003175.1 QNVO02003176.1 QNVO02003177.1 QNVO02003178.1 X Y
07 Mar 2024 13:43:06,643 DEBUG: 	[1] [2024-03-07 21:43:06.643] [GLnexus] [info] db_get_contigs GLnexus.DB
07 Mar 2024 13:43:06,787 DEBUG: 	[1] [2024-03-07 21:43:06.786] [GLnexus] [info] Beginning bulk load with no range filter.
07 Mar 2024 13:52:07,720 DEBUG: 	[1] [2024-03-07 21:52:07.720] [GLnexus] [info] Loaded 16 datasets with 16 samples; 137157658272 bytes in 1295984971 BCF records (1497160 duplicate) in 1587535 buckets. Bucket max 734504 bytes, 6860 records. 2260 BCF records skipped due to caller-specific exceptions
07 Mar 2024 13:52:07,736 DEBUG: 	[1] [2024-03-07 21:52:07.736] [GLnexus] [info] Created sample set *@16
07 Mar 2024 13:52:07,738 DEBUG: 	[1] [2024-03-07 21:52:07.736] [GLnexus] [info] Flushing database...
07 Mar 2024 13:53:12,910 DEBUG: 	[1] [2024-03-07 21:53:12.906] [GLnexus] [info] Bulk load complete!
07 Mar 2024 13:53:13,736 DEBUG: 	[1] [2024-03-07 21:53:13.735] [GLnexus] [info] found sample set *@16
07 Mar 2024 13:53:13,738 DEBUG: 	[1] [2024-03-07 21:53:13.735] [GLnexus] [info] discovering alleles in 1 range(s) on 6 threads
07 Mar 2024 13:53:50,417 DEBUG: 	[1] [2024-03-07 21:53:50.416] [GLnexus] [info] discovered 6125193 alleles
07 Mar 2024 13:54:07,986 DEBUG: 	terminate called after throwing an instance of 'std::bad_alloc'
07 Mar 2024 13:54:07,988 DEBUG: 	  what():  std::bad_alloc

```

When I run this same pattern for any of the other contigs the tool runs fine. Any help would be appreciated.",bbimber,https://github.com/dnanexus-rnd/GLnexus/issues/309
I_kwDOAgB6-M6FV33c,"RNC is "".."" on site with DP=1, but it's ""D."" on site with DP=2",OPEN,2024-04-11T07:35:31Z,2024-04-11T07:35:31Z,,"Hi,

I'm using glnexus to do the joint call on gvcfs generated by GATK, and it is part of a SNP calling pipeline for NGS data with a sequencing depth of ~1×. During reading the pVCFs, I found that the genotype on some variations are successfully called, even if the DP on the site is only one (e.g. red boxes in the image), while genotypes on some other sites with DP=2 are called as half call with the RNC=""D."" (e.g. blue boxes in the image). 

![image](https://github.com/dnanexus-rnd/GLnexus/assets/25820435/db3bd266-c921-49f7-9248-5b90eba2fe8e)

Could you please clarify for me that under what exact condition the glnexus would give a half call with the RNC=""D.""? Thanks!

Sincerely,
Wang",esctrionsit,https://github.com/dnanexus-rnd/GLnexus/issues/311
I_kwDOAgB6-M6IDq3S,Merging vcf files error with glnexus:v1.2.7,OPEN,2024-05-07T08:49:32Z,2024-05-07T08:49:32Z,,"Describe the issue:
Merging vcf files error.
Setup

Operating system: working on cluster
DeepVariant version:latest
Installation method (Docker):
Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.)
Steps to reproduce:

Command:
`udocker run \
-v ""${PWD}/output"":""/output"" \
quay.io/mlin/glnexus:v1.2.7 \
/usr/local/bin/glnexus_cli \
--config DeepVariant_unfiltered \
/output/HG002.g.vcf.gz \
/output/HG003.g.vcf.gz \
/output/HG004.g.vcf.gz \
| udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \
  bcftools view - \
| udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \
  bgzip -c > output/HG002_trio_merged.vcf.gz`
  
Error trace: (if applicable)
Num BCF records read 118736378 query hits 14552613
[E::bgzf_read_block] Invalid BGZF header at offset 265038798
[E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes
[E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes
Error: BCF read err

![Screenshot from 2024-05-06 15-00-29](https://github.com/dnanexus-rnd/GLnexus/assets/45700858/fc61171d-4c32-423e-8fe3-44e5ab329a73)

",poddarharsh15,https://github.com/dnanexus-rnd/GLnexus/issues/312
I_kwDOAgB6-M6OeCCC,Inquiry Regarding IOError Encountered During Multiple Rounds of Merging gVCF Files Using GLnexus,OPEN,2024-07-04T08:12:56Z,2024-07-06T02:08:33Z,,"Hi!

Thank you for providing this tool.

I encountered a minor issue while using GLnexus and would like to seek your guidance.

Initially, I used GLnexus to merge five datasets, each consisting of several hundred gVCFs, and this process was completed without any problems. However, after converting the five merged BCFs back to gVCFs and attempting to merge these five files again using GLnexus, I encountered a failure during the ""discovering alleles"" step.

Here are the details of the error message:

[GLnexus] [info] glnexus_cli release v1.4.1-0-g68e25e5 Aug 13 2021
[GLnexus] [info] detected jemalloc 
[GLnexus] [info] Loading config preset gatk
[GLnexus] [info] config:
...
[GLnexus] [info] config CRC32C = 1926883223
[GLnexus] [info] init database, exemplar_vcf=./all_gvcf/500.gvcf.gz
[GLnexus] [info] Initialized GLnexus database in GLnexus.DB
[GLnexus] [info] bucket size: 30000
[GLnexus] [info] contigs: 
...
[GLnexus] [info] db_get_contigs GLnexus.DB
[GLnexus] [info] Beginning bulk load with no range filter.
[GLnexus] [info] Loaded 5 datasets with 2776 samples; 105459735784 bytes in 8064671 BCF records (173 duplicate) in 6449 buckets. Bucket max 105752856 bytes, 5309 records. 0 BCF records skipped due to caller-specific exceptions
[GLnexus] [info] Created sample set *@5
[GLnexus] [info] Flushing database...
[GLnexus] [info] Bulk load complete!
[GLnexus] [warning] Processing full length of 443 contigs, as no --bed was provided. Providing a BED file with regions of interest, if applicable, can speed this up.
[GLnexus] [info] found sample set *@5
[GLnexus] [info] discovering alleles in 443 range(s) on 28 threads
[GLnexus] [error] Failed to discover alleles: IOError: exception deserializing BCF bucket (capnp/arena.c++:127: failed: Exceeded message traversal limit.  See capnp::ReaderOptions. 
stack: 558149f798d8 558149a1e8f7 558149a2a1e5 558149a2a349 5581499efa38 5581499e7508 55814996d248 2ab467bf6996 5581499e3baa 5581499e3d02 55814997716c 558149fef47e 2ab467beefa2 2ab467d014ce)

Can you help me resolve this issue? Or is it the case that GLnexus cannot merge gVCF files that already contain multiple samples?

Thank you in advance for your help!





",zhanxiangzong,https://github.com/dnanexus-rnd/GLnexus/issues/313
I_kwDOAgB6-M6YBi8s,Allele Specific QC filtering at multi-allelic sites,OPEN,2024-09-26T13:08:32Z,2024-09-26T13:08:32Z,,"What is the best approach for QC of multi-allelic variant  in a GLnexus pVCF?  If there is one high quality alternate allele and a poor quality allele at a multi-allelic site, how are they filtered properly?  In GATK VQSR, there is now a Allele Specific INFO field (AS_FilterStatus) to filter on. Is there something comparable with GLnexus?",jjfarrell,https://github.com/dnanexus-rnd/GLnexus/issues/314
I_kwDOAgB6-M6eIs76,This image on your wiki has a transparent background and is unreadable in dark mode,OPEN,2024-11-12T19:11:37Z,2024-11-12T19:11:37Z,,"https://github.com/dnanexus-rnd/GLnexus/wiki/Reading-GLnexus-pVCFs#glnexus-approach

<img width=""992"" alt=""image"" src=""https://github.com/user-attachments/assets/62a35e33-d882-4915-8edb-bff7b478340a"">
",dvg-p4,https://github.com/dnanexus-rnd/GLnexus/issues/315
I_kwDOAgB6-M6egICi,calling haploid chromosomes,OPEN,2024-11-14T15:38:45Z,2024-11-14T15:40:34Z,,"Hi, 

I have a related issue to #291

My genomes are all males but the merged deepvariant calls for Y are diploid instead of haploid (and I do not know where the PAR region are in rat if present).

I would like to extend the 'DeepVariantWGS' config with a yaml file containing something like

```
# config.yaml
ploidy:
  chrY: 1
  chrX: 1
```

but the command takes only a single -config argument

Is there a way out to my problem or is the damage done in deepvariant prior to running GLnexus for merging?

thanks in advance

deepvariant:1.5.0
GLnexus:1.4.3",splaisan,https://github.com/dnanexus-rnd/GLnexus/issues/316
I_kwDOAgB6-M6iBmbW,Unexpected missing calls after merging overlapping gVCF records,OPEN,2024-12-04T17:02:16Z,2024-12-04T17:02:16Z,,"In evaluating glnexus for merging a single sample, glnexus is missing calls where the gVCF call overlaps another record. The variant calls are correct so is there an option I can add to preserve these calls?
Observed this mostly in INDELs, but there are some SNVs too. Two examples are below with the attached files here - [workspace.tar.gz](https://github.com/user-attachments/files/18011622/workspace.tar.gz)

### INDEL
Expecting a HOM ALT, but no call is emitted from glnexus if the overlapping REF call is present
```
$ grep -A 2 ""#CHROM"" indel*.vcf
indel_call.g.vcf:#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA24385
indel_call.g.vcf-chr1	7655595	.	TAC	T,<*>	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:20:18:3,15,0:0.833333,0:26,21,0,990,990,990
--
indel_merge.g.vcf:#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA24385
indel_merge.g.vcf-chr1	7655595	.	TAC	T,<*>	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:20:18:3,15,0:0.833333,0:26,21,0,990,990,990
indel_merge.g.vcf-chr1	7655597	.	C	T,<*>	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:15:3:1,2,0:0.666667,0:0,14,31,990,990,990
$ glnexus_cli --config DeepVariant_unfiltered indel_merge.g.vcf 2> /dev/null | bcftools view - -H
$ rm -rf GLnexus.DB/
$ glnexus_cli --config DeepVariant_unfiltered indel_call.g.vcf 2> /dev/null | bcftools view - -H
chr1	7655595	chr1_7655595_TAC_T	TAC	T	26	.	AF=1;AQ=26	GT:DP:AD:GQ:PL:RNC	1/1:18:3,15:20:26,21,0:..
```

### SNV
Same issue as before - running glnexus on the g.vcf with the overlapping null/RefCall does not output the expected call
```
$ grep -A 2 ""#CHROM"" snp_*.vcf
snp_call.g.vcf:#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA24385
snp_call.g.vcf-chr3	103921462	.	A	T,<*>	48.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:27:26:0,26,0:1,0:48,26,0,990,990,990
--
snp_merge.g.vcf:#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA24385
snp_merge.g.vcf-chr3	103921461	.	TA	T,<*>	0.3	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:12:28:26,2,0:0.0714286,0:0,11,40,990,990,990
snp_merge.g.vcf-chr3	103921462	.	A	T,<*>	48.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:27:26:0,26,0:1,0:48,26,0,990,990,990
$ glnexus_cli --config DeepVariant_unfiltered snp_call.g.vcf 2> /dev/null | bcftools view - -H
chr3	103921462	chr3_103921462_A_T	A	T	48	.	AF=1;AQ=48	GT:DP:AD:GQ:PL:RNC	1/1:26:0,26:27:48,26,0:..
$ rm -rf GLnexus.DB/
$ glnexus_cli --config DeepVariant_unfiltered snp_merge.g.vcf 2> /dev/null | bcftools view - -H
$
```

I've played around with other configs, but the closest to the desired behavior of outputting the variant is with a modified YAML based on `DeepVariant_unfiltered` with just the additional option `trim_uncalled_alleles: false` (in `custom.yml` in attached). However, the result is still unexpected because the records have a null genotype like below -
```
#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA24385
chr1	7655595	chr1_7655595_TAC_T	TAC	T	26	.	AF=1;AQ=26	GT:DP:AD:GQ:PL:RNC	./.:3:.:.:0,0,0:OO
```

Thank you for the any help and supporting this useful tool!",DavidStreid,https://github.com/dnanexus-rnd/GLnexus/issues/317
I_kwDOAgB6-M6iWEQL,building failed,OPEN,2024-12-06T18:37:41Z,2024-12-07T02:02:47Z,,"I am trying to build the docker container using the instructions in the README and I get:
419.3 [ 58%] Completed 'capnp'
419.4 [ 58%] Built target capnp
419.4 Makefile:140: recipe for target 'all' failed
419.4 make: *** [all] Error 2
------

 5 warnings found (use docker --debug to expand):
 - JSONArgsRecommended: JSON arguments recommended for CMD to prevent unintended behavior related to OS signals (line 27)
 - MaintainerDeprecated: Maintainer instruction is deprecated in favor of using label (line 5)
 - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 6)
 - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 7)
 - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 8)
Dockerfile:24
--------------------
  22 |     
  23 |     # compile GLnexus
  24 | >>> RUN cmake -DCMAKE_BUILD_TYPE=$build_type . && make -j4
  25 |     
  26 |     # set up default container start to run tests
--------------------
ERROR: failed to solve: process ""/bin/sh -c cmake -DCMAKE_BUILD_TYPE=$build_type . && make -j4"" did not complete successfully: exit code: 2",bcantarel,https://github.com/dnanexus-rnd/GLnexus/issues/319
